Larger Text,Smaller Text,Symbol
Docker and Kubernetes for Java Developers,NA,NA
"Scale, deploy, and monitor multi-container applications",NA,NA
Jaroslaw Krochmalski,NA,NA
BIRMINGHAM - MUMBAI,NA,NA
Docker and Kubernetes for Java,NA,NA
Developers,NA,NA
Copyright © 2017 Packt Publishing,NA,NA
"All rights reserved. No part of this book may be reproduced, stored in a retrieval ",NA,NA
"system, or transmitted in any form or by any means, without the prior written ",NA,NA
"permission of the publisher, except in the case of brief quotations embedded in ",NA,NA
critical articles or reviews.,NA,NA
Every effort has been made in the preparation of this book to ensure the accuracy of ,NA,NA
"the information presented. However, the information contained in this book is sold ",NA,NA
"without warranty, either express or implied. Neither the author(s), nor Packt ",NA,NA
"Publishing, and its dealers and distributors will be held liable for any damages ",NA,NA
caused or alleged to be caused directly or indirectly by this book.,NA,NA
Packt Publishing has endeavored to provide trademark information about all of the ,NA,NA
companies and products mentioned in this book by the appropriate use of capitals.,NA,NA
"However, Packt Publishing cannot guarantee the accuracy of this information.",NA,NA
First published: August 2017,NA,NA
Production reference: 1240817,NA,NA
Published by Packt Publishing Ltd.,NA,NA
Livery Place ,NA,NA
35 Livery Street ,NA,NA
Birmingham ,NA,NA
"B3 2PB, UK.",NA,NA
ISBN 978-1-78646-839-0,NA,NA
www.packtpub.com,NA,NA
Credits,NA,NA
Author ,NA,NA
Jaroslaw Krochmalski,NA,NA
Copy Editor ,NA,NA
Safis Editing,NA,NA
Reviewer ,NA,NA
Pierre Mavro,NA,NA
Project Coordinator ,NA,NA
Kinjal Bari,NA,NA
Commissioning Editor ,NA,NA
Vijin Boricha,NA,NA
Proofreader ,NA,NA
Safis Editing,NA,NA
Acquisition Editor ,NA,NA
Prachi Bisht,NA,NA
Indexer ,NA,NA
Mariammal Chettiyar,NA,NA
ContentDevelopmentEditor ,NA,NA
Trusha Shriyan,NA,NA
Graphics ,NA,NA
Kirk D'Penha,NA,NA
Technical Editor ,NA,NA
Varsha Shivhare,NA,NA
Production Coordinator ,NA,NA
Shantanu Zagade,NA,NA
About the Author,NA,NA
Jaroslaw Krochmalski,NA,NA
 is a passionate software designer and developer who ,NA,NA
specializes in the financial domain. He has over 12 years of experience in software ,NA,NA
development. He is a clean-code and software craftsmanship enthusiast. He is a ,NA,NA
certified scrum master and a fan of Agile. His professional interests include new ,NA,NA
"technologies in web application development, design patterns, enterprise ",NA,NA
"architectures, and integration patterns.",NA,NA
He has been designing and developing software professionally since 2000 and has ,NA,NA
"been using Java as his primary programming language since 2002. In the past, he has ",NA,NA
worked for companies such as ,NA,NA
Kredyt Bank,NA,NA
 (,NA,NA
KBC,NA,NA
) and Bank BPS on many large-,NA,NA
"scale projects, such as international money orders, express payments, and collection ",NA,NA
systems. He currently works as a consultant at Danish company 7N as an ,NA,NA
infrastructure architect for the Nykredit bank. You can reach him via Twitter at ,@jkroch,NA
 or by email at ,jarek@finsys.pl,NA
.,NA,NA
About the Reviewer,NA,NA
Pierre Mavro,NA,NA
 lives in a suburb of Paris. He's an open source software lover and has ,NA,NA
"been working with Linux for more than 10 years now. Currently, he is working as a ",NA,NA
"lead SRE at Criteo, where he manages distributed systems and NoSQL technologies.",NA,NA
"During the last few years, he has been designing high-availability infrastructures, ",NA,NA
"public and private cloud infrastructures, and worked for a high-frequency trading ",NA,NA
company. He also wrote a book on MariaDB named ,NA,NA
MariaDB High Performance,NA,NA
. ,NA,NA
"He’s also one of the co-founders of Nousmotards, an application for riders.",NA,NA
www.PacktPub.com,NA,NA
"For support files and downloads related to your book, please visit ",NA,NA
www.PacktPub.com,NA,NA
. ,NA,NA
"Did you know that Packt offers eBook versions of every book published, with PDF ",NA,NA
and ePub files available? You can upgrade to the eBook version ,NA,NA
at ,NA,NA
www.PacktPub.com,NA,NA
" and as a print book customer, you are entitled to a discount on ",NA,NA
the eBook copy. Get in touch with us at ,service@packtpub.com,NA
 for more details. At ,NA,NA
www ,NA,NA
.PacktPub.com,NA,NA
", you can also read a collection of free technical articles, sign up for a ",NA,NA
range of free newsletters and receive exclusive discounts and offers on Packt books ,NA,NA
and eBooks.,NA,NA
https://www.packtpub.com/mapt,NA,NA
Get the most in-demand software skills with Mapt. Mapt gives you full access to all ,NA,NA
"Packt books and video courses, as well as industry-leading tools to help you plan ",NA,NA
your personal development and advance your career.,NA,NA
Why subscribe?,NA,NA
Fully searchable across every book published by Packt,NA,NA
"Copy and paste, print, and bookmark content",NA,NA
On demand and accessible via a web browser,NA,NA
Customer Feedback,NA,NA
"Thanks for purchasing this Packt book. At Packt, quality is at the heart of our ",NA,NA
"editorial process. To help us improve, please leave us an honest review on this ",NA,NA
book's Amazon page at ,NA,NA
https://www.amazon.com/dp/1786468395,NA,NA
.,NA,NA
"If you'd like to join our team of regular reviewers, you can e-mail us at ",customerreviews@packtpub.com,NA
. We award our regular reviewers with free eBooks and ,NA,NA
videos in exchange for their valuable feedback. Help us be relentless in improving ,NA,NA
our products!,NA,NA
Table of Contents,NA,NA
Preface ,NA,NA
What this book covers ,NA,NA
What you need for this book ,NA,NA
Who this book is for ,NA,NA
Conventions ,NA,NA
Reader feedback ,NA,NA
Customer support ,NA,NA
Downloading the example code ,NA,NA
Downloading the color images of this book ,NA,NA
Errata ,NA,NA
Piracy ,NA,NA
Questions ,NA,NA
1. ,NA,NA
Introduction to Docker ,NA,NA
The idea behind Docker ,NA,NA
Virtualization and containerization compared ,NA,NA
Benefits from using Docker ,NA,NA
Docker concepts - images and containers ,NA,NA
Images ,NA,NA
Layers ,NA,NA
Containers ,NA,NA
"Docker registry, repository, and index ",NA,NA
Additional tools ,NA,NA
Installing Docker ,NA,NA
Installing on macOS ,NA,NA
Installing on Linux ,NA,NA
Installing on Windows ,NA,NA
Summary ,NA,NA
2. ,NA,NA
Networking and Persistent Storage ,NA,NA
Networking ,NA,NA
Docker network types ,NA,NA
Bridge ,NA,NA
Host ,NA,NA
None ,NA,NA
Networking commands ,NA,NA
Creating and inspecting a network ,NA,NA
Connecting a container to the network ,NA,NA
Exposing ports and mapping ports ,NA,NA
Persistent storage,NA,NA
Volume-related commands ,NA,NA
Creating a volume ,NA,NA
Removing a volume ,NA,NA
Volume drivers ,NA,NA
Summary ,NA,NA
3. ,NA,NA
Working with Microservices ,NA,NA
An introduction to microservices ,NA,NA
Monolithic versus microservices ,NA,NA
The monolithic architecture ,NA,NA
The microservices architecture ,NA,NA
Maintaining data consistency ,NA,NA
The Docker role ,NA,NA
Kubernetes' role ,NA,NA
When to use the microservice architecture ,NA,NA
Summary ,NA,NA
4. ,NA,NA
Creating Java Microservices ,NA,NA
Introduction to REST ,NA,NA
HTTP methods ,NA,NA
REST in Java ,NA,NA
Java EE7 - JAX-RS with Jersey ,NA,NA
JAX-RS annotations ,NA,NA
Spring Boot ,NA,NA
Coding the Spring Boot microservice ,NA,NA
Maven build file ,NA,NA
Application entry point ,NA,NA
Domain model and a repository ,NA,NA
REST controller ,NA,NA
Documenting the API ,NA,NA
Running the application ,NA,NA
Making calls ,NA,NA
Spring RestTemplate ,NA,NA
HTTPie ,NA,NA
Postman ,NA,NA
Paw for Mac ,NA,NA
Spring Initializr ,NA,NA
Summary ,NA,NA
5. ,NA,NA
Creating Images with Java Applications ,NA,NA
Dockerfile ,NA,NA
Dockerfile instructions ,NA,NA
FROM ,NA,NA
MAINTAINER,NA,NA
WORKDIR ,NA,NA
ADD ,NA,NA
COPY ,NA,NA
RUN ,NA,NA
CMD ,NA,NA
The ENTRYPOINT ,NA,NA
EXPOSE ,NA,NA
VOLUME ,NA,NA
LABEL ,NA,NA
ENV ,NA,NA
USER ,NA,NA
ARG ,NA,NA
ONBUILD ,NA,NA
STOPSIGNAL ,NA,NA
HEALTHCHECK ,NA,NA
Creating an image using Maven ,NA,NA
Building the image ,NA,NA
Creating and removing volumes ,NA,NA
Summary ,NA,NA
6. ,NA,NA
Running Containers with Java Applications ,NA,NA
Starting and stopping containers ,NA,NA
Starting ,NA,NA
Stopping ,NA,NA
Listing the running containers ,NA,NA
Removing the containers ,NA,NA
Container running modes ,NA,NA
Foreground ,NA,NA
Detached ,NA,NA
Attaching to running containers ,NA,NA
Monitoring containers ,NA,NA
Viewing logs ,NA,NA
Inspecting a container ,NA,NA
Statistics ,NA,NA
Container events ,NA,NA
Restart policies ,NA,NA
no ,NA,NA
always ,NA,NA
on-failure ,NA,NA
unless-stopped ,NA,NA
Updating a restart policy on a running container,NA,NA
Runtime constraints on resources ,NA,NA
Memory ,NA,NA
Processors ,NA,NA
Updating constraints on a running container ,NA,NA
Running with Maven ,NA,NA
Plugin configuration ,NA,NA
Starting and stopping containers ,NA,NA
Summary ,NA,NA
7. ,NA,NA
Introduction to Kubernetes ,NA,NA
Why do we need Kubernetes?,NA,NA
Basic Kubernetes concepts ,NA,NA
Pods ,NA,NA
ReplicaSets ,NA,NA
Deployment ,NA,NA
Services ,NA,NA
kube-dns ,NA,NA
Namespace ,NA,NA
Nodes ,NA,NA
Kubelet ,NA,NA
Proxy ,NA,NA
Docker ,NA,NA
The Master node ,NA,NA
etcd ,NA,NA
The API server ,NA,NA
The scheduler ,NA,NA
Available tools ,NA,NA
kubectl ,NA,NA
Dashboard ,NA,NA
Minikube ,NA,NA
Summary ,NA,NA
8. ,NA,NA
Using Kubernetes with Java ,NA,NA
Installing Minikube ,NA,NA
Installing on Mac ,NA,NA
Installing on Windows ,NA,NA
Installing on Linux ,NA,NA
Starting up the local Kubernetes cluster ,NA,NA
Installing kubectl ,NA,NA
Installing on Mac ,NA,NA
Installing on Windows ,NA,NA
Installing on Linux ,NA,NA
Deploying on the Kubernetes cluster,NA,NA
Creating a service ,NA,NA
Creating a deployment ,NA,NA
Interacting with containers and viewing logs ,NA,NA
Scaling manually ,NA,NA
Autoscaling ,NA,NA
Viewing cluster events ,NA,NA
Using the Kubernetes dashboard ,NA,NA
Minikube addons ,NA,NA
Cleaning up ,NA,NA
Summary ,NA,NA
9. ,NA,NA
Working with the Kubernetes API ,NA,NA
API versioning ,NA,NA
Alpha ,NA,NA
Beta ,NA,NA
Stable ,NA,NA
Authentication ,NA,NA
HTTP basic auth ,NA,NA
Static token file ,NA,NA
Client certificates ,NA,NA
OpenID ,NA,NA
Authorization ,NA,NA
Attribute-based access control ,NA,NA
Role-based access control (RBAC) ,NA,NA
WebHook ,NA,NA
AlwaysDeny ,NA,NA
AlwaysAllow ,NA,NA
Admission control ,NA,NA
Using the API ,NA,NA
API operations ,NA,NA
Example calls ,NA,NA
Creating a service using the API ,NA,NA
Creating a deployment using the API ,NA,NA
Deleting a service and deployment ,NA,NA
Swagger docs ,NA,NA
Summary ,NA,NA
10. ,NA,NA
Deploying Java on Kubernetes in the Cloud ,NA,NA
"Benefits of using the cloud, Docker, and Kubernetes ",NA,NA
Installing the tools ,NA,NA
Python and PIP ,NA,NA
AWS command-line tools,NA,NA
Kops ,NA,NA
jq ,NA,NA
Configuring Amazon AWS ,NA,NA
Creating an administrative user ,NA,NA
Creating a user for kops ,NA,NA
Creating the cluster ,NA,NA
DNS settings ,NA,NA
Root domain on AWS hosted domain ,NA,NA
The subdomain of the domain hosted on AWS ,NA,NA
Route 53 for a domain purchased with another registrar ,NA,NA
"Subdomain for cluster in AWS Route 53, the domain elsewhere ",NA,NA
Checking the zones' availability ,NA,NA
Creating the storage ,NA,NA
Creating a cluster ,NA,NA
Starting up clusters ,NA,NA
Updating a cluster ,NA,NA
Installing the dashboard ,NA,NA
Summary ,NA,NA
11. ,NA,NA
More Resources ,NA,NA
Docker ,NA,NA
Awesome Docker ,NA,NA
Blogs ,NA,NA
Interactive tutorials ,NA,NA
Kubernetes ,NA,NA
Awesome Kubernetes ,NA,NA
Tutorials ,NA,NA
Blogs ,NA,NA
Extensions ,NA,NA
Tools ,NA,NA
Rancher ,NA,NA
Helm and charts ,NA,NA
Kompose ,NA,NA
Kubetop ,NA,NA
Kube-applier,NA,NA
Preface,NA,NA
Imagine creating and testing Java EE applications on Apache Tomcat or Wildfly in ,NA,NA
"minutes, along with deploying and managing Java applications swiftly. Sounds too ",NA,NA
"good to be true? You have a reason to cheer, because such scenarios are possible by ",NA,NA
leveraging Docker and Kubernetes.,NA,NA
This book will start by introducing Docker and delve deep into its networking and ,NA,NA
persistent storage concepts. You will be then introduced to the concept of ,NA,NA
microservices and learn how to deploy and run Java microservices as Docker ,NA,NA
"containers. Moving on, the book will focus on Kubernetes and its features. You will ",NA,NA
start by running the local cluster using Minikube. The next step will be to deploy ,NA,NA
"your Java service in the real cloud, on Kubernetes running on top of Amazon AWS.",NA,NA
"At the end of the book, you will get hands-on experience of some more advanced ",NA,NA
topics to further extend your knowledge of Docker and Kubernetes.,NA,NA
What this book covers,NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", introduces the reasoning behind Docker and ",NA,NA
presents the differences between Docker and traditional virtualization. The chapter ,NA,NA
"also explains basic Docker concepts, such as images, containers, and Dockerfiles.",NA,NA
Chapter 2,NA,NA
", ",NA,NA
Networking and Persistent Storage,NA,NA
", explains how networking and ",NA,NA
persistent storage work in Docker containers.,NA,NA
Chapter 3,NA,NA
", ",NA,NA
Working with Microservices,NA,NA
", presents an overview of what microservices ",NA,NA
are and explains their advantages in comparison to monolithic architectures.,NA,NA
Chapter 4,NA,NA
", ",NA,NA
Creating Java Microservices,NA,NA
", explores a recipe for quickly constructing ",NA,NA
"Java microservice, by utilizing either Java EE7 or the Spring Boot.",NA,NA
Chapter 5,NA,NA
", ",NA,NA
Creating Images with Java Applications,NA,NA
", teaches how to package the Java ",NA,NA
"microservices into Docker images, either manually or from the Maven build file.",NA,NA
Chapter 6,NA,NA
", ",NA,NA
Running Containers with Java Applications,NA,NA
", shows how to run a ",NA,NA
containerized Java application using Docker.,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", introduces the core concepts of Kubernetes, ",NA,NA
"such as Pods, nodes, services, and deployments.",NA,NA
Chapter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
", shows how to deploy Java microservices, ",NA,NA
"packaged as a Docker image, on the local Kubernetes cluster.",NA,NA
Chapter 9,NA,NA
", ",NA,NA
Working with Kubernetes API,NA,NA
", shows how the Kubernetes API can be used ",NA,NA
to automate the creation of Kubernetes objects such as services or deployments. This ,NA,NA
chapter gives examples of how to use the API to get information about the cluster's ,NA,NA
state.,NA,NA
Chapter 10,NA,NA
", ",NA,NA
Deploying Java on Kubernetes in the Cloud,NA,NA
", shows the reader how to ",NA,NA
configure Amazon AWS EC2 instances to make them suitable to run a ,NA,NA
Kubernetes cluster. This chapter also gives precise instructions on how to create a ,NA,NA
Kubernetes cluster on the Amazon AWS cloud.,NA,NA
Chapter 11,NA,NA
", ",NA,NA
More Resources,NA,NA
", explores how Java and Kubernetes point the reader to ",NA,NA
"additional resources available on the internet that are of high quality, to further",NA,NA
extend knowledge about Docker and Kubernetes.,NA,NA
What you need for this book ,NA,NA
"For this book, you will need any decent PC or Mac, capable of running a modern ",NA,NA
"version of Linux, Windows 10 64-bit, or macOS.",NA,NA
Who this book is for,NA,NA
"This book is for Java developers, who would like to get into the world of ",NA,NA
containerization. The reader will learn how Docker and Kubernetes can help with ,NA,NA
"deployment and management of Java applications on clusters, either on their own ",NA,NA
infrastructure or in the cloud.,NA,NA
Conventions,NA,NA
"In this book, you will find a number of text styles that distinguish between different ",NA,NA
kinds of information. Here are some examples of these styles and an explanation of ,NA,NA
"their meaning. Code words in text, database table names, folder names, filenames, ",NA,NA
"file extensions, pathnames, dummy URLs, user input, and Twitter handles are shown ",NA,NA
"as follows: ""The Dockerfile is used to create the image when you run the ",docker build,NA
"command."" A block of code is set as follows:","{ 
  
 ""apiVersion"": ""v1"", 
  
 ""kind"": ""Pod"", 
  
 ""metadata"":{ 
  
 ""name"": ”rest_service”, 
  
 ""labels"": { 
  
 ""name"": ""rest_service"" 
  
 } 
  
 }, 
  
 ""spec"": { 
  
 ""containers"": [{ 
  
 ""name"": ""rest_service"", 
  
 ""image"": ""rest_service"", 
  
 ""ports"": [{""containerPort"": 8080}], 
  
 }] 
  
 } 
  
 }",NA
Any command-line input or output is written as follows:,docker rm $(docker ps -a -q -f status=exited),NA
New terms,NA,NA
 and ,NA,NA
important words,NA,NA
 are shown in bold. Words that you see on the ,NA,NA
"screen, for example, in menus or dialog boxes, appear in the text like this: ",NA,NA
"""Clicking the Skip For Now will take you to the the images list without logging ",NA,NA
"into the Docker Hub.""",NA,NA
Warnings or important notes appear in a box like this.,NA,NA
Tips and tricks appear like this.,NA,NA
Reader feedback,NA,NA
Feedback from our readers is always welcome. Let us know what you think about ,NA,NA
this book-what you liked or disliked. Reader feedback is important for us as it helps ,NA,NA
us develop titles that you will really get the most out of. To send us general ,NA,NA
"feedback, simply email ",feedback@packtpub.com,NA
", and mention the book's title in the ",NA,NA
subject of your message. If there is a topic that you have expertise in and you are ,NA,NA
"interested in either writing or contributing to a book, see our author guide at ",NA,NA
www.pac ,NA,NA
ktpub.com/authors,NA,NA
.,NA,NA
Customer support ,NA,NA
"Now that you are the proud owner of a Packt book, we have a number of things to ",NA,NA
help you to get the most from your purchase.,NA,NA
Downloading the example code,NA,NA
You can download the example code files for this book from your account at ,NA,NA
http://w ,NA,NA
ww.packtpub.com,NA,NA
". If you purchased this book elsewhere, you can visit ",NA,NA
http://www.packtp ,NA,NA
ub.com/support,NA,NA
 and register to have the files emailed directly to you. You can ,NA,NA
download the code files by following these steps:,NA,NA
1. Log in or register to our website using your email address and password. ,NA,NA
2. Hover the mouse pointer on the SUPPORT tab at the top.,NA,NA
3. Click on Code Downloads & Errata.,NA,NA
4. Enter the name of the book in the Search box.,NA,NA
5. Select the book for which you're looking to download the code files. 6. ,NA,NA
Choose from the drop-down menu where you purchased this book from. 7. ,NA,NA
Click on Code Download.,NA,NA
"Once the file is downloaded, please make sure that you unzip or extract the folder ",NA,NA
using the latest version of:,NA,NA
WinRAR / 7-Zip for Windows,NA,NA
Zipeg / iZip / UnRarX for Mac,NA,NA
7-Zip / PeaZip for Linux,NA,NA
The code bundle for the book is also hosted on GitHub at ,NA,NA
https://github.com/PacktPublish ,NA,NA
ing/Docker-and-Kubernetes-for-Java-Developers,NA,NA
. We also have other code bundles from our ,NA,NA
rich catalog of books and videos available at ,NA,NA
https://github.com/PacktPublishing/,NA,NA
. Check ,NA,NA
them out!,NA,NA
Downloading the color images of this,NA,NA
book,NA,NA
We also provide you with a PDF file that has color images of the ,NA,NA
screenshots/diagrams used in this book. The color images will help you better ,NA,NA
understand the changes in the output. You can download this file from ,NA,NA
http://www.pack ,NA,NA
tpub.com/sites/default/files/downloads/DockerandKubernetesforJavaDevelopers_ColorImages.pdf,NA,NA
.,NA,NA
Errata,NA,NA
"Although we have taken every care to ensure the accuracy of our content, mistakes ",NA,NA
do happen. If you find a mistake in one of our books-maybe a mistake in the text or ,NA,NA
"the code-we would be grateful if you could report this to us. By doing so, you can ",NA,NA
save other readers from frustration and help us improve subsequent versions of this ,NA,NA
"book. If you find any errata, please report them by visiting ",NA,NA
http://www.packtpub.com/sub ,NA,NA
mit-errata,NA,NA
", selecting your book, clicking on the Errata Submission Form link, and ",NA,NA
"entering the details of your errata. Once your errata are verified, your submission ",NA,NA
will be accepted and the errata will be uploaded to our website or added to any list of ,NA,NA
existing errata under the Errata section of that title. To view the previously submitted ,NA,NA
"errata, go to ",NA,NA
https://www.packtpub.com/books/content/support,NA,NA
 and enter the name of the ,NA,NA
book in the search field. The required information will appear under the Errata ,NA,NA
section.,NA,NA
Piracy,NA,NA
Piracy of copyrighted material on the internet is an ongoing problem across all ,NA,NA
"media. At Packt, we take the protection of our copyright and licenses very seriously. ",NA,NA
"If you come across any illegal copies of our works in any form on the internet, please ",NA,NA
provide us with the location address or website name immediately so that we can ,NA,NA
pursue a remedy. Please contact us at ,copyright@packtpub.com,NA
 with a link to the ,NA,NA
suspected pirated material. We appreciate your help in protecting our authors and our ,NA,NA
ability to bring you valuable content.,NA,NA
Questions ,NA,NA
"If you have a problem with any aspect of this book, you can contact us at ",questions@packtpub.com,NA
", and we will do our best to address the problem.",NA,NA
Introduction to Docker,NA,NA
The first thing we will do in this chapter will be to explain the reasoning behind ,NA,NA
"Docker and its architecture. We will cover Docker concepts such as images, layers, ",NA,NA
"and containers. Next, we will install Docker and learn how to pull a sample, basic ",NA,NA
Java application image from the ,remote,NA
 registry and run it on the local machine.,NA,NA
"Docker was created as the internal tool in the platform as a service company, ",NA,NA
"dotCloud. In March 2013, it was released to the public as open source. Its source ",NA,NA
code is freely available to everyone on GitHub at: ,NA,NA
https://github.com/docker/docker,NA,NA
. Not ,NA,NA
"only do the core Docker Inc. team work on the development of Docker, there are ",NA,NA
also a lot of big names sponsoring their time and effort to enhance and contribute to ,NA,NA
"Docker such as Google, Microsoft, IBM, Red Hat, Cisco systems, and many others. ",NA,NA
Kubernetes is a tool developed by Google for deploying containers across clusters of ,NA,NA
computers based on best practices learned by them on Borg (Google's homemade ,NA,NA
"container system). It compliments Docker when it comes to orchestration, ",NA,NA
"automating deployment, managing, and scaling containers; it manages workloads for ",NA,NA
Docker nodes by keeping container deployments balanced across a cluster.,NA,NA
"Kubernetes also provides ways for containers to communicate with each other, ",NA,NA
without the need for opening network ports. Kubernetes is also an open source ,NA,NA
"project, living on the GitHub at ",NA,NA
https://github.com/kubernetes/kubernetes,NA,NA
. Everyone can ,NA,NA
contribute. Let's begin our journey with Docker first. The following will be covered ,NA,NA
in:,NA,NA
We will start with the basic idea behind this wonderful tool and show the ,NA,NA
"benefits gained from using it, in comparison to traditional virtualization",NA,NA
"We will install Docker on three major platforms: macOS, Linux, and Windows",NA,NA
The idea behind Docker,NA,NA
The idea behind Docker is to pack an application with all the dependencies it needs ,NA,NA
"into a single, standardized unit for the deployment. Those dependencies can be ",NA,NA
"binaries, libraries, JAR files, configuration files, scripts, and so on. Docker wraps up ",NA,NA
all of it into a complete filesystem that contains everything your Java application ,NA,NA
"needs to run the virtual machine itself, the application server such as Wildfly or ",NA,NA
"Tomcat, the application code, and ",runtime,NA
" libraries, and basically everything you ",NA,NA
would install and deploy on the server to make your application run. Packaging all of ,NA,NA
this into a complete image guarantees that it is portable; it will always run in the ,NA,NA
"same way, no matter what environment it is deployed in. With Docker, you can run ",NA,NA
Java applications without having to install a Java runtime on the host machine. All ,NA,NA
"the problems related to incompatible JDK or JRE, wrong version of the application ",NA,NA
"server, and so on are gone. Upgrades are also easy and effortless; you just run the ",NA,NA
new version of your container on the host.,NA,NA
"If you need to do some cleanup, you can just destroy the Docker image and it's as ",NA,NA
"though nothing ever happened. Think about Docker, not as a programming language ",NA,NA
"or a framework, but rather as a tool that helps in solving the common problems such ",NA,NA
"as installing, distributing, and managing the software. It allows developers and ",NA,NA
"DevOps to build, ship, and run their code anywhere. Anywhere means also on more ",NA,NA
"than one machine, and this is where Kubernetes comes in handy; we will shortly get ",NA,NA
back to it.,NA,NA
Having all of your application code and runtime dependencies packaged as a single ,NA,NA
"and complete unit of software may seem the same as a virtualization engine, but it's ",NA,NA
"far from that, as we will explain now. To fully get to know what Docker really is, ",NA,NA
first we need to understand the difference between traditional virtualization and ,NA,NA
containerization. Let's compare those two technologies now.,NA,NA
Virtualization and containerization,NA,NA
compared,NA,NA
"A traditional virtual machine represents the hardware-level virtualization. In essence, ",NA,NA
"it's a complete, virtualized physical machine with BIOS and an operating system ",NA,NA
installed. It runs on top of the host operating system. Your Java application runs in ,NA,NA
the virtualized environment as it would normally do on your own machine. There are ,NA,NA
a lot of advantages from using virtual machines for your applications. Each virtual ,NA,NA
machine can have a totally different operating system; those can be different Linux ,NA,NA
"flavors, Solaris, or Windows, for example. Virtual machines are also very secure by ",NA,NA
"definition; they are totally isolated, complete operating systems in a box.",NA,NA
"However, nothing comes without a price. Virtual machines contain all the features ",NA,NA
"that an operating system needs to have to be operational: core system libraries, ",NA,NA
"device drivers, and so on. Sometimes they can be resource hungry and heavyweight. ",NA,NA
"Virtual machines require full installation, which sometimes can be cumbersome and ",NA,NA
"not so easy to set up. Last, but not least, you will need more compute power and ",NA,NA
resources to execute your application in the virtual machine the hypervisor needs to ,NA,NA
"first import the virtual machine and then power it up and this takes time. However, I ",NA,NA
"believe, when it comes to running Java applications, having the complete virtualized ",NA,NA
environment is not something that we would want very often. Docker comes to the ,NA,NA
"rescue with the concept of containerization. Java applications (but of course, it's not ",NA,NA
limited to Java) run on Docker in an isolated environment called a container. A ,NA,NA
container is not a virtual machine in the popular sense. It behaves as a kind of ,NA,NA
"operating system virtualization, but there's no emulation at all. The main difference ",NA,NA
is that while each traditional virtual machine image runs on an independent guest ,NA,NA
"operating system, the Docker containers run within the same kernel running on the ",NA,NA
host machine. A container is self-sufficient and isolated not only from the underlying ,NA,NA
"OS, but from other containers as well. It has its own separated filesystem and ",NA,NA
"environment variables. Naturally, containers can communicate with each other (as an ",NA,NA
application and a database container for example) and also can share the files on ,NA,NA
disk. Here comes the main difference when comparing to traditional virtualization ,NA,NA
because the containers run within the same kernel they utilize fewer system ,NA,NA
resources. All the operating system core software is removed from the Docker ,NA,NA
"image. The base container can be, and usually is, very lightweight. There is no ",NA,NA
overhead related to a classic virtualization hypervisor and a guest operating system.,NA,NA
"This way you can achieve almost bare metal, core performance for your Java ",NA,NA
"applications. Also, the startup time of a containerized Java application is usually very ",NA,NA
low due to the minimal overhead of the container. You can also roll-out hundreds of ,NA,NA
application containers in seconds to reduce the time needed for provisioning your ,NA,NA
software. We will do this using Kubernetes in one of the coming chapters. Although ,NA,NA
Docker is quite different from the traditional virtualization engines. Be aware that ,NA,NA
containers cannot substitute virtual machines for all use cases; a thoughtful ,NA,NA
evaluation is still required to determine what is best for your application. Both ,NA,NA
"solutions have their advantages. On the one hand, we have the fully isolated secure ",NA,NA
"virtual machine with average performance. On the other hand, we have the ",NA,NA
"containers that are missing some of the key features, but are equipped with high ",NA,NA
performance that can be provisioned very fast. Let's see what other benefits you will ,NA,NA
get when using Docker containerization.,NA,NA
Benefits from using Docker,NA,NA
"As we have said before, the major visible benefit of using Docker will be very fast ",NA,NA
performance and short provisioning time. You can create or destroy containers ,NA,NA
quickly and easily. Containers share resources such as the operating system's kernel ,NA,NA
"and the needed libraries efficiently with other Docker containers. Because of that, ",NA,NA
multiple versions of an application running in containers will be very lightweight. ,NA,NA
"The result is faster deployment, easier migration, and startup times.",NA,NA
Docker can be especially useful when deploying Java microservices. We will get ,NA,NA
back to microservices in detail in one of the coming chapters. A microservices ,NA,NA
"application is composed of a series of discrete services, communicating with others ",NA,NA
via an API. Microservices break an app into a large number of small processes. They ,NA,NA
"are the opposite of the monolithic applications, which run all operations as a single ",NA,NA
process or a set of large processes.,NA,NA
"Using Docker containers enables you to deploy ready-to-run software, which is ",NA,NA
portable and extremely easy to distribute. Your containerized application simply runs ,NA,NA
within its container; there's no need for installation. The lack of an installation ,NA,NA
process has a huge advantage; it eliminates problems such as software and library ,NA,NA
conflicts or even driver compatibility issues. Docker containers are portable; they ,NA,NA
"can be run from anywhere: your local machine, a remote server, and private or public ",NA,NA
"cloud. All major cloud computing providers, such as ",NA,NA
Amazon Web Services,NA,NA
 (,NA,NA
AWS,NA,NA
) ,NA,NA
"and Google's compute platform support Docker now. A container running on, let's ",NA,NA
"say, an Amazon EC2 instance, can easily be transferred to some other environment, ",NA,NA
achieving exactly the same consistency and functionality. The additional level of ,NA,NA
abstraction Docker provides on the top of your infrastructure layer is an ,NA,NA
indispensable feature. Developers can create the software without worrying about the ,NA,NA
"platform it will later be run on. Docker has the same promise as Java; write once, run ",NA,NA
"anywhere; except instead of code, you configure your server exactly the way you ",NA,NA
"want it (by picking the operating system, tuning the configuration files, installing ",NA,NA
dependencies) and you can be certain that your server template will run exactly the ,NA,NA
same on any host that runs Docker.,NA,NA
"Because of Docker's reproducible build environment, it's particularly well suited for ",NA,NA
"testing, especially in your continuous integration or continuous delivery flow. You ",NA,NA
can quickly boot up identical environments to run the tests. And because the ,NA,NA
"container images are all identical each time, you can distribute the workload and run",NA,NA
tests in parallel without a problem. Developers can run the same image on their ,NA,NA
"machine that will be run in production later, which again has a huge advantage in ",NA,NA
testing.,NA,NA
The use of Docker containers speeds up continuous integration. There are no more ,NA,NA
endless build-test-deploy cycles; Docker containers ensure that applications run ,NA,NA
"identically in development, test, and production environments. The code grows over ",NA,NA
time and becomes more and more troublesome. That's why the idea of an immutable ,NA,NA
infrastructure becomes more and more popular nowadays and the concept of ,NA,NA
containerization has become so popular. By putting your Java applications into ,NA,NA
"containers, you can simplify the process of deployment and scaling. By having a ",NA,NA
"lightweight Docker host that needs almost no configuration management, you ",NA,NA
manage your applications simply by deploying and redeploying containers to the ,NA,NA
"host. And again, because the containers are very lightweight, it takes only seconds.",NA,NA
"We have been talking a lot about images and containers, without getting much into ",NA,NA
the details. Let's do it now and see what Docker images and containers are.,NA,NA
Docker concepts - images ,NA,NA
and containers,NA,NA
"When dealing with Kubernetes, we will be working with Docker containers; it is an ",NA,NA
"open source container cluster manager. To run our own Java application, we will ",NA,NA
need to create an image first. Let's begin with the concept of Docker images.,NA,NA
Images,NA,NA
Think of an image as a read-only template which is a base foundation to create a ,NA,NA
container from. It's same as a recipe containing the definition of everything your ,NA,NA
application needs to operate. It can be Linux with an application server (such as ,NA,NA
"Tomcat or Wildfly, for example) and your Java application itself. Every image starts ",NA,NA
"from a base image; for example, Ubuntu; a Linux image. Although you can begin ",NA,NA
"with a simple image and build your application stack on top of it, you can also pick ",NA,NA
an already prepared image from the hundreds available on the Internet. There are a ,NA,NA
lot of images especially useful for Java developers: ,openjdk,NA
", ",tomcat,NA
", ",wildfly,NA
", and many ",NA,NA
others. We will use them later as a foundation for our own images. It's a lot easier to ,NA,NA
"have, let's say, Wildfly installed and configured properly as a starting point for your ",NA,NA
own image. You can then just focus on your Java application. If you're a novice in ,NA,NA
"building images, downloading a specialized base image is a great way to get a ",NA,NA
serious speed boost in comparison to developing one by yourself.,NA,NA
"Images are created using a series of commands, called instructions. Instructions are ",NA,NA
"placed in the Dockerfile. The Dockerfile is just a plain text file, containing an ",NA,NA
ordered collection of ,root,NA
 filesystem changes (the same as running a command that ,NA,NA
"starts an application server, adding a file or directory, creating environmental ",NA,NA
"variables, and so on.) and the corresponding execution parameters for use within a ",NA,NA
container runtime later on. Docker will read the Dockerfile when you start the ,NA,NA
process of building an image and execute the instructions one by one. The result will ,NA,NA
be the final image. Each instruction creates a new layer in the image. That image ,NA,NA
layer then becomes the parent for the layer created by the next instruction. Docker ,NA,NA
images are highly portable across hosts and operating systems; an image can be run ,NA,NA
in a Docker container on any host that runs Docker. Docker is natively supported in ,NA,NA
"Linux, but has to be run in a VM on Windows and macOS. It's important to know ",NA,NA
"that Docker uses images to run your code, not the Dockerfile. The Dockerfile is used ",NA,NA
to create the image when you run the ,docker build,NA
" command. Also, if you publish ",NA,NA
"your image to the Docker Hub, you publish a resulting image with its layers, not a ",NA,NA
source Dockerfile itself.,NA,NA
We have said before that every instruction in a Dockerfile creates a new layer. ,NA,NA
Layers are the internal nature of an image; Docker images are composed from them. ,NA,NA
Let's explain now what they are and what their characteristics are.,NA,NA
Layers,NA,NA
"Each image consists of a series of layers which are stacked, one on top of the ",NA,NA
"another. In fact, every layer is an intermediate image. By using the ",NA,NA
union filesystem,NA,NA
", ",NA,NA
Docker combines all these layers into a single image entity. The union filesystem ,NA,NA
"allows transparent overlaying files and directories of separate filesystems, giving a ",NA,NA
"single, consistent filesystem as a result, as you can see the following diagram:",NA,NA
Contents and structure of directories which have the same path within these separate ,NA,NA
"filesystems will be seen together in a single merged directory, within the new, ",NA,NA
"virtual-like filesystem. In other words, the filesystem structure of the top layer will ",NA,NA
merge with the structure of the layer beneath. Files and directories which have the ,NA,NA
same path as in the previous layer will cover those beneath. Removing the upper ,NA,NA
layer will again reveal and expose the previous directory content. As we have ,NA,NA
"mentioned earlier, layers are placed in a stack, one on the top of another. To maintain ",NA,NA
"the order of layers, Docker utilizes the concept of layer IDs and pointers. Each layer ",NA,NA
contains the ID and a pointer to its parent layer. A layer without a pointer referencing ,NA,NA
"the parent is the first layer in the stack, a base. You can see the relation in the ",NA,NA
following diagram:,NA,NA
"Layers have some interesting features. First, they are reusable and cacheable. The ",NA,NA
pointer to a parent layer you can see in the previous diagram is important. As Docker ,NA,NA
is processing your Dockerfile it's looking at two things: the Dockerfile instruction ,NA,NA
being executed and the parent image. Docker will scan all of the children of the ,NA,NA
parent layer and look for one whose command matches the current instruction. If a ,NA,NA
"match is found, Docker skips to the next Dockerfile instruction and repeats the ",NA,NA
"process. If a matching layer is not found in the cache, a new one is created. For the ",NA,NA
"instructions that add files to your image (we will get to know them later in detail), ",NA,NA
"Docker creates a checksum for each file contents. During the building process, this ",NA,NA
checksum is compared against the checksum of the existing images to check if the ,NA,NA
"layer can be reused from the cache. If two different images have a common part, let's ",NA,NA
"say a Linux shell or Java runtime for example, Docker, which tracks all of the pulled ",NA,NA
"layers, will reuse the shell layer in both of the images. It's a safe operation; as you ",NA,NA
"already know, layers are read-only. When downloading another image, the layer will ",NA,NA
be reused and only the difference will be pulled from the Docker Hub. This saves ,NA,NA
"time, bandwidth, and disk space of course, but it has another great advantage. If you ",NA,NA
"modify your Docker image, for example by modifying your containerized Java ",NA,NA
"application, only the application layer gets modified. After you've successfully built ",NA,NA
"an image from your Dockerfile, you will notice that subsequent builds of the same ",NA,NA
"Dockerfile finish a lot faster. Once Docker caches an image layer for an instruction, ",NA,NA
"it doesn't need to be rebuilt. Later on, instead of distributing the whole image, you ",NA,NA
push just the updated part. It makes the process simpler and faster. This is especially ,NA,NA
useful if you use Docker in your continuous deployment flow: pushing a Git branch ,NA,NA
will trigger building an image and then publishing the application for users. Due to,NA,NA
"the layer-reuse feature, the whole process is a lot faster.",NA,NA
The concept of reusable layers is also a reason why Docker is so lightweight in ,NA,NA
"comparison to full virtual machines, which don't share anything. It is thanks to layers ",NA,NA
"that when you pull an image, you eventually don't have to download all of its ",NA,NA
filesystem. If you already have another image that has some of the layers of the ,NA,NA
"image you pull, only the missing layers are actually downloaded. There is a word of ",NA,NA
"warning though, related to another feature of layers: apart from being reusable, ",NA,NA
"layers are also additive. If you create a large file in the container, then make a ",NA,NA
"commit (we will get to that in a while), then delete the file, and do another commit; ",NA,NA
this file will still be present in the layer history. Imagine this scenario: you pull the ,NA,NA
"base Ubuntu image, and install the Wildfly application server. Then you change your ",NA,NA
"mind, uninstall the Wildfly and install Tomcat instead. All those files removed from ",NA,NA
"the Wildfly installation will still be present in the image, although they have been ",NA,NA
deleted. Image size will grow in no time. Understanding of Docker's layered ,NA,NA
filesystem can make a big difference in the size of your images. Size can become a ,NA,NA
problem when you publish your images to a registry; it takes more requests and is ,NA,NA
longer to transfer.,NA,NA
Large images become an issue when thousands of containers need to be deployed ,NA,NA
"across a cluster, for example. You should always be aware of the additivity of layers ",NA,NA
"and try to optimize the image at every step of your Dockerfile, the same as using the ",NA,NA
"command chaining, for example. We will be using the command chaining technique ",NA,NA
"later on, when creating our Java application images.",NA,NA
"Because layers are additive, they provide a full history of how a specific image was ",NA,NA
built. This gives you another great feature: the possibility to make a rollback to a ,NA,NA
certain point in the image's history. Since every image contains all of its building ,NA,NA
"steps, we can easily go back to a previous step if we want to. This can be done by ",NA,NA
tagging a certain layer. We will cover image tagging later in our book.,NA,NA
"Layers and images are closely related to each other. As we have said before, Docker ",NA,NA
images are stored as a series of read-only layers. This means that once the container ,NA,NA
"image has been created, it does not change. But having all the filesystem read-only ",NA,NA
would not make a lot of sense. What about modifying an image? Or adding your ,NA,NA
"software to a base web server image? Well, when we start a container, Docker ",NA,NA
actually takes the read-only image (with all its read-only layers) and adds a writable ,NA,NA
layer on top of the layers stack. Let's focus on the containers now.,NA,NA
Containers,NA,NA
A running instance of an image is called a container. Docker launches them using the ,NA,NA
"Docker images as read-only templates. If you start an image, you have a running ",NA,NA
"container of this image. Naturally, you can have many running containers of the ",NA,NA
"same image. In fact, we will do it very often a little bit later, using Kubernetes.",NA,NA
"To run a container, we use the ",docker run,NA
 command:,docker run [OPTIONS] IMAGE [COMMAND] [ARG...],NA
There are a lot of ,run,NA
 command options and switches that can be used; we will get to ,NA,NA
"know them later on. Some of the options include the network configuration, for ",NA,NA
example (we will explain Docker's networking concepts in ,NA,NA
Chapter 2,NA,NA
", ",NA,NA
Networking and ,NA,NA
Persistent Storage,NA,NA
"). Others, the same as the ",-it,NA
" (from interactive), tell the Docker ",NA,NA
"engine to behave differently; in this case, to make the container interactive and to ",NA,NA
attach a terminal to its output and input. Let's just focus on the idea of the container ,NA,NA
to better understand the whole picture. We are going to use the ,docker run,NA
  command ,NA,NA
in a short while to test our setup.,NA,NA
"So, what happens under the hood when we run the ",docker run,NA
 command? Docker will ,NA,NA
check if the image that you would like to run is available on your local machine. If ,NA,NA
"not, it will be pulled down from the ",remote,NA
 repository. The Docker engine takes the ,NA,NA
"image and adds a writable layer on top of the image's layers stack. Next, it initializes ",NA,NA
"the image's name, ID, and resource limits, such as CPU and memory. In this phase, ",NA,NA
Docker will also set up a container's IP address by finding and attaching an available ,NA,NA
"IP address from a pool. The last step of the execution will be the actual command, ",NA,NA
passed as the last parameter of the ,docker run,NA
 command. If the ,it,NA
 option has been ,NA,NA
"used, Docker will capture and provide the container output, it will be displayed in the ",NA,NA
console. You can now do things you would normally do when preparing an ,NA,NA
operating system to run your applications. This can be installing packages (via ,"apt-
 get",NA
", for example), pulling source code with Git, building your Java application using ",NA,NA
"Maven, and so on. All of these actions will modify the filesystem in the top, writable ",NA,NA
layer. If you then execute the ,commit,NA
" command, a new image containing all of your ",NA,NA
"changes will be created, kind of frozen, and ready to be run later. To stop a ",NA,NA
"container, use the ",docker stop,NA
 command:,docker stop,NA
A container when stopped will retain all settings and filesystem changes (in the top ,NA,NA
layer that is writeable). All processes running in the container will be stopped and ,NA,NA
you will lose everything in memory. This is what differentiates a stopped container ,NA,NA
from a Docker image.,NA,NA
"To list all containers you have on your system, either running or stopped, execute the ",docker ps,NA
 command:,docker ps -a,NA
"As a result, the Docker client will list a table containing container IDs (a unique ",NA,NA
"identifier you can use to refer to the container in other commands), creation date, the ",NA,NA
"command used to start a container, status, exposed ports, and a name, either assigned ",NA,NA
"by you or the funny name Docker has picked for you. To remove a container, you ",NA,NA
can just use the ,docker rm,NA
" command. If you want to remove a couple of them at once, ",NA,NA
you can use the list of containers (given by the ,docker ps,NA
 command) and a filter:,docker rm $(docker ps -a -q -f status=exited),NA
We have said that a Docker image is always read-only and immutable. If it did not ,NA,NA
"have the possibility to change the image, it would not be very useful. So how's the ",NA,NA
"image modification possible except by, of course, altering a Dockerfile and doing a ",NA,NA
"rebuild? When the container is started, the writable layer on top of the layers stack is ",NA,NA
for our disposal. We can actually make changes to a running container; this can be ,NA,NA
"adding or modifying files, the same as installing a software package, configuring the ",NA,NA
"operating system, and so on. If you modify a file in the running container, the file ",NA,NA
"will be taken out of the underlying (parent) read-only layer and placed in the top, ",NA,NA
writable layer. Our changes are only possible in the top layer. The union filesystem ,NA,NA
"will then cover the underlying file. The original, underlying file will not be modified; ",NA,NA
"it still exists safely in the underlying, read-only layer. By issuing the ",docker commit,NA
 ,NA,NA
"command, you create a new read-only image from a running container (and all it ",NA,NA
changes in the writable layer):,docker commit <container-id> <image-name>,NA
The ,docker commit,NA
 command saves changes you have made to the container in the ,NA,NA
"writable layer. To avoid data corruption or inconsistency, Docker will pause a ",NA,NA
container you are committing changes into. The result of the ,docker commit,NA
 command ,NA,NA
"is a brand new, read-only image, which you can create new containers from:",NA,NA
"In response to a successful commit, Docker will output the full ID of a newly ",NA,NA
generated image. If you remove the container without issuing a ,commit,NA
 first and then ,NA,NA
"relaunch the same image again, Docker will start a fresh container without any of the ",NA,NA
"changes made in the previously running container. In either case, with or without a ",commit,NA
", your changes to the filesystem will never affect the base image. Creating ",NA,NA
images by altering the top writable layer in the container is useful when debugging ,NA,NA
"and experimenting, but it's usually better to use a Dockerfile to manage your images ",NA,NA
in a documented and maintainable way.,NA,NA
We have now learned about the build (Dockerfile and the image) and runtime ,NA,NA
(container) pieces of our containerization world. We are still missing the last ,NA,NA
"element, the distribution component. The distribution component of Docker consists ",NA,NA
"of the Docker registry, index, and repository. Let's focus on them now to have a ",NA,NA
complete picture.,NA,NA
"Docker registry, repository, and index",NA,NA
The first component in Docker's distribution system is the registry. Docker utilizes a ,NA,NA
"hierarchical system for storing images, shown in the following screenshot:",NA,NA
Images which you build can be stored in a ,remote,NA
 registry for others to use. The ,Docker,NA
"registry is a service (an application, in fact) that is storing your Docker images. The ",NA,NA
Docker Hub is an example of the publicly available registry; it's free and serves a ,NA,NA
"huge, constantly growing collection of existing images. The repository, on the other ",NA,NA
"hand, is a collection (namespace) of related images, usually providing different ",NA,NA
versions of the same application or service. It's a collection of different Docker ,NA,NA
images with the same name and different tags.,NA,NA
If your app is named ,hello-world-java,NA
 and your username (or namespace) for the ,NA,NA
Registry is ,dockerJavaDeveloper,NA
 then your image will be placed in the ,dockerJavaDeveloper/hello-world-java,NA
 repository. You can tag an image and store ,NA,NA
multiple versions of that image with different IDs in a single named repository and ,NA,NA
access different tagged versions of an image with a special syntax such as ,username/image_name:tag,NA
. The ,Docker,NA
 repository is quite similar to a Git repository. For ,NA,NA
"example, ",Git,NA
", a ",Docker,NA
 repository is identified by a URI and can either be public or ,NA,NA
private. The URI looks the same as the following:,{registryAddress}/{namespace}/{repositoryName}:{tag},NA
The Docker Hub is the default registry and Docker will pull images from the Docker ,NA,NA
"Hub if you do not specify a registry address. To search an image in the registry, ",NA,NA
execute the ,docker search,NA
 command; for example:,$ docker search hello-java-world,NA
Without specifying the ,remote,NA
" registry, Docker will conduct a search on the ",NA,NA
Docker Hub and output the list of images matching your search criteria:,NA,NA
The difference between the registry and repository can be confusing at the ,NA,NA
"beginning, so let's describe what will happen if you execute the following command:",$ docker pull ubuntu:16.04,NA
The command downloads the image tagged ,16.04,NA
 within the ,ubuntu,NA
 repository from ,NA,NA
the Docker Hub registry. The official ,ubuntu,NA
" repository doesn't use a username, so the ",NA,NA
namespace part is omitted in this example.,NA,NA
"Although the Docker Hub is public, you get one private repository for free with your ",NA,NA
"Docker Hub user account. Last, but not least, the component you should be aware of ",NA,NA
is an index. An index manages searching and tagging and also user accounts and ,NA,NA
"permissions. In fact, the registry delegates authentication to the index. When ",NA,NA
"executing remote commands, such as ",push,NA
 or ,pull,NA
", the index first will look at the ",NA,NA
"name of the image and then check to see if it has a corresponding repository. If so, ",NA,NA
"the index verifies if you are allowed to access or modify the image. If you are, the",NA,NA
operation is approved and the registry takes or sends the image.,NA,NA
Let's summarize what we have learned so far:,NA,NA
The Dockerfile is the recipe to build an image. It's a text file containing ordered ,NA,NA
instructions. Each Dockerfile has a base image you build upon,NA,NA
"An image is a specific state of a filesystem: a read-only, frozen immutable ",NA,NA
snapshot of a live container,NA,NA
An image is composed of layers representing changes in the filesystem at ,NA,NA
various points in time; layers are a bit same as the commit history of a Git ,NA,NA
repository. Docker uses the layers cache,NA,NA
Containers are runtime instances of an image. They can be running or stopped. ,NA,NA
You can have multiple containers of the same image running,NA,NA
You can make changes to the filesystem on a container and commit them to ,NA,NA
make them persisted. Commit always creates a new image,NA,NA
"Only the filesystem changes can be committed, memory changes will be lost",NA,NA
"A registry holds a collection of named repositories, which themselves are a ",NA,NA
collection of images tracked by their IDs. The registry is same as a Git ,NA,NA
repository: you can ,push,NA
 and ,pull,NA
 images,NA,NA
You should now have an understanding of the nature of images with their layers and ,NA,NA
containers. But Docker is not just a Dockerfile processor and the runtime engine. ,NA,NA
Let's look at what else is available.,NA,NA
Additional tools,NA,NA
It's a complete package with a wide selection of tools and APIs that are helpful ,NA,NA
"during the developer's and DevOp's daily work. There's a Kinematic, for example, a ",NA,NA
desktop developer environment for using Docker on Windows and macOS X.,NA,NA
"From a Java developer's perspective, there are tools available, which are especially ",NA,NA
"useful in a programmer's daily job, such as the IntelliJ IDEA Docker integration ",NA,NA
plugin (we will be using this add-on heavily in the coming chapters). Eclipse fans ,NA,NA
"can use the Docker tooling for Eclipse, which is available starting with Eclipse Mars.",NA,NA
NetBeans also supports Docker commands. No matter which development ,NA,NA
"environment you pick, these add-ons let you download and build Docker images, ",NA,NA
"create and start containers, and carry out other related tasks straight from your ",NA,NA
favorite IDE.,NA,NA
"Docker is so popular these days, no wonder hundreds of third-party tools have been ",NA,NA
developed to make Docker even more useful. The most prominent of them is ,NA,NA
"Kubernetes, which we are going to focus on in this book. But apart from Kubernetes, ",NA,NA
"there are many others. They will support you with Docker-related operations, such as ",NA,NA
"continuous integration/continuous delivery, deployment and infrastructure, or ",NA,NA
optimizing images. Tens of hosting services now support running and managing ,NA,NA
Docker containers.,NA,NA
"As Docker captures more attention, more and more Docker-related tools pop-up ",NA,NA
almost every month. You can find a very well-crafted list of Docker-related tools and ,NA,NA
"services on the GitHub awesome Docker list, available at ",NA,NA
https://github.com/veggiemonk/ ,NA,NA
awesome-docker,NA,NA
.,NA,NA
"But there are not only tools available. Additionally, Docker provides a set of APIs ",NA,NA
that can be very handy. One of them is the Remote API for the management of the ,NA,NA
"images and containers. Using this API, you will be able to distribute your images to ",NA,NA
the runtime Docker engine. There's also the Stats API that will expose live resource ,NA,NA
"usage information (such as CPU, memory, network I/O, and block I/O) for your ",NA,NA
containers. This API endpoint can be used create tools that show how your ,NA,NA
"containers behave; for example, on a production system.",NA,NA
"As we now know the idea behind Docker, the differences between virtualization and ",NA,NA
"containerization, and the benefits of using Docker, let's get to the action. We are",NA,NA
going to install Docker first.,NA,NA
Installing Docker,NA,NA
"In this section, we will find out how to install Docker on Windows, macOS, and ",NA,NA
"Linux operating systems. Next, we will run a sample ",hello-world,NA
 image to verify the ,NA,NA
setup and check if everything works fine after the installation process.,NA,NA
"Docker installation is quite straightforward, but there are some things you will need ",NA,NA
to focus on to make it run smoothly. We will point them out to make the installation ,NA,NA
process painless. You should know that Linux is the natural environment for Docker.,NA,NA
"If you run the container, it will run on a Linux kernel. If you run your container on ",NA,NA
"Docker running on Linux, it will use the kernel of your own machine. This is not the ",NA,NA
case in macOS and Windows; that's the reason why the Linux kernel needs to be ,NA,NA
virtualized if you want to run a Docker container on these operating systems. The ,NA,NA
"Docker engine, when running on macOS or MS Windows, will use the lightweight ",NA,NA
"Linux distribution, made specifically to run Docker containers. It runs completely ",NA,NA
"from RAM, using only several megabytes, and boots in a couple of seconds. After ",NA,NA
"the installation of the main Docker package on macOS and Windows, the OS built-in ",NA,NA
"virtualization engine will be used by default. Therefore, there are some special ",NA,NA
"requirements for your machine. For the newest, native Docker setup, which is deeply ",NA,NA
"integrated into native virtualization engines present in your operating system, you ",NA,NA
"will need to have 64-bit Windows 10 professional or enterprise. For macOS, the ",NA,NA
"newest Docker for Mac is a native Mac application developed from scratch, with a ",NA,NA
"native user interface, integrated with OS X native virtualization, hypervisor ",NA,NA
"framework, networking, and filesystem. The mandatory requirement will be ",NA,NA
Yosemite 10.10.3 or newer. Let's begin with installing on macOS.,NA,NA
Installing on macOS,NA,NA
"To get the native Docker version for your Mac, head to the ",NA,NA
http://www.docker.com,NA,NA
 and ,NA,NA
"then  the Get Docker macOS section. Docker for Mac is a standard, native ",dmg,NA
package you can mount. You will find just a single application inside the package:,NA,NA
Now just move the ,Docker.app,NA
 into your ,Applications,NA
" folder, and you are all set. ",NA,NA
"Couldn't be easier. If you run Docker, it will sit as a small whale icon in your macOS ",NA,NA
menu. The icon will animate during the Docker startup process and stabilize after it ,NA,NA
finishes:,NA,NA
"If you now click the icon, it will give you a handy menu with the Docker status ",NA,NA
and some additional options:,NA,NA
"Docker for Mac has an auto-update capability, which is great for keeping your ",NA,NA
installation up to date. The first Preferences... pane gives you the possibility to ,NA,NA
automatically check for updates; it's marked by default:,NA,NA
"If you are a brave soul, you can also switch to the beta channel for getting ",NA,NA
"updates. This way you can always have the latest and greatest Docker features, ",NA,NA
"with the risk of decreased stability, as is always the case with beta software.",NA,NA
Also take note that switching to the beta channel will uninstall your current ,NA,NA
stable version of Docker and destroy all of your settings and containers. Docker ,NA,NA
"will warn you about this, to make sure you really want to do it:",NA,NA
The File Sharing pane of the Preferences... will give you an option to mark,NA,NA
macOS directories on your machine to be bind mounted into Docker containers ,NA,NA
you are going to run later. We will explain mounting directories in detail later ,NA,NA
"on in the book. For the time being, let's just have the default set of selected ",NA,NA
directories:,NA,NA
The Advanced pane has some options to adjust the resources of your computer,NA,NA
"that will be available for Docker, it will be the number of processors and ",NA,NA
memory amount. The default settings are usually a good start if you begin with ,NA,NA
Docker on macOS:,NA,NA
"The Proxies pane gives you the possibility to setup a proxy, if you need it on ",NA,NA
"your machine. You can opt for using system or manual settings, as you can see",NA,NA
in the following screenshot:,NA,NA
"On the next page, you can edit some Docker daemon settings. This will include",NA,NA
adding registries and registry mirrors. Docker will use them when pulling the ,NA,NA
"image. The Advanced tab contains a text field, in which you can enter the JSON ",NA,NA
text containing the daemon config:,NA,NA
"In the Daemon pane, you can also turn off Docker Experimental features. For ",NA,NA
"some time now, Experimental features have been enabled by default. From time ",NA,NA
"to time, a new version of Docker comes with new Experimental features. At the ",NA,NA
"time of writing this book, they will include, for example, Checkpoint & Restore ",NA,NA
"(a feature that allows you to freeze a running container by checkpointing it), ",NA,NA
Docker graph driver plugins (to use an external/out-of-process graph driver for ,NA,NA
use with the Docker engine as an alternative to using the built-in storage ,NA,NA
"drivers), and some others. It's always interesting to see what new features are ",NA,NA
included in the new version of Docker. Clicking the link in the Daemon page ,NA,NA
will take you to the GitHub page which lists and explains all the new ,NA,NA
experimental features.,NA,NA
The last Preferences... pane is the Reset. If you find that your Docker won't start ,NA,NA
"or behaves badly, you can try to reset the Docker installation to the factory ",NA,NA
defaults:,NA,NA
"You should be warned though, that resetting Docker to the factory state will also ",NA,NA
remove all downloaded images and containers you may have on your machine. If ,NA,NA
"you have images that have not been pushed anywhere yet, having a backup first is ",NA,NA
always a good idea.,NA,NA
The Open Kitematic in the Docker menu is a handy shortcut to open the Kitematic ,NA,NA
application we have mentioned earlier. It's a desktop utility for using Docker on ,NA,NA
"Windows and Mac OS X. If you do not have Kitematic installed already, Docker will ",NA,NA
give you a link with the installation package:,NA,NA
"If you run Kitematic, it will present you the Docker Hub login screen first. You ",NA,NA
can now Sign up to the Docker Hub and then log in providing your username ,NA,NA
and password:,NA,NA
Clicking on Skip For Now will take you to the images list without logging into the ,NA,NA
Docker Hub. Let's test our installation by pulling and running an image. Let's search ,NA,NA
for ,hello-java-world,NA
", as seen on the following screenshot:",NA,NA
"After pulling the image from the registry, start it. Kitematic will present the running ",NA,NA
"Container logs, which will be the famous ",hello world,NA
" message, coming from a ",NA,NA
containerized Java application:,NA,NA
That's it for running the container in Kitematic. Let's try to do the same from the ,NA,NA
shell. Execute the following in the terminal: ,$ docker run milkyway/java-hello-world,NA
"As a result, you will see the same greeting, coming from a containerized Java ",NA,NA
"application, this time in the macOS terminal:",NA,NA
"That's it, we have a native Docker up and running on our macOS. Let's install it on ",NA,NA
"Linux, as well.",NA,NA
Installing on Linux,NA,NA
There are a lot of various Linux distributions out there and the installation process ,NA,NA
can be a little bit different for each Linux distribution. I'm going to install Docker on the ,NA,NA
"latest, 16.04 Ubuntu desktop: ",NA,NA
"1. First, we need to allow the ",apt,NA
 package manager to use a repository over the ,NA,NA
HTTPS protocol. Execute from the shell: ,$ sudo apt-get install -y --no-install-recommends apt-transport-https ca-certifica,NA
2. ,NA,NA
The next thing we are going to do is add Docker's ,apt,NA
 repository ,gpg,NA
 key to our ,apt,NA
 sources list: ,$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add –,NA
3. A ,NA,NA
simple ,OK,NA
 will be the response if succeeded. Use the following command to ,NA,NA
set up the stable repository: ,"$ sudo add-apt-repository ""deb [arch=amd64] https://download.docker.com/linux/ubun",NA
4. ,NA,NA
"Next, we need to update the ",apt,NA
 packages index: ,$ sudo apt-get update,NA
5. Now we need to make sure the ,apt,NA
 installer will use the official Docker ,NA,NA
repository instead of the default Ubuntu repository (which may contain the ,NA,NA
older version of Docker): ,$ apt-cache policy docker-ce,NA
6. Use this command to install the latest version of Docker: ,$ sudo apt-get install -y docker-ce,NA
7. The ,apt,NA
 package manager will download a lot of packages; those will be the ,NA,NA
needed dependencies and the ,docker-engine,NA
 itself:,NA,NA
"8. That's it, you should be all set. Let's verify if Docker works on our Linux box: ",$sudo docker run milkyway/java-hello-world,NA
"9. As you can see, the Docker engine will pull the ",milkyway/java-hello-world,NA
 image ,NA,NA
with all its layers from the Docker Hub and respond with a greeting:,NA,NA
But do we need to run Docker commands with ,sudo?,NA
 The reason for that is the ,NA,NA
Docker daemon always runs as the ,root,NA
" user, and since Docker version 0.5.2, the ",NA,NA
"Docker daemon binds to a Unix socket instead of a TCP port. By default, that Unix ",NA,NA
socket is owned by the user ,root,NA
", and so, by default, you can access it with sudo.",NA,NA
Let's fix it to be able to run the ,Docker,NA
 command as a normal user:,NA,NA
"1. First, add the ",Docker,NA
 group if it doesn't already exist:,$ sudo groupadd docker,NA
"2. Then, add your own user to the Docker group. Change the username to match ",NA,NA
your preferred user:,$ sudo gpasswd -a jarek docker,NA
3. Restart the Docker daemon:,$ sudo service docker restart,NA
"4. Now let's log out and log in again, and execute the ",docker run,NA
 command one ,NA,NA
"more time, without ",sudo,NA
" this time. As you can see, you are now able to work ",NA,NA
"with Docker as a normal, non-",root,NA
 user:,NA,NA
5. That's it. Our Linux Docker installation is ready to play with. Let's do an ,NA,NA
installation on the Windows box now.,NA,NA
Installing on Windows,NA,NA
The native Docker package can be run on 64-bit Windows 10 Professional or ,NA,NA
Enterprise. It uses the Windows 10 virtualization engine to virtualize the Linux ,NA,NA
kernel. This is the reason that the installation package does no longer contain the ,NA,NA
"VirtualBox setup, as with the previous versions of Docker for Windows. The native ",NA,NA
application comes in a typical ,.msi,NA
" installation package. If you run it, it will greet you ",NA,NA
"with a friendly message, saying that it is going to live in your task bar tray, under the ",NA,NA
"small whale icon, from now on:",NA,NA
The Docker's icon in the tray informs you about the Docker engine state. It also ,NA,NA
contains a small but useful context menu:,NA,NA
"Let's explore the preferences settings and see what's available. The first tab, General, ",NA,NA
allows you to set Docker to run automatically when you log in. If you use Docker ,NA,NA
daily that may be the recommended setting. You can also mark to check for updates ,NA,NA
automatically and send usage statistics. Sending usage statistics will help the Docker ,NA,NA
"team improve the tool in future versions; unless you have some mission critical, ",NA,NA
"secure work to be done, I recommend turning this option on. This is a great way to ",NA,NA
contribute to future versions of this magnificent tool:,NA,NA
"The second tab, Shared Drives, allows you to select the local Windows drives which ",NA,NA
will be available to the Docker containers you will be running:,NA,NA
We are going to cover Docker volumes in ,NA,NA
Chapter 2,NA,NA
", ",NA,NA
Networking and Persistent ,NA,NA
Storage,NA,NA
. Selecting a drive here means that you can map a directory from your local ,NA,NA
system and read that as a Windows host machine to your Docker container. The next ,NA,NA
"preferences page, Advanced, allows us to make some restrictions on the Docker ",NA,NA
engine running on our Windows PC and also select the location of the virtual ,NA,NA
machine image with the Linux kernel:,NA,NA
The default values are usually good out of the box and unless you experience ,NA,NA
"problems during the development process, I would recommend leaving them as they ",NA,NA
"are. The Network lets you configure the way Docker works with the network, the ",NA,NA
same as subnet address and mask or DNS server. We are going to cover Docker ,NA,NA
networking in ,NA,NA
Chapter 2,NA,NA
", ",NA,NA
Networking and Persistent Storage,NA,NA
:,NA,NA
If you're behind a proxy in your network and would like Docker to access the ,NA,NA
"Internet, you can set up the proxy settings in the Proxies tab:",NA,NA
The dialog is similar to what you find in other applications where you can define ,NA,NA
"proxy settings. It can accept no proxy, system proxy settings, or manual settings",NA,NA
(with a different proxy for HTPP and HTTPS communication). The next pane can be ,NA,NA
useful to configure the Docker daemon:,NA,NA
The Basic switch means that Docker uses the basic configuration. You can switch it ,NA,NA
to Advanced and provide a customized setting in a form of JSON structure. The ,NA,NA
Experimental features are the same as we have already mentioned during the Docker ,NA,NA
"setup on macOS, this will be Checkpoint & Restore or enabling Docker graph driver ",NA,NA
"plugins, for example. You can also specify a list of remote registries. Docker will be ",NA,NA
pulling images from insecure registries using just plain HTTP instead of HTTPS.,NA,NA
Using the Reset options on the last pane lets you restart or reset Docker to its factory ,NA,NA
settings:,NA,NA
"Be aware though, that resetting Docker to its initial settings will also remove ",NA,NA
all images and containers currently present on your machine.,NA,NA
"The Open Kitematic... option, which is also present in the Docker tray icon context ",NA,NA
"menu, is a quick shortcut to launch Kitematic. If you do it for the first time and don't ",NA,NA
"have Kitematic installed, Docker will ask if you would like to download it first:",NA,NA
That's it for installing Docker for Windows. It's a pretty painless process. As a last ,NA,NA
"step of the installation process, let's check if Docker can be run from the command ",NA,NA
"prompt, because it's probably the way you will be launching it in the future. Execute ",NA,NA
the following command in the command prompt or in the PowerShell:,NA,NA
"As you can see on the previous screenshot, we have a Hello World message coming ",NA,NA
from the Java application started as a Docker container.,NA,NA
Summary,NA,NA
"That's it. Our Docker for Windows installation is fully functional. In this chapter, we ",NA,NA
have learned about the idea behind Docker and the main differences between ,NA,NA
traditional virtualization and containerization. We know a lot about Docker core ,NA,NA
"concepts such as images, layers, containers, and registries. We should have Docker ",NA,NA
installed already on our local machine; it's now time to move on and learn about ,NA,NA
"more advanced Docker features, such as networking and persistent storage.",NA,NA
Networking and Persistent Storage,NA,NA
We learned a lot about Docker concepts in the previous chapter. We know that the ,NA,NA
container is a runtime of an image. It will contain your Java application altogether ,NA,NA
"with all needed dependencies, such as JRE or an application server. But, there are ",NA,NA
rare cases when the Java application is self-sufficient. It always needs to ,NA,NA
"communicate with other servers (as a database), or expose itself to others (as a web ",NA,NA
application running on the application server which needs to accept requests coming ,NA,NA
from the user or from the other applications). It's time to describe ways to open the ,NA,NA
"Docker container to the outside world, networking, and persistent storage. In this ",NA,NA
"chapter, you are going to learn how to configure networking, and expose and map ",NA,NA
"network ports. By doing that, you will enable your Java application to communicate ",NA,NA
with other containers. Imagine the following scenario: you can have one container ,NA,NA
"running a Tomcat application server with your Java application, communicating with ",NA,NA
"another container running a database, ",PostgreSQL,NA
 for example. While the Kubernetes ,NA,NA
approach to networking is somewhat different in comparison to what Docker ,NA,NA
"provides by default, let's focus on Docker itself briefly now. We are going to cover ",NA,NA
Kubernetes' specific networking later on. The container communication with the ,NA,NA
"outside world is not only about networking; in this chapter, we will also focus on ",NA,NA
data volumes as a way to persist the data between container run and stop cycles.,NA,NA
This chapter covers the following topics:,NA,NA
Docker network types,NA,NA
Networking commands,NA,NA
Creating a network,NA,NA
Mapping and exposing ports,NA,NA
Volume-related commands,NA,NA
Creating and removing volumes,NA,NA
Let's begin with Docker networking.,NA,NA
Networking,NA,NA
"To make your container able to communicate with the outside world, whether ",NA,NA
"another server or another Docker container, Docker provides different ways of ",NA,NA
configuring networking. Let's begin with the network types which are available for ,NA,NA
our containers.,NA,NA
Docker network types,NA,NA
"There are three different network types Docker delivers out of the box. To list them, ",NA,NA
execute the ,docker network ls,NA
 command:,$ docker network ls,NA
Docker will output the list of available networks containing the unique network ,NA,NA
"identifier, its name, and a driver which powers it behind the scenes:",NA,NA
"To have an overview of the differences between various network types, let's describe ",NA,NA
them now one by one.,NA,NA
Bridge,NA,NA
"This is the default network type in Docker. When the Docker service daemon starts, ",NA,NA
"it configures a virtual bridge, named ",docker0,NA
. If you do not specify a network with the ,docker run -net=<NETWORK>,NA
" option, the Docker daemon will connect the container to the ",NA,NA
"bridge network by default. Also, if you create a new container, it will be connected ",NA,NA
"to the bridge network. For each container that Docker creates, it allocates a virtual ",NA,NA
Ethernet device which will be attached to the bridge. The virtual Ethernet device is ,NA,NA
mapped to appear as ,eth0,NA
" in the container, using Linux namespaces, as you can see in ",NA,NA
the following diagram:,NA,NA
The ,in-container eth0,NA
 interface is given an IP address from the bridge's address range. ,NA,NA
"In other words, Docker will find a free IP address from the range available on the ",NA,NA
bridge and will configure the container's ,eth0,NA
 interface with that IP address. From ,NA,NA
"now on, if the new container wants to, for example, connect to the Internet, it will ",NA,NA
use the bridge; the host's own IP address. The bridge will automatically forward ,NA,NA
packets between any other network interfaces that are attached to it and also allow ,NA,NA
"containers to communicate with the host machine, as well as with the containers on ",NA,NA
the same host. The bridge network will probably be the most frequently used one.,NA,NA
Host,NA,NA
"This type of network just puts the container in the host's network stack. That is, all of ",NA,NA
"the network interfaces defined on the host will be accessible to the container, as you ",NA,NA
can see in the following diagram:,NA,NA
If you start your container using the ,-net=host,NA
" option, then the container will use the ",NA,NA
"host network. It will be as fast as normal networking: there is no bridge, no ",NA,NA
"translation, nothing. That's why it can be useful when you need to get the best ",NA,NA
network performance. Containers running in the host's network stack will achieve ,NA,NA
"faster network performance compared to those running on bridge networking, there ",NA,NA
is no need to traverse the ,docker0bridge,NA
 and ,iptables,NA
" port mappings. In host mode, the ",NA,NA
"container shares the networking namespace of the host (your local machine, for ",NA,NA
"example), directly exposing it to the outside world. By using the ",-net=host,NA
 command ,NA,NA
"switch, your container will be accessible through the host's IP address. However, you ",NA,NA
need to be aware that this can be dangerous. If you have an application running as ,NA,NA
"root and it has some vulnerabilities, there will be a risk of a security breach, as ",NA,NA
someone can get remote control of the host network via the Docker container. Using ,NA,NA
the host network type also means that you will need to use port mapping to reach ,NA,NA
"services inside the container. We are going to cover port mapping later, in this ",NA,NA
chapter.,NA,NA
None,NA,NA
"To cut a long story short, the none network does not configure networking at all. ",NA,NA
There is no driver being used by this network type. It's useful when you don't need ,NA,NA
your container to have network access; the ,-net=none,NA
 switch to ,docker run,NA
 command ,NA,NA
completely disables networking.,NA,NA
Docker provides a short list of commands to deal with networking. You can run ,NA,NA
them from the shell (Linux or macOS) or the command prompt and PowerShell in ,NA,NA
Windows. Let's get to know them now.,NA,NA
Networking commands,NA,NA
The parent command for managing networks in Docker is ,docker network,NA
. You can list ,NA,NA
the whole command set using the ,docker network help,NA
" command, as you can see in the ",NA,NA
following screenshot:,NA,NA
To have a detailed syntax and description of each option available for a specific ,NA,NA
"command, use the ",-help,NA
" switch for each of the commands. For example, to get the ",NA,NA
description of parameters available for ,docker network create,NA
", execute the ","docker 
 network create -help",NA
.,NA,NA
Let's briefly describe each command available:,$ docker network ls,NA
": This is the command we have been using previously, it ",NA,NA
simply lists networks available for your containers. It will output the network ,NA,NA
"identifier, its name, the driver being used, and a scope of the network",$ docker network create,NA
: Creates new network. The full syntax of the command ,NA,NA
"is, ",docker network create [OPTIONS] NETWORK,NA
. We will use the command in a short ,NA,NA
while,$ docker network rm,NA
: The ,dockercnetworkcrm,NA
  command simply removes the ,NA,NA
network,$ docker network connect,NA
: Connects the container to the specific network,$ docker network disconnect,NA
": As the name suggests, it will disconnect the ",NA,NA
container from the network,$ docker network inspect,NA
: The docker network inspect command displays detailed ,NA,NA
"information about the network. It's very useful, if you have network issues. We ",NA,NA
are going to create and inspect our network now,NA,NA
The ,docker network,NA
 inspect command displays detailed information about the ,NA,NA
network. It's very useful if you have network issues. We are going to create and ,NA,NA
inspect our network now.,NA,NA
Creating and inspecting a network,NA,NA
Let's create a network. We are going to call our network ,myNetwork,NA
. Execute the ,NA,NA
following command from the shell or command line:,$ docker network create myNetwork,NA
"This is the simplest form of the command, and yet it will probably be used the most ",NA,NA
"often. It takes a default driver (we haven't used any option to specify a driver, we ",NA,NA
"will just use the default one, which is bridge). As the output, Docker will print out ",NA,NA
the identifier of the newly created network:,NA,NA
You will later use this identifier to refer to this network when connecting containers ,NA,NA
to it or inspecting the network's properties. The last parameter of the command is the ,NA,NA
"network's name, which is a lot more convenient and easier to remember than the ID. ",NA,NA
The network name in our case is ,myNetwork,NA
. The ,docker network,NA
 create command takes ,NA,NA
"more parameters, as shown in the following table:",NA,NA
Option,NA,NA
Description,"-d, -driver=""bridge""",NA
Driver to manage the network,-aux-address=map[],NA
Auxiliary IPv4 or IPv6 addresses used by network driver,-gateway=[],NA
IPv4 or IPv6 gateway for the master subnet,-ip-range=[],NA
Allocate container IP from a sub-range,-ipam-driver=default,NA
IP address management driver,-o,NA
", ",-opt=map[],NA
Set driver's specific options,-subnet=[],NA
Subnet in CIDR format that represents a network segment,NA,NA
One of the most important parameters is the ,-d,NA
 (,--driver,NA
") option, with the default ",NA,NA
"value bridge. Drivers let you specify the network type. As you remember, Docker ",NA,NA
has a couple of drivers available by default: ,host,NA
", ",bridge,NA
", and ",none,NA
.,NA,NA
"After creating a network, we can inspect its properties using the ","docker network 
 inspect",NA
 command. Execute the following from the shell or command line:,$ docker network inspect myNetwork,NA
"In response, you will get a lot of detailed information about your network. As you ",NA,NA
"can see in the screenshot, our newly created network uses the bridge driver, even if ",NA,NA
we haven't explicitly asked for it:,NA,NA
"As you can see, the container list is empty, and the reason why is that we haven't ",NA,NA
connected any container to this network yet. Let's do it now.,NA,NA
Connecting a container to the network,NA,NA
Now we have our ,myNetwork,NA
" ready, we can run the Docker container and attach it to ",NA,NA
"the network. To launch containers, we are going to user the ",docker run --net=<NETWORK>,NA
"option, where the ",<NETWORK>,NA
 is the name of one of the default networks or the one you ,NA,NA
"have created yourself. Let's run Apache Tomcat for example, which is an open ",NA,NA
source implementation of the Java Servlet and JavaServer pages technologies:,docker run -it --net=myNetwork tomcat,NA
It will take a while. The Docker engine will pull all of the Tomcat's image layers ,NA,NA
from the Docker Hub and then run the Tomcat container. There's another option to ,NA,NA
"attach the network to the container, you can inform Docker that you would like the ",NA,NA
"container to connect to the same network as other containers use. This way, instead ",NA,NA
"of specifying a network explicitly, you just instruct Docker that you want two ",NA,NA
"containers run on the same network. To do this, use the ",container:,NA
" prefix, as in the ",NA,NA
following example:,"docker run -it --net=bridge myTomcat 
  
 docker run -it --net=container:myTomcat myPostgreSQL",NA
"In the previous example, we run the ",myTomcat,NA
 image using the bridge network. The ,NA,NA
next command will run the ,myPostgreSQL,NA
" image, using the same network as ",myTomcat,NA
uses. This is a very common scenario; your application will run on the same network ,NA,NA
"as the database and this will allow them to communicate. Of course, the containers ",NA,NA
you launch into the same network must be run on the same Docker host. Each ,NA,NA
container in the network can directly communicate with other containers in the ,NA,NA
"network. Though, the network itself isolates the containers from external networks, ",NA,NA
as seen in the following diagram:,NA,NA
"If you run your containers in a bridge, isolated network, we need to instruct Docker ",NA,NA
on how to map the ports of our containers to the host's ports. We are going to do this ,NA,NA
now.,NA,NA
Exposing ports and mapping ports,NA,NA
A common scenario is usually when you want your containerized application to ,NA,NA
"accept incoming connections, either from other containers or from outside of ",NA,NA
Docker. It can be an application server listening on port 80 or a database accepting ,NA,NA
incoming requests.,NA,NA
An image can expose ports. Exposing ports means that your containerized ,NA,NA
"application will listen on an exposed port. As an example, the Tomcat application ",NA,NA
server will listen on the port ,8080,NA
 by default. All containers running on the same host ,NA,NA
and on the same network can communicate with Tomcat on this port. Exposing a ,NA,NA
port can be done in two ways. It can be either in the Dockerfile with the ,EXPOSE,NA
instruction (we will do this in the chapter about creating images later) or in the ,"docker 
 run",NA
 command using the ,--expose,NA
 option. Take this official Tomcat image Dockerfile ,NA,NA
fragment (note that it has been shortened for clarity of the example):,"FROM openjdk:8-jre-alpine
  
 ENV CATALINA_HOME /usr/local/tomcat
  
 ENV PATH $CATALINA_HOME/bin:$PATH
  
 RUN mkdir -p ""$CATALINA_HOME""
  
 WORKDIR $CATALINA_HOME
  
 EXPOSE 8080
  
 CMD [""catalina.sh"", ""run""]",NA
"As you can see, there's an ",EXPOSE 8080,NA
 instruction near the end of the Dockerfile. It ,NA,NA
"means that we could expect that the container, when run, will listen on port number ",8080,NA
". Let's run the latest Tomcat image again. This time, we will also give our ",NA,NA
"container a name, ",myTomcat,NA
. Start the application server using the following ,NA,NA
command:,docker run -it --name myTomcat --net=myNetwork tomcat,NA
"For the purpose of checking if containers on the same network can communicate, we ",NA,NA
"will use another image, ",busybox,NA
. BusyBox is software that provides several stripped-,NA,NA
down Unix tools in a single executable file. Let's run the following command in the ,NA,NA
separate shell or command prompt window:,NA,NA
"As you can see, we have instructed Docker that we want our ",busybox,NA
 container to use ,NA,NA
"the same network as Tomcat uses. As an alternative, we could of course go with ",NA,NA
"specifying a network name explicitly, using the ",--net myNetwork,NA
 option.,NA,NA
Let's check if they indeed can communicate. Execute the following in the shell ,NA,NA
window with ,busybox,NA
 running:,$ wget localhost:8080,NA
The previous instruction will execute the ,HTTP GET,NA
 request on port ,8080,NA
", on which ",NA,NA
Tomcat is listening in another container. After the successful download of ,NA,NA
Tomcat's ,index.html,NA
", we have proof that both containers can communicate:",NA,NA
"So far so good, containers running on the same host and the same network can ",NA,NA
communicate with each other. But what about communicating with our container ,NA,NA
"from the outside? Mapping ports comes in handy. We can map a port, exposed by ",NA,NA
"the Docker container, into the port of the host machine, which will be a localhost in ",NA,NA
our case. The general idea is that we want the port on the host to be mapped to a ,NA,NA
"specific port in the running container, the same as port number ",8080,NA
 of the Tomcat ,NA,NA
container.,NA,NA
"To bind a port (or group of ports) from a host to the container, we use the ",-p,NA
 flag of ,NA,NA
the ,docker run,NA
" command, as in the following example:",$ docker run -it --name myTomcat2 --net=myNetwork -p 8080:8080 tomcat,NA
"The previous command runs another Tomcat instance, also connected to ",NA,NA
the ,myNetwork,NA
" network. This time, however, we map the container's port ",8080,NA
 to the ,NA,NA
host's port of the same number. The syntax of the ,-p,NA
 switch is quite straightforward: ,NA,NA
"you just enter the host port number, a colon, and then a port number in the container ",NA,NA
you would like to be mapped:,$ docker run -p <hostPort>:<containerPort> <image ID or name>,NA
The Docker image can expose a whole range of ports to other containers using either,NA,NA
the ,EXPOSE,NA
 instruction in a Dockerfile (the same as ,EXPOSE 7000-8000,NA
", for example) or ",NA,NA
the ,docker run,NA
" command, for example: ",$ docker run --expose=7000-8000 <container ID or name>,NA
You can then map a whole range of ports from the host to the container by using the ,docker run,NA
 command: ,$ docker run -p 7000-8000:7000-8000 <container ID or name>,NA
Let's verify if we can access the Tomcat container from outside of Docker. To do ,NA,NA
"this, let's run Tomcat with mapped ports: ",$ docker run -it --name myTomcat2 --net=myNetwork -p 8080:8080 tomcat,NA
"Then, we can simply enter the following address in our favorite web browser: ",http://localhost:8080,NA
.,NA,NA
"As a result, we can see Tomcat's default welcome page, served straight from the ",NA,NA
"Docker container running, as you can see in the following screenshot:",NA,NA
"Good, we can communicate with our container from the outside of Docker. By the ",NA,NA
"way, we now have two isolated Tomcats running on the host, without any port ",NA,NA
"conflicts, resource conflicts, and so on. This is the power of containerization.",NA,NA
"You may ask, what is the difference between exposing and mapping ports, that is, ",NA,NA
between ,--expose,NA
 switch and ,-p,NA
" switches? Well, the ",--expose,NA
 will expose a port at ,NA,NA
runtime but will not create any mapping to the host. Exposed ports will be available ,NA,NA
"only to another container running on the same network, on the same Docker host. ",NA,NA
The ,-p,NA
" option, on the other hand, is the same as ",publish,NA
: it will create a port mapping ,NA,NA
"rule, mapping a port on the container with the port on the host system. The mapped ",NA,NA
port will be available from outside Docker. Note that if you do ,-p,NA
", but there is no ",EXPOSE,NA
" in the Dockerfile, Docker will do an implicit ",EXPOSE,NA
". This is because, if a port ",NA,NA
"is open to the public, it is automatically also open to other Docker containers.",NA,NA
There is no way to create a port mapping in the Dockerfile. Mapping a port or ports ,NA,NA
"is, just a runtime option. The reason for that is because port mapping configuration ",NA,NA
depends on the host. The Dockerfile needs to be host-independent and portable.,NA,NA
You can bind a port using ,-p,NA
 in the runtime only.,NA,NA
"There is yet one more option, which allows you to map all ports exposed in an image ",NA,NA
"(that is; in the Dockerfile) at once, automatically during the container startup. The ",-P,NA
switch (capital ,P,NA
 this time) will map a dynamically allocated random host port to all ,NA,NA
container ports that have been exposed in the Dockerfile by the ,EXPOSE,NA
 instruction.,NA,NA
The ,-p,NA
 option gives you more control than ,-P,NA
 when mapping ports. ,NA,NA
Docker will not automatically pick any random port; it's up to you what ,NA,NA
ports on the host should be mapped to the container ports.,NA,NA
"If you run the following command, Docker will map a random port on the host to ",NA,NA
Tomcat's exposed port number ,8080,NA
:,$ docker run -it --name myTomcat3 --net=myNetwork -P tomcat,NA
"To check exactly which host port has been mapped, you can use the ",docker ps,NA
command. This is probably the quickest way of determining the current port ,NA,NA
mapping. The ,docker ps,NA
 command is used to see the list of running containers.,NA,NA
Execute the following from a separate shell console:,NA,NA
"In the output, Docker will list all running containers, showing which ports have been ",NA,NA
mapped in the ,PORTS,NA
 column:,NA,NA
"As you can see in the previous screenshot, our ",myTomcat3,NA
 container will have the ,8080,NA
port mapped to port number ,32772,NA
" on the host. Again, executing the ",HTTP GET,NA
 method ,NA,NA
on the ,http://localhost:32772,NA
 address will give us ,myTomcat3,NA
's welcome page. An ,NA,NA
alternative to the ,docker ps,NA
" command is the docker port command, used with the ",NA,NA
container ,ID,NA
 or with a ,name,NA
 as a parameter (this will give you information about what ,NA,NA
"ports have been mapped). In our case, this will be:",$ docker port myTomcat3,NA
"As a result, Docker will output the mapping, saying that port number 80 from the ",NA,NA
container has been mapped to port number ,8080,NA
 on the host machine:,NA,NA
Information about all the port mappings is also available in the result of the docker ,NA,NA
"inspect command. Execute the following command, for example:",$ docker inspect myTomcat2,NA
In the output of the ,docker inspect,NA
" command, you will find the ",Ports,NA
 section ,NA,NA
containing the information about mappings:,NA,NA
Let's briefly summarize the options related to exposing and mapping ports in a table:,NA,NA
Instruction,NA,NA
Meaning,EXPOSE,NA
Signals that there is service available on the specified ,NA,NA
port. Used in the Dockerfile and makes exposed ports ,NA,NA
open for other containers.,--expose,NA
The same as ,EXPOSE,NA
" but used in the runtime, during the ",NA,NA
container startup.,"-p 
  
 hostPort:containerPort",NA
"Specify a port mapping rule, mapping the port on the ",NA,NA
container with the port on the host machine. Makes a port ,NA,NA
open from the outside of Docker.,-P,NA
Map dynamically allocated random port (or ports) of the ,NA,NA
host to all ports exposed using ,EXPOSE,NA
 or ,--expose,NA
.,NA,NA
Mapping ports is a wonderful feature. It gives you flexible configuration possibilities ,NA,NA
"to open your containers to the external world. In fact, it's indispensable if you want ",NA,NA
"your containerized web server, database, or messaging server to be able to talk to ",NA,NA
"others. If a default set of network drivers is not enough, you can always try to find a ",NA,NA
specific driver on the Internet or develop one yourself. Docker Engine network ,NA,NA
"plugins extend Docker to support a wide range of networking technologies, such as ",NA,NA
"IPVLAN, MACVLAN, or something completely different and exotic. Networking ",NA,NA
possibilities are almost endless in Docker. Let's focus now on another very important ,NA,NA
aspect of Docker container extensibility volumes.,NA,NA
Persistent storage,NA,NA
As you remember from ,NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", the Docker container ",NA,NA
"filesystem is kind of temporary by default. If you start up a Docker image (that is, ",NA,NA
"run the container), you'll end up with a read-write layer on top of the layers stack.",NA,NA
"You can create, modify, and delete files as you wish; if you commit the changes ",NA,NA
"back into the image, they will become persisted. This is a great feature if you want to ",NA,NA
"create a complete setup of your application in the image, altogether with all its ",NA,NA
"environment. But, this is not very convenient when it comes to storing and retrieving ",NA,NA
data. The best option would be to separate the container life cycle and your ,NA,NA
"application from the data. Ideally, you would probably want to keep these separate, ",NA,NA
so that the data generated (or being used) by your application is not destroyed or tied ,NA,NA
to the container life cycle and can thus be reused.,NA,NA
The perfect example would be a web application server: the Docker image contains ,NA,NA
"web server software, the same as Tomcat for example, with your Java application ",NA,NA
"deployed, configured, and ready to use. But, the data the server will be using ",NA,NA
"should be separated from the image. This is done via volumes, which we will focus ",NA,NA
"on in this part of the chapter. Volumes are not part of the union filesystem, and so ",NA,NA
"the write operations are instant and as fast as possible, there is no need to commit ",NA,NA
any changes.,NA,NA
Volumes live outside of the union filesystem and exist as normal ,NA,NA
directories and files on the host filesystem.,NA,NA
There are three main use cases for Docker data volumes:,NA,NA
To share data between the host filesystem and the Docker container,NA,NA
To keep data when a container is removed,NA,NA
To share data with other Docker containers,NA,NA
Let's begin with a list of volume-related commands at our disposal.,NA,NA
Volume-related commands,NA,NA
The basis of volume-related commands is docker volume. The commands are as ,NA,NA
follows:,$docker volume create,NA
: Creates a volume,$ docker volume inspect,NA
: Displays detailed information on one or more volumes,$docker volume ls,NA
: Lists volumes,$ docker volume rm,NA
: removes one or more volumes,$ docker volume prune,NA
": removes all unused volumes, which is all volumes that are ",NA,NA
no longer mapped into any container,NA,NA
"Similar to network-related commands, you can get the detailed description and all ",NA,NA
the possible options for each command if you execute it with the ,-help,NA
" switch, for ",NA,NA
example: docker volume create ,-help,NA
. Let's begin with creating a volume.,NA,NA
Creating a volume,NA,NA
As you remember from ,NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", there's a settings screen in ",NA,NA
"Docker for Windows or Docker for Mac, that allows us to specify which drives ",NA,NA
"Docker can have access to. For a start, let's mark drive D in our Docker for Windows ",NA,NA
to make it available for Docker containers:,NA,NA
"For the purpose of our volume examples, I've created a ",docker_volumes/volume1,NA
directory on my ,D,NA
 drive and created an empty ,data.txt,NA
 file inside:,NA,NA
There are two ways to create volumes. The first one is to specify the ,-v,NA
 option when ,NA,NA
running an image. Let's run the ,busybox,NA
" image we already know and, at the same ",NA,NA
"time, create a volume for our data:",NA,NA
"In the previous command, we have created a volume using the ",-v,NA
 switch and ,NA,NA
instructed Docker that the ,host,NA
 directory ,d:/docker_volumes/volume1,NA
 should be mapped ,NA,NA
into the ,/volume,NA
 directory in the running container. If we now list the contents of the ,/volume,NA
 directory in the running ,busybox,NA
" container, we can see our empty ",data1.txt,NA
" file, ",NA,NA
as you can see in the following screenshot:,NA,NA
The parameters in the ,-v,NA
 options are the directory on the host (your own operating ,NA,NA
"system in this case, it is ",d:/docker_volumes/volume1,NA
" in our example), a colon, and a path ",NA,NA
"at which it will be available for the container, ",/volume1,NA
 in our example. The volume ,NA,NA
created is a kind of mapped directory. It will be available for the container and also ,NA,NA
available from the host operating system. Any files already existing in the mapped ,NA,NA
directory (host's ,d:/docker_volumes/volume1,NA
) will be available inside the container; they ,NA,NA
will not be deleted during the mapping.,NA,NA
The ,-v,NA
 option can be used not only for directories but for a single file as well. This ,NA,NA
can be very useful if you want to have configuration files available in your container.,NA,NA
The best example for this is the example from the official Docker documentation:,$ docker run -it -v ~/.bash_history:/root/.bash_history ubuntu,NA
Executing the previous command will give you the same bash history between your ,NA,NA
"local machine and a running Ubuntu container. And best of all, if you exit the ",NA,NA
"container, the bash history on your own local machine will contain the bash ",NA,NA
commands you have been executing inside the container. Mapping files can be ,NA,NA
"useful also for you, as a developer, when debugging or trying out your application ",NA,NA
"configuration, for example.",NA,NA
Mapping a single file from a host allows exposing a configuration of ,NA,NA
your application.,NA,NA
"Apart from creating a volume when starting a container, there is a command to ",NA,NA
create a volume prior to starting a container. We will use it now.,NA,NA
The simplest form of creating a nameless volume will be just:,$ docker volume create,NA
"As the output, Docker will give you the volume identifier, which you can later use to ",NA,NA
refer to this volume. It's better to give a volume a meaningful name. To create a ,NA,NA
"standalone, named volume, execute the following command:",$ docker volume create --name myVolume,NA
"To list the volumes we now have available, execute the ",docker volume ls,NA
 command:,$ docker volume ls,NA
The output will be simply the list of volumes we have created so far:,NA,NA
Volumes created this way will not be mapped explicitly with a path on the host. If the ,NA,NA
container's base image contains data at the specified mount point (as a result of ,NA,NA
"Dockerfile processing), this data will be copied into the new volume upon volume ",NA,NA
initialization. This is different in comparison to specifying a ,host,NA
 directory explicitly.,NA,NA
"The idea behind it is that when creating your image, you should not care about ",NA,NA
"the location of the volume on the host system, making the image portable ",NA,NA
between different hosts. Let's run another container and map the named volume ,NA,NA
into it:,$ docker run -it -v myVolume:/volume --name myBusybox3 busybox,NA
"Note that this time, we do not specify a path on the host. Instead, we instruct ",NA,NA
Docker to use the named volume we created in the previous step. The named ,NA,NA
volume will be available at the ,/volume,NA
 path in the container. Let's create a text file ,NA,NA
on the volume:,NA,NA
"If we run another container now, specifying the same named volume, we will be able ",NA,NA
to access the same data we have available in our ,myBusybox3,NA
 container which was,NA,NA
created previously:,$ docker run -it -v myVolume:/volume --name myBusybox4 busybox,NA
"Our two containers share the single volume now, as you can see in the following ",NA,NA
screenshot:,NA,NA
Docker named volumes are an easy way of sharing volumes between containers. ,NA,NA
They are also a great alternative to data-only containers that used to be a common ,NA,NA
practice in the old days of Docker. This is no longer the case—named volumes are ,NA,NA
way better. It's worth noting that you are not limited to just one volume per ,NA,NA
"container, as that would be a serious limitation.",NA,NA
You can use the ,-v,NA
 multiple times to mount multiple data volumes.,NA,NA
Another option to share the volume between containers is the ,-volumes-from,NA
 switch. If ,NA,NA
"one of your containers has volumes mounted already, by using this option we can ",NA,NA
"instruct Docker to use the volume mapped in some other container, instead of ",NA,NA
providing the name of the volume. Consider this example:,$ docker run -it -volumes-from myBusybox4 --name myBusybox5 busybox,NA
After running the ,myBusybox5,NA
" container this way, again, if you enter the ",/volume,NA
directory in the ,myBusybox5,NA
" container running, you will see the same ",data.txt,NA
 file.,NA,NA
The ,docker volume ls,NA
" command can take some filter parameters, which can be quite ",NA,NA
"useful. For example, you can list volumes that are not being used by any container:",docker volume ls -f dangling=true,NA
Volumes that are no longer used by any container can be easily removed by using ,NA,NA
the docker volumes prune command:,docker volume prune,NA
To list volumes being created with a specific driver (we are going to cover drivers in ,NA,NA
"a short while), you can filter a list using the driver filter, as in the following example:",docker volume ls -f driver=local,NA
"Last but not least, another way of creating a volume is the ",VOLUME CREATE,NA
 instruction in ,NA,NA
a Dockerfile. We will be using it later in the book when creating an image from a ,NA,NA
Dockerfile. Creating volumes using the ,VOLUME CREATE,NA
 instruction has one but very ,NA,NA
important difference in comparison to using the ,-v,NA
 option during the container ,NA,NA
startup: you cannot specify a ,host,NA
 directory when using ,VOLUME CREATE,NA
. It's an analogy ,NA,NA
to exposing and mapping ports. You cannot map a port in a Dockerfile. Dockerfiles ,NA,NA
"are meant to be portable, shareable, and host-independent. The ",host,NA
 directory is ,NA,NA
"100% host-dependent and will break on any other machine, which is a little bit off ",NA,NA
"from the Docker's idea. Because of this, it is only possible to use portable ",NA,NA
instructions within a Dockerfile.,NA,NA
If you need to specify a ,host,NA
" directory when creating a volume, you ",NA,NA
need to specify it at runtime.,NA,NA
Removing a volume,NA,NA
"The same as with creating volumes, there are two ways of removing a volume in ",NA,NA
"Docker. Firstly, you can remove a volume by referencing a container's name ",NA,NA
and executing the docker ,rm -v,NA
 command:,$ docker rm -v <containerName or ID>,NA
"Docker will not warn you, when removing a container without providing the ",-v,NA
"option, to delete its volumes. As a result, you will have ",dangling,NA
 volumes—volumes ,NA,NA
"that are no longer referenced by a container. As you remember, they are easy to get ",NA,NA
rid of using the docker volume prune command.,NA,NA
Another option to remove the volume is by using the ,docker volume rm,NA
 command:,$ docker volume rm <volumeName or ID>,NA
"If the volume happens to be in use by the container, Docker Engine will not allow ",NA,NA
you to delete it and will give you a warning message:,NA,NA
"As you can see, creating, sharing, and removing volumes in Docker is not that tricky. ",NA,NA
It's very flexible and allows the creating a setup you will need for your applications.,NA,NA
"But there's more to this flexibility. When creating a volume, you can specify a ","--
 driver",NA
 option (or ,-d,NA
" for short), which may be useful if you need to map some ",NA,NA
"external, not so standard storage. The volumes we have created so far were using the ",NA,NA
local filesystem driver (the files were being stored on the local drive of the host ,NA,NA
system); you can see the driver name when inspecting a volume using the ,"volume 
 inspect",NA
 command. There are other options though—let's look at them now.,NA,NA
Volume drivers,NA,NA
"The same as with network driver plugins, volume plugins extend the capabilities of ",NA,NA
the Docker engine and enable integration with other types of storage. There are a ton ,NA,NA
of ready to use plugins available for free on the Internet; you can find a list on ,NA,NA
Docker's GitHub page. Some of them include:,NA,NA
Docker volume driver for Azure file storage,NA,NA
: This is a Docker volume driver ,NA,NA
which uses Azure file storage to mount file shares on the cloud to Docker ,NA,NA
containers as volumes. It uses the network file sharing (SMB/CIFS protocols) ,NA,NA
capabilities of Azure file storage. You can create Docker containers that can ,NA,NA
migrate from one host to another seamlessly or share volumes among multiple ,NA,NA
containers running on different hosts.,NA,NA
IPFS,NA,NA
: Open source volume plugin that allows the use of an IPFS filesystem as a ,NA,NA
volume. IPFS is a very interesting and promising storage system; it makes it ,NA,NA
possible to distribute high volumes of data with high efficiency. It provides ,NA,NA
"deduplication, high performance, and clustered persistence, providing secure ",NA,NA
"P2P content delivery, fast performance, and decentralized archiving. IPFS ",NA,NA
"provides resilient access to data, independent of low latency or connectivity to ",NA,NA
the backbone.,NA,NA
Keywhiz,NA,NA
: You can use this driver to make your container talk to a remote ,NA,NA
"Keywhiz server. Keywhiz is a system for managing and distributing secret data, ",NA,NA
"the same as TLS certificates/keys, GPG keys, API tokens, and database ",NA,NA
credentials. Instead of putting this data in config files or copying files (which is ,NA,NA
"similarly to be leaked or difficult to track), Keywhiz makes managing it easier ",NA,NA
and more secure: Keywhiz servers in a cluster centrally store secrets encrypted ,NA,NA
in a database. Clients use ,NA,NA
mutually authenticated TLS,NA,NA
 (,NA,NA
mTLS,NA,NA
) to retrieve ,NA,NA
secrets they have access to.,NA,NA
"As you can see from the previous examples, they are quite interesting, sometimes ",NA,NA
"even exotic. Because of the extendable nature of Docker and its plugin architecture, ",NA,NA
"you can create very flexible setups. But, third-party drivers do not always introduce ",NA,NA
"completely new storage types; sometimes, they just extend the existing drivers. An ",NA,NA
"example of that can be the Local Persist Plugin, a volume plugin that extends the ",NA,NA
default local driver's functionality by allowing you to specify a mount point ,NA,NA
"anywhere on the host, which enables the files to always persist, even if the volume is ",NA,NA
removed via the ,docker volume rm,NA
 command.,NA,NA
"If you need a volume plugin that is not yet available, you can just write your own. ",NA,NA
"The process is very well documented on Docker's GitHub page, together with ",NA,NA
extensible examples.,NA,NA
We've now covered how to open our containers to the external world. We can ,NA,NA
use networking and mounted volumes to be able to share data between containers ,NA,NA
and other hosts. Let's summarize what we have learned so far in this chapter:,NA,NA
We can use the network plugins to further extend the networking data exchange,NA,NA
"Volumes persist the data, even through container restarts",NA,NA
"Changes to files on the volume are made directly, but they will not be included ",NA,NA
when you update an image,NA,NA
Data volumes persist even if the container itself is deleted,NA,NA
Volumes allow of sharing data between the host filesystem and the Docker ,NA,NA
"container, or between other Docker containers",NA,NA
We can use the volume drivers to further extend the file exchange possibilities,NA,NA
Containers from the same Docker host see each other automatically on,NA,NA
the default bridge network.,NA,NA
Summary,NA,NA
"In this chapter, we have learned about Docker networking and storage volume ",NA,NA
"features. We know how to differentiate between various network types, how ",NA,NA
"to create a network, and expose and map network ports.",NA,NA
We've been through volume-related commands and can now create or remove a ,NA,NA
volume. In ,NA,NA
Chapter 3,NA,NA
", ",NA,NA
Working with Microservices,NA,NA
", we are going to focus on the ",NA,NA
"software that we are going to deploy using Docker and Kubernetes, and later, Java ",NA,NA
microservices.,NA,NA
Working with Microservices,NA,NA
"After reading the previous two chapters, you should now have an understanding of ",NA,NA
"the Docker architecture and its concepts. Before we go further on our Java, Docker, ",NA,NA
"and Kubernetes journey, let's get to know the concept of microservices.",NA,NA
"By reading this chapter, you will find out why a transition to microservices and ",NA,NA
cloud development is necessary and why monolithic architecture is not an option ,NA,NA
anymore. The microservices architecture is also where Docker and Kubernetes will ,NA,NA
be especially useful.,NA,NA
This chapter will cover the following topics:,NA,NA
An introduction to microservices and comparison to a monolithic architecture,NA,NA
How Docker and Kubernetes fits into the microservices world,NA,NA
When to use microservices architecture,NA,NA
Before we actually create the Java microservice and deploy it using Docker and ,NA,NA
"Kubernetes, let's start with an explanation of the microservices idea and compare it ",NA,NA
to the monolithic architecture.,NA,NA
An introduction to microservices,NA,NA
"By definition, microservices, also known as the ",NA,NA
Microservice Architecture,NA,NA
 (,NA,NA
MSA,NA,NA
"), ",NA,NA
is an architectural style and design pattern which says that an application should ,NA,NA
consist of a collection of loosely-coupled services. This architecture decomposes ,NA,NA
"business domain models into smaller, consistent pieces implemented by services. In ",NA,NA
"other words, each of the services will have its own responsibilities, independent of ",NA,NA
"others, each one of them will provide a specific functionality.",NA,NA
"These services should be isolated and autonomous. Yet, they of course need to ",NA,NA
communicate to provide some piece of business functionality. They usually ,NA,NA
communicate using ,REST,NA
 exposures or by publishing and subscribing events in the ,NA,NA
publish/subscribe way.,NA,NA
The best way of explaining the reasoning behind the idea of microservices is to ,NA,NA
"compare them with an old, traditional approach for building large applications, the ",NA,NA
monolithic design.,NA,NA
Take a look at the following diagram presenting the monolithic application and ,NA,NA
distributed application consisting of microservices:,NA,NA
"As you can see on the previous diagram, the monolithic application differs totally ",NA,NA
from an application created using the microservices architecture. Let's compare the ,NA,NA
two approaches and point out their advantages and flaws.,NA,NA
Monolithic versus microservices ,NA,NA
We ,NA,NA
begin the comparison by starting with the description of the monolithic ,NA,NA
architecture to present its characteristics.,NA,NA
The monolithic architecture,NA,NA
"In the past, we used to create applications as complete, massive, and uniform pieces ",NA,NA
of code. Let's take a web MVC application for example. A simplified architecture of ,NA,NA
such an application is presented in the following diagram:,NA,NA
"As you can see, the diagram presents the typical web application, a fragment of a ",NA,NA
banking system in this case. It's the ,NA,NA
ModelView Controller,NA,NA
 (,NA,NA
MVC,NA,NA
") application, ",NA,NA
"consisting of models, views, and controllers to serve up HTML content back to the ",NA,NA
client's browser. It could probably also accept and send the JSON content via the ,NA,NA
"REST endpoints. This kind of an application is built as a single unit. As you can see, ",NA,NA
we have a couple of layers here. Enterprise Applications are built in three parts ,NA,NA
usually: a client-side user interface (consisting of HTML pages and JavaScript ,NA,NA
"running in a browser), a server-side part handling the ",HTTP,NA
 requests (probably ,NA,NA
"constructed using some spring-like controllers), then we have a service layer, which ",NA,NA
could probably be implemented using EJBs or Spring services. The service layer ,NA,NA
"executes the domain specific business logic, and retrieves/updates data in the ",NA,NA
"database, eventually. This is a very typical web application which every one of us ",NA,NA
"has probably created once in a while. The whole application is a monolith, a single ",NA,NA
"logical executable. To make any changes to the system, we must build and deploy an ",NA,NA
updated version of the whole server-side application; this kind of application is ,NA,NA
"packaged into single WAR or EAR archive, altogether with all the static content ",NA,NA
"such as HTML and JavaScript files. When deployed, all the application code runs in ",NA,NA
the same machine. Scaling this kind of application usually requires deploying ,NA,NA
"multiple copies of the exact same application code to multiple machines in a cluster,",NA,NA
behind some load balancer perhaps.,NA,NA
"This design wasn't too bad, we had our applications up and running, after all. But the ",NA,NA
"world, especially when using Agile methodologies, changes fast. Businesses have ",NA,NA
started asking to release software faster than ever. ASAP has become a very common ,NA,NA
"word in the IT development language dictionary. The specification fluctuates, so the ",NA,NA
code changes often and grows over time. If the team working on the application is ,NA,NA
"large (and it probably will be in case of complex, huge applications) everyone must ",NA,NA
"be very careful not to destroy each other's work. With every added feature, our ",NA,NA
applications become more and more complex. The compile and build times become ,NA,NA
"longer, sooner or later it will become tricky to test the whole thing using unit or ",NA,NA
"integration tests. Also, the point of entry for new members coming to the team can be ",NA,NA
"daunting, they will need to checkout the whole project from the source code ",NA,NA
repository. Then they need to build it in their IDE (which is not always that easy in ,NA,NA
"case of huge applications), and analyze and understand the component structure to ",NA,NA
"get their job done. Additionally, people working on the user interface part will need ",NA,NA
"to communicate with developers working on the middle-tier, with people modelling ",NA,NA
"the database, DBAs, and so on. The team structure will often begin to mimic the ",NA,NA
application architecture over time. There's a risk that a developer working on the ,NA,NA
specific layer will tend to put as much logic into the layer he controls as he can. As a ,NA,NA
"result, the code can become unmaintainable over time. We all have been there and ",NA,NA
"done that, haven't we?",NA,NA
"Also, the scaling of monolithic systems is not as easy as putting a WAR or EAR in ",NA,NA
another application server and then booting it. Because all the application code runs ,NA,NA
"in the same process on the server, it's often almost impossible to scale individual ",NA,NA
portions of the application. Take this example: we have an application which ,NA,NA
integrates with the VOIP external service. We don't have many users of our ,NA,NA
"application, but then there is a lot of events coming from the VOIP service we need ",NA,NA
"to process. To handle the increasing load, we need to scale our application and, in the ",NA,NA
"case of a monolithic system, we need to scale the whole system. That's because the ",NA,NA
"application is a single, big, working unit. If just one of the application's services is ",NA,NA
"CPU or resource hungry, the whole server must be provisioned with enough memory ",NA,NA
and CPU to handle the load. This can be expensive. Every server needs a fast CPU ,NA,NA
and enough RAM to be able to run the most demanding component of our ,NA,NA
application.,NA,NA
All monolithic applications have these characteristics:,NA,NA
"They are rather large, often involving a lot of people working on them. This can",NA,NA
"be a problem when loading your project into the IDE, despite having powerful ",NA,NA
"machines and a great development environment, such as IntelliJ IDEA, for ",NA,NA
"example. But it's not only about the hundreds, thousands, or millions of lines of ",NA,NA
"code. It's about the complexity of the solution, such as communication problems ",NA,NA
between team members. Problems with communication could lead to multiple ,NA,NA
solutions for the same problem in different parts of the application. And this ,NA,NA
"will make it even bigger, it can easily evolve into a big ball of mud where no ",NA,NA
"one can understand the whole system any longer. Moreover, people can be ",NA,NA
"afraid of introducing substantial changes to the system, because something at an ",NA,NA
opposite end could suddenly stop working. Too bad if this is reported by the ,NA,NA
"users, on a production system.",NA,NA
"They have a long release cycle, we all know the process of release management, ",NA,NA
"permissions, regression testing, and so on. It's almost impossible to create a ",NA,NA
"continuous delivery flow having a huge, monolith application.",NA,NA
They are difficult to scale; it typically takes a considerable amount of work to ,NA,NA
put in a new application instance in the cluster by the operations team. Scaling ,NA,NA
"the specific feature is impossible, the only option you have is to multiply the ",NA,NA
instances of the whole system in the cluster. This makes scaling up and down a ,NA,NA
big challenge.,NA,NA
"In case of deployment failure, the whole system is unavailable.",NA,NA
You are locked into the specific programming language or technology stack. Of ,NA,NA
"course, with Java, parts of the system can be developed in one or more ",NA,NA
"languages that run on JVM, such as Scala, Kotlin, or Groovy, but if you need to ",NA,NA
integrate with a ,.net,NA
" library, here begins the trouble. This also means that you ",NA,NA
will not always be able to use the right tool for the job. Imagine a scenario in ,NA,NA
which you would like to store a lot of complex documents in the database. They ,NA,NA
often have different structures. MongoDB as a document database should be ,NA,NA
"suitable, right? Yes, but our system is running on Oracle.",NA,NA
"It's not well suited well for agile development processes, where we need to ",NA,NA
"implement changes all the time, release to production almost at once, and be ",NA,NA
ready for the next iteration.,NA,NA
"As you can see, monolithic applications are only good for small scale teams and ",NA,NA
small projects. If you need something that has a larger scale and involves many ,NA,NA
"teams, it's better to look at the alternative. But what to do with the existing ",NA,NA
monolithic system you may enjoy dealing with? You may realize that it can be handy ,NA,NA
"to outsource some parts of the system outside, into small services. This will speed up ",NA,NA
the development process and increase testability. It will also make you application ,NA,NA
"easier to scale. While the monolithic application still retains the core functionality, ",NA,NA
many pieces can be outsourced into small side services supporting the core module.,NA,NA
This approach is presented in the following diagram:,NA,NA
"In this, let's say intermediary solution, the main business logic will stay in your ",NA,NA
"application monolith. Things such as integrations, background jobs, or other small ",NA,NA
"subsystems that can be triggered by messages, for example, can be moved to their ",NA,NA
"own services. You can even put those services into the cloud, to limit the necessity ",NA,NA
for managing infrastructure around them even further. This approach allows you to ,NA,NA
gradually move your existing monolith application into a fully service-oriented ,NA,NA
architecture. Let's look at the microservices approach.,NA,NA
The microservices architecture,NA,NA
The microservices architecture is designed to address the issues we've mentioned ,NA,NA
with monolithic applications. The main difference is that the services defined in the ,NA,NA
"monolithic application are decomposed into individual services. Best of all, they are ",NA,NA
deployed separately from one another on separate hosts. Take a look at the following ,NA,NA
diagram:,NA,NA
"When creating an application using the microservices architecture, each microservice ",NA,NA
"is responsible for a single, specific business function and contains only the ",NA,NA
implementation that is required to perform exactly that specific business logic. It's ,NA,NA
same as a ,NA,NA
divide,NA,NA
 and ,NA,NA
conquer,NA,NA
 way of creating a system. This may seem similar to ,NA,NA
"the SOA-oriented architecture. In fact, traditional SOA and microservices ",NA,NA
architecture share some common features. Both organize fragments of the ,NA,NA
application into services and both define clear boundaries at which a service can be ,NA,NA
"decoupled from the other. SOA, however, has its roots in the need to integrate ",NA,NA
"monolithic applications with another one. This has been done, usually, using an API ",NA,NA
"that was usually SOAP-based, using heavy XML messaging. In SOA, this ",NA,NA
"integration was relying heavily on some kind of middleware in between, usually ",NA,NA
Enterprise Service Bus,NA,NA
 (,NA,NA
ESB,NA,NA
). Microservices architecture can also utilize the ,NA,NA
"message bus, with significant differences. In microservices architecture there is no ",NA,NA
"logic in the messaging layer at all, it is purely used as a transport for messages from ",NA,NA
"one service to another. This is a total contrast to ESB, which needed a lot of logic for ",NA,NA
"message routing, schema validation, message translation, and so on. As a result, ",NA,NA
microservices architecture is less cumbersome than traditional SOA.,NA,NA
"When it comes to scaling, there's a huge difference when comparing microservices to ",NA,NA
monolithic applications. The key advantage of microservices is that a single service ,NA,NA
"can be scaled individually, depending on the resource requirements. That's because ",NA,NA
they are self-sufficient and independent. As a microservice is usually deployed on ,NA,NA
smaller (in terms of resources) host; the host needs to contain only resources that are ,NA,NA
"required for a service to function properly. As the resource requirement grows, ",NA,NA
"scaling is easy both ways, horizontally and vertically. To scale horizontally, you just ",NA,NA
deploy as many instances as you need to handle load on a specific component.,NA,NA
"We will get back to this concept in the coming chapters, when we will be getting to ",NA,NA
know Kubernetes. Scaling vertically is also a lot easier and cheaper in comparison to ,NA,NA
"the monolithic systems, you upgrade only a host on which your microservice is being ",NA,NA
"deployed. Also, introducing new versions of the service is easy, you don't need to ",NA,NA
"stop the whole system just to upgrade a piece of functionality. In fact, you can do it ",NA,NA
"on the fly. When deployed, microservices improve the fault tolerance for the entire ",NA,NA
"application. For example, if there is a memory leak in one service or some other ",NA,NA
"problem, only this service will be affected and can then be fixed and upgraded ",NA,NA
without interfering with the rest of the system. This is not the case with monolithic ,NA,NA
"architecture, where one faulty component can bring down the entire application.",NA,NA
"From a developer's perspective, having your application split into separate pieces ",NA,NA
deployed individually gives a huge advantage. A developer skilled in server-side ,NA,NA
JavaScript can develop its piece ,node.js,NA
", while the rest of the system will be ",NA,NA
developed in Java. It's all related to the API exposed by each microservice; apart ,NA,NA
"from this API, each microservice doesn't need to know anything about the rest of the ",NA,NA
services. This makes the development process a lot easier. Separate microservices ,NA,NA
"can be developed and tested independently. Basically, the microservices approach ",NA,NA
"dictates that instead of having one giant code base that all developers are working on, ",NA,NA
"which often becomes tricky to manage, there are several smaller code bases managed ",NA,NA
by small and agile teams. The only dependency services have on one another is their ,NA,NA
"exposed APIs. There's a difference in storing data as well. As we have said before, ",NA,NA
"each microservice should be responsible for storing its own data, because again, it ",NA,NA
should be independent. This leads to another feature of the ,NA,NA
"microservices architecture, a possibility to have a polyglot persistence.",NA,NA
Microservices should own their data.,NA,NA
While microservices communicate and exchange data with other microservices using ,NA,NA
"REST endpoints or events, they can store their own data in the form that is best ",NA,NA
"suitable for the job. If the data is relational, the service will be using a traditional, ",NA,NA
relational database such as MySQL or PostgreSQL. If a document database is better,NA,NA
"suited for the job, a microservice can use MongoDB for example, or Neo4j if it's ",NA,NA
"graph as data. That leads to another conclusion, by implementing the microservices ",NA,NA
architecture we can now only choose the programming language or framework that ,NA,NA
"will be best suited for the job, this applies to the data storage as well. Of course, ",NA,NA
"having its own data can lead to a challenge in the microservices architecture, data ",NA,NA
consistency. We are going to cover this subject in a while in this chapter.,NA,NA
Let's summarize the benefits of using the microservices architecture from the ,NA,NA
development process perspective:,NA,NA
"Services can be written using a variety of languages, frameworks, and their ",NA,NA
versions,NA,NA
"Each microservice is relatively small, easier to understand by the ",NA,NA
developer ,NA,NA
"(which results in less bugs), easy to develop, and testable",NA,NA
"The deployment and start up time is fast, which makes developers more ",NA,NA
productive,NA,NA
Each service can consist of multiple service instances for increased throughput ,NA,NA
and availability,NA,NA
"Each service can be deployed independently of other services, easier to deploy ",NA,NA
new versions of services frequently,NA,NA
It is easier to organize the development process; each team owns and is ,NA,NA
"responsible for one or more service and can develop, release, or scale their ",NA,NA
service independently of all of the other teams,NA,NA
You can choose whatever programming language or framework you think is ,NA,NA
best for the job. There is no long-term commitment to a technology stack. If ,NA,NA
"needed, the service can be rewritten in the new technology stack, and if there ",NA,NA
"are no API changes, this will be transparent for the rest of the system",NA,NA
"It is better for continuous delivery as small units are easier to manage, test, and ",NA,NA
deploy. As long as each team maintains backwards and forward API ,NA,NA
"compatibility, it can work in release cycles that are decoupled from other teams. ",NA,NA
"There are some scenarios where these release cycles are coupled, but this is not ",NA,NA
the common case,NA,NA
Maintaining data consistency,NA,NA
"Services must be loosely coupled so that they can be developed, deployed, and ",NA,NA
"scaled independently. They of course, need to communicate, but they are ",NA,NA
"independent of each other. They, have well defined interfaces and encapsulate ",NA,NA
implementation details. But what about data? In the real world and in non-trivial ,NA,NA
"applications (and microservice applications will probably be non-trivial), business ",NA,NA
"transactions must often span multiple services. If you, for example, create a banking ",NA,NA
"application, before you execute the customer's money transfer order, you need to ",NA,NA
ensure that it will not exceed his account balance. The single database that comes ,NA,NA
"with a monolith application gives us a lot of convenience: atomic transactions, a ",NA,NA
"single place to look for data, and so on.",NA,NA
"On the other hand, in the microservices world, different services need to be ",NA,NA
independent. This also means that they can have different data storage requirements.,NA,NA
"For some services, it will be a relational database, others might need a document ",NA,NA
"database such as MongoDB, which is good at storing complex, unstructured data.",NA,NA
"So, when building microservices and thus splitting up our database into multiple ",NA,NA
"smaller databases, how do we manage these challenges? We have also said that ",NA,NA
"services should own their data. That is, every microservice should depend only on its ",NA,NA
own database. The service's database is effectively part of the implementation of that ,NA,NA
service. This leads to quite an interesting challenge when designing the ,NA,NA
microservices architecture. As Martin Fowler says in his ,Microservice trade-offs,NA
column: Maintaining strong consistency is extremely difficult for a distributed ,NA,NA
"system, which means everyone has to manage eventual consistency. How do we deal ",NA,NA
"with this? Well, it's all about boundaries.",NA,NA
Microservices should have clearly defined responsibilities and boundaries.,NA,NA
"Microservices need to be grouped according to their business domain. Also, in ",NA,NA
"practice, you will need to design your microservices in such a way that they cannot ",NA,NA
directly connect to a database owned by another service. The loose coupling means ,NA,NA
microservices should expose clear API interfaces that model the data and access ,NA,NA
"patterns related to this data. They must stick to those interfaces, when changes are ",NA,NA
"necessary, you will probably introduce a versioning mechanism and create another ",NA,NA
version of the microservice. You could use a publish/subscribe pattern to dispatch ,NA,NA
"events from one microservice to be processed by others, as you can see in the",NA,NA
following diagram:,NA,NA
The publish/subscribe mechanism you would want to use should provide retry and ,NA,NA
"rollback features for the event processing. In a publish/subscribe scenario, the ",NA,NA
service that modifies or generates the data allows other services to subscribe to ,NA,NA
events. The subscribed services receive the event saying that the data has been ,NA,NA
modified. It's often the case that the event contains the data that has been modified. ,NA,NA
"Of course, the event publish/subscribe pattern can be used not only in relation to data ",NA,NA
"changes, it can be used as a generic communication mechanism between services. ",NA,NA
"This is a simple and effective approach but it has a downside, there is a possibility to ",NA,NA
lose an event.,NA,NA
"When creating distributed applications, you may want to consider that there will be ",NA,NA
data inconsistency for some amount of time. When an application changes data items ,NA,NA
"on one machine, that change needs to be propagated to the other replicas. Since the ",NA,NA
"change propagation is not instant, there's a time interval during which some of the ",NA,NA
"copies will have the most recent change, but others won't. However, the change will ",NA,NA
"be propagated to all the copies, eventually. That's why this is called eventual ",NA,NA
consistency. Your services would need to assume that the data will be in an ,NA,NA
inconsistent state for a while and need to deal with the situation by using the data as ,NA,NA
"is, postponing the operation, or even ignoring certain pieces of data.",NA,NA
"As you can see, there are a lot of challenges, but also a lot of advantages behind ",NA,NA
"using microservices architecture. You should be warned, though, there are more ",NA,NA
"challenges we need to address. As services are independent of each other, they can ",NA,NA
be implemented in different programming languages. This means the deployment ,NA,NA
process of each may vary: it will be totally different for a Java web application and ,NA,NA
for a ,node.js,NA
 application. This can make the deployment to a server complex. This is,NA,NA
precisely the point where Docker comes to the rescue.,NA,NA
The Docker role,NA,NA
"As you remember from the previous chapters, Docker utilizes the concept of ",NA,NA
"containerization. You simply put your application (in this context, the application ",NA,NA
"will be a microservice) no matter what language and technology it uses, into a single, ",NA,NA
"deployable and runnable piece of software, called the image. We are going to cover ",NA,NA
the process of packaging a Java application into the image in detail in the ,NA,NA
Chapter 4,NA,NA
", ",NA,NA
Creating Java Microservices,NA,NA
. The Docker image will contain everything our service ,NA,NA
"needs to work, it can be a Java Virtual Machine with all required libraries and an ",NA,NA
"application server, or it can also be a ",node.js,NA
 application packaged together with the ,node.js,NA
 runtime with all the needed ,node.js,NA
" modules, such as ",express.js,NA
 or whatever ,NA,NA
the ,node.js,NA
" service needs to run. A microservice might consist of two containers,   ",NA,NA
one running the service code and another running a database to keep the service's ,NA,NA
own data.,NA,NA
"Docker isolates containers to one process or service. In effect, all the pieces of our ",NA,NA
"application will just be a bunch of black boxes, packaged and ready to use Docker ",NA,NA
"images. Containers operate as fully isolated sandboxes, with only the minimal kernel ",NA,NA
of the operating system present for each container. Docker uses the Linux kernel and ,NA,NA
"makes use of kernel interfaces such as cnames and namespaces, which allow ",NA,NA
multiple containers to share the same kernel while running in complete isolation ,NA,NA
from one another.,NA,NA
"Because the system resources of the underlying system are shared, you can run your ",NA,NA
"services at optimal performance, the footprint is substantially smaller in comparison ",NA,NA
"to traditional virtual machines. Because containers are portable, as we have said in ",NA,NA
C ,NA,NA
hapter 2,NA,NA
", ",NA,NA
Networking and Persistent Storage,NA,NA
", they can run everywhere the Docker ",NA,NA
engine can run. This makes the process of deployment of microservices easy. To ,NA,NA
"deploy a new version of a service running on a given host, the running container can ",NA,NA
simply be stopped and a new container started that is based on a Docker image using ,NA,NA
the latest version of the service code. We are going to cover the process of creating ,NA,NA
"new versions of the image later in this book. Of course, all the other containers ",NA,NA
running on the host will not be affected by this change.,NA,NA
As microservices need to communicate using the ,REST,NA
" protocol, our Docker ",NA,NA
"containers (or, to be more precise, your Java microservices packaged and running ",NA,NA
from within the Docker container) also need to communicate using the network. As ,NA,NA
you remember from ,NA,NA
Chapter 2,NA,NA
", ",NA,NA
Networking and Persistent Storage,NA,NA
", about networking,",NA,NA
it's very easy to expose and map a network port for the Docker container. It seems ,NA,NA
that Docker containerization is ideal for the purposes of microservice architecture.,NA,NA
You can package the microservice into a portable box and expose the needed ,NA,NA
"network ports, enabling it to communicate to the outside world. When needed, you ",NA,NA
can run as many of those boxes as you want.,NA,NA
Let's summarize the Docker features that are useful when dealing with ,NA,NA
microservices:,NA,NA
"It is easy to scale up and scale down a service, you just change the running ",NA,NA
container instances count,NA,NA
The container hides the details of the technology behind each of the services. ,NA,NA
All containers with our services are started and stopped in exactly the same ,NA,NA
"way, no matter what technology stack they use",NA,NA
Each service instance is isolated,NA,NA
You can limit the runtime constraints on the CPU and memory consumed by a ,NA,NA
container,NA,NA
Containers are fast to build and start. As you remember from ,NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", there's minimal overhead in comparison to traditional ",NA,NA
virtualization,NA,NA
"Docker image layers are cached, this gives you another speed boost when ",NA,NA
creating a new version of the service,NA,NA
Doesn't it fit perfectly for the definition of the microservices architecture? Sure it ,NA,NA
"does, but there's one problem. Because our microservices are spread out across ",NA,NA
"multiple hosts, it can be difficult to track which hosts are running certain services ",NA,NA
"and also monitor which of them need more resources or, in the worst case, are dead ",NA,NA
"and not functioning properly. Also, we need to group services that belong to the ",NA,NA
specific application or feature. This is the missing element in our puzzle: container ,NA,NA
management and orchestration. A lot of frameworks emerged for the sole purpose of ,NA,NA
handling more complex scenarios: managing single services in a cluster or multiple ,NA,NA
"instances in a service across hosts, or how to coordinate between multiple services ",NA,NA
on a deployment and management level. One of these tools is Kubernetes.,NA,NA
Kubernetes' role,NA,NA
"While Docker provides the lifecycle management of containers, Kubernetes takes it ",NA,NA
to the next level by providing orchestration and managing clusters of containers. As ,NA,NA
"you know, your application created using the microservice architecture will contain a ",NA,NA
"couple of separated, independent services. How do we orchestrate and manage them?",NA,NA
Kubernetes is an open-source tool that's perfect for this scenario. It defines a set of ,NA,NA
"building blocks which provide mechanisms for deploying, maintaining, and scaling ",NA,NA
applications. The basic scheduling unit in Kubernetes is called a pod. Containers in a ,NA,NA
"pod run on the same host, share the same IP address, and find each other via ",NA,NA
localhost. They can also communicate with each other using standard inter-process ,NA,NA
"communications, such as shared memory or semaphores. A pod adds another level of ",NA,NA
abstraction to containerized components. A pod consists of one or more containers ,NA,NA
that are guaranteed to be co-located on the host machine and can share resources. It's ,NA,NA
same as a logical collection of containers that belong to an application.,NA,NA
"For traditional services, such as a REST endpoint together with the corresponding ",NA,NA
"database (our complete microservice, in fact), Kubernetes provides a concept of ",NA,NA
service. A service defines a logical group of pods and also enforces rules for ,NA,NA
accessing such logical groups from the outside world. Kubernetes uses the concept ,NA,NA
"of Labels for pods and other resources (services, deployments, and so on). These are ",NA,NA
simple the key-value pairs that can be attached to resources at creation time and then ,NA,NA
"added and modified at any time. We will be using labels later on, to organize and to ",NA,NA
"select subsets of resources (pods, for example) to manage them as one entity.",NA,NA
Kubernetes can place your container or a group of containers in the specific host ,NA,NA
"automatically. To find a suitable host (the one with the smallest workload), it will ",NA,NA
analyze the current workload of the hosts and different colocation and availability ,NA,NA
"constraints. Of course, you will be able to specify the host manually, but having this ",NA,NA
automatic feature can make the best of the processing power and resources available.,NA,NA
"Kubernetes can monitor the resource usage (CPU and RAM) at the container, pod, ",NA,NA
and cluster level. The resource usage and performance analysis agent runs on each ,NA,NA
"node, auto-discovers containers on the node, and collects CPU, memory, filesystem, ",NA,NA
and network usage statistics.,NA,NA
Kubernetes also manages the lifecycle of your container instances. If there are too ,NA,NA
"many of them, some of them will be stopped. If the workload increases, new ",NA,NA
containers will be started automatically. This feature is called container auto-scaling.,NA,NA
"It will automatically change the number of running containers, based on memory, ",NA,NA
"CPU utilization, or other metrics you define for your services, as the number of ",NA,NA
"queries per second, for example.",NA,NA
As you remember from ,NA,NA
Chapter 2,NA,NA
", ",NA,NA
Networking and Persistent Storage,NA,NA
", Docker ",NA,NA
operates volumes to persist your application data. Kubernetes also supports two ,NA,NA
"kinds of volume: regular which has the same lifecycle as the pod, and persistent with ",NA,NA
a lifecycle independent of any pod. Volume types are implemented the same way as ,NA,NA
in Docker in the form of plugins. This extensible design enables you to have almost ,NA,NA
any type of volume you need. It currently contains storage plugins such as Google ,NA,NA
"Cloud Platform volume, AWS elastic block storage volume, and others.",NA,NA
"Kubernetes can monitor the health of your services, it can do it by executing a ",NA,NA
specified ,HTTP,NA
 method (the same as ,GET,NA
 for example) for the specified URL and ,NA,NA
analyzing the ,HTTP,NA
" status code given back in response. Also, a TCP probe can check ",NA,NA
if a specified port is open which can also be used to monitor the health of your ,NA,NA
"service. Last, but not least, you can specify the command that can be executed in the ",NA,NA
"container, and some actions that could be taken based on the command's response. If ",NA,NA
"the specified probe method signals that something is wrong with the container, it can ",NA,NA
"be automatically restarted. When you need to update your software, Kubernetes ",NA,NA
"supports rolling updates. This feature allows you to update a deployed, containerized ",NA,NA
application with minimal downtime. The rolling update feature lets you specify the ,NA,NA
number of old replicas that may be down while they are being updated. Upgrading ,NA,NA
"containerized software with Docker is especially easy, as you already know, it will ",NA,NA
just be a new image version for the container. I guess you are now getting the ,NA,NA
"complete picture. Deployments can be updated, rolled out, or rolled back. Load ",NA,NA
"balancing, service discovery, all the features you would probably need when ",NA,NA
orchestrating and managing your herd of microservices running from within Docker ,NA,NA
"containers are available in Kubernetes. Initially made by Google for big scale, ",NA,NA
Kubernetes is nowadays widely used by organizations of various sizes to run ,NA,NA
containers in production.,NA,NA
When to use the microservice,NA,NA
architecture,NA,NA
The microservice architecture is a new way to think about structuring applications At ,NA,NA
"the beginning, when you begin creating a system and it's relatively small, there will ",NA,NA
"probably be no need to use the microservices approach. Of course, it's nothing wrong ",NA,NA
with the basic web application. When doing basic web applications for the people in ,NA,NA
"your office, going with the microservice architecture may be overkill. On the other ",NA,NA
"hand, if you plan to develop a new, super internet service that will be used by ",NA,NA
"millions of mobile clients, I would consider going with microservices from the start.",NA,NA
"Joking aside, you get the picture, always try to pick the best tool for the job. In the ",NA,NA
"end, the goal is to provide business value.",NA,NA
"However, you should keep in mind the whole picture of your system after some time. ",NA,NA
"If your application is growing larger in features and functionality than you expected, ",NA,NA
"or you know that from the beginning, you may want to start breaking features off ",NA,NA
into microservices. You should try to do the functional decomposition and point out ,NA,NA
the fragments of your systems that have clear boundaries and which would need ,NA,NA
"scaling, and separate deployments in the future. If there's a lot of people working on ",NA,NA
"a project, having them developing the separate, independent pieces of an application ",NA,NA
will give the development process a huge boost. There can be a mix of technology ,NA,NA
stacks used each service can be implemented in a different programming language or ,NA,NA
framework and store its own data in the most suitable data storage. It's all about API ,NA,NA
and the way services communicate with each other. Having this architecture will ,NA,NA
"result in a faster time to market the build, test, and deployment time is highly ",NA,NA
reduced in comparison to a monolith architecture. If you need to scale only the ,NA,NA
service that needs to handle higher workload. Having Docker and Kubernetes ,NA,NA
"available, there is no reason not to go into the microservice architecture; it will pay ",NA,NA
"off in the future, for sure.",NA,NA
"The microservice architecture is not just a new trendy buzzword, it's generally ",NA,NA
accepted as a better way to build applications today. The birth of the ,NA,NA
microservice idea has been driven by the need to make better use of compute ,NA,NA
resources and the need to maintain more and more complex web-based ,NA,NA
applications.,NA,NA
Java is an excellent choice when building microservices. You can create a ,NA,NA
"microservice as a single executable JAR, self-contained Spring Boot application, or",NA,NA
fully featured web application deployed on an application server such as Wildfly or ,NA,NA
Tomcat. Depending on your use case and the responsibilities and features of your ,NA,NA
"microservices, any of the previous will do. Docker Repository contains a lot of ",NA,NA
useful images you can use freely as a base for your microservice. Many images ,NA,NA
"present in The Docker Hub are created by private individuals, some extending ",NA,NA
"official images and customizing them to their needs, but others are entire platform ",NA,NA
configurations customized from base images. The base image can be as simple as ,NA,NA
pure JDK or it can be a fully configured Wildfly ready to run. This gives a serious ,NA,NA
development performance boost.,NA,NA
Summary,NA,NA
"In this chapter, we have compared monolithic and microservices architectures. I hope ",NA,NA
you see the advantages of using the latter. We have also learned how Docker and ,NA,NA
Kubernetes fits into the whole picture when deploying containerized ,NA,NA
"applications, making this process a lot more easy and pleasant. Java is a proven ",NA,NA
ecosystem for implementing microservices. The software you are going to create will ,NA,NA
"consist of small, highly testable, and efficient modules. In fact, in ",NA,NA
Chapter 4,NA,NA
", ",NA,NA
Creating ,NA,NA
Java Microservices,NA,NA
", we are going to get our hands dirty and create such a ",NA,NA
microservice.,NA,NA
Creating Java Microservices,NA,NA
We've seen a lot of theory behind microservice architecture in ,NA,NA
Chapter 3,NA,NA
", ",NA,NA
Working ,NA,NA
with Microservices,NA,NA
. It's time to do some hands-on practice; we are going to ,NA,NA
"implement our own microservice. This will be a simple REST service, accepting ",HTTP,NA
methods such as ,GET,NA
 and ,POST,NA
 to retrieve and update entities. There are a couple of ,NA,NA
"choices when developing microservices in Java. In this chapter, we are going to get ",NA,NA
"an overview about two main approaches, probably the most popular will be JEE7, ",NA,NA
and Spring Boot. We will briefly see how we can code a microservice using JEE ,NA,NA
"JAX-RS. We will also create a microservice running on Spring Boot. In fact, in ",NA,NA
Chapt ,NA,NA
er 5,NA,NA
", ",NA,NA
Creating Images with Java Applications,NA,NA
", we are going to run our Spring Boot ",NA,NA
microservice from within a Docker container. As we have said in ,NA,NA
Chapter 3,NA,NA
", ",NA,NA
Working ,NA,NA
with Microservices,NA,NA
", microservices usually communicate with the outside world using ",NA,NA
REST. Our REST microservice will be as simple as possible; we just need to have ,NA,NA
something to deploy using Docker and Kubernetes. We will not focus on advanced ,NA,NA
"microservice features such as authentication, security, filters, and so on, as this is ",NA,NA
outside the scope of this book. The purpose of our examples is to give you an idea of ,NA,NA
how to develop REST services and then deploy them using Docker and Kubernetes.,NA,NA
This chapter will cover the following topics:,NA,NA
Introduction to REST,NA,NA
Creating a REST service in Java using Java EE7 annotations,NA,NA
Creating a REST service using Spring Boot,NA,NA
Running the service and then calling it with different HTTP clients,NA,NA
"At the end of the chapter, we will become familiar with some useful tools- we will ",NA,NA
use some code generation tools such as Spring Initialzr to quickly bootstrap a Spring ,NA,NA
"Boot service project. Before we start coding our own microservice, let's explain ",NA,NA
briefly what REST is.,NA,NA
Introduction to REST,NA,NA
The REST acronym stands for Representational State Transfer. It's an architectural ,NA,NA
style and a design for network-based software. It describes how one system can ,NA,NA
communicate a state with another. This fits perfectly well into the microservice ,NA,NA
world. As you will remember from ,NA,NA
Chapter 3,NA,NA
", ",NA,NA
Working with Microservices,NA,NA
", the ",NA,NA
software applications based on the microservices architecture is a bunch of ,NA,NA
"separated, independent services talking to each other.",NA,NA
"There are some concepts in REST that we need to understand, before we go further:",resource,NA
: This is the main concept in the REST architecture. Any information ,NA,NA
"can be a resource. A bank account, a person, an image, a book. A representation ",NA,NA
of a resource must be ,NA,NA
stateless,representation,NA
": A specific way a resource can be represented. For example, a ",NA,NA
"bank account resource can be represented using JSON, XML, or HTML. ",NA,NA
"Different clients might request different representations of the resource, one can ",NA,NA
"accept JSON, while others will be expecting XML",server,NA
: A service provider. It exposes services which can be consumed by ,NA,NA
clients,client,NA
": A service consumer. This could be another microservice, application, or ",NA,NA
"just a user's web browser running an Angular application, for example",NA,NA
"As the definition says, REST is being used to transport those resource ",NA,NA
representations over the network. The representation itself is being created via some ,NA,NA
media type. Media types can be different. Some examples of media types include ,NA,NA
"JSON, XML, or RDF. The JSON media type is widely accepted and probably the ",NA,NA
"most often used. In our examples, we will also use JSON to communicate with our ",NA,NA
"service. Of course, REST is not the only option for microservices communication; ",NA,NA
"there are others, such as Google's very good gRPC, for example, which brings a lot ",NA,NA
"of advantages such as HTTP/2 and protobuff. In the REST architecture, resources are ",NA,NA
"manipulated by components. In fact, these components are our microservices.",NA,NA
Components request and manipulate resources via a standard uniform interface. ,NA,NA
"REST is not tied to any specific protocol; however, REST calls are most often ",NA,NA
being made using the most popular ,HTTP,NA
 or ,HTTPS,NA
 protocol. In the case of ,HTTP,NA
", this ",NA,NA
uniform interface consists of standard HTTP methods such as ,GET,NA
", ",PUT,NA
", ",POST,NA
", and ",DELETE,NA
.,NA,NA
REST is not tied to any specific protocol.,NA,NA
Before we start implementing our service that will respond to ,HTTP,NA
" calls, it's worth ",NA,NA
knowing about the HTTP methods we are going to use. We are going to focus on ,NA,NA
them a little bit closer now.,NA,NA
HTTP methods,NA,NA
The REST-based architecture uses standard HTTP methods: ,PUT,NA
", ",GET,NA
", ",POST,NA
", and ",DELETE,NA
. ,NA,NA
The following list gives an explanation of these operations:,GET,NA
 gives a read access to the resource. Calling ,GET,NA
 should not create any side-,NA,NA
effects. It means that the ,GET,NA
 operation is idempotent. The resource is never ,NA,NA
changed via a ,GET,NA
" request; for example, the request has no side effects. It means ",NA,NA
it's idempotent,PUT,NA
 creates a new resource. Similar to ,GET,NA
", it should also be idempotent",DELETE,NA
 removes the resource or resources. The ,DELETE,NA
 operation should not give ,NA,NA
different results when called repeatedly,POST,NA
 will update an existing resource or create a new one,NA,NA
A RESTful web service is simply a web service that is based on the ,REST,NA
 resource ,NA,NA
concept and usage of HTTP methods. It should define the base URI for the exposed ,NA,NA
"methods, the MIME-types supported, such as XML, text, or JSON, and the set of ",NA,NA
operations (,POST,NA
", ",GET,NA
", ",PUT,NA
", and ",DELETE,NA
) which the service handles. HTTP is simple and ,NA,NA
"very natural for REST, according to RESTful principles. These principles are a set of ",NA,NA
"constraints that ensure that clients (service consumers, other services or browsers, for ",NA,NA
example) can communicate with servers in a flexible way. Let's look at them now.,NA,NA
"In REST principles client-server communication, all applications built in the ",NA,NA
RESTful style must also be client-server in principle. There should be a server ,NA,NA
(service provider) and a client (service consumer). Having this enables loose ,NA,NA
coupling and independent evolution of server and client. This fits very well to the ,NA,NA
concept of a microservice. As you will remember from ,NA,NA
Chapter 3,NA,NA
", ",NA,NA
Working with ,NA,NA
Microservices,NA,NA
", they must be independent:",NA,NA
Stateless,NA,NA
: Each ,client,NA
 request to the server requires that its state be fully ,NA,NA
represented. The server must be able to completely understand the ,client,NA
"request without using any server context or server session state. In other words, ",NA,NA
all states must be managed on the client side. Each REST service should be ,NA,NA
stateless,NA,NA
. Subsequent requests should not depend on some data from a previous ,NA,NA
request being temporarily stored. Messages should be self-descriptive.,NA,NA
Cacheable,NA,NA
: Response data could be marked as cacheable or non-,NA,NA
cacheable. ,NA,NA
Any data marked as cacheable may be reused as the response ,NA,NA
to the same ,NA,NA
subsequent request. Each response should indicate if it is ,NA,NA
cacheable.,NA,NA
Uniform interface,NA,NA
: All components must interact through a single uniform ,NA,NA
"interface. Because all component interactions occur via this interface, ",NA,NA
interaction with different services is very simple.,NA,NA
Layered system,NA,NA
: A consumer of the service should not assume direct ,NA,NA
"connection to the service provider. In other words, at any time the client cannot ",NA,NA
tell if it is connected to the end server or to an intermediate. The intermediate ,NA,NA
layer helps to enforce the security policies and improve the system scalability ,NA,NA
"by enabling load-balancing. Since requests can be cached, the client might be ",NA,NA
getting the cached response from a middle layer.,NA,NA
Manipulation of resources through representations,NA,NA
: A resource can have ,NA,NA
multiple representations. It should be possible to modify the resource through a ,NA,NA
message with any of these representations.,NA,NA
Hypermedia As The Engine Of Application State (HATEOAS),NA,NA
: A consumer ,NA,NA
of a RESTful application should know about only one fixed service URL. All ,NA,NA
subsequent resources should be discoverable from the links included in the ,NA,NA
resource representations.,NA,NA
The previous concepts represent defining characteristics of REST and differentiate ,NA,NA
the REST architecture from other architectures such as web services. It is useful to ,NA,NA
"note that a REST service is a web service, but a web service is not necessarily a ",NA,NA
REST service. The REST microservice should represent the state of an entity. Let ,NA,NA
"our entity be a book, for example (altogether with its properties such as ID, title, and ",NA,NA
"an author), represented as XML, JSON, or plain text. The most basic way of thinking ",NA,NA
"about REST is as a way of formatting the URLs of your service. For example, ",NA,NA
having our ,book,NA
" resource, we could imagine having the following operations defined ",NA,NA
in the service:,/books,NA
 would allow access of all the books,/books/:id,NA
" would be an operation for viewing an individual book, retrieved ",NA,NA
based on its unique ID,NA,NA
sending a ,POST,NA
 request to ,/books,NA
 would be how you would actually create a new ,NA,NA
book and store it in a database,NA,NA
sending a ,PUT,NA
 request to ,/books/:id,NA
 would be how you would update the ,NA,NA
"attributes of a given book, again identified by its unique ID",NA,NA
sending a ,DELETE,NA
 request to ,/books/:id,NA
 would be how you would delete a specific ,NA,NA
"book, again identified by its unique ID",NA,NA
It's worth trying to understand that REST is not HTTP. It often uses HTTP because ,NA,NA
"in its most general form, REST is about mapping the concept of a verb against an ",NA,NA
arbitrary collection of nouns and fits well with HTTP methods. HTTP contains a,NA,NA
useful set of generic verbs (,GET,NA
", ",POST,NA
", ",PUT,NA
", ",PATCH,NA
", and so on). In REST, we do not ",NA,NA
"transfer an actual object but a representation of it in a specific form, such as XML, ",NA,NA
"text, or JSON. REST as an architectural style means it is just a concept. How it's ",NA,NA
"implemented, is up to you. Java is suited well for developing REST services. Let's ",NA,NA
see how can we do it.,NA,NA
REST in Java,NA,NA
"When developing a REST service in Java, we have at least a couple of options for ",NA,NA
the framework we could use. The most popular will be pure JEE7 with JAX-RS or ,NA,NA
Spring Framework with its Spring Boot. You can use either of them or mix them ,NA,NA
"together. Let's look at those two now in more detail, starting with JAX-RS.",NA,NA
Java EE7 - JAX-RS with Jersey,NA,NA
JAX-RS was born as a result of ,NA,NA
Java Specification Request,NA,NA
 (,NA,NA
JSR,NA,NA
) 311. As the ,NA,NA
"official definition says, the JAX-RS is the Java API for RESTful web services. It's a ",NA,NA
specification that provides support in creating web services according to the REST ,NA,NA
"architectural pattern. JAX-RS uses Java annotations, introduced in Java SE 5, to ",NA,NA
simplify the development and deployment of web service clients and endpoints.,NA,NA
"From version 1.1 on, JAX-RS is an official part of Java EE. A notable feature of ",NA,NA
being an official part of Java EE is that no configuration is necessary to start using ,NA,NA
JAX-RS.,NA,NA
"Java EE 7 with JAX-RS 2.0 brings several useful features, which further simplify the ",NA,NA
development of microservices. One of the most important new features of JAX-RS ,NA,NA
2.0 is the support for hypermedia following the HATEOAS principle of REST.,Jersey,NA
", a library from Oracle, is probably the most widely known library, which ",NA,NA
implements this specification.,NA,NA
Jersey is the reference implementation for the JSR 311 specification.,NA,NA
The Jersey implementation provides a library to implement RESTful web services in ,NA,NA
"a Java servlet container. On the server-side, Jersey provides a servlet implementation ",NA,NA
which scans predefined classes to identify RESTful resources. Jersey makes it a lot ,NA,NA
easier to write RESTful services. It abstracts away a lot of the low level coding you ,NA,NA
"will need to do yourself otherwise. Using Jersey, you do it in a declarative way. The ",NA,NA
"servlet, registered in your ",web.xml,NA
" file, analyzes the incoming ",HTTP,NA
 request and selects ,NA,NA
the correct class and method to respond to this request. It finds the proper method to ,NA,NA
execute by looking at the class and method level annotations. Annotated classes can ,NA,NA
"reside in different packages, but you can instruct a Jersey servlet via the ",web.xml,NA
 to ,NA,NA
scan certain packages for annotated classes.,NA,NA
JAX-RS supports the creation of XML and JSON via the ,NA,NA
Java Architecture for ,NA,NA
XML Binding,NA,NA
 (,NA,NA
JAXB,NA,NA
). The Jersey implementation also provides a ,client,NA
 library to ,NA,NA
communicate with a RESTful web service.,NA,NA
"As we have said before, we develop JAX-RS applications using Java annotations. It's ",NA,NA
easy and pleasant to work with. Let's describe those annotations now.,NA,NA
JAX-RS annotations ,NA,NA
The most important annotations in JAX-RS are listed in the following table:,NA,NA
Annotation,NA,NA
Meaning,@PATH,NA
Sets the path to base ,URL + /your_path,NA
. The base URL is based on ,NA,NA
"your application name, the servlet, and the URL pattern from ",NA,NA
the ,web.xml,NA
 configuration file.,@POST,NA
Indicates that the following method will answer to an ,HTTP POST,NA
request.,@GET,NA
Indicates that the following method will answer to an ,HTTP GET,NA
request.,@PUT,NA
Indicates that the following method will answer to an ,HTTP PUT,NA
request.,@DELETE,NA
Indicates that the following method will answer to an ,"HTTP 
 DELETE",NA
 request.,@Produces,NA
Defines which MIME type is delivered by a method annotated ,NA,NA
with ,@GET,NA
. It can be ,"""text/plain""",NA
", ","""application/xml""",NA
", or ","""application/json""",NA
 for example.,@Consumes,NA
Defines which MIME type is consumed by this method.,NA,NA
Used to extract (inject) values from the URL into a method ,NA,NA
"parameter. This way you inject, for example, the ID of a ",NA,NA
resource into the method to get the correct object.,@QueryParam,NA
Used to extract (inject) the URI query parameter coming with ,NA,NA
the request. The ,NA,NA
Uniform Resource Identifier,NA,NA
 (,NA,NA
URI,NA,NA
) is a string ,NA,NA
of characters used to identify a name or a resource on the ,NA,NA
Internet.,@DefaultValue,NA
Specifies a default value. Useful  for optional parameters.,@CookieParam,NA
Annotation that allows you to inject cookies sent by a client ,NA,NA
request into your JAX-RS resource methods.,@Provider,NA
The ,@Provider,NA
 annotation is used for anything that is of interest ,NA,NA
"to the JAX-RS runtime, such as ",MessageBodyReader,NA
 and ,MessageBodyWriter,NA
. For ,HTTP,NA
" requests, ",MessageBodyReader,NA
 is used to ,NA,NA
map an ,HTTP,NA
 request entity body to method parameters. On the ,NA,NA
"response side, a return value is mapped to an ",HTTP,NA
 response ,NA,NA
entity body by using ,MessageBodyWriter,NA
. If the application needs ,NA,NA
"to supply additional metadata, such as ",HTTP,NA
 headers or a ,NA,NA
"different status code, a method can return a response that wraps ",NA,NA
the entity and that can be built using ,Response.ResponseBuilder,NA
.,@ApplicationPath,NA
The ,@ApplicationPath,NA
 annotation is used to define the URL ,NA,NA
mapping for the application. The path specified by ,@ApplicationPath,NA
 is the base URI for all resource URIs specified ,NA,NA
by ,@Path,NA
 annotations in the ,resource,NA
 class. You may only apply ,@ApplicationPath,NA
 to a subclass of ,javax.ws.rs.core.Application,NA
.,NA,NA
The annotation names might not be clear or self-explanatory at first glance. Let's,NA,NA
"look at the sample REST endpoint implementation, and it will become a lot clearer.",NA,NA
The application itself is marked with the ,@ApplicationPath,NA
" annotation. By default, ",NA,NA
"during start-up of the JEE compliant server, JAX-RS will scan all the resources in a ",NA,NA
Java application archive to find the exposed endpoints. We can override the ,getClasses(),NA
 method to manually register the ,resource,NA
 classes in the application with ,NA,NA
the JAX-RS runtime. You can see it in the following example:,"package pl.finsys.jaxrs_example 
  
 @ApplicationPath(""/myApp"") 
  
 public class MyApplication extends Application { 
  
  
 @Override 
  
  
  public Set<Class<?>> getClasses() { 
  
  
  
  final Set<Class<?>> classes = new HashSet<>(); 
  
  
  classes.add(MyBeansExposure.class); 
  
  
  
  return classes; 
  
  
  } 
  
 }",NA
"In the previous example, we just register a REST application, giving it the ",/myApp,NA
base URI path. There is only one ,REST,NA
" method handler (endpoint), the ",MyBeansExposure,NA
"class, which we register within the REST application. The simplified REST ",NA,NA
"endpoint, implemented in the separate Java class can look same as this:","package pl.finsys.jaxrs_example 
  
 import javax.annotation.PostConstruct; 
  
 import javax.enterprise.context.ApplicationScoped; 
 import javax.ws.rs.DELETE; 
  
 import javax.ws.rs.GET; 
  
 import javax.ws.rs.POST; 
  
 import javax.ws.rs.Path; 
  
 import javax.ws.rs.PathParam; 
  
 import javax.ws.rs.container.ResourceContext; 
 import javax.ws.rs.core.Context; 
  
 import javax.ws.rs.core.Response; 
  
 @ApplicationScoped 
  
 @Path(""beans"") 
  
 public class MyBeansExposure { 
  
  
  @Context ResourceContext rc; 
  
  
  private Map<String, Bean> myBeans; 
  
  @GET 
  
  @Produces(""application/json"") 
  
  public Collection<Bean> allBeans() { 
  
  
  return Response.status(200).entity(myBeans.values()).build();  
 } 
  
  @GET 
  
  @Produces(""application/json"") 
  
  @Path(""{id}"") 
  
  public Bean singleBean(@PathParam(""id"") String id) { 
  
  
  return Response.status(200).entity(myBeans.get(id)).build();  
 } 
  
  @POST",NA
"As you can see in the previous example, we have class-level ",@Path,NA
 annotation. Every ,NA,NA
method marked with ,@GET,NA
", ",@PUT,NA
", ",@DELETE,NA
", or ",@POST,NA
 annotations will respond to a call to ,NA,NA
the URI starting with the base ,@Path,NA
". Additionally, we can use the ",@Path,NA
 annotation on ,NA,NA
"a method level; it will, kind of, extend the URI path that the specific method ",NA,NA
"responds to. In our example, the ",HTTP GET,NA
 executed with a URI path ,myApp/beans,NA
 will ,NA,NA
call the ,allBeans(),NA
" method, returning the collection of beans in JSON format. The ",GET,NA
method executed using the ,myApp/beans/12,NA
 URI path will call the ,singleBean(),NA
" method, ",NA,NA
and the ,{id},NA
 parameter will be transferred to the method because of the ,@PathParam,NA
annotation. Calling the ,HTTP DELETE,NA
 method on the ,myApp|beans|12,NA
 URI will execute the ,remove(),NA
 method with an ,id,NA
 parameter value ,12,NA
". To give you almost infinite flexibility, ",NA,NA
the ,@Path,NA
 annotation supports regular expressions. Consider the following example:,"package pl.finsys.jaxrs_example 
  
 import javax.ws.rs.GET; 
  
 import javax.ws.rs.Path; 
  
 import javax.ws.rs.PathParam; 
  
 import javax.ws.rs.core.Response; 
  
 @Stateless 
  
 @Path(""/books"") 
  
 public class BookResource { 
  
  @GET 
  
  @Path(""{title : [a-zA-Z][a-zA-Z_0-9]}"") 
  
  public Response getBookByTitle(@PathParam(""title"") String title) { 
  
   
  return Response.status(200).entity(""getBookByTitle is called, title : "" + title).build( 
 } 
  
  
  @GET 
  
  
  @Path(""{isbn : \\d+}"") 
  
  
  public Response getBookByISBN(@PathParam(""isbn"") String isbn) { 
  
  
  
  return Response.status(200).entity(""getBookByISBN is called, isbn : "" + isbn).build(); 
  
  } 
  
 }",NA
"In the previous example, we have two ",@GET,NA
" mappings, each with the same ",/books/,NA
"path mapped. The first one, with the ",/{title : [a-zA-Z][a-zA-Z_0-9]},NA
" parameter, will ",NA,NA
"react only to letters and numbers. The second one, with the ",/{isbn : \\d+},NA
" parameter, ",NA,NA
"will be executed only if you provide a number when calling the URI. As you can see, ",NA,NA
"we have mapped two identical paths, but each one will react to a different type of ",NA,NA
incoming path parameter.,NA,NA
Apart from using ,@PathParam,NA
", we can also use ",@QueryParams,NA
 to supply parameters using ,NA,NA
the request parameters. Take a look at the following example:,"package pl.finsys.jaxrs_example 
  
 import java.util.List; 
  
 import javax.ws.rs.GET; 
  
 import javax.ws.rs.Path; 
  
 import javax.ws.rs.core.Context; 
  
 import javax.ws.rs.core.Response; 
  
 import javax.ws.rs.core.UriInfo; 
  
 @Stateless 
  
 @Path(""/users"") 
  
 public class UserResource { 
  
  
  @EJB private UserService userService; 
  
  
  @GET 
  
  
  @Path(""/query"") 
  
  
  @Produces(""application/json"") 
  
  
  public Response getUsers( 
  
  
  
  @QueryParam(""from"") int from, 
  
  
  
  @QueryParam(""to"") int to, 
  
  
  
  @QueryParam(""orderBy"") List<String> orderBy)) { 
  
  
  
  List<User> users = userService.getUsers(from, to, orderBy); 
  
  
  return Response.status(200).entity(users).build(); 
  
  
  } 
  
 }",NA
"In the previous example, when calling ",HTTP GET,NA
 on the ,"/users/query?
  
 from=1&to=100&orderBy=name",NA
 JAX-RS will pass the URI parameters into the ,getUsers(),NA
method parameter and call the injected ,userService,NA
" to get the data (for example, from ",NA,NA
a database).,NA,NA
"To package the JAX-RS application, we will need a Maven ",pom.xml,NA
" file, of course. In ",NA,NA
"its simplest form, it can look the same as the following:","<?xml version=""1.0"" encoding=""UTF-8""?> 
  
 <project xmlns=""http://maven.apache.org/POM/4.0.0"" 
  
  
  
  xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" 
  
  
  
  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/ma
  
  <modelVersion>4.0.0</modelVersion> 
  
  <groupId>pl.finsys</groupId> 
  
  <artifactId>jee7-rest</artifactId> 
  
  <packaging>war</packaging> 
  
  <version>1.0-SNAPSHOT</version> 
  
  <dependencies>",NA
"Creating JEE7 REST services is quite straightforward, isn't it? By building the ",NA,NA
"project and deploying it to a JEE compliant application server, we have a couple of ",NA,NA
endpoints ready and waiting to be called over ,HTTP,NA
. But there's an even more simple ,NA,NA
"and faster approach. In the era of microservices, we would want to create individual ",NA,NA
"components faster with a minimal overhead, after all. Here comes Spring Boot. Let's ",NA,NA
look at it now.,NA,NA
Spring Boot,NA,NA
Spring itself is a very popular Java-based framework for building web and enterprise ,NA,NA
"applications. It's not only the Spring Core, which focuses on dependency injection. ",NA,NA
Spring Framework provides a lot of features that can make a developer's life easier ,NA,NA
out of the box and allows you to deliver needed features faster. The list is long; here ,NA,NA
are just a few examples:,NA,NA
Spring data,NA,NA
: Simplifies data access from relational and NoSQL data stores,NA,NA
Spring batch,NA,NA
: Provides a powerful batch processing framework,NA,NA
Spring security,NA,NA
: Provides numerous ways to secure applications,NA,NA
Spring social,NA,NA
: Supports integration with social networking sites such as ,NA,NA
"Twitter, Facebook, GitHub, and so on",NA,NA
Spring integration,NA,NA
: An implementation of enterprise integration patterns to ,NA,NA
facilitate integration with other enterprise applications using lightweight ,NA,NA
messaging and declarative adapters,NA,NA
But why did Spring become so popular? There are several reasons for that:,NA,NA
"It uses the dependency injection approach, which encourages writing ",NA,NA
"testable, ",NA,NA
loosely coupled code,NA,NA
It's easy to include database transaction management capabilities,NA,NA
"The integration with other popular Java frameworks such as JPA/Hibernate, for ",NA,NA
example,NA,NA
It includes a state of the art MVC framework for building web applications ,NA,NA
"faster, separating the view from the business logic",NA,NA
Configuring beans in the Spring framework can be done in multiple ways such as the ,NA,NA
"XML definition file, Java annotations, and code configuration. This can be a tedious ",NA,NA
"process. Also, we often do a lot of boilerplate configuration all the time, for different ",NA,NA
applications. Spring Boot was born to address the complexity of configuration. We ,NA,NA
"can use Spring Boot for our own purposes, and develop small, independent services ",NA,NA
"that can just be run. It can be a single runnable fat JAR file, with all the Java ",NA,NA
dependencies needed to run your application. There's no need for an application ,NA,NA
"server or the complicated deployment descriptor configuration. In fact, behind the ",NA,NA
"scenes, Spring Boot will boot up an embedded server for you. Of course, you are not ",NA,NA
forced to use the embedded application server. You can always build a WAR file to ,NA,NA
"deploy it on your own Tomcat or Wildfly, for example. It's worth knowing, that even",NA,NA
though most things will happen automatically when running a Spring ,NA,NA
"Boot application, it's not a code generation framework.",NA,NA
Does all of this remind you about the simplicity and portability of Docker ,NA,NA
"containers? Sure it does, but on the application level. As we discussed in ",NA,NA
Chapter 3,NA,NA
", ",NA,NA
Working with Microservices,NA,NA
", we are moving towards architectures with smaller, ",NA,NA
independently deployable microservices. This means we will need to be able to ,NA,NA
quickly get off the ground and get running with new components. We get a lot of ,NA,NA
features out of the box when using Spring Boot. These features are delivered in the ,NA,NA
"form of Maven artifacts, which you can just include in your Maven ",pom.xml,NA
 file.,NA,NA
The following table shows some of the important starter projects provided by Spring ,NA,NA
Boot we will be using:,NA,NA
Project,NA,NA
Description,"spring-boot-
 starter",NA
Base starter for Spring Boot applications. Provides support for ,NA,NA
auto-configuration and logging.,"spring-boot-
 starter-web",NA
Starter project for building Spring MVC based web applications ,NA,NA
or RESTful applications. This uses Tomcat as the default ,NA,NA
embedded servlet container.,"spring-boot-
 starter-
  
 data-jpa",NA
Provides support for Spring Data JPA. Default implementation is ,NA,NA
Hibernate.,"spring-boot-
 starter-
  
 validation",NA
Provides support for Java Bean Validation API. Default ,NA,NA
implementation is Hibernate Validator.,"spring-boot-
 starter-test",NA
"Provides support for various unit testing frameworks, such as JUnit, ",NA,NA
"Mockito, and Hamcrest matchers",NA,NA
"There are a lot more projects, which can be useful for you. We are not going to use ",NA,NA
"them, but let's look at what else is available:","spring-
  
 boot-
  
 starter-
 web-
  
 services",NA
Starter project for developing XML based web services,"spring-
  
 boot-
  
 starter-
 activemq",NA
Supports message based communication using JMS on ActiveMQ,"spring-
  
 boot-
  
 starter-
  
 integration",NA
"Supports Spring Integration, framework that provides ",NA,NA
implementations for Enterprise Integration Patterns,"spring-
  
 boot-
  
 starter-
 jdbc",NA
Provides support for using Spring JDBC. Configures a Tomcat ,NA,NA
JDBC connection pool by default.,"spring-
  
 boot-
  
 starter-
 hateoas",NA
HATEOAS stands for Hypermedia as the Engine of Application ,NA,NA
State. RESTful services that use ,HATEOAS,NA
 return links to additional ,NA,NA
resources that are related to the current context in addition to data.,"spring-
  
 boot-
  
 starter-
 jersey",NA
JAX-RS is the Java EE standard for developing REST APIs. Jersey ,NA,NA
is the default implementation. This starter project provides support ,NA,NA
for building JAX-RS based REST APIs.,"spring-
  
 boot-
  
 starter-
  
 websocket
  
 HTTP",NA
 is stateless. Web sockets allow maintaining connection between ,NA,NA
server and browser. This starter project provides support for Spring ,NA,NA
WebSockets. ,NA,NA
Provides support for Aspect oriented programming. Also provides ,NA,NA
support for AspectJ for advanced Aspect oriented programming.,"spring-
  
 boot-
  
 starter-
 amqp",NA
With default as ,RabbitMQ,NA
", this starter project provides message ",NA,NA
passing with AMQP.,"spring-
  
 boot-
  
 starter-
 security",NA
This starter project enables auto-configuration for Spring Security.,"spring-
  
 boot-
  
 starter-
 batch",NA
Provides support for developing batch applications using Spring ,NA,NA
Batch.,"spring-
  
 boot-
  
 starter-
 cache",NA
Basic support for caching using Spring Framework.,"spring-
  
 boot-
  
 starter-
  
 data-rest",NA
Support for exposing REST services using Spring Data REST.,NA,NA
Let's use some of these goodies to code our own Spring Boot microservice.,NA,NA
Coding the Spring Boot microservice,NA,NA
"We know that we have some starters available, so let's make use of them to save ",NA,NA
some time. The service that we are going to create will be the simple REST ,NA,NA
"microservice for storing and retrieving entities from a database: books, in our case. ",NA,NA
"We are not going to implement authentication and security features, just to make it ",NA,NA
as clean and simple as possible. Books will be stored in an in-memory relational H2 ,NA,NA
"database. We are going to build and run our bookstore with Maven, so let's begin ",NA,NA
with the ,pom.xml,NA
 build file.,NA,NA
Maven build file,NA,NA
"As you will see, the parent project for our own service is spring-boot-starter-parent. ",NA,NA
Spring this is the parent project providing dependency and plugin management for ,NA,NA
Spring Boot-based applications. This gives us a lot of features to start with. We also ,NA,NA
include two starters:,spring-boot-starter-web,NA
: This is because we are going to create our request ,NA,NA
mappings (similar to ,@GET,NA
 or ,@POST,NA
 mappings with the ,@Path,NA
 annotation we did ,NA,NA
previously using JEE7 JAX-RS,spring-boot-starter-data-jpa,NA
: Because we are going to save our books in the in-,NA,NA
memory H2 database,NA,NA
Starters are simplified dependency descriptors customized for different purposes. For ,NA,NA
"example, ",spring-boot-starter-web,NA
" is the starter for building web and RESTful, ",NA,NA
applications using Spring MVC. It uses Tomcat as the default embedded container.,NA,NA
"We also include the Spring Boot Maven plugin, which allows us to run the ",NA,NA
"applications in place without building a JAR or a WAR, or preparing a JAR or WAR ",NA,NA
file for future deployment. Our complete ,pom.xml,NA
 should look the same as this:,"<?xml version=""1.0"" encoding=""UTF-8""?> 
  
 <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchem
  
  
  xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/ma
  
  <modelVersion>4.0.0</modelVersion> 
  
  <groupId>pl.finsys</groupId> 
  
  <artifactId>rest-example</artifactId> 
  
  <version>0.1.0</version> 
  
  <parent> 
  
  
  <groupId>org.springframework.boot</groupId> 
  
  
 <artifactId>spring-boot-starter-
  
  
  
  parent</artifactId> 
  
  
  <version>1.5.2.RELEASE</version> 
  
  </parent> 
  
  <dependencies> 
  
  
  <dependency> 
  
  
  
  <groupId>org.springframework.boot</groupId> 
  
  
  <artifactId>spring-boot-starter-
  
  
  
   
  web</artifactId> 
  
  
  </dependency> 
  
  
  <dependency> 
  
  
  
  <groupId>org.springframework.boot</groupId> 
  
  
  <artifactId>spring-boot-starter-data-
  
  
  
  jpa</artifactId> 
  
  
  </dependency>",NA
"First, in the ",pom.xml,NA
" file, we define the parent Maven artifact. As our application is the ",NA,NA
"Spring Boot application, we inherit our ",pom.xml,NA
 from the ,spring-boot-starter-parent,NA
"artifact. This gives us all the Spring Boot goodies out of the box, such as the startup ",NA,NA
"mechanism, dependency injection, and so on. By adding ",spring-boot-starter-data-jpa,NA
"as a dependency, we will be able to use all the database-related features, such as ",NA,NA
"JDBC transaction management, JPA annotations for the entity classes, and so on.",NA,NA
Having the ,pom.xml,NA
" ready, let's continue and define the entry point for our",NA,NA
microservice.,NA,NA
Application entry point,NA,NA
Our application entry point will be named ,BookStoreApplication,NA
 and will be ,BookstoreApplication.java,NA
:,"package pl.finsys.example; 
  
 import org.springframework.boot.SpringApplication; 
  
 import org.springframework.boot.autoconfigure.SpringBootApplication; 
  
 @SpringBootApplication 
  
 public class BookstoreApplication { 
  
  
  public static void main(final String[] args) { 
  
  
  
  SpringApplication.run(BookstoreApplication.class, args); 
  
  } 
  
 }",NA
"That's it. The whole nine lines of code, not counting blank lines. It could not be more ",NA,NA
concise. The ,@SpringBootApplication,NA
" is a kind of shortcut annotation, which is very ",NA,NA
convenient. It replaces all of the following annotations:,@Configuration,NA
: A class marked with this annotation becomes a source of bean ,NA,NA
definitions for the application context,@EnableAutoConfiguration,NA
: This annotation makes Spring Boot add beans based on ,NA,NA
"classpath settings, other beans, and various property settings",@EnableWebMvc,NA
: Normally you would add ,this one,NA
" for a Spring MVC application, ",NA,NA
but Spring Boot adds it automatically when it sees ,spring-webmvc,NA
 on the ,NA,NA
"classpath. This marks the application as a web application, which in turn will ",NA,NA
activate key behaviors such as setting up a ,"DispatcherServlet
  
  
 @ComponentScan",NA
": Tells Spring to look for other components, configurations, and ",NA,NA
"services, allowing it to find the controllers",NA,NA
So far so good. We need some models for our service. We are going to save some ,NA,NA
entities in the database; this is where the ,spring-boot-starter-data-jpa,NA
 starter will ,NA,NA
come in handy. We will be able to use JPA (implemented with Hibernate) and ,javax.transaction-api,NA
 without even declaring it explicitly. We need an entity model ,NA,NA
for our bookstore.,NA,NA
Domain model and a repository,NA,NA
A domain model in our service will be a ,Book,NA
" class, defined in the ",Book.java,NA
 file:,"package pl.finsys.example.domain; 
  
 import javax.persistence.Column; 
  
 import javax.persistence.Entity; 
  
 import javax.persistence.Id; 
  
 import javax.validation.constraints.NotNull; 
 import javax.validation.constraints.Size; 
  
 @Entity 
  
 public class Book { 
  
  @Id 
  
  @NotNull 
  
  @Column(name = ""id"", nullable = false, updatable = false)  
 private Long id; 
  
  @NotNull 
  
  @Size(max = 64) 
  
  @Column(name = ""author"", nullable = false)  
 private String author; 
  
  @NotNull 
  
  @Size(max = 64) 
  
  @Column(name = ""title"", nullable = false)  
 private String title; 
  
  public Book() { 
  
  } 
  
  public Book(final Long id, final String author, final String title) { 
  
  this.id = id; 
  
  
  this.title = title; 
  
  
  this.author = author; 
  
  } 
  
  public Long getId() { 
  
  
  return id; 
  
  } 
  
  public String getAuthor() { 
  
  
  return author; 
  
  } 
  
  public String getTitle() { 
  
  
  return title; 
  
  } 
  
  public void setTitle(String title) { 
  
  
  this.title = title; 
  
  }",NA
"As you can see on the previous listing, the ",Book,NA
 class is a simple POJO with some ,NA,NA
"annotations, properties, and getters and setters. The ",@Entity,NA
 annotations come from ,NA,NA
the ,javax.persistence,NA
" package and marks the POJO as a database entity, to enable ",NA,NA
JPA to store or retrieve it from the H2 database. ,@Column,NA
 annotations specify the ,NA,NA
names of database columns where the corresponding book properties will be stored. ,NA,NA
The ,@NotNull,NA
 and ,@Size,NA
 annotations will make sure that our entity has proper values ,NA,NA
"filled in, before it goes into the database.",NA,NA
We have our entity defined; it's now time to have a mechanism to read and store it in ,NA,NA
the database. We will use Spring's ,JpaRepository,NA
 for this purpose. The name of our ,NA,NA
repository will be ,BookRepository,NA
 in the ,BookRepository.java,NA
 file:,"package pl.finsys.example.repository; 
  
 import pl.finsys.example.domain.Book; 
  
 import org.springframework.data.jpa.repository.JpaRepository; 
  
 public interface BookRepository extends JpaRepository<Book, Long> { 
 }",NA
The Spring Data JPA provides a repository programming model that starts with an ,NA,NA
interface per managed domain object. Defining this interface serves two purposes.,NA,NA
"First, by extending the ",JPARepository,NA
" interfaces, we get a bunch of generic CRUD ",NA,NA
"methods into our type that allows saving our entities, deleting them, and so on. For ",NA,NA
"example, the following methods are available (declared in the ",JPARepository,NA
 interfaces ,NA,NA
we are extending):,"List<T> findAll();
  
  
 List<T> findAll(Sort sort);
  
  
 List<T> findAll(Iterable<ID> ids);
  
  
 <S extends T> List<S> save(Iterable<S> entities);
  
  
 T getOne(ID id);
  
  
 <S extends T> S save(S entity);
  
  
 <S extends T> Iterable<S> save(Iterable<S> entities);
  
  
 T findOne(ID id);
  
  
 boolean exists(ID id);",NA
"No SQL coding, no JPA-QL queries, nothing. Simply by extending the Spring ",JPARepository,NA
" interface, all those methods are at our disposal. Of course, we are not ",NA,NA
"limited to those. We can declare our own methods in our interface, ",NA,NA
as ,findByTitle(String title),NA
", for example. It will be picked up by Spring at runtime ",NA,NA
and will find us a book by its title. I highly recommend reading the Spring Data ,NA,NA
project documentation and experimenting further; it's very convenient to use. Using ,NA,NA
the ,entity,NA
" repository straight from the controller is usually not very good practice, so ",NA,NA
it's time to have a book service. It will be a ,BookService,NA
" interface, defined in the ",BookService.java,NA
:,"package pl.finsys.example.service; 
  
 import pl.finsys.example.domain.Book; 
  
 import javax.validation.Valid; 
  
 import javax.validation.constraints.NotNull; 
 import java.util.List; 
  
 public interface BookService { 
  
  
  Book saveBook(@NotNull @Valid final Book book); 
  
  
 List<Book> getList(); 
  
  
  Book getBook(Long bookId); 
  
  
  void deleteBook(final Long bookId); 
  
 }",NA
"The implementation, in the ",BookServiceImpl.java,NA
", can look the same as following:","package pl.finsys.example.service; 
  
 import org.springframework.beans.factory.annotation.Autowired; 
  
 import pl.finsys.example.domain.Book; 
  
 import pl.finsys.example.repository.BookRepository; 
  
 import pl.finsys.example.service.exception.BookAlreadyExistsException; 
 import org.slf4j.Logger; 
  
 import org.slf4j.LoggerFactory; 
  
 import org.springframework.stereotype.Service; 
  
 import org.springframework.transaction.annotation.Transactional; import 
 org.springframework.validation.annotation.Validated; 
  
 import javax.validation.Valid; 
  
 import javax.validation.constraints.NotNull; 
 import java.util.List; 
  
 @Service",NA
The previous listing presents the ,BookService,NA
 implementation. Note that we have ,NA,NA
injected the ,BookRepository,NA
" in the constructor. All the implementation methods, such ",NA,NA
as ,saveBook(),NA
", ",getBook(),NA
", ",deleteBook(),NA
", and ",getList(),NA
 will use the injected ,BookRepository,NA
"to operate on the book entities in the database. It's time for the last class, the actual ",NA,NA
controller that will wire all the previous classes together.,NA,NA
REST controller,NA,NA
The REST controller defines URI paths that the service is going to respond to. It ,NA,NA
declares paths and corresponding ,HTTP,NA
 methods that each controller method should ,NA,NA
react to. We define all of these using annotations. This approach is very similar to ,NA,NA
"JAX-RS with Jersey. Our service has just one, single ",book,NA
" resource, so we will have ",NA,NA
just a single controller for starters. It will be ,BookController,NA
" class, defined in the ",BookController.java,NA
:,"package pl.finsys.example.controller; 
  
 import org.springframework.beans.factory.annotation.Autowired; 
  
 import pl.finsys.example.domain.Book; 
  
 import pl.finsys.example.service.BookService; 
  
 import pl.finsys.example.service.exception.BookAlreadyExistsException; 
 import org.slf4j.Logger; 
  
 import org.slf4j.LoggerFactory; 
  
 import org.springframework.http.HttpStatus; 
  
 import org.springframework.web.bind.annotation.*; 
  
 import javax.validation.Valid; 
  
 import java.util.List; 
  
 @RestController 
  
 public class BookController { 
  
  
  private static final Logger LOGGER =     LoggerFactory.getLogger(BookController.class); 
 private final BookService bookService; 
  
  @Autowired 
  
  public BookController(final BookService bookService) { 
  
  this.bookService = bookService; 
  
  } 
  
 @RequestMapping(value = ""/books"", method = RequestMethod.POST, consumes={""application/json""})
  
  public Book saveBook(@RequestBody @Valid final Book book) { 
  
  
  
  LOGGER.debug(""Received request to create the {}"", book); 
  
  
  
  return bookService.saveBook(book); 
  
  
  } 
  
 @RequestMapping(value = ""/books"", method = RequestMethod.GET, produces={""application/json""}) 
  
  public List<Book> listBooks() {             
  
  
  
  LOGGER.debug(""Received request to list all books""); 
  
  
  
  return bookService.getList(); 
  
  
  } 
  
 @RequestMapping(value = ""/books/{id}"", method = RequestMethod.GET, produces={""application/jso
  
  public Book singleBook(@PathVariable Long id) { 
  
  
  
  LOGGER.debug(""Received request to list a specific book""); 
  
  
  
  return bookService.getBook(id); 
  
  
  } 
  
 @RequestMapping(value = ""/books/{id}"", method = RequestMethod.DELETE)",NA
"As you can see in the previous example, the class is annotated with the ",@RestController,NA
" annotation. This is what makes it a controller, actually. In fact, it's a ",NA,NA
convenient annotation that is itself annotated with ,@Controller,NA
 and ,@ResponseBody,NA
annotations. ,@Controller,NA
 indicates that an annotated class is a controller (a web ,NA,NA
"controller), also allowing for implementation classes to be autodetected through ",NA,NA
Spring's classpath scanning. Every method in a controller that should respond to a ,NA,NA
call to a specific URI is mapped with the ,@RequestMapping,NA
 annotation. ,@RequestMapping,NA
"takes parameters, the most important ones are:",value,NA
 : It will specify the URI path,method,NA
 : Specifyies the ,HTTP,NA
 method to handle,headers,NA
" : The headers of the mapped request, in a format ",myHeader=myValue,NA
. A ,NA,NA
"request will be handled by the method using the headers parameter, only if the ",NA,NA
incoming request header is found to have the given value,consumes,NA
" : Specifies the media types the mapped request can consume, such ",NA,NA
as ,"""text/plain""",NA
 or ,"""application/json""",NA
". This can be a list of media types, for ",NA,NA
example: ,"{""text/plain"", ""application/json""}
  
  
 produces",NA
" : Specifies the media types the mapped request can produce, such ",NA,NA
as ,"""text/plain""",NA
 or ,"""application/json""",NA
". This again can be a list of media types, for ",NA,NA
example: ,"{""text/plain"", ""application/json""}
  
 Similar to JAX-RS@PathParam",NA
 and ,@QueryParam,NA
 to specify the controller method's input ,NA,NA
parameters,",",NA
 now we have ,@PathVariable,NA
 and ,@RequestParam,NA
 in Spring. If you need to ,NA,NA
have your method parameter come in the request body (as a whole JSON object that ,NA,NA
"you want to save, the same as in our ",saveBook(),NA
" method), you will need to map the ",NA,NA
parameter using the ,@RequestBody,NA
" annotation. As for the output, the ",@ResponseBody,NA
annotation can tell our controller that the method return value should be bound to the ,NA,NA
web response body.,NA,NA
"In a real-world service, you will probably have a lot of controllers with a lot of paths ",NA,NA
"mapped. When exposing such a service to the world, it's usually a good practice to ",NA,NA
document the API of the service. This API documentation is the service contract. ,NA,NA
"Doing this manually could be a tedious process. Also, if you make changes, it's good",NA,NA
"to have the API documentation in sync. There is a tool that can make it a lot easier, ",NA,NA
Swagger.,NA,NA
Documenting the API,NA,NA
"Before a client can consume a service, it would need a service contract. A service ",NA,NA
"contract defines all the details about a service; for example, how the service can be ",NA,NA
"called, the URI of the service, and what the request and response formats are. Your ",NA,NA
clients will need to know how to interact with your API. Swagger is gaining a lot of ,NA,NA
ground with support from major vendors in the last couple of years. Swagger's ,NA,NA
specification presents all the details of your service resources and operations in a ,NA,NA
JSON format. The format of the specification is known as the OpenAPI specification ,NA,NA
(Swagger RESTful API documentation specification). It's human and machine ,NA,NA
"readable, easy for parsing, transferring, and using in integration. The ",SpringFox,NA
 library ,NA,NA
can be used to generate Swagger documentation from the RESTful services code.,NA,NA
"What's more, there is a wonderful tool called Swagger UI, which when integrated ",NA,NA
"into the application, provides human readable documentation. In this section, we will ",NA,NA
generate Swagger documentation for our services. The ,SpringFox,NA
" library, available on ",NA,NA
GitHub at ,NA,NA
http://springfox.github.io/springfox/,NA,NA
" and in the Maven central, is a tool to ",NA,NA
automatically build JSON API documentation for APIs built with Spring. Even ,NA,NA
"better, the library provides the Swagger UI tool. The tool will be deployed together ",NA,NA
"with your service and can be used, browse the generated API documentation in a ",NA,NA
very convenient way. Let's introduce Swagger to our service. We begin with adding ,NA,NA
the needed dependencies to our service ,pom.xml,NA
 file:,"<dependency> 
  
  
  <groupId>io.springfox</groupId> 
  
  
  <artifactId>springfox-swagger2</artifactId> 
  
  <version>2.6.1</version> 
  
 </dependency> 
  
 <dependency> 
  
  
  <groupId>io.springfox</groupId> 
  
  
  <artifactId>springfox-swagger-ui</artifactId> 
  
  <version>2.5.0</version> 
  
 </dependency>",NA
"Having the library available in a classpath of our application, we need to turn it on. ",NA,NA
The next step will be then be adding the configuration class to enable and generate ,NA,NA
the Swagger documentation. We do it by creating a class annotated with the Spring ,@Configuration,NA
" annotation, the same as in the following example:","package pl.finsys.example.configuration; 
  
 import org.springframework.context.annotation.Bean; 
  
 import org.springframework.context.annotation.Configuration;",NA
A couple of words of explanation here. ,@Configuration,NA
 means that the annotated class ,NA,NA
"is defining a Spring configuration, ",@EnableSwagger2,NA
 turns off the Swagger support. The ,Docket,NA
" is a builder class to configure the generation of Swagger documentation, ",NA,NA
configured with ,DocumentationType.SWAGGER_2,NA
 to generate Swagger 2 compatible API ,NA,NA
documentation. The ,select(),NA
 method called on the ,Docket,NA
 bean instance returns an ,ApiSelectorBuilder,NA
", which provides the ",apis(),NA
 and ,paths(),NA
 methods to filter the ,NA,NA
"controllers and methods being documented using string predicates. In our example, ",NA,NA
we want all controllers and all mapped paths to be documented; that's why we use ,.apis(RequestHandlerSelectors.any()).paths(PathSelectors.any()),NA
You could also use the ,regex,NA
 parameter passed to ,paths(),NA
 to provide an additional ,NA,NA
filter to generate documentation only for the path matching the regex expression.,NA,NA
That's it; it's the simplest form of generating a documentation for your API. If you ,NA,NA
"now run the service (we are going to do this in a short while), two endpoints will be ",NA,NA
available:,"http://localhost:8080/v2/api-docs
  
  
 http://localhost:8080/swagger-ui.html",NA
"The first one contains the Swagger 2 compatible documentation, in a JSON format, ",NA,NA
as you can see in the following screenshot:,NA,NA
"To browse the API documentation in a lot more useful form, point your browser to ",NA,NA
the second URL. You will be presented with the Swagger UI tool interface:,NA,NA
"The Swagger UI is a collection of HTML, JavaScript, and CSS assets that ",NA,NA
dynamically generate beautiful documentation from a Swagger-compliant API. It ,NA,NA
"lists your service operations, and its request and response formats. Best of all, you ",NA,NA
"can test your service using this tool, by executing specific requests. In fact, it's a great ",NA,NA
tool to quickly test your service. Our documentation is not very descriptive. Of ,NA,NA
"course, we have a listing of our exposed endpoints with their input and output ",NA,NA
description. It would be nice if we could enhance the documentation with some more ,NA,NA
"specific details. We CAN do it, there are Java annotations we can use in the service's ",NA,NA
code to enhance the generated documentation. The annotations come from the ,NA,NA
"Swagger-annotation package, which will be available if you use the ",springfox-swagger2,NA
 ,NA,NA
"library in your project. For example, consider the following code snippet:",NA,NA
"In the previous code, we use the ",@ApiOperation,NA
 annotation to provide a more detailed ,NA,NA
description of what the operation does. There's a lot more: ,@ApiImplicitParam,NA
 for ,NA,NA
"describing parameters, ",@Authorization,NA
 to provide a name of the authorization scheme ,NA,NA
"to be used on this resource/operation, ",@License,NA
 to provide information about the ,NA,NA
"license, and so on. All of those annotations will be picked up by ",springfox-swagger2,NA
and used to enhance the generated documentation. I highly recommend looking at ,NA,NA
the swagger-annotations JavaDoc; you will be able to document your API in a ,NA,NA
"detailed, professional way.",NA,NA
I guess our little service is ready; it's time to bring it to life.,NA,NA
Running the application,NA,NA
Because we have defined the Spring Boot plugin in our ,pom.xml,NA
" build file, we can ",NA,NA
now start the application using Maven. All you need to have is Maven present on the ,NA,NA
"system path, but you probably have this already as a Java developer. To run the ",NA,NA
"application, execute the following from the command shell (terminal on MacOS or ",cmd.exe,NA
 on Windows):,$ mvn spring-boot:run,NA
"After a while, the Spring splash log will show up in the console and your ",NA,NA
microservice will be ready to accept ,HTTP,NA
" requests. Soon, in ",NA,NA
Chapter 5,NA,NA
", ",NA,NA
Creating ,NA,NA
Images with Java Applications,NA,NA
", our goal will be to see the same coming from the ",NA,NA
Docker container:,NA,NA
"If you want to, you can also run the application straight from the IDE, be it IntelliJ ",NA,NA
"IDEA, Eclipse, or Netbeans. Our ",BookstoreApplication,NA
 class has a ,main(),NA
 method; you ,NA,NA
will just need to create a runtime configuration in your IDE and run it. This is ,NA,NA
"different from the JEE7 JAX-RS service. It that case, you would need to deploy the ",NA,NA
service in a JEE compliant application server to be able to run it. Having the ,main(),NA
method defined is very convenient when debugging your service. Just start a ,NA,NA
debugging session with ,BookstoreApplication,NA
 as the entry point. There is no need to ,NA,NA
"create a remote debugging session. Having our service running, it's time to make ",NA,NA
some calls to its exposed endpoints.,NA,NA
Making calls,NA,NA
Making a call to the operation exposed from the service can be done using any tool ,NA,NA
or library that can execute the ,HTTP,NA
 requests. The first obvious choice would be just a ,NA,NA
web browser. But a web browser is convenient only for executing ,GET,NA
 requests (as for ,NA,NA
getting a list of books from our bookstore service). If you need to execute other ,NA,NA
methods such as ,POST,NA
 or ,PUT,NA
" or provide additional request parameters, header values, ",NA,NA
"and so on, you will need to use some alternatives. The first choice could be cURL, a ",NA,NA
command-line tool for transferring data using various protocols. Let's look at other ,NA,NA
options we have.,NA,NA
Spring RestTemplate,NA,NA
"If you need to call a service from another service, you will need a ",HTTP,NA
 client. Spring ,NA,NA
provides the very useful ,RestTemplate,NA
 class. It gives you a synchronous client-side ,HTTP,NA
" access, simplifies communication with HTTP servers, and enforces RESTful ",NA,NA
"principles. It handles HTTP connections, leaving application code to provide URLs ",NA,NA
"(with possible template variables) and extracts results. By default, ",RestTemplate,NA
 relies ,NA,NA
on standard JDK facilities to establish HTTP connections. You can switch to a ,NA,NA
"different HTTP library of your choice, such as Apache ",HttpComponents,NA
", ",Netty,NA
", and ",OkHttp,NA
 through its ,setRequestFactory(),NA
 method. Calling the ,REST,NA
 resource to get a book ,NA,NA
with ,ID = 1,NA
 can be as simple as follows:,"package pl.finsys.example.client; 
  
 import org.springframework.http.ResponseEntity; 
 import org.springframework.web.client.RestTemplate; 
 import pl.finsys.example.domain.Book; 
  
 public class ExampleClient { 
  
  
  public static void main(String[] args) { 
  
  
  
  try { 
  
  
  
  
  RestTemplate restTemplate = new RestTemplate(); 
  
  
  
  
  ResponseEntity<Book> response = restTemplate.getForEntity(""http://localhost:8080/
  
  
  
  System.out.println(response.getBody()); 
  
  
  
  } catch (Exception e) { 
  
  
  
  
  e.printStackTrace(); 
  
  
  
  } 
  
  
  } 
  
 }",NA
"Of course, this is just a simplified client example, to present you the idea. You can ",NA,NA
use ,RestTemplate,NA
 to create more sophisticated client calls to the REST resources.,NA,NA
HTTPie,NA,NA
"A great command-line alternative to cURL is HTTPie, available at ",NA,NA
https://httpie.org,NA,NA
.,NA,NA
It's a command-line ,HTTP,NA
" client. Luckily, the ",ie,NA
 in the name doesn't come from ,NA,NA
"Internet Explorer. If you prefer to work from the shell or command line, ",HTTPie,NA
 is a ,NA,NA
"just a single command which adds the following features to cUrl: sensible defaults, ",NA,NA
"expressive and intuitive command syntax, colorized and formatted terminal output, ",NA,NA
"built-in JSON support, persistent sessions, forms and file uploads, proxies and ",NA,NA
"authentication support, and support for arbitrary request data and headers. It's written ",NA,NA
"in Python and works on Linux, macOSX, and Windows.",NA,NA
Postman,NA,NA
Postman is a tool of choice for many developers. It's available as the Chrome plugin ,NA,NA
or a standalone utility at ,NA,NA
https://www.getpostman.com,NA,NA
. Postman is very convenient for ,NA,NA
"use. It's a powerful GUI platform to make your API development faster and easier, ",NA,NA
"from building API requests through testing, documentation, and sharing. You can ",NA,NA
save your ,HTTP,NA
 requests for later use and organize them in collections. If you work in ,NA,NA
"multiple environments, for example your localhost, when developing the service and ",NA,NA
"a production environment later on, Postman introduces the concept of environments. ",NA,NA
Environments give you the ability to customize your requests using variables. This ,NA,NA
way you can easily switch between different setups without changing your requests.,NA,NA
Each environment is represented as a set of key-value pairs. This makes working ,NA,NA
with multiple environments easy. It also has a very handy UI for editing your ,HTTP,NA
requests:,NA,NA
"You can define request headers, cookies, and body. If your service supports ",NA,NA
"authentication, Postman contains a lot of authentication helpers: it can be basic Auth, ",NA,NA
"digest Auth, and OAuth. The response body can be viewed in one of three views:",NA,NA
"pretty, raw, and preview. The pretty mode formats JSON or XML responses so that ",NA,NA
they are easier to look at and headers are displayed as key/value pairs in the header ,NA,NA
"tab. It's a really powerful and pleasant to use tool. If you work on macOS, there's ",NA,NA
something even better.,NA,NA
Paw for Mac,NA,NA
Paw,NA,NA
 is a full-featured ,HTTP,NA
 client that lets you test the APIs you build or consume. It ,NA,NA
"has a beautiful native OS X interface to compose requests, inspect server responses, ",NA,NA
"and generate client code out of the box. As you can see in the following screenshot, ",NA,NA
it also contains a powerful editor to compose your requests:,NA,NA
"It also supports a lot of authentication schemas including OAuth 1 and 2, Basic Auth, ",NA,NA
"Digest Auth, Hawk, AWS Signature Version 4, and Amazon S3. Similar to Postman, ",NA,NA
Paw also allows you to organize your requests in folders. You can also define and ,NA,NA
switch different environments quickly. The interesting feature is that Paw can ,NA,NA
"generate client code to execute your requests. It can generate code for cURL, ",NA,NA
"HTTPie, Objective-C, Python, JavaScript, Ruby, PHP, Java, Go, and many others.",NA,NA
And guess what? Paw can also import the Swagger documentation we have been ,NA,NA
talking about. You can use this feature to test the service you were given the ,NA,NA
documentation for.,NA,NA
"If you need to quickly start with your new service, there are a couple of tools that ",NA,NA
may come in handy. One of them is ,NA,NA
Initializr,NA,NA
.,NA,NA
Spring Initializr,NA,NA
Spring Initializr is a web-based tool available at ,NA,NA
https://start.spring.io,NA,NA
. It's a quick start ,NA,NA
generator for Spring projects. Spring Initializr can be used as follows:,NA,NA
From the web browser at ,NA,NA
https://start.spring.io,NA,NA
"In your IDE (IntelliJ IDEA Ultimate or NetBeans, using plugins)",NA,NA
From the command line with the Spring Boot CLI or simply with cURL or ,NA,NA
HTTPie,NA,NA
Using the web application is very convenient; all you need to do is provide details ,NA,NA
"about your application Maven archetype, such as group, artifact name, description, ",NA,NA
and so on:,NA,NA
"In the Dependencies section, you can enter the keywords of the features you would ",NA,NA
"like to have included, such as JPA, web, and so on. You can also switch the UI to an ",NA,NA
"advanced view, to have all the features listed and ready to be selected:",NA,NA
"As the output, Spring Initializr will create a ZIP archive with the base Maven project ",NA,NA
you want to start with. The project created by Spring Initializr is a Maven project and ,NA,NA
follows the standard ,Maven,NA
 directory layout. This really saves a lot of time when ,NA,NA
creating new Spring projects. You no longer need to search for specific Maven ,NA,NA
archetypes and look for their versions. Initializr will generate the ,pom.xml,NA
" for you, ",NA,NA
automatically. The presence of the dependencies in the ,pom.xml,NA
 is important because ,NA,NA
Spring Boot will make decisions on what to create automatically when certain things ,NA,NA
"are found on the classpath. For example, if the dependency for the H2 database is ",NA,NA
"present and exists on the classpath when the application is run, Spring Boot will ",NA,NA
automatically create a data connection and an embedded H2 database.,NA,NA
Summary,NA,NA
"As you can see, developing Java microservices is not as tricky as it may sound. You ",NA,NA
"can choose between JEE7 JAX-RS or Spring Boot, wire some classes, and a basic ",NA,NA
service is ready. You are not limited to using Spring MVC for creating your REST ,NA,NA
"endpoints. If you are more familiar with the Java EE JAX-RS specification, you can ",NA,NA
"easily integrate JAX-RS into Spring applications, especially Spring Boot ",NA,NA
applications. You can then take what is best for you from both.,NA,NA
"Of course, in the real world you would probably want to include some more ",NA,NA
advanced features such as authentication and security. Having Spring Initializr ,NA,NA
available can give you a serious speed boost when developing your own service. In ,NA,NA
C ,NA,NA
hapter 5,NA,NA
", ",NA,NA
Creating Images with Java Applications,NA,NA
", we are going to package our ",NA,NA
bookstore service into a Docker image and run it using Docker Engine.,NA,NA
Creating Images with Java,NA,NA
Applications,NA,NA
"Now that we have a simple, but functional Java microservice based on Spring ",NA,NA
"Bootstrap, we can go further. Before we deploy it using Kubernetes, let's package it ",NA,NA
"as a Docker image. In this chapter, we will create a Docker image containing our ",NA,NA
"application, and we will dockerize a Spring Boot application to run it in an isolated ",NA,NA
"environment, a container.",NA,NA
Topics covered in this chapter will be:,NA,NA
Creating a Dockerfile,NA,NA
Dockerfile instructions,NA,NA
Building the image,NA,NA
Creating and removing images,NA,NA
Let's begin with the definition of a ,Dockerfile,NA
", which will be the definition of our ",NA,NA
container.,NA,NA
Dockerfile,NA,NA
As you will remember from ,NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", the ",Dockerfile,NA
 is kind ,NA,NA
of a recipe to build an image. It's a plain text file containing instructions which are ,NA,NA
executed by Docker in the order they are placed. Each ,Dockerfile,NA
 has a base image ,NA,NA
that the Docker engine will use to build upon. A resulting image will be a specific ,NA,NA
"state of a file system: a read-only, frozen immutable snapshot of a live container, ",NA,NA
composed of layers representing changes in the filesystem at various points in time.,NA,NA
The image creation flow in Docker is pretty straightforward and consists basically of ,NA,NA
two steps:,NA,NA
"1. First, you prepare a text file named ",Dockerfile,NA
", which contains a series of ",NA,NA
instructions on how to build the image. The set of instructions you can use in ,NA,NA
the ,Dockerfile,NA
" is not very broad, but sufficient to fully instruct Docker how to ",NA,NA
create an image.,NA,NA
"2. Next, you execute the ",docker build,NA
 command to create a Docker image based on ,NA,NA
the ,Dockerfile,NA
 that you have just created. The ,docker build,NA
 command runs within ,NA,NA
"the context. The build's context is the files at a specified location, which can be ",NA,NA
a ,PATH,NA
 or a URL. The ,PATH,NA
 is a directory on your local filesystem and the URL is ,NA,NA
a Git repository location. A context is processed recursively. ,PATH,NA
 will include ,NA,NA
any subdirectories. The URL will include the repository and its submodules.,NA,NA
"If you create an image containing a Java application, you can also skip the second ",NA,NA
step and utilize one of the Docker Maven plugins available. After we learn how to ,NA,NA
build images using the ,docker build,NA
" command, we will also create our image using ",NA,NA
"Maven. When building using Maven, the context to the ",docker build,NA
 command (or a ,NA,NA
"build process, in this case) will be provided automatically by Maven itself. Actually, ",NA,NA
there is no need for the ,Dockerfile,NA
" at all, it will be created automatically during the ",NA,NA
build process. We will get to this in a short while.,NA,NA
The standard name for a ,Dockerfile,NA
 is just ,Dockerfile,NA
. It's just a plain text file.,NA,NA
"Depending on the IDE you use, there are plugins to provide Dockerfile syntax ",NA,NA
"highlighting and autocompletion, which makes editing them a breeze. Dockerfile ",NA,NA
"instructions use simple and clear syntax which makes them quite easy to understand, ",NA,NA
"create, and use. They are designed to be self-explanatory, especially because they ",NA,NA
allow commenting just as properly written application source code. Let's get to know ,NA,NA
the ,Dockerfile,NA
 instructions now.,NA,NA
Dockerfile instructions ,NA,NA
"We will begin with the instruction that every Dockerfile must have at the top, the ",FROM,NA
 instruction.,NA,NA
FROM,NA,NA
This is the first instruction in the Dockerfile. It sets the base image for every ,NA,NA
subsequent instruction coming next in the file. The syntax for the ,FROM,NA
 instruction is ,NA,NA
straightforward. It's just:,FROM <image>,NA
", or ",FROM <image>:<tag>,NA
", or ",FROM <image>@<digest>,NA
The ,FROM,NA
 instruction takes a ,tag,NA
 or ,digest,NA
" as a parameter. If you decide to skip them, ",NA,NA
Docker will assume you want to build your image from the ,latest,NA
 tag. Be aware that ,latest,NA
 will not always be the latest version of the image you want to build upon. The ,latest,NA
" tag is kind of a special one. Also, it may not work as you may expect. Well, to ",NA,NA
"cut a long story short, it doesn't mean anything special unless the image creator ",NA,NA
(,openjdk,NA
 or ,fabric8,NA
", for example) has a specific ",build,NA
", ",tag,NA
", and ",push,NA
 pattern. The ,latest,NA
tag assigned to an image simply means that it's the image that was last built and ,NA,NA
executed without a specific tag provided. It's easy to understand that it may be ,NA,NA
"confusing, pulling the image tagged ",latest,NA
 will not fetch the latest version of the ,NA,NA
software.,NA,NA
Docker will not take care of checking if you are getting the newest ,NA,NA
version of the software when pulling the image tagged ,latest,NA
.,NA,NA
Docker will throw an error during the build if it cannot find a tag or digest you ,NA,NA
provide. You should choose the base image wisely. My recommendation would be to ,NA,NA
always prefer the official repositories that can be found on Docker Hub. By choosing ,NA,NA
"an official image you can be pretty sure it will be of high quality, tested, supported, ",NA,NA
and maintained.,NA,NA
"For containerizing a Java application, we have two options. The first one is to use a ",NA,NA
base Linux image and install Java using the ,RUN,NA
 instruction (we will cover ,RUN,NA
 in a ,NA,NA
while). The second option will be to pull an image containing the Java runtime ,NA,NA
already installed. Here you have a lot more to choose from. For example:,openjdk,NA
: An official repository containing an open-source implementation of the ,NA,NA
"Java platform, Standard Edition. The tag ",latest,NA
", which will be used if you do ",NA,NA
"not specify any tag, points to the ",8u121-alpine,NA
" OpenJDK release, as of the time ",NA,NA
of writing this book,NA,NA
: This base image is actually also being used by ,NA,NA
the fabric8 Maven plugin,frolvlad/alpine-oraclejdk8,NA
: There are three tags you can choose from: full (only ,NA,NA
"src tarballs get removed), cleaned (desktop parts get cleaned), slim, everything ",NA,NA
but the compiler and JVM is removed. The tag latest points to the cleaned one,jeanblanchard/java,NA
: A repository containing images based on Alpine Linux to ,NA,NA
keep the size minimal (about 25% of an Ubuntu-based image). The tag ,latest,NA
points to Oracle Java 8 (Server JRE),NA,NA
By registering and creating your account on the Docker Hub at ,NA,NA
https://hub.docker.com,NA,NA
", ",NA,NA
you will get access to the Docker Store. It's available at ,NA,NA
https://store.docker.com,NA,NA
. Try ,NA,NA
searching the Docker Store for Java-related images. You will find a lot of useful ,NA,NA
"images to choose from, and one of them is the official Oracle Java 8 SE (Server JRE) ",NA,NA
"image. This Docker image provides the Server JRE, a runtime environment ",NA,NA
specifically targeted for deploying Java in server environments. The Server JRE ,NA,NA
includes tools for JVM monitoring and tools commonly required for server ,NA,NA
applications. You can get this official Java Docker image by buying it on the Docker ,NA,NA
"Store. Click Get Content, it's priced $0.00, so it will be available for your ",NA,NA
development purposes free of charge.,NA,NA
Take note that images coming from the Docker Store are bound to your,NA,NA
Docker Hub account. Before you pull them or build your own images ,NA,NA
"having them as the base image, you will need to the authenticate to ",NA,NA
Docker Store using the ,docker login,NA
 command and your Docker Hub,NA,NA
credentials.,NA,NA
"For our purposes, let's choose ",jeanblanchard/java,NA
. It's the official Oracle Java running ,NA,NA
on top of the Alpine Linux distribution. The base image is small and fast to ,NA,NA
download. Our ,FROM,NA
 instruction will look the same as this:,FROM jeanblanchard/java:8,NA
If a ,FROM,NA
" image is not found on your Docker host (on your local machine, for ",NA,NA
"example), Docker will try to find and pull it out from the Docker Hub (or your ",NA,NA
private repository if you have it set up). All subsequent instructions in the ,Dockerfile,NA
will use the image specified in the ,FROM,NA
 as a base starting point. That's why it's ,NA,NA
mandatory; a valid ,Dockerfile,NA
 must have it at the top.,NA,NA
MAINTAINER,NA,NA
By using the ,MAINTAINER,NA
" instruction, you set the ",Author,NA
 field of the generated image.,NA,NA
"This can be your name, username, or whatever you would like as an author of the ",NA,NA
image that will be created by using the ,Dockerfile,NA
 you are writing. This command can ,NA,NA
be placed anywhere in a ,Dockerfile,NA
", but good practice is to place it on the top of the ",NA,NA
"file, just after the ",FROM,NA
" instruction. This is a so-called, non-executing command, ",NA,NA
"meaning that it will not make any changes to the generated image. The syntax, again, ",NA,NA
is very simple:,MAINTAINER authors_name,NA
WORKDIR,NA,NA
The ,WORKDIR,NA
 instruction adds a working directory for any ,CMD,NA
", ",RUN,NA
", ",ENTRYPOINT,NA
", ",COPY,NA
", and ",ADD,NA
 instructions that comes after it in the Dockerfile. The syntax for the instruction is ,WORKDIR /PATH.,NA
 You can have multiple ,WORKDIR,NA
" instructions in one Dockerfile, if the ",NA,NA
relative path is provided; it will be relative to the path of the previous ,WORKDIR,NA
instruction.,NA,NA
ADD,NA,NA
What ,ADD,NA
 basically does is copy the files from the source into the container's own ,NA,NA
filesystem at the desired destination. It takes two arguments: the source (,"<source path 
 or URL>",NA
) and a destination (,<destination path>,NA
):,ADD <source path or URL> <destination path >,NA
"The source can have two forms: it can be a path to a file, a directory, or the URL. ",NA,NA
The path is relative to the directory in which the build process is going to be started ,NA,NA
"(the build context we have mentioned earlier). This means you cannot have, for ",NA,NA
example ,"""../../config.json""",NA
 placed as a source path parameter of the ,ADD,NA
 instruction.,NA,NA
The source and destination paths can contain wildcards. Those are the same as in a ,NA,NA
conventional file system: ,*,NA
" for any text string, or ",?,NA
 for any single character.,NA,NA
"For example, ",ADD target/*.jar /,NA
 will add all files ending with ,.jar,NA
 into the root ,NA,NA
directory in the image's file system.,NA,NA
"If you need, you can specify multiple source paths, and separate them with a comma. ",NA,NA
"All of them must be relative to the build context, the same as if you have just a single ",NA,NA
"source path. If your source or destination paths contain spaces, you will need to use a ",NA,NA
"special syntax, adding the square brackets around:","ADD [""<source path or URL>"" ""<destination path>""]",NA
"If the source path doesn't end with a trailing slash, it will be considered a single file ",NA,NA
"and just copied into the destination. If the source path ends with a trailing slash, it ",NA,NA
will be considered a directory: its whole contents will then be copied into the ,NA,NA
"destination path, but the directory itself will not be created at the destination path.",NA,NA
"So, as you can see, a trailing slash ",/,NA
 is quite important when adding files or ,NA,NA
directories to an image. If the source path points to the compressed archive in one of ,NA,NA
"the common formats such as ZIP, TAR, and so on, it will be decompressed into the ",NA,NA
"destination path. Docker doesn't recognize an archive by the filename, it checks the ",NA,NA
contents of the file.,NA,NA
"If the archive is damaged or unreadable by Docker in any other way, it ",NA,NA
will not be extracted and you will not be given an error message. The ,NA,NA
file will just be copied into the destination path.,NA,NA
The same trailing slash rules apply to the destination path; if it ends with a trailing ,NA,NA
"slash, it means that it's a directory. Otherwise, it will be considered a single file. This ",NA,NA
gives you great flexibility when constructing the file system content of your image; ,NA,NA
"you can add files into directories, add files as single files (with the same or different ",NA,NA
"names), or just add whole directories.",NA,NA
The ,ADD,NA
" command is not only about copying files from the local file system, you can ",NA,NA
use it to get the file from the network. If the source is a URL then the contents of the ,NA,NA
URL will be automatically downloaded and placed at the destination. Note that file ,NA,NA
"archives that were downloaded from the network will not be decompressed. Again, ",NA,NA
the trailing slash is important when downloading files; if the destination path ends ,NA,NA
"with a slash, the file will be downloaded into the directory. Otherwise, the ",NA,NA
downloaded file will just be saved under the name you provided as the destination ,NA,NA
path.,NA,NA
The ,<destination directory>,NA
 is either an absolute path or a path which is relative to the ,NA,NA
directory specific by the ,WORKDIR,NA
 instruction (we will cover it in a while). The source ,NA,NA
(or multiple sources) will just be copied into the destination specified. For example:,ADD config.json projectRoot/,NA
 will add the ,config.json,NA
 file to ,"<WORKDIR>/projectRoot/
  
  
 ADD config.json /absoluteDirectory/",NA
 will add the ,config.json,NA
 file to the,/absoluteDirectory/,NA
"When it comes to the ownership of the files created in the image, they will always be ",NA,NA
created with the user ID (,UID,NA
) ,0,NA
 and group ID (,GID,NA
) ,0,NA
. Permissions will be the same as ,NA,NA
"in the source file, unless it's a file downloaded from the remote URL: in this case, it ",NA,NA
will get permissions value ,600,NA
 (only the owner can read and write the file). If you ,NA,NA
"need to change these values (ownership or permissions), you will need to provide ",NA,NA
"more instructions in your Dockerfile, after the ",ADD,NA
 instruction.,NA,NA
If the files that you need to add to the image are placed on the URL that ,NA,NA
"needs authentication, the ",ADD,NA
 instruction will not work. You will need to ,NA,NA
"use a shell command to download the file, such as ",wget,NA
 or ,curl,NA
.,NA,NA
Note that ,ADD,NA
" shouldn't be used if you don't need its special features, such as ",NA,NA
"unpacking archives, you should use ",COPY,NA
 instead.,NA,NA
COPY,NA,NA
The ,COPY,NA
 instruction will copy new files or directories from ,<source path>,NA
 and add ,NA,NA
them to the file system of the container at the path ,<destination path>,NA
.,NA,NA
It's very similar to the ,ADD,NA
" instruction, even the syntax is no different:",COPY <source path or URL> <destination path >,NA
The same rules from ,ADD,NA
 apply to ,COPY,NA
: all source paths must be relative to the context ,NA,NA
of the build. Again the presence of the trailing slash at the end of the source and ,NA,NA
"destination path is important: if it's present, the path will be considered a file; ",NA,NA
"otherwise, it will be treated as a directory.",NA,NA
"Of course, as in ",ADD,NA
", you can have multiple source paths. If source or destination ",NA,NA
"paths contain spaces, you will need to wrap them in square brackets:","COPY [""<source path or URL>"" ""<destination path>""]",NA
The ,<destination path>,NA
" is an absolute path (if begins with a slash), or a path relative to ",NA,NA
the path specified by the ,WORKDIR,NA
 instruction.,NA,NA
"As you can see, the functionality of ",COPY,NA
 is almost the same as the ,ADD,NA
" instruction, ",NA,NA
with one difference. ,COPY,NA
 supports only the basic copying of local files into the ,NA,NA
"container. On the other hand, ",ADD,NA
" gives some more features, such as archive ",NA,NA
"extraction, downloading files through URL, and so on. Docker's best practices say ",NA,NA
that you should prefer ,COPY,NA
 if you do not need those additional features of ,ADD,NA
. The ,Dockerfile,NA
 will be cleaner and easier to understand thanks to the transparency of the ,COPY,NA
 command.,NA,NA
"There is one common, important aspect for both ",ADD,NA
 and ,COPY,NA
" instructions, a cache.",NA,NA
"Basically, Docker caches the files that go into the image during the build. The ",NA,NA
contents of the file or files in the image are examined and a checksum is calculated ,NA,NA
"for each file. During the cache lookup, the checksum is compared against the ",NA,NA
"checksum in the existing images. If anything has changed in the file(s), such as the ",NA,NA
"contents and metadata, then the cache is being invalidated. Otherwise, if the source ",NA,NA
"file has not changed, an existing image layer is being reused.",NA,NA
If you have multiple Dockerfile steps that use different files from your,NA,NA
"context, ",COPY,NA
" them individually, rather than all at once. This will ensure ",NA,NA
that each step's build cache is only invalidated (forcing the step to be ,NA,NA
re-run) if the specifically required files change.,NA,NA
"As you can see, the ",COPY,NA
 instruction has almost identical syntax and behavior to the ,ADD,NA
" instruction, but their feature set is somehow different. For files and directories ",NA,NA
that do not require the ,ADD,NA
" feature of archive unpacking or fetching from the URL, ",NA,NA
you should always use ,COPY,NA
.,NA,NA
RUN,NA,NA
The ,RUN,NA
 instruction is the central executing instruction for the ,Dockerfile,NA
". In essence, ",NA,NA
the ,RUN,NA
 instruction will execute a command (or commands) in a new layer on top of ,NA,NA
the current image and then commit the results. The resulting committed image will ,NA,NA
be used as a base for the next instruction in the ,Dockerfile,NA
. As you will remember ,NA,NA
from ,NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", layering is the core concept in Docker. ",RUN,NA
", ",NA,NA
takes a command as its argument and runs it to create the new layer.,NA,NA
This also means that ,COPY,NA
 and ,ENTRYPOINT,NA
" set parameters can be overridden at runtime, ",NA,NA
"so if you don't change anything after starting your container, the result will always be ",NA,NA
the same. ,RUN,NA
" however, will be executed at build time and no matter what you do at ",NA,NA
"runtime, its effects will be here.",NA,NA
"To make your Dockerfile more readable and easier to maintain, you ",NA,NA
can split long or complex ,RUN,NA
 statements on multiple lines separating ,NA,NA
them with a backslash.,NA,NA
The ,RUN,NA
 commands from the ,Dockerfile,NA
 will be executed in the order they appear in it.,NA,NA
Each ,RUN,NA
 instruction creates a new layer in the image.,NA,NA
As you already know from ,NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", layers are being cached ",NA,NA
and reused by Docker. The cache for ,RUN,NA
 instructions isn't invalidated automatically ,NA,NA
"during the next build. For example, the cache for an instruction the same as ","RUN apt-
 get upgrade -y",NA
 will be reused during the next build. What makes the cache important? ,NA,NA
"For the most part, the cache is exceptionally helpful and can save you a tremendous ",NA,NA
"amount of time while building your image. It makes building a new container really, ",NA,NA
"really fast. However, there is a word of warning. There are times when the caching ",NA,NA
can be dangerous and provide unexpected results. The cache is used pretty heavily ,NA,NA
during the build process and this may cause issues when you want the updated output ,NA,NA
of a ,RUN,NA
 command to make it into the new container. If the ,RUN,NA
 command doesn't ,NA,NA
"change between two builds, Docker's cache will not get invalidated. In effect, ",NA,NA
Docker will reuse the previous results from the cache. This is clearly harmful. ,NA,NA
Imagine a case when you use the ,RUN,NA
 command for pulling source code from the Git ,NA,NA
"repository, by using the ",git clone,NA
 as the first step of building the image.,NA,NA
"Be aware when the Docker cache needs to be invalidated, otherwise ",NA,NA
you will get unexpected results with your image builds.,NA,NA
That's why it's good to know how to selectively invalidate the cache. In the Docker ,NA,NA
"world, this is called cache busting.",NA,NA
Consider the following example. Probably the most common usecase for ,RUN,NA
 is an ,NA,NA
application of ,apt-get,NA
", which is a package manager command for downloading ",NA,NA
"packages on Ubuntu. Let's say we have the following Dockerfile, installing Java ",NA,NA
runtime:,"FROM ubuntu 
  
 RUN apt-get update 
  
 RUN apt-get install -y openjdk-8-jre",NA
If we build an image from this ,Dockerfile,NA
", all layers from two ",RUN,NA
 instructions will be ,NA,NA
"put into the layers cache. But, after a while you decide you want the ",node.js,NA
 package ,NA,NA
"in your image, so now the Dockerfile looks the same as this:","FROM ubuntu 
  
 RUN apt-get update 
  
 RUN apt-get install -y openjdk-8-jre 
  
 RUN apt-get install -y nodejs",NA
If you run the ,docker build,NA
" for the second time, Docker will reuse the layers by taking ",NA,NA
"them from the cache. As a result, the ",apt-get update,NA
" will not be executed, because the ",NA,NA
"cached version will be used. In effect, your newly created image will potentially ",NA,NA
have an outdated version of the ,java,NA
 and ,node.js,NA
 packages. You should always have ,NA,NA
the cache concept in mind when creating ,RUN,NA
" instructions. In our example, we should ",NA,NA
always combine ,RUN apt-get update,NA
 with ,apt-get install,NA
 in the same ,RUN,NA
" statement, ",NA,NA
which will create just a single layer; for example:,"RUN apt-get update \ 
  
 && apt-get install -y openjdk-8-jre \ 
  
 && apt-get install -y nodejs \ 
  
 && apt-get clean",NA
"Better than this, you can also use a technique called ""version pinning"" to avoid cache ",NA,NA
"problems. It's nothing more than just providing a specific, concrete version for the ",NA,NA
package you want to install.,NA,NA
CMD,NA,NA
The purpose of a ,CMD,NA
 instruction is to provide defaults for an executing container.,NA,NA
You can think of the ,CMD,NA
" instruction as a starting point of your image, when the ",NA,NA
"container is being run later on. This can be an executable, or, if you specify the ",ENTRYPOINT,NA
" instruction (we are going to explain it next), you can omit the executable ",NA,NA
and provide the default parameters only. The ,CMD,NA
 instruction syntax can have two ,NA,NA
forms:,"CMD [""executable"",""parameter1"",""parameter2""]",NA
: This is a so called ,exec,NA
 form. It's ,NA,NA
"also the preferred and recommended form. The parameters are JSON array, and ",NA,NA
they need to be enclosed in square brackets. The important note is that the ,exec,NA
form does not invoke a command shell when the container is run. It just runs the ,NA,NA
executable provided as the first parameter. If the ,ENTRYPOINT,NA
 instruction is present ,NA,NA
in the ,Dockerfile,NA
", ",CMD,NA
 provides a default set of parameters for the ,ENTRYPOINT,NA
instruction.,CMD command parameter1 parameter2,NA
": This a shell form of the instruction. This time, ",NA,NA
the shell (if present in the image) will be processing the provided command.,NA,NA
The specified binary will be executed with an invocation of the shell using ,/bin/sh -c,NA
". It means that if you display the container's hostname, for example, ",NA,NA
using ,CMD echo $HOSTNAME,NA
", you should use the shell form of the instruction.",NA,NA
We have said before that the recommended form of ,CMD,NA
 instruction is the ,exec,NA
 form. ,NA,NA
Here's why: everything started through the shell will be started as a subcommand of ,/bin/sh -c,NA
", which does not pass signals. This means that the executable will not be ",NA,NA
"the container's PID 1, and will not receive Unix signals, so your executable will not ",NA,NA
receive a ,SIGTERM,NA
 from ,docker stop <container>,NA
. There is another drawback: you will ,NA,NA
"need a shell in your container. If you're building a minimal image, it doesn't need to ",NA,NA
contain a shell binary. The ,CMD,NA
 instruction using the shell form will simply fail.,NA,NA
"When Docker is executing the command, it doesn't check if the shell is ",NA,NA
available inside the container. If there is no ,/bin/sh,NA
" in the image, the ",NA,NA
container will fail to start.,NA,NA
"On the other hand, if we change the ",CMD,NA
 to the ,exec,NA
" form, Docker will be looking for ",NA,NA
an executable named ,echo,NA
", which, of course, will fail, because ",echo,NA
 is a shell ,NA,NA
command.,NA,NA
Because ,CMD,NA
 is the same as a starting point for the Docker engine when running a ,NA,NA
"container, there can only be one single ",CMD,NA
 instruction in a Dockerfile.,NA,NA
If there are more than one ,CMD,NA
" instruction in a Dockerfile, only the last ",NA,NA
one will take effect.,NA,NA
You may notice that the ,CMD,NA
 instruction is very similar to ,RUN,NA
. They both can run any ,NA,NA
command (or application). There is a key important difference: the time of ,NA,NA
execution. The command supplied through the ,RUN,NA
 instruction is executed during the ,NA,NA
"build time, whereas the command specified through the ",CMD,NA
 instruction is executed ,NA,NA
when the container is launched by executing ,docker run,NA
 on the newly created image. ,NA,NA
Unlike ,CMD,NA
", the ",RUN,NA
" instruction is actually used to build the image, by creating a new ",NA,NA
layer on top of the previous one which is committed.,RUN,NA
" is a build-time instruction, the ",CMD,NA
 is a runtime instruction.,NA,NA
"Believe it or not, we can now have our REST example microservice containerized.",NA,NA
Let's check if it builds by executing the ,mvn clean install,NA
 on the ,pom.xml,NA
 file created in ,NA,NA
Chapter 4,NA,NA
", ",NA,NA
Creating Java Microservices,NA,NA
". After the successful build, we should have a ",NA,NA
target directory with the ,rest-example-0.1.0.jar,NA
 file created. The Spring Boot ,NA,NA
application JAR in the ,target,NA
" directory is an executable, fat JAR. We are going to run ",NA,NA
it from within the Docker container. Let's write the basic ,Dockerfile,NA
 using the ,NA,NA
command we already know and place it in the root of our project (this will be the ,NA,NA
context for our ,docker build,NA
 command):,"FROM jeanblanchard/java:8 
  
 COPY target/rest-example-0.1.0.jar rest-example-0.1.0.jar 
 CMD java -jar rest-example-0.1.0.jar",NA
We can now run the ,docker build,NA
" command, using ",rest-example,NA
" as the image name, ",NA,NA
"omitting the tag (as you will remember, omitting a tag when building an image will ",NA,NA
result in creating the ,latest,NA
 tag):,$ docker build . -t rest-example,NA
The dot as the first parameter specifies the context for the ,docker build,NA
 command. In ,NA,NA
"our case, it will be just a root directory of our little microservice. During the build ",NA,NA
"process, Docker will output all the steps and layer IDs. Notice that almost every ",Dockerfile,NA
 instruction creates a new layer. If you remember from ,NA,NA
Chapter 1,NA,NA
",",NA,NA
Introduction to Docker,NA,NA
", Docker utilizes the layer cache. If a specific layer can be ",NA,NA
"reused, it will be taken from the cache. It greatly improves the build process ",NA,NA
"performance. At the end, Docker will output the ID of the newly created image, as ",NA,NA
you can see in the following screenshot:,NA,NA
"An image has been created, so it should be present on the images available to run. To ",NA,NA
"list images, execute the following Docker command:",$ docker image ls,NA
"As you can see in the following screenshot, our ",rest-example,NA
 image is present and ,NA,NA
ready to be run:,NA,NA
"So far, so good. We have a basic form of our image built. Although the process of ",NA,NA
running images is the topic for ,NA,NA
Chapter 6,NA,NA
", ",NA,NA
Running Containers with Java Applications,NA,NA
", ",NA,NA
"let's quickly run it now to prove it's working. To run the image, execute the ",NA,NA
following:,$ docker run -it rest-example,NA
"After a while, you should see the familiar Spring Boot banner as a sign that our ",NA,NA
service is running from inside the Docker container:,NA,NA
"That wasn't very tricky, right? The basic ",Dockerfile,NA
" contains just three lines, the base ",NA,NA
image definition using ,FROM,NA
", ",COPY,NA
 to transfer the executable jar into the image's ,NA,NA
"filesystem, and a ",CMD,NA
 instruction to run the service.,NA,NA
Building an application jar archive using Maven and then copying it using a ,NA,NA
Dockerfile ,COPY,NA
 instruction simply works. What about delegating the build process to ,NA,NA
"the Docker daemon itself? Well, we can do it, using the ",Dockerfile,NA
 instructions we ,NA,NA
already know. The drawback of building a Java app using the Docker daemon is that ,NA,NA
"the image will contain all of the JDK (including the Java compiler), Maven binaries, ",NA,NA
and our application source code. I would recommend building a single artifact (a ,NA,NA
"JAR or WAR file), testing it thoroughly (using a release-oriented QA cycle), and ",NA,NA
deploying the sole artifact (with its dependencies of course) onto the target machine.,NA,NA
"However, to have an idea what's possible with a ",Dockerfile,NA
", take a look at the ",NA,NA
"following example, assuming that our application code in the ",/app,NA
 folder on the local ,NA,NA
disk:,"FROM java:8 
  
 RUN apt-get update 
  
 RUN apt-get install -y maven 
  
 WORKDIR /app 
  
 COPY pom.xml /app/pom.xml 
  
 COPY src /app/src 
  
 RUN [""mvn"", ""package""] 
  
 CMD [""/usr/lib/jvm/java-8-openjdk-amd64/bin/java"", 
 ""-jar"", ""target/ rest-example-0.1.0.jar""]",NA
"In the previous example, the Maven build process will be executed by Docker. We",NA,NA
just run the ,apt-get,NA
" command to install Maven, add our application source code to the ",NA,NA
"image, execute the Maven ",package,NA
" command, and then run our service. It will behave ",NA,NA
exactly the same as if we just copy the already-built artifact into the image's file ,NA,NA
system.,NA,NA
There's a Dockerfile instruction which is kind of related to ,CMD,NA
 instruction: the ,ENTRYPOINT,NA
. Let's look at it now.,NA,NA
The ENTRYPOINT,NA,NA
The official Docker documentation says that the ,ENTRYPOINT,NA
 instruction allows you to ,NA,NA
"configure a container that will run as an executable. It's not very clear, at least for the ",NA,NA
first time. The ,ENTRYPOINT,NA
 instruction is related to the ,CMD,NA
" instruction. In fact, it can be ",NA,NA
confusing at the beginning. The reason for that is simple: ,CMD,NA
" was developed first, ",NA,NA
then ,ENTRYPOINT,NA
" was developed for more customization, and some functionality ",NA,NA
overlaps between those two instructions. Let's explain it a bit.,NA,NA
The ,ENTRYPOINT,NA
 specifies a command that will always be executed when the container ,NA,NA
starts. The ,CMD,NA
", on the other hand, specifies the arguments that will be fed to ",NA,NA
the ,ENTRYPOINT,NA
. Docker has a default ,ENTRYPOINT,NA
 which is ,/bin/sh -c,NA
 but does not have a ,NA,NA
default ,CMD,NA
". For example, consider this Docker command:","docker run ubuntu ""echo"" ""hello world""",NA
"In this case, the image will be the latest ",ubuntu,NA
", the ",ENTRYPOINT,NA
 will be the default ,/bin/sh -c,NA
", and the command passed to the ",ENTRYPOINT,NA
 will be ,"echo ""hello world""",NA
.,NA,NA
The syntax for the ,ENTRYPOINT,NA
" instruction can have two forms, similar to ",CMD,NA
.,"ENTRYPOINT [""executable"", ""parameter1"", ""parameter2""]",NA
 is the ,exec,NA
" form, preferred and ",NA,NA
recommended. Exactly the same as the ,exec,NA
 form of the ,CMD,NA
" instruction, this will not ",NA,NA
invoke a command shell. This means that the normal shell processing will not ,NA,NA
"happen. For example, ","ENTRYPOINT [ ""echo"", ""$HOSTNAME"" ]",NA
 will not do variable ,NA,NA
substitution on the ,$HOSTNAME,NA
 variable. If you want shell processing then you need ,NA,NA
either to use the shell form or execute a shell directly. For example:,"ENTRYPOINT [ ""sh"", ""-c"", ""echo $HOSTNAME"" ]",NA
Variables that are defined in the Dockerfile using ,ENV,NA
 (we are going to cover this in a ,NA,NA
"while), will be substituted by the Dockerfile parser.",ENTRYPOINT command parameter1 parameter2,NA
 is a a shell form. Normal shell processing ,NA,NA
will occur. This form will also ignore any ,CMD,NA
 or ,docker run,NA
 command line arguments. ,NA,NA
"Also, your command will not be PID 1, because it will be executed by the shell. As a ",NA,NA
"result, if you then ",run docker stop <container>,NA
", the container will not exit cleanly, and ",NA,NA
the stop command will be forced to send a ,SIGKILL,NA
 after the timeout.,NA,NA
Exactly the same as with the ,CMD,NA
" instruction, only the last ",ENTRYPOINT,NA
 instruction in the ,NA,NA
Dockerfile will have an effect. Overriding the ,ENTRYPOINT,NA
 in the Dockerfile allows you ,NA,NA
to have a different command processing your arguments when the container is run. If ,NA,NA
"you need to change the default shell in your image, you can do this by changing an ",ENTRYPOINT,NA
:,"FROM ubuntu 
  
 ENTRYPOINT [""/bin/bash""]",NA
"From now on, all parameters from ",CMD,NA
", or provided when starting the container using ",docker run,NA
", will be processed by the Bash shell instead of the default ",/bin/sh -c,NA
.,NA,NA
Consider this simple ,Dockerfile,NA
 based on BusyBox. BusyBox is software that ,NA,NA
provides several stripped-down Unix tools in a single executable file. To ,NA,NA
demonstrate ,ENTRYPOINT,NA
", we are going to use a ",ping,NA
 command from BusyBox:,"FROM busybox 
  
 ENTRYPOINT [""/bin/ping""] 
  
 CMD [""localhost""]",NA
"Let's build the image using the previous Dockerfile, by executing the command:",$ docker build -t ping-example .,NA
If you now run the container using the ,ping,NA
" image, the ",ENTRYPOINT,NA
 instruction will be ,NA,NA
processing arguments from the supplied ,CMD,NA
 argument: it will be ,localhost,NA
 by default ,NA,NA
"in our case. Let's run it, using the following command:",$ docker run ping-example,NA
"As a result, you will have a ",/bin/ping localhost,NA
" command-line response, as you can ",NA,NA
see in the following screenshot:,NA,NA
The ,CMD,NA
" instruction, as you will remember from its description, sets the default",NA,NA
"command and/or parameters, which can be overwritten from the command line when ",NA,NA
you run the container. The ,ENTRYPOINT,NA
" is different, its command and parameters cannot ",NA,NA
"be overwritten using the command line. Instead, all command line arguments will be ",NA,NA
appended after the ,ENTRYPOINT,NA
" parameters. This way you can, kind of, lock the ",NA,NA
command that will be executed always during the container start.,NA,NA
Unlike the ,CMD,NA
" parameters, the ",ENTRYPOINT,NA
 command and parameters are ,NA,NA
not ignored when a Docker container runs with command-line ,NA,NA
parameters.,NA,NA
Because the command-line parameter will be appended to the ,ENTRYPOINT,NA
" parameters, ",NA,NA
we can run our ,ping,NA
 image with different parameters passed to the ,ENTRYPOINT,NA
. Let's try ,NA,NA
"it, by running our ping example with different input:",$ docker run ping-example www.google.com,NA
This time it will behave differently. The provided argument value ,www.google.com,NA
 will ,NA,NA
be appended to the ,ENTRYPOINT,NA
", instead of the default ",CMD,NA
 value provided in the ,NA,NA
Dockerfile. The total command line that will be executed will be ,"/bin/ping 
  
 www.google.com",NA
", as you can see in the following screenshot:",NA,NA
You can use the ,exec,NA
 form of ,ENTRYPOINT,NA
 to set fairly stable default ,NA,NA
commands and arguments and then use either form of ,CMD,NA
 to set ,NA,NA
additional defaults that are more likely to be changed.,NA,NA
Having the ,ENTRYPOINT,NA
" instruction gives us a lot of flexibility. And, last but not least, ",NA,NA
an ,ENTRYPOINT,NA
 can be also overridden when starting the container using the ,"--
  
 entrypoint",NA
 parameter for the ,docker run,NA
 command. Note that you can override the ,ENTRYPOINT,NA
 setting using ,--entrypoint,NA
", but this can only set the binary to execute (no ","sh-
 c",NA
" will be used). As you can see, both ",CMD,NA
 and ,ENTRYPOINT,NA
 instructions define what ,NA,NA
command gets executed when running a container. Let's summarize what we have,NA,NA
learned about the differences and their cooperation:,NA,NA
A Dockerfile should specify at least one ,CMD,NA
 or ,ENTRYPOINT,NA
 instruction,NA,NA
Only the last ,CMD,NA
 and ,ENTRYPOINT,NA
 in a Dockerfile will be used,ENTRYPOINT,NA
 should be defined when using the container as an executable,NA,NA
You should use the ,CMD,NA
 instruction as a way of defining default arguments for ,NA,NA
the command defined as ,ENTRYPOINT,NA
 or for executing an ,ad-hoc,NA
 command in a ,NA,NA
container,CMD,NA
 will be overridden when running the container with alternative arguments,ENTRYPOINT,NA
 sets the concrete default application that is used every time a ,NA,NA
container is created using the image,NA,NA
If you couple ,ENTRYPOINT,NA
 with ,CMD,NA
", you can remove an executable from ",CMD,NA
 and ,NA,NA
just leave its arguments which will be passed to ,ENTRYPOINT,NA
The best use for ,ENTRYPOINT,NA
" is to set the image's main command, allowing that ",NA,NA
image to be run as though it was that command (and then use ,CMD,NA
 as the default ,NA,NA
flags),NA,NA
"Well, our service is running fine, but it's not very useful. First, it involves a lot of ",NA,NA
"manual steps to get it running, that's why we are going to automate it later in this ",NA,NA
"chapter using Maven. Second, as you will remember, our service listens for ",HTTP,NA
requests incoming on port number ,8080,NA
". Our basic image runs, but doesn't expose any ",NA,NA
network ports so no one and nothing can access the service. Let's continue learning ,NA,NA
about the remaining Dockerfile instructions to fix it.,NA,NA
EXPOSE,NA,NA
The ,EXPOSE,NA
 instruction informs Docker that the container listens on the specified ,NA,NA
network ports at runtime. We have already mentioned the ,EXPOSE,NA
 instruction in ,NA,NA
Chapter ,NA,NA
2,NA,NA
", ",NA,NA
Networking and Persistent Storage,NA,NA
". As you will remember, ",EXPOSE,NA
 in a Dockerfile ,NA,NA
is the equivalent to the ,--expose,NA
 command-line option. Docker uses the ,EXPOSE,NA
command followed by a port number to allow incoming traffic to the container. We ,NA,NA
already know that ,EXPOSE,NA
 does not make the ports of the container automatically ,NA,NA
"accessible on the host. To do that, you must use either the ",-p,NA
 flag to publish a range ,NA,NA
of ports or the ,-P,NA
 flag to publish all of the exposed ports at once.,NA,NA
Let's get back to our ,Dockerfile,NA
 and expose a port:,"FROM jeanblanchard/java:8 
  
 COPY target/rest-example-0.1.0.jar rest-example-0.1.0.jar 
 CMD java -jar rest-example-0.1.0.jar 
  
 EXPOSE 8080",NA
"If you now re-build the image using the same command, ","docker build . -t rest-
 example",NA
", you'll notice that Docker outputs the fourth layer, saying that port ",8080,NA
 has ,NA,NA
been exposed. Exposed ports will be available for the other containers on this Docker ,NA,NA
"host, and, if you map them during runtime, also for the external world. Well, let's try ",NA,NA
"it, using the following ",docker run,NA
 command:,$ docker run -p 8080:8080 -it rest-example,NA
If you now call the localhost with a ,HTTP,NA
 request such as ,POST,NA
 (for saving our book ,NA,NA
entities) or ,GET,NA
 (for getting the list of books or a single book) as we have done in ,NA,NA
Chap ,NA,NA
ter 4,NA,NA
", ",NA,NA
Creating Java Microservices,NA,NA
", using any of the HTTP tools such as HTTPie or ",NA,NA
"Postman, it will respond the same as before. This time, however, from with the ",NA,NA
"Docker container. Now, this is something. Let's get to know the remaining important ",NA,NA
Dockerfile instructions.,NA,NA
VOLUME,NA,NA
As you will remember from ,NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", container file systems ",NA,NA
"are kind of temporary by default. If you start a Docker image up (that is, run the ",NA,NA
"container), you'll end up with a read-write layer on top of the layer's stack. You can ",NA,NA
"create, modify, and delete files as you wish, then commit the layer to persist the ",NA,NA
changes. In ,NA,NA
Chapter 2,NA,NA
", ",NA,NA
"Networking and Persistent Storage,",NA,NA
 we have learned how to ,NA,NA
"create volumes, which is a great way of storing and retrieving data from the Docker ",NA,NA
container. We can do the same in the ,Dockerfile,NA
", using the ",VOLUME,NA
 instruction.,NA,NA
The syntax couldn't be simpler: it's just ,"VOLUME [""/volumeName""]",NA
.,NA,NA
The parameter for ,VOLUME,NA
" can be a JSON array, a plain string with one or more ",NA,NA
arguments. For example:,"VOLUME [""/var/lib/tomcat8/webapps/""] 
  
 VOLUME /var/log/mongodb /var/log/tomcat",NA
The ,VOLUME,NA
 instruction creates a mount point with the specified name and marks it as ,NA,NA
holding externally mounted volumes from a native host or other containers.,NA,NA
The ,VOLUME,NA
 command will mount a directory inside your container and store any files ,NA,NA
created or edited inside that directory on your host's disk outside the container file ,NA,NA
structure. Using ,VOLUME,NA
 in the ,Dockerfile,NA
 let's Docker know that a certain directory ,NA,NA
contains permanent data. Docker will create a volume for that data and never delete ,NA,NA
"it, even if you remove all the containers that use it. It also bypasses the union file ",NA,NA
"system, so that the volume is in fact an actual directory that gets mounted, either ",NA,NA
"read-write or read-only, in the right place, in all the containers that share it (if they ",NA,NA
are started with the ,--volumes-from,NA
" option, for example). To understand ",VOLUME,NA
", let's ",NA,NA
look at the simple Dockerfile:,"FROM ubuntu 
  
 VOLUME /var/myVolume",NA
If you now run your container and save some files in the ,/var/myVolume,NA
", they will be ",NA,NA
available for other containers for sharing.,NA,NA
"Basically, ",VOLUME,NA
 and ,-v,NA
 are almost equal. The difference between ,VOLUME,NA
 and ,-v,NA
 is that ,NA,NA
you can use ,-v,NA
 dynamically and mount your ,host,NA
 directory on your container when ,NA,NA
starting it by executing ,docker run,NA
. The reason for that is Dockerfiles are meant to be,NA,NA
portable and shared. The host directory volume is 100% host dependent and will ,NA,NA
"break on any other machine, which is a little bit off the Docker idea. Because of this, ",NA,NA
it is only possible to use portable instructions within a Dockerfile.,NA,NA
The fundamental difference between ,VOLUME,NA
 and ,-v,NA
 is this: ,-v,NA
 will mount ,NA,NA
existing files from your operating system inside your Docker container ,NA,NA
and ,VOLUME,NA
" will create a new, empty volume on your host and mount it ",NA,NA
inside your container.,NA,NA
LABEL,NA,NA
"To add the metadata to our image, we use the ",LABEL,NA
 instruction. A single label is a ,NA,NA
"key-value pair. If you need to have spaces in the label value, you will need to wrap it ",NA,NA
"in a pair of quotes. Labels are additive, they include all labels taken from an image ",NA,NA
that is the base of your own image (the one from the ,FROM,NA
 instruction). If Docker ,NA,NA
"encounters a label that already exists, it will override the label having the same key ",NA,NA
with the new value. There are some rules that you must stick to when defining labels: ,NA,NA
"keys can only consist of lowercase alphanumeric characters, dots, and dashes, and ",NA,NA
"must begin and end with alphanumeric characters. To prevent naming conflicts, ",NA,NA
Docker recommends using namespaces to label keys using reverse domain notation.,NA,NA
"On the other hand, keys without namespaces (dots) are reserved for command-line ",NA,NA
use.,NA,NA
The syntax of the ,LABEL,NA
 instruction is straightforward:,"LABEL ""key""=""value""",NA
"To have a multiline value, separate the lines with backslashes; for example:","LABEL description=""This is my \ 
  
 multiline description of the software.""",NA
You can have multiple labels in a single image. Provide them separated with a space ,NA,NA
or a backslash; for example:,"LABEL key1=""value1"" key2=""value2"" key3=""value3"" 
 LABEL key1=""value1"" \ 
  
 key2=""value2"" \ 
  
 key3=""value3""",NA
"Actually, if you need to have multiple labels in your image, it's recommended to ",NA,NA
use the multi-label form of the ,LABEL,NA
" instruction, because it will result in just one ",NA,NA
additional layer in the image.,NA,NA
Each ,LABEL,NA
 instruction creates a new layer. If your image has many ,NA,NA
"labels, use the multiple form of the single ",LABEL,NA
 instruction.,NA,NA
"If you want to inspect what labels an image has, use the ",docker inspect,NA
 command you ,NA,NA
already know about from the previous chapters.,NA,NA
ENV,ENV,NA
 is a ,Dockerfile,NA
 instruction that sets the environment variable ,<key>,NA
 to the value ,<value>,NA
. You have two options for using ,ENV,NA
:,NA,NA
"The first one, ",ENV <key> <value>,NA
", will set a single variable to a value. The entire ",NA,NA
string after the first space will be treated as the ,<value>,NA
. This will include any ,NA,NA
"character, and also spaces and quotes. For example:",ENV JAVA_HOME /var/lib/java8,NA
"The second one, with an equal sign, is ",ENV <key>=<value>,NA
. This form allows ,NA,NA
setting multiple environment variables at once. If you need to provide spaces in ,NA,NA
"the values, you will need to use quotes. If you need quotes in the values, use ",NA,NA
backslashes:,"ENV CONFIG_TYPE=file CONFIG_LOCATION=""home/Jarek/my \app/config.json""",NA
Note that you can use ,ENV,NA
 to update the ,PATH,NA
" environment variable, and then ",CMD,NA
parameters will be aware of that setting. This will result in a cleaner form of ,CMD,NA
parameters in the ,Dockerfile,NA
". For example, set the following:",ENV PATH /var/lib/tomcat8/bin:$PATH,NA
This will ensure that ,"CMD [""startup.sh""]",NA
" will work, because it will find the ",startup.sh,NA
file in the system ,PATH,NA
. You can also use ,ENV,NA
 to set the often-modified version ,NA,NA
"numbers so that upgrades are easier to handle, as seen in the following example:","ENV TOMCAT_VERSION_MAJOR 8 
  
 ENV TOMCAT_VERSION 8.5.4 
  
 RUN curl -SL http://apache.uib.no/tomcat/tomcat-$TOMCAT_VERSION_MAJOR/v$TOMCAT_VERSION/bin/ap 
 ENV PATH /usr/Jarek/apache-tomcat-$TOMCAT_VERSION/bin:$PATH",NA
"In the previous example, Docker will download the version of Tomcat specified in ",NA,NA
the ,ENV,NA
" variable, extract it to the new directory with that version in its name, and also ",NA,NA
set up the system ,PATH,NA
 to make it available for running.,NA,NA
The environment variables set using ,ENV,NA
 will persist when a container is run from the ,NA,NA
resulting image. The same as with labels created with ,LABEL,NA
", you can view the ",ENV,NA
values using the ,docker inspect,NA
 command. The ,ENV,NA
 values can also be overridden just ,NA,NA
"before the start of the container, using ",docker run --env <key>=<value>,NA
.,NA,NA
USER,NA,NA
The ,USER,NA
 instruction sets the username or UID to use when running the image. It will ,NA,NA
affect the user for any ,RUN,NA
", ",CMD,NA
", and ",ENTRYPOINT,NA
 instructions that will come next in the ,Dockerfile,NA
.,NA,NA
The syntax of the instruction is just ,USER <user name or UID>,NA
; for example:,USER tomcat,NA
You can use the ,USER,NA
 command if an executable can be run without privileges. The ,NA,NA
Dockerfile can contain the user and group creation instruction the same as this one:,RUN groupadd -r tomcat && useradd -r -g tomcat tomcat,NA
Switching USER back and forth frequently will increase the number of layers in the ,NA,NA
resulting image and also will make the Dockerfile more complex.,NA,NA
ARG,NA,NA
The ,ARG,NA
 instruction is being used to pass an argument to the Docker daemon during ,NA,NA
the ,docker build,NA
 command. An ,ARG,NA
 variable definition comes into effect from the line ,NA,NA
on which it is defined in the ,Dockerfile,NA
. By using the ,--build-arg,NA
" switch, you can ",NA,NA
assign a value to the defined variable:,$ docker build --build-arg <variable name>=<value> .,NA
The value from the ,--build-arg,NA
 will be passed to the daemon building the image. You ,NA,NA
can specify multiple arguments using multiple ,ARG,NA
 instructions. If you specify a build ,NA,NA
time argument that is not defined using ,ARG,NA
", the build will fail with an error, but the ",NA,NA
default value can be specified in the ,Dockerfile,NA
 . You specify the default argument ,NA,NA
value this way:,"FROM ubuntu 
  
 ARG user=jarek",NA
"If no argument will be specified before starting the build, the default value will be ",NA,NA
used:,NA,NA
It is not recommended to use ,ARG,NA
" for passing secrets as GitHub keys, ",NA,NA
"user credentials, passwords, and so on, as all of them will be visible to ",NA,NA
any user of the image by using the ,docker history,NA
 command!,NA,NA
ONBUILD,NA,NA
The ,ONBUILD,NA
 instruction specifies an additional instruction which will be triggered ,NA,NA
"when some other image is built by using this image as its base image. In other words, ",NA,NA
the ,ONBUILD,NA
 instruction is an instruction the parent ,Dockerfile,NA
 gives to the ,NA,NA
child ,Dockerfile,NA
 (downstream build). Any build instruction can be registered as a ,NA,NA
trigger and those instructions will be triggered immediately after the ,FROM,NA
 instruction ,NA,NA
in the ,Dockerfile,NA
.,NA,NA
The syntax of the ,ONBUILD,NA
 instruction is as follows:,ONBUILD <INSTRUCTION>,NA
"Within this, ",<INSTRUCTION>,NA
" is another Dockerfile build instruction, which will be ",NA,NA
triggered later when the child image is going to be built. There are some limitations: ,NA,NA
the ,ONBUILD,NA
 instruction does not allow the chaining of another ,ONBUILD,NA
 instruction and ,NA,NA
it does not allow the ,FROM,NA
 and ,MAINTAINER,NA
 instructions as ,ONBUILD,NA
 triggers.,NA,NA
This is useful if you are building an image which will be used as a base to build other ,NA,NA
"images. For example, an application build environment or a daemon which may be ",NA,NA
customized with a user-specific configuration. The ,ONBUILD,NA
 instruction is very useful ( ,NA,NA
https://docs.docker.com/engine/reference/builder/#onbuild,NA,NA
 and ,NA,NA
https://docs.docker.com/engine/refe ,NA,NA
rence/builder/#maintainer-deprecated,NA,NA
"), for automating the build of your chosen software ",NA,NA
stack. Consider the following example with Maven and building Java applications ,NA,NA
"(yes, Maven is also available as a Docker container). Basically, all your project's ",NA,NA
Dockerfile needs to do is reference the base container containing the ,ONBUILD,NA
instructions:,"FROM maven:3.3-jdk-8-onbuild 
  
 CMD [""java"",""-jar"",""/usr/src/app/target/app-1.0-SNAPSHOT-jar-with-dependencies.jar""]",NA
"There's no magic, and everything becomes clear if you look into the parent's ",NA,NA
"Dockerfile. In our case, it will be a ",docker-maven,NA
 Dockerfile available on GitHub:,"FROM maven:3-jdk-8 
  
 RUN mkdir -p /usr/src/app 
  
 WORKDIR /usr/src/app 
  
 ONBUILD ADD . /usr/src/app 
  
 ONBUILD RUN mvn install",NA
There's a base image that has both Java and Maven installed and a series of,NA,NA
instructions to copy files and run Maven.,NA,NA
The ,ONBUILD,NA
 instruction adds to the image a trigger instruction to be executed at a ,NA,NA
"later time, when the image is used as the base for another build. The trigger will be ",NA,NA
"executed in the context of the child build, as if it had been inserted immediately after ",NA,NA
the ,FROM,NA
 instruction in the child ,Dockerfile,NA
.,NA,NA
When Docker encounters an ,ONBUILD,NA
" instruction during the build process, the builder ",NA,NA
adds a kind of trigger to the metadata of the image being built. But this is the only ,NA,NA
"way this image is being affected. At the end of the build, a list of all triggers is stored ",NA,NA
"in the image manifest, under the key ",OnBuild,NA
. You can see them using the ,"docker 
 inspect",NA
"  command, which we already know.",NA,NA
"Later the image may be used as a base for a new build, using the ",FROM,NA
 instruction. As ,NA,NA
part of processing the ,FROM,NA
" instruction, the Docker builder looks for ",ONBUILD,NA
" triggers, ",NA,NA
"and executes them in the same order they were registered. If any of the triggers fail, ",NA,NA
the ,FROM,NA
" instruction is aborted which will make the build fail. If all triggers succeed, ",NA,NA
the ,FROM,NA
 instruction completes and the build resumes.,NA,NA
STOPSIGNAL,NA,NA
"To specify what system call signal should be sent to the container to exit, use the ",STOPSIGNAL,NA
 instruction. This signal can be a valid unsigned number that matches a ,NA,NA
position in the kernel's ,syscall,NA
 table: for instance ,9,NA
", or a signal name in the format ",SIGNAME,NA
", for instance ",SIGKILL,NA
.,NA,NA
HEALTHCHECK,NA,NA
The ,HEALTHCHECK,NA
 instruction can be used to inform Docker how to test a container to ,NA,NA
check that it is still working. This can be checking if our rest service responds to ,HTTP,NA
calls or just listens on a specified port.,NA,NA
A container can have several statuses which can be listed using the ,docker ps,NA
command. These can be ,created,NA
", ",restarting,NA
", ",running,NA
", ",paused,NA
", ",exited,NA
", or ",dead,NA
. But ,NA,NA
sometimes this is not enough; a container may be still alive from Docker's point of ,NA,NA
"view, but the application can hang or fail in some other way. An additional checking ",NA,NA
for the application status can be useful and ,HEALTHCHECK,NA
 comes in handy.,NA,NA
The ,HEALTHCHECK,NA
" status is initially starting. Whenever a health check passes, it ",NA,NA
becomes ,healthy,NA
 (whatever state it was previously in). After a certain number of ,NA,NA
"consecutive failures, it becomes ",unhealthy,NA
.,NA,NA
The syntax for a ,HEALTHCHECK,NA
 instruction is as follows:,HEALTHCHECK --interval=<interval> --timeout=<timeout> CMD <command>,NA
The ,<interval>,NA
 (the default value is 30 seconds) and ,<timeout>,NA
" (again, the default is 30 ",NA,NA
"seconds) are time values, specifying the checking interval and timeout accordingly. ",NA,NA
The ,<command>,NA
 is the command actually being used to check if the application is still ,NA,NA
running. The exit code of the ,<command>,NA
 is being used by Docker to determine if a ,NA,NA
health check failed or succeeded. The values can be ,0,NA
", meaning the container is ",NA,NA
healthy and ready for use and ,1,NA
 meaning that something is wrong and the container is ,NA,NA
not working correctly. The Java microservice ,healthcheck,NA
 implementation could be ,NA,NA
just a simple ,/ping,NA
" REST endpoint, returning whatever (as a timestamp) or even ",NA,NA
returning an empty response with ,HTTP 200,NA
 status code proving it's alive. Our ,HEALTHCHECK,NA
 could execute a ,GET,NA
" method on this endpoint, checking if the service is ",NA,NA
responding:,HEALTHCHECK --interval=5m --timeout=2s --retries=3 CMD curl -f http://localhost/ping || exit,NA
"In the previous example, the command ",curl -f http://localhost/ping,NA
 will be executed ,NA,NA
"every 5 minutes, for the maximum timeout of 2 seconds. If a single run of the check ",NA,NA
takes longer than 2 seconds then the check is considered to have failed. If three ,NA,NA
"consecutive retries fail, the container will get the ",unhealthy,NA
 status.,NA,NA
There can only be one ,HEALTHCHECK,NA
 instruction in a Dockerfile. If you list ,NA,NA
more than one then only the last ,HEALTHCHECK,NA
 will take effect.,NA,NA
The ,HEALTCHECK,NA
 instruction gives you the possibility to fine tune the container ,NA,NA
"monitoring, and thus be sure that your container is working fine. It's better than just ",running,NA
", ",exited,NA
 or ,dead,NA
 standard Docker status.,NA,NA
Now that we have an understanding of ,Dockerfile,NA
" instructions, we are ready to ",NA,NA
prepare our images. Let's automate things a bit. We are going to create and run our ,NA,NA
image using Maven.,NA,NA
Creating an image using Maven,NA,NA
"Naturally, we could build our Docker image using Docker itself. But this is not a ",NA,NA
typical use case for Spring developers. A typical use case for us would be to use ,NA,NA
"Maven. This can be especially useful, if you have continuous integration flow set up, ",NA,NA
using Jenkins for example. Delegating the image build process to Maven gives you a ,NA,NA
lot of flexibility and also saves a lot of time. There is at least a couple of Docker ,NA,NA
"Maven plugins available for free on GitHub, such as:",NA,NA
https://github.com/spotify/docker-maven-plugin,NA,NA
: A Maven plugin for building and ,NA,NA
pushing Docker images by Spotify.,NA,NA
https://github.com/alexec/docker-maven-plugin,NA,NA
.,NA,NA
https://github.com/fabric8io/docker-maven-plugin,NA,NA
: This is the one I find to be most ,NA,NA
useful and configurable. Of all the Maven plugins for Docker at the time of ,NA,NA
"writing, Fabric8 seems to be the most robust. Fabric8 is an integrated open ",NA,NA
source DevOps and integration platform which works out of the box on any ,NA,NA
"Kubernetes or OpenShift environment and provides continuous delivery, ",NA,NA
"management, ChatOps, and a Chaos Monkey. We are going to use this one for ",NA,NA
the rest of the chapter.,NA,NA
"Our use case will be using Maven to package the Spring Boot executable JAR, and ",NA,NA
then have that build artifact copied into the Docker image. Using the Maven plugin ,NA,NA
for Docker focuses on two major aspects:,NA,NA
Building and pushing Docker images which contain build artifacts,NA,NA
Starting and stopping Docker containers for integration testing and ,NA,NA
development. This is what we are going to focus on in ,NA,NA
Chapter 6,NA,NA
", ",NA,NA
Running ,NA,NA
Containers with Java Applications,NA,NA
Let's focus on creating an image now starting with the plugin goals and possible ,NA,NA
configuration options.,NA,NA
The fabric8 Docker plugin provides a couple of Maven goals:,docker:build,NA
: This uses the assembly descriptor format from the maven-,NA,NA
assembly-plugin to specify the content which will be added from a sub-,NA,NA
directory in the image (,/maven,NA
 by default),docker:push,NA
: Images that are built with this plugin can be pushed to public or,NA,NA
private Docker registries,docker:start,NA
 and ,docker:stop,NA
: For or starting and stopping the container,docker:watch,NA
: This will execute ,docker:build,NA
 and ,docker:run,NA
 sequentially. It can ,NA,NA
"run forever in the background (separate console), unless you stop it with ",NA,NA
CTRL+C. It can watch for assembly files changing and re-run the build. It saves ,NA,NA
a lot of time,docker:remove,NA
: This is for cleaning up the images and containers,docker:logs,NA
: This prints out the output of the running containers,docker:volume-create,NA
 and ,docker:volume-remove,NA
: For creating and removing ,NA,NA
"volumes, respectively. We will get back to these later in this chapter",NA,NA
"Before we can run these targets, we need to instruct the plugin how it should behave. ",NA,NA
We do it in the plugin configuration in the project's ,pom.xml,NA
 file:,NA,NA
Maven Docker plugin configuration,NA,NA
The important part in the plugin definition is the ,<configuration>,NA
 element. This is ,NA,NA
where you set up the plugin's behavior. There are two main elements in the ,<configuration>,NA
:,NA,NA
A ,<build>,NA
configuration specifying how images are built,NA,NA
A ,<run>,NA
configuration describing how containers should be created and started,NA,NA
Here is a simplest example of the configuration for the ,fabric8,NA
 Maven plugin for ,NA,NA
Docker:,"<plugin>
  
  <groupId>io.fabric8</groupId>
  
  <artifactId>docker-maven-plugin</artifactId> 
 <version>0.20.1</version>
  
  <configuration>
  
   
  <dockerHost>http://127.0.0.1:2375</dockerHost>
   
  <verbose>true</verbose>
  
  <images>
  
   
  <image>
  
    
  <name>rest-example:${project.version}</name>
    
  <build>
  
    
  <dockerFile>Dockerfile</dockerFile>
  
    
  <assembly>
  
     
  <descriptorRef>artifact</descriptorRef>
  
   
  </assembly>
  
    
  </build>
  
   
  </image>
  
  </images>
  
  </configuration> 
  
 </plugin>",NA
The ,<dockerHost>,NA
" specifies the IP address and the port of the running Docker engine,",NA,NA
"so of course, to make it build you will need to have Docker running first. In the ",NA,NA
"previous case, if you run the ",mvn clean package docker:build,NA
" command from the shell, ",NA,NA
the Fabric8 Docker plugin will build the image using the ,Dockerfile,NA
 you provide. But ,NA,NA
"there is another way of building the image, using no ",Dockerfile,NA
" at all, at least not ",NA,NA
"defined explicitly. To do this, we need to change the plugin configuration a bit. Take ",NA,NA
a look at the modified configuration:,"<configuration>
  
  <images>
  
    
  <image>
  
      
  <name>rest-example:${project.version}</name>
  
      
  <alias>rest-example</alias>
  
      
  <build>
  
      
  <from>jeanblanchard/java:8</from>
  
      
  <assembly>
  
         
  <descriptorRef>artifact</descriptorRef>
  
      
  </assembly>
  
      
  <cmd>java -jar      
  
        
  maven/${project.name}-${project.version}.jar</cmd>
  
     
  </build>
  
     
  </image>
  
   
  </images> 
  
 </configuration>",NA
"As you can see, we no longer deliver a ",Dockerfile,NA
". Instead, we just provide the ",Dockerfile,NA
 instructions as plugin configuration elements. It's very convenient because ,NA,NA
"we no longer need to hardcode an executable jar name, version, and so on. It will be ",NA,NA
"taken from the Maven build scope. For example, the name of the jar will be provided ",NA,NA
for the ,<cmd>,NA
 element. It will result in the generation of a valid ,CMD,NA
 instruction in the ,Dockerfile,NA
 automatically. If we now build the project using the ,"mvn clean package 
 docker:build",NA
" command, Docker will build an image with our application. Let's list the ",NA,NA
"configuration elements available for us, alphabetically:",NA,NA
Element,NA,NA
Description,NA,NA
The ,<assembly>,NA
 element defines how to build artifacts and other files ,NA,NA
that can enter the Docker image. You can use ,targetDir,NA
 element to ,NA,NA
provide a directory under which the files and artifacts contained in ,NA,NA
the assembly will be copied into the image. The default value for ,NA,NA
this is ,/maven,NA
". In our example, we will use ",<descriptorRef>,NA
 to provide ,NA,NA
one of the predefined assembly descriptors. The ,<descriptorRef>,NA
 is ,NA,NA
"kind of a handy shortcut, which can take the following values:",NA,NA
: Attaches a project's artifact and all ,NA,NA
"its dependencies. Also, when a classpath file exists in the ",NA,NA
"target directory, this will be added to.",artifact,NA
: Attaches only the project's artifact but no ,NA,NA
dependencies.,project,NA
: Attaches the whole Maven project but without the ,target/,NA
 directory.,rootWar,NA
: Copies the artifact as ,ROOT.war,NA
 to the ,exposed,NA
 directory.,NA,NA
"For example, Tomcat can then deploy the war under ",root,NA
context.,buildArgs,NA
Allows for providing a map specifying the value of Docker ,buildArgs,NA
", which should be used when building the image with an ",NA,NA
external Dockerfile which uses build arguments. The key-value ,NA,NA
syntax is the same as when defining Maven properties (or ,labels,NA
 or ,env,NA
).,buildOptions,NA
A map specifying the build options to provide to the Docker ,NA,NA
daemon when building the image.,cleanup,NA
This is useful to clean up untagged images after each build ,NA,NA
(including any containers created from them). The default value is ,try,NA
" which tries to remove the old image, but doesn't fail the build if ",NA,NA
"this is not possible because, for example, the image is still used by a ",NA,NA
running container.,cmd,NA
This is equivalent to the ,CMD,NA
" instruction we already know about, for ",NA,NA
providing a command to execute by default.,compression,NA
Can take ,none,NA
" (which is the default), ",gzip,NA
", or ",bzip2,NA
 values. It allows ,NA,NA
us to specify the compression mode and how the build archive is ,NA,NA
transmitted to the Docker daemon (,docker:build,NA
).,NA,NA
Equivalent to ,ENTRYPOINT,NA
 in a Dockerfile.,env,NA
Equivalent to ,ENV,NA
 in a Dockerfile.,from,NA
Equivalent to ,FROM,NA
" in a Dockerfile, for specifying a base image.",healthCheck,NA
Equivalent to ,HEALTHCHECK,NA
 in a Dockerfile.,labels,NA
"For defining labels, the same as ",LABEL,NA
 in a Dockerfile.,maintainer,NA
Equivalent to ,MAINTAINER,NA
 in a Dockerfile.,nocache,NA
Used to disable Docker's build layer cache. This can be overwritten ,NA,NA
by setting a system property ,docker.nocache,NA
", when running a Maven ",NA,NA
command.,optimize,NA
If set to true then it will compress all the ,runCmds,NA
 into a single ,RUN,NA
directive. Highly recommended to minimize the number of image ,NA,NA
layers created.,ports,NA
The equivalent of ,EXPOSE,NA
 in a Dockerfile. This is a list of ,<port>,NA
"elements, one for each port to expose. The format can be either pure ",NA,NA
numerical as ,"""8080""",NA
" or with the protocol attached, as ","""8080/tcp""",NA
.,runCmds,NA
Equivalent to ,RUN,NA
", commands to be run during the build process. It ",NA,NA
contains ,<run>,NA
 elements which will be passed to the shell.,NA,NA
Can contain a list of ,<tag>,NA
 elements to provide additional tags which ,NA,NA
an image is to be tagged with after the build.,user,NA
Equivalent to ,USER,NA
" in a Dockerfile, it specifies the user to which the ",NA,NA
Dockerfile should switch.,volumes,NA
Contains a list of ,VOLUME,NA
" equivalents, a list of ",<volume>,NA
 elements to ,NA,NA
create a container volume.,workdir,NA
Equivalent to ,WORKDIR,NA
" from a Dockerfile, a directory to change into ",NA,NA
when starting the container.,NA,NA
"As you can see, the plugin configuration is very flexible, it contains a complete set ",NA,NA
of equivalents for Dockerfile instructions. Let's see how our ,pom.xml,NA
 can look with the ,NA,NA
proper configuration.,NA,NA
The complete ,pom.xml,NA
.,NA,NA
"If you have been following our project from the beginning, the complete Maven ",NA,NA
POM is the same as the following:,"<?xml version=""1.0"" encoding=""UTF-8""?>
  
  <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLS
  
  <modelVersion>4.0.0</modelVersion>
  
  
  <groupId>pl.finsys</groupId>
  
  
  <artifactId>rest-example</artifactId>
  
  
  <version>0.1.0</version>
  
  
  <parent>
  
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  
  <artifactId>spring-boot-starter-
  
  
  
  
  parent</artifactId>
  
  
  
  <version>1.5.2.RELEASE</version>
  
  
  </parent>
  
  
  <dependencies>
  
  
  
  <dependency>
  
  
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  
  
  <artifactId>spring-boot-starter-web</artifactId>
  
  
  
  </dependency>
  
  
  
  <dependency>
  
  
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  
  
  <artifactId>spring-boot-starter-data-
  
  
  
    
  jpa</artifactId>",NA
Building the image,NA,NA
"To build the Docker image with our Spring Boot artifact, run this command:",$ mvn clean package docker:build,NA
The ,clean,NA
 tells Maven to delete the ,target,NA
 directory. Maven will always compile your ,NA,NA
classes with the ,package,NA
 command. It is very important to run the ,package,NA
 command ,NA,NA
with the ,docker:build,NA
 command. You'll encounter errors if you try to run these in two ,NA,NA
"separate steps. While the Docker image is building, you will see the following output ",NA,NA
in the console:,NA,NA
The ID of a new image will be presented in the console output. If you wonder how ,NA,NA
"the automatically generated Dockerfile looks the same as, you will find it in the ",target/docker/rest-example/0.1.0/build,NA
 directory in your project. The first time you ,NA,NA
"build this Docker image, it will take longer since all the layers are being ",NA,NA
downloaded. But every build will be a lot faster thanks to layer caching.,NA,NA
Creating and removing volumes ,NA,NA
The Fabric8 Maven Docker plugin couldn't be a complete solution without the ,NA,NA
"possibility of managing volumes. Indeed, it provides two ways to handle volumes: ",docker:volume-create,NA
 and ,docker:volume-remove,NA
. As you probably remember from ,NA,NA
Chapter ,NA,NA
2,NA,NA
", ",NA,NA
Networking and Persistent Storage,NA,NA
", Docker uses a plugin-like architecture when ",NA,NA
handling volumes and their drivers. The ,fabric8,NA
 plugin can be configured to pass a ,NA,NA
specific volume driver and its parameters to the Docker daemon. Consider the ,NA,NA
following fragment of the plugin configuration: ,"<plugin>
  
  <configuration>
  
  [...]
  
  <volumes>
  
  <volume>
  
  <name>myVolume</name>
  
  <driver>local</driver>
  
  <opts>
  
  <type>tmpfs</type>
  
  <device>tmpfs</device>
  
  <o>size=100m,uid=1000</o>
  
  </opts>
  
  <labels>
  
  <volatileData>true</volatileData>
  
  </labels>",NA
"In the previous example, we create a named volume using the local filesystem driver. ",NA,NA
"It can be mounted during the startup of the container, as specified in the ",<run>,NA
 section ,NA,NA
of the ,pom.xml,NA
 file.,NA,NA
Summary,NA,NA
"In this chapter, we looked at how to get started with Docker containers and ",NA,NA
packaging Java applications. We can do it manually by hand using the ,docker build,NA
command and a ,Dockerfile,NA
 or we can use Maven to automate things. For Java ,NA,NA
"developers, Docker helps isolate our apps in a clean environment. Isolation is ",NA,NA
important because it reduces the complexity of the software environment we're ,NA,NA
using. The Fabric8 Maven Docker plugin is a great tool which we can use to ,NA,NA
"automate our image builds using Maven, especially when dealing with Java ",NA,NA
"applications. No more writing Dockerfiles by hand, we just configure the plugin ",NA,NA
"using the extensive set of options and we are done. Additionally, having this working ",NA,NA
with Maven allows us to easily incorporate Docker builds into our existing ,NA,NA
"development flows, as continuous delivery using Jenkins, for example. In ",NA,NA
Chapter 6,NA,NA
", ",NA,NA
Running Containers with Java Applications,NA,NA
", we will go into more detail about ",NA,NA
"running our Java applications from within a container. Of course, we will use Maven ",NA,NA
"for this, as well.",NA,NA
Running Containers with Java,NA,NA
Applications,NA,NA
In ,NA,NA
Chapter 5,NA,NA
", ",NA,NA
Creating Images with Java Applications,NA,NA
", we learned about the structure ",NA,NA
"of a Dockerfile and how to build our images. At this point, you should be able to ",NA,NA
"create your own Docker image and start using it. Actually, we did run the containers ",NA,NA
"several times, but without getting much into details. We built the image manually, ",NA,NA
"using a Dockerfile, and then issuing a ",docker build,NA
 command. We have also been ,NA,NA
using Maven to automate the build process. The image we have created contains our ,NA,NA
simple REST Java service. We've already been running it for the purpose of ,NA,NA
"checking if it really works. This time, however, we are going into some more detail ",NA,NA
about running the containers from our images. This chapter will include the ,NA,NA
following concepts:,NA,NA
Starting and stopping containers,NA,NA
Container running modes,NA,NA
Monitoring containers,NA,NA
Container restart policies,NA,NA
Runtime constraints on resources,NA,NA
Running containers using Maven,NA,NA
Starting and stopping containers ,NA,NA
Let's go back a little and begin with the basics: how to run and stop the Docker ,NA,NA
"container manually, from the shell or the command line.",NA,NA
Starting,NA,NA
"As you have seen in the previous chapters, to spin-up the container from the image, ",NA,NA
we use the ,docker run,NA
" command. The running container will have its own file system, ",NA,NA
"networking stack, and isolated process tree separate from the host. As you will ",NA,NA
remember from ,NA,NA
Chapter 5,NA,NA
", ",NA,NA
Creating Images with Java Applications,NA,NA
", every single ",docker run,NA
 command creates a new container and executes a command specified in ,NA,NA
"the Dockerfile, ",CMD,NA
", or ",ENTRYPOINT,NA
.,NA,NA
The syntax of the ,docker run,NA
 command is as follows:,$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...],NA
"The command takes the image name, with the optional ",TAG,NA
 or ,DIGEST,NA
. If you skip the ,TAG,NA
 and ,DIGEST,NA
" command parameters, Docker will run the container based on the ",NA,NA
image tagged ,latest,NA
. The ,docker run,NA
 command also takes a set of possible options you ,NA,NA
"may find useful, such as the runtime mode, detached or foreground, network settings, ",NA,NA
or runtime restrictions on CPU and memory. We are going to cover these later in this ,NA,NA
"chapter. Of course, you can execute the ",docker run,NA
 command without almost any ,NA,NA
arguments except the image name. It will run and take the default options defined in ,NA,NA
the image. Specifying options gives you the chance to override the options specified ,NA,NA
by the author of the image and also runtime defaults of the Docker engine.,NA,NA
The ,COMMAND,NA
" parameter is not mandatory, the author of the image may have already ",NA,NA
provided a default ,COMMAND,NA
 using the ,CMD,NA
 instruction in the ,Dockerfile,NA
. The ,CMD,NA
 occurs ,NA,NA
only once in a Dockerfile and it's usually the last instruction. When starting the ,NA,NA
"container from an image, we can override the ",CMD,NA
" instruction, simply by providing ",NA,NA
our own command or parameters as the ,COMMAND,NA
 parameter for the ,docker run,NA
.,NA,NA
Anything that appears after the image name in the ,docker run,NA
 command will be ,NA,NA
passed to the container and treated as ,CMD,NA
 arguments. If the image also specifies an ,ENTRYPOINT,NA
 then the ,CMD,NA
 or ,COMMAND,NA
 gets appended as an argument to the ,ENTRYPOINT,NA
. But ,NA,NA
"guess what, we can override the ",ENTRYPOINT,NA
" as well, using the ",--entrypoint,NA
 option for ,NA,NA
the ,docker run,NA
 command.,NA,NA
Stopping,NA,NA
To stop one or more running Docker containers we use the ,docker stop,NA
 command. ,NA,NA
The syntax is simple:,$ docker stop [OPTIONS] CONTAINER [CONTAINER...],NA
You can specify one or more container to stop. The only option for ,docker stop,NA
 is ,-t,NA
(,--time,NA
) which allows us to specify a time to wait before stopping a container. 10 ,NA,NA
"seconds is the default value, which is supposed to be enough for the container to ",NA,NA
"gracefully stop. To stop the container in a more brutal way, you can execute the ",NA,NA
following command:,$ docker kill  CONTAINER [CONTAINER...],NA
What's the difference between ,docker stop,NA
 and ,docker kill,NA
 ? They will both stop a ,NA,NA
running container. There's an important difference though:,docker stop,NA
: The main process inside the container will first receive a ,SIGTERM,NA
", ",NA,NA
"and after a grace period, a ","SIGKILL
  
  
 docker kill",NA
: The main process inside the container will be sent ,SIGKILL,NA
 (by ,NA,NA
default) or any signal specified with option ,--signal,NA
"In other words, ",docker stop,NA
 attempts to trigger a graceful shutdown by sending the ,NA,NA
standard POSIX signal ,SIGTERM,NA
", whereas ",docker kill,NA
" just brutally kills the process and, ",NA,NA
"therefore, shuts down the container.",NA,NA
Listing the running containers,NA,NA
"To list the running containers, simply execute the ",docker ps,NA
 command:,$ docker ps,NA
"To include all containers present on your Docker host, include the ",-a,NA
 option:,$ docker ps -a,NA
You can also filter the list using ,-f,NA
 option to specify a filter. The filter needs to be ,NA,NA
provided as a ,key=value,NA
 format. Currently available filters include:,id,NA
: Filters by the container's id,label,NA
: Filters by label,name,NA
: Filters by the container's name,exited,NA
: Filters by the container's exit code,status,NA
": Filters by status, which can be created, restarting, running, removing, ",NA,NA
"paused, exited or dead",volume,NA
: When specified with volume name or mount point will include ,NA,NA
containers that mount specified volumes,network,NA
": When specified with network id or name, will include containers ",NA,NA
connected to the specified network,NA,NA
"Consider the following example, which will take all containers present on the ",NA,NA
Docker host and filter them out by running status:,$ docker ps -a -f status=running,NA
Removing the containers,NA,NA
"To remove the container from the host, we use the ",docker rm,NA
 command. The syntax is ,NA,NA
as follows:,$ docker rm [OPTIONS] CONTAINER [CONTAINER...],NA
You can specify a single container or more containers at once. If you are running ,NA,NA
"short-term foreground processes over and over many times, these file systems can ",NA,NA
grow rapidly in size. There's a solution for that: instead of cleaning manually by ,NA,NA
"hand, tell Docker to automatically clean up the container and remove the file system ",NA,NA
when the container exits. You do this by adding the ,--rm,NA
" flag, so that the container ",NA,NA
data is removed automatically after the process has finished.,--rm,NA
 flag will make Docker remove container after it has been shut ,NA,NA
down.,NA,NA
"For example, use the ",run,NA
 command as in the following example:,$ docker run --rm -it Ubuntu /bin/bash,NA
The preceding command tells Docker to remove the container if it's shut down.,NA,NA
"When starting a Docker container, you can decide if you want to run the container in ",NA,NA
"the default mode, in the foreground, or in the background, in the so called detached ",NA,NA
mode. Let's explain what the difference is.,NA,NA
Container running modes ,NA,NA
"Docker has two container running modes, foreground and detached. Let's begin with ",NA,NA
"the default one, the foreground mode.",NA,NA
Foreground,NA,NA
"In the foreground mode, the console you are using to execute ",docker run,NA
 will be ,NA,NA
"attached to standard input, output, and error streams. This is the default; Docker will ",NA,NA
attach ,STDIN,NA
", ",STDOUT,NA
 and ,STDERR,NA
" streams to your shell console. If you need to, you can ",NA,NA
change this behavior and use the ,-a,NA
 switch for the ,docker run,NA
 command. As a ,NA,NA
parameter for the ,-a,NA
" switch, you use the name of the stream you want to attach to the ",NA,NA
console. For example:,$ docker run -a stdin -a stdout -i -t centos /bin/bash,NA
The preceding command will attach both ,stdin,NA
 and ,stdout,NA
 streams to your console.,NA,NA
The useful ,docker run,NA
 options are the ,-i,NA
 or ,--interactive,NA
 (for keeping ,STDIN,NA
 stream ,NA,NA
"open, even if not attached) and ",-t,NA
 or ,-tty,NA
 (for attaching a ,pseudo-tty,NA
") switches, ",NA,NA
commonly used together as ,-it,NA
 which you will need to use to allocate a ,pseudo-tty,NA
"console for the process running in the container. Actually, we used this option in ",NA,NA
Cha ,NA,NA
pter 5,NA,NA
", ",NA,NA
Creating Images with Java Applications,NA,NA
", when we were running our REST ",NA,NA
service:,$ docker run -it rest-example,NA
"Simply speaking, the ",-it,NA
 is used combined to attach the command line to the ,NA,NA
container after it has started. This way you can see what's going on in the running ,NA,NA
"container in your shell console and interact with the container, if needed.",NA,NA
Detached,NA,NA
You can start a Docker container in detached mode with a ,-d,NA
 option. It's the opposite ,NA,NA
"of the foreground mode. The container starts up and runs in background, the same as ",NA,NA
"a daemon or a service. Let's try to run our rest-example in the background, executing ",NA,NA
the following command:,$ docker run -d -p 8080:8080 rest-example,NA
"After the container starts, you will be given a control and can use a shell or ",NA,NA
command line for executing other commands. Docker will just output the container ,NA,NA
"ID, as you can see on the following screenshot:",NA,NA
"You can use the container ID to reference the container in other docker commands, ",NA,NA
"for example, if you need to stop the container or attach to it. Our service, while ",NA,NA
"sitting in the background, still works: the Spring Boot application listens on port ",8080,NA
for ,HTTPGET,NA
 or ,POST,NA
 requests. Take note that containers started in detached mode stop ,NA,NA
when the root process used to run the container exits. Understanding this is ,NA,NA
"important, even if you have some process running in the background (started from ",NA,NA
"the instruction in the Dockerfile), Docker will stop the container if the command that ",NA,NA
"started the container finishes. In our case, Spring Boot application is running and ",NA,NA
"listening, and, at the same time, prevents Docker from shutting down the container.",NA,NA
To bring the container back from the background into the foreground of your ,NA,NA
"console, you will need to attach to it.",NA,NA
Attaching to running containers,NA,NA
"To retain control over a detached container, use ",docker attach,NA
 command. The syntax ,NA,NA
for ,docker attach,NA
 is quite simple:,$ docker attach [OPTIONS] <container ID or name>,NA
"In our case this would be the ID we were given, when the container was started:",$ docker attach 5687bd611f84b53716424fd826984f551251bc95f3db49715fc7211a6bb23840,NA
"At this time, if there is something that gets printed out, such as another log line from ",NA,NA
"our running REST service, you will see it on the console. As you can see, the ","docker 
 attach",NA
 command can come in handy if you need to see what is written to the ,stdout,NA
stream in real time. It will basically ,NA,NA
reattach,NA,NA
 your console to the process running in ,NA,NA
"the container. In other words, it will stream the ",stdout,NA
 into your screen and map the ,stdin,NA
" to your keyboard, allowing you to enter the commands and see their output.",NA,NA
Note that pressing the ,NA,NA
CTRL + C,NA,NA
 keyboard sequence while being attached to the ,NA,NA
"container would kill the running process of the container, not detach from the ",NA,NA
console. To detach from the process use the default ,NA,NA
CTRL+P,NA,NA
 and ,NA,NA
CTRL+Q,NA,NA
 keyboard ,NA,NA
sequence. If the ,NA,NA
CTRL + P,NA,NA
 and ,NA,NA
CTRL + Q,NA,NA
 sequence clashes with your existing ,NA,NA
"keyboard shortcuts, you can provide your own detach sequence by setting the ","--
 detach-keys",NA
 option for the ,docker attach,NA
 command. If you would like to be able to ,NA,NA
detach using ,NA,NA
CTRL + C,NA,NA
", you may tell Docker not to send ",sig-term,NA
 to the process ,NA,NA
running in the container by using the ,sig-proxy,NA
 parameter set to ,false,NA
:,$ docker attach --sig-proxy=false [container-name or ID],NA
"If the container is running in the background, it would be nice to be able to monitor ",NA,NA
its behavior. Docker provides a set of features for doing that. Let's see how we can ,NA,NA
monitor running containers.,NA,NA
Monitoring containers,NA,NA
There are some ways of monitoring running Docker containers. It can be viewing the ,NA,NA
"log files, looking at the container events and statistics, and also inspecting container ",NA,NA
properties. Let's begin with the powerful logging features Docker has. Access to the ,NA,NA
"log entries is crucial, especially if you have your container running in the detached ",NA,NA
runtime mode. Let's see what Docker can offer when it comes to a logging ,NA,NA
mechanism.,NA,NA
Viewing logs,NA,NA
Most applications output their log entries to the standard ,stdout,NA
 stream. If the ,NA,NA
"container is being run in the foreground mode, you will just see it in the console. ",NA,NA
"However, when running a container in detached mode, you will see nothing but the ",NA,NA
"container ID on the console. However, the Docker engine collects all the ",stdout,NA
output from a running container in a history file on the host. You can display it by ,NA,NA
using the ,docker logs,NA
 command. The syntax of the command is as follows:,$ docker logs -f <container name or ID>,NA
The ,docker logs,NA
 command will output just a few last lines of the log into the console. ,NA,NA
"As the container still works in the background (in detached mode), you will be given ",NA,NA
"the prompt back immediately, as you can see on the following screenshot, presenting ",NA,NA
a fragment of the logfile from our REST service:,NA,NA
The ,-f,NA
 flag acts as the same flag in Linux ,tail,NA
" command, it will continuously display ",NA,NA
"new log entries on the console. When you are done, hit ",NA,NA
CTRL + C,NA,NA
 to stop displaying ,NA,NA
log files on the console. Note that this is different from hitting ,NA,NA
CTRL + C,NA,NA
 when ,NA,NA
"attached to the container, where ",NA,NA
CTRL + C,NA,NA
 would kill the process running within the ,NA,NA
"container. This time, it will just stop displaying the log file and it's safe.",NA,NA
"The log file is permanent and available even after the container stops, as long as its ",NA,NA
file system is still present on disk (until it is removed with the ,docker rm,NA
 command).,NA,NA
"By default, the log entries are stored in a JSON file located in the ",/var/lib/docker,NA
directory. You can see the complete path of the log file using the ,docker inspect,NA
command and using a template to extract the ,LogPath,NA
 (we are going to cover ,inspect,NA
and templates in a while).,NA,NA
"We have said that, by default, the log entries will go to the JSON file. But this can be ",NA,NA
"easily changed, because Docker utilizes the concept of logging drivers. By using ",NA,NA
"different drivers, you can pick other storage for your containers log. The default ",NA,NA
driver is the ,json-file,NA
" driver, which just writes out the entries into the JSON file. ",NA,NA
"Each driver can take additional parameters. The JSON driver accepts, for example:","--log-opt max-size=[0-9+][k|m|g]
  
 --log-opt max-file=[0-9+]",NA
"As you may have guessed, it's similar to a rolling file in our Java applications. The ",max-size,NA
 specifies the maximum file size that can be created; after reaching the ,NA,NA
"specified size, Docker will create a new file. You can use the size suffixes ",k,NA
", ",m,NA
", or ",g,NA
", ",NA,NA
"where k will be for kilobytes, ",m,NA
 for megabytes and ,g,NA
 for gigabytes. Splitting a log into ,NA,NA
"separate files makes it easier to transfer, archive, and so on. Also, searching through ",NA,NA
the log file is a lot more convenient if the file is smaller.,NA,NA
The ,docker log,NA
 command only displays log entries from the latest log ,NA,NA
file.,NA,NA
There are some other log drivers available. The list includes:,none,NA
: It will just switch off logging completely,syslog,NA
: It's a ,syslog,NA
 logging driver for Docker. It will write log messages to the ,NA,NA
system ,"syslog
  
  
 journald",NA
: Will log messages to ,journald,NA
. ,systemd-journald,NA
 is a daemon responsible ,NA,NA
"for event logging, with append-only binary files serving as its logfiles",splunk,NA
: Provides the writing of log messages to Splunk using ,Event Http,NA
Collector. Splunk can be used as an enterprise-grade log analyzer. You can read ,NA,NA
more about it at ,NA,NA
https://www.splunk.com,gelf,NA
: Will write log entries into a GELF endpoint such as Graylog or Logstash. ,NA,NA
"Graylog, available at ",NA,NA
https://www.graylog.org,NA,NA
", is an open source log management, ",NA,NA
"supporting search, analysis, and alerting across all of your log files. Logstash, ",NA,NA
which you can find at ,NA,NA
https://www.elastic.co/products/logstash,NA,NA
", is a pipeline for ",NA,NA
processing any data (including log data) from any source,fluentd,NA
: Writes log messages to ,fluentd,NA
. Fluentd is an open source data collector ,NA,NA
for a unified logging layer. The main feature of Fluentd is that it separates data,NA,NA
sources from backend systems by providing a unified logging layer in between.,NA,NA
"It's small, fast and has hundreds of plugins that make a very flexible solution ",NA,NA
out of it. You can read more about ,fluentd,NA
 on its website at ,NA,NA
https://www.fluentd.org,gcplogs,NA
: Will send the log entries to Google Cloud logging,awslogs,NA
: This driver will write log messages to the Amazon CloudWatch logs.,NA,NA
"As you can see, again, the Docker's pluggable architecture gives you almost infinite ",NA,NA
"flexibility when running the container. To switch to the other log driver, use the ","--
 log-driver",NA
 option for the ,docker run,NA
 command. To store log entries in the ,syslog,NA
 for ,NA,NA
"example, execute the following:",$ docker run --log-driver=syslog rest-example,NA
Note that the ,docker logs,NA
 command works only for the ,json-file,NA
 and ,journald,NA
 drivers. ,NA,NA
"To access logs written to another log engine, you will need to use the tool matching ",NA,NA
the driver you have chosen. It will often be more convenient to use the specialized ,NA,NA
"tool for browsing log entries; actually, this is often the reason you choose another ",NA,NA
"logging driver. For example, searching and browsing the logs in Logstash or Splunk ",NA,NA
is way faster than digging though the text files full of JSON entries.,NA,NA
Looking at the log entries is the convenient way of monitoring how our application ,NA,NA
"behaves on the host. Sometimes, it could be also nice to see the properties of the ",NA,NA
"running containers, as the mapped network port or volume being mapped and so on.",NA,NA
"To display the container properties, we use the ",docker inspect,NA
" command, which is ",NA,NA
extremely useful.,NA,NA
Inspecting a container,NA,NA
The ,docker ps,NA
 command we have been using to list the running containers gives us a ,NA,NA
"lot of information about containers, such as their IDs, uptime, mapped ports, and so ",NA,NA
"on. To display more details about the running container, we can user ",docker inspect,NA
.,NA,NA
The syntax of the command is as follows:,$ docker inspect [OPTIONS] CONTAINER|IMAGE|TASK [CONTAINER|IMAGE|TASK...],NA
"By default, the ",docker inspect,NA
 command will output information about the container ,NA,NA
"or image in a JSON array format. Because there are many properties, it may not be ",NA,NA
"very readable. If we know what we are looking for, we can provide a template for ",NA,NA
"processing the output, using the ",-f,NA
 (or ,--format,NA
) option. The template uses the ,NA,NA
"template format coming from the Go language (Docker itself is written in Go, by the ",NA,NA
way). The simplest and the most often used template for the ,docker inspect,NA
 command ,NA,NA
"is just a short template to extract exactly the information you need, for example:",$ docker inspect -f '{{.State.ExitCode}}' jboss/wildfly,NA
As the ,inspect,NA
 command accepts the Go template to form the output of the container ,NA,NA
"or image metadata, this feature gives you almost infinite possibilities for processing ",NA,NA
"and transforming the results. The Go templating engine is quite powerful, so, instead ",NA,NA
"of piping the output through grep, which is quick but messy, you can use the ",NA,NA
template engine to further process the result.,NA,NA
The argument to ,--format,NA
 is a just a template that we want to apply to the metadata of ,NA,NA
"the container. In this template, we can use conditional statements, loops, and other ",NA,NA
"Go language features. For example, the following will find the names of all ",NA,NA
containers with a non-zero exit code:,$ docker inspect -f '{{if ne 0.0 .State.ExitCode }}{{.Name}} {{.State.ExitCode}}{{ end }}' $(,NA
Note that we provide ,$(docker ps -aq),NA
 instead of the container ID or name. As a ,NA,NA
"result, all of the running containers' IDs will be piped to the ",docker inspect,NA
" command, ",NA,NA
which can be quite a handy shortcut. The curly brackets ,{{}},NA
 mean Go template ,NA,NA
"directives, anything outside of them will be printed out literally. The dot (",.,NA
) in Go ,NA,NA
templates means context. Most of the time the current context will be whole data ,NA,NA
"structure for the metadata, but it can be rebound when needed, including using the ",with,NA
" action. For example, these two ",inspect,NA
 commands will print out exactly the same,NA,NA
result:,"$ docker inspect -f '{{.State.ExitCode}}' wildfly
  
 $ docker inspect -f '{{with .State}} {{.ExitCode}} {{end}}' wildfly",NA
"If you are inside the bound context, the dollar sign (",$,NA
) will always get you the ,root,NA
context. We can execute this command:,$ docker inspect -f '{{with .State}} {{$.Name}} exited with {{.ExitCode}} exit code \ {{end}},NA
It will then output:,/wildfly exited with 0 exit code.,NA
"The template engine supports logical functions, such as ",and,NA
", ",or,NA
 and ,not,NA
; they will ,NA,NA
"return a boolean result. Also, the comparison functions are supported, such as ",eq,NA
"(equals), ",ne,NA
" (not equals), ",lt,NA
" (less than), ",le,NA
" (less than or equal to), ",gt,NA
" (greater than), ",NA,NA
and ,ge,NA
" (greater than or equal to). Comparison functions can compare strings, floats or ",NA,NA
integers. Together with the conditional functions such as ,if,NA
", all of these can be very ",NA,NA
useful when creating some more sophisticated output from the ,inspect,NA
 command:,"$ docker inspect -f '{{if eq .State.ExitCode 0.0}} \ 
 Normal Exit \ 
  
 {{else if eq .State.ExitCode 1.0}} \ 
  
 Not a Normal Exit \ 
  
 {{else}} \ 
  
 Still Not a Normal Exit \ 
  
 {{end}}' wildfly",NA
Sometimes the huge output of the ,docker inspect,NA
 command can be quite confusing. ,NA,NA
"Since the output comes in JSON format, the ",jq,NA
 tool can be used to get an overview of ,NA,NA
the output and pick out interesting parts.,NA,NA
The ,jq,NA
 tool is available for free at ,NA,NA
https://stedolan.github.io/jq/,NA,NA
. It's a lightweight and ,NA,NA
"flexible command-line JSON processor, such as ",sed,NA
 command for the JSON data.,NA,NA
"For example, let's extract the container IP address from the metadata:",$ docker inspect <containerID> | jq -r '.[0].NetworkSettings.IPAddress',NA
"As you can see, the ",docker inspect,NA
 command provides useful information about ,NA,NA
Docker containers. Combined with the Go template features and optionally with the ,jq,NA
" tool, it gives you a powerful tool to get the information about your containers and ",NA,NA
can be used further in scripting. But there's another source of valuable information ,NA,NA
"apart from the metadata. It's runtime statistics, which we are going to focus on now.",NA,NA
Statistics,NA,NA
"To see the CPU, memory, disk i/o and network i/o statistics for containers, use the ",docker stats,NA
 command. The syntax for the command is as follows:,docker stats [OPTIONS] [CONTAINER...],NA
You can limit the statistics measure to one or more specific containers by specifying ,NA,NA
"a list of container IDs or names separated by a space. By default, if no containers are ",NA,NA
"specified, the command will display statistics for all running containers, as you can ",NA,NA
see on the following screenshot:,NA,NA
The ,docker stats,NA
" command accepts options, which can include:",--no-stream,NA
: This will disable streaming stats and only pull the first result,-a,NA
 (,--all,NA
): This will show statistics for all (not only running) containers,NA,NA
The statistics can be used to see if our containers behave well when running. The ,NA,NA
information can be useful to check if we need some constraints on the resources to ,NA,NA
"be applied to containers, we are going to cover the runtime constraints in a while in ",NA,NA
this chapter.,NA,NA
"Viewing logs, container metadata and runtime statistics, give you almost infinite ",NA,NA
"possibilities when monitoring your running containers. Apart from this, we can see ",NA,NA
what's happening on your docker host globally. When the docker engine on the host ,NA,NA
"receives a command, it will emit an event we can observe. Let's look at this ",NA,NA
mechanism now.,NA,NA
Container events,NA,NA
"To observe the events coming to the docker engine in real time, we use the ","docker 
 events",NA
" command. If the container has been started, stopped, paused, and so on, the ",NA,NA
event will be published. This can be very useful if you would like to know what has ,NA,NA
happened during the container runtime. It's a powerful monitoring feature. Docker ,NA,NA
"containers report a huge list of events, which you can list with the ",docker events,NA
command. The list includes:,"attach, commit, copy, create, destroy, detach, die, exec_create, exec_detach, exec_start, exp",NA
The ,docker events,NA
 command can take the ,-f,NA
" switch, which will filter the output if you ",NA,NA
"are looking for something specific. If no filter is provided, all events will be ",NA,NA
reported. Currently the list of possible filters includes:,NA,NA
container (,container=<name or id>,NA
),NA,NA
event (,event=<event action>,NA
),NA,NA
image (,image=<tag or id>,NA
),NA,NA
plugin (experimental) (,plugin=<name or id>,NA
),NA,NA
label (,label=<key> or label=<key>=<value>,NA
),NA,NA
type (,type=<container or image or volume or network or daemon>,NA
),NA,NA
volume (,volume=<name or id>,NA
),NA,NA
network (,network=<name or id>),NA
daemon (,daemon=<name or id>,NA
),NA,NA
Take a look at the following example. The ,docker events,NA
 command has been run in ,NA,NA
"one console window, while the ",docker run rest-example,NA
 has been issued in the separate ,NA,NA
"console. As you can see in the following screenshot, ",docker events,NA
" will report create, ",NA,NA
"attach, connect and start events for our rest-example container:",NA,NA
"As a result, you will get a timestamp and the name of the event, together with the ID ",NA,NA
of the container that has caused an event. The ,docker events,NA
 command can take ,NA,NA
"additional options, such as ",--since,NA
 and ,--until,NA
", which can be used to specify a ",NA,NA
timeframe that you want to get the events from. Monitoring container events is a ,NA,NA
"great tool to see what's going on the docker host. However, there's more. You can ",NA,NA
"also influence, how your containers behave in case of a crash, for example. We use ",NA,NA
container restart policies for that.,NA,NA
Restart policies,NA,NA
By using the ,--restart,NA
 option with the ,docker run,NA
 command you can specify a restart ,NA,NA
policy. This tells Docker how to react when a container shuts down. The container ,NA,NA
"then can be restarted to minimize downtime, for example if running on a production ",NA,NA
"server. However, before we explain the Docker restart policy, let's focus for a while ",NA,NA
"on exit codes. The exit code is crucial information, it tells why the container failed to ",NA,NA
run or why it exited. Sometimes it's related to the contained command you will give ,NA,NA
to the ,docker run,NA
 as a parameter. When the ,docker run,NA
 command ends with a non-zero ,NA,NA
"code, the exit codes follow the ",chroot,NA
" standard, as you can see here:",NA,NA
exit code ,125,NA
: The ,docker run,NA
 command fails by itself,NA,NA
exit code,126,NA
: The supplied command cannot be invoked,NA,NA
exit code ,127,NA
: The supplied command cannot be found,NA,NA
"Other, non-zero, application dependent exit code",NA,NA
"As you may remember, in previous chapters we have been using the ",docker ps,NA
"command to list running containers. To list the non-running containers as well, we ",NA,NA
can add the ,-a,NA
 switch for the ,docker ps,NA
 command. The exit code can be found in the ,NA,NA
output of the ,docker ps -a,NA
 command in a Status column when a container completes. ,NA,NA
It's possible to automatically restart crashed containers by specifying a restart policy ,NA,NA
when starting the container. Specifying the desired restart policy is done by the -,NA,NA
restart switch for the ,docker run,NA
" command, as in the example:",$ docker run --restart=always rest-example,NA
Currently Docker has four restart policies. Let's get to know them now one by ,NA,NA
"one, starting with the simplest: ",no,NA
.,NA,NA
no,NA,NA
The ,no,NA
 policy is the default restart policy and simply will not restart a container ,NA,NA
"under any case. Actually, you do not have to specify this policy, because this is the ",NA,NA
"default behavior. Unless you have some configurable setup to run Docker containers, ",NA,NA
then the ,no,NA
 policy can be used as an off switch.,NA,NA
always,NA,NA
If we wanted the container to be restarted no matter what exit code the command ,NA,NA
"has, we can use the ",always,NA
" restart policy. Basically, it does what it says; Docker will ",NA,NA
restart the container in every case. The restart policy will always restart the ,NA,NA
"container. This is true, even if the container has been stopped before the reboot. ",NA,NA
"Whenever the Docker service is restarted, containers using the always policy will ",NA,NA
"also be restarted, it doesn't matter whether they were executing or not.",NA,NA
With the ,always,NA
" restart policy, the Docker daemon will try to restart the ",NA,NA
container ,NA,NA
indefinitely.,NA,NA
on-failure,NA,NA
This is a kind of special restart policy and probably the most often used. By using the ,on-failure,NA
" restart policy, you instruct Docker to restart your container whenever it ",NA,NA
exits with a non-zero exit status and not restart otherwise. That's the reason we have ,NA,NA
begun explaining restart policies with the exit codes. You can optionally provide a ,NA,NA
number of times for Docker to attempt to restart the container. The syntax of this ,NA,NA
"restart policy is also a little bit different, because using this policy, you can also ",NA,NA
specify a maximum number of tries that Docker will make to automatically restart ,NA,NA
the container.,NA,NA
Consider this example:,$ docker run --restart=on-failure:5 rest-example,NA
The preceding command will run the container with our REST service and will try to ,NA,NA
restart it five times in the case of failure before giving up. The main benefit of the ,"on-
 failures",NA
" restart policy is that, when an application exits with a successful exit code ",NA,NA
"(that means there were no errors in the application; it just finished executing), the ",NA,NA
container will not be restarted. The number of restart tries for a container can be ,NA,NA
obtained via the ,docker inspect,NA
" command we already know. For example, to get the ",NA,NA
number of restarts for a container with a specific ID or name:,"$ docker inspect -f ""{{ .RestartCount }}"" <ContainerID>",NA
You can also discover the last time the container was started again:,"$ docker inspect -f ""{{ .State.StartedAt }}"" <ContainerID>",NA
"You should know that Docker uses a delay between restarting the container, to ",NA,NA
prevent flood-like protection. This is an increasing delay; it starts with the value of ,NA,NA
"100 milliseconds, then Docker will double the previous delay. In effect, the daemon ",NA,NA
"will wait for 100 ms, then 200 ms, 400, 800 and so on, until either the ",on-failure,NA
"limit is reached, or when you stop the container using ","docker stop,",NA
 or execute the ,NA,NA
force removal by executing the ,docker rm -f,NA
 command.,NA,NA
"If a container is successfully restarted, the delay is reset to the default ",NA,NA
value of 100 milliseconds.,NA,NA
unless-stopped,NA,NA
"Again, similar to ",always,NA
", if we want the container to be restarted regardless of the exit ",NA,NA
"code, we can use ",unless-stopped,NA
. The ,unless-stopped,NA
 restart policy acts the same as ,always,NA
" with one exception, it will restart the container regardless of the exit status, but ",NA,NA
do not start it on daemon startup if the container has been put to a stopped state ,NA,NA
before. This means that with the ,unless-stopped,NA
" restart policy, if the container was ",NA,NA
"running before the reboot, the container would be restarted once the system restarted.",NA,NA
"When an application within a Docker container exits, that container will be also ",NA,NA
"halted. If an application that is running within a container crashes, the container ",NA,NA
stops and that container will remain stopped until someone or something restarts ,NA,NA
it.,NA,NA
"Before you apply the restart policy to your container, it's good to think first what ",NA,NA
kind of work the container will be used to do. That also depends on the kind of ,NA,NA
"software that will be running on the container. A database, for example, should ",NA,NA
probably have the ,always,NA
 or ,unless-stopped,NA
 policy applied. If your container has some ,NA,NA
"restart policy applied, it will be shown as ",Restarting,NA
 or ,Up,NA
 status when you list your ,NA,NA
container using the ,docker ps,NA
 command.,NA,NA
Updating a restart policy on a running,NA,NA
container,NA,NA
"Sometimes, there's a need to update the Docker runtime parameters after the ",NA,NA
"container has already started, ",NA,NA
on the fly,NA,NA
. An example would be if you want to prevent ,NA,NA
containers from consuming too many resources on the Docker host. To set the policy ,NA,NA
"during runtime, we can use the ",docker update,NA
 command. Apart from other runtime ,NA,NA
"parameters (such as memory or CPU constraints for example, which we are going to ",NA,NA
"discuss later in this chapter), the ",docker update,NA
 command gives you the option to ,NA,NA
"update the restart policy on a running container. The syntax is quite straightforward, ",NA,NA
you just need to provide the new restart policy that you would like the container to ,NA,NA
have and the container's ID or name:,$ docker update --restart=always <CONTAINER_ID or NAME>,NA
A new restart policy will take effect immediately after you run the ,docker update,NA
"command on a container. On the other hand, if you execute the ",update,NA
 command on a ,NA,NA
"container that is stopped, the policy will be used when you start the container later ",NA,NA
on. The possible options are exactly the same as those you can specify when starting ,NA,NA
the container:,no,NA
 (which is default),"always
  
  
 on-failure
  
  
 unless-stopped",NA
"If you have more than one container running on the Docker host, and",NA,NA
"want to specify a new restart policy on all of them at once, just provide ",NA,NA
"all of their IDs or names, separated by a space.",NA,NA
You can also see which restart policy was applied using the ,docker events,NA
" command, ",NA,NA
which you already know from the previous section. The ,docker events,NA
 which can be ,NA,NA
"used to observe the history of runtime events that the container has reported, will ",NA,NA
also report the ,docker update,NA
" event, providing you with details about what has ",NA,NA
"changed. If the container has been applied the restart policy, the event will be ",NA,NA
published. If you want to check the restart policy of a running container use ,"docker 
 inspect",NA
 with the container ID or name with the ,--format,NA
 argument set for the path of,NA,NA
the value:,$ docker inspect --format '{{ .HostConfig.RestartPolicy.Name }}' <ContainerID>,NA
The ability to set a restart policy on a container by container basis is great for those ,NA,NA
cases where your images are self-contained and you don't need to do more complex ,NA,NA
orchestration tasks. The restart policy is not the only parameter you can change on ,NA,NA
running containers.,NA,NA
Runtime constraints on resources ,NA,NA
It may be useful to restrict the Docker container usage of resources when running. ,NA,NA
"Docker gives you a many possibilities to set constraints on the memory, CPU usage ",NA,NA
or disk access usage. Let's begin with setting the memory constraints.,NA,NA
Memory,NA,NA
"It's worth knowing that, by default, that is, if you use the default settings without any ",NA,NA
"constraints, the running container can use all of the host memory. To change this ",NA,NA
behavior we can use the ,--memory,NA
 (or ,-m,NA
 for short) switch for the ,docker run,NA
 command.,NA,NA
It takes the usual suffixes ,k,NA
", ",m,NA
", or ",g,NA
" for kilobytes, megabytes and gigabytes, ",NA,NA
respectively.,NA,NA
The syntax of the ,docker run,NA
 command with memory constraints set will be as ,NA,NA
follows:,$ docker run -it -m 512m ubuntu,NA
The preceding command will execute the Ubuntu image with the maximum memory ,NA,NA
that can be used by the container of half of a gigabyte.,NA,NA
"If you do not set the limit on memory that the container can allocate, ",NA,NA
this can lead to random issues where a single container can easily ,NA,NA
make the whole host system unstable and/or unusable. So it's a wise ,NA,NA
decision to always use the memory constraints on the container.,NA,NA
"Apart from user memory limit, there are also memory reservation and kernel ",NA,NA
memory constraints. Let's explain what a memory reservation limit is. Under normal ,NA,NA
"working conditions, a running container can, and probably will, use as much of the ",NA,NA
"memory as needed, up to the limit you have set using the ",--memory,NA
 (,-m,NA
) switch for the ,docker run,NA
" command. When memory reservation is applied, Docker will detect a low ",NA,NA
memory situation and will try to force the container to restrict its consumption up to ,NA,NA
"a reservation limit. If you do not set the memory reservation limit, it will be exactly ",NA,NA
the same as the hard memory limit set with the ,-m,NA
 switch.,NA,NA
Memory reservation is not a hard limit feature. There's no guarantee the limit won't ,NA,NA
be exceeded. The memory reservation feature will attempt to ensure that memory ,NA,NA
"will be allocated, based on the reservation setting.",NA,NA
Consider the following example:,$ docker run -it -m 1G --memory-reservation 500M ubuntu /bin/bash,NA
The preceding command sets the hard memory limit to ,1g,NA
", and then sets the memory",NA,NA
"reservation to half a gig. With those constraints set, when the container consumes ",NA,NA
memory more than ,500M,NA
 and less than ,1G,NA
", Docker will attempt to shrink container ",NA,NA
memory less than ,500M,NA
.,NA,NA
In the next example we are going to set the memory reservation without setting the ,NA,NA
hard memory limit:,$ docker run -it --memory-reservation 1G ubuntu /bin/bash,NA
"In the preceding example, when the container starts, it can use as much memory as ",NA,NA
its processes need. The ,--memory-reservation,NA
 switch setting will prevent the container ,NA,NA
"from consuming too much memory for a long time, because every memory reclaim ",NA,NA
will shrink the container's memory usage to the size specified in the reservation.,NA,NA
"The kernel memory is something entirely different from the user memory, the main ",NA,NA
difference is that kernel memory can't be swapped out to disk. It includes stack ,NA,NA
"pages, slab pages, sockets memory pressure and TCP memory pressure. You use ",NA,NA
the--kernel-memory switch to set up the kernel memory limit to constrain these ,NA,NA
"kinds of memory. As with setting the user memory limit, just provide a number with ",NA,NA
a suffix such as ,k,NA
", ",b,NA
", and ","g,",NA
" for kilobyte, megabyte or gigabyte respectively, although ",NA,NA
setting it in kilobytes may be a really rare case.,NA,NA
"For example, every process eats some stack pages. By restricting kernel memory, ",NA,NA
you can prevent new processes from being started when the kernel memory usage is ,NA,NA
"too high. In addition, because the host cannot swap the kernel memory to disk, the ",NA,NA
container can block the whole host service by consuming too much kernel memory.,NA,NA
Setting the kernel memory limit is straightforward. We can set the ,--kernel-memory,NA
"alone, without limiting the total memory with ",-m,NA
", as in the following example:",$ docker run -it --kernel-memory 100M ubuntu  /bin/bash,NA
"In the preceding example, the process in the container can take memory as it needs, ",NA,NA
but it can only consume ,100M,NA
 of kernel memory. We can also setup the hard memory ,NA,NA
"limit, as in the following command:",$ docker run -it -m 1G --kernel-memory 100M ubuntu /bin/bash,NA
"In the preceding command, we set memory and kernel memory altogether, so the ",NA,NA
processes in the container can use ,1G,NA
" memory in total, and this ",1G,NA
 will include ,100M,NA
 of ,NA,NA
the kernel memory.,NA,NA
One more constraint related to the memory which can be useful when running ,NA,NA
"containers, is the swappines constraint. We apply the constraint by using the ","--
 memory-swappiness",NA
 switch to the ,docker run,NA
 command. It can be helpful when you want ,NA,NA
to avoid performance drops related to memory swapping. The parameter for the ,"--
 memory-swappiness",NA
 switch is the percentage of anonymous memory pages that can be ,NA,NA
"swapped out, so it takes values from ",0,NA
 to ,100,NA
". Setting the value to zero, will, ",NA,NA
"depending on your kernel version, disable swapping or use the minimal swap. In ",NA,NA
"contrast, a value of ",100,NA
 sets all anonymous pages as candidates for swapping out. For ,NA,NA
example:,$ docker run -it --memory-swappiness=0 ubuntu /bin/bash,NA
"In the preceding command, we turn the swapping completely for our ",ubuntu,NA
container.,NA,NA
"Apart from setting the memory usage constraint, you can also instruct Docker how ",NA,NA
the processor power should be assigned to containers it's going to run.,NA,NA
Processors,NA,NA
By using the ,-c,NA
 (or ,--cpu-shares,NA
 as an equivalent) for the ,docker run,NA
" command switch, ",NA,NA
it's possible to specify a value of shares of the CPU that a container can allocate. By ,NA,NA
"default, every new container has 1024 shares of CPU and all containers get the same ",NA,NA
part of CPU cycles. This percentage can be altered by shifting the container's CPU ,NA,NA
share weighting relative to the weighting of all other running containers. But take ,NA,NA
"note, that you cannot set the precise processor speed that a container can use. This is ",NA,NA
a ,NA,NA
relative weight ,NA,NA
"and has nothing to do with the real processor speed. In fact, there ",NA,NA
is no way to say precisely that a container should have the right to use only 2 GHz of ,NA,NA
the host's processor.,NA,NA
"CPU share is just a number, it's not related at all to the CPU speed.",NA,NA
"If we start two containers and both will use 100% CPU, the processor time will be ",NA,NA
divided equally between the two containers. The reason for that is two containers ,NA,NA
will have the same number of processor shares. But if you constrain one container's ,NA,NA
"processor shares to 512, it will receive just a half of the CPU time. This does not ",NA,NA
mean that it can use only half of the CPU; the proportion will only apply when CPU-,NA,NA
intensive processes are running. If the other container (with ,1024,NA
" shares) is idle, our ",NA,NA
container will be allowed to use 100% of the processor time. The real amount of ,NA,NA
CPU time will differ depending on the number of containers running on the system. ,NA,NA
It's easier to understand on a tangible example.,NA,NA
"Consider three containers, one (let's call it ",Container1,NA
) has ,--cpu-shares,NA
 set for ,1024,NA
 and ,NA,NA
two others (,Container2,NA
 and ,Container3,NA
) have a ,--cpu-shares,NA
 setting of ,512,NA
. When ,NA,NA
"processes in all three containers attempt to use all of the CPU power, ",Container1,NA
 will ,NA,NA
"receive 50% of the total CPU time, because it has half of the CPU usage allowed in ",NA,NA
comparison to the sum of other running containers (,Container2,NA
 and ,Container3,NA
). If we ,NA,NA
add a fourth container (,Container4,NA
) with a ,--cpu-share,NA
" of 1024, our first ",Container1,NA
 will ,NA,NA
"only get 33% of the CPU, because it now has one third of the total CPU power ",NA,NA
"assigned, relatively. ",Container2,NA
" will receive 16.5%, ",Container3,NA
 also 16.5% and the last ,NA,NA
"one, ",Container4,NA
", again, will be allowed to use 33% of the CPU.",NA,NA
While the ,-c,NA
 or ,--cpu_shares,NA
 flag for the ,docker run,NA
 command modifies the container's ,NA,NA
"CPU share weighting relative to the weighting of all other running containers, it does",NA,NA
not restrict the container's use of CPU from the host machine. But there's another ,NA,NA
flag to limit the CPU usage for the container: ,--cpu-quota,NA
. Its default value is ,100000,NA
which means an allowance of 100% of the CPU usage. We can use the ,--cpu-quota,NA
 ,NA,NA
"to limit CPU usage, for example:",$ docker run -it  --cpu-quota=50000 ubuntu /bin/bash,NA
"In the preceding command, the limit for the container will be 50% of a CPU ",NA,NA
resource. The ,--cpu-quota,NA
 is usually used in conjunction with the ,--cpu-period,NA
 flag for ,NA,NA
the ,docker run,NA
. This is the setting for the CPU CFS (Completely Fair Scheduler) ,NA,NA
period. The default period value is 100000 which is 100 milliseconds. Take a look at ,NA,NA
the example:,$ docker run -it --cpu-quota=25000 --cpu-period=50000  ubuntu /bin/bash,NA
It means that the container can get 50% of the CPU usage every 50 ms.,NA,NA
Limiting CPU shares and usage is not the only processor-related constraint we can ,NA,NA
set on the container. We can also assign the container's processes to a particular ,NA,NA
processor or processor core. The ,--cpuset,NA
 switch of the ,docker run,NA
 command comes in ,NA,NA
handy when we want to do this. Consider the following example:,$ docker run -it --cpuset 4 ubuntu,NA
The preceding command will run the ,ubuntu,NA
 image and allow the container to use all ,NA,NA
four processor cores. To start the container and only allow usage of one processor ,NA,NA
"core, you can change the ",--cpuset,NA
 value to ,1,NA
:,$ docker run -it --cpuset 1 ubuntu,NA
You can of course mix the option ,--cpuset,NA
 with ,--cpu_shares,NA
 to tweak you ,NA,NA
container's CPU constraints.,NA,NA
Updating constraints on a running,NA,NA
container,NA,NA
"As with the restart policies, the constraints can also be updated when the container is ",NA,NA
"already running. This may be helpful, if you see your containers eating too much of ",NA,NA
"the Docker host system resources and would like to limit this usage. Again, we use ",NA,NA
the ,docker update,NA
 command to do this.,NA,NA
"As with restart policies, the syntax for the ",docker update,NA
 command will be the same as ,NA,NA
"when starting the container, you specify the desired constraints as an argument for ",NA,NA
the docker update command and then give the container ID (taken from the ,docker ps,NA
"command output for example) or its name. Again, if you would like to change the ",NA,NA
"constraints on more than one container at once, just provide their IDs or names ",NA,NA
separated by a space. Let's look at some examples of how to update constraints at ,NA,NA
runtime:,$ docker update --cpu-shares 512 abbdef1231677,NA
The preceding command will limit the CPU shares to the value of 512. Of ,NA,NA
"course, you can apply CPU and memory constraints at the same time, to more ",NA,NA
than one container:,docker update --cpu-shares 512 -m 500M abbdef1231677 dabdff1231678,NA
The preceding command will update CPU shares and memory limits to two ,NA,NA
"containers, identified by ",abbdef1231677,NA
 and ,dabdff1231678,NA
.,NA,NA
"Of course, when updating the runtime constraints, you can also apply the desired ",NA,NA
"restart policy in one single command, as in the following example:",$ docker update --restart=always -m 300M aabef1234716,NA
"As you can see, the ability to set constraints gives you a lot of flexibility when ",NA,NA
"running Docker containers. But it's worth noting, that applying constraints is not ",NA,NA
always possible. The reason for that is the constraint setting features depend heavily ,NA,NA
"of the internals of the Docker host, especially its kernel. For example, it's not always ",NA,NA
possible to set up the kernel memory limit or ,memory swappiness,NA
" for example, ",NA,NA
sometimes all you will get is ,Your kernel does not support kernel memory limit or,NA
 messages. Sometimes those ,NA,NA
"limitations can be configurable, sometimes not. For example if you get ","WARNING: Your 
 kernel does not support cgroup swap limit on Ubuntu",NA
", you can tweak your Grub ",NA,NA
bootloader with the ,cgroup_enable=memory swapaccount=1,NA
 setting in the Grub ,NA,NA
"configuration file, this will be ",/etc/default/grub,NA
" in Ubuntu, for example. It's ",NA,NA
"important to read logs printed out by Docker, to make sure your constraints are in ",NA,NA
place.,NA,NA
Always take note of the warnings Docker outputs during the container ,NA,NA
"startup or after updating your constraints on the fly, it may happen that ",NA,NA
your constraints will not take action!,NA,NA
We already know how to run and observe containers using the commands available ,NA,NA
"from the command line. It's not very convenient, however, if you need to spin-up ",NA,NA
"your containers during the development flow, for example for integration testing. ",NA,NA
The Fabric8 Docker Maven plugin we've been using in ,NA,NA
Chapter 5,NA,NA
", ",NA,NA
Creating Images ,NA,NA
with Java Applications,NA,NA
", to build images, comes in handy if we need to run ",NA,NA
"containers, as well. Let's do it now.",NA,NA
Running with Maven,NA,NA
The plugin provides two Maven goals related to starting and stopping containers. ,NA,NA
This will be ,docker:start,NA
 and ,docker:stop,NA
. Containers are created and started with the ,docker:start,NA
 and stopped and destroyed with the ,docker:stop,NA
. If you need to run the ,NA,NA
"container during the integration tests, the typical use case will be to include those ",NA,NA
goals in Maven build phases: the ,docker:start,NA
 will be bound to the ,"pre-integration-
 test",NA
 and ,docker:stop,NA
 to the ,post-integration-test,NA
 phase.,NA,NA
Plugin configuration,NA,NA
The plugin uses the configuration from the ,<run>,NA
 sub-element of the ,<configuration>,NA
 in ,NA,NA
the ,pom.xml,NA
 file. The list of the most important configuration elements is as follows:,"cmd
  
 entrypoint
  
 log
  
 memory",NA
Command which should be executed at the end of the container's startup. If ,NA,NA
the image's default command is used.,NA,NA
Entry point for the container.,NA,NA
Log configuration for whether and how log messages from the running ,NA,NA
cont,NA,NA
be printed. This can also configure the log driver to use.,NA,NA
Memory limit in bytes,NA,NA
Naming strategy for how the container name is created:,NA,NA
n,"amingStrategy
  
 none",NA
: Uses randomly assigned names from Docker (default) ,alias,NA
: Uses the alias specified in the image configuration. An error is ,NA,NA
t,NA,NA
container already exists with this name.,NA,NA
The ,<network>,NA
 element can be used to configure the network mode of the ,NA,NA
con knows the following sub elements:,<mode>,NA
": The network mode, which can be one of the following values: ",bridge,NA
: Bridged mode with the default Docker bridge (default) ,host,NA
: Share the Docker host network interfaces,"network 
  
 container",NA
: Connect to the network of the specified container,NA,NA
The name of the container is taken from the ,<name>,NA
 element :,NA,NA
": Use a custom network, which must be created before using ",NA,NA
Doc create ,none,NA
 : No network will be setup,NA,NA
The,<ports>,NA
configuration contains a list of port mappings. Each mapping ,NA,NA
"has parts, each separate by a colon. This is equivalent to the port mapping ",NA,NA
when ,docker run,NA
 command with option ,-p,NA
.,ports,NA
An example entry can look same as this:,"<ports> 
  
 <port>8080:8080</port> 
  
 </ports>",NA
Provides a restart policy we've been discussing earlier in this chapter. An ,NA,NA
ex can look same as following:,"restartPolicy 
  
 <restartPolicy> 
  
 <name> on-failure</name> 
  
 <retry>5</retry> 
  
 </restartPolicy>",NA
Volume configuration for binding to host directories and from other ,NA,NA
contain example configuration could look same as following:,"volumes 
  
 <volumes> 
  
 <bind> 
  
 <volume>/logs</volume><volume>/opt/host_export:/opt/container_import</volu
 m </volumes>",NA
The complete ,<configuration>,NA
 element of our Java REST service can look same as ,NA,NA
"following. This is a very basic example, we are only configuring the runtime ",NA,NA
port mapping here:,"<configuration> 
  
 <images> 
  
 <image> 
  
 <name>rest-example:${project.version}</name> 
  
 <alias>rest-example</alias> 
  
 <build> 
  
 <from>openjdk:latest</from> 
  
 <assembly> 
  
 <descriptorRef>artifact</descriptorRef> 
  
 </assembly>",NA
"Having configured our container, let's try to run it, using Maven.",NA,NA
Starting and stopping containers,NA,NA
"To start-up the container, execute the following:",$ mvn clean package docker:start,NA
"Maven will build our REST service from source, build the image and start up the ",NA,NA
"container in the background. As the output, we will be given the ID of the container, ",NA,NA
as you can see on the following screenshot:,NA,NA
"The container is now running in the background. To test if it's running, we could ",NA,NA
issue a ,docker ps,NA
" to list all the running containers, or just call the service by executing ",NA,NA
some ,HTTP,NA
 methods such as ,GET,NA
 or ,POST,NA
 on the mapped ,8080,NA
 port. The port has been ,NA,NA
exposed in the,<build>,NA
 configuration element and exposed in the ,<run>,NA
 configuration ,NA,NA
"element. This is convenient, isn't it? But what if we would like to see the container's ",NA,NA
output instead of running it in the background? That's also easy; let's stop it first by ,NA,NA
issuing the following command:,$ mvn docker:stop,NA
"After 10 seconds (as you'll remember, it's a default timeout before stopping the ",NA,NA
"container), Maven will output a statement that the container has been stopped:","[INFO] DOCKER> [rest-example:0.1.0] ""rest-example"": Stop and removed container 51660084f0d8 a",NA
"Let's run the container again, this time using the Maven ",docker:run,NA
 goal instead of ,docker:start,NA
. Execute the following:,$ mvn clean package docker:run,NA
"This time, Maven Docker plugin will run the container and we will see the Spring ",NA,NA
"Boot banner on the console, as you can see on the following screenshot:",NA,NA
I guess you can identify the difference between ,docker:start,NA
 and ,docker:run,NA
 now. ,NA,NA
"Correct, ",docker:run,NA
 is the equivalent of option ,-i,NA
 for the ,docker run,NA
 command. The ,docker:run,NA
 will also automatically switch on the ,showLogs,NA
" option, so that you can see ",NA,NA
"what is happening within the container. As an alternative, you can provide ",docker.follow,NA
 as system property so that the ,docker:start,NA
 will never return but block ,NA,NA
until ,NA,NA
CTRL + C,NA,NA
" is pressed, exactly the same as when you execute the ",docker:run,NA
Maven goal.,NA,NA
"As you can see, the Fabric8 Docker Maven plugin gives you the same control as you ",NA,NA
would have when running and stopping containers from the shell or the command ,NA,NA
line. But here comes the advantage of the Maven build process itself: you can ,NA,NA
"automate things. The Docker containers can be now used during the build, the ",NA,NA
"integration testing, and the continuous delivery flow you may have; you name it.",NA,NA
Summary,NA,NA
"In this chapter we have learned how to manage the container's life, start it using ",NA,NA
"different run modes (foreground and detached), stop or remove it. We also know ",NA,NA
"how to create constraints to make our containers run exactly how we want them to, ",NA,NA
by limiting the CPU and RAM usage using runtime constraints. Having our ,NA,NA
"containers running, we are now able to inspect the container's behavior in numerous ",NA,NA
"ways, it will be reading log output, looking at events or browsing the statistics. If you ",NA,NA
"are using Maven, and as the Java developer you probably are, you can now configure ",NA,NA
the Docker Maven plugin to start or stop containers for you automatically.,NA,NA
"We know a lot about Docker already, we can build and run images. It's time to go ",NA,NA
"further. We are going automate deployment, scaling, and management of ",NA,NA
containerized applications using Kubernetes. And this is the moment where the real ,NA,NA
fun begins.,NA,NA
Introduction to Kubernetes,NA,NA
After reading ,NA,NA
Chapter 6,NA,NA
", ",NA,NA
Running Containers with Java Applications,NA,NA
", you now have a ",NA,NA
lot of knowledge about using Docker to package your Java applications. It's now ,NA,NA
time to move even further and focus on what we are missing--the container ,NA,NA
"management and orchestration. There are some suitable tools on the market, such as ",NA,NA
"Nomad, Docker Swarm, Apache Mesos, or AZK, for example. In this chapter, we ",NA,NA
"will focus on probably the most popular one, Kubernetes. Kubernetes (sometimes ",NA,NA
"referred to as k8s) is an open source orchestration system for Docker containers, ",NA,NA
created by Google in 2015. The first unified container management system ,NA,NA
"developed at Google was the system, internally called, Borg; Kubernetes is its ",NA,NA
descendant. The list of topics covered in this chapter will be:,NA,NA
Why and when we need container management,NA,NA
An introduction to Kubernetes,NA,NA
Basic Kubernetes concepts,NA,NA
"Let's begin with answering the question, why do we even need Kubernetes? We will ",NA,NA
look at the reasoning behind container management and orchestration.,NA,NA
Why do we need Kubernetes?,NA,NA
"As you already know, Docker containers provide great flexibility for running Java ",NA,NA
"services packaged into small, independent pieces of software. Docker containers ",NA,NA
make components of your application portable--you can move individual services ,NA,NA
across different environments without needing to worry about the dependencies or ,NA,NA
the underlying operating system. As long as the operating system is able to run the ,NA,NA
"Docker engine, your Java containers can run on this system.",NA,NA
"Also, as you remember from ",NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", the Docker concept of ",NA,NA
isolating containers is far from the traditional virtualization. The difference is that ,NA,NA
"Docker containers utilize the resources of the host operating system--they are light, ",NA,NA
"fast, and easy to spin up. It's all very nice, but there are some risks. Your application ",NA,NA
"consists of multiple, independent microservices. The number of services can, and ",NA,NA
"probably will, grow in time. Also, if your application starts to experience a higher ",NA,NA
"load, it would be nice to increase the number of containers with the same service, ",NA,NA
just to distribute the load. It doesn't mean you only need to use your own server ,NA,NA
infrastructure--your containers can go to the cloud. Today we have a lot of cloud ,NA,NA
"providers, such as Google or Amazon. By having the possibility to run your ",NA,NA
"containers in the cloud, it gives you a lot of advantages. First, you don't need to ",NA,NA
"manage your own servers. Second, in most clouds, you pay only for the real usage. If ",NA,NA
"there's a peak in the load, the cost of the cloud service will increase, of course, as ",NA,NA
"you will be using more computing power. But if there is no load, you will pay ",NA,NA
"nothing. This is easy to say, but monitoring your server usage, especially with an ",NA,NA
"application or applications running with a huge number of components, can be ",NA,NA
tricky. You will need to look at the bill from the cloud company carefully and make ,NA,NA
sure that you don't have a container sitting in the cloud spinning and doing nothing. ,NA,NA
If the specific service is not that important for your application and does not need to ,NA,NA
"respond fast, you can move it to the cheapest machine. On the other hand, if another ",NA,NA
"service experiences higher loads and it's critical, you will want to move it to a more ",NA,NA
"powerful machine or spin up more instances of it. Best of all, by using Kubernetes, it ",NA,NA
"can be automated. By having the right tool for managing Docker containers, this can ",NA,NA
be done on the fly. Your application can adapt itself in a very agile way--the end ,NA,NA
users will probably not even be aware of where an application they're using resides.,NA,NA
Container management and monitoring software can greatly reduce the hardware ,NA,NA
costs by better utilizing the hardware you are paying for. Kubernetes handles ,NA,NA
scheduling onto nodes in a compute cluster and actively manages workloads to,NA,NA
ensure that their state matches the user's declared intentions. Using the concepts of ,NA,NA
"labels and Pods (which we are going to cover later in this chapter), Kubernetes ",NA,NA
groups the containers which make up an application into logical units for easy ,NA,NA
management and discovery.,NA,NA
Having your application in the form of a set of containers running in a managed ,NA,NA
environment also changes the perspective on software development. You can work ,NA,NA
"on a new version of the service and when it's ready, you can do a rolling update on ",NA,NA
the fly. This also means focusing on the application over the machines it runs on and ,NA,NA
"this, as a result, allows developer teams to operate in a much more flexible, smaller, ",NA,NA
"and modular manner. It allows the software development to be truly agile, which is ",NA,NA
"what we always wanted. Microservices are small and independent, and the build and ",NA,NA
"deployment times are dramatically lower. Also, the risk of doing releases is smaller ",NA,NA
"so you can release smaller changes more often, minimizing the possibility of a huge ",NA,NA
failure which may happen if you release everything in one go.,NA,NA
"Before we begin with basic Kubernetes concepts, let's summarize what ",NA,NA
Kubernetes gives us in a list:,NA,NA
Deploying applications quickly and predictably,NA,NA
Scaling on the fly,NA,NA
Releasing new features seamlessly,NA,NA
Fail-proofing,NA,NA
Limiting hardware usage only to required resources,NA,NA
Agile application development,NA,NA
"Portability between operating systems, hosts, and cloud providers",NA,NA
This is a list of features that cannot be easily beaten. To understand how this is being ,NA,NA
"achieved, we need to understand the core Kubernetes concepts. So far, we know only ",NA,NA
"one single concept coming from Docker--the container--which is a portable, ",NA,NA
"independent unit of software. The container can contain anything we want, be it a ",NA,NA
database or a Java REST microservice. Let's get to know the remaining pieces.,NA,NA
Basic Kubernetes concepts,NA,NA
A cluster is a group of nodes; they can be physical servers or virtual machines that ,NA,NA
have the Kubernetes platform installed. The basic Kubernetes architecture is ,NA,NA
presented in the following diagram:,NA,NA
"As you can see, the Kubernetes cluster consists of a Master node and a number of ",NA,NA
worker nodes with some components inside. While it may look scary and ,NA,NA
"complicated at first glance, it will be easier to understand if we describe the concepts ",NA,NA
"one by one, starting with the Pod.",NA,NA
Pods,NA,NA
The Pod consists of one or more Docker containers. This is the basic unit of the ,NA,NA
Kubernetes platform and an elementary piece of execution that Kubernetes works ,NA,NA
with. A diagram of the Pod is presented as following:,NA,NA
"Containers running in the same Pod share the same common network namespace, ",NA,NA
"disk, and security context. In fact, the communication over localhost is ",NA,NA
recommended between containers running on the same Pod. Each container can also ,NA,NA
communicate with any other Pod or service within the cluster.,NA,NA
As you remember from ,NA,NA
Chapter 2,NA,NA
", ",NA,NA
Networking and Persistent Storage,NA,NA
", you can mount ",NA,NA
volumes within Docker containers. Kubernetes also supports the concept of a ,NA,NA
volume. Volumes that are attached to the Pod may be mounted inside of one or more ,NA,NA
containers running on this Pod. Kubernetes supports a lot of different volume types ,NA,NA
"as a native support for mounting GitHub repositories, network disks, local hard ",NA,NA
"drives, and so on.",NA,NA
If your application needs a distributed storage and needs to handle large amounts of ,NA,NA
"data, you are not limited only to local hard drives. Kubernetes also supports Volume ",NA,NA
"Providers. Currently, the list of available Persistent Volume Providers includes:",NA,NA
GCE,NA,NA
: Which is a Google Cloud platform,NA,NA
AWS,NA,NA
: Amazon Web Services,NA,NA
GlusterFS,NA,NA
": A scalable network filesystem. Using GlusterFS, which is free and",NA,NA
"an open source software, you can use your existing storage hardware to create ",NA,NA
"large, distributed storage solutions",NA,NA
OpenStack Cinder,NA,NA
: A block storage service for users of the OpenStack ,NA,NA
Nova ,NA,NA
compute platform,NA,NA
CephRBD,NA,NA
: A ,NA,NA
Reliable Autonomic Distributed Object Store,NA,NA
 (,NA,NA
RADOS,NA,NA
"), ",NA,NA
"which provides your applications with object, block, and file system storage in a ",NA,NA
single unified storage cluster,NA,NA
QuoByte,NA,NA
Kube-Aliyun,NA,NA
Network namespace and volumes are not the only properties of the Pod. As you can ,NA,NA
"see on the Pod's diagram, a Pod can have labels and annotations attached. Labels are ",NA,NA
"very important in Kubernetes. They are key/value pairs that are attached to objects, ",NA,NA
in this case to Pods. The idea behind labels is that they can be used to identify ,NA,NA
objects--labels are meaningful and relevant to users. An example of the label may be:,"app=my-rest-service 
  
 layer=backend",NA
"Later on, we will be using label selectors to select objects (such as Pods) having the ",NA,NA
"specified label. Via a label selector, which is the core grouping primitive in ",NA,NA
"Kubernetes, the client or user can identify an object or a set of objects. A selector, ",NA,NA
"similar to a label, is also a key-value expression to identify resources using matching ",NA,NA
"labels. For example, the selector expression ",app = my-rest-service,NA
 would select all ,NA,NA
Pods with the label ,app = my-rest-service,NA
". Annotations, on the other hand, are a kind ",NA,NA
of metadata you can attach to Pods. They are not intended to be identifying ,NA,NA
attributes; they are such properties that can be read by tools of libraries. There are no ,NA,NA
rules as to what an annotation should contain--it's up to you. The annotation can ,NA,NA
"contain information such as the build or release version, a timestamp, Git branch ",NA,NA
"name, Git ",pull,NA
" request number, or just anything, as a mobile number.",NA,NA
Labels are intended for identifying information about Kubernetes objects such as ,NA,NA
Pods. Annotations are just metadata attached to an object.,NA,NA
We've said before that a Pod is a basic unit of execution in Kubernetes. It can contain ,NA,NA
multiple containers. A real-life example of having a Pod with more than one Docker ,NA,NA
container could be our Java REST microservice Pod. For example purposes in ,NA,NA
"previous chapters, our microservice has been storing its database data in memory. In ",NA,NA
"real life, the data should probably go to the real database. Our Pod would probably ",NA,NA
"have a container with Java JRE and the Spring Boot application itself, together with ",NA,NA
"the second container with a PostgreSQL database, which the microservice uses to",NA,NA
"store its data. Two of those containers makes a Pod--a single, decoupled unit of ",NA,NA
execution that contains everything our REST service needs to operate.,NA,NA
The Pod's definition is a JSON or YAML file called a ,Pod,NA
 manifest. Take a look at a ,NA,NA
simple example with one container:,"apiVersion: v1 
  
 kind: Pod 
  
 metadata:
  
   
  name: rest_service 
  
 spec:
  
   
  containers:
  
    
  name: rest_service
  
    
  image: rest_service
  
    
  
  ports:
  
  - containerPort: 8080",NA
The same ,pod,NA
 manifest in a JSON file will look the same as the following:,"{
  
  
  ""apiVersion"": ""v1"", 
  
  
  ""kind"": ""Pod"",
  
  
  ""metadata"":{
  
  
  
  ""name"": ”rest_service”,
  
  
  
  ""labels"": {
  
  
  
   
  ""name"": ""rest_service""
  
  
  
  }
  
  
  },
  
  
  ""spec"": {
  
  
  
  ""containers"": [{
  
  
  
   
  ""name"": ""rest_service"",
  
  
  
   
  ""image"": ""rest_service"",
  
  
  
   
  ""ports"": [{""containerPort"": 8080}],
  
  
  }]
  
  
  } 
  
 }",NA
The container's ,image,NA
 is a Docker image name. The ,containerPort,NA
 exposes that port ,NA,NA
from the REST service container so we can connect to the service at the Pod's IP. By ,NA,NA
"default, as you remember from ",NA,NA
Chapter 1,NA,NA
", ",NA,NA
Introduction to Docker,NA,NA
", the entry point ",NA,NA
defined in the ,image,NA
 is what will run.,NA,NA
It's very important to be aware that a Pod's life is fragile. Because the Pods are ,NA,NA
"treated as stateless, independent units, if one of them is unhealthy or is just being ",NA,NA
"replaced with a newer version, the Kubernetes Master doesn't have mercy on it--it ",NA,NA
just kills it and disposes of it.,NA,NA
"In fact, Pods have a strictly defined lifecycle. The following list describes the phases ",NA,NA
of a Pod's life:,NA,NA
: This phase means that the Pod has been accepted by the Kubernetes ,NA,NA
"system, but one or more of the Docker container images has not been created. ",NA,NA
Pods can be in this phase for a while--if the image needs to be downloaded from ,NA,NA
"the internet, for example.",running,NA
: The Pod has been put onto a node and all of the Pod's Docker ,NA,NA
containers have been created.,succeeded,NA
: All Docker containers in the Pod have been terminated with a success ,NA,NA
status.,failed,NA
": All Docker containers in the Pod have been terminated, but at least one ",NA,NA
container has terminated with a failure status or was terminated by the system.,unknown,NA
: This typically indicates a problem with communication to the host of ,NA,NA
"the Pod; for some reason, the state of the Pod could not be retrieved.",NA,NA
"When a Pod is being brought down, it's not only because it has failed. More often, if ",NA,NA
"our application needs to handle an increased load, we need to have more Pods ",NA,NA
"running. On the other hand, if the load decreases or there is no load at all, there's no ",NA,NA
"point in having a lot of Pods running--we can dispose of them. Of course, we could ",NA,NA
"start and stop Pods manually, but it's always better to automate. This brings us to the ",NA,NA
concept of ReplicaSets.,NA,NA
ReplicaSets,NA,NA
ReplicaSets is the concept used in scaling your application by using replication. ,NA,NA
"What is Kubernetes replication useful for? Typically, you would want to replicate ",NA,NA
"your containers (which are, in fact, your application) for several reasons, including:",NA,NA
Scaling,NA,NA
: When load increases and becomes too heavy for the number of ,NA,NA
"existing instances, Kubernetes enables you to easily scale up your application, ",NA,NA
creating additional instances as needed.,NA,NA
Load balancing,NA,NA
: We can easily distribute traffic to different instances to ,NA,NA
prevent overloading of a single instance or node. Load balancing comes out of ,NA,NA
the box because of Kubernetes' architecture and it's very convenient.,NA,NA
Reliability and fault tolerance,NA,NA
": By having multiple versions of an application, ",NA,NA
you prevent problems if one or more fail. This is particularly true if the system ,NA,NA
replaces any containers that fail.,NA,NA
"Replication is appropriate for numerous use cases, including microservice-based ",NA,NA
"applications where multiple, independent small services provide very specific ",NA,NA
"functionality, or cloud native applications that are based on the theory that any ",NA,NA
component can fail at any time. Replication is a perfect solution for implementing ,NA,NA
"them, as multiple instances naturally fit into the architecture.",NA,NA
"A ReplicaSet ensures that a specified number of Pod clones, known as replicas, are ",NA,NA
"running at any given time. It there are too many, they will be shut down. If there is a ",NA,NA
"need for more, for example some of them died because of an error or crash, or maybe ",NA,NA
"there's a higher load, some more Pods will be brought to life. ReplicaSets are used by ",NA,NA
Deployments. Let's see what Deployments are.,NA,NA
Deployment,NA,NA
The Deployment is responsible for creating and updating instances of your ,NA,NA
"application. Once the Deployment has been created, the Kubernetes Master ",NA,NA
schedules the application instances onto individual nodes in the cluster. A ,NA,NA
Deployment is a higher level of abstraction; it manages ReplicaSets when doing Pod ,NA,NA
"orchestration, creation, deletion, and updates. A Deployment provides declarative ",NA,NA
updates for Pods and ReplicaSets. The Deployment allows for easy updating of a ,NA,NA
Replica Set as well as the ability to roll back to a previous deployment.,NA,NA
You just specify the number of replicas you need and the container to run within ,NA,NA
each Pod and the Deployment controller will spin them up. The example ,NA,NA
Deployment manifest definition in the YAML file looks the same as the following:,"apiVersion: 1.0 
  
 kind: Deployment 
  
 metadata:
  
  name: rest_service-deployment 
  
 spec:
  
  replicas: 3
  
  template:
  
   
  metadata:
  
   
  
  labels:
  
   
  
  
  app: rest_service
  
   
  spec:
  
   
  
  containers:
  
   
  
  - name: rest_service
  
   
  
  
  image: rest_service
  
   
  
  
  ports:
  
   
  
  
  - containerPort: 8080",NA
"In the previous example, the Deployment Controller will create a ReplicaSet ",NA,NA
containing three Pods running our Java REST service.,NA,NA
The Deployment is a kind of control structure that takes care of the spinning up or ,NA,NA
down of Pods. A Deployment takes care of the state of a Pod or group of pods by ,NA,NA
creating or shutting down replicas. Deployments also manage updates to Pods. ,NA,NA
"Deployments are a higher abstraction, which create ReplicaSets resources.",NA,NA
ReplicaSets watch over the Pods and make sure the correct number of replicas are ,NA,NA
"always running. When you want to update a Pod, you will need to modify the ",NA,NA
"Deployment manifest. This modification will create a new ReplicaSet, which will be ",NA,NA
"scaled up while the previous ReplicaSet will be scaled down, providing no down-",NA,NA
time deployment of your application.,NA,NA
The main purpose of Deployments is to do rolling updates and rollbacks. A rolling ,NA,NA
"update is the process of updating an application to a newer version, in a serial, one-",NA,NA
"by-one fashion. By updating one instance at a time, you are able to keep the ",NA,NA
"application up and running. If you were to just update all instances at the same time, ",NA,NA
"your application would likely experience downtime. In addition, performing a rolling ",NA,NA
update allows you to catch errors during the process so that you can roll back before ,NA,NA
it affects all of your users.,NA,NA
"Deployment also allows us to do an easy rollback. To do the rollback, we simply set ",NA,NA
the revision that we want to roll back to. Kubernetes will scale up the corresponding ,NA,NA
"ReplicaSet and scale down the current one, and this will result in a rollback to a ",NA,NA
"specified revision of our service. In fact, we will be using Deployments heavily in ",NA,NA
Ch ,NA,NA
apter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
", to roll out an update of our service to the cluster.",NA,NA
"Replication is a large part of Kubernetes' features. As you can see, the life of a Pod is ",NA,NA
"delicate and ephemeral. Because Pods and their clones come and go all the time, we ",NA,NA
"need something permanent and tangible, something that will stay forever so our ",NA,NA
application's users (or other Pods as well) can discover and call. This brings us to the ,NA,NA
concept of Kubernetes services. Let's focus on them now.,NA,NA
Services,NA,NA
Kubernetes services group one or more Pods into an internal or external process that ,NA,NA
"needs to be long-running and externally accessible, as our Java REST API endpoint ",NA,NA
"or a database host, for example. This is where the labels we gave to our Pods become ",NA,NA
very important; a service finds Pods to group by looking for a specific label. We use ,NA,NA
label selectors to select Pods with particular labels and apply services or ReplicaSets ,NA,NA
to them. Other applications can find our service through Kubernetes service ,NA,NA
discovery.,NA,NA
A service is Kubernetes' abstraction to provide a network connection to one or more ,NA,NA
"Pods. While (as you remember from the chapter about Docker networking), by ",NA,NA
"default, Docker uses host-private networking, containers can communicate with ",NA,NA
"other containers only if they are on the same host machine. In Kubernetes, cluster ",NA,NA
"Pods can communicate with other Pods, regardless of which host they land on. This ",NA,NA
is possible because of the services. Each service is given its own IP address and port ,NA,NA
which remains constant for the lifetime of the service. Services have an integrated ,NA,NA
load-balancer that will distribute network traffic to all Pods. While a Pod's life can be ,NA,NA
"fragile as they are being spun up or down depending on your application needs, the ",NA,NA
"service is a more constant concept. Each Pod gets its own IP address, but when it ",NA,NA
"dies and another one is being brought to life, the IP address can be different. This ",NA,NA
could potentially become a problem--if a set of Pods provides functionality to other ,NA,NA
"Pods inside the Kubernetes cluster, one can lose track of the other one's IP address.",NA,NA
"Services, by having a lifetime-assigned IP address, solves this issue. The Service ",NA,NA
abstraction enables decoupling. Let's say we have our Java REST service running on ,NA,NA
"top of the Spring Boot application. We need a way to route HTTP requests, such as ",GET,NA
 or ,POST,NA
", from the internet to our Docker containers. We will do it by setting up a ",NA,NA
Kubernetes service that uses a load balancer to route requests coming from a public ,NA,NA
IP address to one of the containers. We will group the containers with the REST ,NA,NA
"service into a Pod and name it, let's say, Our little REST service. Then we will define ",NA,NA
a Kubernetes service that will serve port ,8080,NA
 to any of the containers in the Our little ,NA,NA
REST service Pod. Kubernetes will then use a load balancer to divide the traffic ,NA,NA
between the specified containers. Let's summarize the Kubernetes service features:,NA,NA
Services are persistent and permanent,NA,NA
They provide discovery,NA,NA
They offer load balancing,NA,NA
They expose a stable network IP address,NA,NA
They find Pods to group by usage of labels,NA,NA
We have said that there is a service discovery mechanism built-in. Kubernetes ,NA,NA
supports two primary modes of finding a service: environment variables and DNS.,NA,NA
Service discovery is the process of figuring out how to connect to a service. ,NA,NA
Kubernetes contains a built-in DNS server for that purpose: the kube-dns.,NA,NA
kube-dns,NA,NA
"Kubernetes offers a DNS cluster add-on, started automatically each time the cluster ",NA,NA
is started up. The DNS service runs as a cluster service itself--its SkyDNS--a ,NA,NA
distributed service for announcement and discovery of services built on top of ,etcd,NA
(you will get to know what etcd is later in this chapter). It utilizes DNS queries to ,NA,NA
"discover available services. It supports forward lookups (A records), service lookups ",NA,NA
"(SRV records), and reverse IP address lookups (PTR records). Actually, the service ",NA,NA
is the only type of object to which Kubernetes assigns DNS names; Kubernetes ,NA,NA
generates an internal DNS entry that resolves to a service's IP address. Services are ,NA,NA
assigned a DNS A record for a name in the form ,"service-name.namespace-
  
 name.svc.cluster.local",NA
". This resolves to the cluster IP of the service. For example, for ",NA,NA
a service named ,my-rest-service,NA
", the DNS add-on will make sure that the service will ",NA,NA
be available for other Pods (and other services) in the cluster via the ,"my-rest-
 service.default.svc.cluster.local",NA
 hostname. The DNS-based service discovery ,NA,NA
provides a flexible and generic way to connect to services across the cluster.,NA,NA
Note that when using the ,hostNetwork=true,NA
" option, Kubernetes will use ",NA,NA
the host's DNS servers and will not use the cluster's DNS server.,NA,NA
There's one more concept that will appear from time to time during our Kubernetes ,NA,NA
journey--a namespace. Let's find out what it's for.,NA,NA
Namespace,NA,NA
"A namespace functions as a grouping mechanism inside of Kubernetes. Pods, ",NA,NA
"volumes, ReplicaSets, and services can easily cooperate within a namespace, but the ",NA,NA
namespace provides an isolation from the other parts of the cluster. What would be ,NA,NA
"the possible use case for such isolation? Well, namespaces let you manage different ",NA,NA
"environments within the same cluster. For example, you can have different test and ",NA,NA
staging environments in the same cluster of machines.,NA,NA
"This could potentially save some resources in your infrastructure, but it can be ",NA,NA
"dangerous; without namespaces, it would be risky to roll out a new version of your ",NA,NA
"software to test the environment, having the pre-release version running on the same ",NA,NA
"cluster. By having namespaces available, you can act on different environments in ",NA,NA
the same cluster without worrying about affecting other environments.,NA,NA
Because Kubernetes uses the ,default,NA
" namespace, using namespaces is optional, but ",NA,NA
recommended.,NA,NA
"We have all the Kubernetes abstractions explained--we know that there are Pods, ",NA,NA
"ReplicaSets, Deployments, and services. Now it's time to move to the physical, ",NA,NA
"execution layer of Kubernetes' architecture. All those little, fragile Pods need to live ",NA,NA
"somewhere. They live in nodes, which we are going to learn about now.",NA,NA
Nodes,NA,NA
A node is a work horse in Kubernetes' architecture. It may be a virtual or physical ,NA,NA
"machine, depending on your infrastructure. A worker node runs the tasks as ",NA,NA
"instructed by the Master node, which we will explain very soon. Nodes (in the earlier ",NA,NA
"Kubernetes life, they were called Minions) can run one or more Pods. They provide ",NA,NA
an application-specific virtual host in a containerized environment.,NA,NA
"When a worker node dies, the Pods running on the node die as well.",NA,NA
The following diagram shows the contents of a node:,NA,NA
"As you can see in the previous diagram, a node in Kubernetes has some processes ",NA,NA
"running inside, and each is very important. Let's explain their purposes, one by one.",NA,NA
Kubelet,NA,NA
Kubelet is probably the most important controller in Kubernetes. It's a process that ,NA,NA
responds to the commands coming from the Master node (we are going to explain ,NA,NA
what the Master node is in a second). Each node has this process listening. The ,NA,NA
"Master calls it to manage Pods and their containers. The Kubelet runs Pods (which, ",NA,NA
"as you already know, are collections of containers that share an IP and volumes). The ",NA,NA
Kubelet (,NA,NA
https://kubernetes.io/v1.0/docs/admin/kubelet/,NA,NA
) is responsible for what's running ,NA,NA
"on an individual machine and it has one job: given a set of containers to run, to make ",NA,NA
"sure they are all running. To rephrase, a Kubelet is the name of the agent and a node ",NA,NA
is what we call the machine the agent runs on. It's worth knowing that each Kubelet ,NA,NA
also has an internal ,HTTP,NA
 server which listens for HTTP requests and responds to a ,NA,NA
simple API call to submit a new manifest.,NA,NA
Proxy,NA,NA
A proxy is a network proxy that creates a virtual IP address which clients can access. ,NA,NA
The network calls will be transparently proxied to the Pods in a Kubernetes service. ,NA,NA
"A service, as you already know, provides a way to group Pods into kind of a single ",NA,NA
"business process, which can be reached under a common access policy. By having a ",NA,NA
"proxy run on a node, we can call the service IP address. Technically, a node's proxy ",NA,NA
is a ,kube-proxy,NA
 (,NA,NA
https://kubernetes.io/docs/admin/kube-proxy/,NA,NA
) process which programs ,iptables,NA
 rules to trap access to the service IP address. The Kubernetes network proxy ,NA,NA
"runs on each node. Without it, we would not be able to access the service.",kube-proxy,NA
" knows only UDP and TCP, does not understand HTTP, ",NA,NA
"provides load balancing, and is just used to reach services.",NA,NA
Docker,NA,NA
"Finally, each node needs something to run. It will be a Docker container runtime, ",NA,NA
which is responsible for pulling the images and running containers.,NA,NA
"All those nodes, as any other group of workers in the real world, need a manager. In ",NA,NA
"Kubernetes, the role of the node manager is being performed by one special node: ",NA,NA
the Master node.,NA,NA
The Master node,NA,NA
The Master node does not run any containers--it just handles and manages the ,NA,NA
cluster. The Master is the central control point that provides a unified view of the ,NA,NA
"cluster. There is a single Master node that controls multiple worker nodes, which ",NA,NA
actually run our containers. The Master automatically handles the scheduling of the ,NA,NA
Pods across the worker nodes in the cluster -by taking into account the available ,NA,NA
resources on each node. The structure of the Master node is presented in the ,NA,NA
following diagram:,NA,NA
"Let's dissect the Master node piece by piece, starting with ",etcd,NA
.,NA,NA
etcd,NA,NA
Kubernetes stores all of its cluster state in ,etcd,NA
", a distributed data store with a strong ",NA,NA
consistency model. ,etcd,NA
" is a distributed, reliable key-value store for the most ",NA,NA
"critical data of a distributed system, with a focus on being:",NA,NA
Simple,NA,NA
": Well-defined, user-facing API",NA,NA
Secure,NA,NA
: Automatic TLS with optional client cert authentication,NA,NA
Fast,NA,NA
": Benchmarked for 10,000 writes/sec",NA,NA
Reliable,NA,NA
: Properly distributed using Raft,NA,NA
"This state includes what nodes exist in the cluster, what Pods should be running, ",NA,NA
"which nodes they are running on, and a whole lot more. The whole cluster state is ",NA,NA
stored in an instance of ,etcd,NA
. This provides a way to store configuration data reliably. ,NA,NA
Another crucial component running on the Master node is the API server.,NA,NA
The API server,NA,NA
One of the main components residing on the Master node is the API server. It's so ,NA,NA
"important that sometimes, you may find out that the Master node is being referred to ",NA,NA
"as the API server in general. Technically, it's a process named ",kube-apiserver,NA
 which ,NA,NA
accepts and responds to ,HTTPREST,NA
 requests using JSON. It's main purpose is to ,NA,NA
"validate and configure data for the API objects which are Pods, services, ",NA,NA
"ReplicaSets, and others. The API server provides the frontend to the cluster's shared ",NA,NA
state through which all other components interact. The API server is the central ,NA,NA
management entity and is the only Kubernetes component that connects to etcd. All ,NA,NA
the other components must go through the API server to work with the cluster state.,NA,NA
We will cover the Kubernetes API in detail in ,NA,NA
Chapter 9,NA,NA
", ",NA,NA
Working With Kubernetes ,NA,NA
API,NA,NA
.,NA,NA
The Master node does not run any containers--it just handles and ,NA,NA
manages the whole cluster. The nodes that actually run the containers ,NA,NA
are the worker nodes.,NA,NA
The scheduler,NA,NA
"As we have said before, if you create a Deployment, the Master will schedule the ",NA,NA
distribution of application instances onto individual nodes in the cluster. Once the ,NA,NA
"application instances are up and running, the Deployment Controller will be ",NA,NA
continuously monitoring those instances. This is kind of a self-healing mechanism--,NA,NA
"if a node goes down or is deleted, the Deployment Controller replaces it.",NA,NA
Now that we know what the Kubernetes specific components are that form it's ,NA,NA
"architecture, let's look what tools are available for us.",NA,NA
Available tools ,NA,NA
There are a couple of tools we will be using throughout the rest of the book. Let's ,NA,NA
start with the most important one: ,kubectl,NA
.,NA,NA
kubectl,kubectl,NA
 is a command-line interface for running commands against Kubernetes ,NA,NA
"clusters. In fact, this is the command used most often when working with ",NA,NA
Kubernetes. In ,NA,NA
Chapter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
", we will go through the ",NA,NA
command's syntax and possible usages. Using ,kubectl,NA
", you will be interacting with ",NA,NA
"your cluster. Of course, having the API exposed by the Master node and the API ",NA,NA
"server, we could do it using an ",HTTP,NA
" client of our choice, but using ",kubectl,NA
 is a lot ,NA,NA
faster and more convenient. ,kubectl,NA
" provides a lot of functionalities, such as listing ",NA,NA
"resources, showing detailed information about the resources, prints log, managing ",NA,NA
"cluster, and executing commands on a container in a Pod.",NA,NA
Dashboard,NA,NA
"Kubernetes Dashboard is a nice, clean web-based UI for Kubernetes clusters. Using ",NA,NA
"the Dashboard, you can manage and troubleshoot the cluster itself as well as the ",NA,NA
applications running in it. You could say it's the Kubernetes user interface. For those ,NA,NA
"who prefer to use the graphical UI, the Dashboard can be a handy tool for deploying ",NA,NA
containerized applications and getting an overview of applications running on your ,NA,NA
"cluster, as well as for creating or modifying individual resources such as ",NA,NA
"Deployments, Pods, and services. For example, you can scale a Deployment, initiate ",NA,NA
"a rolling update, restart a Pod, or deploy new applications using a deploy wizard. We ",NA,NA
will also use the Dashboard in ,NA,NA
Chapter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
.,NA,NA
Minikube,NA,NA
Running a cluster seems to be a complicated process that needs a lot of setup. This is ,NA,NA
"not necessarily the truth. Actually, it's quite easy to have the Kubernetes cluster up ",NA,NA
"and running on the local machine, for learning, testing, and development purposes. ",NA,NA
The ,minikube,NA
" tool, available at GitHub at ",NA,NA
https://github.com/kubernetes/minikube,NA,NA
", allows ",NA,NA
you to set up the local cluster on your own machine. It's available for all major ,NA,NA
"platforms, which includes Linux, macOS, and Windows. The cluster started will of ",NA,NA
"course be a single node cluster, but it's more than enough to start doing real-life ",NA,NA
"Kubernetes examples. In fact, in ",NA,NA
Chapter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
", before we ",NA,NA
start deploying our ,REST,NA
" service into the cluster, we are going to run Kubernetes ",NA,NA
locally.,NA,NA
"Apart from those mentioned previously, you may find a lot of other tools and utilities ",NA,NA
that work very well with Kubernetes on the internet.,NA,NA
Summary,NA,NA
This chapter introduced a lot of new concepts. Let's briefly summarize what we have ,NA,NA
learned about the Kubernetes architecture.,NA,NA
Kubernetes (k8s) is an open source platform for automating container operations ,NA,NA
"such as deployment, scheduling, and scalability across a cluster of nodes. Using ",NA,NA
"Kubernetes, you can:",NA,NA
Automate the deployment and replication of containers,NA,NA
Scale up and down containers on the fly,NA,NA
Organize containers in groups and provide load balancing between them,NA,NA
Easily roll out new versions of application containers,NA,NA
Provide fault tolerance mechanisms to your application--if a container dies it ,NA,NA
gets replaced,NA,NA
Kubernetes consists of:,NA,NA
A Cluster,NA,NA
: A group of nodes.,NA,NA
Nodes,NA,NA
: Physical or virtual machines that act as workers. Each node runs ,NA,NA
"the kubelet, proxy, and a Docker engine process.",NA,NA
The Master node,NA,NA
: Provides a unified view into the cluster. It delivers the ,NA,NA
Kubernetes API server. The API server provides a ,REST,NA
 endpoint that can ,NA,NA
be used to interact with the cluster. The Master also includes the ,NA,NA
controllers used to create and replicate Pods.,NA,NA
Pods,NA,NA
: Scheduled to nodes. Each Pod runs a single container or a group of ,NA,NA
containers and volumes. Containers in the same Pod share the same ,NA,NA
network namespace and volumes and can communicate with each other ,NA,NA
using localhost. Their life is fragile; they will be born and die all the ,NA,NA
time.,NA,NA
Labels,NA,NA
": Pods have labels, with key/value pairs attached. Labels are used to ",NA,NA
precisely select Pods.,NA,NA
Services,NA,NA
: An abstraction that defines a set of Pods and a policy to access ,NA,NA
them. Services find their group of Pods by using label selectors. Because ,NA,NA
"the IP of the single Pod can change, the service provides a permanent IP ",NA,NA
address for its client to use.,NA,NA
"That was a piece of theory that may be a bit overwhelming. Don't worry, in ",NA,NA
Chapter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
", we are going to run the local Kubernetes cluster. Our ",NA,NA
plan will consist of creating a local Kubernetes cluster using ,minikube,NA
. We will then ,NA,NA
deploy and manage Docker containers with our Java REST microservice. By doing,NA,NA
"some practical, hands-on actions, the Kubernetes architecture will be a lot more ",NA,NA
"clear. Running a local Kubernetes is not the only thing we are going to do. Later on, ",NA,NA
in ,NA,NA
Chapter 10,NA,NA
", ",NA,NA
Deploying Java on Kubernetes in the Cloud,NA,NA
", we will put our application ",NA,NA
in the real cloud--a place where Kubernetes really shines.,NA,NA
Using Kubernetes with Java,NA,NA
In ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", we learned about the Kubernetes ",NA,NA
"architecture and concepts. We know about nodes, Pods, and services. In this chapter, ",NA,NA
we will do some practical hands-on and deploy our Java REST service to a local ,NA,NA
"Kubernetes cluster. For learning purposes, we will use the Minikube tool to create a ",NA,NA
cluster on the local machine. It's easier to learn Kubernetes on a local machine ,NA,NA
"instead of going to the cloud in the first place. Because Minikube runs locally, ",NA,NA
"instead of through a cloud provider, certain provider-specific features such as load ",NA,NA
"balancers and persistent volumes, will not work out of the box. However, you can ",NA,NA
use ,NodePort,NA
", ",HostPath,NA
", persistent volumes and several addons such as DNS, or ",NA,NA
"dashboard to test your apps locally before pushing to a real, production-grade cluster.",NA,NA
In ,NA,NA
Chapter 10,NA,NA
", ",NA,NA
Deploying Java on Kubernetes in the Cloud,NA,NA
", we will run Kubernetes ",NA,NA
using ,NA,NA
Amazon Web Services,NA,NA
 (,NA,NA
AWS,NA,NA
) and hosted Kubernetes in Google container ,NA,NA
engine.,NA,NA
"To follow along, we will need the following tools ready:",Docker,NA
 : To build the Docker images we want to deploy,minikube,NA
: A local Kubernetes environment,kubectl,NA
: The Kubernetes command line interface,NA,NA
This chapter will cover the following topics:,NA,NA
"Installing Minikube on macOS, Windows, and Linux",NA,NA
Starting up the local Kubernetes cluster using Minikube,NA,NA
Deploying a Java application on a local cluster,NA,NA
"Interacting with containers: scaling, autoscaling, and viewing cluster events",NA,NA
Using the Kubernetes dashboard,NA,NA
"I assume you have Docker up and running so far, so let's focus on the ",minikube,NA
 utility.,NA,NA
We have already mentioned ,minikube,NA
 in the ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to ,NA,NA
Kubernetes;,NA,NA
" now, we will go into some more details, starting with the installation ",NA,NA
process.,NA,NA
Installing Minikube ,NA,NA
The Minikube tool source code with all the documentation is available at GitHub at ,NA,NA
h ,NA,NA
ttps://github.com/kubernetes/minikube,NA,NA
.,NA,NA
Installing on Mac,NA,NA
The following sequences of commands will download the ,minikube,NA
" binary, set the ",NA,NA
executable flag and copy it to the ,/usr/local/bin,NA
" folder, which will make it available ",NA,NA
in the macOS shell:,"$ curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.12.2/minikube-darwin-
 $ chmod +x minikube 
  
 $ sudo mv minikube /usr/local/bin/",NA
"Alternatively, if you use Homebrew package manager (available freely at ",NA,NA
https://brew. ,NA,NA
sh,NA,NA
"), which is, by the way, very handy and recommended, you can just install ",minikube,NA
by typing:,$ brew cask install minikube,NA
Installing on Windows,NA,NA
Minikube for Windows is also simply a single executable file. You can always find ,NA,NA
"the newest version on the Minikube's site, at ",NA,NA
https://github.com/kubernetes/minikube,NA,NA
. You ,NA,NA
"just need to download the latest executable, rename it ",minikube.exe,NA
", and place it in ",NA,NA
your system path to have it available from the command line.,NA,NA
Installing on Linux,NA,NA
The installation process on Linux is identical to the macOS one. The only difference ,NA,NA
is the executable name. The following command will download the latest Minikube ,NA,NA
"release, set the executable bit, and move it to the ",/usr/local/bin,NA
 directory:,$ curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-am,NA
"That's all, a single Minikube and Docker is all we need to start the local cluster. It's ",NA,NA
time to bring it to life:,NA,NA
Starting up the local Kubernetes cluster,NA,NA
We're using the local Kubernetes cluster provided by ,minikube,NA
. Start your cluster ,NA,NA
with:,$ minikube start,NA
"Minikube works on its own virtual machine. Depending on your host OS, you can ",NA,NA
choose between several virtualization drivers. Currently supported are ,virtualbox,NA
", ",vmwarefusion,NA
", ",xhyve,NA
", ",hyperv,NA
", and ",kvm,NA
 (,NA,NA
Kernel-based virtual machine,NA,NA
). The default VM ,NA,NA
driver is virtual box. You can override this option. This is the example macOS ,NA,NA
startup command line which uses ,xhyve,NA
:,$ minikube start --vm-driver=xhyve,NA
"When starting Minikube for the first time, you will see it downloading the Minikube ",NA,NA
"ISO, so the process will take a little longer. This is, however, a one-time action. The ",NA,NA
Minikube configuration will be saved in the ,.minikube,NA
 folder in your ,home,NA
" directory, ",NA,NA
for example ,~/.minikube,NA
" on Linux or macOS. On the first run, Minikube will also ",NA,NA
configure the ,kubectl,NA
 command line tool (we will get back to it in a short while) to ,NA,NA
use the local ,minikube,NA
 cluster. This setting is called a ,kubectl,NA
 context. It determines ,NA,NA
which cluster ,kubectl,NA
 is interacting with. All available contexts are present in the ,~/.kube/config,NA
 file.,NA,NA
As the cluster is running now and we have the ,dashboard,NA
" addon enabled by default, ",NA,NA
you can take a look at the (still empty) Kubernetes dashboard with the following ,NA,NA
command:,$ minikube dashboard,NA
It will open your default browser with the URL of the cluster's dashboard:,NA,NA
"As you can see, the dashboard is empty now. If you browse to the Namespaces ",NA,NA
"menu, you will notice that Minikube creates some namespaces, with the one ",NA,NA
available for our purposes named simply the default. The parts of the Minikube ,NA,NA
"installation, such as DNS or the Dashboard, which are also running on the cluster ",NA,NA
"itself, with separate namespaces such as kube-public and kube-system.",NA,NA
"Feel free to browse the menus and sections; so far, no harm can be done, it's a local ",NA,NA
development cluster running nothing at the moment. We will get back to the ,NA,NA
"dashboard in the last section of this chapter, to see how can we use it to deploy our ",NA,NA
"services from the nice UI, if you prefer to do so, instead to using the shell of ",NA,NA
command line.,NA,NA
"Of course, having the cluster running empty is quite useless, so we need a tool to ",NA,NA
"manage it. While we can almost all everything using the dashboard, it's a lot more ",NA,NA
convenient to have a command line tool for that. ,kubectl,NA
 controls the Kubernetes ,NA,NA
cluster. We will use the ,kubectl,NA
" command line tool heavily to deploy, schedule, and ",NA,NA
scale our applications and microservices. The tool comes as a self-contained binary ,NA,NA
"for Mac, Linux, and Windows. In the next section you will find installation ",NA,NA
instructions for different platforms.,NA,NA
Installing kubectl ,kubectl,NA
 is available for all major platforms. Let's start with macOS installation.,NA,NA
Installing on Mac,NA,NA
The following sequences of command will download the ,kubectl,NA
" binary, set the ",NA,NA
executable flag and copy it to ,/usr/local/bin,NA
 folder which will make it available in ,NA,NA
the macOS shell: ,"$ curl -O https://storage.googleapis.com/kubernetes-release/release/v1.5.2 
  
  
 /bin/darwin/amd64/kubectl 
  
  
 $ chmod +x kubectl 
  
  
 $ sudo cp kubectl /usr/local/bin",NA
Homebrew provides the most convenient way to install ,kubectl,NA
 and keep it up to date.,NA,NA
"To install, use this command: ",$ brew install kubectl,NA
"To update, use the following ",NA,NA
command: ,$ brew upgrade kubectl,NA
Installing on Windows,NA,NA
You can find the list of Windows ,kubectl,NA
 releases on GitHub at ,NA,NA
https://github.com/eirslet ,NA,NA
t/kubectl-windows/releases,NA,NA
". Similar to Minikube, kubectl is just a single ",.exe,NA
 file. At the ,NA,NA
time of writing this book it's ,NA,NA
https://github.com/eirslett/kubectl-windows/releases/download/v1 ,NA,NA
.6.3/kubectl.exe,NA,NA
. You will need to download the ,exe,NA
 file and place in on your system ,NA,NA
"path, to have it available in the command line.",NA,NA
Installing on Linux,NA,NA
"The installation process is, again, very similar to the macOS. The following ",NA,NA
commands will fetch the ,kubectl,NA
" binary, give it an executable flag, and then move it ",NA,NA
to the ,/usr/local/bin,NA
 to make it available in the shell:,"$ curl -O https://storage.googleapis.com/kubernetes-release/release/v1.5.2 
 /bin/linux/amd64/kubectl 
  
 $ chmod +x kubectl 
  
 $ sudo cp kubectl /usr/local/bin/kubectl",NA
To verify if your local cluster is up and running and ,kubectl,NA
" is properly configured, ",NA,NA
execute the following command:,$ kubectl cluster-info,NA
"In the output, you will be given basic information about the cluster, which includes ",NA,NA
"its IP address, and running Minikube addons (we will get back to addons later in this ",NA,NA
chapter):,NA,NA
"To list the nodes we have running in our cluster, execute the ",get nodes,NA
 command:,$ kubectl get nodes,NA
"Of course, this is just a single node cluster, so there is no surprise in the output of the ",NA,NA
previous command:,NA,NA
Our cluster is up and running; it's time to deploy our service on it.,NA,NA
Deploying on the Kubernetes cluster,NA,NA
We begin the process of deploying our software on the Kubernetes cluster by ,NA,NA
defining a service. As you remember from ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", ",NA,NA
"services abstract a set of Pods as a single IP and port, allow simple TCP/UDP load, ",NA,NA
and allow the list of Pods to change dynamically. Let's start with service creation.,NA,NA
Creating a service,NA,NA
"By default, each Pod is only accessible by its internal IP address within the ",NA,NA
Kubernetes cluster. To make the container accessible from outside the Kubernetes ,NA,NA
"virtual network, we need to expose the Pod as a Kubernetes Service. To create a ",NA,NA
"service, we are going to use the simple ",.yaml,NA
" file, with a service manifest. YAML is a ",NA,NA
"human-readable data serialization language, which is commonly used for ",NA,NA
configuration files. A sample service manifest for our Java ,rest-example,NA
 could look ,NA,NA
the same as the following:,"apiVersion: v1 
  
 kind: Service 
  
 metadata:
  
  name: rest-example
  
  labels:
  
   
  app: rest-example
  
   
  tier: backend 
  
 spec:
  
  type: NodePort
  
  ports:
  
  - port: 8080
  
  selector:
  
   
  app: rest-example
  
   
  tier: backend",NA
"Note that the manifest of a service doesn't refer to a Docker image. This is because, ",NA,NA
as you remember from ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", a service in Kubernetes ",NA,NA
is just an abstraction which provides a network connection to one or more Pods.,NA,NA
"Each service is given its own IP address and port, which remains constant for the ",NA,NA
"lifetime of the service. Each Pod needs to have a specific label, to be discovered by ",NA,NA
"the service, services find Pods to group using and labels ",selectors,NA
. In our previous ,NA,NA
"example, the ",selector,NA
 will pick up all Pods having a label ,app,NA
 with the value of ,"rest-
 example",NA
 and a label named ,tier,NA
 with a value of ,backend,NA
:,"selector:
  
  app: rest-example
  
  tier: backend",NA
As you remember from ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", every node in a ",NA,NA
Kubernetes cluster runs a kube-proxy process. The kube-proxy plays a crucial role in ,NA,NA
Kubernetes services. Its purpose is to expose a virtual IP for them. Since Kubernetes ,NA,NA
"1.2, the iptables proxy is the default. You have two options that you can use for ",NA,NA
setting up the proxy: userspace and iptables. Those settings refer to what actually ,NA,NA
"handles the connection forwarding. In both cases, local iptables rules are installed to",NA,NA
intercept outbound TCP connections that have a destination IP address associated ,NA,NA
with a service. There's an important difference between those two modes:,Proxy-mode: userspace,NA
": In the userspace mode, the iptables rule forwards to a ",NA,NA
"local port where kube-proxy is listening for connections. The kube-proxy, ",NA,NA
"running in userspace, terminates the connection, establishes a new connection to ",NA,NA
"a backend for the service, and then forwards requests to the backend and ",NA,NA
responses back to the local process. An advantage of the userspace mode is that ,NA,NA
"because the connections are created from an application, if the connection is ",NA,NA
"refused, the application can retry to a different backend.",Proxy-mode: iptables,NA
": in this mode, the iptables rules are installed to directly ",NA,NA
forward packets that are destined for a service to a backend for the service. This ,NA,NA
is more efficient than moving the packets from the kernel to kube-proxy and ,NA,NA
then back to the kernel so it results in higher throughput and better tail latency. ,NA,NA
"However, unlike the userspace mode, using iptables mode makes it impossible ",NA,NA
"to automatically retry another Pod if the one it initially selects does not respond, ",NA,NA
so it depends on having working readiness probes.,NA,NA
"As you can see, in both cases there will be a kube-proxy binary running on the node. ",NA,NA
"In userspace mode, it inserts itself as the proxy; in iptables mode, it will configure ",NA,NA
iptables rather than to proxy connections itself.,NA,NA
The service type can have the following values:,NA,NA
NodePort,NA,NA
: By specifying a service type of ,NodePort,NA
", we declare to expose the ",NA,NA
service outside the cluster. The Kubernetes master will allocate a port from a ,NA,NA
flag-configured range (,default: 30000-32767,NA
"), and each node of the cluster will ",NA,NA
proxy that port (the same port number on every node) into your service,NA,NA
Load balancer,NA,NA
: This would create a load balancer on cloud providers which ,NA,NA
"support external load balancers (for example, on Amazon AWS cloud). This ",NA,NA
feature is not available when using Minikube,NA,NA
Cluster IP,NA,NA
: This would expose the service only within the cluster. This is the ,NA,NA
default value which will be used if you don't provide another,NA,NA
Having our ,service.yml,NA
" file ready, we can create our first Kubernetes service, by ",NA,NA
executing the following ,kubectl,NA
 command:,$ kubectl create -f service.yml,NA
"To see if our service is created properly, we can execute the ",kubectl get services,NA
command:,NA,NA
We can also list other services (including the services provided by the ,minikube,NA
"cluster itself, if you are curious) by adding the ",--all-namespaces,NA
 switch:,$ kubectl get services --all-namespaces,NA
"To see the details of a specific service, we use the ",describe,NA
 command. Execute the ,NA,NA
following to see the details of our ,rest-example,NA
 Java service:,$ kubectl describe service rest-example,NA
"In the output, we are presented with the most useful service properties, especially the ",NA,NA
"endpoints (our internal container IP and port, just one in this case, because we have ",NA,NA
"one Pod running in the service), service internal port, and proxied NodePort:",NA,NA
Having all of the settings in a ,.yaml,NA
" file is very convenient. Sometimes, though, there ",NA,NA
is a need to create a service in a more dynamic way; for example in some automation ,NA,NA
"flows. In this case, instead of creating a ",.yaml,NA
" file first, we can create a service ",NA,NA
"manually, by providing all the parameters and options to the ",kubectl,NA
 command itself. ,NA,NA
"Before doing this, however, you will need have the deployment created first, because ",NA,NA
creating a service manually is just exposing a deployment using the ,kubectl,NA
"command. After all, a service is an exposed deployment which, in fact, is just a set of ",NA,NA
"Pods. The example of such exposure, which will result with service creation, looks ",NA,NA
the same as this:,NA,NA
Creating a deployment,NA,NA
"Before creating a deployment, we need to have our Docker image ready and ",NA,NA
"published to a registry, the same as the Docker Hub for example. Of course, it can ",NA,NA
also be a private repository hosted in your organization. As you remember from the ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", each Docker container in a Pod has its own ",NA,NA
"image. By default, the kubectl process in a Pod will try to pull each image from the ",NA,NA
specified registry. You can change this behavior by specifying a value for the ,imagePullPolicy,NA
 property in a deployment descriptor. It can have the following values:,IfNotPresent,NA
": With this setting, the image will be pulled from the registry only if ",NA,NA
not present on the local host,Never,NA
": With this one, kubelet will use only local images",NA,NA
Setting ,imagePullPolicy,NA
 with a value ,IfNotPresent,NA
 when creating a deployment is ,NA,NA
"useful; otherwise, Minikube will try to download the image before looking for an ",NA,NA
image on the local host.,NA,NA
"Kubernetes uses the same syntax for images as Docker itself, including private ",NA,NA
registries and tags.,NA,NA
"It is important that you provide a tag in the image name. Otherwise, Kubernetes will ",NA,NA
"use the latest tag when looking for your image in a repository, the same as Docker ",NA,NA
does.,NA,NA
Using locally built images gets a little bit tricky when working with a local ,NA,NA
"Kubernetes cluster. Minikube runs in a separate VM, hence it will not see the images ",NA,NA
you've built locally using Docker on your machine. There's a workaround for that.,NA,NA
You can execute the following command:,$ eval $(minikube docker-env),NA
The previous command will actually utilize the Docker daemon running on ,minikube,NA
", ",NA,NA
"and build your image on the Minikube's Docker. This way, the locally built image ",NA,NA
will be available to the Minikube without pulling from the external registry. This is ,NA,NA
"not very convenient, it is certainly easier to push the Docker image to a ",remote,NA
registry. Let's push our rest-example image into the ,DockerHub,NA
 registry.,NA,NA
"1. First, we need to log in:",NA,NA
"2. Then, we are going to tag our image using the ",docker tag,NA
 command (not that you ,NA,NA
will need to provide your own DockerHub username instead of ,$DOCKER_HUB_USER,NA
):,$ docker tag 54529c0ebed7 $DOCKER_HUB_USER/rest-example,NA
3. The final step will be to push our image to Docker Hub using the ,docker push,NA
command:,$ docker push $DOCKER_HUB_USER/rest-example,NA
"4. Now that we have an image available in the registry, we need a deployment ",NA,NA
manifest. It's again a ,.yaml,NA
" file, which can look the same as this:","apiVersion: extensions/v1beta1 
  
 kind: Deployment 
  
 metadata:
  
  
  name: rest-example 
  
 spec:
  
  
  replicas: 1
  
  
  template:
  
   
  metadata:
  
   
  
  labels:
  
   
  
  
  app: rest-example
  
   
  
  
  tier: backend
  
   
  spec:
  
   
  
  containers:
  
   
  
  - name: rest-example
  
   
  
  
  image: jotka/rest-example
  
   
  
  
  imagePullPolicy: IfNotPresent
  
   
  
  
  resources:
  
   
  
  
  
  requests:
  
   
  
  
  
  
  cpu: 100m
  
   
  
  
  
  
  memory: 100Mi
  
   
  
  
  env:
  
   
  
  
  - name: GET_HOSTS_FROM
  
   
  
  
  
  value: dns
  
   
  
  
  ports:
  
   
  
  
  - containerPort: 8080",NA
To create this deployment on the cluster using ,kubectl,NA
", you will need to execute ",NA,NA
"the following command, which is exactly the same as when creating a service, ",NA,NA
with a difference in the filename:,$ kubectl create -f deployment.yml,NA
You can look at the deployment properties with: ,$ kubectl describe deployment rest-service,NA
"As you can see, one Pod has been created along with a ReplicaSet and the default ",NA,NA
rolling update strategy. You can also look at the Pods with: ,$ kubectl get pods,NA
The output of ,get pods,NA
 command will give you the names of Pods running in the ,NA,NA
"deployment. This is will be important later, because if you want to interact with a ",NA,NA
"specific Pod, you will need to know its name:",NA,NA
As an alternative to the deployment descriptor in ,.yaml,NA
" file, you can create",NA,NA
deployments from the command line using ,kubectl run,NA
" command with options, as ",NA,NA
you can see in the following example:,"$ kubectl run rest-example --image=jotka/rest-example --replicas=1 --port=8080 --labels=""app:",NA
Let's summarize the ,kubectl,NA
 commands related to creating resources and getting ,NA,NA
"information about them, with some examples, in a table:",NA,NA
Example command,NA,NA
Meaning,kubectl create -f ./service.yaml,NA
Create resource(s),"kubectl create -f ./service.yaml -f 
 ./deployment.yaml",NA
Create from multiple files,kubectl create -f ./dir,NA
Create resource(s) in all manifest files ,NA,NA
in the specified directory,kubectl create -f https://sampleUrl,NA
Create resource(s) from URL,kubectl run nginx --image=nginx,NA
Start a single instance of nginx,Kubectl get pods,NA
Get the documentation for ,"pod
  
 kubectl get pods --
  
 selector=app=rest-example",NA
List all the Pods that match the specified ,NA,NA
label ,"selector
  
 kubectl explain pods",NA
Show details of all Pods,NA,NA
List all created services,kubectl explain service,NA
Show details of specified service,kubectl explain services,NA
Show details of all created services,kubectl get deployments,NA
List all created deployments,kubectl get deployment,NA
Show details of specified service,kubectl explain deployment,NA
Show details of specified deployment,kubectl explain deployments,NA
Show details of all created deployments,kubectl get nodes,NA
List all cluster nodes,kubectl explain node,NA
Show details of specified node,Calling the service,NA
As we have seen on the ,kubectl,NA
 describe service ,rest-example,NA
" command output, our ",rest-example service,NA
 can be accessed within the cluster via port ,8080,NA
 and the domain ,NA,NA
name ,rest-example,NA
". In our case, the complete URL of the endpoint would be ",http://rest-example:8080,NA
". However, to be able to execute the service from the outside ",NA,NA
"world, we have used the ",NodePort,NA
" mapping, and we know that it was given the port ",31141,NA
. All we need to call the service is the IP of the cluster. We can get it using the ,NA,NA
following command:,$ minikube ip,NA
There's a shortcut for getting to know the externally accessible service URL and a ,NA,NA
port number. We can use a ,minikube service,NA
 command to tell us the exact service ,NA,NA
address:,$ minikube service rest-example --url,NA
The output of the previous command will be the service URL with a mapped port ,NA,NA
number. If you skip the ,--url,NA
" switch, ",minikube,NA
 will just open the service's URL using ,NA,NA
your default web browser. This is sometimes handy.,NA,NA
"Having the complete URL of the endpoint, we can access the service, using any of ",NA,NA
the ,HTTP,NA
" clients, such as ",curl,NA
", for example:",NA,NA
"When the service is running, application logs can often help you understand what is ",NA,NA
happening inside your cluster. The logs are particularly useful for debugging ,NA,NA
problems and monitoring cluster activity. Let's see how we can access our container ,NA,NA
logs.,NA,NA
Interacting with containers and viewing,NA,NA
logs,NA,NA
Most modern applications have some kind of logging mechanism. Our Java REST ,NA,NA
"service, for example, uses slf4j to output logs from the REST controller. The easiest ",NA,NA
and most simple logging method for containerized applications is just to write to the ,NA,NA
standard output and standard error streams. Kubernetes supports this out of the box.,NA,NA
"Assuming we've sent requests to our new web service using the browser or curl, we ",NA,NA
"should now be able to see some logs. Prior to that, we need to have a Pods name, ",NA,NA
"created automatically during deployment. To get the Pod's name, use the ","kubectl get 
 pods",NA
" command. After that, you can show logs of the specified Pod:",$ kubectl logs rest-example-3660361385-gkzb8,NA
"As you can see in the following screenshot, we will get access to a well-known ",NA,NA
Spring Boot banner coming from a service running in a Pod:,NA,NA
Viewing the log is not the only thing we can do with a specific Pod. Similar to ,NA,NA
"Docker (a Pod is running Docker, actually), we can interact with a container by using ",NA,NA
the ,kubectl exec,NA
" command. For example, to get a shell to the running container:",$ kubectl exec -it rest-example-3660361385-gkzb8 -- /bin/bash,NA
The previous command will attach your shell console into the shell in the running ,NA,NA
"container, where you can interact with it, such as listing the processes, for example, ",NA,NA
as you can see in the following screenshot:,NA,NA
The syntax of a ,kubectl exec,NA
 command is very similar to the ,exec,NA
 command in ,NA,NA
"Docker, with one little difference, as you remember from the ",NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction ,NA,NA
to Kubernetes,NA,NA
", a Pod can run more than one container. In such case, we can use ","--
 container",NA
 or ,-c,NA
 command switch to specify a container in the ,kubectl exec,NA
 command. ,NA,NA
"For example, let's suppose we have a Pod named ",rest-example-3660361385-gkzb8,NA
. This ,NA,NA
Pod has two containers named service and database. The following command would ,NA,NA
open a shell to the service container:,$ kubectl exec -it rest-example-3660361385-gkzb8 --container service -- /bin/bash,NA
Having the possibility to view logs and interact with the containers gives you a lot of ,NA,NA
flexibility to pinpoint potential problems you may have with running Pods. Let's ,NA,NA
summarize the ,kubectl,NA
 commands related to viewing logs and interacting with the ,NA,NA
Pods in a table:,NA,NA
Example command,NA,NA
Meaning,kubectl logs myPod,NA
Dump ,pod,NA
 logs (,stdout,NA
),kubectl logs myPod -c myContainer,NA
Dump ,pod,NA
 container logs (,stdout,NA
", multi-",NA,NA
container case),NA,NA
Stream ,pod,NA
 logs (,stdout,NA
),"kubectl logs -f myPod -c 
 myContainer",NA
Stream ,pod,NA
 container logs (,stdout,NA
", multi-",NA,NA
container case),"kubectl run -i --tty busybox --
 image=busybox -- sh
  
 run pod",NA
 as interactive shell,kubectl attach myPod -i,NA
Attach to running container,"kubectl port-forward myPod 
 8080:8090",NA
Forward port ,8080,NA
 of Pod to your to ,8090,NA
 on ,NA,NA
your local machine,"kubectl exec myPod -- ls /
  
 run",NA
 command in existing ,pod,NA
 (one container ,NA,NA
case),"kubectl exec myPod -c myContainer -- 
 ls /
  
 run",NA
 command in existing ,pod,NA
 (multi-container ,NA,NA
case),"kubectl top pod POD_NAME --
 containers",NA
Show metrics for a given ,pod,NA
 and its ,NA,NA
containers,NA,NA
"As you already know, Pods and containers are fragile. They can crash or be killed. ",NA,NA
You can use ,kubectl,NA
 logs to retrieve logs from a previous instantiation of a container ,NA,NA
with the ,--previous,NA
" flag, in case the container has crashed. Let's say our service is ",NA,NA
"running fine, but for the reasons described in the ",NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to ,NA,NA
Kubernetes,NA,NA
", such as higher load, for example, you decide to increase the number of ",NA,NA
containers running. Kubernetes gives you the possibility to increase the number of,NA,NA
Pod instances running in each service. This can be done manually or automatically. ,NA,NA
Let's focus on the manual scaling first.,NA,NA
Scaling manually,NA,NA
"When the deployment has been created, the new ReplicaSet has also been created, ",NA,NA
automatically. As you will remember from ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", a ",NA,NA
"ReplicaSet ensures that a specified number of Pod clones, known as ",replicas,NA
", are ",NA,NA
"running at any given time. It there are too many, some of them will be shut down. If ",NA,NA
"there is a need for more, for example if some of them died because of an error or ",NA,NA
"crash, new Pods will be created. Note that if you try to scale the ReplicaSet directly, ",NA,NA
"then it will (for a very short time) have a new count of your desired number of Pods, ",NA,NA
for example three. But if the deployment controller sees that you have modified the ,NA,NA
"replica set to three, since it knows that it is supposed to be one (defined in the ",NA,NA
"deployment manifest), it will reset it back to one. By manually modifying the replica ",NA,NA
"set that was created for you, you are, kind of, dealing against the system controller.",NA,NA
You need to scale your deployment instead of the replica set directly.,NA,NA
"Of course, our Java ",rest-example,NA
" service keeps its data in memory so it's not stateless, ",NA,NA
"so it may be not the best example for scaling; if another instance is brought to life, it ",NA,NA
"will have its own data. However, it is a Kubernetes service, so we can use it to ",NA,NA
demonstrate scaling anyway. To scale up our ,rest-example,NA
 deployment from one up to ,NA,NA
"three Pods, execute the following ",kubectl scale,NA
 command:,$ kubectl scale deployment rest-example --replicas=3,NA
"After a short while, in order to check, execute the following commands, you will see ",NA,NA
that now three Pods are running in the deployment:,"$ kubectl get deployments 
  
 $ kubectl get pods",NA
"In the following table, you can see some more examples of ",kubectl,NA
 commands related ,NA,NA
to manual scaling:,NA,NA
Example command,NA,NA
Meaning,NA,NA
Scale a deployment named ,rest-example,NA
to ,3,NA
 Pods,"kubectl scale --replicas=3 -f 
 deployment.yaml",NA
Scale a resource specified in ,deployment.yaml,NA
 file to ,"3
  
 kubectl scale deployment rest-example --
 current-replicas=2 --replicas=3",NA
If the deployment named ,rest-example,NA
current size is ,2,NA
", scale it to ",3,NA
 Pods,"kubectl scale --replicas=5 
  
 deployment/foo deployment/bar",NA
Scale multiple deployments at one time,NA,NA
"Scaling can be done automatically by Kubernetes, if, for example, the service load",NA,NA
increases.,NA,NA
Autoscaling,NA,NA
"With horizontal Pod auto scaling, Kubernetes automatically scales the number of ",NA,NA
Pods in a deployment or ReplicaSet based on observed CPU utilization. The ,NA,NA
Kubernetes controller periodically adjusts the number of Pod ,replicas,NA
 in a ,NA,NA
deployment to match the observed average CPU utilization to the target you ,NA,NA
specified.,NA,NA
"The Horizontal Auto Scaler is just another type of resource in Kubernetes, so we can ",NA,NA
"create it as any other resource, using the ",kubectl,NA
 commands:,kubectl get hpa,NA
: List autoscalers,kubectl describe hpa,NA
: Get detailed description,kubectl delete hpa,NA
: Delete an autoscaler,NA,NA
"Additionally, there is a special ",kubectl autoscale,NA
command for easy creation of a ,NA,NA
Horizontal Pod Autoscaler. An example could be:,$ kubectl autoscale deployment rest-example --cpu-percent=50 --min=1 --max=10,NA
The previous command will create an autoscaler for our ,rest-example,NA
" deployment, ",NA,NA
with the target CPU utilization set to ,50,NA
% and the number of ,replicas,NA
 between ,1,NA
 and ,10,NA
.,NA,NA
"All cluster events are being registered, including those which come from scaling, ",NA,NA
either manually or automatically. Viewing cluster events can be helpful when ,NA,NA
monitoring what exactly is being performed on our cluster.,NA,NA
Viewing cluster events ,NA,NA
"To view cluster events, type the following command: ",$ kubectl get events,NA
"It will present a huge table, with all the events registered on the cluster:",NA,NA
"The table will include the changes in the status of nodes, pulling Docker images, ",NA,NA
"events of starting and stopping containers, and so on. It can be very handy to see the ",NA,NA
picture of the whole cluster.,NA,NA
Using the Kubernetes dashboard,NA,NA
"Kubernetes dashboard is a general purpose, web-based UI for Kubernetes clusters. It ",NA,NA
"allows users to manage applications running in the cluster and troubleshoot them, as ",NA,NA
"well as manage the cluster itself. We can also edit the manifest files of deployment, ",NA,NA
"services, or Pods. The changes will be picked up immediately by Kubernetes, so it ",NA,NA
"gives us the capability to scale down or up the deployment, for example.",NA,NA
If you open the dashboard with the ,minikube dashboard,NA
" command, it will open your ",NA,NA
"default browser with a dashboard URL. From here, you can list all the resources on ",NA,NA
"the cluster, such as deployments, services, Pods, and so on. Our dashboard is no ",NA,NA
"longer empty, as you can see in the following screenshot; we have one deployment ",NA,NA
called ,rest-example,NA
:,NA,NA
"If you click on its name, you will be taken to the deployment details page, which will ",NA,NA
show the same information you could get with the ,kubectl describe deployment,NA
"command, with a nice UI:",NA,NA
The dashboard is not only read-only utility. Each resource has a handy menu which ,NA,NA
you can use to delete it or to edit its manifest:,NA,NA
"If you pick the view/edit YAML menu option, you will be able to edit the manifest ",NA,NA
with a handy editor:,NA,NA
"Note that if you change a value, for example the number of ",replicas,NA
", and click ",NA,NA
"Update, the change will be sent to the Kubernetes and executed. This way you can ",NA,NA
"also, for example, scale your deployment.",NA,NA
"As deployment has created a ReplicaSet automatically, the ReplicaSet will also be ",NA,NA
visible in the dashboard:,NA,NA
"The same applies to services. If you browse to the Services menu, it will present a ",NA,NA
list of all services created on a cluster:,NA,NA
Clicking on the name of service will take you to the details page:,NA,NA
"On the details screen, all important information is listed. This includes label selector, ",NA,NA
"that will be used to find Pods, port type, cluster IP, internal endpoints, and of course ",NA,NA
"the list of Pods running inside the service. By clicking Pod's name, you can see ",NA,NA
"details of a running Pod, including its log output, as you can see in the following ",NA,NA
screenshot:,NA,NA
"The dashboard is a very handy tool to interact with your existing deployments, ",NA,NA
"services, and Pods. But there's more. If you click on the Create button in the top right ",NA,NA
"corner of the dashboard's toolbar, you will be presented with a Deploy a ",NA,NA
"Containerized App screen. From here, you can actually create a new deployment:",NA,NA
You have an opportunity to use the ,.yaml,NA
" file, as we did before using the command ",NA,NA
"line, but also you can specify details of the deployment manually, providing an ",NA,NA
"application name, and container image to use and optionally create a service for the ",NA,NA
"deployment. Quite handy, isn't it? The dashboard is just one of the Minikube add-ons ",NA,NA
available. Let's look at what else we have at our disposal.,NA,NA
Minikube addons,NA,NA
"Minikube comes with several add-ons, such as Kubernetes dashboard, Kubernetes ",NA,NA
"DNS, and so on. We can list the available addons by executing the following ",NA,NA
command:,$ minikube addons list,NA
The output of the previous command will list the available addons with their current ,NA,NA
"status, for example:",NA,NA
"To enable or disable the addon, we use ",minikube addons disable,NA
 or ,"minikube addons 
 enable",NA
", respectively, for example:","$ minikube addons disable dashboard 
  
 $ minikube addons enable heapster",NA
"If the add-on is enabled, we can the corresponding web user interface by executing ",NA,NA
the ,addon open,NA
" command, for example:",$ minikube addons open heapster,NA
Cleaning up,NA,NA
If you finish playing with your deployment and services or would like to start from ,NA,NA
"the beginning, you can do some cluster cleaning by removing the deployment or ",NA,NA
services:,"$ kubectl delete deployment rest-example 
  
 $ kubectl delete service rest-example",NA
"This code can also be combined in one command, for example:","$ kubectl delete service,deployment rest-example",NA
The ,kubectl delete,NA
 supports label ,selectors,NA
 and namespaces. Let's see some other ,NA,NA
examples of the command in a table:,NA,NA
Example command,NA,NA
Meaning,"kubectl delete pod,service baz foo",NA
Delete pods and services with same names ,baz,NA
 and ,"foo
  
 kubectl delete pods,services -l 
 name=myLabel",NA
Delete pods and services with label ,"name=myLabel
  
 kubectl -n my-ns delete po,svc --all",NA
Delete all pods and services in namespace ,my-ns,NA
To stop the ,minikube,NA
" cluster, issue simply:",$ minikube stop,NA
If you would like to delete the current ,minikube,NA
" cluster, you can issue the following ",NA,NA
command to do it:,$ minikube delete,NA
Summary,NA,NA
"As you can see, the Minikube is an easy way to try out Kubernetes and use it for ",NA,NA
local development. Running the local cluster is not as scary as it may have seemed at ,NA,NA
"the beginning. Best of all, the local ",minikube,NA
 cluster is a valid Kubernetes cluster. If ,NA,NA
"you get to know Kubernetes by playing with it locally, you will be able to deploy ",NA,NA
your applications in the real cloud without any issues. Let's summarize the steps that ,NA,NA
we need to perform to make our Java application run on the Kubernetes cluster.,NA,NA
"First, we need to write some code for our microservice. This can be based on ",NA,NA
"whatever you want, it can be a microservice running on Tomcat, JBoss, or Spring ",NA,NA
"Bootstrap. It doesn't matter, you just choose the technology you want your software ",NA,NA
to run with:,NA,NA
"Next, put the code into Docker image. You can do it by hand by creating a ",NA,NA
Dockerfile or you can use Docker Maven plugin to automate this,NA,NA
"Create Kubernetes metadata, such as deployment manifest and service manifest",NA,NA
Apply the metadata by rolling out the deployment and creating the service,NA,NA
Scale your applications to your needs,NA,NA
Manage your cluster either from the command line or from the dashboard,NA,NA
In ,NA,NA
Chapter 9,NA,NA
", ",NA,NA
Working with Kubernetes API,NA,NA
", we will take a look at the Kubernetes ",NA,NA
"API. This is a great way of interacting with Kubernetes cluster. Because of API, the ",NA,NA
"possibilities are almost endless, you can create your own development flows, such as ",NA,NA
"continuous delivery using Jenkins, for example. Having the API, you are not limited ",NA,NA
only to existing tools to deploy your software to Kubernetes. Things can get more ,NA,NA
interesting.,NA,NA
Working with the Kubernetes API,NA,NA
 In ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", and ",NA,NA
Chapter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
", ",NA,NA
we learned about the Kubernetes concepts and used them in practice by installing ,NA,NA
local Kubernetes clusters with ,minikube,NA
. We know all the pieces of Kubernetes ,NA,NA
"architecture, such as pods, nodes, deployment, and services, for example. We have ",NA,NA
"also mentioned one of the main components residing on the Master node, which is ",NA,NA
the API server. As you remember from ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", the API ",NA,NA
server is technically a process named ,kube-apiserver,NA
 that accepts and responds to ,"HTTP 
 REST",NA
 requests using JSON. The API server's main purpose is to validate and process ,NA,NA
"data of cluster resources, such as Pods, services, or deployments. The API Server is ",NA,NA
the central management entity. It's also the only Kubernetes component that directly ,NA,NA
connects to ,etcd,NA
", a distributed key-value data store where Kubernetes stores all its ",NA,NA
cluster state.,NA,NA
"In previous chapters, we've been using a ",kubectl,NA
 command-line tool to manage our ,NA,NA
cluster. ,Kubectl,NA
" is a useful utility, whenever we want to execute commands against ",NA,NA
"our cluster, either for creating, editing, or removing resources. In fact ",kubectl,NA
 also ,NA,NA
communicates with the API server; you may have noticed that almost every action in ,NA,NA
Kubernetes that changes something is basically editing a resource. If you want to ,NA,NA
"scale up or down your application, this will be done by modifying the deployment ",NA,NA
resource. Kubernetes will pick up the change on the fly and apply it to the resource.,NA,NA
"Also, read-only operations such as listing Pods or deployments, will execute the ",NA,NA
corresponding ,GET,NA
 request.,NA,NA
"In fact, you can see what ",REST,NA
 calls are being made by the ,kubectl,NA
 command if you ,NA,NA
"run it with a higher level of verbosity, with the ",--v=6,NA
 or ,--v=9,NA
" option, we will get back ",NA,NA
to it later in this chapter. We can access the API using ,kubectl,NA
", ",client,NA
" libraries, or by ",NA,NA
making ,REST,NA
 requests. When can the ,REST,NA
" API be useful? Well, you can create a ",REST,NA
call in every programming or scripting language. This creates a whole new level of ,NA,NA
"flexibility, you can manage Kubernetes from your own Java application, from your ",NA,NA
"continuous delivery flow in Jenkins, or from the build tool you are using, let it be ",NA,NA
"Maven for example. Possibilities are almost endless. In this chapter, we will get to ",NA,NA
"know the API overview, its structure, and example requests. We will be doing this ",NA,NA
using the ,REST,NA
 calls with the command-line ,curl,NA
 utility. This chapter will cover the ,NA,NA
following topics:,NA,NA
Explanation about the API versioning,NA,NA
Authentication (determining who is who),NA,NA
Authorization (determining who can do what),NA,NA
Using the API by making some example calls,NA,NA
OpenAPI Swagger documentation,NA,NA
Let's gets started with an API overview.,NA,NA
API versioning,NA,NA
Kubernetes grows continuously. Its features change and this results in the API ,NA,NA
changing as well. To deal with those changes and to not break compatibility with ,NA,NA
"existing clients over an extended period of time, Kubernetes supports multiple API ",NA,NA
"versions, each with a different API path, such as ",/api/v1,NA
 or ,/apis/extensions/v1beta1,NA
.,NA,NA
"There are three API levels in the Kubernetes API specification: alpha, beta, and ",NA,NA
stable. Let's get to know the difference.,NA,NA
Alpha,NA,NA
"The alpha version level is disabled by default, as with the other software, an alpha ",NA,NA
"version should be considered as buggy and not production ready. Also, you should ",NA,NA
note that any featured introduced in the alpha version might not always be available ,NA,NA
"later, in the stable version. Also, the changes in the API may be incompatible in the ",NA,NA
next release. You should not use the ,alpha,NA
" version, unless you are very eager to test ",NA,NA
new features or do some experiments.,NA,NA
Beta,NA,NA
The beta level totally different from the ,alpha,NA
" level of the API, code is tested (it still ",NA,NA
"may have some bugs, as it is still not the ",stable,NA
" release). Also, in contrast to the ",alpha,NA
"level, features in ",beta,NA
" will not be dropped in the future releases. If there is a breaking, ",NA,NA
"not backward compatible change in the API, Kubernetes team will provide a guide ",NA,NA
on how to migrate. Using ,beta,NA
" on a production environment is not the best idea, but ",NA,NA
you can safely use ,beta,NA
 on a non-business critical cluster. You are also encouraged to ,NA,NA
provide feedback from using ,beta,NA
", this will make Kubernetes better for everyone of ",NA,NA
us using it. A version name in the ,beta,NA
 level will contain the word ,beta,NA
", such as ",v1beta1,NA
 for example.,NA,NA
Stable,NA,NA
"The stable level of the API is a tested, production-ready software. The version name ",NA,NA
in the stable API will be ,vX,NA
 where ,X,NA
" is an integer number, such as ",v1,NA
 for example.,NA,NA
Kubernetes API utilizes a concept of API groups. API groups have been introduced ,NA,NA
to make it easier to extend the Kubernetes API in the future. The API group is ,NA,NA
specified in a ,REST,NA
 path and in the ,apiVersion,NA
 field of a call's JSON payload.,NA,NA
"Currently, there are several API groups in use: core, batch, and extensions. The ",NA,NA
group name is a part of the ,REST,NA
 path of an API call: ,/apis/$GROUP_NAME/$VERSION,NA
. The ,NA,NA
"core group is an exception, it does not show up in the ",REST,NA
" path, for example: ",/api/v1,NA
. ,NA,NA
You can find the full list of supported API groups in the Kubernetes API ,NA,NA
reference.,NA,NA
"By using the API, you can do almost anything with your cluster, as you would ",NA,NA
normally do using the ,kubectl,NA
 command. This can be dangerous; that's why ,NA,NA
Kubernetes supports authentication (determining who you are) and authorization ,NA,NA
(what you can do). The basic flow of calling the API service is presented in the ,NA,NA
following diagram:,NA,NA
Let's begin with the authentication.,NA,NA
Authentication,NA,NA
"By default, the Kubernetes API server serves ",HTTP,NA
 requests on two ports:,NA,NA
Localhost,NA,NA
", ",NA,NA
unsecured port,NA,NA
": By default, the IP address is ",localhost,NA
 and a port ,NA,NA
number is ,8080,NA
". There is no TLS communication, all requests on this port ",NA,NA
bypasses authentication and authorization plugins. This is intended for testing ,NA,NA
"and bootstrap, and for other components of the master node. This is also used to ",NA,NA
other Kubernetes components such as scheduler or controller-manager to ,NA,NA
execute API calls. You can change the port number with the ,--insecure-port,NA
"switch, and the default IP by using the ",--insecure-bind-address,NA
 command-line ,NA,NA
switch.,NA,NA
Secure port,NA,NA
: The default port number is ,6443,NA
 (it can be changed with the ,"`--
  
 secure-port",NA
" switch), usually it's ",443,NA
 on Cloud providers. It uses TLS ,NA,NA
communication. A certificate can be set with a ,--tls-cert-file,NA
 switch. A private ,NA,NA
SSL key can be provided with a ,--tls-private-key-file,NA
 switch. All requests ,NA,NA
coming through this port will be handled by authentication and authorization ,NA,NA
modules and admission control modules. You should use the secure port ,NA,NA
whenever possible. By having your API clients verify the TLS certificate ,NA,NA
presented by the ,api-server,NA
", they can verify that the connection is both ",NA,NA
encrypted and not susceptible to man-in-the-middle attacks. You should also be ,NA,NA
running the ,api-server,NA
" where the insecure port is only accessible to localhost, so ",NA,NA
that connections that come across the network use ,HTTP,NA
's.,NA,NA
"With minikube, to access the API server directly, you'll need to use the custom ",NA,NA
SSL certs that have been generated by minikube. The client certificate and key ,NA,NA
are typically stored in ,~/.minikube/apiserver.crt,NA
 and ,~/.minikube/apiserver.key,NA
. ,NA,NA
You'll have to load them into your ,HTTP,NA
'S client when you make ,HTTP,NA
 requests. If ,NA,NA
you're using ,curl,NA
 use the,--cert,NA
 and the ,--key,NA
 options to use the ,cert,NA
 and ,key,NA
 file.,NA,NA
"The access to the API server can be simplified through the proxy, ",NA,NA
which we will start later in this chapter.,NA,NA
"If you want to send requests to the Kubernetes API from a different domain, you will ",NA,NA
need to enable ,cors,NA
 on ,api-server,NA
. You do that by adding a ,"--cors-allowed-origins= 
 [""http://*""]",NA
 argument to ,kube-apiserver,NA
" configuration, typically in the ",/etc/default/kube-apiserver,NA
 file and restart ,kube-apiserver,NA
.,NA,NA
"Note that Kubernetes cluster does not manage users by itself. Instead, users are ",NA,NA
"assumed to be managed by an outside, independent service. There is no resource in ",NA,NA
Kubernetes cluster that represents normal user accounts,NA,NA
.,NA,NA
 That's why users cannot be ,NA,NA
added to a cluster through an API call.,NA,NA
Kubernetes does not manage user accounts by itself.,NA,NA
The Kubernetes API supports multiple forms of authentication: ,HTTP,NA
" basic auth, ",NA,NA
"bearer token, and client certificates. They are called authentication strategies. When ",NA,NA
launching the ,api-server,NA
", you can enable or disable each of these authentication ",NA,NA
"strategies with command-line flags. Let's look what's possible, starting with the ",NA,NA
"simplest, basic auth strategy.",NA,NA
HTTP basic auth,NA,NA
"To use this authentication strategy, you will need to start the ",api-server,NA
 with the ,"--
 basic-auth-file=<path_to_auth_file>",NA
 switch. It should be a ,csv,NA
 file with the following ,NA,NA
entry for each user:,"password, user name, userid",NA
"You can also specify an optional fourth column containing group names, separated ",NA,NA
"by a comma. If there is more than one group for the user, the whole column contents ",NA,NA
"must be enclosed in double quotes, for example:","password, user, userid,""group1,group2,group3""",NA
If the ,api-server,NA
" utilizes the basic auth strategy, it will expect all ",REST,NA
 calls to be made ,NA,NA
with the ,Authorization,NA
 header containing username and password encoded in ,BASE64,NA
"(similar to ordinary basic auth protected web calls), for example:",BASE64ENCODED(USER:PASSWORD),NA
"To generate the authorization header value, you can use the following command in ",NA,NA
"the shell, it will generate the value for user having password secret:","echo -n ""user:secret"" | base64",NA
Note that any changes to the basic ,auth,NA
 file will require a restart of the ,api-server,NA
 to ,NA,NA
pick up the changes.,HTTP,NA
 basic auth is typically used as default when running Kubernetes in the cloud. For ,NA,NA
"example, once you launch your container cluster on Google Container Engine, you ",NA,NA
will have a master running the ,api-server,NA
 on a VM in your GCP project. If you run a ,gcloud preview container clusters,NA
" list, you will see the endpoint at which the ",api-server,NA
 ,NA,NA
listens for requests as well as the credentials needed to access it. You will find more ,NA,NA
on running Kubernetes in the cloud in ,NA,NA
Chapter 10,NA,NA
", ",NA,NA
Deploying Java on ,NA,NA
Kubernetes in the Cloud,NA,NA
.,NA,NA
Static token file,NA,NA
To make ,api-server,NA
" use this scheme, it needs to be started with the ","--token-auth-file= 
 <PATH_TO_TOKEN_FILE>",NA
 switch. Similar to the ,HTTP,NA
" basic auth strategy, the provided file is ",NA,NA
a ,csv,NA
 file with a record for every user. The record needs to be in the following ,NA,NA
format:,"token, user, userid, group",NA
"Again, the group name is optional and if there is more than one group for the user, ",NA,NA
you will need to separate them with a comma and enclose them in double quotes. ,NA,NA
The token is just a ,base64,NA
 encoded string. An example command to generate a token ,NA,NA
on Linux can be as follows:,"$ echo `dd if=/dev/urandom bs=128 count=1 2>/dev/null | base64 | tr -d ""=+/"" | dd bs=32 count",NA
"The output will be a token, which you then enter into the ",token,NA
" file, for example:","3XQ8W6IAourkXOLH2yfpbGFXftbH0vn,default,default",NA
"When using this strategy, ",api-server,NA
 will be expecting an ,Authorization,NA
 header with a ,NA,NA
value of ,Bearer <TOKEN>,NA
". In our example, this will looks the same as the following:",Authorization: Bearer 3XQ8W6IAourkXOLH2yfpbGFXftbH0vn,NA
"Tokens last indefinitely, and the token list cannot be changed without restarting API ",NA,NA
server.,NA,NA
Client certificates,NA,NA
"In order to use this scheme, the ",api-server,NA
 needs to be started with the following ,NA,NA
switch:,--client-ca-file=<PATH_TO_CA_CERTIFICATE_FILE>,NA
The ,CA_CERTIFICATE_FILE,NA
 must contain one or more certificates authorities that can be ,NA,NA
used to validate client certificates presented to the ,api-server,NA
. The /CN (common ,NA,NA
name) of the client certificate is used as the username. Client certificates can also ,NA,NA
indicate a user's group memberships using the organization fields. To include ,NA,NA
multiple group memberships for a user you will need to include multiple ,NA,NA
"organization fields in the certificate. For example, using the ",openssl,NA
 command-line ,NA,NA
tool to generate a certificate signing request:,"$ openssl req -new -key user.pem -out user-csr.pem \-
 subj ""/CN=user/O=group1/O=group2""",NA
This would create a certificate signing request for the username ,user,NA
", belonging to ",NA,NA
"two groups, ",group1,NA
 and ,group2,NA
.,NA,NA
OpenID,NA,NA
OpenID connect 1.0 is a simple identity layer on top of the OAuth 2.0 protocol. You ,NA,NA
can read more about OpenID connect on the internet at ,https://openid.net/connect,NA
. It ,NA,NA
allows clients to verify the identity of the end-user based on the authentication ,NA,NA
"performed by an authorization server, as well as to obtain basic profile information ",NA,NA
about the end-user in an interoperable and ,REST,NA
"-like manner. All cloud providers, ",NA,NA
"including Azure, Amazon, and Google support OpenID. The main difference with ",OAuth2,NA
 is the additional field returned with the access token called an ,id_token,NA
. This ,NA,NA
token is a ,NA,NA
JSON Web Token,NA,NA
 (,NA,NA
JWT,NA,NA
) with well-known fields (user's email for ,NA,NA
"example), signed by the server. To identify the user, the authenticator uses ",NA,NA
the ,id_token,NA
 from the ,OAuth2token,NA
 response as a bearer token. To use the OpenID ,NA,NA
"authentication, you will need to log in to your identity provider, which will provide ",NA,NA
you with an ,id_token,NA
 (and also standard OAuth 2.0 ,access_token,NA
 and a ,refresh_token,NA
),NA,NA
.,NA,NA
Since all of the data needed to do the authentication is contained within the ,id_token,NA
", ",NA,NA
Kubernetes does not need to make an additional call to the identity provider. This is ,NA,NA
"very important from the scalability purposes, every request is stateless.",NA,NA
To provide a token value to the ,kubectl,NA
" command, you will need to use the ",--token,NA
"flag. Alternatively, you can add it directly to your ",kubeconfig,NA
 file.,NA,NA
This is the simplified flow of things that will happen if you execute a ,HTTP,NA
 call to ,NA,NA
your ,api-server,NA
:,kubectl,NA
 will send your ,id_token,NA
 in an ,authorization,NA
 header to the API server,NA,NA
The API server will validate the JWT signature by checking against the ,NA,NA
certificate named in the configuration,NA,NA
The API server will check to make sure the ,id_token,NA
 hasn't expired,NA,NA
"The API server will make sure the user is authorized, and returns a response to ",kubectl,NA
 if so,NA,NA
"By default, anyone who has access credentials to the ",api-server,NA
 has full access to the ,NA,NA
"cluster. You can also configure more fine grained authorization policies, let's look at ",NA,NA
authorization now.,NA,NA
Authorization,NA,NA
The next step after the successful authentication is to check what operations are ,NA,NA
allowed for the authenticated user. Kubernetes supports four types of authorization ,NA,NA
"policy schemes as of today. To utilize the specific authorization schema, use the ","--
 authorization-mode",NA
 switch when starting ,api-server,NA
. The syntax is:,$ kube-apiserver --authorization-mode <mode>,NA
The ,<mode>,NA
 parameter contains an ordered list of authorization plugins that ,NA,NA
Kubernetes is supposed to authenticate users with. When multiple authentication ,NA,NA
"plugins are enabled, the first one that will successfully authenticate the request will ",NA,NA
make Kubernetes skip executing all remaining plugins.,NA,NA
The default authorization mode is ,AlwaysAllow,NA
", which allows all requests.",NA,NA
The following authorization schemes are supported:,NA,NA
Attribute-based control,NA,NA
Role-based control,NA,NA
Webhook,"AlwaysDeny
  
  
 AlwaysAllow",NA
"Let's describe them, one by one, briefly.",NA,NA
Attribute-based access control ,NA,NA
Attribute-Based Access Control,NA,NA
 (,NA,NA
ABAC,NA,NA
) policy will be used if you start the ,"api-
 server",NA
 with the ,--authorization-mode=ABAC,NA
 option. This policy uses local files in which ,NA,NA
"you can, in a flexible way, define permission every user should have. There is an ",NA,NA
additional option to provide a policy file: ,--authorization-policy-file,NA
", so the complete ",NA,NA
syntax to use this policy will be:,"$ kube-apiserver --authorization-mode=ABAC \
  
 --authorization-policy-file=<PATH_TO_ POLICY_FILE>",NA
Note that any changes to policy file will require a restart of the ,api-server,NA
.,NA,NA
As you remember from ,NA,NA
Chapter 7,NA,NA
", ",NA,NA
Introduction to Kubernetes,NA,NA
", Kubernetes clusters ",NA,NA
"use the concept of namespaces to group related resources, such as Pods, ",NA,NA
"deployments, or services. The authorization schemas in the ",api-server,NA
's make use of ,NA,NA
these namespaces. The ,ABAC,NA
 policy file syntax is rather clear and readable. Each entry ,NA,NA
is a JSON object describing the authorization rule. Consider the following entry in ,NA,NA
"the policy file, which gives user ",john,NA
 complete access to the namespace ,myApp,NA
:,"{
  
  
  ""apiVersion"": ""abac.authorization.kubernetes.io/v1beta1"", 
  
  ""kind"": ""Policy"", 
  
  
  ""spec"": {
  
  
  
  ""user"":""john"", 
  
  
  
  ""namespace"": ""myApp"", 
  
  
  
  ""resource"": ""*"", 
  
  
  
  ""apiGroup"": ""*"", 
  
  
  
  ""nonResourcePath"": ""*"" 
  
  
  } 
  
 }",NA
The next example will give user ,admin,NA
 complete access to all the namespaces:,"{
  
  
  ""apiVersion"": ""abac.authorization.kubernetes.io/v1beta1"", 
  
  ""kind"": ""Policy"", 
  
  
  ""spec"":{
  
  
  
  ""user"":""admin"", 
  
  
  
  ""namespace"": ""*"", 
  
  
  ""resource"": ""*"", 
  
  
  ""apiGroup"": ""*"", 
  
  
  ""nonResourcePath"": ""*"" 
  
  
  } 
  
 }",NA
"And finally, an example that gives all users read-only access to the entire cluster:",NA,NA
Role-based access control (RBAC),NA,NA
The ,NA,NA
Role-Based Access Control,NA,NA
 (,NA,NA
RBAC,NA,NA
"), policy implementation is deeply ",NA,NA
"integrated into Kubernetes. In fact, Kubernetes uses it internally for the system ",NA,NA
"components, to grant the permissions necessary for them to function. ",RBAC,NA
 is 100% ,NA,NA
"API driven, roles and bindings are API resources that an administrator can write and ",NA,NA
"create on the cluster such as other resources such as Pods, deployments, or services.",NA,NA
Enabling ,RBAC,NA
 mode is as easy as passing a flag to ,kube-apiserver,NA
:,--authorization-mode=RBAC,NA
This mode allows you to create and store policies using the Kubernetes API. In the ,RBAC,NA
" API, a set of permission is represented by the concept of role. There is a ",NA,NA
"distinction between namespace roles, represented by a ",Role,NA
" resource, and a whole ",NA,NA
"cluster role, represented by a ",ClusterRole,NA
 resource. A ,ClusterRole,NA
 can define the same ,NA,NA
all permissions a ,Role,NA
" can define, but also some cluster-related permission, such as ",NA,NA
managing cluster nodes or modifying resources across all available namespaces.,NA,NA
Note that once ,RBAC,NA
" is enabled, every aspect of the API is disallowed access.",NA,NA
Permissions are additive; there are no deny rules.,NA,NA
This is an example of role that gives the whole set of available permissions to ,NA,NA
all operations on all resources:,"apiVersion: rbac.authorization.k8s.io/v1beta1 
 metadata:
  
  name: cluster-writer 
  
 rules:
  
  - apiGroups: [""*""]
  
   
  resources: [""*""]
  
   
  verbs: [""*""]
  
   
  nonResourceURLs: [""*""]",NA
"The Role is a resource, as you remember from ",NA,NA
Chapter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
", ",NA,NA
"to create resource using the file, you execute the ",kubectl create,NA
" command, for ",NA,NA
example:,$ kubectl create -f cluster-writer.yml,NA
A ,Role,NA
 and ,ClusterRole,NA
" defines the set of permissions, but does not assign them to",NA,NA
"users or groups directly. There is another resource for that in Kubernetes API, which ",NA,NA
is ,RoleBinding,NA
 or ,ClusterRoleBinding,NA
. They bind ,Role,NA
 or ,ClusterRole,NA
 to the specific ,NA,NA
"subject, which can be user, group, or service user. To bind the ",Role,NA
 or ,ClusterRole,NA
", ",NA,NA
you will need to execute the ,kubectl create rolebinding,NA
 command. Take a look at the ,NA,NA
following examples. To grant the ,adminClusterRole,NA
 to a user named ,john,NA
 in the ,NA,NA
namespace ,myApp,NA
:,"$ kubectl create rolebinding john-admin-binding 
 \--clusterrole=admin --user=john --
 namespace=myApp",NA
The next one will grant the ,cluster-admin ClusterRole,NA
 to a user named ,admin,NA
 across the ,NA,NA
entire cluster:,"$ kubectl create clusterrolebinding admin-cluster-admin-binding 
 \--clusterrole=cluster-admin --user=admin",NA
The equivalent YAML file to use with ,kubectl create -f,NA
 will be as follows:,"apiVersion: rbac.authorization.k8s.io/v1beta1 
 kind: ClusterRoleBinding 
  
 metadata:
  
  name: admin-cluster-admin-binding 
  
 roleRef:
  
  apiGroup: rbac.authorization.k8s.io
  
  kind: ClusterRole
  
  name cluster-admin 
  
 subjects:
  
 - kind: User
  
  name: admin",NA
WebHook,NA,NA
When the ,api-server,NA
 is started with the ,--authorization-mode=Webhook,NA
" option, it will ",NA,NA
make calls to external ,HTTP,NA
 server to authorize the user. This gives you the capability ,NA,NA
"to create your own authorization servers. In other words, a WebHook is an ",HTTP,NA
callback mode that allows you to manage authorization using a remote ,REST,NA
" server, ",NA,NA
"either developed on your own, or a third-party authorization server.",NA,NA
"When doing the authorization check, the ",api-server,NA
 will execute a ,HTTP POST,NA
" request, ",NA,NA
with a JSON payload containing a serialized ,api.authorization.v1beta1.SubjectAccessReview,NA
 object. This object describes the user ,NA,NA
making request to the ,api-server,NA
", the action which this user would like to execute, ",NA,NA
and the details about the resource being the subject of this action. An example ,NA,NA
request payload could look like the following example:,"{
  
  ""apiVersion"": ""authorization.k8s.io/v1beta1"", 
 ""kind"": ""SubjectAccessReview"",
  
  ""spec"": {
  
   
  ""resourceAttributes"": {
  
   
  
  ""namespace"": ""rest-example"",
  
   
  
  ""verb"": ""get"",
  
   
  
  ""resource"": ""pods""
  
   
  },
  
   
  ""user"": ""john"",
  
   
  ""group"": [
  
   
  
  ""group1"",
  
   
  
  ""group2""
  
   
  ]
  
  } 
  
 }",NA
"The remote authorization server should provide a response, saying if this user is ",NA,NA
authorized to execute the specified action on a specified resource. The response ,NA,NA
should contain the ,SubjectAccessReviewStatus,NA
" field, specifying if the ",api-server,NA
 should ,NA,NA
either allow or disallow access. A permissive JSON response would looks the same ,NA,NA
as the this:,"{
  
  ""apiVersion"": ""authorization.k8s.io/v1beta1"", 
 ""kind"": ""SubjectAccessReview"",
  
  ""status"": {
  
   
  ""allowed"": true
  
  } 
  
 }",NA
The negative response will appear as in the following example:,"{
  
  ""apiVersion"": ""authorization.k8s.io/v1beta1"",
  
  ""kind"": ""SubjectAccessReview"",
  
  ""status"": {
  
   
  ""allowed"": false,
  
   
  ""reason"": ""user does not have read access to the namespace"" 
 } 
  
 }",NA
Having the possibility to delegate the authorization to another service makes the ,NA,NA
"authorization process very flexible, imagine your own software that authorizes a user ",NA,NA
to do certain things in your cluster depending on the roles they have in the corporate ,LDAP,NA
 directory for example.,NA,NA
AlwaysDeny ,NA,NA
This policy denies all requests. If will be used if you start the ,api-server,NA
 with a ,"--
 authorization-mode=AlwaysDeny",NA
 switch. This can be useful if you are doing some testing ,NA,NA
or would like to block incoming requests without actually stopping the ,api-server,NA
.,NA,NA
AlwaysAllow,NA,NA
If you start the ,api-server,NA
 with ,--authorization-mode=AlwaysAllow,NA
", all requests will be ",NA,NA
"accepted, without using any authorization schema. Use this flag only if you do not ",NA,NA
require authorization for your API requests.,NA,NA
"As you can see, the authentication and authorization possibilities in Kubernetes are ",NA,NA
very flexible. On the diagram at the beginning of this chapter we have seen the third ,NA,NA
phase of the API call flow: the admission control. What role does the admission ,NA,NA
control play? Let's find out.,NA,NA
Admission control,NA,NA
An admission control plug-in intercepts requests to the Kubernetes API server after ,NA,NA
"the request is authenticated and authorized, but prior to making any changes to the ",NA,NA
"API resource. These plug-ins run in sequence, before a request is accepted into the ",NA,NA
"cluster. The Kubernetes API server supports a flag, ",admission-control,NA
 that takes a ,NA,NA
"comma-delimited, ordered list of admission control plugins.",NA,NA
"Now that we have an overview of how the API call looks the same, let's actually ",NA,NA
make some use of it.,NA,NA
Using the API,NA,NA
"The API reference is a detailed document, available on the internet ",NA,NA
https://kubernetes.io/ ,NA,NA
docs/api-reference/v1.6/,NA,NA
; ,NA,NA
"of course the API version will change in the future, ",v1.6,NA
 was the current o ,NA,NA
ne at the time of writing.,NA,NA
Before we make some actual calls to the ,api-server,NA
", it's worth knowing that ",kubectl,NA
"also communicates with Kubernetes cluster using the API. As we mentioned earlier, ",NA,NA
you can see what ,REST,NA
 calls are being made by the ,kubectl,NA
 command. Looking at ,NA,NA
what's being sent to the server during the usage of ,kubectl,NA
 is a great way to become ,NA,NA
familiar with Kubernetes API.,NA,NA
To see ,REST,NA
 requests being executed by ,kubectl,NA
", run it with a higher level ",NA,NA
"of verbosity, for example with a ",--v=6,NA
 or ,--v=9,NA
 option.,NA,NA
Before we start making actual ,REST,NA
" calls, let's briefly see what API operations are ",NA,NA
possible.,NA,NA
API operations,NA,NA
"Kubernetes API defines the CRUD (create, update, read, and delete) set of ",NA,NA
operations:,Create,NA
: Create operations will create the resource in the cluster. The JSON ,NA,NA
payload that you will need to provide with your ,REST,NA
 call is the resource ,NA,NA
manifest. It's the equivalent of the YAML file we've been constructing in the ,NA,NA
Ch ,NA,NA
apter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
". This time, it will be in the JSON format.",Update,NA
: The update operation can be either ,Replace,NA
 or ,Patch,NA
. A ,Replace,NA
 will simply ,NA,NA
"replace the whole resource object (a Pod, for example) with the provided spec. ",NA,NA
A ,Patch,NA
", on the other hand, will apply a change only to a specific field.",Read,NA
: A read operation can be either ,Get,NA
", ","List,",NA
 or ,Watch,NA
. By executing ,Get,NA
", you ",NA,NA
will be given a specific resource object by its name. Executing ,List,NA
 will retrieve ,NA,NA
all resource objects of a specific type within a namespace. You can use the ,NA,NA
selector query. A special form of the ,List,NA
 operation is ,List All Namespaces,NA
", as the ",NA,NA
name says this will retrieve resources across all namespaces. A ,Watch,NA
 operation ,NA,NA
will stream results for an object or a of list objects as they are updated.,Delete,NA
: Will simply delete a resource.,NA,NA
Kubernetes ,api-server,NA
" also exposes some additional, resource-specific operations. ",NA,NA
This includes ,Rollback,NA
", which rollbacks a Pod template to a previous version or read ",NA,NA
"/write scale, which reads or updates the number of replicas for the given resource.",NA,NA
Example calls,NA,NA
"In the following examples, we will be using a command-line ",HTTP,NA
" client, ",curl,NA
. You ,NA,NA
are not limited to ,curl,NA
", you can freely use the ",HTTP,NA
 client you find convenient. Using ,NA,NA
the ,HTTP,NA
" client with the user interface is often very handy, they usually present the ",HTTP,NA
" response in a structured form and sometimes also do some request validation, if ",NA,NA
"it's well formed. My recommended GUI clients will be Postman (for Windows, ",NA,NA
"Linux, or Mac), or PAW for Mac.",NA,NA
"Before making any calls, let's first start a proxy to the Kubernetes API server. The ",kubectl,NA
" needs to be configured first, to be able to communicate with your cluster. In ",NA,NA
our local Kubernetes installation with ,minikube,NA
", the ",kubectl,NA
 command will be ,NA,NA
automatically configured. To start a proxy to the ,api-server,NA
", execute the following ",NA,NA
command:,$ kubectl proxy --port=8080,NA
"While the proxy session is running, any request sent to ",localhost:8000,NA
 will be ,NA,NA
forwarded to the Kubernetes API server. To check if our ,api-server,NA
" is running, let's ",NA,NA
ask for the API version it supports:,$ curl http://localhost:8080/api/,NA
If the ,api-server,NA
" is running and waiting for incoming requests, it should give you ",NA,NA
an output similar to this one:,NA,NA
"It seems to be running fine; let's continue and make some use of the exposed API, ",NA,NA
"starting, the same as previously, by creating a service.",NA,NA
Creating a service using the API,NA,NA
"First, let's create a service manifest file. Note that if you have your services, ",NA,NA
"deployments, and Pods created in ",NA,NA
Chapter 8,NA,NA
", ",NA,NA
Using Kubernetes with Java,NA,NA
", by using the ",kubectl,NA
", you will need to delete them using ",kubectl,NA
 or the Kubernetes dashboard. We ,NA,NA
are going to use the same names for the service and a deployment. When using ,curl,NA
 ,NA,NA
"with larger payloads, it's more convenient to have the payload in the external file and ",NA,NA
not type it in the command-line. The JSON file that we will use as the payload is ,NA,NA
very similar to the one we have been using when creating a Pod with ,kubectl,NA
", but in ",NA,NA
JSON format this time. Let's create a file named ,service.json,NA
:,"{
  
  ""apiVersion"": ""v1"",
  
  ""kind"": ""Service"",
  
  ""metadata"": {
  
   
  ""name"": ""rest-example"",
  
   
  ""labels"": {
  
   
  
  ""app"": ""rest-example"",
  
   
  
  ""tier"": ""backend""
  
   
  }
  
  },
  
  ""spec"": {
  
   
  ""type"": ""NodePort"",
  
   
  ""ports"": [
  
   
  
  {
  
   
  
  
  ""port"": 8080
  
   
  
  }
  
   
  ],
  
   
  ""selector"": {
  
   
  
  ""app"": ""rest-example"",
  
   
  
  ""tier"": ""backend""
  
   
  }
  
  } 
  
 }",NA
Note that the contents of the JSON file are basically identical to the one we've been ,NA,NA
"using when we were creating resources using YAML files. Yes, you can clearly see ",NA,NA
how the ,kubectl,NA
" command is implemented, it just creates a JSON payload from the ",NA,NA
"file input, there is no magic behind the scenes, at all.",NA,NA
You can convert between YAML to JSON and vice-versa using one of ,NA,NA
the YAML/JSON converters available online. The Kubernetes ,"api-
 server",NA
 will accept such JSON as ,Kubectl,NA
 accepts the YAML file.,NA,NA
"Having our JSON file ready, the next step is to create the service resource in our ",NA,NA
cluster by invoking the following command:,NA,NA
"Having our service defined, let's create a deployment.",NA,NA
Creating a deployment using the API,NA,NA
"Creating a deployment is very similar to creating a service, it's creating another type ",NA,NA
"of Kubernetes resource, after all. All we need is a proper JSON payload file that we ",NA,NA
will be sending to the ,api-server,NA
 using the ,POST HTTP,NA
 method. Our ,rest-example,NA
deployment manifest in JSON can look as follows:,"{
  
  ""apiVersion"": ""extensions/v1beta1"",
  
  ""kind"": ""Deployment"",
  
  ""metadata"": {
  
   
  ""name"": ""rest-example""
  
  },
  
  ""spec"": {
  
   
  ""replicas"": 1,
  
   
  ""template"": {
  
   
  
  ""metadata"": {
  
   
  
  
  ""labels"": {
  
   
  
  
  ""app"": ""rest-example"",
  
   
  
  
  ""tier"": ""backend""
  
   
  
  
  }
  
   
  
  },
  
   
  
  ""spec"": {
  
   
  
  
  ""containers"": [
  
   
  
  
  {
  
   
  
  
  
  
  ""name"": ""rest-example"",
  
   
  
  
  
  
  ""image"": ""jotka/rest-example"",
  
   
  
  
  
  ""imagePullPolicy"": ""IfNotPresent"",
  
   
  
  
  
  ""resources"": {
  
   
  
  
  
  
  
  ""requests"": {
  
   
  
  
  
  
  
  ""cpu"": ""100m"",
  
   
  
  
  
  
  
  ""memory"": ""100Mi""
  
   
  
  
  
  
  
  }
  
   
  
  
  
  
  },
  
   
  
  
  
  
  ""env"": [
  
   
  
  
  
  
  
  {
  
   
  
  
  
  
  
  ""name"": ""GET_HOSTS_FROM"",
  
   
  
  
  
  
  
  ""value"": ""dns""
  
   
  
  
  
  
  
  }
  
   
  
  
  
  
  ],
  
   
  
  
  
  
  ""ports"": [
  
   
  
  
  
  
  
  {
  
   
  
  
  
  
  
  ""containerPort"": 8080
  
   
  
  
  
  
  
  }
  
   
  
  
  
  
  ]
  
   
  
  
  }
  
   
  
  
  ]
  
   
  
  }
  
   
  }
  
  } 
  
 }",NA
Let's save the file using the ,deployment.json,NA
" filename. Again, all we need to do now is",NA,NA
to post this file to the ,api-server,NA
. This process is very similar to the creation of the ,NA,NA
"service, it will be just a ",POST,NA
 to the different endpoint with a different payload. To ,NA,NA
create a deployment from the shell using ,curl,NA
", execute the following command:","$ curl -s \ http://localhost:8080/apis/extensions/v1beta1/namespaces/default/deployments -
 XPO-d@deployment.json",NA
"In the preceding example, you should note that deployment related API ",NA,NA
commands are in another API group: ,extensions,NA
. That's why the endpoint will have ,NA,NA
a different ,REST,NA
 path.,NA,NA
After executing those two ,REST HTTP,NA
" requests, we should have our service and ",NA,NA
"deployment created in the cluster. Of course, because of the deployment manifest ",NA,NA
contains the number of replicas with the value ,1,NA
", one Pod will be created as well.",NA,NA
"Let's check if it's true, by executing the following commands:","$ kubectl get services 
  
 $ kubectl get deployments 
  
 $ kubectl get pods",NA
"As you can see in the following screenshot, all of the resources exist on our cluster. ",NA,NA
"This time, however, they were created by two simple ",HTTP POST,NA
 requests to the ,NA,NA
Kubernetes ,api-servers,NA
", without using ",kubectl,NA
:,NA,NA
We have said before that we can observe what ,HTTP,NA
 requests are being executed by ,NA,NA
the ,kubectl,NA
 tool. Let's verify that. We will execute the last command to get the list of ,NA,NA
"Pods, but with additional verbosity level, the same as this:",$ kubectl get pods -v6,NA
The output should be similar to the following:,NA,NA
"There's a bunch of log lines about getting information from the cluster cache, but the ",NA,NA
"last line is especially interesting, it contains the actual ",HTTP,NA
 request being made by ,kubectl,NA
:,GET https://192.168.99.100:8443/api/v1/namespaces/default/pods,NA
If you now run the ,curl GET,NA
" command using this URL, all the authentication and ",NA,NA
authorization mechanisms would come into play. But having the ,api-server,NA
 proxy ,NA,NA
"running, we can skip authorization and authentication by executing the call on the ",NA,NA
proxied port (note that ,curl,NA
 executes the ,GET,NA
 method by default):,$ curl http://localhost:8080/api/v1/namespaces/default/pods,NA
"As the output, you will be given the JSON response containing detailed information ",NA,NA
"about Pods in your cluster. The API is working, as you can see in the following ",NA,NA
screenshot:,NA,NA
Deleting a service and deployment,NA,NA
"If you decide it's time to do some clean up, you may delete the service and the ",NA,NA
deployment by executing the ,HTTP DELETE,NA
" request, for example:","$ curl http://localhost:8000/ \ apis/extensions/v1beta1/namespaces/default/deployments/rest-
 e-XDELETE 
  
 $ curl http://localhost:8080/ \ api/v1/namespaces/default/services/rest-example -XDELETE",NA
Finding out the proper API operation ,REST,NA
 paths (endpoints) can be very inconvenient ,NA,NA
just by looking at the web documentation or by spying what URLs are being called ,NA,NA
by ,kubectl,NA
. There's a better way of doing this; OpenAPI specification of the ,NA,NA
Kubernetes ,api-server,NA
. Let's look at how we can get this specification.,NA,NA
Swagger docs,NA,NA
The Kubernetes ,api-server,NA
 provides the list of available API commands by utilizing ,NA,NA
"the OpenAPI specification. The OpenAPI Specification defines a standard, language-",NA,NA
agnostic interface to ,REST,NA
 APIs that allows both humans and computers to discover ,NA,NA
"and understand the capabilities of the service without access to source code, ",NA,NA
"documentation, or through network traffic inspection. It's very convenient to browse ",NA,NA
the API commands catalogue using the SwaggerUI tool that comes with Kubernetes ,api-server,NA
. You can also execute the ,HTTP,NA
 commands using SwaggerUI.,NA,NA
Note that the SwaggerUI is not enabled by default if you are running the local cluster ,NA,NA
"using Minikube. You will need to enable it during the cluster startup, using the ",NA,NA
following command:,$ minikube start --extra-config=apiserver.Features.EnableSwaggerUI=true,NA
Having the ,api-server,NA
 proxy still running using port ,8080,NA
", visit the following host in ",NA,NA
your web browser to see the SwaggerUI screen:,http://localhost:8080/swagger-ui/,NA
"You will be presented with a list of available API commands, grouped into API ",NA,NA
groups:,NA,NA
Expanding each API section will give you all the available endpoints with the ,NA,NA
description of each operation. The SwaggerUI is a great tool to explore an API in a ,NA,NA
clear and readable form.,NA,NA
Summary,NA,NA
"As you can see, the API exposed by Kubernetes is a very powerful tool in your ",NA,NA
arsenal. Any task that can be performed through the dashboard or ,kubectl,NA
 client is ,NA,NA
exposed as an API. You can do almost anything with your cluster simply by utilizing ,HTTP,NA
 calls. Kubernetes takes an API-first approach that makes it programmable and ,NA,NA
extensible. As we have seen it is easy to get started with the API. Our service and ,NA,NA
"deployment creating examples, may be simple but should give you an idea how to ",NA,NA
experiment with the ,api-server,NA
. Using the API you can create and retrieve cluster ,NA,NA
resources not only from the command-line using ,kubectl,NA
", but also from your own ",NA,NA
"application, build scripts, or continuous delivery pipelines. Only your imagination ",NA,NA
"and the sky is the limit, and speaking of the sky, it's time to move there and see how ",NA,NA
Kubernetes can be used in the cloud.,NA,NA
Deploying Java on Kubernetes in the,NA,NA
Cloud,NA,NA
"In previous chapters, we have managed to run the Kubernetes cluster locally. Using ",minikube,NA
 is a great way to learn Kubernetes and experiment on your own machine.,NA,NA
The ,minikube,NA
 powered cluster behaves exactly the same as the normal cluster that runs ,NA,NA
"on the server. However, if you decide to run your clustered software in a production, ",NA,NA
"the cloud is one of the best solutions. In this chapter, we will briefly cover the ",NA,NA
advantages of using cloud environments in the context of microservices running on ,NA,NA
"Docker. Next, we are going to deploy our Kubernetes cluster on the Amazon AWS. ",NA,NA
Configuring AWS and running Kubernetes on it is not the easiest and most ,NA,NA
"straightforward process from the start but, following this chapter will give you an ",NA,NA
"overview of the process, you will be able to run your own cloud cluster quickly and ",NA,NA
deploy your own or third-party Docker images on it.,NA,NA
The list of topics covered includes:,NA,NA
"The benefits of using cloud, Docker, and Kubernetes",NA,NA
Installing the needed tools,NA,NA
Configuring AWS,NA,NA
Deploying the cluster,NA,NA
Let's begin with the advantages of using a cloud-deployed Kubernetes cluster.,NA,NA
"Benefits of using the cloud, Docker, and",NA,NA
Kubernetes,NA,NA
Having an application deployed on a Kubernetes cluster has its advantages. It's fail ,NA,NA
"resilient, scalable, and has efficient architecture. What's the difference between ",NA,NA
"having your own infrastructure and using the cloud? Well, it comes down to couple ",NA,NA
"of factors. First, it can be a significant cost reduction. For small services or ",NA,NA
"applications, which could be shut down when not in use, the price of deploying ",NA,NA
"applications in the cloud can be lower, due to lower hardware costs, there will be ",NA,NA
more effective usage of physical resources. You will not have to pay for the nodes ,NA,NA
that do not use the computing power or network bandwidth.,NA,NA
"Having your own servers requires you to pay for the hardware, energy, and operating ",NA,NA
"system software. Docker and Kubernetes are free of charge, even for commercial ",NA,NA
"purposes; so, if you run it in the cloud, the cloud provider fee will be the only cost.",NA,NA
Cloud providers update their software stack often; you can benefit from this by ,NA,NA
having the latest and greatest versions of the operating system software.,NA,NA
"When it comes to the computing power or network bandwidth, large cloud providers ",NA,NA
"such as, Amazon or Google cannot be easily beaten. Their cloud infrastructure is ",NA,NA
"huge. Since they provide services to many different clients, they buy large, high-",NA,NA
performance systems that offer performance levels much higher than a small ,NA,NA
"company can afford to run internally. Also, as you will see in the next sections of ",NA,NA
"this chapter, cloud providers can spin up new servers or services in minutes or even ",NA,NA
"seconds. As a result, if there's a need, new instances will be brought to life in a way ",NA,NA
that is almost transparent for the users of your software. If your application needs to ,NA,NA
"handle a lot of requests, sometimes having it deployed in the cloud can be the only ",NA,NA
option.,NA,NA
"As for fault-tolerance, because cloud providers have their infrastructure spread out ",NA,NA
"over the whole world (such as AWS zones, as you will see later in this chapter), your ",NA,NA
"software can be fail-proof. No single accident such as power outage, fire, or an ",NA,NA
"earthquake, can stop your application from running. Adding Kubernetes to the ",NA,NA
equation can scale the deployment up or down and will increase the fault tolerance of ,NA,NA
"your application, even reducing the chance of complete failure to zero.",NA,NA
"Let's move our software to the cloud. To do this, we need to create a toolset first, by",NA,NA
installing the required software.,NA,NA
Installing the tools,NA,NA
"To be able to manage Kubernetes cluster on Amazon EC2, we will need to install ",NA,NA
"some command-line tools first. Of course, using the Amazon EC2 web interface is ",NA,NA
also possible. Spinning up a cluster is quite a complicated process; you will need to ,NA,NA
"have a user with proper access and permissions, storage for a cluster state, EC2 ",NA,NA
"instances to run your Kubernetes master and worker nodes, and so on. Doing ",NA,NA
"everything manually is possible, but can be time consuming and error prone. ",NA,NA
"Luckily, we have tools that can automate most of the things for us, this will be the ",NA,NA
AWS command-line client (,awscli,NA
) and ,kops,NA
", Kubernetes operations, production ",NA,NA
"Grade K8s installation, upgrades, and management. There are some requirements ",NA,NA
though. ,Kops,NA
" runs on Linux and macOS, it's written in Go, like Docker. The ",awscli,NA
 is ,NA,NA
"written in Python, so let's focus on Python installation first.",NA,NA
Python and PIP,NA,NA
To run the AWS command-line tools (,awscli,NA
"), we will need ",python3,NA
 present on our ,NA,NA
machine.,NA,NA
"It may be present already, you can verify that using the command:",$ python3 --version,NA
If the output is ,command not found,NA
", the fastest way of installing it will be using the ",NA,NA
"package manager you have on your system, such as ",apt,NA
" on Debian/Ubuntu, ",yum,NA
 on ,NA,NA
"Fedora, or Homebrew on macOS. If you work on macOS and do not have ",NA,NA
"Homebrew installed, I highly recommend doing so; it's a wonderful tool that gives ",NA,NA
you the possibility to easily install thousands of packages together with all the ,NA,NA
needed dependencies. Homebrew is available freely at ,NA,NA
https://brew.sh/,NA,NA
". To install it, ",NA,NA
execute the following:,"$ ruby -e ""$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)""",NA
"From now on, you should have the ",brew,NA
 command available in your macOS terminal.,NA,NA
To install Python on Linux using the ,apt,NA
" package manager (on Debian or Ubuntu), ",NA,NA
execute the following commands:,"$ sudo apt-get update 
  
 $ sudo apt-get install python3.6",NA
"On macOS, this will be the following command:",$ brew install python3,NA
The process of installing Python depends on the speed of your machine and internet ,NA,NA
"connection, but it should not take long. Once Python is installed, we will need ",NA,NA
"another tool, which is ",pip,NA
. ,pip,NA
 is the recommended tool for installing Python ,NA,NA
packages. It's written in Python itself. You can install it using the package manager ,NA,NA
"of your choice, executing the following, for example, on Ubuntu or Debian:",$ sudo apt-get install python3-pip,NA
An alternative way of installing ,pip,NA
" is using the installation script. In this case, the ",NA,NA
"process is exactly the same for Linux and macOS. First, we need to download the",NA,NA
installation script using the following command: ,$ curl -O https://bootstrap.pypa.io/get-pip.py,NA
"After a while, we need to run the installation script by executing the following: ",$ python3 get-pip.py -user,NA
"After a while, ",pip,NA
 should be available for you in the terminal shell. To verify if it's ,NA,NA
"working, execute the following command: ","$ pip -V 
  
  
 or 
  
  
 $ pip --version",NA
"Now that we have Python and pip installed and working properly, it's time to move ",NA,NA
"on to more interesting things, installing Amazon AWS command-line utilities.",NA,NA
AWS command-line tools,NA,NA
The Amazon ,NA,NA
AWS command-line tool,NA,NA
 (,NA,NA
awscli,NA,NA
) interface is a unified tool for ,NA,NA
managing your AWS services. The ,awscli,NA
 is built on top of the AWS SDK for ,NA,NA
"Python, which provides commands for interacting with AWS services. With minimal ",NA,NA
"configuration (actually, providing login id and a secret is enough, we will do it in a ",NA,NA
"while), you can start using all of the functionality provided by the AWS ",NA,NA
"Management Console web interface. Moreover, the ",awscli,NA
" is not only about EC2, ",NA,NA
"which we will be using to deploy our cluster on, but also other services such as S3 (a ",NA,NA
storage service) for example.,NA,NA
To install ,awscli,NA
", execute the following ",pip,NA
 command:,$ pip3 install --user --upgrade awscli,NA
"After a while, ",pip,NA
 will download and install the necessary files in the ,python3,NA
 folder ,NA,NA
structure on your drive. It will be ,~/Library/Python/3.6/bin,NA
 in case of macOS and ,NA,NA
Python 3.6. It's very convenient to add this folder to your ,PATH,NA
" environment variable, ",NA,NA
to make it available from anywhere in the shell. This is straightforward; you will ,NA,NA
need to edit the ,PATH,NA
" variable in one of those files, depending on the shell you use:",NA,NA
Bash,NA,NA
: ,.bash_profile,NA
", ",.profile,NA
", or ",.bash_login,NA
Zsh,NA,NA
: ,.zshrc,NA
Tcsh,NA,NA
: ,.tcshrc,NA
", ",.cshrc,NA
 or ,.login,NA
An example ,PATH,NA
" entry could look the same as this, on macOS:",export PATH=~/Library/Python/3.6/bin/:$PATH,NA
"After logging back in or launching a new terminal, you can verify if the ",aws,NA
"command is available, by executing the following command:",$ aws -version,NA
"As you can see in the output, this will give you a detailed ",aws,NA
 command-line tools ,NA,NA
version also with the Python version it's running on:,NA,NA
The ,awscli,NA
" is ready to use, but we have one more tool to add to our tool setup. It will ",NA,NA
be Kubernetes ,kops,NA
.,NA,NA
Kops,NA,NA
Kubernetes operations or ,kops,NA
", for short, is the production grade Kubernetes ",NA,NA
"installation, upgrades, and management tool. It's a command-line utility that helps ",NA,NA
"you create, destroy, upgrade, and maintain highly available Kubernetes clusters on ",NA,NA
AWS. AWS is officially supported by the tool. You can find the ,kops,NA
 releases on ,NA,NA
GitHub: ,NA,NA
https://github.com/kubernetes/kops/releases,NA,NA
"To install on either macOS or Linux, you will just need to download the binary, ",NA,NA
"change the permission to executable and you are done. To download, execute, for ",NA,NA
example:,"$ wget \ https://github.com/kubernetes/kops/releases/download/1.6.1/kops-darwin-amd64 
 $ chmod +x kops-darwin-amd64 
  
 $ mv kops-darwin-amd64 /usr/local/bin/kops",NA
"Alternatively, if you are using Linux, execute the following command:","$ wget \ https://github.com/kubernetes/kops/releases/download/1.6.2/kops-linux-amd64 
 $ chmod +x kops-linux-amd64 
  
 $ mv kops-linux-amd64 /usr/local/bin/kops",NA
"Alternatively, again, using the package manager will be the easiest way to get ",NA,NA
the latest ,kops,NA
" binary, for example using ",brew,NA
 on macOS:,$ brew update && brew install kops,NA
Note that you must have ,kubectl,NA
 (,NA,NA
https://kubernetes.io/docs/tasks/tools/install-kubectl/,NA,NA
) ,NA,NA
installed in order for ,kops,NA
" to work. If you use the package manager, the dependency ",NA,NA
to ,kubectl,NA
 will be probably defined in the ,kops,NA
" package, so the ",kubernetes-cli,NA
 will be ,NA,NA
installed first.,NA,NA
The last tool is the ,jq,NA
". Although not mandatory, it's very useful when dealing with ",NA,NA
"JSON data. All the AWS, Kubernetes, and ",kops,NA
 commands will post and receive ,NA,NA
"JSON objects, so having a tool for parsing JSON comes in handy, I highly ",NA,NA
recommend installing ,jq,NA
.,NA,NA
jq,jq,NA
 is a command-line JSON processor. It works like ,sed,NA
 for JSON data; you can use it ,NA,NA
"to filter, parse, and transform structured data with the same ease that ",sed,NA
", ",awk,NA
", or ",grep,NA
let you do with raw text. ,Jq,NA
 is available on GitHub at ,NA,NA
https://stedolan.github.io/jq/,NA,NA
. The ,NA,NA
"installation is very simple; it's just a single binary, available for Windows, macOS, ",NA,NA
and Linux. Just download it and copy it into the folder available on your system ,PATH,NA
 ,NA,NA
to be able to run it from the shell or command-line.,NA,NA
"Assuming we have all the tools installed before we start using kops, we will need to ",NA,NA
configure our AWS account first. This will be creating an administrative user and ,NA,NA
"then, using the ",aws,NA
" command-line tool, creating the user for running ",kops,NA
.,NA,NA
Configuring Amazon AWS,NA,NA
The configuration of AWS before setting up a Kubernetes cluster goes down to ,NA,NA
"creating a user, basically. All the rest will be done more or less automatically by the ",kops,NA
 command. Before we can use ,kops,NA
" from the command-line, it's good to have a ",NA,NA
user dedicated to ,kops,NA
". But first, we will need to create an administrator user. We will ",NA,NA
do it from the Web Management Console.,NA,NA
Creating an administrative user,NA,NA
"Depending on the AWS region you have chosen, the AWS Management Console is ",NA,NA
available at a subdomain of ,console.aws.amazon.com,NA
", this will be ",NA,NA
https://eu-central-1.consol ,NA,NA
e.aws.amazon.com,NA,NA
", for example. After logging in, go to the IAM page of the Security, ",NA,NA
"Identity, and Compliance section, then switch to the Users page, then click on the ",NA,NA
Add user button.,NA,NA
You will be presented with the user creation screen:,NA,NA
We will need this user for using ,awscli,NA
", so the only option we need to mark is the ",NA,NA
"Programmatic Access. After clicking on Next: Permissions, let's give our ",admin,NA
 ,NA,NA
user full administrative rights by adding him to the ,admin,NA
 group:,NA,NA
"On the last page of the user creation wizard, you will be able to see the Access key ",NA,NA
"ID and Secret access key ID. Do not close the page, we will need both in a short ",NA,NA
while to authenticate using ,awscli,NA
:,NA,NA
That's it. We have created an admin user with all the administrative rights and have ,NA,NA
the access keys. It's all we need to manage our AWS instances using ,awscli,NA
. Running ,kops,NA
 using the ,admin,NA
" user is probably not the best idea, so let's create a separate user ",NA,NA
"for that. This time, however, we will do it from the command-line. It will be a lot ",NA,NA
"easier in comparison to UI clicking on the Web Console. First, let's authenticate ",NA,NA
using the admin user's Access key ID and ,Secret access key ID,NA
", presented on the last ",NA,NA
page of the user creation wizard.,NA,NA
Creating a user for kops,NA,NA
The ,kops,NA
 user will need to have the following permissions in AWS to function ,NA,NA
properly:,"AmazonEC2FullAccess
  
  
 AmazonS3FullAccess
  
  
 AmazonRoute53FullAccess
  
  
 IAMFullAccess
  
  
 AmazonVPCFullAccess",NA
"First, we are going to create a group named ",kops,NA
 and give the needed permissions to ,NA,NA
the group. Execute the following list of commands to create a group and assign ,NA,NA
permissions:,"$ aws iam create-group --group-name kops 
  
 $ aws iam attach-group-policy --policy-arn $ arn:aws:iam::aws:policy/AmazonEC2FullAccess --gr 
 $ aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonS3FullAccess --group 
 $ aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonRoute53FullAccess --
 $ aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/IAMFullAccess --group-name 
 $ aws iam attach-group-policy --policy-arn arn:aws:iam::aws:policy/AmazonVPCFullAccess --grou",NA
The ,create-group,NA
" command will give you some JSON response, but there will be no ",NA,NA
response when attaching a permission (group policy) to the group if all goes well:,NA,NA
"Next, let's create the ",kops,NA
 IAM user and add the user to the ,kops,NA
" group, using the ",NA,NA
following commands:,$ aws iam create-user --user-name kops,NA
If you are curious you can now login into the web AWS console. You will see that ,NA,NA
our ,kops,NA
 user has all the permissions we need:,NA,NA
"To list all the registered users, execute the following command: ",$ aws iam list-users,NA
"As you can see in the following screenshot, we should now have two users: ",admin,NA
 and ,kops,NA
:,NA,NA
The last thing we need to do regarding our new ,kops,NA
 user is to generate the access ,NA,NA
keys. We will need them to authenticate using the ,aws configure,NA
 command. Execute ,NA,NA
the following to generate the access keys for the ,kops,NA
 user:,$ aws iam create-access-key --user-name kops,NA
"As you can see in the following screenshot, AWS will answer with the JSON ",NA,NA
response containing ,AccessKeyId,NA
 and ,SecretAccessKey,NA
; we will need both when ,NA,NA
authenticating using the ,aws configure,NA
 command:,NA,NA
All we need to do now is to authenticate using the ,aws configure,NA
" command, providing ",NA,NA
the ,AccessKeyId,NA
 and ,SecretAccessKey,NA
 we got in the response. Execute the following:,$ aws configure,NA
Because the ,aws configure,NA
 command doesn't export these variables for ,kops,NA
" to use, we ",NA,NA
need to export them now:,"$ export AWS_ACCESS_KEY_ID=<access key> 
  
 $ export AWS_SECRET_ACCESS_KEY=<secret key>",NA
"That's it, we have authenticated with our new user named ",kops,NA
", which has all the ",NA,NA
"permissions needed to spin up a Kubernetes cluster. From now on, every ",kops,NA
command we execute will use the AWS ,kops,NA
 user. It's time to get back to the point ,NA,NA
"and create our cluster, eventually.",NA,NA
Creating the cluster,NA,NA
We are going to create a simple cluster with one master node and two worker nodes. ,NA,NA
To do it using ,kops,NA
", we will need:",NA,NA
A user profile declared in ,~/.aws/credentials,NA
 (this is done automatically if you ,NA,NA
authenticate using ,aws configure,NA
).,NA,NA
An S3 bucket to store ,kops,NA
 cluster state. In order to store the representation of ,NA,NA
"our cluster and its state, we need to create a dedicated S3 bucket for ",kops,NA
 to use.,NA,NA
This bucket will become the source of truth for our cluster configuration.,NA,NA
DNS configured. This means we will need a Route 53 hosted zone in the same ,NA,NA
AWS account. Amazon Route 53 is a highly available and scalable cloud ,NA,NA
Domain Name System,NA,NA
 (,NA,NA
DNS,NA,NA
) web service. Kops will use it to create records ,NA,NA
"needed by the cluster. If you are using newer kops (1.6.2 or later), then DNS ",NA,NA
"configuration is optional. Instead, a gossip-based cluster can be easily created.",NA,NA
"For the purposes of the example's simplicity, we will use the gossip-based ",NA,NA
"cluster. To make it work, the cluster name must end with ",k8s.local,NA
. Let's look at ,NA,NA
"other options we have regarding DNS setup, though.",NA,NA
DNS settings,NA,NA
"Four scenarios are possible for our cluster's domain, basically: the root domain, ",NA,NA
"which is hosted on AWS, the subdomain of the domain hosted on AWS, using ",NA,NA
"Amazons Route 53 for a domain hosted elsewhere, and finally, a subdomain for your ",NA,NA
cluster set up in Route 53 while having the root domain elsewhere. Let's briefly look ,NA,NA
at those setups now.,NA,NA
Root domain on AWS hosted domain,NA,NA
"If you have your domain bought and hosted on AWS, you will probably have the ",NA,NA
Route 53 configured for you automatically already. If you would like to use this root ,NA,NA
"level domain for your cluster, you need do nothing to be able to use that domain ",NA,NA
name with your cluster.,NA,NA
The subdomain of the domain hosted,NA,NA
on AWS,NA,NA
"If you have your domain bought and hosted on AWS, but would like to use the ",NA,NA
"subdomain for the cluster, you will need to create a new hosted zone in Route 53 and ",NA,NA
then delegate the new route to this new zone. This is basically about copying the NS ,NA,NA
servers of your subdomain up to the parent domain in Route 53. Let's assume our ,NA,NA
domain is ,NA,NA
mydomain.com,NA,NA
; we need to get some information first. Note that the ,jq,NA
"command-line tool comes in handy now, when executing ",aws,NA
" commands. First, we ",NA,NA
need the ID of our main parent zone:,"$ aws route53 list-hosted-zones | jq '.HostedZones[] \ | 
 select(.Name==""mydomain.com."") | .Id'",NA
"To create a new subdomain, execute the following:","$ aws route53 create-hosted-zone --name myservice.mydomain.com \ -
 -caller-reference $ID | jq .DelegationSet.NameServers",NA
Note that the previous command will list the name servers of the new domain. If you ,NA,NA
"created the subdomain before, and would like to list the name servers (to copy the ",NA,NA
"NS servers list to the parent zone, we will need to know them first), execute the ",NA,NA
following command to get the subdomain zone ID:,"$ aws route53 list-hosted-zones | jq '.HostedZones[] | \ select(.Name=="" myservice.mydomain.c",NA
"Having the ID of the subdomain zone, we can list its name servers, by executing ",NA,NA
the following command:,"$ aws route53 get-hosted-zone --id <your-subdomain-zoneID> \ 
 | jq .DelegationSet.NameServers",NA
"So far, we have our parent's zone ID, subdomain zone's ID and a list of subdomain's ",NA,NA
name servers. We are ready to copy them into the parent. The most convenient way ,NA,NA
"will be to prepare the JSON file, as it's quite a long input. The file will look the same ",NA,NA
as the following:,"{
  
  ""Changes"": [
  
   
  {
  
   
  
  ""Action"": ""CREATE"",
  
   
  
  ""ResourceRecordSet"": {",NA
"You will need to save this as a file, let's say ",my-service-subdomain.json,NA
", and execute the ",NA,NA
last command. It will copy the name servers list into the parent zone:,"$ aws route53 change-resource-record-sets 
  
 --change-batch file://my-service-subdomain.json \-
 -hosted-zone-id <your-parent-zone-id>",NA
"After a while, all network traffic to ",*.myservice.mydomain.com,NA
 will be routed to the ,NA,NA
correct subdomain hosted zone in AWS Route 53.,NA,NA
Route 53 for a domain purchased with,NA,NA
another registrar,NA,NA
"If you bought your domain elsewhere, and would like to dedicate the entire domain ",NA,NA
"to your AWS hosted cluster, things can get a little complicated, as this setup requires ",NA,NA
you to make crucial changes in another domain registrar.,NA,NA
If the registrar for your domain is also the DNS service provider for the ,NA,NA
"domain (which is, actually, very often the case), it's recommended to ",NA,NA
transfer your DNS service to Amazon Route 53 before you continue with ,NA,NA
the process to transfer the domain registration.,NA,NA
"The reason for that is that when you transfer the registration, the previous registrar ",NA,NA
"might disable the DNS service for the domain, as soon as they receive a transfer ",NA,NA
"request from Route 53. As a result, any service you have on this domain, such as a ",NA,NA
"web application or an email, might become unavailable. To transfer the domain ",NA,NA
"registration to Route 53 from another registrar, you will need to use the Route 53 ",NA,NA
"console, available at ",NA,NA
https://console.aws.amazon.com/route53/,NA,NA
". In the navigation pane, ",NA,NA
"choose Registered Domains and then Transfer Domain, and enter the name of the ",NA,NA
domain which you would like to transfer and click on Check. If the domain is ,NA,NA
"unavailable for transfer, the console will list the probable reasons and a ",NA,NA
recommended way to handle them. If everything is ok and the domain is available ,NA,NA
"for transfer, you will have an option to add it to the cart. You will need to enter some ",NA,NA
"details then, such as your contact information, the authorization code for transfer ",NA,NA
(you should get it from the previous registrar) and the name server settings. I highly ,NA,NA
"recommend selecting the Route 63 managed DNS server, as it's quite easy to ",NA,NA
configure and reliable. The Route 63 will take care of communication with your ,NA,NA
"previous registrar, but you may receive some emails requiring you to confirm some ",NA,NA
"things. The transfer process can take a longer time, but when it's done, you may ",NA,NA
proceed with configuring the domain for your AWS based cluster in the same way as ,NA,NA
in the previous two cases.,NA,NA
Subdomain for cluster in AWS Route,NA,NA
"53, the domain elsewhere",NA,NA
If you have your domain registered at a registrar other than Amazon and would like ,NA,NA
"to use the subdomain of that domain to point to your cluster, you will need to modify ",NA,NA
your name servers entries in your registrar. This would require a new hosted zone ,NA,NA
subdomain to be created in Route 53 and then migration of this subdomain's name ,NA,NA
server records to your registrar.,NA,NA
"Similar to the subdomain on the AWS-hosted domain, let's create a subdomain first, ",NA,NA
by executing the following command:,"$ aws route53 create-hosted-zone \
  
 --name myservice.mydomain.com \
  
 --caller-reference $ID | jq .DelegationSet.NameServers",NA
The output of the previous command will list the name servers for the subdomain. ,NA,NA
"You will need to log in to your registrar's settings page and create a new subdomain, ",NA,NA
providing the four name server records received from the previous command. You ,NA,NA
can find detailed instructions on how to edit the name servers for your domain in ,NA,NA
your specific registrar help guides.,NA,NA
The previous guides should make your cluster available under a specific domain or ,NA,NA
"subdomain. For the rest of our chapter, however, we will be running the gossip-based ",NA,NA
cluster.,NA,NA
"Before we create anything on AWS, we must see what zones are available for use. ",NA,NA
You should know that Amazon EC2 is hosted in multiple locations world-wide. ,NA,NA
These locations are composed of regions and availability zones. Each region is a ,NA,NA
"separate geographic area. Each region has multiple, isolated locations known as ",NA,NA
"availability zones. You can pick the location you want, but first, you will need to ",NA,NA
check the zones availability. Let's do that now.,NA,NA
Checking the zones' availability ,NA,NA
"To list the zones available for the specific region, execute the following command: ",$ aws ec2 describe-availability-zones --region eu-central-1,NA
"As you can see on the following screenshot, AWS will give you the list of zones in ",NA,NA
the response:,NA,NA
Creating the storage,NA,NA
Our cluster needs to store its state somewhere. Kops uses Amazon S3 buckets for ,NA,NA
that purpose. An S3 bucket is a logical unit of storage in the ,NA,NA
Amazon Web Services ,NA,NA
(,NA,NA
AWS,NA,NA
") object storage service, ",NA,NA
Simple Storage Solution,NA,NA
 (,NA,NA
S3,NA,NA
),NA,NA
.,NA,NA
 Buckets are used to ,NA,NA
"store objects, which consist of data and metadata that describes the data. To create a ",NA,NA
"bucket, execute the following ",aws,NA
 command:,"$ aws s3api create-bucket \
  
 --bucket my-cluster-store \
  
 --region eu-central-1 \
  
 --create-bucket-configuration LocationConstraint=eu-central-1",NA
"As you will see on the following screenshot, AWS will give you back the concise ",NA,NA
information about the location of the store:,NA,NA
"Having the store created, we will need to make it available for ",kops,NA
 when creating a ,NA,NA
"cluster. To do this, we need to export the bucket's name into the ",KOPS_STATE_STORE,NA
environment variable to:,$ export KOPS_STATE_STORE=s3://my-cluster-store,NA
We are now ready to create a cluster.,NA,NA
"As you remember, we are going to use a gossip-based cluster instead of ",NA,NA
"configured DNS, so the name must end with ",k8s.local,NA
.,NA,NA
Creating a cluster,NA,NA
"Let's first export our cluster name to the environment variable. This will be useful, ",NA,NA
because we are going to refer to the cluster's name often. Execute the following ,NA,NA
command to export the cluster name:,$ export NAME=my-rest-cluster.k8s.local,NA
The ,kops create cluster,NA
 is the command we are going to use to create our cluster. ,NA,NA
Note that this will not affect our Amazon EC2 instances yet. The outcome of the ,NA,NA
command will be just a local cluster template which we can review and edit before ,NA,NA
"rolling out real, physical changes on the AWS.",NA,NA
The syntax of the command is very simple:,$ kops create cluster [options],NA
The command takes a lot of options; you can always find the up-to-date description ,NA,NA
on GitHub at ,NA,NA
https://github.com/kubernetes/kops/blob/master/docs/cli/kops_create_cluster.md,NA,NA
.,NA,NA
Let's focus on the most important ones:,NA,NA
Option,NA,NA
Description,"--master-count 
 [number]",NA
Sets the number of master nodes. The default is one master ,NA,NA
node per master-zone.,"--master-size 
 [string]",NA
"Sets instance size for masters, for example:","-
 -master-size=t2.medium",NA
.,"--master-volume-size 
 [number]",NA
Sets instance volume size for master nodes in gigabytes.,--master-zones,NA
Specifies AWS zones in which to run masters (this must be,NA,NA
an odd number).,"--zones [zone1,zone2 
 ]",NA
"Zones in which to run the cluster, for example: ","--zones eu-
 central-1a,eu-central-1b",NA
.,"--node-count 
 [number]",NA
Sets the number of nodes.,--node-size [string],NA
"Sets instance size for nodes, for ",NA,NA
example:,--node-size=t2.medium,NA
.,"--node-volume-size 
 int32",NA
Sets instance volume size (in GB) for nodes.,NA,NA
If you would like to make your cluster private (it's public by default) you will need,NA,NA
to consider using these options additionally:,NA,NA
Option,NA,NA
Description,"--associate-
 public-ip 
  
 [true|false]",NA
Specifies if you want your cluster to have a public IP assigned ,NA,NA
or not.,"--topology 
  
 [public|private]",NA
"Specifies the internal networking topology for the cluster, it can ",NA,NA
be ,public,NA
 or ,private,NA
.,NA,NA
The ,--bastion,NA
 flag enables a bastion instance group. The option ,NA,NA
is valid only with the private topology. It will generate a ,NA,NA
dedicated SSH jump host for SSH access to cluster instances. A,NA,NA
jump host provides a point of entry into a private network of ,NA,NA
your cluster. It can be started and stopped to enable or disable ,NA,NA
inbound SSH communication from the internet.,NA,NA
"Let's create our cluster now, using the following command:","$ kops create cluster --v=0 \
  
 --cloud=aws --node-count 2 \
  
 --master-size=t2.medium \
  
 --master-zones=eu-central-1a \
  
 --zones eu-central-1a,eu-central-1b  \
  
 --name=${NAME} \
  
 --node-size=t2.medium",NA
"In the response, ",kops,NA
 will list all the details of the configuration that has been created ,NA,NA
and suggest some next steps you can take with your new cluster configuration:,NA,NA
"After running the command, ",kops,NA
 will configure your ,kubectl,NA
 Kubernetes client to ,NA,NA
point to your new cluster; this will be ,my-rest-cluster.k8s.local,NA
 in our example.,NA,NA
"As we have said before, at this stage, only the cluster's template is created, not the",NA,NA
cluster itself. You can still change any option by editing your cluster:,$ kops edit cluster my-rest-cluster.k8s.local,NA
"This will bring up the default editor you have defined in your shell, where you ",NA,NA
can see the cluster template that has been generated. It will contain a lot more ,NA,NA
"settings, not only those you have specified when running the ",cluster create,NA
 ,NA,NA
command:,NA,NA
"If you are satisfied with your cluster template, it's time to spin it up to create real ",NA,NA
"cloud-based resources, such as networks and EC2 instances. Once the infrastructure ",NA,NA
"is ready, ",kops,NA
 will install Kubernetes on the EC2 instances. Let's do it.,NA,NA
Starting up clusters,NA,NA
"To start the cluster and spin up all the necessary EC2 instances, you will need to ",NA,NA
execute the ,update,NA
 command. It's recommended in the ,kops,NA
 manual that you should do ,NA,NA
it first in the preview mode without the ,--yes,NA
 switch. This will not spin up any EC2 ,NA,NA
instances:,$ kops update cluster ${NAME},NA
"If all is looking correct, execute the update command with the ",--yes,NA
 switch:,$ kops update cluster ${NAME} --yes,NA
Your cluster is starting and should be ready in a few minutes. If you now log in into ,NA,NA
"the WAS Management Console, you will see your EC2 instances starting up, as you ",NA,NA
can see in the following screenshot:,NA,NA
"You can also check the whole cluster state, issuing the following command:",$ kops validate cluster,NA
The output will contain information about the number and status of the cluster's ,NA,NA
"nodes, including the master node:",NA,NA
"Of course, as the ",kubectl,NA
" is now configured to act on our AWS cluster, we can list ",NA,NA
nodes using ,kubectl get nodes,NA
" command, exactly the same as we did in the ",NA,NA
Chapter 9,NA,NA
", ",NA,NA
Working with Kubernetes API,NA,NA
", with ",minikube,NA
 base cluster. Execute the following ,NA,NA
command:,$ list nodes: kubectl get nodes --show-labels,NA
You will be given the information about the name and status of your cluster's nodes:,NA,NA
Updating a cluster,Kops,NA
 behaves similarly to ,kubectl,NA
; you can edit the configuration files in the editor ,NA,NA
before actually doing any changes on the cluster. The ,kops update,NA
 command will ,NA,NA
"apply configuration changes, but will not modify the running infrastructure. To ",NA,NA
"update the running cluster, you will need to execute the ",rolling-update,NA
 command. The ,NA,NA
following will start the update or recreation process of the cluster's infrastructure:,$ kops rolling-update cluster –yes,NA
"Our fresh cluster is running, but it's empty. Let's deploy something.",NA,NA
Installing the dashboard,NA,NA
"Having the cluster running, it would be nice to have a dashboard deployed, to see the ",NA,NA
"status of your services, deployments, pods and so on. The dashboard is included in ",NA,NA
the ,minikube,NA
" cluster by default, but on our brand new Amazon cluster we will need to ",NA,NA
install it manually. This is a straightforward process. As we have ,kubectl,NA
 configured ,NA,NA
"to act on the remote cluster, we can execute the following ",kubectl create,NA
 command ,NA,NA
with the ,kubernetes-dashboard.yaml,NA
 template as an input:,"$ kubectl create -f \ 
  
 https://rawgit.com/kubernetes/dashboard/master/src/deploy 
 kubernetes-dashboard.yaml",NA
"The next thing would be to proxy the network traffic, using the following ","kubectl 
 proxy",NA
 command we already know:,$ kubectl proxy,NA
That's it! After a while the dashboard will be deployed and we will be able to access ,NA,NA
it using the localhost address:,http://localhost:8001/,NA
", as you can see in the following screenshot, is the same ",NA,NA
dashboard we have already seen in the ,NA,NA
Chapter 9,NA,NA
", ",NA,NA
Working with Kubernetes API,NA,NA
:,NA,NA
"From now on, you can use the ",kubectl,NA
 and the dashboard to manage your cluster as ,NA,NA
we did before in the ,NA,NA
Chapter 9,NA,NA
", ",NA,NA
Working with Kubernetes API,NA,NA
. All the ,kubectl create,NA
"commands will work the same as with the local cluster. This time, however, your ",NA,NA
software will go to the cloud.,NA,NA
"If you decide to remove the cluster, execute the following command:",$ kops delete cluster -name=${NAME} --yes,NA
"Note that if you just created the cluster template, without executing ","kops 
 update cluster ${NAME} --yes",NA
" first, you can also delete the cluster, as you can ",NA,NA
see in the following screenshot:,NA,NA
"If the cluster is already created on Amazon, the process of deleting it will take ",NA,NA
"longer, as all EC2 instances for master and worker nodes needs to be shutdown first.",NA,NA
Summary,NA,NA
"In this chapter, we have set up a cluster in the real cloud, Amazon AWS. ",Kops,NA
 is one ,NA,NA
of the best tools that we have available right now to manage Kubernetes on AWS.,NA,NA
"Using it, you can easily create and manage clusters on AWS. It can be a test or a ",NA,NA
production-grade cluster; ,kops,NA
 will make the creation and management of it a breeze.,NA,NA
More Resources,NA,NA
"We are at the end of our Docker and Kubernetes journey. After reading this book, ",NA,NA
you should already know how Kubernetes compliments Docker. You may think of ,NA,NA
"them as of different layers of your software stack; Docker sits below, serving single ",NA,NA
"containers, while Kubernetes orchestrates and manages them in a cluster. Docker ",NA,NA
becomes more and more popular and a lot of people use it during the development or ,NA,NA
"production deployments. Just to name a few big ones, it is used by PayPal, General ",NA,NA
"Electric, Groupon, Spotify, and Uber. It's mature enough to be run on production and ",NA,NA
I hope you will use it too to deploy and run your Java applications with success.,NA,NA
"To further extend your knowledge about Docker and Kubernetes, there's plenty of ",NA,NA
"information. The trick is to find the valuable information. In this chapter, I will ",NA,NA
present the most useful if you want to further extend your Docker and Kubernetes ,NA,NA
knowledge.,NA,NA
Docker ,NA,NA
The first one on our list will be the awesome Docker list.,NA,NA
Awesome Docker,NA,NA
Awesome Docker available on GitHub at ,NA,NA
http://veggiemonk.github.io/awesome-docker/,NA,NA
. ,NA,NA
"The author updates the list often, so you can clone the Git repository locally and do ",NA,NA
periodical updates to see what's new. Awesome Docker contains sections such as an ,NA,NA
"introduction to Docker, tools (with the groups such as developer tools, testing, or ",NA,NA
"utilities). The Videos section can be especially useful when learning Docker, you can ",NA,NA
"find tutorials and trainings here. Apart from this list, it's really hard to find some ",NA,NA
more that could be useful.,NA,NA
Blogs,NA,NA
The first blog I would recommend to continue learning about Docker will be Arun ,NA,NA
"Gupta's blog, available at ",NA,NA
http://blog.arungupta.me,NA,NA
". Arun, who first started blogging ",NA,NA
"about Docker in July 2014, is the VP of developer advocacy at Couchbase, a Java ",NA,NA
"champion, a JUG leader, and a Docker captain. He writes about many things on his ",NA,NA
blog; you can filter the content to only related to Docker using the ,#docker,NA
" tag, using ",NA,NA
the link: ,NA,NA
http://blog.arungupta.me/tag/docker/,NA,NA
.,NA,NA
"You will find a lot of useful stuff here, related to Java development and Docker. He ",NA,NA
"also authored a great Docker tutorial, available on GitHub: ",NA,NA
https://github.com/arun-gupta/ ,NA,NA
docker-tutorial,NA,NA
.,NA,NA
"Next comes the official Docker blog, available at ",NA,NA
https://blog.docker.com,NA,NA
. You will not ,NA,NA
"find many tutorials on how to use Docker, but there will be announcements about ",NA,NA
"new releases and their features, more advanced Docker usage tips, and community ",NA,NA
news such as Docker events.,NA,NA
"The Red Hat developer program, under the category containers, available at ",NA,NA
https://dev ,NA,NA
elopers.redhat.com/blog/category/containers/,NA,NA
 also contains a lot of useful articles around ,NA,NA
Docker and container technology in general.,NA,NA
Interactive tutorials,NA,NA
"There are many Docker tutorials available on the web, but I find one of them ",NA,NA
"especially interesting. It's Katakoda's interactive Docker learning course, available at ",NA,NA
https://www.katacoda.com/courses/docker,NA,NA
. You will find the complete feature set of ,NA,NA
"Docker here, starting with deployment of a single container and going through ",NA,NA
"subjects such as adding labels, inspecting containers, and optimizing your image ",NA,NA
"builds. It's interactive; all you need is a modern browser, you do not even need to ",NA,NA
install Docker on your local machine. It's very complete and fun to learn with. The ,NA,NA
other one is ,NA,NA
http://training.play-with-docker.com,NA,NA
". It comes with three sections: beginner, ",NA,NA
"which covers the basics such as running single containers, intermediate, covering ",NA,NA
"networking for example, and advanced, covering Docker security. Some of the ",NA,NA
"course tasks are interactive, you can execute them straight in your browser.",NA,NA
Kubernetes ,NA,NA
When Docker started to gain more popularity the need for containers management ,NA,NA
"platform started to gain attention. Thus, more resources regarding Kubernetes started ",NA,NA
to pop up on the internet.,NA,NA
Awesome Kubernetes,NA,NA
"Similar to its Docker counterpart, the awesome Kubernetes list, available at GitHub ",NA,NA
h ,NA,NA
ttps://github.com/ramitsurana/awesome-kubernetes,NA,NA
 contains a lot of useful resources ,NA,NA
regarding Kubernetes. You will find a lot here; staring from the introduction to ,NA,NA
"Kubernetes, through the list of useful tools and developer platforms, up to the ",NA,NA
enterprise Kubernetes products. There's even a link to the tutorial on how to install ,NA,NA
Kubernetes cluster using Raspberry Pi devices!,NA,NA
Tutorials,NA,NA
"The official Kubernetes site contains a lot of interesting tutorials, starting from the ",NA,NA
basics and going through the whole Kubernetes feature lists. The list of tutorials is ,NA,NA
available at ,NA,NA
https://kubernetes.io/docs/tutorials/,NA,NA
. If you haven't followed our Minikube ,NA,NA
"install guide, I highly recommend doing so, using Kubernetes official Bootcamp, it's ",NA,NA
an interactive web based tutorial and its goal is to deploy a local development ,NA,NA
Kubernetes cluster using Minikube. It's available at ,NA,NA
https://kubernetes.io/docs/tutorials/kub ,NA,NA
ernetes-basics/cluster-interactive/,NA,NA
.,NA,NA
Blogs,NA,NA
The official Kubernetes blog is available at ,NA,NA
http://blog.kubernetes.io/,NA,NA
. You will find ,NA,NA
"announcements about new releases, useful technical articles, and interesting case ",NA,NA
studies here.,NA,NA
The Red Hat enterprise Linux blog also contains a lot of interesting articles ,NA,NA
"regarding Kubernetes. They are tagged with the Kubernetes tag, so you can easily ",NA,NA
filter them out by using the link ,NA,NA
http://rhelblog.redhat.com/tag/kubernetes/,NA,NA
.,NA,NA
Extensions,NA,NA
"As you know, Kubernetes supports extensions. There is a nice resource tracking a ",NA,NA
"number of Kubernetes, available at ",NA,NA
https://github.com/coreos/awesome-kubernetes-extension ,NA,NA
s,NA,NA
". If you need, for example, to integrate some cert manager into your architecture, ",NA,NA
you will probably find a proper extension there.,NA,NA
Tools ,NA,NA
"Apart from useful articles and tutorials, there are also a couple of useful tools or ",NA,NA
platforms that make using Kubernetes more enjoyable. Let's briefly present them ,NA,NA
now.,NA,NA
Rancher,NA,NA
"Rancher, available at ",NA,NA
http://rancher.com,NA,NA
", is a platform that deserves a separate section ",NA,NA
in our book. It's open source software that makes it easy to deploy and manage ,NA,NA
Docker containers and Kubernetes in production on any infrastructure. You can ,NA,NA
easily deploy and run containers in production on any infrastructure with the most ,NA,NA
complete container management platform.,NA,NA
Helm and charts,NA,NA
Kubernetes Helm (available on GitHub at ,NA,NA
https://github.com/kubernetes/helm,NA,NA
) introduces ,NA,NA
"the concept of charts, which are packages of pre-configured Kubernetes resources, ",NA,NA
curated application definitions for Kubernetes. Helm is a tool for managing charts; it ,NA,NA
streamlines installing and managing Kubernetes applications. Think of it as an ,apt/yum/homebrew,NA
 package manager for Kubernetes. You can use it to find and use ,NA,NA
"popular software packaged as Kubernetes charts, share your own applications as ",NA,NA
"Kubernetes charts, and create reproducible builds of your Kubernetes applications. ",NA,NA
"There's a separate repository for charts, of course, on GitHub: ",NA,NA
https://github.com/kuberne ,NA,NA
tes/charts,NA,NA
". Currently, the chart binary repository is available on Google Cloud at ",NA,NA
https:// ,NA,NA
console.cloud.google.com/storage/browser/kubernetes-charts/,NA,NA
 and contains a lot of useful ,NA,NA
prepackaged tools such as Ghost (,node.js,NA
" blogging platform), Jenkins, Joomla, ",NA,NA
"MongoDb, MySQL, Redis, Minecraft, and just to name a few.",NA,NA
Kompose,NA,NA
Kompose (,NA,NA
https://github.com/kubernetes/kompose,NA,NA
) is a tool to help move Compose ,NA,NA
configuration files into Kubernetes. Kompose is a tool for defining and running ,NA,NA
"multi-container Docker applications. If you are a Kompose user, you can use it to ",NA,NA
move your multi-containers configuration straight into Kubernetes setup by ,NA,NA
translating a Docker Compose file into Kubernetes objects. Note that the ,NA,NA
transformation of the Docker Compose format to Kubernetes resources manifest may ,NA,NA
"not be exactly precise, but it helps tremendously when first deploying an application ",NA,NA
on Kubernetes.,NA,NA
Kubetop,NA,NA
"Kubetop, again available on GitHub ",NA,NA
https://github.com/LeastAuthority/kubetop,NA,NA
", is the ",NA,NA
same as the ,top,NA
 command for Kubernetes cluster. It's extremely useful; it lists all ,NA,NA
"your cluster's running nodes, all pods on them and all containers in those pods. The ",NA,NA
"tool gives you information about the CPU and memory utilization for each node, ",NA,NA
similar to the Unix/Linux ,top,NA
 command. If you need to know quickly what's ,NA,NA
"consuming the most resources on your cluster, the quick command-line tool is a very ",NA,NA
handy option.,NA,NA
Kube-applier,NA,NA
Available on GitHub at ,NA,NA
https://github.com/box/kube-applier,NA,NA
", ",kube-applier,NA
 enables ,NA,NA
automated deployment and declarative configuration for your Kubernetes cluster. It ,NA,NA
"runs as a Kubernetes service, takes a set of declarative configuration files hosted in a ",NA,NA
"Git repository, and applies them for a Kubernetes cluster.",NA,NA
The ,kube-applier,NA
 runs itself as a Pod in your cluster and continuously watches the Git ,NA,NA
repository to ensure that the cluster objects are up to date with their associated ,spec,NA
files (JSON or YAML) in the repository. The tool also contains a status page and ,NA,NA
"provides metrics for monitoring. I find it extremely useful in the daily development, ",NA,NA
"where your deployment, services, or pod definition change often.",NA,NA
"As you can see, there are a lot of useful resources for Docker and Kubernetes around ",NA,NA
"the web. After reading this book, you will probably want to skip most of the ",NA,NA
beginnings and go straight to more advanced topics. The best thing about all of those ,NA,NA
"resources is that they are free of charge, so basically nothing stops you from ",NA,NA
"exploring the wonderful world of managed containers. Try and learn, and if the time ",NA,NA
"comes, go ahead and use Docker and Kubernetes to deploy your production ready ",NA,NA
"Java software, either on your own infrastructure or on the cloud. It will be amazing ",NA,NA
to see how your Java application scales itself and becomes fail proof. Docker and ,NA,NA
"Kubernetes enable it and you now have the knowledge to use it. Docker, together ",NA,NA
"with Kubernetes, has radically changed the face of the technology landscape and I ",NA,NA
hope it will also change your development and release flow for the better.,NA,NA
