Larger Text,Smaller Text,Symbol
Go: Building Web ,NA,NA
Applications,NA,NA
"Build real-world, production-ready solutions by ",NA,NA
harnessing the powerful features of Go,NA,NA
A course in three modules,BIRMINGHAM - MUMBAI,NA
Go: Building Web Applications,"Copyright © 2016 Packt Publishing
  
 All rights reserved. No part of this course may be reproduced, stored in a retrieval 
 system, or transmitted in any form or by any means, without the prior written 
 permission of the publisher, except in the case of brief quotations embedded in critical 
 articles or reviews.
  
 Every effort has been made in the preparation of this course to ensure the accuracy of 
 the information presented. However, the information contained in this course is sold 
 without warranty, either express or implied. Neither the authors, nor Packt Publishing, 
 and its dealers and distributors will be held liable for any damages caused or alleged to 
 be caused directly or indirectly by this course.
  
 Packt Publishing has endeavored to provide trademark information about all of the 
 companies and products mentioned in this course by the appropriate use of capitals. 
  
 However, Packt Publishing cannot guarantee the accuracy of this information.
  
 Published on: August 2016
  
 Published by Packt Publishing Ltd.
  
 Livery Place 
  
 35 Livery Street
  
 Birmingham B3 2PB, UK.
  
 ISBN 978-1-78712-349-6
  
 www.packtpub.com",NA
Credits,"Authors 
  
 Nathan Kozyra 
  
 Mat Ryer
  
 Reviewers 
  
 Karthik Nayak 
  
 Tyler Bunnell 
  
 Michael Hamrah 
  
 Nimish Parmar 
  
 Jeremy R. Budnack 
  
 János Fehér 
  
 Aleksandar S. Sokolovski 
 Michele Della Torre
  
 Content Development Editor 
 Arun Nadar
  
 Graphics 
  
 Abhinash Sahu
  
 Production Coordinator 
 Melwyn D'sa",NA
Preface,"Since the late 1980s and early 1990s, there has been a slow flood of powerful new 
 languages and paradigms—Perl, Python, Ruby, PHP, and JavaScript—have taken an 
 expanding user base by storm and has become one of the most popular languages (up 
 there with stalwarts such as C, C++, and Java). Multithreading, memory caching, and APIs 
 have allowed multiple processes, dissonant languages, applications, and even separate 
 operating systems to work in congress.
  
 And while this is great, there's a niche that until very recently was largely unserved: 
 powerful, compiled, cross-platform languages with concurrency support that are geared 
 towards systems programmers.
  
 So when Google announced Go in 2009, which included some of the best minds in 
 language design (and programming in general)—Rob Pike and Ken Thompson of Bell 
 Labs fame and Robert Griesemer, who worked on Google's JavaScript 
 implementation V8—to design a modern, concurrent language with development 
 ease at the forefront.. 
  
 For Go programming bright future, the team focused on some sore spots in the 
 alternatives, which are as follows:
  
 • 
  
 • 
  
 • 
  
 Dynamically typed languages have—in recent years—become incredibly 
 popular. Go eschews the explicit, ""cumbersome"" type systems of Java or C++. Go 
 uses type inference, which saves development time, but is still also strongly 
 typed.
  
 Concurrency, parallelism, pointers/memory access, and garbage collection are 
 unwieldy in the aforementioned languages. Go lets these concepts be as easy 
 or as complicated as you want or need them to be.
  
 As a newer language, Go has a focus on multicore design that was a 
 necessary afterthought in languages such as C++.
  
 [
  i 
 ]",NA
What this learning path covers,"Module 1, Learning Go Web Development
 , starts off with introducing and setting up Go 
 before you move on to produce responsive servers that react to certain web endpoint. 
 You will then implement database connections to acquire data and then present it to our 
 users using different template packages. Later on, you will learn about sessions and 
 cookies to retain information before delving with the basics of microservices. By the end 
 of this module, we will be covering the testing, debugging, and the security aspect.
  
 Module 2, Go Programming Blueprints
 , has a project-based approach where you will be 
 building chat application, adding authentication, and adding your own profile pictures in 
 different ways. You will learn how Go makes it easy to build powerful command-line tools 
 to find domain names before building a highly scalable Twitter polling and vote counting 
 engine powered by NSQ and MongoDB. Later on it covers the functionalities of RESTful 
 Data Web Service API and Google Places API before you move on to build a simple but 
 powerful filesystem backup tool for our code projects. 
  
 Module 3, Mastering Concurrency in Go
 , introduces you to Concurrency in Go where you 
 will be understanding the Concurrency model and developing a strategy for designing 
 applications. You will learn to create basic and complex communication channels 
 between our goroutines to manage data not only across single or 
  
 multithreaded systems but also distributed systems. Later on you will be tackling a real-
 world problem, that is, being able to develop a high performance web server that can 
 handle a very large volume of live, active traffic. You will then learn how to scale your 
 application and make it capable of being expanded in scope, design, and/ or capacity. It 
 will then focus on when and where to implement concurrent patterns, utilize 
 parallelism, and ensure data consistency. At the end of this module, we will be logging 
 and testing concurrency before we finally look at the best practices on how to 
 implement complicated and advanced techniques offered by Go.
  
 [
  ii 
 ]",NA
What you need for this learning path,"For this course, any modern computers running a standard Linux flavor, OS X or 
 Windows should be enough to get started. You can find a full list of requirements at 
 https://golang.org/dl/
 . Later on, you'll also need to have the following software 
 installed:
  
 • 
  
 MySQL (http://dev.mysql.com/downloads/)
  
 • 
  
 Couchbase (http://www.couchbase.com/download)
  
 Your choice of IDE is a matter of personal preference.",NA
Who this learning path is for,"This course is intended for developers who are new to Go but have previous 
  
 experience of building web applications and APIs. It is also targeted towards systems or 
 network programmer with some knowledge of Go and concurrency, but would like to 
 know about the implementation of concurrent systems written in Go",NA
Reader feedback,"Feedback from our readers is always welcome. Let us know what you think about this 
 course—what you liked or disliked. Reader feedback is important for us as it helps us 
 develop titles that you will really get the most out of.
  
 To send us general feedback, simply e-mail 
 feedback@packtpub.com
 , and mention the 
 course's title in the subject of your message.
  
 If there is a topic that you have expertise in and you are interested in either writing or 
 contributing to a book, see our author guide at 
 www.packtpub.com/authors
 .",NA
Customer support,"Now that you are the proud owner of a Packt course, we have a number of things to help 
 you to get the most from your purchase.",NA
Downloading the example code,"You can download the example code files for this course from your account at 
 http://www.packtpub.com
 . If you purchased this course elsewhere, you can visit 
 http://www.packtpub.com/support
  and register to have the files e-mailed directly to 
 you.
  
 [
  iii 
 ]",NA
Errata,"Although we have taken every care to ensure the accuracy of our content, mistakes do 
 happen. If you find a mistake in one of our courses—maybe a mistake in the text or the 
 code—we would be grateful if you could report this to us. By doing so, you can save 
 other readers from frustration and help us improve subsequent versions of this course. 
 If you find any errata, please report them by visiting 
 http://www.
  
 packtpub.com/submit-errata
 , selecting your course, clicking on the 
 Errata 
 Submission Form
  link, and entering the details of your errata. Once your errata are 
 verified, your submission will be accepted and the errata will be uploaded to our 
 website or added to any list of existing errata under the Errata section of that title.
  
 To view the previously submitted errata, go to 
 https://www.packtpub.com/books/ 
 content/support
  and enter the name of the course in the search field. The required 
 information will appear under the 
 Errata
  section.
  
 [
  iv 
 ]",NA
Piracy,"Piracy of copyrighted material on the Internet is an ongoing problem across all media. At 
 Packt, we take the protection of our copyright and licenses very seriously. If you come 
 across any illegal copies of our works in any form on the Internet, please provide us with 
 the location address or website name immediately so that we can pursue a remedy.
  
 Please contact us at 
 copyright@packtpub.com
  with a link to the suspected pirated 
 material.
  
 We appreciate your help in protecting our authors and our ability to bring you 
 valuable content.",NA
Questions,"If you have a problem with any aspect of this course, you can contact us at 
 questions@packtpub.com
 , and we will do our best to address the problem.
  
 [
  v 
 ]",NA
Module 1: Learning Go Web Development,"Chapter 1: Introducing and Setting Up Go 
 Installing Go  
 Structuring a project  
 Importing packages  
 Introducing the net package  
 Hello, Web  
 Summary  
 Chapter 2: Serving and Routing 
  
 Serving files directly  
 Basic routing  
 Using more complex routing with Gorilla 
 Redirecting requests  
 Serving basic errors  
 Summary  
 Chapter 3: Connecting to Data 
 Connecting to a database  
 Using GUID for prettier URLs 
 Handling 404s  
 Summary  
 Chapter 4: Using Templates 
  
 Introducing templates, context, and visibility 
 HTML templates and text templates  
 Displaying variables and security  
 Using logic and control structures  
 Summary  
 Chapter 5: Frontend Integration with RESTful APIs 
 Setting up the basic API endpoint  
 RESTful architecture and best practices  
 Creating our first API endpoint  
 3 
  
 4  
 6  
 8  
 10  
 10  
 12 
 13 
  
 13  
 14  
 15  
 18  
 19  
 22 
 23 
  
 24  
 30  
 31  
 32 
 33 
  
 34  
 35  
 37  
 39  
 44 
 45 
  
 46  
 47  
 48",NA
Module 2: Go Programming Blueprints,"Chapter 1: Chat Application with Web Sockets 
 A 
 simple web server  
 Modeling a chat room and clients on the server 
 Building an HTML and JavaScript chat client Tracing 
 code to get a look under the hood  
 Summary  
 Chapter 2: Adding Authentication 
  
 Handlers all the way down  
 Making a pretty social sign-in page  
 Endpoints with dynamic paths  
 OAuth2  
 Tell the authentication providers about your app 
 Implementing external logging in  
 Summary  
 Chapter 3: Three Ways to Implement Profile Pictures 
 Avatars from the authentication server  
 Implementing Gravatar  
 Uploading an avatar picture  
 Combining all three implementations  
 Summary  
 Chapter 4: Command-line Tools to Find Domain Names 
 Pipe design for command-line tools  
 Five simple programs  
 Composing all five programs  
 Summary  
 121 
  
 122  
 127  
 135  
 140  
 151 
 153 
  
 154  
 156  
 159  
 161  
 162  
 163  
 174 
 177 
  
 178  
 184  
 193  
 208  
 210 
 211 
  
 212  
 212  
 231  
 235 
 Chapter 5: Building Distributed Systems and Working 
  
 with Flexible Data 
  
 System design  
 Installing the environment 
 Votes from Twitter  
 Counting votes  
 Running our solution  
 Summary  
 237 
  
 238  
 240  
 244  
 260  
 266  
 267",NA
Module 3: Mastering Concurrency in Go,"Chapter 1: An Introduction to Concurrency in Go 
 Introducing goroutines  
 Implementing the defer control mechanism  
 Understanding goroutines versus coroutines  
 Implementing channels  
 Closures and goroutines  
 Building a web spider using goroutines and channels 
 Summary  
 Chapter 2: Understanding the Concurrency Model 
 Understanding the working of goroutines  
 Synchronous versus asynchronous goroutines  
 Visualizing concurrency  
 353 
  
 353  
 357  
 365  
 366  
 377  
 379  
 384 
 385 
  
 385  
 386  
 388",NA
Module 1,"Learning Go Web Development
  
 Build frontend-to-backend web applications using the best practices of a powerful, fast, 
  
 and easy-to-deploy server language",NA
Introducing and Setting Up Go,"When starting with Go, one of the most common things you'll hear being said is that it's 
 a systems language.
  
 Indeed, one of the earlier descriptions of Go, by the Go team itself, was that the language 
 was built to be a modern systems language. It was constructed to combine the speed 
 and power of languages, such as C with the syntactical elegance and thrift of modern 
 interpreted languages, such as Python. You can see that goal realized when you look at 
 just a few snippets of Go code.
  
 From the Go FAQ on why Go was created:
  
 ""Go was born out of frustration with existing languages and environments for 
 systems programming.""
  
 Perhaps the largest part of present-day Systems programming is designing backend 
 servers. Obviously, the Web comprises a huge, but not exclusive, percentage of that 
 world.
  
 Go hasn't been considered a web language until recently. Unsurprisingly, it took a few 
 years of developers dabbling, experimenting, and finally embracing the language to start 
 taking it to new avenues.
  
 While Go is web-ready out of the box, it lacks a lot of the critical frameworks and tools 
 people so often take for granted with web development now. As the community around 
 Go grew, the scaffolding began to manifest in a lot of new and exciting ways. Combined 
 with existing ancillary tools, Go is now a wholly viable option for end-to-end web 
 development. But back to that primary question: Why Go? To be fair, it's not right for 
 every web project, but any application that can benefit from high-performance, secure 
 web-serving out of the box with the added benefits of a beautiful concurrency model 
 would make for a good candidate.
  
 [
  3 
 ]",NA
Installing Go,"The most critical first step is, of course, making sure that Go is available and ready to start 
 our first web server.
  
  
 While one of Go's biggest selling points is its cross-platform support 
  
  
 (both building and using locally while targeting other operating 
  
 systems), your life will be much easier on a Nix compatible platform.
  
 If you're on Windows, don't fear. Natively, you may run into 
  
 incompatible packages, firewall issues when running using 
 go run
  
 command and some other quirks, but 95% of the Go ecosystem will be 
  
 available to you. You can also, very easily, run a virtual machine, and in 
  
 fact that is a great way to simulate a potential production environment.
  
 In-depth installation instructions are available at 
 https://golang.org/doc/ 
 install
 , but we'll talk about a few quirky points here before moving on.
  
 For OS X and Windows, Go is provided as a part of a binary installation package. For 
 any Linux platform with a package manager, things can be pretty easy.
  
  
 To install via common Linux package managers:
  
  
 Ubuntu: 
 sudo apt-get golang
  
 CentOS: 
 sudo yum install golang
  
 [
  4 
 ]",NA
Structuring a project,"When you're first getting started and mostly playing around, there's no real problem 
 with setting your application lazily.
  
 For example, to get started as quickly as possible, you can create a simple 
 hello.go 
 file anywhere you like and compile without issue.
  
 But when you get into environments that require multiple or distinct packages (more 
 on that shortly) or have more explicit cross-platform requirements, it makes sense to 
 design your project in a way that will facilitate the use of the go build tool.
  
 The value of setting up your code in this manner lies in the way that the go build tool 
 works. If you have local (to your project) packages, the build tool will look in the 
 src 
 directory first and then your 
 GOPATH
 . When you're building for other platforms, go build 
 will utilize the local bin folder to organize the binaries.
  
 When building packages that are intended for mass use, you may also find that either 
 starting your application under your 
 GOPATH
  directory and then symbolically linking it 
 to another directory, or doing the opposite, will allow you to develop without the need 
 to subsequently go get your own code.",NA
Code conventions,"As with any language, being a part of the Go community means perpetual 
  
 consideration of the way others create their code. Particularly if you're going to work in 
 open source repositories, you'll want to generate your code the way that others do, in 
 order to reduce the amount of friction when people get or include your code.
  
 [
  6 
 ]",NA
Importing packages,"Beyond the absolute and the most trivial application—one that cannot even produce a 
 HelloWorld
  output—you must have some imported package in a Go application.
  
 To say 
 HelloWorld
 , for example, we'd need some sort of a way to generate an output. 
 Unlike in many other languages, even the core language library is accessible by a 
 namespaced package. In Go, namespaces are handled by a repository endpoint URL, 
 which is 
 github.com/nkozyra/gotest
 , which can be opened directly on Github (or 
 any other public location) for the review.",NA
Handling private repositories,"The go get tool easily handles packages hosted at the repositories, such as Github, 
 Bitbucket, and Google Code (as well as a few others). You can also host your own 
 projects, ideally a git project, elsewhere, although it might introduce some 
 dependencies and sources for errors, which you'd probably like to avoid.
  
 But what about the private repos? While go get is a wonderful tool, you'll find 
 yourself looking at an error without some additional configuration, SSH agent 
 forwarding, and so on.
  
 You can work around this in a couple of ways, but one very simple method is to 
 clone the repository locally, using your version control software directly.
  
 [
  8 
 ]",NA
Dealing with versioning,"You may have paused when you read about the way namespaces are defined and 
 imported in a Go application. What happens if you're using version 1 of the 
 application but would like to bring in version 2? In most cases, this has to be 
 explicitly defined in the path of the 
 import
 . For example:
  
 import (
  
  ""github.com/foo/foo-v1""
  
 )
  
 versus:
  
 import (
  
  ""github.com/foo/foo-v2""
  
 )
  
 As you might imagine, this can be a particularly sticky aspect of the way Go handles the 
 remote packages.
  
 Unlike a lot of other package managers, go get is decentralized—that is, nobody maintains 
 a canonical reference library of packages and versions. This can sometimes be a sore spot 
 for new developers.
  
 For the most part, packages are always imported via the 
 go get
  command, which reads 
 the master branch of the remote repository. This means that maintaining multiple 
 versions of a package at the same endpoint is, for the most part, impossible.
  
 It's the utilization of the URL endpoints as namespaces that allows the decentralization, 
 but it's also what provides a lack of internal support for versioning.
  
 Your best bet as a developer is to treat every package as the most up-to-date version 
 when you perform a 
 go get
  command. If you need a newer version, you can always 
 follow whatever pattern the author has decided on, such as the preceding example.
  
 As a creator of your own packages, make sure that you also adhere to this philosophy. 
 Keeping your master branch HEAD as the most up-to-date will make sure your that the 
 code fits with the conventions of other Go authors.
  
 [
  9 
 ]",NA
Introducing the net package ,"At the heart of all network communications in Go is the aptly-named net package, which 
 contains subpackages not only for the very relevant HTTP operations, but also for other 
 TCP/UDP servers, DNS, and IP tools.
  
 In short, everything you need to create a robust server environment.
  
 Of course, what we care about for the purpose of this book lies primarily in the 
 net/http
  package, but we'll look at a few other functions that utilize the rest of the 
 package, such as a TCP connection, as well as WebSockets.
  
 Let's quickly take a look at just performing that Hello World (or Web, in this case) 
 example we have been talking about.",NA
"Hello, Web ","The following application serves as a static file at the location 
 /static
 , and a dynamic 
 response
  at the location 
 /dynamic
 :
  
 package main
  
 import (
  
  
  ""fmt""
  
  
  ""net/http""
  
  
  ""time"" 
  
 )
  
 const (
  
  
  Port = "":8080"" 
  
 )
  
 func serveDynamic(w http.ResponseWriter, r *http.Request) {
  
  response := ""The time is now "" + time.Now().String()
  
  
 fmt.Fprintln(w,response) 
  
 }
  
 Just as 
 fmt.Println
  will produce desired content at the console level, 
 Fprintln 
 allows you to direct output to any writer. We'll talk a bit more about the writers in 
 Chapter 2
 , 
 Serving and Routing
 , but they represent a fundamental, flexible interface 
 that is utilized in many Go applications, not just for the Web:
  
 func serveStatic(w http.ResponseWriter, r *http.Request) 
 {
  
  http.ServeFile(w, r, ""static.html"") 
  
 }
  
 [
  10 
 ]",NA
Summary ,"This chapter serves as an introduction to the most basic concepts of Go and 
 producing for the Web in Go, but these points are critical foundational elements for 
 being productive in the language and in the community.
  
 We've looked at coding conventions and package design and organization, and we've 
 produced our first program—the all-too-familiar Hello, World application—and 
 accessed it via our localhost.
  
 Obviously, we're a long way from a real, mature application for the Web, but the 
 building blocks are essential to getting there.
  
 In 
 Chapter 2
 , 
 Serving and Routing
 , we'll look at how to direct different requests to 
 different application logic using the built-in routing functionality in Go's 
 net/http 
 package, as well as a couple of third party router packages.
  
 [
  12 
 ]",NA
Serving and Routing,"The cornerstone of the Web as a commercial entity—the piece on which marketing 
 and branding has relied on nearly exclusively—is the URL. While we're not yet looking 
 at the top-level domain handling, we need to take up the reins of our URL and its paths 
 (or endpoints).
  
 In this chapter, we'll do just this by introducing multiple routes and corresponding 
 handlers. First, we'll do this with a simple flat file serving and then we'll introduce 
 complex mixers to do the routing with more flexibility by implementing a library that 
 utilizes regular expressions in its routes.
  
 By the end of this chapter, you should be able to create a site on localhost that can be 
 accessed by any number of paths and return content relative to the requested path.
  
 In this chapter, we will cover the following topics:
  
 • 
  
 Serving files directly
  
 • 
  
 Basic routing
  
 • 
  
 Using more complex routing with Gorilla
  
 • 
  
 Redirecting requests
  
 • 
  
 Serving basic errors",NA
Serving files directly,"In the preceding chapter, we utilized the 
 fmt.Fprintln
  function to output some 
 generic Hello, World messaging in the browser.
  
 This obviously has limited utility. In the earliest days of the Web and web servers, the 
 entirety of the Web was served by directing requests to corresponding static files. In 
 other words, if a user requested 
 home.html
 , the web server would look for a file called 
 home.html
  and return it to the user.
  
 [
  13 
 ]",NA
Basic routing,"In 
 Chapter 1
 , 
 Introducing and Setting Up
 , we produced a very basic URL endpoint that 
 allowed static file serving.
  
 The following are the simple routes we produced for that example:
  
 func main() {
  
  http.HandleFunc(""/static"",serveStatic)
  
  http.HandleFunc(""/"",serveDynamic)
  
  http.ListenAndServe(Port,nil)
  
 }
  
 In review, you can see two endpoints, 
 /static
  and 
 /
 , which either serve a single 
 static file or generate output to the 
 http.ResponseWriter
 .
  
 [
  14 
 ]",NA
Using more complex routing with Gorilla,"In the previous session, we looked at basic routing but that can only take us so far, we 
 have to explicitly define our endpoints and then assign them to handlers. What happens 
 if we have a wildcard or a variable in our URL? This is an absolutely essential part of the 
 Web and any serious web server.
  
 To invoke a very simple example, consider hosting a blog with unique identifiers for 
 each blog entry. This could be a numeric ID representing a database ID entry or a text-
 based globally unique identifier, such as 
 my-first-block-entry
 .
  
  
 In the preceding example, we want to route a URL like 
 /pages/1
  to 
  
  
 a filename called 
 1.html
 . Alternately, in a database-based scenario, 
  
 we'd want to use 
 /pages/1
  or 
 /pages/hello-world
  to map to a 
  
 database entry with a GUID of 
 1
  or 
 hello-world
 , respectively. To do 
  
 this we either need to include an exhaustive list of possible endpoints, 
  
 which is extremely wasteful, or implement wildcards, ideally through 
  
 regular expressions.
  
 In either case, we'd like to be able to utilize the value from the URL directly within 
 our application. This is simple with URL parameters from 
 GET
  or 
 POST
 . 
  
 We can extract those simply, but they aren't particularly elegant in terms of clean, 
 hierarchical or descriptive URLs that are often necessary for search engine 
 optimization purposes.
  
 The built-in 
 net/http
  routing system is, perhaps by design, relatively simple. To get 
 anything more complicated out of the values in any given request, we either need to 
 extend the routing capabilities or use a package that has done this.
  
 In the few years that Go has been publicly available and the community has been 
 growing, a number of web frameworks have popped up. We'll talk about these in a little 
 more depth as we continue the book, but one in particular is well-received and very 
 useful: the Gorilla web toolkit.
  
 [
  15 
 ]",NA
Redirecting requests,"Before we look at simple and incredibly common errors like 404s, let's address the idea of 
 redirecting requests, something that's very common. Although not always for reasons that 
 are evident or tangible for the average user.
  
 So we might we want to redirect requests to another request? Well there are quite a 
 few reasons, as defined by the HTTP specification that could lead us to implement 
 automatic redirects on any given request. Here are a few of them with their 
 corresponding HTTP status codes:
  
 • 
  
 • 
  
 • 
  
 A non-canonical address may need to be redirected to the canonical one for 
 SEO purposes or for changes in site architecture. This is handled by 
 301 Moved 
 Permanently
  or 
 302 Found
 .
  
 Redirecting after a successful or unsuccessful 
 POST
 . This helps us to prevent re-
 POSTing of the same form data accidentally. Typically, this is defined by 
 307 
 Temporary Redirect
 .
  
 The page is not necessarily missing, but it now lives in another location. 
 This is handled by the status code 
 301 Moved Permanently
 .
  
 [
  18 
 ]",NA
Serving basic errors,"At this point, it makes some sense to talk a bit about errors. In all likelihood, you may 
 have already encountered one as you played with our basic flat file serving server, 
 particularly if you went beyond two or three pages.
  
 Our example code includes four example HTML files for flat serving, numbered 
 1.html
 , 
 2.html
 , and so on. What happens when you hit the 
 /pages/5
  endpoint, 
 though? Luckily, the 
 http
  package will automatically handle the file not found errors, 
 just like most common web servers.
  
 Also, similar to most common web servers, the error page itself is small, bland, and 
 nondescript. In the following section, you can see the 
 404 page not found
  status 
 response we get from Go:
  
  
 As mentioned, it's a very basic and nondescript page. Often, that's a good thing—error 
 pages that contain more information or flair than necessary can have a negative impact.
  
 Consider this error—the 
 404
 —as an example. If we include references to images and 
 stylesheets that exist on the same server, what happens if those assets are also 
 missing?
  
 In short, you can very quickly end up with recursive errors—each 
 404
  page calls an 
 image and stylesheet that triggers 
 404
  responses and the cycle repeats. Even if the web 
 server is smart enough to stop this, and many are, it will produce a nightmare scenario 
 in the logs, rendering them so full of noise that they become useless.
  
 [
  19 
 ]",NA
Summary,"We can now produce not only the basic routes from the 
 net/http
  package but more 
 complicated ones using the Gorilla toolkit. By utilizing Gorilla, we can now create 
 regular expressions and implement pattern-based routing and allow much more 
 flexibility to our routing patterns.
  
 With this increased flexibility, we also have to be mindful of errors now, so we've 
 looked at handling error-based redirects and messages, including a custom 
 404, 
 Page not found
  message to produce more customized error messages.
  
 Now that we have the basics down for creating endpoints, routes, and handlers; we 
 need to start doing some non-trivial data serving.
  
 In 
 Chapter 3
 , 
 Connecting to Data
 , we'll start getting dynamic information from 
 databases, so we can manage data in a smarter and more reliable fashion. By 
 connecting to a couple of different, commonly-used databases, we'll be able to 
 build robust, dynamic, and scalable web applications.
  
 [
  22 
 ]",NA
Connecting to Data,"In the previous chapter, we explored how to take URLs and translate them to different 
 pages in our web application. In doing so, we built URLs that were dynamic and resulted 
 in dynamic responses from our (very simple) 
 net/http
  handlers.
  
 By implementing an extended mux router from the Gorilla toolkit, we expanded the 
 capabilities of the built-in router by allowing regular expressions, which gives our 
 application a lot more flexibility.
  
 This is something that's endemic to some of the most popular web servers. For example, 
 both Apache and Nginx provide methods to utilize regular expressions in routes and 
 staying at par with common solutions should be our minimal baseline for functionality.
  
 But this is just an admittedly important stepping stone to build a robust web 
 application with a lot of varied functionality. To go any further, we need to look at 
 bringing in data.
  
 Our examples in the previous chapter relied on hardcoded content grabbed from 
 static files—this is obviously archaic and doesn't scale. Anyone who has worked in 
 the pre-CGI early days of the Web could regale you with tales of site updates 
 requiring total retooling of static files or explain the anachronism that was Server-
 Side Includes.
  
 But luckily, the Web became largely dynamic in the late 1990s and databases began to 
 rule the world. While APIs, microservices and NoSQL have in some places replaced that 
 architecture, it still remains the bread and butter of the way the Web works today.
  
 So without further ado, let's get some dynamic data.
  
 In this chapter, we will cover the following topics:
  
 • 
  
 Connecting to a database
  
 [
  23 
 ]",NA
Connecting to a database,"When it comes to accessing databases, Go's SQL interface provides a very simple and 
 reliable way to connect to various database servers that have drivers.
  
 At this point, most of the big names are covered—MySQL, Postgres, SQLite, MSSQL, and 
 quite a few more have well-maintained drivers that utilize the 
 database/sql 
 interface 
 provided by Go.
  
 The best thing about the way Go handles this through a standardized SQL 
  
 interface is that you won't have to learn custom Go libraries to interact with your 
 database. This doesn't preclude needing to know the nuances of the database's SQL 
 implementation or other functionality, but it does eliminate one potential area of 
 confusion.
  
 Before you go too much farther, you'll want to make sure that you have a library and 
 a driver for your database of choice installed via 
 go get
  command.
  
 The Go project maintains a Wiki of all of the current SQLDrivers and is a good 
 starting reference point when looking for an adapter at 
 https://github.com/ 
 golang/go/wiki/SQLDrivers
  
  
 Note: We're using MySQL and Postgres for various examples in this 
  
  
 book, but use the solution that works best for you. Installing MySQL 
  
 and Postgres is fairly basic on any Nix, Windows, or OS X machine.
  
 MySQL can be downloaded from 
 https://www.mysql.com/
  and although there are a 
 few drivers listed by Google, we recommend the Go-MySQL-Driver. Though you won't go 
 wrong with the recommended alternatives from the Go project, the Go-MySQL-Driver is 
 very clean and well-tested. You can get it at 
 https://github.com/ go-sql-
 driver/mysql/
  
 For Postgres, grab a binary or package manager command from 
 http://www. 
 postgresql.org/
 . The Postgres driver of choice here is 
 pq
 , which can be installed via 
 go get
  at 
 github.com/lib/pq",NA
Creating a MySQL database,"You can choose to design any application you wish, but for these examples we'll look 
 at a very simple blog concept.
  
 [
  24 
 ]",NA
Using GUID for prettier URLs,"Earlier in this chapter we talked about using the GUID to act as the URL identifier for all 
 requests. Instead, we started by yielding to the numeric, thus automatically 
 incrementing column in the table. That was for the sake of simplicity, but switching this 
 to the alphanumeric GUID is trivial.
  
 All we'll need to do is to switch our regular expression and change our resulting SQL 
 query in our 
 ServePage
  handler.
  
 If we only change our regular expression, our last URL's page will still work:
  
 routes.HandleFunc(""/page/{id:[0-9a-zA\\-]+}"", ServePage)
  
 The page will of course still pass through to our handler. To remove any ambiguity, let's 
 assign a 
 guid
  variable to the route:
  
 routes.HandleFunc(""/page/{guid:[0-9a-zA\\-]+}"", ServePage)
  
 After that, we change our resulting call and SQL:
  
 func ServePage(w http.ResponseWriter, r *http.Request) {
  
  vars := mux.Vars(r)
  
  pageGUID := vars[""guid""]
  
  thisPage := Page{}
  
  fmt.Println(pageGUID)
  
  err := database.QueryRow(""SELECT page_title,page_content,page_date 
 FROM pages WHERE page_guid=?"", 
  
 pageGUID).Scan(&thisPage.Title, &thisPage.Content, &thisPage.Date)
  
 [
  30 
 ]",NA
Handling 404s,"A very obvious problem with our preceding code is that it does not handle a scenario 
 wherein an invalid ID (or GUID) is requested.
  
 As it is, a request to, say, 
 /page/999
  will just result in a blank page for the user and in the 
 background a 
 Couldn't get page!
  message, as shown in the following screenshot:
  
  
 Resolving this is pretty simple by passing proper errors. Now, in the previous chapter we 
 explored custom 
 404
  pages and you can certainly implement one of those here, but the 
 easiest way is to just return an HTTP status code when a post cannot be found and allow 
 the browser to handle the presentation.
  
 In our preceding code, we have an error handler that doesn't do much except return the 
 issue to our log file. Let's make that more specific:
  
  err := database.QueryRow(""SELECT  
  
 page_title,page_content,page_date FROM pages WHERE page_guid=?"", 
 pageGUID).Scan(&thisPage.Title, &thisPage.Content, 
 &thisPage.Date)
  
  if err != nil {
  
  http.Error(w, http.StatusText(404), http.StatusNotFound)
  
  log.Println(""Couldn't get page!"")
  
  }
  
 [
  31 
 ]",NA
Summary,"In this chapter, we've taken the leap from simply showing content to showing content 
 that's maintained in a sustainable and maintainable way using a database. 
  
 While this allows us to display dynamic data easily, it's just a core step toward a 
 fully-functional application.
  
 We've looked at creating a database and then retrieving the data from it to inject into 
 route while keeping our query parameters sanitized to prevent SQL injections.
  
 We also accounted for potential bad requests with invalid GUIDs, by returning 
 404 Not 
 Found
  statuses for any requested GUID that does not exist in our database. 
  
 We also looked at requesting data by ID as well as the alphanumeric GUID.
  
 This is just the start of our application, though.
  
 In 
 Chapter 4
 , 
 Using Templates
 , we'll take the data that we've grabbed from MySQL (and 
 Postgres) and apply some of Go's template language to them to give us more frontend 
 flexibility.
  
 By the end of that chapter, we will have an application that allows for creation 
 and deletion of pages directly from our application.
  
 [
  32 
 ]",NA
Using Templates,"In 
 Chapter 2
 , 
 Serving and Routing
 , we explored how to take URLs and translate them to 
 different pages in our web application. In doing so, we built URLs that were dynamic and 
 resulted in dynamic responses from our (very simple) 
 net/http
  handlers.
  
 We've presented our data as real HTML, but we specifically hard-coded our HTML 
 directly into our Go source. This is not ideal for production-level environments for a 
 number of reasons.
  
 Luckily, Go comes equipped with a robust but sometimes tricky template engine for 
 both text templates, as well as HTML templates.
  
 Unlike a lot of other template languages that eschew logic as a part of the presentation 
 side, Go's template packages enable you to utilize some logic constructs, such as loops, 
 variables, and function declarations in a template. This allows you to offset some of your 
 logic to the template, which means that it's possible to write your application, but you 
 need to allow the template side to provide some extensibility to your product without 
 rewriting the source.
  
 We say some logic constructs because Go templates are sold as logic-less. We will 
 discuss more on this topic later.
  
 In this chapter, we'll explore ways to not only present your data but also explore some of 
 the more advanced possibilities in this chapter. By the end, we will be able to parlay our 
 templates into advancing the separation of presentation and source code.
  
 We will cover the following topics:
  
 • 
  
 Introducing templates, context, and visibility
  
 • 
  
 HTML templates and text templates
  
 • 
  
 Displaying variables and security
  
 • 
  
 Using logic and control structures
  
 [
  33 
 ]",NA
"Introducing templates, context, ",NA,NA
and visibility,"It's worth noting very early that while we're talking about taking our HTML part out of 
 the source code, it's possible to use templates inside our Go application. Indeed, there's 
 nothing wrong with declaring a template as shown:
  
 tpl, err := template.New(""mine"").Parse(`<h1>{{.Title}}</h1>`)
  
 If we do this, however, we'll need to restart our application every time the template needs 
 to change. This doesn't have to be the case if we use file-based templates; instead we can 
 make changes to the presentation (and some logic) without restarting.
  
 The first thing we need to do to move from in-application HTML strings to file-based 
 templates is create a template file. Let's briefly look at an example template that 
 somewhat approximates to what we'll end up with later in this chapter:
  
 <!DOCTYPE html>
  
 <html>
  
 <head>
  
 <title>{{.Title}}</title>
  
 </head>
  
 <body>
  
  <h1>{{.Title}}</h1>
  
  <div>{{.Date}}</div>
  
  {{.Content}}
  
 </body>
  
 </html>
  
 Very straightforward, right? Variables are clearly expressed by a name within double 
 curly brackets. So what's with all of the periods/dots? Not unlike a few other similarly-
 styled templating systems (Mustache, Angular, and so on), the dot signifies scope or 
 context.
  
 The easiest way to demonstrate this is in areas where the variables might otherwise 
 overlap. Imagine that we have a page with a title of 
 Blog Entries
  and we then list all of 
 our published blog articles. We have a page title but we also have individual entry titles. 
 Our template might look something similar to this:
  
 {{.Title}}
  
 {{range .Blogs}}
  
  <li><a href=""{{.Link}}"">{{.Title}}</a></li>
  
 {{end}}
  
 [
  34 
 ]",NA
HTML templates and text templates ,"In our first example of displaying the values from our blog from our database to the 
 Web, we produced a hardcoded string of HTML and injected our values directly.
  
 Following are the two lines that we used in 
 Chapter 3
 , 
 Connecting to Data
 :
  
  
  html := `<html><head><title>` + thisPage.Title +  
  
 `</title></head><body><h1>` + thisPage.Title + `</h1><div>` + 
 thisPage.Content + `</div></body></html>
  
  
  fmt.Fprintln(w, html)
  
 It shouldn't be hard to realize why this isn't a sustainable system for outputting our 
 content to the Web. The best way to do this is to translate this into a template, so we 
 can separate our presentation from our application.
  
 To do this as succinctly as possible, let's modify the method that called the preceding 
 code, 
 ServePage
 , to utilize a template instead of hardcoded HTML.
  
 So we'll remove the HTML we placed earlier and instead reference a file that will 
 encapsulate what we want to display. From your root directory, create a 
 templates 
 subdirectory and 
 blog.html
  within it.
  
 The following is the very basic HTML we included, feel free to add some flair:
  
 <html> 
  
 <head> 
  
 <title>{{.Title}}</title> 
  
 </head> 
  
 <body>
  
  
  <h1>{{.Title}}</h1>
  
  
  <p>
  
  
  {{.Content}}
  
  
  </p>
  
  
  <div>{{.Date}}</div> 
  
 </body> 
  
 </html>
  
 [
  35 
 ]",NA
Displaying variables and security,"To demonstrate this, let's create a new blog entry by adding this SQL command to your 
 MySQL command line:
  
 INSERT INTO `pages` (`id`, `page_guid`, `page_title`, 
 page_content`, `page_date`)
  
 VALUES:
  
  (2, 'a-new-blog', 'A New Blog', 'I hope you enjoyed the last  
 blog!  Well brace yourself, because my latest blog is even 
 <i>better</i> than the last!', '2015-04-29 02:16:19');
  
 Another thrilling piece of content, for sure. Note, however that we have some 
 embedded HTML in this when we attempt to italicize the word better.
  
 Debates about how formatting should be stored notwithstanding, this allows us to 
 take a look at how Go's templates handle this by default. If we visit 
 http://localhost:9500/page/a-new-blog
  we'll see something similar to this:
  
  
 [
  37 
 ]",NA
Using logic and control structures,"Earlier in this chapter we looked at how we can use a range in our templates just as we 
 would directly in our code. Take a look at the following code:
  
 {{range .Blogs}}
  
  <li><a href=""{{.Link}}"">{{.Title}}</a></li>
  
 {{end}}
  
 You may recall that we said that Go's templates are without any logic, but this 
 depends on how you define logic and whether shared logic lies exclusively in the 
 application, the template, or a little of both. It's a minor point, but because Go's 
 templates offer a lot of flexibility; it's the one worth thinking about.
  
 Having a range feature in the preceding template, by itself, opens up a lot of 
 possibilities for a new presentation of our blog. We can now show a list of blogs or 
 break our blog up into paragraphs and allow each to exist as a separate entity. This can 
 be used to allow relationships between comments and paragraphs, which have started 
 to pop up as a feature in some publication systems in recent years.
  
 But for now, let's use this opportunity to create a list of blogs in a new index page. To do 
 this, we'll need to add a route. Since we have 
 /page
  we could go with 
 /pages
 , but since 
 this will be an index, let's go with 
 /
  and 
 /home
 :
  
  routes := mux.NewRouter()
  
  routes.HandleFunc(""/page/{guid:[0-9a-zA\\-]+}"", ServePage)
  
 routes.HandleFunc(""/"", RedirIndex)
  
 routes.HandleFunc(""/home"", ServeIndex)
  
  http.Handle(""/"", routes)
  
 [
  39 
 ]",NA
Summary,"We've just scratched the surface of what Go's templates can do and we'll explore 
 further topics as we continue, but this chapter has hopefully introduced the core 
 concepts necessary to start utilizing templates directly.
  
 We've looked at simple variables, as well as implementing methods within the 
 application, within the templates themselves. We've also explored how to bypass 
 injection protection for trusted content.
  
 In the next chapter, we'll integrate a backend API for accessing information in a 
 RESTful way to read and manipulate our underlying data. This will allow us to do 
 some more interesting and dynamic things on our templates with Ajax.
  
 [
  44 
 ]",NA
Frontend Integration ,NA,NA
with RESTful APIs,"In 
 Chapter 2
 , 
 Serving and Routing
 , we explored how to route URLs to the different 
 pages in our web application. In doing so, we built URLs that were dynamic and 
 resulted in dynamic responses from our (very simple) 
 net/http
  handlers.
  
 We've just scratched the surface of what Go's templates can do, and we'll also explore 
 further topics as we continue, but in this chapter we have tried to introduce the core 
 concepts that are necessary to start utilizing the templates directly.
  
 We've looked at simple variables as well as the implementing methods within the 
 application using the templates themselves. We've also explored how to bypass 
 injection protection for trusted content.
  
 The presentation side of web development is important, but it's also the least 
 engrained aspect. Almost any framework will present its own extension of built-in Go 
 templating and routing syntaxes. What really takes our application to the next level is 
 building and integrating an API for both general data access, as well as allowing our 
 presentation layer to be more dynamically driven.
  
 In this chapter, we'll develop a backend API for accessing information in a RESTful way 
 and to read and manipulate our underlying data. This will allow us to do some more 
 interesting and dynamic things in our templates with Ajax.
  
 In this chapter, we will cover the following topics:
  
 • 
  
 Setting up the basic API endpoint
  
 • 
  
 RESTful architecture and best practices
  
 • 
  
 Creating our first API endpoint
  
 • 
  
 Implementing security
  
 [
  45 
 ]",NA
Setting up the basic API endpoint ,"First, we'll set up a basic API endpoint for both pages and individual blog entries.
  
 We'll create a Gorilla endpoint route for a 
 GET
  request that will return information 
 about our pages and an additional one that accepts a GUID, which matches 
 alphanumeric characters and hyphens:
  
 routes := mux.NewRouter() 
  
 routes.HandleFunc(""/api/pages"", APIPage).
  
  Methods(""GET"").
  
  
  Schemes(""https"") 
  
 routes.HandleFunc(""/api/pages/{guid:[0-9a-zA\\-]+}"", 
 APIPage).
  
  Methods(""GET"").
  
  Schemes(""https"") 
  
 routes.HandleFunc(""/page/{guid:[0-9a-zA\\-]+}"", 
 ServePage) http.Handle(""/"", routes) 
  
 http.ListenAndServe(PORT, nil)
  
 Note here that we're capturing the GUID again, this time for our 
 /api/pages/* 
 endpoint, which will mirror the functionality of the web-side counterpart, returning all 
 meta data associated with a single page.
  
 func APIPage(w http.ResponseWriter, r *http.Request) { 
  
 vars := mux.Vars(r) 
  
 pageGUID := vars[""guid""] 
  
 thisPage := Page{} 
  
 fmt.Println(pageGUID) 
  
 err := database.QueryRow(""SELECT page_title,page_content,page_date 
 FROM pages WHERE page_guid=?"", pageGUID).Scan(&thisPage.Title, 
 &thisPage.RawContent, &thisPage.Date) 
  
 thisPage.Content = template.HTML(thisPage.RawContent) 
  
 if err != nil {
  
  
  http.Error(w, http.StatusText(404), http.StatusNotFound)
  
  
  log.Println(err)
  
  
  return 
  
 } 
  
 APIOutput, err := json.Marshal(thisPage)
  
  
  fmt.Println(APIOutput) 
  
 if err != nil {
  
  
  http.Error(w, err.Error(), http.StatusInternalServerError)
  
 [
  46 
 ]",NA
RESTful architecture and best practices,"In the world of web API design, there has been an array of iterative, and sometimes 
 competing, efforts to find a standard system and format to deliver information across 
 multiple environments.
  
 In recent years, the web development community at large seems to have—at least 
 temporarily—settled on REST as the de facto approach. REST came after a few years of 
 SOAP dominance and introduced a simpler method for sharing data.
  
 REST APIs aren't bound to a format and are typically cacheable and delivered via 
 HTTP or HTTPS.
  
 The biggest takeaway to start with is an adherence to HTTP verbs; those initially specified 
 for the Web are honored in their original intent. For example, HTTP verbs, such as 
 DELETE
  
 and 
 PATCH
  fell into years of disuse despite being very explicit about their purpose. REST 
 has been the primary impetus for the use of the right method for the right purpose. Prior 
 to REST, it was not uncommon to see 
 GET
  and 
 POST
  requests being used interchangeably 
 to do myriad things that were otherwise built into the design of HTTP.
  
 In REST, we follow a 
 Create-Read-Update-Delete
  (
 CRUD
 )-like approach to retrieve or 
 modify data. 
 POST
  is used majorly to create, 
 PUT
  is used as an update (though it can also 
 be used to create), the familiar 
 GET
  is used to read and 
 DELETE
  is used to delete, is well, 
 just that.
  
 Perhaps even more important is the fact that a RESTful API should be stateless. By 
 that we mean that each request should exist on its own, without the server 
 necessarily having any knowledge about prior or potential future requests. This 
 means that the idea of a session would technically violate this ethos, as we'd be 
 storing some sense of state on the server itself. Some people disagree; we'll look at 
 this in detail later on.
  
 [
  47 
 ]",NA
Creating our first API endpoint,"Given that we want to access data from the client-side as well as from server to server, 
 we'll need to start making some of that accessible via an API.
  
 The most reasonable thing for us to do is a simple read, since we don't yet have 
 methods to create data outside of direct SQL queries. We did that at the beginning of 
 the chapter with our 
 APIPage
  method, routed through a 
 /api/pages/{UUID} 
 endpoint.
  
 [
  48 
 ]",NA
Implementing security,"When you think about creating data with an API like the one we've just designed, 
 what's the first concern that comes to your mind? If it was security, then good for you. 
 Accessing data is not always without a security risk, but it's when we allow for 
 modification of data that we need to really start thinking about security.
  
 In our case, read data is totally benign. If someone can access all of our blog entries 
 via a 
 GET
  request, who cares? Well, we may have a blog on embargo or accidentally 
 exposed sensitive data on some resource.
  
 Either way, security should always be a concern, even with a small personal project like 
 a blogging platform, similar to the one we're building.
  
 There are two big ways of separating these concerns:
  
 • 
  
 Are the requests to our APIs secure and private?
  
 • 
  
 Are we controlling access to data?
  
 Lets tackle Step 2 first. If we want to allow users to create or delete information, we 
 need to give them specific access to that.
  
 There are a few ways to do this:
  
 We can provide API tokens that will allow short-lived request windows, which can be 
 validated by a shared secret. This is the essence of Oauth; it relies on a shared secret to 
 validate cryptographically encoded requests. Without the shared secret, the request 
 and its token will never match, and an API request can then be rejected.
  
 The 
 cond
  method is a simple API key, which leads us back to point number 1 in the 
 preceding list.
  
 If we allow cleartext API keys, then we might as well not have security at all. If our 
 requests can be sniffed off the wire without much effort, there's little point in even 
 requiring an API key.
  
 [
  49 
 ]",NA
Creating data with POST ,"Now that we have a security certificate in place, we can switch to TLS for our API 
 calls for both 
 GET
  and other requests. Let's do that now. Note that you can retain 
 HTTP for the rest of our endpoints or switch them at this point as well.
  
  
 Note: It's largely becoming a common practice to go the HTTPS-only 
  
  
 way and it's probably the best way to future-proof your app. This doesn't 
  
 solely apply to APIs or areas where explicit and sensitive information is 
  
 otherwise sent in cleartext, with privacy on the forefront; major providers 
  
 and services are stressing on the value of HTTPS everywhere.
  
 Lets add a simple section for anonymous comments on our blog:
  
 <div id=""comments"">
  
  
  <form action=""/api/comments"" method=""POST"">
  
  
  <input type=""hidden"" name=""guid"" value=""{{Guid}}"" />
  
  
  <div>
  
    
  <input type=""text"" name=""name"" placeholder=""Your Name"" />
  
  
 </div>
  
 [
  51 
 ]",NA
Modifying data with PUT,"Depending on whom you ask, 
 PUT
  and 
 POST
  can be used interchangeably for the 
 creation of records. Some people believe that both can be used for updating the 
 records and most believe that both can be used for the creation of records given a set 
 of variables. In lieu of getting into a somewhat confusing and often political debate, 
 we've separated the two as follows:
  
 • 
  
 Creation of new records: 
 POST
  
 • 
  
 Updating existing records, idempotently: 
 PUT
  
 Given these guidelines, we'll utilize the 
 PUT
  verb when we wish to make updates to 
 resources. We'll allow comments to be edited by anyone as nothing more than a 
 proof of concept to use the REST 
 PUT
  verb.
  
 [
  55 
 ]",NA
Summary,"In this chapter, we've gone from exclusively server-generated HTML presentations to 
 dynamic presentations that utilize an API. We've examined the basics of REST and 
 implemented a RESTful interface for our blogging application.
  
 While this can use a lot more client-side polish, we have 
 GET
 /
 POST
 /
 PUT
  requests 
 that are functional and allow us to create, retrieve, and update comments for our 
 blog posts.
  
 In 
 Chapter 6
 , 
 Session and Cookies
 , we'll examine user authentication, sessions, and cookies, 
 and how we can take the building blocks we've laid in this chapter and apply some very 
 important security parameters to it. We had an open-ended creation and updates of 
 comments in this chapter; we'll restrict that to unique users in the next.
  
 In doing all of this, we'll turn our proof-of-concept comment management into 
 something that can be used in production practically.
  
 [
  60 
 ]",NA
Sessions and Cookies,"Our application is beginning to get a little more real now; in the previous chapter, we 
 added some APIs and client-side interfaces to them.
  
 In our application's current state, we've added 
 /api/comments
 , 
 /api/comments/ 
 [id]
 , 
 /api/pages
 , and 
 /api/pages/[id]
 , thus making it possible for us to get and 
 update our data in JSON format and making the application better suited for Ajax and 
 client-side access.
  
 Though we can now add comments and edit them directly through our API, there is 
 absolutely no restriction on who can perform these actions. In this chapter, we'll look at 
 the ways to limit access to certain assets, establishing identities, and securely 
 authenticating when we have them.
  
 By the end, we should be able to enable users to register and log in and utilize 
 sessions, cookies, and flash messages to keep user state in our application in a 
 secure way.",NA
Setting cookies,"The most common, fundamental, and simplest way to create persistent memory 
 across a user's session is by utilizing cookies.
  
 Cookies provide a way to share state information across requests, URL endpoints, and 
 even domains, and they have been used (and abused) in every possible way.
  
 Most often, they're used to keep a track of identity. When a user logs into a service, 
 successive requests can access some aspects of the previous request (without duplicating 
 a lookup or the login module) by utilizing the session information stored in a cookie.
  
 [
  61 
 ]",NA
Capturing user information,"When a user with a valid session and
 /
 or cookie attempts to access restricted data, we 
 need to get that from the user's browser.
  
 A session itself is just that—a single session on the site. It doesn't naturally persist 
 indefinitely, so we need to leave a breadcrumb, but we also want to leave one that's 
 relatively secure.
  
 For example, we would never want to leave critical user information in the cookie, 
 such as name, address, email, and so on.
  
 However, any time we have some identifying information, we leave some vector for 
 misdeed—in this case we'll likely leave a session identifier that represents our 
 session ID. The vector in this case allows someone, who obtains this cookie, to log in 
 as one of our users and change information, find billing details, and so on.
  
 [
  62 
 ]",NA
Creating users ,"In the previous chapter, we allowed non-authorized requests to create new comments 
 by hitting our REST API via a 
 POST
 . Anyone who's been on the Internet for a while 
 knows a few truisms, such as:
  
 1. The comments section is often the most toxic part of any blog or news post
  
 2. Step 1 is true, even when users have to authenticate in non-anonymous ways
  
 Now, let's lock down the comments section to ensure that users have registered 
 themselves and are logged in.
  
 We won't go deep into the authentication's security aspects now, as we'll be going 
 deeper with that in 
 Chapter 9
 , 
 Security
 .
  
 First, let's add a 
 users
  table in our database:
  
 CREATE TABLE `users` (
  
  
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  
  
  `user_name` varchar(32) NOT NULL DEFAULT '',
  
  
  `user_guid` varchar(256) NOT NULL DEFAULT '',
  
  
  `user_email` varchar(128) NOT NULL DEFAULT '',
  
  
  `user_password` varchar(128) NOT NULL DEFAULT '',
  
  `user_salt` varchar(128) NOT NULL DEFAULT '',
  
  
  `user_joined_timestamp` timestamp NULL DEFAULT 
 NULL,
  
  PRIMARY KEY (`id`) 
  
 ) ENGINE=InnoDB DEFAULT CHARSET=latin1;
  
 We could surely go a lot deeper with user information, but this is enough to get us 
 started. As mentioned, we won't go too deep into security, so we'll just generate a hash 
 for the password now and not worry about the salt.
  
 Finally, to enable sessions and users in the app, we'll make some changes to our 
 structs:
  
 type Page struct 
 {
  
  
  Id         int
  
 [
  63 
 ]",NA
Enabling sessions ,"In addition to storing the users themselves, we'll also want some way of persistent 
 memory for accessing our cookie data. In other words, when a user's browser session 
 ends and they come back, we'll validate and reconcile their cookie value against values in 
 our database.
  
 Use this SQL to create the 
 sessions
  table:
  
 CREATE TABLE `sessions` (
  
  
  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
  
  
  `session_id` varchar(256) NOT NULL DEFAULT '',
  
  
  `user_id` int(11) DEFAULT NULL,
  
  
  `session_start` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON  
 UPDATE CURRENT_TIMESTAMP,
  
  
  `session_update` timestamp NOT NULL DEFAULT '0000-00-00  
  
 00:00:00',
  
  
  `session_active` tinyint(1) NOT NULL,
  
  
  PRIMARY KEY (`id`),
  
  
  UNIQUE KEY `session_id` (`session_id`) 
  
 ) ENGINE=InnoDB DEFAULT CHARSET=latin1;
  
 [
  64 
 ]",NA
Letting users register,"To be able to allow users to create accounts themselves, we'll need a form for both 
 registering and logging in. Now, most systems similar to this do some multi-factor 
 authentication to allow a user backup system for retrieval as well as validation that the 
 user is real and unique. We'll get there, but for now let's keep it as simple as possible.
  
 We'll set up the following endpoints to allow a user to 
 POST
  both the register and 
 login forms:
  
  routes.HandleFunc(""/register"", RegisterPOST).
  
  Methods(""POST"").
  
  Schemes(""https"")
  
  routes.HandleFunc(""/login"", LoginPOST).
  
  Methods(""POST"").
  
  Schemes(""https"")
  
 Keep in mind that these are presently set to the HTTPS scheme. If you're not using 
 that, remove that part of the 
 HandleFunc
  register.
  
 Since we're only showing these following views to unauthenticated users, we can put 
 them on our 
 blog.html
  template and wrap them in 
 {{if .Session. 
 Unauthenticated}} … {{end}}
  template snippets. We defined 
 .Unauthenticated 
 and 
 .Authenticated
  in the application under the 
 Sessionstruct
 , as shown in the 
 following example:
  
 {{if .Session.Unauthenticated}}<form action=""/register"" 
 method=""POST"">
  
  
  <div><input type=""text"" name=""user_name"" placeholder=""User name""  
 /></div>
  
  
  <div><input type=""email"" name=""user_email"" placeholder=""Your  
 email"" /></div>
  
  
  <div><input type=""password"" name=""user_password""  
 placeholder=""Password"" /></div>
  
  
  <div><input type=""password"" name=""user_password2""  
 placeholder=""Password (repeat)"" /></div>
  
  <div><input type=""submit"" value=""Register"" /></div>
  
 </form>{{end}}
  
 [
  65 
 ]",NA
Letting users log in ,"A user may be already registered; in which case, we'll also want to provide a login 
 mechanism on the same page. This can obviously be subject to better design 
 considerations, but we just want to make them both available:
  
 [
  66 
 ]",NA
Initiating a server-side session,"One of the most common ways of authenticating a user and saving their state on the 
 Web is through sessions. You may recall that we mentioned in the last chapter that REST 
 is stateless, the primary reason for that is because HTTP itself is stateless.
  
 If you think about it, to establish a consistent state with HTTP, you need to include a 
 cookie or a URL parameter or something that is not built into the protocol itself.
  
 Sessions are created with unique identifiers that are usually not entirely random but 
 unique enough to avoid conflicts for most logical and plausible scenarios. This is not 
 absolute, of course, and there are plenty of (historical) examples of session token 
 hijacking that are not related to sniffing.
  
 Session support as a standalone process does not exist in Go core. Given that we have a 
 storage system on the server side, this is somewhat irrelevant. If we create a safe 
 process for generation of server keys, we can store them in secure cookies.
  
 But generating session tokens is not completely trivial. We can do this using a set of 
 available cryptographic methods, but with session hijacking as a very prevalent way of 
 getting into systems without authorization, that may be a point of insecurity in our 
 application.
  
 Since we're already using the Gorilla toolkit, the good news is that we don't have to 
 reinvent the wheel, there's a robust session system in place.
  
 Not only do we have access to a server-side session, but we get a very convenient 
 tool for one-time messages within a session. These work somewhat similar to a 
 message queue in the manner that once data goes into them, the flash message is no 
 longer valid when that data is retrieved.
  
 [
  67 
 ]",NA
Creating a store ,"To utilize the Gorilla sessions, we first need to invoke a cookie store, which will hold all 
 the variables that we want to keep associated with a user. You can test this out pretty 
 easily by the following code:
  
 package main
  
 import (
  
  
  ""fmt""
  
  
  ""github.com/gorilla/sessions""
  
  
  ""log""
  
  
  ""net/http"" 
  
 )
  
 func cookieHandler(w http.ResponseWriter, r *http.Request) {
  
  
  var cookieStore = sessions.NewCookieStore([]byte(""ideally, some  
 random piece of entropy""))
  
  
  session, _ := cookieStore.Get(r, ""mystore"")
  
  
  if value, exists := session.Values[""hello""]; exists {
  
  
  fmt.Fprintln(w, value)
  
  
  } else {
  
  
  session.Values[""hello""] = ""(world)""
  
  
  session.Save(r, w)
  
  
  fmt.Fprintln(w, ""We just set the value!"")
  
  
  } 
  
 }
  
 func main() {
  
  
  http.HandleFunc(""/test"", cookieHandler)
  
  
  log.Fatal(http.ListenAndServe("":8080"", 
 nil)) }
  
 The first time you hit your URL and endpoint, you'll see 
 We just set the value!
 , as 
 shown in the following screenshot:
  
  
 [
  68 
 ]",NA
Utilizing flash messages ,"As mentioned earlier in this chapter, Gorilla sessions offer a simple system to utilize a 
 single-use and cookie-based data transfer between requests.
  
 The idea behind a flash message is not all that different than an in-browser/server 
 message queue. It's most frequently utilized in a process such as this:
  
 • 
  
 • 
  
 • 
  
 • 
  
 A form is POSTed 
  
 The data is processed 
  
 A header redirect is initiated 
  
 The resulting page needs some access to information about the 
 POST
  process 
 (success, error)
  
 [
  71 
 ]",NA
Summary,"Hopefully by this point you have a grasp of how to utilize basic cookies and sessions in 
 Go, either through native Go or through the use of a framework, such as Gorilla. We've 
 tried to demonstrate the inner workings of the latter so you're able to build without 
 additional libraries obfuscating the functionality.
  
 We've implemented sessions into our application to enable persistent state between 
 requests. This is the very basis of authentication for the Web. By enabling 
 users
  and 
 sessions
  table in our database, we're able to log users in, register a session, and 
 associate that session with the proper user on subsequent requests.
  
 [
  74 
 ]",NA
Microservices and ,NA,NA
Communication,"Our application is beginning to get a little more real now. In the previous chapter, we 
 added some APIs and client-side interfaces to them.
  
 Microservices have become very hot in the last few years, primarily because they 
 reduce the developmental and support weight of a very large or monolithic 
 application. By breaking apart these monoliths, microservices enable a more agile 
 and concurrent development. They can allow separate teams to work on separate 
 parts of the application without worrying too much about conflicts, backwards 
 compatibility issues, or stepping on the toes of other parts of the application.
  
 In this chapter, we'll introduce microservices and explore how Go can work within 
 them, to enable them and even drive their central mechanisms.
  
 To sum this all up, we will be covering the following aspects:
  
 • 
  
 Introducing the microservice approach
  
 • 
  
 Pros and cons of utilizing microservices
  
 • 
  
 Understanding the heart of microservices
  
 • 
  
 Communicating between microservices
  
 • 
  
 Putting a message on the wire
  
 • 
  
 Reading from another service
  
 [
  77 
 ]",NA
Introducing the microservice approach,"If you've not yet encountered the term microservice or explored its meaning in depth, 
 we can very quickly demystify it. Microservices are, in essence, independent functions of 
 an overall application being broken apart and made accessible via some universally 
 known protocol.
  
 The microservice approach is, usually, utilized to break apart a very large monolithic 
 application.
  
 Imagine your standard web application in the mid-2000s. When new functionality is 
 needed, let's say a function that emails new users, it's added directly to the codebase 
 and integrated with the rest of the application.
  
 As the application grows, so does the necessary test coverage. So, it increases the 
 potential for critical errors too. In this scenario, a critical error doesn't just bring 
 down that component, in this case the e-mailing system; it takes down the entire 
 application.
  
 This can be a nightmare to track down, patch, and re-deploy, and it's exactly the type of 
 nightmare that microservices were designed to address.
  
 If the e-mailing part of the application is separated into its own app, it has a level of 
 isolation and insulation that makes finding problems much easier. It also means that the 
 entire stack doesn't fall down just because someone introduced a critical error into one 
 small part of the whole app, as shown in the following figure:
  
  
 Consider the following basic example architecture, where an application is split into four 
 separate concepts, which represent their own applications in the microservices 
 framework.
  
 Once, every single piece existed in its own application; now they are broken apart 
 into smaller and more manageable systems. Communication between the 
 applications happens via a message queue utilizing REST API endpoints.
  
 [
  78 
 ]",NA
Pros and cons of utilizing microservices,"If microservices seem like a panacea at this point, we should also note that this 
 approach does not come without its own set of issues. Whether the tradeoff is 
 worth it or not depends heavily on an overall organizational approach.
  
 As mentioned earlier, stability and error detection comprise a big production-level win 
 for microservices. But if you think of the flip side of applications not breaking, it could 
 also mean that issues go hidden for longer than they otherwise would. It's hard to ignore 
 the entire site being down, but it could be hours before anyone realizes that e-mails 
 have not been sent, unless some very robust logging is in place.
  
 But there are other big pros to microservices. For one, utilizing an external standard 
 communication protocol (REST, for example) means that you're not locked into a single 
 language.
  
 If, for example, some part of your application can be written better in Node than in Go, 
 you can do that without having to rewrite an entire application. This is a frequent 
 temptation for developers: rewriting the whole thing because the new and shiny 
 language app or feature is introduced. Well, microservices safely enable this behavior—
 it allows a developer or a group of developers to try something without needing to go 
 deeper than the specific function they wish to write.
  
 This, too, comes with a potentially negative scenario—since the application 
  
 components are decoupled, so can the institutional knowledge around them be 
 decoupled. Few developers may know enough to keep the service operating ideally. 
  
 Other members of the group may lack the language knowledge to jump in and fix 
 critical errors.
  
 One final, but important, consideration is that microservice architecture generally 
 means a distributed environment by default. This leads us to the biggest immediate 
 caveat, which is the fact that this situation almost always means that eventual 
 consistency is the name of the game.
  
 Since every message must depend on multiple external services, you're subject to 
 several layers of latency to get a change enacted.",NA
Understanding the heart of microservices,"You might be wondering about one thing as you consider this system to design 
 dissonant services that work in congress: what's the communication platform? 
  
 To answer this, we'll say there is an easy answer and a more intricate one.
  
 [
  79 
 ]",NA
Communicating between microservices,"There are a number of approaches to communicate between microservices, as 
 mentioned; REST endpoints provide a nice landing pad for messages. You may recall 
 the preceding graphic, which shows a message queue as the central conduit between 
 services. This is one of the most common ways to handle message passing and we'll 
 use RabbitMQ to demonstrate this.
  
 In this case, we'll show when new users register to an e-mail queue for the delivery of 
 a message in our RabbitMQ installation, which will then be picked up by an emailing 
 microservice.
  
  
 You can read more about RabbitMQ, which utilizes 
 Advanced Message 
  
  
 Queuing Protocol
  (
 AMQP
 ) here: 
 https://www.rabbitmq.com/
 .
  
 To install an AMQP client for Go, we'll recommend Sean Treadway's 
  
 AMQP package. You can install it with a 
 go get
  command. You can 
  
 get it at 
 github.com/streadway/amqp",NA
Putting a message on the wire,"There are a lot of approaches to use RabbitMQ. For example, one allows multiple 
 workers to accomplish the same thing, as a method for distributing works among 
 available resources.
  
 Assuredly, as a system grows, it is likely to find use for that method. But in our tiny 
 example, we want to segregate tasks based on a specific channel. Of course, this is not 
 analogous to Go's concurrency channels, so keep that in mind when you read about this 
 approach.
  
 [
  80 
 ]",NA
Reading from another service ,"Now that we've sent a message to our message queue in our app, let's use another 
 microservice to pluck that from the queue on the other end.
  
 To demonstrate the flexibility of a microservice design, our secondary service will be a 
 Python script that connects to the MQ and listens for messages on the e-mail queue, when 
 it finds one. It will parse the message and send an e-mail. Optionally, it could publish a 
 status message back on the queue or log it, but we won't go down that road for now:
  
 import pika 
  
 import json 
  
 import smtplib 
  
 from email.mime.text import MIMEText
  
 connection = pika.BlockingConnection(pika.ConnectionParameters( 
 host='localhost')) 
  
 channel = connection.channel() 
  
 channel.queue_declare(queue='email')
  
 print ' [*] Waiting for messages. To exit press CTRL+C'
  
 def callback(ch, method, properties, body):
  
  print "" [x] Received %r"" % (body,)
  
  parsed = json.loads(body)
  
  msg = MIMEText()
  
  msg['From'] = 'Me'
  
 [
  84 
 ]",NA
Summary,"In this chapter, we looked at experimenting with utilizing microservices as a way to 
 dissect your app into separate domains of responsibility. In this example, we delegated 
 the e-mail aspect of our application to another service written in Python.
  
 We did this to utilize the concept of microservices or interconnected smaller 
 applications as callable networked functions. This ethos is driving a large part of 
 the Web of late and has myriad benefits and drawbacks.
  
 In doing this, we implemented a message queue, which operates as the backbone of 
 our communications system, allowing each component to speak to the other in a 
 reliable and repeatable way. In this case, we used a Python application to read 
 messages sent from our Go application across RabbitMQ and take that e-mail data and 
 process it.
  
 In 
 Chapter 8
 , 
 Logging and Testing
 , we'll focus on logging and testing, which we can 
 use to extend the microservices concept so that we can recover from errors and 
 understand where things might go awry in the process.
  
 [
  85 
 ]",NA
Logging and Testing,"In the previous chapter, we discussed delegating application responsibility to 
 networked services accessible by API and intra-process communication and 
 handled by a message queue.
  
 This approach mimics an emerging trend of breaking large monolithic applications 
 into smaller chunks; thus, allowing developers to leverage dissonant languages, 
 frameworks, and designs.
  
 We listed a few upsides and downsides of this approach; while most of the upsides dealt 
 with keeping the development agile and lean while preventing catastrophic and cascading 
 errors that might bring down an entire application, a large downside is the fragility of 
 each individual component. For example, if our e-mail microservice had bad code as a 
 part of a large application, the error would make itself known quickly because it would 
 almost assuredly have a direct and detectable impact on another component. But by 
 isolating processes as part of microservices, we also isolate their state and status.
  
 This is where the contents of this chapter come into play—the ability to test and log 
 within a Go application is the strength of the language's design. By utilizing these in our 
 application, it grows to include more microservices; due to which we can be in a better 
 position to keep track of any issues with a cog in the system without imposing too much 
 additional complexity to the overall application.
  
 In this chapter we will cover the following topics:
  
 • 
  
 Introducing logging in Go
  
 • 
  
 Logging to IO
  
 • 
  
 Formatting your output
  
 • 
  
 Using panics and fatal errors
  
 • 
  
 Introducing testing in Go
  
 [
  87 
 ]",NA
Introducing logging in Go,"Go comes with innumerable ways to display output to 
 stdout
 , most commonly the 
 fmt
  
 package's 
 Print
  and 
 Println
 . In fact, you can eschew the 
 fmt
  package entirely and 
 just use 
 print()
  or 
 println()
 .
  
 In mature applications, you're unlikely to see too many of these, because simply 
 displaying an output without having the capability to store that somewhere for 
 debugging or later analysis is rare and lacks much utility. Even if you're just 
 outputting minor feedback to a user, it often makes sense to do so and keep the 
 ability to save that to a file or elsewhere, this is where the 
 log
  package comes into 
 play. Most of the examples in this book have used 
 log.Println
  in lieu of 
 fmt.
  
 Println
  for this very reason. It's trivial to make that change if, at some point, you 
 choose to supplant 
 stdout
  with some other (or additional) 
 io.Writer
 .",NA
Logging to IO,"So far we've been logging in to 
 stdout
 , but you can utilize any 
 io.Writer
  to ingest the 
 log data. In fact, you can use multiple 
 io.Writers
  if you want the output to be routed to 
 more than one place.",NA
Multiple loggers,"Most mature applications will write to more than one log file to delineate between the 
 various types of messages that need to be retained.
  
 The most common use case for this is found in web server. They typically keep an 
 access.log
  and an 
 error.log
  file to allow the analysis of all successful requests; 
 however, they also maintain separate logging of different types of messages.
  
 In the following example, we modify our logging concept to include errors as well as 
 warnings:
  
 package main
  
 import (
  
  ""log""
  
  ""os""
  
 )
  
 var (
  
  Warn   *log.Logger
  
  Error  *log.Logger
  
  Notice *log.Logger
  
 )
  
 [
  88 
 ]",NA
Formatting your output ,"When instantiating a new 
 Logger
 , you can pass a few useful parameters and/or helper 
 strings to help define and clarify the output. Each log entry can be prepended with a 
 string, which can be helpful while reviewing multiple types of log entries. 
  
 You can also define the type of date and time formatting that you would like on 
 each entry.
  
 To create a custom formatted log, just invoke the 
 New()
  function with an 
 io.Writer 
 as 
 shown:
  
 package main
  
 import (
  
  
  ""log""
  
  
  ""os"" 
  
 )
  
 var (
  
  
  Warn   *log.Logger
  
  
  Error  *log.Logger
  
  
  Notice *log.Logger 
  
 )
  
 func main() {
  
  
  warnFile, err := os.OpenFile(""warnings.log"",  
  
 os.O_RDWR|os.O_APPEND, 0660)
  
  
  defer warnFile.Close()
  
  
  if err != nil {
  
  
  log.Fatal(err)
  
  
  }
  
  
  Warn = log.New(warnFile, ""WARNING: "", log.Ldate|log.Ltime)
  
  
  Warn.Println(""Messages written to a file called 'warnings.log'  
 are likely to be ignored :("")
  
  
  log.Println(""Done!"") 
  
 }
  
 This not only allows us to utilize 
 stdout
  with our 
 log.Println
  function but also 
 store more significant messages in a log file called 
 warnings.log
 . Using the 
 os.O_RDWR|os.O_APPEND
  constants allow us to write to the file and use an append 
 file mode, which is useful for logging.
  
 [
  90 
 ]",NA
Using panics and fatal errors,"In addition to simply storing messages from your applications, you can create 
 application panics and fatal errors that will prevent the application from continuing. 
  
 This is critical for any use case where errors that do not halt execution lead to 
 potential security issues, data loss, or any other unintended consequence. These 
 types of mechanisms are generally relegated to the most critical of errors.
  
 When to use a 
 panic()
  method is not always clear, but in practice this should be 
 relegated to errors that are unrecoverable. An unrecoverable error typically means the 
 one where state becomes ambiguous or cannot otherwise be guaranteed.
  
 For example, operations on acquired database records that fail to return expected 
 results from the database may be considered unrecoverable because future 
 operations might occur on outdated or missing data.
  
 In the following example, we can implement a panic where we can't create a new user; 
 this is important so that we don't attempt to redirect or move forward with any further 
 creation steps:
  
  
  if err != nil {
  
  
  fmt.Fprintln(w, err.Error)
  
  
  RegError.Println(""Could not complete registration:"",  
 err.Error)
  
  
  panic(""Error with registration,"")
  
  
  } else {
  
  
  http.Redirect(w, r, ""/page/""+pageGUID, 301)
  
  
  }
  
 Note that if you want to force this error, you can just make an intentional MySQL 
 error in your query:
  
  res, err := database.Exec(""INSERT INTENTIONAL_ERROR INTO users  
 SET user_name=?, user_guid=?, user_email=?, user_password=?"", 
 name, guid, email, passwordEnc)
  
 When this error is triggered you will find this in your respective log file or 
 stdout
 :
  
  
 In the preceding example, we utilize the panic as a hard stop, one that will prevent 
 further execution that could lead to further errors and/or data inconsistency. If it need 
 not be a hard stop, utilizing the 
 recover()
  function allows you to re-enter application 
 flow once the problem has been addressed or mitigated.
  
 [
  91 
 ]",NA
Introducing testing in Go,"Go comes packaged with a great deal of wonderful tools for making sure your code is 
 clean, well-formatted, free of race conditions, and so on. From 
 go vet
  to 
 go fmt
 , many of 
 the helper applications that you need to install separately in other languages come as a 
 package with Go.
  
 Testing is a critical step for software-development. Unit testing and test-driven 
 development helps find bugs that aren't immediately apparent, especially to the 
 developer. Often we're too close and too familiar with the application to make the 
 types of usability mistakes that can invoke the otherwise undiscovered errors.
  
 Go's testing package allows unit testing of actual functionality as well as making 
 certain that all of the dependencies (network, file system locations) are available; 
 testing in disparate environments allows you to discover these errors before users 
 do.
  
 If you're already utilizing unit tests, Go's implementation will be both familiar and 
 pleasant to get started in:
  
 package example
  
 func Square(x int) int {
  
  y := x * x
  
  return y
  
 }
  
 This is saved as 
 example.go
 . Next, create another Go file that tests this square root 
 functionality, with the following code:
  
 package example
  
 import (
  
  ""testing""
  
 )
  
 func TestSquare(t *testing.T) {
  
  if v := Square(4); v != 16 {
  
  t.Error(""expected"", 16, ""got"", v)
  
  }
  
 }
  
 [
  92 
 ]",NA
Summary,"Simply building an application is not even half the battle and user-testing as a 
 developer introduces a huge gap in testing strategy. Test coverage is a critical 
 weapon when it comes to finding bugs, before they ever manifest to an end user.
  
 Luckily, Go provides all the tools necessary to implement automated unit tests and the 
 logging architecture necessary to support it.
  
 In this chapter, we looked at both loggers and testing options. By producing multiple 
 loggers for different messages, we were able separate warnings from errors brought 
 about by internal application failures.
  
 We then examined unit testing using the test and the 
 httptest
  packages to 
 automatically check our application and keep it current by testing for potential 
 breaking changes.
  
 In 
 Chapter 9
 , 
 Security
 , we'll look at implementing security more thoroughly; from 
 better TLS/SSL, to preventing injection and man-in-the-middle and cross-site request 
 forgery attacks in our application.
  
 [
  96 
 ]",NA
Security,"In the previous chapter we looked at how to store information generated by our 
 application as it works as well as adding unit tests to our suite to ensure that the 
 application behaves as we expect it to and diagnose errors when it does not.
  
 In that chapter, we did not add a lot of functionality to our blog app; so let's get back 
 to that now. We'll also extend some of the logging and testing functionality from this 
 chapter into our new features.
  
 Till now, we have been working on the skeleton of a web application that implements 
 some basic inputs and outputs of blog data and user-submitted comments. Just like any 
 public networked server, ours is subject to a variety of attack vectors.
  
 None of these are unique to Go, but we have an arsenal of tools at our disposal to 
 implement the best practices and extend our server and application to mitigate 
 common issues.
  
 When building a publicly accessible networked application, one quick and easy 
 reference guide for common attack vectors is the 
 Open Web Application Security 
 Project
  (
 OWASP
 ), which provides a periodically updated list of the most critical areas 
 where security issues manifest. OWASP can be found at 
 https://www.owasp.
  
 org/
 . Its Top Ten Project compiles the 10 most common and/or critical network security 
 issues. While it's not a comprehensive list and has a habit of becoming dated between 
 updates, but it still remains a good first start when compiling potential vectors.
  
 A few of the most pervasive vectors of the years have unfortunately stuck around; despite 
 the fact that security experts have been shouting from the rooftops of their severity. Some 
 have seen a rapid decrease in exposure across the Web (like injection), but they still tend 
 to stick around longer, for years and years, even as legacy 
  
 applications phase out.
  
 [
  97 
 ]",NA
HTTPS everywhere – implementing TLS,"In 
 Chapter 5
 , 
 Frontend Integration with RESTful APIs
 , we looked at creating self-signed 
 certificates and utilizing HTTPS/TLS in our app. But let's review quickly why this 
 matters so much in terms of overall security for not just our application but the Web in 
 general.
  
 First, simple HTTP generally produces no encryption for traffic, particularly for vital 
 request header values, such as cookies and query parameters. We say generally here 
 because RFC 2817 does specify a system use TLS over the HTTP protocol, but it's all but 
 unused. Most importantly, it would not give users the type of palpable feedback 
 necessary to register that a site is secure.
  
 Second and similarly, HTTP traffic is subsequently vulnerable to man-in-the-middle 
 attacks.
  
 One other side effect: Google (and perhaps other search engines) begun to favor 
 HTTPS traffic over less secure counterparts.
  
 [
  98 
 ]",NA
Preventing SQL injection,"While injection remains one of the biggest attack vectors across the Web today, most 
 languages have simple and elegant ways of preventing or largely mitigating the odds of 
 leaving vulnerable SQL injections in place with prepared statements and sanitized inputs.
  
 But even with languages that provide these services, there is still an opportunity to 
 leave areas open for exploits.
  
 One of the core tenets of any software development whether on the Web or a server or a 
 standalone executable is to never trust input data acquired from an external (and 
 sometimes internal) source.
  
 [
  100 
 ]",NA
Protecting against XSS,"We've touched briefly upon cross-site scripting and limiting this as a vector makes your 
 application safer for all users, against the actions of a few bad apples. The crux of the 
 issue is the ability for one user to add dangerous content that will be shown to users 
 without scrubbing out the aspects that make it dangerous.
  
 Ultimately you have a choice here—sanitize the data as it comes in or sanitize the 
 data as you present it to other users.
  
 In other words, if someone produces a block of comment text that includes a 
 script
  
 tag, you must take care to stop that from ever being rendered by another user's 
 browser. You can choose to save the raw HTML and then strip all, or only the 
 sensitive tags on the output rendering. Or, you can encode it as it's entered.
  
 There's no right answer; however, you may discover value in following the former 
 approach, where you accept anything and sanitize the output.
  
 There is risk with either, but this approach allows you to keep the original intent of the 
 message should you choose to change your approach down the road. The downside is 
 that of course you can accidentally allow some of this raw data to slip through 
 unsanitized:
  
 template.HTMLEscapeString(string)
  
 template.JSEscapeString(inputData)
  
 [
  102 
 ]",NA
Preventing cross-site request forgery ,NA,NA
(CSRF),"While we won't go very deeply into CSRF in this book, the general gist is that it is a 
 slew of methods that malicious actors can use to fool a user into performing an 
 undesired action on another site.
  
 As it's at least tangentially related to XSS in approach, it's worth talking about now.
  
 [
  104 
 ]",NA
Securing cookies,"One of the attack vectors we looked at earlier was session hijacking, which we 
 discussed in the context of HTTP versus HTTPS and the way others can see the 
 types of information that are critical to identity on a website.
  
 [
  105 
 ]",NA
Using the secure middleware,"One of the more helpful packages for quickly implementing some of the security fixes 
 (and others) mentioned in this chapter is a package from Cory Jacobsen called, helpfully, 
 secure
 .
  
 Secure offers a host of useful utilities, such as SSLRedirects (as we implemented in this 
 chapter), allowed Hosts, HSTS options, and X-Frame-Options shorthand for preventing 
 your site from being loaded into frames.
  
 A good amount of this covers some of the topics that we looked at in this chapter and is 
 largely the best practice. As a piece of middleware, secure can be an easy way to quickly 
 cover some of those best practices in one swoop.
  
  
 To grab 
 secure
 , simply go get it at 
 github.com/unrolled/secure
 .
  
  
 [
  106 
 ]",NA
Summary,"While this chapter is not a comprehensive review of web security issues and solutions, we 
 hoped to address some of the biggest and most common vectors as surfaced by OWASP 
 and others.
  
 Within this chapter we covered or reviewed the best practices to prevent some of 
 these issues from creeping into your applications.
  
 In 
 Chapter 10
 , 
 Caching, Proxies, and Improved Performance
 , we'll look at how to make 
 your application scale with increased traffic while remaining performant and speedy.
  
 [
  107 
 ]",NA
"Caching, Proxies and ",NA,NA
Improved Performance,"We have covered a great deal about the web application that you'll need to connect to 
 data sources, render templates, utilize SSL/TLS, build APIs for single-page 
 applications, and so on.
  
 While the fundamentals are clear, you may find that putting an application built on these 
 guidelines into production would lead to some quick problems, particularly under heavy 
 load.
  
 We've implemented some of the best security practices in the last chapter by 
 addressing some of the most common security issues in web applications. Let's do the 
 same here in this chapter, by applying the best practices against some of the biggest 
 issues of performance and speed.
  
 To do this, we'll look at some of the most common bottlenecks in the pipeline and see 
 how we can reduce these to make our application as performant as possible in 
 production.
  
 Specifically, we'll be identifying those bottlenecks and then looking to reverse 
 proxies and load balancing, implementing caching into our application, utilizing 
 SPDY
 , and look at how to use managed cloud services to augment our speed 
 initiatives by reducing the number of requests that get to our application.
  
 By this chapter's end, we hope to produce tools that can help any Go application 
 squeeze every bit of performance out of our environment.
  
 In this chapter, we will cover the following topics:
  
 • 
  
 Identifying bottlenecks
  
 • 
  
 Implementing reverse proxies
  
 [
  109 
 ]",NA
Identifying bottlenecks,"To simplify things a little, there are two types of bottlenecks for your application, 
 those caused by development and programming deficiencies and those inherent to 
 an underlying software or infrastructure limitation.
  
 The answer to the former is simple, identify the poor design and fix it. Putting patches 
 around bad code can hide the security vulnerabilities or delay even bigger 
 performance issues from being discovered in a timely manner.
  
 Sometimes these issues are born from a lack of stress testing; a code that is performant 
 locally is not guaranteed to scale without applying artificial load. A lack of this testing 
 sometimes leads to surprise downtime in production.
  
 However, ignoring bad code as a source of issues, lets take a look at some of the 
 other frequent offenders:
  
 • 
  
 Disk I/O
  
 • 
  
 Database access
  
 • 
  
 High memory/CPU usage
  
 • 
  
 Lack of concurrency support
  
 There are of course hundreds of offenders, such as network issues, garbage collection 
 overhead in some applications, not compressing payloads/headers, non-database 
 deadlocks, and so on.
  
 High memory and CPU usage is most often the result rather than the cause, but a lot of 
 the other causes are specific to certain languages or environments.
  
 For our application, we could have a weak point at the database layer. Since we're doing 
 no caching, every request will hit the database multiple times. ACID-compliant 
 databases (such as MySQL/PostgreSQL) are notorious for failing under loads, which 
 would not be a problem on the same hardware for less strict key/value stores and 
 NoSQL solutions. The cost of database consistency contributes heavily to this and it's 
 one of the trade-offs of choosing a traditional relational database.
  
 [
  110 
 ]",NA
Implementing reverse proxies,"As we know by now, unlike a lot of languages, Go comes with a complete and 
 mature web server platform with 
 net/http
 .
  
 Of late, some other languages have been shipped with small toy servers intended for 
 local development, but they are not intended for production. In fact, many specifically 
 warn against it. Some common ones are WEBrick for Ruby, Python's SimpleHTTPServer, 
 and PHP's -S. Most of these suffer from concurrency issues that prevent them from being 
 viable choices in production.
  
 Go's 
 net/http
  is different; by default, it handles these issues with aplomb out of the 
 box. Obviously, much of this depends on the underlying hardware, but in a pinch you 
 could use it natively with success. Many sites are using 
 net/http
  to serve non-trivial 
 amounts of traffic.
  
 But even strong underlying web servers have some inherent limitations:
  
 • 
  
 They lack failover or distributed options
  
 • 
  
 They have limited caching options upstream
  
 • 
  
 They cannot easily load balance the incoming traffic
  
 • 
  
 They cannot easily concentrate on centralized logging
  
 This is where a reverse proxy comes into play. A reverse proxy accepts all the incoming 
 traffic on behalf of one or more servers and distributes it by applying the preceding (and 
 other) options and benefits. Another example is URL rewriting, which is more applicable 
 for underlying services that may not have built-in routing and URL rewriting.
  
 There are two big advantages of throwing a simple reverse proxy in front of your 
 web server, such as Go; they are caching options and the ability to serve static 
 content without hitting the underlying application.
  
 One of the most popular options for reverse proxying sites is Nginx (pronounced 
 Engine-X). While Nginx is a web server itself, it gained acclaim early on for being 
 lightweight with a focus on concurrency. It quickly became the frontend du jour for front 
 line defense of a web application in front of an otherwise slower or heavier web server, 
 such as Apache. The situation has changed a bit in recent years, as Apache has caught up 
 in terms of concurrency options and utilization of alternative approaches to events and 
 threading. The following is an example of a reverse proxy Nginx configuration:
  
 server {
  
  listen 80;
  
 [
  111 
 ]",NA
Implementing caching strategies,"There are a number of ways to decide when to create and when to expire the cache items, 
 so we'll look at one of the easier and faster methods for doing so. But if you are interested 
 in developing this further, you might consider other caching strategies; some of which can 
 provide efficiencies for resource usage and performance.",NA
Using Least Recently Used,"One common tactic to maintain cache stability within allocated resources (disk 
 space, memory) is the 
 Least Recently Used
  (
 LRU
 ) system for cache expiration. In 
 this model, utilizing information about the last cache access time (creation or 
 update) and the cache management system can remove the oldest entry in the list.
  
 This has a number of benefits for performance. First, if we assume that the most 
 recently created/updated cache entries are for entries that are presently the most 
 popular, we can remove entries that are not being accessed much sooner; in order to 
 free up the resources for the existing and new resources that might be accessed 
 much more frequently.
  
 This is a fair assumption, assuming the allocated resources for caching is not 
 inconsequential. If you have a large volume for file cache or a lot of memory for 
 memcache, the oldest entries, in terms of last access, are quite likely not being 
 utilized with great frequency.
  
 [
  113 
 ]",NA
Caching by file,"Our first approach is probably best described as a classical one for caching, but a 
 method not without issues. We'll utilize the disk to create file-based caches for 
 individual endpoints, both API and Web.
  
 So what are the issues associated with caching in the filesystem? Well, previously in the 
 chapter, we mentioned that disk can introduce its own bottleneck. Here, we're doing a 
 trade-off to protect the access to our database in lieu of potentially running into other 
 issues with disk I/O.
  
 This gets particularly complicated if our cache directory gets very big. At this point we 
 end up introducing more file access issues.
  
 Another downside is that we have to manage our cache; because the filesystem is not 
 ephemeral and our available space is. We'll need to be able to expire cache files by hand. 
 This introduces another round of maintenance and another point of failure.
  
 All that said, it's still a useful exercise and can still be utilized if you're willing to take on 
 some of the potential pitfalls:
  
 package cache
  
 const (
  
  Location ""/var/cache/""
  
 )
  
 type CacheItem struct {
  
  TTL int
  
  Key string
  
 }
  
 func newCache(endpoint string, params ...[]string) {
  
 }
  
 func (c CacheItem) Get() (bool, string) {
  
  return true, """"
  
 [
  114 
 ]",NA
Caching in memory,"Just as file system caching became a lot more palatable because storage prices 
 plummeted, we've seen a similar move in RAM, trailing just behind hard storage. 
  
 The big advantage here is speed, caching in memory can be insanely fast for 
 obvious reasons.
  
 Memcache, and its distributed sibling Memcached, evolved out of a need to create a 
 light and super-fast caching for LiveJournal and a proto-social network from 
 Brad 
 Fitzpatrick
 . If that name feels familiar, it's because Brad now works at Google and is a 
 serious contributor to the Go language itself.
  
 As a drop-in replacement for our file caching system, Memcached will work similarly. 
 The only major change is our key lookups, which will be going against working 
 memory instead of doing file checks.
  
  
 To use memcache with Go language, go to 
 godoc.org/github.com/
  
  
 bradfitz/gomemcache/memcache
  from 
 Brad Fitz
 , and install it 
  
 using 
 go get
  command.",NA
Implementing HTTP/2,"One of the more interesting, perhaps noble, initiatives that Google has invested in within 
 the last five years has been a focus on making the Web faster. Through tools, such as 
 PageSpeed, Google has sought to push the Web as a whole to be faster, leaner, and more 
 user-friendly.
  
 No doubt this initiative is not entirely altruistic. Google has built their business on 
 extensive web search and crawlers are always at the mercy of the speed of the pages they 
 crawl. The faster the web pages, the faster and more comprehensive is the crawling; 
 therefore, less time and less infrastructure resulting in less money required. 
  
 The bottom line here is that a faster web benefits Google, as much as it does people 
 creating and viewing web sites.
  
 But this is mutually beneficial. If web sites are faster to comply with Google's 
 preferences, everyone benefits with a faster Web.
  
 This brings us to HTTP/2, a version of HTTP that replaces 1.1, introduced in 1999 
 and largely the defacto method for most of the Web. HTTP/2 also envelops and 
 implements a lot of SPDY, a makeshift protocol that Google developed and supported 
 through Chrome.
  
 [
  117 
 ]",NA
Summary,"In this chapter, we focused on quick wins for increasing the overall performance for our 
 application, by reducing impact on our underlying application's bottlenecks, namely our 
 database.
  
 We've implemented caching at the file level and described how to translate that into a 
 memory-based caching system. We looked at SPDY and HTTP/2, which has now become 
 a part of the underlying Go 
 net/http
  package by default.
  
 This in no way represents all the optimizations that we may need to produce highly 
 performant code, but hits on some of the most common bottlenecks that can keep 
 applications that work well in development from behaving similarly in production 
 under heavy load.
  
 This is where we end the book; hope you all enjoyed the ride!
  
 [
  118 
 ]",NA
Module 2,"Go Programming Blueprints
  
 Build real-world, production-ready solutions in Go using cutting-edge technology 
  
 and techniques",NA
Chat Application with ,NA,NA
Web Sockets,"Go is great for writing high-performance, concurrent server applications and tools, and 
 the Web is the perfect medium over which to deliver them. It would be difficult these 
 days to find a gadget that is not web-enabled and allows us to build a single application 
 that targets almost all platforms and devices.
  
 Our first project will be a web-based chat application that allows multiple users to have 
 a real-time conversation right in their web browser. Idiomatic Go applications are often 
 composed of many packages, which are organized by having code in different folders, 
 and this is also true of the Go standard library. We will start by building a simple web 
 server using the 
 net/http
  package, which will serve the HTML files. We will then go on 
 to add support for web sockets through which our messages will flow.
  
 In languages such as C#, Java, or Node.js, complex threading code and clever use of 
 locks need to be employed in order to keep all clients in sync. As we will see, Go helps 
 us enormously with its built-in channels and concurrency paradigms.
  
 In this chapter, you will learn how to:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 Use the 
 net/http
  package to serve HTTP requests 
  
 Deliver template-driven content to users' browsers 
  
 Satisfy a Go interface to build our own 
 http.Handler
  types 
  
 Use Go's goroutines to allow an application to perform multiple tasks 
 concurrently 
  
 Use channels to share information between running Go routines 
 Upgrade HTTP requests to use modern features such as web sockets",NA
A simple web server ,"The first thing our chat application needs is a web server that has two main 
 responsibilities: it must serve the HTML and JavaScript chat clients that run in 
 the user's browser and accept web socket connections to allow the clients to 
 communicate.
  
 Create a 
 main.go
  file inside a new folder called 
 chat
  in your 
 GOPATH
  and add the 
 following code:
  
 package main
  
 import (
  
  
  ""log""
  
  
  ""net/http"" 
  
 )
  
 func main() {
  
  
  http.HandleFunc(""/"", func(w http.ResponseWriter, r  
 *http.Request) {
  
  
  w.Write([]byte(`
  
    
  <html>
  
     
  <head>
  
     
  <title>Chat</title>
  
     
  </head>
  
     
  <body>
  
     
  Let's chat!
  
    
  </body>
  
  
  </html>
  
  `))
  
  })
  
 [
  122 
 ]",NA
Templates,"Templates allow us to blend generic text with specific text, for instance, injecting a 
 user's name into a welcome message. For example, consider the following template:
  
 Hello {name}, how are you?
  
 [
  123 
 ]",NA
Doing things once,"We only need to compile the template once, and there are a few different ways to 
 approach this in Go. The most obvious is to have a 
 NewTemplateHandler
  function that 
 creates the type and calls some initialization code to compile the template. If we were 
 sure the function would be called by only one goroutine (probably the main one during 
 the setup in the 
 main
  function), this would be a perfectly acceptable approach. An 
 alternative, which we have employed in the preceding section, is to compile the 
 template once inside the 
 ServeHTTP
  method. The 
 sync.Once
  type guarantees that the 
 function we pass as an argument will only be executed once, regardless of how many 
 goroutines are calling 
 ServeHTTP
 . This is helpful because web servers in Go are 
 automatically concurrent and once our chat application takes the world by storm, we 
 could very well expect to have many concurrent calls to the 
 ServeHTTP
  method.
  
 Compiling the template inside the 
 ServeHTTP
  method also ensures that our code does 
 not waste time doing work before it is definitely needed. This lazy initialization 
 approach doesn't save us much in our present case, but in cases where the setup tasks 
 are time- and resource-intensive and where the functionality is used less frequently, 
 it's easy to see how this approach would come in handy.",NA
Using your own handlers,"To implement our 
 templateHandler
  type, we need to update the 
 main
  body 
 function so that it looks like this:
  
 func main() {
  
  // root
  
 http.Handle(""/"", &templateHandler{filename: ""chat.html""})
  
  // start the web server
  
  if err := http.ListenAndServe("":8080"", nil); err != nil {
  
  log.Fatal(""ListenAndServe:"", err)
  
  }
  
 }
  
 The 
 templateHandler
  structure is a valid 
 http.Handler
  type so we can pass it 
 directly to the 
 http.Handle
  function and ask it to handle requests that match the 
 specified pattern. In the preceding code, we created a new object of the type 
 templateHandler
  specifying the filename as 
 chat.html
  that we then take the 
 address of (using the 
 &
 address of
  operator) and pass it to the 
 http.Handle 
 function. We do not store a reference to our newly created 
 templateHandler 
 type, but that's OK because we don't need to refer to it again.
  
 [
  126 
 ]",NA
Properly building and executing Go programs,"Running Go programs using a 
 go run
  command is great when our code is made up of 
 a single 
 main.go
  file. However, often we might quickly need to add other files. This 
 requires us to properly build the whole package into an executable binary before 
 running it. This is simple enough, and from now on, this is how you will build and run 
 your programs in a terminal:
  
 go build -o {name}
  
 ./{name}
  
 The 
 go build
  command creates the output binary using all the 
 .go
  files in the 
 specified folder, and the 
 -o
  flag indicates the name of the generated binary. You can 
 then just run the program directly by calling it by name.
  
 For example, in the case of our chat application, we could run:
  
 go build -o chat
  
 ./chat
  
 Since we are compiling templates the first time the page is served, we will need to 
 restart your web server program every time anything changes in order to see the 
 changes take effect.",NA
Modeling a chat room and clients on ,NA,NA
the server,"All users (clients) of our chat application will automatically be placed in one big 
 public room where everyone can chat with everyone else. The 
 room
  type will be 
 responsible for managing client connections and routing messages in and out, while 
 the 
 client
  type represents the connection to a single client.
  
  
 Go refers to classes as types and instances of those classes as objects.
  
  
 [
  127 
 ]",NA
Modeling the client ,"Create a new file called 
 client.go
  alongside 
 main.go
  in the 
 chat
  folder and add the 
 following code:
  
 package main 
  
 import (
  
  
  ""github.com/gorilla/websocket"" 
  
 ) 
  
 // client represents a single chatting user.
  
 type client struct {
  
  
  // socket is the web socket for this 
 client.
  
  socket *websocket.Conn
  
  // send is a channel on which messages are 
 sent.
  
  send chan []byte
  
  // room is the room this client is chatting in.
  
  
  room *room 
  
 }
  
 In the preceding code, socket will hold a reference to the web socket that will allow 
 us to communicate with the client, and the 
 send
  field is a buffered channel through 
 which received messages are queued ready to be forwarded to the user's browser 
 (via the socket). The 
 room
  field will keep a reference to the room that the client is 
 chatting in—this is required so that we can forward messages to everyone else in the 
 room.
  
 [
  128 
 ]",NA
Modeling a room ,"We need a way for clients to join and leave rooms in order to ensure that the 
 c.room. 
 forward <- msg
  code in the preceding section actually forwards the message to all the 
 clients. To ensure that we are not trying to access the same data at the same time, a 
 sensible approach is to use two channels: one that will add a client to the room and 
 another that will remove it. Let's update our 
 room.go
  code to look like this:
  
 package main
  
 type room struct {
  
  // forward is a channel that holds incoming 
 messages // that should be forwarded to the other 
 clients.
  
  forward chan []byte
  
  // join is a channel for clients wishing to join the room.
  
  join chan *client
  
  // leave is a channel for clients wishing to leave the 
 room.
  
  leave chan *client
  
  // clients holds all current clients in this room.
  
  
  clients 
 map[*client]bool 
  
 }
  
 [
  130 
 ]",NA
Concurrency programming using idiomatic Go ,"Now we get to use an extremely powerful feature of Go's concurrency offerings—the 
 select
  statement. We can use 
 select
  statements whenever we need to synchronize or 
 modify shared memory, or take different actions depending on the various activities 
 within our channels.
  
 Beneath the 
 room
  structure, add the following 
 run
  method that contains two of 
 these 
 select
  clauses:
  
 func (r *room) run() {
  
  
  for {
  
  
  select {
  
  
  case client := <-r.join:
  
    
  // joining
  
    
  r.clients[client] = true
  
  
  case client := <-r.leave:
  
    
  // leaving
  
    
  delete(r.clients, client)
  
    
  close(client.send)
  
  
  case msg := <-r.forward:
  
    
  // forward message to all clients
  
    
  for client := range r.clients {
  
     
  select {
  
     
  case client.send <- msg:
  
     
  // send the message
  
     
  default:
  
     
  // failed to send
  
     
  delete(r.clients, client)
  
     
  close(client.send)
  
     
  }
  
    
  }
  
  
  }
  
  
  } 
  
 }
  
 [
  131 
 ]",NA
Turning a room into an HTTP handler,"Now we are going to turn our 
 room
  type into an 
 http.Handler
  type like we did with the 
 template handler earlier. As you will recall, to do this, we must simply add a method 
 called 
 ServeHTTP
  with the appropriate signature. Add the following code to the bottom 
 of the 
 room.go
  file:
  
 const (
  
  socketBufferSize  = 1024
  
  messageBufferSize = 256
  
 )
  
 [
  132 
 ]",NA
Use helper functions to remove complexity,"Our room is almost ready to use, although in order for it to be of any use, the 
 channels and map need to be created. As it is, this could be achieved by asking the 
 developer to use the following code to be sure to do this:
  
 r := &room{
  
  forward: make(chan []byte),
  
  join:    make(chan *client),
  
  leave:   make(chan *client),
  
  clients: make(map[*client]bool),
  
 }
  
 Another, slightly more elegant, solution is to instead provide a 
 newRoom
  function that 
 does this for us. This removes the need for others to know about exactly what needs to 
 be done in order for our room to be useful. Underneath the 
 type room struct
  
 definition, add this function:
  
 // newRoom makes a new room that is ready to go.
  
 func newRoom() *room {
  
  return &room{
  
  forward: make(chan []byte),
  
  join:    make(chan *client),
  
  leave:   make(chan *client),
  
  clients: make(map[*client]bool),
  
  }
  
 }
  
 Now the users of our code need only call the 
 newRoom
  function instead of the more 
 verbose six lines of code.
  
 [
  134 
 ]",NA
Creating and using rooms ,"Let's update our 
 main
  function in 
 main.go
  to first create and then run a room for 
 everybody to connect to:
  
 func main() {
  
  
  r := newRoom()
  
  
  http.Handle(""/"", &templateHandler{filename: ""chat.html""})
  
  http.Handle(""/room"", r)
  
  
  // get the room going
  
  
  go r.run()
  
  
  // start the web server
  
  
  if err := http.ListenAndServe("":8080"", nil); err != nil {
  
  log.Fatal(""ListenAndServe:"", err)
  
  
  } 
  
 }
  
 We are running the room in a separate Go routine (notice the 
 go
  keyword again) so 
 that the chatting operations occur in the background, allowing our main thread to run 
 the web server. Our server is now finished and successfully built, but remains useless 
 without clients to interact with.",NA
Building an HTML and JavaScript chat ,NA,NA
client ,"In order for the users of our chat application to interact with the server and therefore 
 other users, we need to write some client-side code that makes use of the web sockets 
 found in modern browsers. We are already delivering HTML content via the template 
 when users hit the root of our application, so we can enhance that.
  
 Update the 
 chat.html
  file in the 
 templates
  folder with the following markup:
  
 <html>
  
  
  <head>
  
  
  <title>Chat</title>
  
  
  <style>
  
    
  input { display: block; }
  
    
  ul    { list-style: none; }
  
  
  </style>
  
  
  </head>
  
  
  <body>
  
  
  <ul id=""messages""></ul>
  
 [
  135 
 ]",NA
Getting more out of templates,"Currently, we are using templates to deliver static HTML, which is nice because it gives 
 us a clean and simple way to separate the client code from the server code. However, 
 templates are actually much more powerful, and we are going to tweak our application 
 to make some more realistic use of them.
  
 [
  137 
 ]",NA
Tracing code to get a look under the ,NA,NA
hood,"The only way we will know that our application is working is by opening two or more 
 browsers and using our UI to send messages. In other words, we are manually testing 
 our code. This is fine for experimental projects such as our chat application or small 
 projects that aren't expected to grow, but if our code is to have a longer life or be 
 worked on by more than one person, manual testing of this kind becomes a liability. We 
 are not going to tackle 
 Test-driven Development
  (
 TDD
 ) for our chat program, but we 
 should explore another useful debugging technique called 
 tracing
 .
  
 Tracing is a practice by which we log or print key steps in the flow of a program to make 
 what is going on under the covers visible. In the previous section, we added a 
 log.Println
  call to output the address that the chat program was binding to. In this 
 section, we are going to formalize this and write our own complete tracing package.
  
 We are going to explore TDD practices when writing our tracing code because it is a 
 perfect example of a package that we are likely to reuse, add to, share, and hopefully, even 
 open source.",NA
Writing a package using TDD,"Packages in Go are organized into folders, with one package per folder. It is a build error 
 to have differing package declarations within the same folder because all sibling files are 
 expected to contribute to a single package. Go has no concept of subpackages, which 
 means nested packages (in nested folders) exist only for aesthetic or informational 
 reasons but do not inherit any functionality or visibility from super packages. In our 
 chat application, all of our files contributed to the 
 main
  package because we wanted to 
 build an executable tool. Our tracing package will never be run directly, so it can and 
 should use a different package name. We will also need to think about the 
 Application 
 Programming Interface
  (
 API
 ) of our package, considering how to model a package so 
 that it remains as extensible and flexible as possible for users. This includes the fields, 
 functions, methods, and types that should be exported (visible to the user) and remain 
 hidden for simplicity's sake.
  
 [
  140 
 ]",NA
Interfaces,"Interfaces in Go are an extremely powerful language feature that allow us to define 
 an API without being strict or specific on the implementation details. Wherever 
 possible, describing the basic building blocks of your packages using interfaces 
 usually ends up paying dividends down the road, and this is where we will start for 
 our tracing package.
  
 Create a new file called 
 tracer.go
  inside the 
 trace
  folder and write the 
 following code:
  
 package trace
  
 // Tracer is the interface that describes an object capable of
  
 // tracing events throughout code.
  
 type Tracer interface {
  
  Trace(...interface{})
  
 }
  
 The first thing to notice is that we have defined our package as 
 trace
 .
  
  
 While it is a good practice to have the folder name match the package 
  
  
 name, Go tools do not enforce it, which means you are free to name 
  
 them differently if it makes sense. Remember, when people import 
  
 your package, they will type the name of the folder, and if suddenly 
  
 a package with a different name is imported, it could get confusing.
  
 [
  141 
 ]",NA
Unit tests,"We promised ourselves we would follow test-driven practices, but interfaces are 
 simply definitions that do not provide any implementation and so cannot be 
 directly tested. But we are about to write a real implementation of a 
 Tracer 
 method, and we will indeed write the tests first.
  
 Create a new file called 
 tracer_test.go
  in the 
 trace
  folder and insert the 
 following scaffold code:
  
 package trace
  
 import (
  
  ""testing""
  
 )
  
 func TestNew(t *testing.T) {
  
  t.Error(""We haven't written our test yet"")
  
 }
  
 Testing was built into the Go tool chain from the very beginning, making writing 
 automatable tests a first-class citizen. The test code lives alongside the production 
 code in files suffixed with 
 _test.go
 . The Go tools will treat any function that starts 
 with 
 Test
  (taking a single 
 *testing.T
  argument) as a unit test, and it will be 
 executed when we run our tests. To run them for this package, navigate to the 
 trace
  
 folder in a terminal and do the following:
  
 go test
  
 You will see that our tests fail because of our call to 
 t.Error
  in the body of our 
 TestNew
  function:
  
 --- FAIL: TestNew (0.00 seconds)
  
 [
  142 
 ]",NA
Red-green testing,"Running 
 go test
  now actually produces an error; it complains that there is no 
 New 
 function. We haven't made a mistake here; we are following a practice known as red-
 green testing. Red-green testing proposes that we first write a unit test, see it fail (or 
 produce an error), write the minimum amount of code possible to make that test pass, 
 and rinse and repeat it again. The key point here being that we want to make sure the 
 code we add is actually doing something as well as ensuring that the test code we write 
 is testing something meaningful.
  
  
 Consider a meaningless test for a minute:
  
  
 if true == true {
  
  t.Error(""True should be true"")
  
 }
  
 It is logically impossible for true to not be true (if true ever equals false, 
  
 it's time to get a new computer), and so our test is pointless. If a test or 
  
 claim cannot fail, there is no value whatsoever to be found in it.
  
 Replacing 
 true
  with a variable that you expect to be set to 
 true
  under 
  
 certain conditions would mean that such a test can indeed fail (like 
  
 when the code being tested is misbehaving)—at this point, you have 
  
 a meaningful test that is worth contributing to the code base.
  
 You can treat the output of 
 go test
  like a to-do list, solving only one problem at a time. 
 Right now, the complaint about the missing 
 New
  function is all we will address. 
  
 In the 
 tracer.go
  file, let's add the minimum amount of code possible to progress 
 with things; add the following snippet underneath the interface type definition:
  
 func New() {}
  
 Running 
 go test
  now shows us that things have indeed progressed, albeit not 
 very far. We now have two errors:
  
 ./tracer_test.go:11: too many arguments in call to New
  
 ./tracer_test.go:11: New(&buf) used as value
  
 The first error tells us that we are passing arguments to our 
 New
  function, but the 
 New 
 function doesn't accept any. The second error says that we are using the return of the 
 New
  
 function as a value, but that the 
 New
  function doesn't return anything. You might have 
 seen this coming, and indeed as you gain more experience writing test-driven code, you 
 will most likely jump over such trivial details. However, to properly illustrate the method, 
 we are going to be pedantic for a while. Let's address the first error by updating our 
 New
  
 function to take in the expected argument:
  
 func New(w io.Writer) {}
  
 [
  144 
 ]",NA
Implementing the interface,"To satisfy this test, we need something that we can properly return from the 
 New 
 method because 
 Tracer
  is only an interface and we have to return something real. 
  
 Let's add an implementation of a tracer to our 
 tracer.go
  file:
  
 type tracer struct {
  
  out io.Writer
  
 }
  
 func (t *tracer) Trace(a ...interface{}) {}
  
 Our implementation is extremely simple; the 
 tracer
  type has an 
 io.Writer
  field 
 called 
 out
  which is where we will write the trace output to. And the 
 Trace
  method 
 exactly matches the method required by the 
 Tracer
  interface, although it doesn't do 
 anything yet.
  
 Now we can finally fix the 
 New
  method:
  
 func New(w io.Writer) Tracer {
  
  return &tracer{out: w}
  
 }
  
 Running 
 go test
  again shows us that our expectation was not met because nothing was 
 written during our call to 
 Trace
 :
  
 tracer_test.go:18: Trace should not write ''.
  
 Let's update our 
 Trace
  method to write the blended arguments to the specified 
 io.Writer
  field:
  
 func (t *tracer) Trace(a ...interface{}) {
  
  t.out.Write([]byte(fmt.Sprint(a...)))
  
  t.out.Write([]byte(""\n""))
  
 }
  
 When the 
 Trace
  method is called, we call 
 Write
  on the 
 io.Writer
  stored in the 
 out
  
 field and use 
 fmt.Sprint
  to format the 
 a
  arguments. We convert the string return 
 type from 
 fmt.Sprint
  to 
 string
  and then to 
 []byte
  because that is what is expected 
 by the 
 io.Writer
  interface.
  
 Have we finally satisfied our test?
  
 go test -cover
  
 PASS
  
 [
  146 
 ]",NA
Unexported types being returned to users,"The 
 tracer
  struct type we wrote is unexported because it begins with a lowercase 
 t
 , so 
 how is it that we are able to return it from the exported 
 New
  function? After all, doesn't 
 the user receive the returned object? This is perfectly acceptable and valid Go code; the 
 user will only ever see an object that satisfies the 
 Tracer
  interface and will never even 
 know about our private 
 tracer
  type. Since they only ever interact with the interface 
 anyway, it wouldn't matter if our 
 tracer
  implementation exposed other methods or 
 fields; they would never be seen. This allows us to keep the public API of our package 
 clean and simple.
  
 This hidden implementation technique is used throughout the Go standard library, for 
 example, the 
 ioutil.NopCloser
  method is a function that turns a normal 
 io.Reader
  
 into 
 io.ReadCloser
  whereas the 
 Close
  method does nothing (used for when 
 io.Reader
  objects that don't need to be closed are passed into functions that require 
 io.ReadCloser
  types). The method returns 
 io.ReadCloser
  as far as the user is 
 concerned, but under the hood, there is a secret 
 nopCloser
  type hiding the 
 implementation details.
  
  
 To see this for yourself, browse the Go standard library source code 
  
  
 at 
 http://golang.org/src/pkg/io/ioutil/ioutil.go
  and 
  
 search for the 
 nopCloser
  struct.",NA
Using our new trace package,"Now that we have completed the first version of our 
 trace
  package, we can use it in 
 our chat application in order to better understand what is going on when users send 
 messages through the user interface.
  
 In 
 room.go
 , let's import our new package and make some calls to the 
 Trace 
  
 method. The path to the 
 trace
  package we just wrote will depend on your 
 GOPATH 
 environment variable because the import path is relative to the 
 $GOPATH/src
  folder. 
  
 So if you create your 
 trace
  package in 
 $GOPATH/src/mycode/trace
 , then you 
 would need to import 
 mycode/trace
 .
  
 [
  147 
 ]",NA
Making tracing optional,"Once the application is released, the sort of tracing information we are generating will be 
 pretty useless if it's just printed out to some terminal somewhere, or even worse, if it 
 creates a lot of noise for our systems administrators. Also, remember that when we don't 
 set a tracer for our 
 room
  type, our code panics, which isn't a very user-friendly situation. 
 To resolve these two issues, we are going to enhance our 
 trace
  package with a 
 trace.Off()
  method that will return an object that satisfies the 
 Tracer
  interface but 
 will not do anything when the 
 Trace
  method is called.
  
 [
  149 
 ]",NA
Clean package APIs,"A quick glance at the API (in this context, the exposed variables, methods, and types) for 
 our 
 trace
  package highlights that a simple and obvious design has emerged:
  
 • 
  
 The 
 New()
  method
  
 • 
  
 The 
 Off()
  method
  
 • 
  
 The 
 Tracer
  interface
  
 I would be very confident to give this package to a Go programmer without any 
 documentation or guidelines, and I'm pretty sure they would know what do to with it.
  
  
 In Go, adding documentation is as simple as adding comments to the 
  
  
 line before each item. The blog post on the subject is a worthwhile read 
  
 (
 http://blog.golang.org/godoc-documenting-go-code
 ), 
  
 where you can see a copy of the hosted source code for 
 tracer.go
  that 
  
 is an example of how you might annotate the 
 trace
  package. For more 
  
 information, refer to 
 github.com/matryer/goblueprints/blob/
  
 master/chapter1/trace/tracer.go
 .",NA
Summary,"In this chapter, we developed a complete concurrent chat application and our own 
 simple package to trace the flow of our programs to help us better understand what is 
 going on under the hood.
  
 We used the 
 net/http
  package to quickly build what turned out to be a very powerful 
 concurrent HTTP web server. In one particular case, we then upgraded the connection to 
 open a web socket between the client and server. This means that we can easily and 
 quickly communicate messages to the user's web browser without having to write messy 
 polling code. We explored how templates are useful to separate the code from the content 
 as well as to allow us to inject data into our template source, which let us make the host 
 address configurable. Command-line flags helped us give simple configuration control to 
 the people hosting our application while also letting us specify sensible defaults.
  
 Our chat application made use of Go's powerful concurrency capabilities that allowed us 
 to write clear 
 threaded
  code in just a few lines of idiomatic Go. By controlling the coming 
 and going of clients through channels, we were able to set synchronization points in our 
 code that prevented us from corrupting memory by attempting to modify the same 
 objects at the same time.
  
 [
  151 
 ]",NA
Adding Authentication,"The chat application we built in the previous chapter focused on high-performance 
 transmission of messages from the clients to the server and back again, but our users 
 have no way of knowing who they are talking to. One solution to this problem is building 
 of some kind of signup and login functionality and letting our users create accounts and 
 authenticate themselves before they can open the chat page.
  
 Whenever we are about to build something from scratch, we must ask ourselves how 
 others have solved this problem before (it is extremely rare to encounter genuinely 
 original problems), and whether any open solutions or standards already exist that we 
 can make use of. Authorization and authentication are hardly new problems, especially in 
 the world of the Web, with many different protocols out there to choose from. So how do 
 we decide on the best option to pursue? As always, we must look at this question from the 
 point of view of the user.
  
 A lot of websites these days allow you to sign in using your accounts existing 
 elsewhere on a variety of social media or community websites. This saves users the 
 tedious job of entering all their account information over and over again as they 
 decide to try out different products and services. It also has a positive effect on the 
 conversion rates for new sites.
  
 In this chapter, we will enhance our chat codebase to add authentication, which will 
 allow our users to sign in using Google, Facebook, or GitHub and you'll see how easy it 
 is to add other sign-in portals too. In order to join the chat, users must first sign in. 
 Following this, we will use the authorized data to augment our user experience so 
 everyone knows who is in the room, and who said what.
  
 In this chapter, you will learn to:
  
 • 
  
 • 
  
 Use the decorator pattern to wrap 
 http.Handler
  types to add additional 
 functionality to handlers
  
 Serve HTTP endpoints with dynamic paths",NA
Handlers all the way down,"For our chat application, we implemented our own 
 http.Handler
  type in order to 
 easily compile, execute, and deliver HTML content to browsers. Since this is a very 
 simple but powerful interface, we are going to continue to use it wherever possible 
 when adding functionality to our HTTP processing.
  
 In order to determine whether a user is authenticated, we will create an 
 authentication wrapper handler that performs the check, and passes execution on 
 to the inner handler only if the user is authenticated.
  
 Our wrapper handler will satisfy the same 
 http.Handler
  interface as the object 
 inside it, allowing us to wrap any valid handler. In fact, even the authentication 
 handler we are about to write could be later encapsulated inside a similar wrapper 
 if needed.
  
  
 Diagram of a chaining pattern when applied to HTTP handlers
  
 [
  154 
 ]",NA
Making a pretty social sign-in page,"So far we haven't paid much attention to making our application look nice, after all this 
 book is about Go and not user-interface development. However, there is no excuse for 
 building ugly apps, and so we will build a social sign-in page that is as pretty as it is 
 functional.
  
 [
  156 
 ]",NA
Endpoints with dynamic paths,"Pattern matching for the 
 http
  package in the Go standard library isn't the most 
 comprehensive and fully featured implementation out there. For example, Ruby on 
 Rails makes it much easier to have dynamic segments inside the path:
  
 ""auth/:action/:provider_name""
  
 This then provides a data map (or dictionary) containing the values that the framework 
 automatically extracted from the matched path. So if you visit 
 auth/login/google
 , then 
 params[:provider_name]
  would equal 
 google
 , and 
 params[:action]
  would equal 
 login
 .
  
 The most the 
 http
  package lets us specify by default is a path prefix, which we can 
 do by leaving a trailing slash at the end of the pattern:
  
 ""auth/""
  
 We would then have to manually parse the remaining segments to extract the 
 appropriate data. This is acceptable for relatively simple cases, which suits our needs 
 for the time being since we only need to handle a few different paths such as:
  
 • 
  
 /auth/login/google
  
  
 • 
  
 /auth/login/facebook
  
 • 
  
 /auth/callback/google
  
 • 
  
 /auth/callback/facebook
  
  
 If you need to handle more advanced routing situations, you might want 
 to consider using dedicated packages such as Goweb, Pat, Routes, or 
 mux. For extremely simple cases such as ours, the built-in capabilities 
 will do.
  
 We are going to create a new handler that powers our login process. In 
 auth.go
 , add 
 the following 
 loginHandler
  code:
  
 // loginHandler handles the third-party login process.
  
 // format: /auth/{action}/{provider}
  
 func loginHandler(w http.ResponseWriter, r *http.Request) {
  
  segs := strings.Split(r.URL.Path, ""/"")
  
  action := segs[2]
  
  provider := segs[3]
  
  switch action {
  
  case ""login"":
  
  log.Println(""TODO handle login for"", provider)
  
 [
  159 
 ]",NA
OAuth2,"OAuth2 is an open authentication and authorization standard designed to allow resource 
 owners to give clients delegated access to private data (such as wall posts or tweets) via 
 an access token exchange handshake. Even if you do not wish to access the private data, 
 OAuth2 is a great option that allows people to sign in using their existing credentials, 
 without exposing those credentials to a third-party site. In this case, we are the third 
 party and we want to allow our users to sign in using services that support OAuth2.
  
 From a user's point of view, the OAuth2 flow is:
  
 1. A user selects provider with whom they wish to sign in to the client app.
  
 2. The user is redirected to the provider's website (with a URL that includes the 
  
 client app ID) where they are asked to give permission to the client app.
  
 3. The user signs in from the OAuth2 service provider and accepts the 
  
 permissions requested by the third-party application.
  
 4. The user is redirected back to the client app with a request code.
  
 5. In the background, the client app sends the grant code to the provider, 
  
 who sends back an auth token.
  
 6. The client app uses the access token to make authorized requests to the 
  
 provider, such as to get user information or wall posts.
  
 To avoid reinventing the wheel, we will look at a few open source projects that 
 have already solved this problem for us.",NA
Open source OAuth2 packages,"Andrew Gerrand has been working on the core Go team since February 2010, that 
 is two years before Go 1.0 was officially released. His 
 goauth2
  package (see 
 https://code.google.com/p/goauth2/
 ) is an elegant implementation of the 
 OAuth2 protocol written entirely in Go.
  
 Andrew's project inspired Gomniauth (see 
 https://github.com/stretchr/ 
 gomniauth
 ). An open source Go alternative to Ruby's 
 omniauth
  project, Gomniauth 
 provides a unified solution to access different OAuth2 services. In the future, when 
 OAuth3 (or whatever next-generation authentication protocol it is) comes out, in theory, 
 Gomniauth could take on the pain of implementing the details, leaving the user code 
 untouched.
  
 [
  161 
 ]",NA
Tell the authentication providers about ,NA,NA
your app,"Before we ask an authentication provider to help our users sign in, we must tell them 
 about our application. Most providers have some kind of web tool or console where you 
 can create applications to kick-start the process. Here's one from Google:
  
  
 In order to identify the client application, we need to create a client ID and secret. 
 Despite the fact that OAuth2 is an open standard, each provider has their own 
 language and mechanism to set things up, so you will most likely have to play around 
 with the user interface or the documentation to figure it out in each case.
  
 [
  162 
 ]",NA
Implementing external logging in,"In order to make use of the projects, clients, or accounts that we created on the 
 authentication provider sites, we have to tell Gomniauth which providers we want to 
 use, and how we will interact with them. We do this by calling the 
 WithProviders 
 function on the primary Gomniauth package. Add the following code snippet to 
 main.
  
 go
  (just underneath the 
 flag.Parse()
  line towards the top of the 
 main
  function):
  
 // set up gomniauth
  
 gomniauth.SetSecurityKey(""some long key"")
  
 gomniauth.WithProviders(
  
  facebook.New(""key"", ""secret"",
  
  ""http://localhost:8080/auth/callback/facebook""),
  
  github.New(""key"", ""secret"",
  
  ""http://localhost:8080/auth/callback/github""),
  
  google.New(""key"", ""secret"",
  
  ""http://localhost:8080/auth/callback/google""),
  
 )
  
 [
  163 
 ]",NA
Logging in ,"Now that we have configured Gomniauth, we need to redirect users to the provider's 
 authentication page when they land on our 
 /auth/login/{provider}
  path. We just 
 have to update our 
 loginHandler
  function in 
 auth.go
 :
  
 func loginHandler(w http.ResponseWriter, r *http.Request) {
  
  
  segs := strings.Split(r.URL.Path, ""/"")
  
  
  action := segs[2]
  
  
  provider := segs[3]
  
  
  switch action {
  
  
  case ""login"":
  
  
  provider, err := gomniauth.Provider(provider)
  
  
  if err != nil {
  
    
  log.Fatalln(""Error when trying to get provider"", provider,  
 ""-"", err)
  
  
  }
  
  
  loginUrl, err := provider.GetBeginAuthURL(nil, nil)
  
  
  if err != nil {
  
 [
  164 
 ]",NA
Handling the response from the provider,"Once the user clicks on 
 Accept
  on the provider's website (or if they click on the 
 equivalent of 
 Cancel
 ), they will be redirected back to the callback endpoint in our 
 application.
  
 A quick glance at the complete URL that comes back shows us the grant code that the 
 provider has given us.
  
 http://localhost:8080/auth/callback/google?
 code=4/Q92xJ- 
 BQfoX6PHhzkjhgtyfLc0Ylm.QqV4u9AbA9sYguyfbjFEsNoJKMOjQI
  
 [
  166 
 ]",NA
Presenting the user data ,"Having the user data inside a cookie is a good start, but nontechnical people will 
 never even know it's there, so we must bring the data to the fore. We will do this by 
 enhancing our 
 templateHandler
  method that first passes the user data into the 
 template's 
 Execute
  method; this allows us to use template annotations in our HTML 
 to display the user data to the users.
  
 Update the 
 ServeHTTP
  method of our 
 templateHandler
  in 
 main.go
 :
  
 func (t *templateHandler) ServeHTTP(w http.ResponseWriter, r 
 *http.Request) {
  
  
  t.once.Do(func() {
  
   
  t.templ =  
  
 template.Must(template.ParseFiles(filepath.Join(""templates"", 
 t.filename)))
  
  
  }) 
  
   
 data := map[string]interface{}{
  
   
  ""Host"": r.Host,
  
  
  }
  
  
  if authCookie, err := r.Cookie(""auth""); err == nil {
  
   
  data[""UserData""] = objx.MustFromBase64(authCookie.Value)
  
  }
  
  
  t.templ.Execute(w, 
 data) 
  
 }
  
 Instead of just passing the entire 
 http.Request
  object to our template as data, we are 
 creating a new 
 map[string]interface{}
  definition for a data object that potentially 
 has two fields: 
 Host
  and 
 UserData
  (the latter will only appear if an 
 auth 
 cookie is 
 present). By specifying the map type followed by curly braces, we are able to add the 
 Host
  entry at the same time as making our map. We then pass this new 
 data
  object as 
 the second argument to the 
 Execute
  method on our template.
  
 Now we add an HTML file to our template source to display the name. Update the 
 chatbox
  form in 
 chat.html
 :
  
 <form id=""chatbox""> 
  
   
 {{.UserData.name}}:<br/>
  
  
  <textarea></textarea>
  
  
  <input type=""submit"" value=""Send"" 
 /> 
  
 </form>
  
 [
  169 
 ]",NA
Augmenting messages with additional data,"So far, our chat application has only transmitted messages as slices of bytes or 
 [] 
 byte
  types between the client and the server; therefore, our forward channel for our 
 room has the 
 chan []byte
  type. In order to send data (such as who sent it and when) 
 in addition to the message itself, we enhance our forward channel and also how we 
 interact with the web socket on both ends.
  
 Define a new type that will replace the 
 []byte
  slice by creating a new file called 
 message.go
  in the 
 chat
  folder:
  
 package main
  
 import (
  
  ""time""
  
 )
  
 // message represents a single message
  
 type message struct {
  
  Name    string
  
  Message string
  
  When    time.Time
  
 }
  
 The 
 message
  type will encapsulate the message string itself, but we have also added the 
 Name
  and 
 When
  fields that respectively hold the user's name and a timestamp of when 
 the message was sent.
  
 [
  170 
 ]",NA
Summary,"In this chapter, we added a useful and necessary feature to our chat application by 
 asking users to authenticate themselves using OAuth2 service providers, before 
 allowing them to join the conversation. We made use of several open source packages 
 such as 
 Objx
  and 
 Gomniauth
 , which dramatically reduced the amount of multi-server 
 complexity we would otherwise need to deal with.
  
 We implemented a pattern when we wrapped 
 http.Handler
  types to allow us to 
 easily specify which paths require the user to be authenticated, and which were 
 available even without an 
 auth
  cookie. Our 
 MustAuth
  helper function allowed us to 
 generate the wrapper types in a fluent and simple way, without adding clutter and 
 confusion to our code.
  
 [
  174 
 ]",NA
Three Ways to Implement ,NA,NA
Profile Pictures,"So far, our chat application has made use of the OAuth2 protocol to allow users to 
 sign in to our application so that we know who is saying what. In this chapter, we are 
 going to add profile pictures to make the chatting experience more engaging.
  
 We will look at the following ways to add pictures or avatars alongside the messages in 
 our application:
  
 • 
  
 • 
  
 • 
  
 Using the avatar picture provided by the authentication server 
  
 Using the 
 Gravatar.com
  web service to look up a picture by the user's e-
 mail address 
  
 Allowing the user to upload their own picture and host it themselves
  
 The first two options allow us to delegate the hosting of pictures to a third party—
 either an authentication service or 
 Gravatar.com
 —which is great 
  
 because it reduces the cost of hosting our application (in terms of storage costs and 
 bandwidth, since the user's browsers will actually download the pictures from the 
 servers of the authenticating service, not ours). The third option requires us to host 
 pictures ourselves at a location that is web accessible.
  
 These options aren't mutually exclusive; you will most likely use some combination of 
 them in a real-world production application. Towards the end of the chapter, we will see 
 how the flexible design that emerges allows us to try each implementation in turn, until 
 we find an appropriate avatar.",NA
Avatars from the authentication server,"It turns out that most authentication servers already have images for their users, and 
 they make them available through the protected user resource that we already know 
 how to access in order to get our users' names. To use this avatar picture, we need to 
 get the URL from the provider, store it in the cookie for our user, and send it through a 
 web socket so that every client can render the picture alongside the corresponding 
 message.",NA
Getting the avatar URL,"The schema for user or profile resources is not part of the OAuth2 spec, which means that 
 each provider is responsible for deciding how to represent that data. Indeed, providers do 
 things differently, for example, the avatar URL in a GitHub user resource is stored in a 
 field called 
 avatar_url
 , whereas in Google, the same field is called 
 picture
 . Facebook 
 goes even further by nesting the avatar URL value in a 
 url
  field inside an object called 
 picture
 . Luckily, Gomniauth abstracts this for us; its 
 GetUser
  call on a provider 
 standardizes the interface to get common fields.
  
 [
  178 
 ]",NA
Transmitting the avatar URL ,"We need to update our 
 message
  type so that it can also carry with it the avatar URL. 
  
 In 
 message.go
 , add the 
 AvatarURL
  string field:
  
 type message struct {
  
  
  Name      string
  
  
  Message   string
  
  
  When      time.Time 
  
   
 AvatarURL string 
  
 }
  
 So far, we have not actually assigned a value to 
 AvatarURL
  like we do for the 
 Name 
 field, so we must update our 
 read
  method in 
 client.go
 :
  
 func (c *client) read() {
  
  
  for {
  
  
  var msg *message
  
  
  if err := c.socket.ReadJSON(&msg); err == nil {
   
  
  msg.When = time.Now()
  
    
  msg.Name = c.userData[""name""].(string) 
  
     
 if avatarUrl, ok := c.userData[""avatar_url""]; ok { 
   
  
  
 msg.AvatarURL = avatarUrl.(string) 
  
     
 }
  
    
  c.room.forward <- msg
  
  
  } else {
  
 [
  179 
 ]",NA
Adding the avatar to the user interface,"Now that our JavaScript client gets an avatar URL value via the socket, we can use it to 
 display the image alongside the messages. We do this by updating the 
 socket.
  
 onmessage
  code in 
 chat.html
 :
  
 socket.onmessage = function(e) {
  
  var msg = eval(""(""+e.data+"")"");
  
  messages.append(
  
  $(""<li>"").append(
  
 $(""<img>"").css({
  
 width:50,
  
 verticalAlign:""middle""
  
 }).attr(""src"", msg.AvatarURL),
  
  $(""<strong>"").text(msg.Name + "": ""),
  
  $(""<span>"").text(msg.Message)
  
  )
  
  );
  
 }
  
 When we receive a message, we will insert an 
 img
  tag with the source set to the 
 AvatarURL
  field from the message. We will use jQuery's 
 css
  method to force a 
 width of 
 50
  pixels. This protects us from massive pictures spoiling our interface 
 and allows us to align the image to the middle of the surrounding text.
  
 If we build and run our application having logged in with a previous version, you will 
 find that the 
 auth
  cookie that doesn't contain the avatar URL is still there. 
  
 We are not asked to sign in again (since we are already logged in), and the code that 
 adds the 
 avatar_url
  field never gets a chance to run. We could delete our cookie 
 and refresh the page, but we would have to keep doing so whenever we make 
 changes during development. Let's solve this problem properly by adding a logout 
 feature.
  
 [
  180 
 ]",NA
Logging out ,"The simplest way to log a user out is to get rid of the 
 auth
  cookie and redirect the user 
 to the chat page, which will in turn cause a redirect to the login page since we just 
 removed the cookie. We do this by adding a new 
 HandleFunc
  call to 
 main.go
 :
  
 http.HandleFunc(""/logout"", func(w http.ResponseWriter, r 
 *http.Request) {
  
  
  http.SetCookie(w, &http.Cookie{
  
  
  Name:   ""auth"",
  
  
  Value:  """",
  
  
  Path:   ""/"",
  
  
  MaxAge: -1,
  
  
  })
  
  
  w.Header()[""Location""] = []string{""/chat""}
  
  
  w.WriteHeader(http.StatusTemporaryRedirect) 
  
 })
  
 The preceding handler function uses 
 http.SetCookie
  to update the cookie setting 
 MaxAge
  to 
 -1
 , which indicates that it should be deleted immediately by the browser. Not 
 all browsers are forced to delete the cookie, which is why we also provide a new 
 Value
  
 setting of an empty string, thus removing the user data that would previously have been 
 stored.
  
  
 As an additional assignment, you can bulletproof your app a little by 
  
  
 updating the first line in 
 ServeHTTP
  for your 
 authHandler
  in 
 auth.
  
 go
  to make it cope with the empty-value case as well as the missing-
  
 cookie case:
  
 if cookie, err := r.Cookie(""auth""); err == 
  
 http.ErrNoCookie || cookie.Value == """"
  
 Instead of ignoring the return of 
 r.Cookie
 , we keep a reference to the 
  
 returned cookie (if there was actually one) and also add an additional 
  
 check to see whether the 
 Value
  string of the cookie is empty or not.
  
 Before we continue, let's add a 
 Sign Out
  link to make it even easier to get rid of the 
 cookie, and also to allow our users to log out. In 
 chat.html
 , update the 
 chatbox 
 form 
 to insert a simple HTML link to the new 
 /logout
  handler:
  
 <form id=""chatbox"">
  
  
  {{.UserData.name}}:<br/>
  
  
  <textarea></textarea>
  
  
  <input type=""submit"" value=""Send"" 
 /> 
  
   
 or <a href=""/logout"">sign out</a> 
  
 </form>
  
 [
  181 
 ]",NA
Making things prettier,"Our application is starting to look a little ugly, and it's time to do something about it. In 
 the previous chapter, we implemented the Bootstrap library into our login page, and we 
 are now going to extend its use to our chat page. We will make three changes in 
 chat.html
 : include Bootstrap and tweak the CSS styles for our page, change the 
 markup for our form, and tweak how we render messages on the page.
  
 First, let's update the 
 style
  tag at the top of the page and insert a 
 link
  tag above it to 
 include Bootstrap:
  
 <link rel=""stylesheet"" 
  
 href=""//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min. 
  
 css"">
  
 <style>
  
  ul#messages        { list-style: none; }
  
  ul#messages li     { margin-bottom: 2px; }
  
 [
  182 
 ]",NA
Implementing Gravatar,"Gravatar is a web service that allows users to upload a single profile 
  
 picture and associate it with their e-mail address to make it available from any 
 website. Developers, like us, can access those images for our application, just by 
 performing a 
 GET
  operation on a specific API endpoint. In this section, we will see 
 how to implement Gravatar rather than use the picture provided by the 
 authentication service.
  
 [
  184 
 ]",NA
Abstracting the avatar URL process ,"Since we have three different ways of obtaining the avatar URL in our application, we 
 have reached the point where it would be sensible to learn how to abstract the 
 functionality in order to cleanly implement the options. Abstraction refers to a process in 
 which we separate the idea of something from its specific implementation. 
  
 http.Handler
  is a great example of how a handler will be used along with its ins 
 and outs, without being specific about what action is taken by each handler.
  
 In Go, we start to describe our idea of getting an avatar URL by defining an interface. Let's 
 create a new file called 
 avatar.go
  and insert the following code:
  
 package main 
  
 import (
  
  
  ""errors"" 
  
 ) 
  
 // ErrNoAvatar is the error that is returned when the 
 // Avatar instance is unable to provide an avatar 
 URL.
  
 var ErrNoAvatarURL = errors.New(""chat: Unable to get an avatar 
 URL."") 
  
 // Avatar represents types capable of representing 
  
 // user profile pictures.
  
 type Avatar interface {
  
  // GetAvatarURL gets the avatar URL for the specified client, 
 // or returns an error if something goes wrong.
  
  // ErrNoAvatarURL is returned if the object is unable to 
 get // a URL for the specified client.
  
  
  GetAvatarURL(c *client) (string, error) 
  
 }
  
 The 
 Avatar
  interface describes the 
 GetAvatarURL
  method that a type must satisfy in 
 order to be able to get avatar URLs. We took the client as an argument so that we know 
 for which user to return the URL. The method returns two arguments: a string (which will 
 be the URL if things go well) and an error in case something goes wrong.
  
 One of the things that could go wrong is simply that one of the specific 
  
 implementations of 
 Avatar
  is unable to get the URL. In that case, 
 GetAvatarURL 
 will 
 return the 
 ErrNoAvatarURL
  error as the second argument. The 
 ErrNoAvatarURL 
 error 
 therefore becomes a part of the interface; it's one of the possible returns from the 
 method and something that users of our code should probably explicitly handle. We 
 mention this in the comments part of the code for the method, which is the only way to 
 communicate such design decisions in Go.
  
 [
  185 
 ]",NA
The authentication service and avatar's ,NA,NA
implementation ,"The first implementation of 
 Avatar
  we write will replace the existing functionality 
 where we hardcoded the avatar URL obtained from the authentication service. Let's use 
 a 
 Test-driven Development
  (
 TDD
 ) approach so we can be sure our code works 
 without having to manually test it. Let's create a new file called 
 avatar_test.go
  in the 
 chat
  folder:
  
 package main 
  
 import ""testing"" 
  
 func TestAuthAvatar(t *testing.T) {
  
  
  var authAvatar AuthAvatar
  
  
  client := new(client)
  
  
  url, err := authAvatar.GetAvatarURL(client)
  
  
  if err != ErrNoAvatarURL {
  
  
  t.Error(""AuthAvatar.GetAvatarURL should return ErrNoAvatarURL  
 when no value present"")
  
  
  }
  
  
  // set a value
  
  
  testUrl := ""http://url-to-gravatar/""
  
  
  client.userData = map[string]interface{}{""avatar_url"": testUrl}
  
  url, err = authAvatar.GetAvatarURL(client)
  
  
  if err != nil {
  
  
  t.Error(""AuthAvatar.GetAvatarURL should return no error when  
 value present"")
  
  
  } else {
  
  
  if url != testUrl {
  
    
  t.Error(""AuthAvatar.GetAvatarURL should return correct URL"")
  
  }
  
  
  } 
  
 }
  
 [
  186 
 ]",NA
Using an implementation,"When we use an implementation, we could refer to either the helper variables 
  
 directly or create our own instance of the interface whenever we need the functionality. 
  
 However, this would defeat the very object of the abstraction. Instead, we use the 
 Avatar
  interface type to indicate where we need the capability.
  
 For our chat application, we will have a single way to obtain an avatar URL per chat 
 room. So let's update the 
 room
  type so it can hold an 
 Avatar
  object. In 
 room.go
 , add the 
 following field definition to the type 
 room struct
 :
  
 // avatar is how avatar information will be obtained.
  
 avatar Avatar
  
 Update the 
 newRoom
  function so we can pass in an 
 Avatar
  implementation for use; we 
 will just assign this implementation to the new field when we create our 
 room 
 instance:
  
 // newRoom makes a new room that is ready to go.
  
 func newRoom(avatar Avatar) *room {
  
  return &room{
  
  forward: make(chan *message),
  
  join:    make(chan *client),
  
  leave:   make(chan *client),
  
  clients: make(map[*client]bool),
  
  tracer:  trace.Off(),
  
  avatar:  avatar,
  
  }
  
 }
  
 Building the project now will highlight the fact that the call to 
 newRoom
  in 
 main.go
  is 
 broken because we have not provided an 
 Avatar
  argument; let's update it by passing in 
 our handy 
 UseAuthAvatar
  variable as follows:
  
 r := newRoom(UseAuthAvatar)
  
 [
  188 
 ]",NA
Gravatar implementation,"The Gravatar implementation in 
 Avitar
  will do the same job as the 
 AuthAvatar 
 implementation, except it will generate a URL for a profile picture hosted on 
 Gravatar.com
 . Let's start by adding a test to our 
 avatar_test.go
  file:
  
 func TestGravatarAvatar(t *testing.T) {
  
  var gravatarAvitar GravatarAvatar
  
  client := new(client)
  
  
  client.userData = map[string]interface{}{""email"":  
 ""MyEmailAddress@example.com""}
  
  url, err := gravatarAvitar.GetAvatarURL(client)
  
  if err != nil {
  
  t.Error(""GravatarAvitar.GetAvatarURL should not return an  
 error"")
  
  }
  
  
  if url !=  
  
 ""//www.gravatar.com/avatar/0bc83cb571cd1c50ba6f3e8a78ef1346"" 
 {
  
  t.Errorf(""GravatarAvitar.GetAvatarURL wrongly returned %s"",  
 url)
  
  }
  
 }
  
 Gravatar uses a hash of the e-mail address to generate a unique ID for each profile 
 picture, so we set up a client and ensure 
 userData
  contains an e-mail address. Next, we 
 call the same 
 GetAvatarURL
  method, but this time on an object that has the 
 GravatarAvatar
  type. We then assert that a correct URL was returned. We already 
 know this is the appropriate URL for the specified e-mail address because it is listed as 
 an example in the Gravatar documentation—a great strategy to ensure our code is doing 
 what it should be.
  
  
 Recall that all the source code for this book is available on GitHub. 
  
  
 You can save time on building the preceding core by copying and 
  
 pasting bits and pieces from 
 https://github.com/matryer/
  
 goblueprints
 . Hardcoding things such as the base URL is not 
  
 usually a good idea; we have hardcoded throughout the book to 
  
 make the code snippets easier to read and more obvious, but you 
  
 are welcome to extract them as you go along if you like.
  
 [
  190 
 ]",NA
Uploading an avatar picture,"In the third and final approach of uploading a picture, we will look at how to allow 
 users to upload an image from their local hard drive to use as their profile picture 
 when chatting. We will need a way to associate a file with a particular user to ensure 
 that we associate the right picture with the corresponding messages.",NA
User identification,"In order to uniquely identify our users, we are going to copy Gravatar's approach by 
 hashing their e-mail address and using the resulting string as an identifier. We will store 
 the user ID in the cookie along with the rest of the user-specific data. This will actually 
 have the added benefit of removing from 
 GravatarAuth
  the inefficiency associated with 
 continuous hashing.
  
 In 
 auth.go
 , replace the code that creates the 
 authCookieValue
  object with the 
 following code:
  
 m := md5.New()
  
 io.WriteString(m, strings.ToLower(user.Name()))
  
 userId := fmt.Sprintf(""%x"", m.Sum(nil))
  
 // save some data
  
 authCookieValue := objx.New(map[string]interface{}{
  
  ""userid"":     userId,
  
  ""name"":       user.Name(),
  
  ""avatar_url"": user.AvatarURL(),
  
  ""email"":      user.Email(),
  
 }).MustBase64()
  
 Here we have hashed the e-mail address and stored the resulting value in the 
 userid 
 field at the point at which the user logs in. Henceforth, we can use this value in our 
 Gravatar code instead of hashing the e-mail address for every message. To do this, first 
 we update the test by removing the following line from 
 avatar_test.go
 :
  
 client.userData = map[string]interface{}{""email"": 
 ""MyEmailAddress@example.com""}
  
 We then replace the preceding line with this line:
  
 client.userData = map[string]interface{}{""userid"": 
 ""0bc83cb571cd1c50ba6f3e8a78ef1346""}
  
 [
  193 
 ]",NA
An upload form ,"If our users are to upload a file as their avatar, they need a way to browse their 
 local hard drive and submit the file to the server. We facilitate this by adding a new 
 template-driven page. In the 
 chat/templates
  folder, create a file called 
 upload.html
 :
  
 <html>
  
  
  <head>
  
  
  <title>Upload</title>
  
  
  <link rel=""stylesheet""  
  
    
  href=""//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/ 
    
  bootstrap.min.css"">
  
  
  </head>
  
  
  <body>
  
  
  <div class=""container"">
  
    
  <div class=""page-header"">
  
     
  <h1>Upload picture</h1>
  
    
  </div>
  
    
  <form role=""form"" action=""/uploader""  
  
     
  enctype=""multipart/form-data"" method=""post"">
  
     
  <input type=""hidden"" name=""userid""  
  
     
  value=""{{.UserData.userid}}"" />
  
 [
  194 
 ]",NA
Handling the upload,"When the user clicks on 
 Upload
  after selecting a file, the browser will send the data for 
 the file as well as the user ID to 
 /uploader
 , but right now, that data doesn't actually go 
 anywhere. We will implement a new 
 HandlerFunc
  that is capable of receiving the file, 
 reading the bytes that are streamed through the connection, and saving it as a new file 
 on the server. In the 
 chat
  folder, let's create a new folder called 
 avatars
 —this is where 
 we will save the avatar image files.
  
 Next, create a new file called 
 upload.go
  and insert the following code—make sure to 
 add the appropriate package name and imports (which are 
 ioutils
 , 
 net/http
 , 
 io
 , 
 and 
 path
 ):
  
 func uploaderHandler(w http.ResponseWriter, req *http.Request) {
  
  userId := req.FormValue(""userid"")
  
  file, header, err := req.FormFile(""avatarFile"")
  
  if err != nil {
  
  io.WriteString(w, err.Error())
  
  return
  
  }
  
 [
  195 
 ]",NA
Serving the images,"Now that we have a place to keep our users' avatar images on the server, we need a 
 way to make them accessible to the browser. We do this by using the 
 net/http 
 package's built-in file server. In 
 main.go
 , add the following code:
  
 http.Handle(""/avatars/"",
  
  http.StripPrefix(""/avatars/"",
  
  http.FileServer(http.Dir(""./avatars""))))
  
 [
  197 
 ]",NA
The Avatar implementation for local files,"The final piece to making filesystem avatars work is to write an implementation of 
 our 
 Avatar
  interface that generates URLs that point to the filesystem endpoint we 
 created in the last section.
  
 Let's add a test function to our 
 avatar_test.go
  file:
  
 func TestFileSystemAvatar(t *testing.T) {
  
  // make a test avatar file
  
  filename := path.Join(""avatars"", ""abc.jpg"")
  
  ioutil.WriteFile(filename, []byte{}, 0777)
  
  defer func() { os.Remove(filename) }()
  
  var fileSystemAvatar FileSystemAvatar
  
  client := new(client)
  
  client.userData = map[string]interface{}{""userid"": ""abc""}
  
  url, err := fileSystemAvatar.GetAvatarURL(client)
  
  if err != nil {
  
  t.Error(""FileSystemAvatar.GetAvatarURL should not return an  
 error"")
  
 [
  198 
 ]",NA
Supporting different file types,"To support different file types, we have to make our 
 GetAvatarURL
  method for the 
 FileSystemAvatar
  type a little smarter.
  
 Instead of just blindly building the string, we will use the very useful 
 ioutil. 
 ReadDir
  method to get a listing of the files. The listing also includes directories, so 
 we will use the 
 IsDir
  method to determine whether we should skip it or not.
  
 We will then check to see whether each file starts with the 
 userid
  field (remember that 
 we named our files in this way) by a call to 
 path.Match
 . If the filename matches the 
 userid
  field, then we have found the file for that user and we return the path. If 
 anything goes wrong or if we can't find the file, we return the 
 ErrNoAvatarURL
  error as 
 usual.
  
 Update the appropriate method in 
 avatar.go
  with the following code:
  
 func (_ FileSystemAvatar) GetAvatarURL(c *client) (string, error) {
  
  if userid, ok := c.userData[""userid""]; ok {
  
  if useridStr, ok := userid.(string); ok {
  
  if files, err := ioutil.ReadDir(""avatars""); err == nil {
  
  for _, file := range files {
  
  if file.IsDir() {
  
  continue
  
  }
  
  if match, _ := path.Match(useridStr+""*"", file.Name());  match {
  
  return ""/avatars/"" + file.Name(), nil
  
  }
  
  }
  
  }
  
  }
  
  }
  
  return """", ErrNoAvatarURL
  
 }
  
 [
  200 
 ]",NA
Refactoring and optimizing our code,"When we look back at how our 
 Avatar
  type is used, you will notice that every time 
 someone sends a message, the application makes a call to 
 GetAvatarURL
 . In our latest 
 implementation, each time the method is called, we iterate over all the files in the 
 avatars
  folder. For a particularly chatty user, this could mean that we end up 
 iterating over and over again many times a minute. This is an obvious waste of 
 resources and would, at some point very soon, become a scaling problem.
  
 Instead of getting the avatar URL for every message, we will get it only once when the 
 user first logs in and cache it in the 
 auth
  cookie. Unfortunately, our 
 Avatar
  interface 
 type requires that we pass in a 
 client
  object to the 
 GetAvatarURL
  method and we do 
 not have such an object at the point at which we are authenticating the user.
  
  
 So did we make a mistake when we designed our 
 Avatar
  interface? 
  
  
 While this is a natural conclusion to come to, in fact we did the right 
  
 thing. We designed the solution with the best information we had 
  
 available at the time and therefore had a working chat application 
  
 much sooner than if we'd tried to design for every possible future case. 
  
 Software evolves and almost always changes during the development 
  
 process and will definitely change throughout the lifetime of the code.",NA
Replacing concrete types with interfaces,"We have concluded that our 
 GetAvatarURL
  method depends on a type that is not 
 available to us at the point we need it, so what would be a good alternative? We could 
 pass each required field as a separate argument but this would make our interface 
 brittle, since as soon as an 
 Avatar
  implementation needs a new piece of information, 
 we'd have to change the method signature. Instead, we will create a new type that will 
 encapsulate the information our 
 Avatar
  implementations need while conceptually 
 remaining decoupled from our specific case.
  
 In 
 auth.go
 , add the following code to the top of the page (underneath the 
 package 
 keyword of course):
  
 import gomniauthcommon ""github.com/stretchr/gomniauth/common""
  
 type ChatUser interface {
  
  UniqueID() string
  
  AvatarURL() string
  
 }
  
 [
  201 
 ]",NA
Changing interfaces in a test-driven way,"Before we can use our new type, we must update the 
 Avatar
  interface and 
 appropriate implementations to make use of it. As we will follow TDD practices, we 
 are going to make these changes in our test file, see compiler errors when we try to 
 build our code, and see failing tests once we fix those errors before finally making the 
 tests pass.
  
 Open 
 avatar_test.go
  and replace 
 TestAuthAvatar
  with the following code:
  
 func TestAuthAvatar(t *testing.T) {
  
  var authAvatar AuthAvatar
  
  testUser := &gomniauthtest.TestUser{}
  
  testUser.On(""AvatarURL"").Return("""", ErrNoAvatarURL)
  
 [
  202 
 ]",NA
Fixing existing implementations ,"Changing an interface like the one we have is a good way to automatically find the 
 parts of our code that have been affected because they will cause compiler errors. 
  
 Of course, if we were writing a package that other people would use, we would 
 have to be far stricter towards changing the interfaces.
  
 We are now going to update the three implementation signatures to satisfy the new 
 interface and change the method bodies to make use of the new type. Replace the 
 implementation for 
 FileSystemAvatar
  with the following:
  
 func (_ FileSystemAvatar) GetAvatarURL(u ChatUser) (string, error) {
  
  if files, err := ioutil.ReadDir(""avatars""); err == nil {
  
  
  for _, file := range files {
  
    
  if file.IsDir() {
  
     
  continue
  
    
  }
  
    
  if match, _ := path.Match(u.UniqueID()+""*"", file.Name());  
 match {
  
     
  return ""/avatars/"" + file.Name(), nil
  
    
  }
  
  
  }
  
  
  }
  
  
  return """", ErrNoAvatarURL 
  
 }
  
 The key change here is that we no longer access the 
 userData
  field on the client, and 
 instead just call 
 UniqueID
  directly on the 
 ChatUser
  interface.
  
 Next, we update the 
 AuthAvatar
  implementation with the following code:
  
 func (_ AuthAvatar) GetAvatarURL(u ChatUser) (string, error) 
 {
  
  url := u.AvatarURL()
  
  
  if len(url) > 0 {
  
  
  return url, nil
  
  
  }
  
  
  return """", ErrNoAvatarURL 
  
 }
  
 Our new design is proving to be much simpler; it's always a good thing if we can 
 reduce the amount of code needed. The preceding code makes a call to get the 
 AvatarURL
  value, and provided it isn't empty (or 
 len(url) > 0
 ), we return it; else, 
 we return the 
 ErrNoAvatarURL
  error instead.
  
 [
  205 
 ]",NA
Global variables versus fields,"So far, we have assigned the 
 Avatar
  implementation to the 
 room
  type, which enables us 
 to use different avatars for different rooms. However, this has exposed an issue: when our 
 users sign in, there is no concept of which room they are headed to so we cannot know 
 which 
 Avatar
  implementation to use. Because our application only supports a single 
 room, we are going to look at another approach toward selecting implementations: the 
 use of global variables.
  
 A global variable is simply a variable that is defined outside any type definition and 
 is accessible from every part of the package (and from outside the package if it's 
 exported). For a simple configuration, such as which type of 
 Avatar 
 implementation to use, they are an easy and simple solution. Underneath the 
 import
  statements in 
 main.go
 , add the following line:
  
 // set the active Avatar implementation
  
 var avatars Avatar = UseFileSystemAvatar
  
 This defines 
 avatars
  as a global variable that we can use when we need to get 
 the avatar URL for a particular user.",NA
Implementing our new design,"We need to change the code that calls 
 GetAvatarURL
  for every message to just 
 access the value that we put into the 
 userData
  cache (via the 
 auth
  cookie). 
  
 Change the line where 
 msg.AvatarURL
  is assigned, as follows:
  
 if avatarUrl, ok := c.userData[""avatar_url""]; ok {
  
  msg.AvatarURL = avatarUrl.(string)
  
 }
  
 Find the code inside 
 loginHandler
  in 
 auth.go
  where we call 
 provider.GetUser 
 and replace it down to where we set the 
 authCookieValue
  object with the following 
 code:
  
 user, err := provider.GetUser(creds)
  
 if err != nil {
  
  
  log.Fatalln(""Error when trying to get user from"", provider, ""-"",  
 err)
  
 }
  
 [
  206 
 ]",NA
Tidying up and testing ,"Finally, we get to snip away some of the fat that has accumulated during our 
 refactoring process.
  
 Since we no longer store the 
 Avatar
  implementation in 
 room
 , let's remove the field 
 and all references to it from the type. In 
 room.go
 , delete the 
 avatar Avatar 
 definition from the 
 room
  struct and update the 
 newRoom
  method:
  
 func newRoom() *room {
  
  
  return &room{
  
  
  forward: make(chan *message),
  
  
  join:    make(chan *client),
  
  
  leave:   make(chan *client),
  
  
  clients: make(map[*client]bool),
  
  
  tracer:  trace.Off(),
  
  
  } 
  
 }
  
 [
  207 
 ]",NA
Combining all three implementations ,"To 
 close this chapter off with a bang, we will implement a mechanism in which each 
 Avatar
  implementation takes a turn in trying to get the value. If the first 
 implementation returns the 
 ErrNoAvatarURL
  error, we will try the next and so on 
 until we find a useable value.
  
 In 
 avatar.go
 , underneath the 
 Avatar
  type, add the following type definition:
  
 type TryAvatars []Avatar
  
 The 
 TryAvatars
  type is simply a slice of 
 Avatar
  objects; therefore, we will add the 
 following 
 GetAvatarURL
  method:
  
 func (a TryAvatars) GetAvatarURL(u ChatUser) (string, error) 
 {
  
  for _, avatar := range a {
  
  
  if url, err := avatar.GetAvatarURL(u); err == nil {
  
    
  return url, nil
  
  
  }
  
  
  }
  
  
  return """", ErrNoAvatarURL 
  
 }
  
 [
  208 
 ]",NA
Summary,"In this chapter, we added three different implementations of profile pictures to our chat 
 application. First we asked the authentication service to provide a URL for us to use. We 
 did this by using Gomniauth's abstraction of the user resource data, which we then 
 included as part of the user interface every time a user would send a message. 
  
 Using Go's zero (or default) initialization pattern, we were able to refer to different 
 implementations of our 
 Avatar
  interface without actually creating any instances.
  
 We stored data in a cookie for when the user would log in. Therefore, and also given the 
 fact that cookies persist between builds of our code, we added a handy logout feature to 
 help us validate our changes, which we also exposed to our users so that they could log 
 out too. Other small changes to the code and the inclusion of Bootstrap on our chat page 
 dramatically improved the look and feel of our application.
  
 We used MD5 hashing in Go to implement the 
 Gravatar.com
  API by hashing the e-mail 
 address that the authentication service provided. If the e-mail address is not known to 
 Gravatar, they will deliver a nice default placeholder image for us, which means our user 
 interface will never be broken due to missing images.
  
 We then built and completed an upload form and associated the server functionality that 
 saved uploaded pictures in the 
 avatars
  folder. We saw how to expose the saved 
 uploaded pictures to users via the standard library's 
 http.FileServer
  handler. As this 
 introduced inefficiencies in our design by causing too much filesystem access, we 
 refactored our solution with the help of our unit tests. By moving the 
 GetAvatarURL 
 call to the point at which users log in, rather than every time a message is sent, we made 
 our code significantly more scalable.
  
 Our special 
 ErrNoAvatarURL
  error type was used as part of our interface design to allow 
 us to inform the calling code when it was not possible to obtain an appropriate URL—this 
 became particularly useful when we created our 
 Avatars
  slice type. By implementing the 
 Avatar
  interface on a slice of 
 Avatar
  types, we were able to make a new implementation 
 that took turns trying to get a valid URL from each of the different options available, 
 starting with the filesystem, then the authentication service, and finally Gravatar. We 
 achieved this with zero impact on how the user would interact with the interface. If an 
 implementation returned 
 ErrNoAvatarURL
 , we tried the next one.
  
 Our chat application is ready to go live so we can invite our friends and have a real 
 conversation. But first we need to choose a domain name to host it at, something we 
 will look at in the next chapter.
  
 [
  210 
 ]",NA
Command-line Tools to Find ,NA,NA
Domain Names,"The chat application we built in the previous chapters is ready to take the world by 
 storm, but not before we give it a home on the Internet. Before we invite our friends to 
 join the conversation, we need to pick a valid, catchy, and available domain name that 
 we can point to the server running our Go code. Instead of sitting in front of our favorite 
 domain name provider for hours on end trying different names, we are going to develop 
 a few command-line tools that will help us find the right one. As we do so, we will see 
 how the Go standard library allows us to interface with the terminal and other executing 
 applications, as well as explore some patterns and practices to build command-line 
 programs.
  
 In this chapter, you will learn:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 How to build complete command-line applications with as little as a 
 single code file
  
 How to ensure that the tools we build can be composed with other 
 tools using standard streams
  
 How to interact with a simple third-party JSON RESTful API
  
 How to utilize the standard in and out pipes in Go code
  
 How to read from a streaming source one line at a time
  
 How to build a WHOIS client to look up domain information
  
 How to store and use sensitive or deployment-specific information in 
 environment variables",NA
Pipe design for command-line tools,"We are going to build a series of command-line tools that use the standard streams 
 (
 stdin
  and 
 stdout
 ) to communicate with the user and with other tools. Each tool will 
 take input line by line via the standard in pipe, process it in some way, and then print 
 the output line by line to the standard out pipe for the next tool or for the user.
  
 By default, the standard input is connected to the user's keyboard, and the standard 
 output is printed to the terminal from which the command was run; however, both can be 
 redirected using redirection metacharacters. It's possible to throw the output away by 
 redirecting it to 
 NUL
  on Windows or 
 /dev/null
  on Unix machines, or redirecting it to a 
 file, which will cause the output to be saved to the disk. Alternatively, you can pipe (using 
 the 
 |
  pipe character) the output of one program into the input of another; it is this feature 
 that we will make use of in order to connect our various tools together. 
  
 For example, you could pipe the output from one program to the input of another 
 program in a terminal by using this code:
  
 one | two
  
 Our tools will work with lines of strings where each line (separated by a linefeed 
 character) represents one string. When run without any pipe redirection, we will be able 
 to interact directly with the programs using the default in and out, which will be useful 
 when testing and debugging our code.",NA
Five simple programs,"In this chapter, we will build five small programs that we will combine together at the 
 end. The key features of the programs are as follows:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 Sprinkle
 : This program will add some web-friendly sprinkle words to 
 increase the chances of finding available domain names
  
 Domainify
 : This program will ensure words are acceptable for a domain 
 name by removing unacceptable characters and replacing spaces with 
 hyphens and adding an appropriate top-level domain (such as 
 .com
  and 
 .net
 ) to the end
  
 Coolify
 : This program will make a boring old normal word into Web 2.0 by 
 fiddling around with vowels
  
 Synonyms
 : This program will use a third-party API to find synonyms
  
 Available
 : This program will check to see whether the domain is available or 
 not using an appropriate WHOIS server
  
 Five programs might seem like a lot for one chapter, but don't forget how small 
 entire programs can be in Go.
  
 [
  212 
 ]",NA
Sprinkle ,"Our first program augments incoming words with some sugar terms in order to 
 improve the odds of finding available names. Many companies use this approach to 
 keep the core messaging consistent while being able to afford the 
 .com
  domain. For 
 example, if we pass in the word 
 chat
 , it might pass out 
 chatapp
 ; alternatively, if we 
 pass in 
 talk
 , we may get back 
 talk time
 .
  
 Go's 
 math/rand
  package allows us to break away from the predictability of 
 computers to give a chance or opportunity to get involved in our program's 
 process and make our solution feel a little more intelligent than it actually is.
  
 To make our Sprinkle program work, we will:
  
 • 
  
 Define an array of transformations using a special constant to indicate 
  
 where the original word will appear
  
 • 
  
 Use the 
 bufio
  package to scan input from 
 stdin
  and 
 fmt.Println
  to write 
  
 output to 
 stdout
  
 • 
  
 Use the 
 math/rand
  package to randomly select which transformation to 
  
 apply to the word, such as appending ""app"" or prefixing the term with ""get""
  
  
 example, if your 
 GOPATH
  is 
 ~/Work/projects/go
 , you would create 
  
 your 
 program folders in the 
 ~/Work/projects/go/src
  folder.
  
  
 All of our programs will reside in the 
 $GOPATH/src
  directory. For 
  
 In the 
 $GOPATH/src
  directory, create a new folder called 
 sprinkle
  and add a 
 main. go
  
 file containing the following code:
  
 package main 
  
 import (
  
  
  ""bufio""
  
  
  ""fmt""
  
  
  ""math/rand""
  
  
  ""os""
  
  
  ""strings""
  
  
  ""time"" 
  
 ) 
  
 const otherWord = ""*"" 
  
 var transforms = 
 []string{
  
  
  otherWord,
  
  
  otherWord,
  
  
  otherWord,
  
  
  otherWord,",NA
Exercise – configurable transformations ,"As an extra assignment, rather than hardcoding the 
 transformations
  array as we 
 have done, see if you can externalize it into a text file or database.",NA
Domainify ,"Some of the words that output from Sprinkle contain spaces and perhaps other 
 characters that are not allowed in domains, so we are going to write a program, called 
 Domainify, that converts a line of text into an acceptable domain segment and add an 
 appropriate 
 Top-level Domain
  (
 TLD
 ) to the end. Alongside the 
 sprinkle
  folder, create 
 a new one called 
 domainify
 , and add a 
 main.go
  file with the following code:
  
 package main 
  
 var tlds = []string{""com"", ""net""} 
  
 const allowedChars = ""abcdefghijklmnopqrstuvwxyz0123456789_-"" 
 func main() {
  
  
  rand.Seed(time.Now().UTC().UnixNano())
  
  
  s := bufio.NewScanner(os.Stdin)
  
  
  for s.Scan() {
  
  
  text := strings.ToLower(s.Text())
  
  
  var newText []rune
  
  
  for _, r := range text {
  
    
  if unicode.IsSpace(r) {
  
     
  r = '-'
  
    
  }
  
    
  if !strings.ContainsRune(allowedChars, r) {
  
     
  continue
  
    
  }
  
 [
  216 
 ]",NA
Exercise – making top-level domains configurable,"Only supporting 
 .com
  and 
 .net
  top-level domains is fairly limiting. As an additional 
 assignment, see if you can accept a list of TLDs via a command-line flag.",NA
Coolify,"Often domain names for common words such as 
 chat
  are already taken and a common 
 solution is to play around with the vowels in the words. For example, we might 
 remove the 
 a
  leaving 
 cht
  (which is actually less likely to be available), or add an 
 a
  to 
 produce 
 chaat
 . While this clearly has no actual effect on coolness, it has become a 
 popular, albeit slightly dated, way to secure domain names that still sound like the 
 original word.
  
 Our third program, Coolify, will allow us to play with the vowels of words that come 
 in via the input, and write the modified versions to the output.
  
 Create a new folder called 
 coolify
  alongside 
 sprinkle
  and 
 domainify
 , and create the 
 main.go
  code file with the following code:
  
 package main
  
 const (
  
  duplicateVowel bool   = true
  
  removeVowel    bool   = false
  
 ) 
  
 func randBool() bool {
  
  return rand.Intn(2) == 0
  
 }
  
 func main() {
  
  rand.Seed(time.Now().UTC().UnixNano())
  
  s := bufio.NewScanner(os.Stdin)
  
  for s.Scan() {
  
  word := []byte(s.Text())
  
  if randBool() {
  
  var vI int = -1
  
 [
  218 
 ]",NA
Synonyms,"So far, our programs have only modified words, but to really bring our solution to life, 
 we need to be able to integrate a third-party API that provides word synonyms. This 
 allows us to suggest different domain names while retaining the original meaning. 
  
 Unlike Sprinkle and Domainify, Synonyms will write out more than one response for 
 each word given to it. Our architecture of piping programs together means this is no 
 problem; in fact we do not even have to worry about it since each of the three 
 programs is capable of reading multiple lines from the input source.
  
 The Big Hugh Thesaurus at 
 bighughlabs.com
  has a very clean and simple API that 
 allows us to make a single HTTP 
 GET
  request in order to look up synonyms.
  
  
 If in the future the API we are using changes or disappears (after 
  
  
 all, this is the Internet!), you will find some options at 
 https://
  
 github.com/matryer/goblueprints
 .
  
 Before you can use the Big Hugh Thesaurus, you'll need an API key, which you can 
 get by signing up to the service at 
 http://words.bighugelabs.com/
 .",NA
Using environment variables for configuration,"Your API key is a sensitive piece of configuration information that you won't want to 
 share with others. We could store it as 
 const
  in our code, but that would not only mean 
 we couldn't share our code without sharing our key (not good, especially if you love 
 open source projects), but also, and perhaps more importantly, you would have to 
 recompile your project if the key expires or if you want to use a different one.
  
 A better solution is using an environment variable to store the key, as this will allow you 
 to easily change it if you need to. You could also have different keys for different 
 deployments; perhaps you have one key for development or testing and another for 
 production. This way, you can set a specific key for a particular execution of code, so you 
 can easily switch keys without having to change your system-level settings. 
  
 Either way, different operating systems deal with environment variables in similar 
 ways, so they are a perfect choice if you are writing cross-platform code.
  
 [
  222 
 ]",NA
Consuming a web API ,"Making a request for 
 http://words.bighugelabs.com/apisample.
  
 php?v=2&format=json
  in a web browser shows us what the structure of JSON 
 response data looks like when finding synonyms for the word love:
  
 {
  
  
  ""noun"":{
  
  
  ""syn"":[
  
    
  ""passion"",
  
    
  ""beloved"",
  
    
  ""dear""
  
  
  ]
  
  
  },
  
  
  ""verb"":{
  
  
  ""syn"":[
  
    
  ""love"",
  
    
  ""roll in the hay"",
  
    
  ""make out""
  
  
  ],
  
  
  ""ant"":[
  
    
  ""hate""
  
  
  ]
  
  
  } 
  
 }
  
 The real API returns a lot more actual words than what is printed here, but the 
 structure is the important thing. It represents an object where the keys describe the 
 types of words (verbs, nouns, and so on) and values are objects that contain arrays of 
 strings keyed on 
 syn
  or 
 ant
  (for synonym and antonym respectively); it is the 
 synonyms we are interested in.
  
 [
  223 
 ]",NA
Getting domain suggestions,"By composing the four programs we have built so far in this chapter, we already have 
 a useful tool for suggesting domain names. All we have to do now is run the 
 programs while piping the output into input in the appropriate way. In a terminal, 
 navigate to the parent folder and run the following single line:
  
 ./synonyms/synonyms | ./sprinkle/sprinkle | ./coolify/coolify | 
 ./domainify/domainify
  
 Because the 
 synonyms
  program is first in our list, it will receive the input from the 
 terminal (whatever the user decides to type in). Similarly, because 
 domainify
  is last in 
 the chain, it will print its output to the terminal for the user to see. At each step, the lines 
 of words will be piped through the other programs, giving them each a chance to do 
 their magic.
  
 Type in some words to see some domain suggestions, for example, if you type 
 chat 
 and hit return, you might see:
  
 getcnfab.com
  
 confabulationtim.com
  
 getschmoozee.net
  
 [
  227 
 ]",NA
Available,"Our final program, Available, will connect to a WHOIS server to ask for details about 
 domains passed into it—of course, if no details are returned, we can safely assume that 
 the domain is available for purchase. Unfortunately, the WHOIS specification (see 
 http://tools.ietf.org/html/rfc3912
 ) is very small and contains no information 
 about how a WHOIS server should reply when you ask it for details about a domain. 
  
 This means programmatically parsing the response becomes a messy endeavor. To 
 address this issue for now, we will integrate with only a single WHOIS server that we 
 can be sure will have 
 No match
  somewhere in the response when it has no records for 
 the domain.
  
  
 A more robust solution might be to have a WHOIS interface 
  
  
 with well-defined structures for the details, and perhaps an 
  
 error message for the cases when the domain doesn't exist—with 
  
 different implementations for different WHOIS servers. As you 
  
 can imagine, it's quite a project; perfect for an open source effort.
  
 Create a new folder called 
 available
  alongside the others in 
 $GOPATH/src
  and 
 add a 
 main.go
  file 
  
 in it containing the following function code:
  
 func exists(domain string) (bool, error) {
  
  const whoisServer string = ""com.whois-servers.net""
  
  conn, err := net.Dial(""tcp"", whoisServer+"":43"")
  
  if err != nil {
  
  return false, err
  
 [
  228 
 ]",NA
Composing all five programs,"Now that we have completed all five of our programs, it's time to put them all together 
 so that we can use our tool to find an available domain name for our chat application. 
 The simplest way to do this is to use the technique we have been using throughout this 
 chapter: using pipes in a terminal to connect the output and input.
  
 In the terminal, navigate to the parent folder of the five programs and run the 
 following single line of code:
  
 ./synonyms/synonyms | ./sprinkle/sprinkle | ./coolify/coolify | 
 ./domainify/domainify | ./available/available
  
 Once the programs are running, type in a starting word and see how it generates 
 suggestions before checking their availability.
  
 For example, typing in 
 chat
  might cause the programs to take the following actions:
  
 1. The word 
 chat
  goes into 
 synonyms
  and out comes a series of synonyms:
  
 °
  
 confab
  
 °
  
 confabulation
  
 °
  
 schmooze
  
 [
  231 
 ]",NA
One program to rule them all,"Running our solution by piping programs together is an elegant architecture, but it 
 doesn't have a very elegant interface. Specifically, whenever we want to run our solution, 
 we have to type the long messy line where each program is listed separated by pipe 
 characters. In this section, we are going to write a Go program that uses the 
 os/exec
  
 package to run each subprogram while piping the output from one into the input of the 
 next as per our design.
  
 Create a new folder called 
 domainfinder
  alongside the other five programs, and 
 create another new folder called 
 lib
  inside that folder. The 
 lib
  folder is where we will 
 keep builds of our subprograms, but we don't want to be copying and pasting them 
 every time we make a change. Instead, we will write a script that builds the 
 subprograms and copies the binaries to the 
 lib
  folder for us.
  
 [
  232 
 ]",NA
Summary,"In this chapter, we learned how five small command-line programs can, when 
 composed together, produce powerful results while remaining modular. We avoided 
 tightly coupling our programs so they are still useful in their own right. For example, 
 we can use our available program just to check if domain names we manually enter 
 are available or not, or we can use our 
 synonyms
  program just as a command-line 
 thesaurus.
  
 We learned how standard streams could be used to build different flows of these 
 types of programs, and how redirection of the standard input and the standard 
 output lets us play around with different flows very easily.
  
 [
  235 
 ]",NA
Building Distributed ,NA,NA
Systems and Working ,NA,NA
with Flexible Data,"In this chapter, we will explore transferrable skills that allow us to use schemaless 
 data and distributed technologies to solve big data problems. The system we will build 
 in this chapter will prepare us for a future where democratic elections all happen 
 online—on Twitter of course. Our solution will collect and count votes by querying 
 Twitter's streaming API for mentions of specific hashtags, and each component will be 
 capable of horizontally scaling to meet demand. Our use case is a fun and interesting 
 one, but the core concepts we'll learn and specific technology choices we'll make are 
 the real focus of this chapter. The ideas discussed here are directly applicable to any 
 system that needs true-scale capabilities.
  
  
 Horizontal scaling refers to adding nodes, such as physical machines, 
  
  
 to a system in order to improve its availability, performance, and/
  
 or capacity. Big data companies such as Google can scale by adding 
  
 affordable and easy-to-obtain hardware (commonly referred to as 
  
 commodity hardware) due to the way they write their software 
  
 and architect their solutions. Vertical scaling is synonymous with 
  
 increasing the resource available to a single node, such as adding 
  
 additional RAM to a box, or a processor with more cores.
  
 In this chapter, you will:
  
 • 
  
 • 
  
 Learn about distributed NoSQL datastores; specifically how to interact with 
 MongoDB
  
 Learn about distributed messaging queues; specifically Bit.ly's NSQ and how to 
 use the 
 go-nsq
  package to easily publish and subscribe to events",NA
System design,"Having a basic design sketched out is often useful, especially in distributed systems 
 where many components will be communicating with each other in different ways. We 
 don't want to spend too long on this stage because our design is likely to evolve as we 
 get stuck into the details, but we will look at a high-level outline so we can discuss the 
 constituents and how they fit together.
  
  
 The preceding image shows the basic overview of the system we are going to build:
  
 • 
  
 • 
  
 • 
  
 • 
  
 Twitter is the social media network we all know and love.
  
 Twitter's streaming API allows long-running connections where tweet data is 
 streamed as quickly as possible.
  
 twittervotes
  is a program we will write that reads tweets and pushes the 
 votes into the messaging queue. 
 twittervotes
  pulls the relevant tweet data, 
 figures out what is being voted for (or rather, which options are mentioned), and 
 pushes the vote into NSQ.
  
 NSQ is an open source, real-time distributed messaging platform designed to 
 operate at scale, built and maintained by Bit.ly. NSQ carries the message across 
 its instances making it available to anyone who has expressed an interest in the 
 vote data.
  
 [
  238 
 ]",NA
Database design,"We will call our MongoDB database 
 ballots
 . It will contain a single collection 
 called 
 polls
  which is where we will store the poll details, such as the title, the 
 options, and the results (in a single JSON document). The code for a poll will look 
 something like this:
  
 {
  
  ""_id"": ""???"",
  
  ""title"": ""Poll title"",
  
  ""options"": [""one"", ""two"", ""three""],
  
  ""results"": {
  
  ""one"": 100,
  
  ""two"": 200,
  
  ""three"": 300
  
  }
  
 }
  
 [
  239 
 ]",NA
Installing the environment,"The code we write in this chapter has real external dependencies that we need to get 
 set up before we can start to build our system.
  
  
 Be sure to check out the chapter notes at 
 https://github.com/
  
  
 matryer/goblueprints
  if you get stuck on installing any of the 
  
 dependencies.
  
 In most cases, services such as 
 mongod
  and 
 nsqd
  will have to be started before we can 
 run our programs. Since we are writing components of a distributed system, we will 
 have to run each program at the same time, which is as simple as opening many 
 terminal windows.",NA
NSQ,"NSQ is a messaging queue that allows one program to send messages or events to 
 another, or to many other programs running either locally on the same machine, or on 
 different nodes connected by a network. NSQ guarantees the delivery of messages, 
 which means it keeps undelivered messages cached until all interested parties have 
 received them. This means that, even if we stop our 
 counter
  program, we won't miss 
 any votes. You can contrast this capability with fire-and-forget message queues where 
 information is deemed out-of-date, and therefore is forgotten if it isn't delivered in time, 
 and where the sender of the messages doesn't care if the consumer received them or 
 not.
  
 A message queue abstraction allows you to have different components of a system 
 running in different places, provided they have network connectivity to the queue. Your 
 programs are decoupled from others; instead, your designs start to care about the ins 
 and outs of specialized micro-services, rather than the flow of data through a monolithic 
 program.
  
 [
  240 
 ]",NA
NSQ driver for Go,"The NSQ tools themselves are written in Go, so it is logical that the Bit.ly team 
 already has a Go package that makes interacting with NSQ very easy. We will 
 need to use it, so in a terminal, get it using 
 go get
 :
  
 go get github.com/bitly/go-nsq
  
 [
  241 
 ]",NA
MongoDB,"MongoDB is a document database, which basically allows you to store and query JSON 
 documents and the data within them. Each document goes into a collection that can be 
 used to group the documents together without enforcing any schema on the data inside 
 them. Unlike rows in a traditional RDBMS such as Oracle, Microsoft SQL Server, or 
 MySQL, it is perfectly acceptable for documents to have a different shape. For example, a 
 people
  collection can contain the following three JSON documents at the same time:
  
 {""name"":""Mat"",""lang"":""en"",""points"":57}
  
 {""name"":""Laurie"",""position"":""Scrum Master""}
  
 {""position"":""Traditional Manager"",""exists"":false}
  
 This flexibility allows data with varying structure to coexist without impacting 
 performance or wasting space. It is also extremely useful if you expect your 
 software to evolve over time, as we really always should.
  
 MongoDB was designed to scale while also remaining very easy to work with on 
 single-box install such as our development machine. When we host our application for 
 production, we would likely install a more complex multi-sharded, replicated system, 
 which is distributed across many nodes and locations, but for now, just running 
 mongod
  will do.
  
 Head over to 
 http://www.mongodb.org/downloads
  to grab the latest version of 
 MongoDB and install it, making sure to register the 
 bin
  folder with your 
 PATH 
 environment variable as usual.
  
 To validate that MongoDB is successfully installed, run the 
 mongod
  command, then hit 
 Ctrl
  + 
 C
  to stop it for now.",NA
MongoDB driver for Go,"Gustavo Niemeyer has done a great job in simplifying interactions with MongoDB with 
 his 
 mgo
  (pronounced ""mango"") package hosted at 
 http://labix.org/mgo
 , which is 
 go gettable
  with the following command:
  
 go get gopkg.in/mgo.v2
  
 [
  242 
 ]",NA
Starting the environment,"Now that we have all the pieces we need installed, we need to start our environment. In 
 this section, we are going to:
  
 • 
  
 Start 
 nsqlookupd
  so that our 
 nsqd
  instances are discoverable
  
 • 
  
 Start 
 nsqd
  and tell it which 
 nsqlookupd
  to use
  
 • 
  
 Start 
 mongod
  for data services
  
 Each of these daemons should run in their own terminal window, which will make it 
 easy for us to stop them by just hitting 
 Ctrl
  + 
 C
 .
  
  
 Remember the page number for this section as you will likely revisit 
  
  
 it a few times as you work through this chapter.
  
 In a terminal window, run:
  
 nsqlookupd
  
 Take note of the TCP port, which by default is 
 4160
 , and in another terminal 
 window, run:
  
 nsqd --lookupd-tcp-address=localhost:4160
  
 Make sure the port number in the 
 --lookupd-tcp-address
  flag matches the TCP port 
 of the 
 nsqlookupd
  instance. Once you start 
 nsqd
 , you will notice some output is printed 
 to the terminal from both 
 nsqlookupd
  and 
 nsqd
 ; this indicates that the two processes 
 are talking to each other.
  
 In yet another window or tab, start MongoDB by running:
  
 mongod --dbpath ./db
  
 The 
 dbpath
  flag tells MongoDB where to store the data files for our database. You can 
 pick any location you like, but you'll have to make sure the folder exists before 
 mongod
  
 will run.
  
  
 By deleting the 
 dbpath
  folder at any time, you can effectively erase all 
  
  
 data and start afresh. This is especially useful during development.
  
 Now that our environment is running, we are ready to start building our components.
  
 [
  243 
 ]",NA
Votes from Twitter,"In your 
 $GOPATH/src
  folder, alongside other projects, create a new folder called 
 socialpoll
  for this chapter. This folder won't be a Go package or program by itself, 
 but will contain our three component programs. Inside 
 socialpoll
 , create a new 
 folder called 
 twittervotes
  and add the obligatory 
 main.go
  template (this is 
 important as 
 main
  packages without a 
 main
  function won't compile):
  
 package main
  
 func main(){}
  
 Our 
 twittervotes
  program is going to:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 Load all polls from the MongoDB database using 
 mgo
 , and collect all options 
 from the 
 options
  array in each document
  
 Open and maintain a connection to Twitter's streaming APIs looking for any 
 mention of the options
  
 For each tweet that matches the filter, figure out which option is mentioned and 
 push that option through to NSQ
  
 If the connection to Twitter is dropped (which is common in long-running 
 connections as it is actually part of Twitter's streaming API specification) after a 
 short delay (so we do not bombard Twitter with connection requests), reconnect 
 and continue
  
 Periodically re-query MongoDB for the latest polls and refresh the connection to 
 Twitter to make sure we are always looking out for the right options
  
 When the user terminates the program by hitting 
 Ctrl
  + 
 C
 , it will gracefully 
 stop itself",NA
Authorization with Twitter,"In order to use the streaming API, we will need authentication credentials from Twitter's 
 Application Management console, much in the same way we did for our Gomniauth 
 service providers in 
 Chapter 3
 , 
 Three Ways to Implement Profile Pictures
 . Head over to 
 https://apps.twitter.com
  and create a new app called something like 
 SocialPoll
  
 (the names have to be unique, so you can have some fun here; the choice of name doesn't 
 affect the code either way). When your app has been created, visit the 
 API Keys
  tab and 
 locate the 
 Your access token
  section where you need to create a new access token. After 
 a short delay, refresh the page and notice that you in fact have two sets of keys and 
 secrets; an API key and a secret, and an access token and the corresponding secret. 
 Following good coding practices, we are going to set these values as environment 
 variables so that our program can have access to them without us having to hardcode 
 them in our source files.
  
 [
  244 
 ]",NA
Extracting the connection ,"The Twitter streaming API supports HTTP connections that stay open for a long time, 
 and given the design of our solution, we are going to need to access the 
 net.Conn 
 object in order to close it from outside of the goroutine in which requests occur. We can 
 achieve this by providing our own 
 dial
  method to an 
 http.Transport
  object that we 
 will create.
  
 Create a new file called 
 twitter.go
  inside 
 twittervotes
  (which is where all things 
 Twitter-related will live), and insert the following code:
  
 var conn net.Conn 
  
 func dial(netw, addr string) (net.Conn, error) {
  
  
  if conn != nil {
  
  
  conn.Close()
  
  
  conn = nil
  
  
  }
  
  
  netc, err := net.DialTimeout(netw, addr, 5*time.Second)
  
  if err != nil {
  
 [
  245 
 ]",NA
Reading environment variables,"Next we are going to write a function that will read the environment variables and set 
 up the 
 OAuth
  objects we'll need in order to authenticate the requests. Add the 
 following code in the 
 twitter.go
  file:
  
 var (
  
  authClient *oauth.Client
  
  creds *oauth.Credentials
  
 )
  
 [
  246 
 ]",NA
Reading from MongoDB ,"In order to load the polls, and therefore the options to search Twitter for, we need to 
 connect to and query MongoDB. In 
 main.go
 , add the two functions 
 dialdb 
 and 
 closedb
 :
  
 var db *mgo.Session 
  
 func dialdb() error {
  
  
  var err error
  
  
  log.Println(""dialing mongodb: localhost"")
  
  
  db, err = mgo.Dial(""localhost"")
  
  
  return err
  
 [
  248 
 ]",NA
Reading from Twitter,"Now we are able to load the options and make authorized requests to the Twitter API. 
 We are thus ready to write the code that initiates the connection, and 
  
 continuously reads from the stream until either we call our 
 closeConn
  method, or 
 Twitter closes the connection for one reason or another. The structure contained in the 
 stream is a complex one containing all kinds of information about the tweet—who made 
 it and when, and even what links or mentions of users occur in the body (see Twitter's 
 API documentation for more details). However, we are only interested in the tweet text 
 itself so you need not worry about all the other noise; add the following structure to 
 twitter.go
 :
  
 type tweet struct {
  
  Text string
  
 }
  
 [
  250 
 ]",NA
Signal channels,"A great use of channels in Go is to signal events between code running in different 
 goroutines. We are going to see a real-world example of this when we write our next 
 function.
  
 [
  252 
 ]",NA
Publishing to NSQ ,"Once our code is successfully noticing votes on Twitter and sending them down the 
 votes
  
 channel, we need a way to publish them into an NSQ topic; after all, this is the point of the 
 twittervotes
  program.
  
 We will write a function called 
 publishVotes
  that will take the 
 votes
  channel, this 
 time of type 
 <-chan string
  (a receive-only channel) and publish each string that is 
 received from it.
  
  
 In our previous functions, the 
 votes
  channel was of type 
 chan<- 
  
  
 string
 , but this time it's of the type 
 <-chan string
 . You might 
  
 think this is a mistake, or even that it means we cannot use the same 
  
 channel for both but you would be wrong. The channel we create later 
  
 will be made with 
 make(chan string)
 , neither receive or only send, 
  
 and can act in both cases. The reason for using the 
 <-
  operator on a 
  
 channel in arguments is to make clear the intent of what the channel 
  
 will be used for; or in the case where it is the return type, to prevent 
  
 users from accidentally sending on channels intended for receiving or 
  
 vice versa. The compiler will actually produce an error if they use such 
  
 a channel incorrectly.
  
 Once the 
 votes
  channel is closed (this is how external code will tell our function to 
 stop working), we will stop publishing and send a signal down the returned stop signal 
 channel.
  
 Add the 
 publishVotes
  function to 
 main.go
 :
  
 func publishVotes(votes <-chan string) <-chan struct{} {
  
  
 stopchan := make(chan struct{}, 1)
  
  
  pub, _ := nsq.NewProducer(""localhost:4150"", 
 nsq.NewConfig())
  
  go func() {
  
  
  for vote := range votes {
  
    
  pub.Publish(""votes"", []byte(vote)) // publish vote
  
  }
  
  
  log.Println(""Publisher: Stopping"")
  
  
  pub.Stop()
  
  
  log.Println(""Publisher: Stopped"")
  
  
  stopchan <- struct{}{}
  
  
  }()
  
  
  return stopchan 
  
 }
  
 [
  255 
 ]",NA
Gracefully starting and stopping,"When our program is terminated, we want to do a few things before actually exiting; 
 namely closing our connection to Twitter and stopping the NSQ publisher (which actually 
 deregisters its interest in the queue). To achieve this, we have to override the default 
 Ctrl 
 + C
  behavior.
  
  
 The upcoming code blocks all go inside the main function; they are 
  
  
 broken up so we can discuss each section before continuing.
  
 Add the following code inside the 
 main
  function:
  
 var stoplock sync.Mutex
  
 stop := false
  
 stopChan := make(chan struct{}, 1)
  
 [
  256 
 ]",NA
Testing,"To make sure our program works, we need to do two things: first we need to create a 
 poll in the database, and second, we need to peer inside the messaging queue to see if 
 the messages are indeed being generated by 
 twittervotes
 .
  
 In a terminal, run the 
 mongo
  command to open a database shell that allows us to 
 interact with MongoDB. Then enter the following commands to add a test poll:
  
 > use ballots
  
 switched to db ballots
  
 > db.polls.insert({""title"":""Test poll"",""options"":[""happy"",""sad"",""fail"",""w in""]})
  
 The preceding commands add a new item to the 
 polls
  collection in the 
 ballots 
 database. We are using some common words for options that are likely to be mentioned 
 by people on Twitter so that we can observe real tweets being translated into messages. 
 You might notice that our poll object is missing the 
 results
  field; this is fine since we 
 are dealing with unstructured data where documents do not have to adhere to a strict 
 schema. The 
 counter
  program we are going to write in the next section will add and 
 maintain the 
 results
  data for us later.
  
 Press 
 Ctrl + C
  to exit the MongoDB shell and type the following command:
  
 nsq_tail --topic=""votes"" --lookupd-http-address=localhost:4161
  
 The 
 nsq_tail
  tool connects to the specified messaging queue topic and outputs any 
 messages that it notices. This is where we will validate that our 
 twittervotes 
 program is sending messages.
  
 In a separate terminal window, let's build and run the  
 twittervotes
  program:
  
 go build –o twittervotes
  
 ./twittervotes
  
 Now switch back to the window running 
 nsq_tail
  and notice that messages are 
 indeed being generated in response to live Twitter activity.
  
  
 If you aren't seeing much activity, try looking up trending hashtags on 
  
  
 Twitter and adding another poll containing those options.
  
 [
  259 
 ]",NA
Counting votes ,"The second program we are going to implement is the 
 counter
  tool, which will be 
 responsible for watching out for votes in NSQ, counting them, and keeping 
 MongoDB up to date with the latest numbers.
  
 Create a new folder called 
 counter
  alongside 
 twittervotes
 , and add the 
 following code to a new 
 main.go
  file:
  
 package main 
  
 import (
  
  
  ""flag""
  
  
  ""fmt""
  
  
  ""os"" 
  
 ) 
  
 var fatalErr error 
  
 func fatal(e error) {
  
  
  fmt.Println(e)
  
  
  flag.PrintDefaults()
  
  
  fatalErr = e 
  
 } 
  
 func main() {
  
  
  defer func() {
  
  
  if fatalErr != nil {
  
    
  os.Exit(1)
  
  
  }
  
  
  }() 
  
 }
  
 Normally when we encounter an error in our code, we use a call like 
 log.Fatal
  or 
 os.Exit
 , which immediately terminates the program. Exiting the program with a non-
 zero exit code is important, because it is our way of telling the operating system that 
 something went wrong, and we didn't complete our task successfully. The problem with 
 the normal approach is that any deferred functions we have scheduled (and therefore 
 any tear down code we need to run), won't get a chance to execute.
  
 The pattern employed in the preceding code snippet lets us call the 
 fatal
  function to 
 record that an error occurred. Note that only when our main function exits will the 
 deferred function run, which in turn calls 
 os.Exit(1)
  to exit the program with an exit 
 code of 
 1
 . Because the deferred statements are run in LIFO (last in, first out) order, the 
 first function we defer will be the last function to be executed, which is why the first 
 thing we do in the 
 main
  function is to defer the exiting code. This allows us to be sure 
 that other functions we defer will be called 
 before
  the program exits. We'll use this 
 feature to ensure our database connection gets closed regardless of any errors.
  
 [
  260 
 ]",NA
Connecting to the database,"The best time to think about cleaning up resources, such as database connections, is 
 immediately after you have successfully obtained the resource; Go's 
 defer
  keyword 
 makes this easy. At the bottom of the main function, add the following code:
  
 log.Println(""Connecting to database..."")
  
 db, err := mgo.Dial(""localhost"")
  
 if err != nil {
  
  fatal(err)
  
  return
  
 }
  
 defer func() {
  
  log.Println(""Closing database connection..."")
  
  db.Close()
  
 }()
  
 pollData := db.DB(""ballots"").C(""polls"")
  
 This code uses the familiar 
 mgo.Dial
  method to open a session to the locally running 
 MongoDB instance and immediately defers a function that closes the session. We can be 
 sure that this code will run before our previously deferred statement containing the exit 
 code (because deferred functions are run in the reverse order in which they were called). 
 Therefore, whatever happens in our program, we know that the database session will 
 definitely and properly close.
  
  
 The log statements are optional, but will help us see what's going 
  
  
 on when we run and exit our program.
  
 At the end of the snippet, we use the 
 mgo
  fluent API to keep a reference of the 
 ballots.polls
  data collection in the 
 pollData
  variable, which we will use later to 
 make queries.",NA
Consuming messages in NSQ,"In order to count the votes, we need to consume the messages on the 
 votes
  topic in 
 NSQ, and we'll need a place to store them. Add the following variables to the 
 main
  
 function:
  
 var counts map[string]int
  
 var countsLock sync.Mutex
  
 [
  261 
 ]",NA
Keeping the database updated ,"Our code will listen out for votes, and keep a map of the results in memory, but that 
 information is so far trapped inside our program. Next, we need to add the code that will 
 periodically push the results to the database:
  
 log.Println(""Waiting for votes on nsq..."") 
  
 var updater *time.Timer 
  
 updater = time.AfterFunc(updateDuration, func() {
  
  
  countsLock.Lock()
  
  
  defer countsLock.Unlock()
  
  
  if len(counts) == 0 {
  
  
  log.Println(""No new votes, skipping database update"")
  
  } 
 else {
  
  
  log.Println(""Updating database..."")
  
  
  log.Println(counts)
  
  
  ok := true
  
  
  for option, count := range counts {
  
    
  sel := bson.M{""options"": bson.M{""$in"": []string{option}}}
  
   
  up := bson.M{""$inc"": bson.M{""results."" + option: count}}
  
   
  if _, err := pollData.UpdateAll(sel, up); err != nil {
  
    
  log.Println(""failed to update:"", err)
  
     
  ok = false
  
    
  }
  
  
  }
  
  
  if ok {
  
    
  log.Println(""Finished updating database..."")
  
 [
  263 
 ]",NA
Responding to Ctrl + C ,"The last thing to do before our program is ready is to make sure our 
 main
  function 
 waits for operations to complete before exiting, like we did in our 
 twittervotes 
 program. Add the following code at the end of the 
 main
  function:
  
 termChan := make(chan os.Signal, 1) 
  
 signal.Notify(termChan, syscall.SIGINT, syscall.SIGTERM, syscall.
  
 SIGHUP) 
  
 for {
  
  
  select {
  
  
  case <-termChan:
  
  
  updater.Stop()
  
  
  q.Stop()
  
  
  case <-q.StopChan:
  
  
  // finished
  
  
  return
  
  
  } 
  
 }
  
 Here we have employed a slightly different tactic than before. We trap the 
 termination event, which will cause a signal to go down 
 termChan
  when we hit 
 Ctrl + C
 . Next we start an infinite loop, inside which we use Go's 
 select 
 structure 
 to allow us to run code if we receive something on either 
 termChan
 , or the 
 StopChan
  of the consumer.
  
 [
  265 
 ]",NA
Running our solution ,"It's time to see our code in action. Be sure to have 
 nsqlookupd
 , 
 nsqd
 , and 
 mongod 
 running in separate terminal windows with:
  
 nsqlookupd 
  
 nsqd --lookupd-tcp-address=127.0.0.1:4160 
  
 mongod --dbpath ./db
  
 If you haven't already done so, make sure the 
 twittervotes
  program is running too. 
 Then in the 
 counter
  folder, build and run our counting program:
  
 go build -o counter 
  
 ./counter
  
 You should see periodic output describing what work 
 counter
  is doing, such as:
  
 No new votes, skipping database update 
  
 Updating database...
  
 map[win:2 happy:2 fail:1] 
  
 Finished updating database...
  
 No new votes, skipping database update 
  
 Updating database...
  
 map[win:3] 
  
 Finished updating database...
  
  
 The output will of course vary since we are actually responding to real 
  
  
 live activity on Twitter.
  
 [
  266 
 ]",NA
Summary ,"In this chapter we covered a lot of ground. We learned different techniques for 
 gracefully shutting down programs using signaling channels, which is especially 
 important when our code has some work to do before it can exit. We saw that 
 deferring the reporting of fatal errors at the start of our program can give our other 
 deferred functions a chance to execute before the process ends.
  
 [
  267 
 ]",NA
Exposing Data and ,NA,NA
Functionality through ,NA,NA
a RESTful Data Web ,NA,NA
Service API,"In the previous chapter, we built a service that reads tweets from Twitter, counts the 
 hashtag votes, and stores the results in a MongoDB database. We also used the 
 MongoDB shell to add polls and see the poll results. This approach is fine if we are the 
 only ones using our solution, but it would be madness if we released our project and 
 expected users to connect directly to our MongoDB instance in order to use the service 
 we built.
  
 Therefore, in this chapter, we are going to build a RESTful data service through which 
 the data and functionality will be exposed. We will also put together a simple website 
 that consumes the new API. Users may then either use our website to create and 
 monitor polls or build their own application on top of the web services we release.
  
  
 The code in this chapter depends on the code in 
 Chapter 5
 , 
 Building 
  
  
 Distributed Systems and Working with Flexible Data
 , so it is recommended 
  
 that you complete that chapter first, especially since it covers setting up 
  
 the environment that the code in this chapter runs on.
  
 Specifically, you will learn:
  
 • 
  
 • 
  
 How wrapping 
 http.HandlerFunc
  types can give us a simple but powerful 
 pipeline of execution for our HTTP requests
  
 How to safely share data between HTTP handlers",NA
RESTful API design,"For an API to be considered RESTful, it must adhere to a few principles that stay true 
 to the original concepts behind the Web, and are already known to most developers. 
 Such an approach allows us to make sure we aren't building anything strange or 
 unusual into our API while also giving our users a head start towards consuming it, 
 since they are already familiar with its concepts.
  
 Some of the most important RESTful design concepts are:
  
 • 
  
 HTTP methods describe the kind of action to take, for example, 
 GET
  methods 
  
 will only ever 
 read
  data, while 
 POST
  requests will 
 create
  something
  
 • 
  
 Data is expressed as a collection of resources
  
 • 
  
 Actions are expressed as changes to data
  
 • 
  
 URLs are used to refer to specific data
  
 • 
  
 HTTP headers are used to describe the kind of representation coming into 
  
 and going out of the server
  
 see the Wikipedia article at 
 http://en.wikipedia.org/wiki/ 
 Representational_state_transfer
 .
  
  
 For an in-depth overview of these and other details of RESTful designs, 
  
 The following table shows the HTTP methods and URLs that represent the actions 
 that we will support in our API, along with a brief description and an example use 
 case of how we intend the call to be used:
  
 Request
  
 Description
  
 Use case
  
 GET /polls/
  
 Read all polls
  
 Show a list of polls to the users
  
 GET /polls/{id}
  
 Read the poll
  
 Show details or results of a specific poll
  
 POST /polls/
  
 Create a poll
  
 Create a new poll
  
 DELETE /polls/{id}
  
 Delete a poll
  
 Delete a specific poll
  
 The 
 {id}
  placeholder represents where in the path the unique ID for a poll will go.",NA
Sharing data between handlers,"If we want to keep our handlers as pure as the 
 http.Handler
  interface from the 
 Go standard library, while still extracting common functionality into our own 
 methods, we need a way of sharing data between handlers. The 
 HandlerFunc 
 signature that follows tells us that we are only allowed to pass in an 
 http.
  
 ResponseWriter
  object and an 
 http.Request
  object, and nothing else:
  
 type HandlerFunc func(http.ResponseWriter, *http.Request)
  
 This means that we cannot create and manage database session objects in one 
 place and pass them into our handlers, which is ideally what we want to do.
  
 Instead, we are going to implement an in-memory map of per-request data, and 
 provide an easy way for handlers to access it. Alongside the 
 twittervotes 
 and 
 counter
  folders, create a new folder called 
 api
  and create a new file called 
 vars.go
  inside it. Add the following code to the file:
  
 package main
  
 import (
  
  ""net/http""
  
  ""sync""
  
 )
  
 var vars map[*http.Request]map[string]interface{}
  
 var varsLock sync.RWMutex
  
 Here we declare a 
 vars
  map that has a pointer to an 
 http.Request
  type as its key, 
 and another map as the value. We will store the map of variables keyed with the 
 request instances that the variables belong to. The 
 varsLock
  mutex is important, as 
 our handlers will all be trying to access and change the 
 vars
  map at the same time as 
 handling many concurrent HTTP requests, and we need to ensure that they do this 
 safely.
  
 Next we are going to add the 
 OpenVars
  function that allows us to prepare the 
 vars 
 map to hold variables for a particular request:
  
 func OpenVars(r *http.Request) {
  
  varsLock.Lock()
  
  if vars == nil {
  
  vars = map[*http.Request]map[string]interface{}{}
  
  }
  
  vars[r] = map[string]interface{}{}
  
  varsLock.Unlock()
  
 }
  
 [
  271 
 ]",NA
Wrapping handler functions,"One of the most valuable patterns to learn when building web services and websites in 
 Go is one we already utilized in 
 Chapter 2
 , 
 Adding Authentication
 , where we decorated 
 http.Handler
  types by wrapping them with other 
 http.Handler 
 types. For our 
 RESTful API, we are going to apply this same technique to 
 http.
  
 HandlerFunc
  functions, to deliver an extremely powerful way of modularizing our code 
 without breaking the standard 
 func(w http.ResponseWriter, r *http. Request)
  
 interface.",NA
API key,"Most web APIs require clients to register an API key for their application, which they are 
 asked to send along with every request. Such keys have many purposes, ranging from 
 simply identifying which app the requests are coming from to addressing authorization 
 concerns in situations where some apps are only able to do limited things based on what a 
 user has allowed. While we don't actually need to implement API keys for our application, 
 we are going to ask clients to provide one, which will allow us to add an implementation 
 later while keeping the interface constant.
  
 Add the essential 
 main.go
  file inside your 
 api
  folder:
  
 package main
  
 func main(){}
  
 Next we are going to add our first 
 HandlerFunc
  wrapper function called 
 withAPIKey
  to the bottom of 
 main.go
 :
  
 func withAPIKey(fn http.HandlerFunc) http.HandlerFunc {
  
  return func(w http.ResponseWriter, r *http.Request) {
  
  if !isValidAPIKey(r.URL.Query().Get(""key"")) {
  
  respondErr(w, r, http.StatusUnauthorized, ""invalid API key"")
  
  return
  
  }
  
  fn(w, r)
  
  }
  
 }
  
 [
  273 
 ]",NA
Database session,"Now that we can be sure a request has a valid API key, we must consider how handlers 
 will connect to the database. One option is to have each handler dial its own 
 connection, but this isn't very 
 DRY
  (
 Don't Repeat Yourself
 ), and leaves room for 
 potentially erroneous code, such as code that forgets to close a database session once 
 it is finished with it. Instead, we will create another 
 HandlerFunc
  wrapper that 
 manages the database session for us. In 
 main.go
 , add the following function:
  
 func withData(d *mgo.Session, f http.HandlerFunc) http.HandlerFunc {
  
  return func(w http.ResponseWriter, r *http.Request) {
  
  thisDb := d.Copy()
  
  defer thisDb.Close()
  
 [
  274 
 ]",NA
Per request variables,"Our pattern allows us to very easily perform common tasks on behalf of our actual 
 handlers. Notice that one of the handlers is calling 
 OpenVars
  and 
 CloseVars
  so that 
 GetVar
  and 
 SetVar
  may be used without individual handlers having to concern 
 themselves with setting things up and tearing them down. The function will return an 
 http.HandlerFunc
  that first calls 
 OpenVars
  for the request, defers the calling of 
 CloseVars
 , and calls the specified handler function. Any handlers wrapped with 
 withVars
  will be able to use 
 GetVar
  and 
 SetVar
 .
  
 Add the following code to 
 main.go
 :
  
 func withVars(fn http.HandlerFunc) http.HandlerFunc {
  
  return func(w http.ResponseWriter, r *http.Request) {
  
  OpenVars(r)
  
  defer CloseVars(r)
  
  fn(w, r)
  
  }
  
 }
  
 There are lots of other problems that can be addressed using this pattern; and 
 whenever you find yourself duplicating common tasks inside handlers, it's worth 
 considering whether a handler wrapper function could help simplify code.
  
 [
  275 
 ]",NA
Cross-browser resource sharing,"The same-origin security policy mandates that AJAX requests in web browsers be only 
 allowed for services hosted on the same domain, which would make our API fairly 
 limited since we won't be necessarily hosting all of the websites that use our web 
 service. The CORS technique circumnavigates the same-origin policy, allowing us to 
 build a service capable of serving websites hosted on other domains. To do this, we 
 simply have to set the 
 Access-Control-Allow-Origin
  header in response to 
 *
 . While 
 we're at it—since we're using the 
 Location
  header in our create poll call—we'll allow 
 that header to be accessible by the client too, which can be done by listing it in the 
 Access-Control-Expose-Headers
  header. Add the following code to 
 main.go
 :
  
 func withCORS(fn http.HandlerFunc) http.HandlerFunc {
  
  return func(w http.ResponseWriter, r *http.Request) {
  
  w.Header().Set(""Access-Control-Allow-Origin"", ""*"")
  
  w.Header().Set(""Access-Control-Expose-Headers"", ""Location"")
  
  fn(w, r)
  
  }
  
 }
  
 This is the simplest wrapper function yet; it just sets the appropriate header on the 
 ResponseWriter
  type and calls the specified 
 http.HandlerFunc
  type.
  
  
 In this chapter, we are handling CORS explicitly so we can understand 
  
  
 exactly what is going on; for real production code, you should consider 
  
 employing an open source solution such as 
 https://github.com/
  
 fasterness/cors
 .",NA
Responding,"A big part of any API is responding to requests with a combination of status codes, data, 
 errors, and sometimes headers—the 
 net/http
  package makes all of this very easy to 
 do. One option we have, which remains the best option for tiny projects or even the 
 early stages of big projects, is to just build the response code directly inside the handler. 
 As the number of handlers grows, however, we would end up duplicating a lot of code 
 and sprinkling representation decisions all over our project. 
  
 A more scalable approach is to abstract the response code into helper functions.
  
 For the first version of our API, we are going to speak only JSON, but we want the 
 flexibility to add other representations later if we need to.
  
 [
  276 
 ]",NA
Understanding the request,"The 
 http.Request
  object gives us access to every piece of information we might need 
 about the underlying HTTP request, and therefore it is worth glancing through the 
 net/http
  documentation to really get a feel for its power. Examples include, but are not 
 limited to:
  
 • 
  
 URL, path and query string
  
 • 
  
 HTTP method
  
 • 
  
 Cookies
  
 • 
  
 Files
  
 • 
  
 Form values
  
 • 
  
 Referrer and user agent of requester
  
 • 
  
 Basic authentication details
  
 • 
  
 Request body
  
 • 
  
 Header information
  
 There are a few things it doesn't address, which we need to either solve ourselves or 
 look to an external package to help us with. URL path parsing is one such example—
 while we can access a path (such as 
 /people/1/books/2
 ) as a string via the 
 http.Request
  type's 
 URL.Path
  field, there is no easy way to pull out the data 
 encoded in the path such as the people ID of 
 1
 , or the books ID of 
 2
 .
  
 [
  278 
 ]",NA
A simple main function to serve our API,"A web service is nothing more than a simple Go program that binds to a specific HTTP 
 address and port and serves requests, so we get to use all our command-line tool-
 writing knowledge and techniques.
  
  
 We also want to ensure that our 
 main
  function is as simple and modest 
  
  
 as possible, which is always a goal of coding, especially in Go.
  
 Before we write our 
 main
  function, let's look at a few design goals of our API 
 program:
  
 • 
  
 • 
  
 • 
  
 We should be able to specify the HTTP address and port to which our API 
 listens and the address of the MongoDB instances without having to 
 recompile the program (through command-line flags)
  
 We want the program to gracefully shut down when we terminate it, 
 allowing the in-flight requests (requests that are still being processed 
 when the termination signal is sent to our program) to complete
  
 We want the program to log out status updates and report errors properly
  
 [
  280 
 ]",NA
Using handler function wrappers,"It is when we call 
 HandleFunc
  on the 
 ServeMux
  handler that we are making use of our 
 handler function wrappers, with the line:
  
 withCORS(withVars(withData(db, withAPIKey(handlePolls)))))
  
 Since each function takes an 
 http.HandlerFunc
  type as an argument and also 
 returns one, we are able to chain the execution just by nesting the function calls as 
 we have done previously. So when a request comes in with a path prefix of 
 / 
 polls/
 , the program will take the following execution path:
  
 1. 
 withCORS
  is called, which sets the appropriate header.
  
 2. 
 withVars
  is called, which calls 
 OpenVars
  and defers 
 CloseVars
  for the 
  
 request.
  
 3. 
 withData
  is then called, which copies the database session provided as 
  
 the first argument and defers the closing of that session.
  
 4. 
 withAPIKey
  is called next, which checks the request for an API key and 
  
 aborts if it's invalid, or else calls the next handler function.
  
 5. 
 handlePolls
  is then called, which has access to variables and a database 
 session, and which may use the helper functions in 
 respond.go
  to write a 
 response to the client.
  
 6. Execution goes back to 
 withAPIKey
  that just exits.
  
 7. Execution goes back to 
 withData
  that exits, therefore calling the deferred 
  
 session 
 Close
  function and clearing up the database session.
  
 8. Execution goes back to 
 withVars
  that exits, therefore calling 
 CloseVars 
  
 and tidying that up too.
  
 9. Execution finally goes back to 
 withCORS
  that just exits.
  
  
 The order that we nest the wrapper functions in is important, 
  
  
 because 
 withData
  puts the database session for each request in 
  
 that request's variables map using 
 SetVar
 . So 
 withVars
  must 
  
 be outside 
 withData
 . If this isn't respected, the code will likely 
  
 panic and you may want to add a check so that the panic is more 
  
 meaningful to other developers.
  
 [
  282 
 ]",NA
Handling endpoints,"The final piece of the puzzle is the 
 handlePolls
  function that will use the helpers to 
 understand the incoming request and access the database, and generate a meaningful 
 response that will be sent back to the client. We also need to model the poll data that we 
 were working with in the previous chapter.
  
 Create a new file called 
 polls.go
 , and add the following code:
  
 package main
  
 import ""gopkg.in/mgo.v2/bson""
  
 type poll struct {
  
  ID      bson.ObjectId  `bson:""_id"" json:""id""`
  
  Title   string         `json"":""title""""`
  
  Options []string       `json:""options""`
  
  Results map[string]int `json:""results,omitempty""`
  
 }
  
 Here we define a structure called 
 poll
  that has three fields that in turn describe the polls 
 being created and maintained by the code we wrote in the previous chapter. 
  
 Each field also has a tag (two in the 
 ID
  case), which allows us to provide some 
 extra metadata.",NA
Using tags to add metadata to structs,"Tags are strings that follow a field definition within a 
 struct
  type on the same line of 
 code. We use the back tick character to denote literal strings, which means we are free 
 to use double quotes within the tag string itself. The 
 reflect
  package allows us to pull 
 out the value associated with any key; in our case, both 
 bson
  and 
 json
  are examples of 
 keys, and they are each key/value-pair-separated by a space character. Both the 
 encoding/json
  and 
 gopkg.in/mgo.v2/bson
  packages allow you to use tags to 
 specify the field name that will be used with encoding and decoding (along with some 
 other properties), rather than having it infer the values from the name of the fields 
 themselves. We are using BSON to talk with the MongoDB database and JSON to talk to 
 the client, so we can actually specify different views of the same 
 struct
  type. For 
 example, consider the ID field:
  
 ID bson.ObjectId `bson:""_id"" json:""id""`
  
 The name of the field in Go is 
 ID
 , the JSON field is 
 id
 , and the BSON field is 
 _id
 , 
 which is the special identifier field used in MongoDB.
  
 [
  283 
 ]",NA
Many operations with a single handler ,"Because our simple path-parsing solution cares only about the path, we have to do 
 some extra work when looking at the kind of RESTful operation the client is making. 
  
 Specifically, we need to consider the HTTP method so we know how to handle the 
 request. For example, a 
 GET
  call to our 
 /polls/
  path should read polls, where a 
 POST 
 call 
 would create a new one. Some frameworks solve this problem for you, by allowing you to 
 map handlers based on more than the path, such as the HTTP method or the presence of 
 specific headers in the request. Since our case is ultra simple, we are going to use a simple 
 switch
  case. In 
 polls.go
 , add the 
 handlePolls
  function:
  
 func handlePolls(w http.ResponseWriter, r *http.Request) 
 {
  
  switch r.Method {
  
  
  case ""GET"":
  
  
  handlePollsGet(w, r)
  
  
  return
  
  
  case ""POST"":
  
  
  handlePollsPost(w, r)
  
  
  return
  
  
  case ""DELETE"":
  
  
  handlePollsDelete(w, r)
  
  
  return
  
  
  }
  
  
  // not found
  
  
  respondHTTPErr(w, r, http.StatusNotFound) 
  
 }
  
 We switch on the HTTP method and branch our code depending on whether it is 
 GET
 , 
 POST
 , or 
 DELETE
 . If the HTTP method is something else, we just respond with a 
 404 
 http.StatusNotFound
  error. To make this code compile, you can add the following 
 function stubs underneath the 
 handlePolls
  handler:
  
 func handlePollsGet(w http.ResponseWriter, r *http.Request) {
  
  
  respondErr(w, r, http.StatusInternalServerError, errors.New(""not  
 implemented"")) 
  
 } 
  
 func handlePollsPost(w http.ResponseWriter, r *http.Request) {
  
  
 respondErr(w, r, http.StatusInternalServerError, errors.New(""not  
 implemented"")) 
  
 } 
  
 func handlePollsDelete(w http.ResponseWriter, r *http.Request) {
  
  respondErr(w, r, http.StatusInternalServerError, errors.New(""not  
 implemented"")) 
  
 }
  
 [
  284 
 ]",NA
Reading polls ,"Now it's time to implement the functionality of our web service. Inside the 
 GET
  case, add 
 the following code:
  
 func handlePollsGet(w http.ResponseWriter, r *http.Request) {
  
  db := GetVar(r, ""db"").(*mgo.Database)
  
  
  c := db.C(""polls"")
  
  
  var q *mgo.Query
  
  
  p := NewPath(r.URL.Path)
  
  
  if p.HasID() {
  
  
  // get specific poll
  
  
  q = c.FindId(bson.ObjectIdHex(p.ID))
  
  
  } else {
  
  
  // get all polls
  
  
  q = c.Find(nil)
  
  
  }
  
  
  var result []*poll
  
  
  if err := q.All(&result); err != nil {
  
  
  respondErr(w, r, http.StatusInternalServerError, err)
  
  
 return
  
  
  }
  
  
  respond(w, r, http.StatusOK, &result) 
  
 }
  
 The very first thing we do in each of our subhandler functions is to use 
 GetVar 
 to get 
 the 
 mgo.Database
  object that will allow us to interact with MongoDB. Since this 
 handler was nested inside both 
 withVars
  and 
 withData
 , we know that the database 
 will be available by the time execution reaches our handler. We then use 
 mgo
  to create 
 an object referring to the 
 polls
  collection in the database—if you remember, this is 
 where our polls live.
  
 We then build up an 
 mgo.Query
  object by parsing the path. If an ID is present, we use 
 the 
 FindId
  method on the 
 polls
  collection, otherwise we pass 
 nil
  to the 
 Find 
 method, which indicates that we want to select all the polls. We are converting the ID 
 from a string to a 
 bson.ObjectId
  type with the 
 ObjectIdHex
  method so that we can 
 refer to the polls with their numerical (hex) identifiers.
  
 [
  285 
 ]",NA
Creating a poll ,"Clients should be able to make a 
 POST
  request to 
 /polls/
  to create a poll. Let's add 
 the following code inside the 
 POST
  case:
  
 func handlePollsPost(w http.ResponseWriter, r *http.Request) {
  
  
 db := GetVar(r, ""db"").(*mgo.Database)
  
  
  c := db.C(""polls"")
  
  
  var p poll
  
  
  if err := decodeBody(r, &p); err != nil {
  
  
  respondErr(w, r, http.StatusBadRequest, ""failed to read poll  
 from request"", err)
  
  
  return
  
  
  }
  
  
  p.ID = bson.NewObjectId()
  
  
  if err := c.Insert(p); err != nil {
  
  
  respondErr(w, r, http.StatusInternalServerError, ""failed to  
 insert poll"", err)
  
  
  return
  
  
  }
  
  
  w.Header().Set(""Location"", ""polls/""+p.ID.Hex())
  
  
  respond(w, r, http.StatusCreated, nil) 
  
 }
  
 Here we first attempt to decode the body of the request that, according to RESTful 
 principles, should contain a representation of the poll object the client wants to create. If 
 an error occurs, we use the 
 respondErr
  helper to write the error to the user, and 
 immediately return the function. We then generate a new unique ID for the poll, and use 
 the 
 mgo
  package's 
 Insert
  method to send it into the database. As per HTTP standards, we 
 then set the 
 Location
  header of the response and respond with a 
 201 
 http.StatusCreated
  message, pointing to the URL from which the newly created poll 
 maybe accessed.
  
 [
  287 
 ]",NA
Deleting a poll ,"The final piece of functionality we are going to include in our API is the capability to 
 delete polls. By making a request with the 
 DELETE
  HTTP method to the URL of a poll 
 (such as 
 /polls/5415b060a02cd4adb487c3ae
 ), we want to be able to remove the 
 poll from the database and return a 
 200 Success
  response:
  
 func handlePollsDelete(w http.ResponseWriter, r *http.Request) {
  
  db := GetVar(r, ""db"").(*mgo.Database)
  
  
  c := db.C(""polls"")
  
  
  p := NewPath(r.URL.Path)
  
  
  if !p.HasID() {
  
  
  respondErr(w, r, http.StatusMethodNotAllowed, ""Cannot delete  
 all polls."")
  
  
  return
  
  
  }
  
  
  if err := c.RemoveId(bson.ObjectIdHex(p.ID)); err != nil {
  
  
 respondErr(w, r, http.StatusInternalServerError, ""failed to  
 delete poll"", err)
  
  
  return
  
  
  }
  
  
  respond(w, r, http.StatusOK, nil) // ok 
  
 }
  
 Similar to the 
 GET
  case, we parse the path, but this time we respond with an error if 
 the path does not contain an ID. For now, we don't want people to be able to delete 
 all polls with one request, and so use the suitable 
 StatusMethodNotAllowed
  code. 
  
 Then, using the same collection we used in the previous cases, we call 
 RemoveId
 , 
 passing in the ID in the path after converting it into a 
 bson.ObjectId
  type. Assuming 
 things go well, we respond with an 
 http.StatusOK
  message, with no body.",NA
CORS support ,"In order for our 
 DELETE
  capability to work over CORS, we must do a little extra work 
 to support the way CORS browsers handle some HTTP methods such as 
 DELETE
 . A 
 CORS browser will actually send a pre-flight request (with an HTTP method of 
 OPTIONS
 ) asking for permission to make a 
 DELETE
  request (listed in the 
 Access-
 Control-Request-Method
  request header), and the API must respond appropriately 
 in order for the request to work. Add another case in the 
 switch 
 statement for 
 OPTIONS
 :
  
 case ""OPTIONS"":
  
  w.Header().Add(""Access-Control-Allow-Methods"", 
 ""DELETE"") respond(w, r, http.StatusOK, nil)
  
  return
  
 [
  288 
 ]",NA
Testing our API using curl,"curl
  is a command-line tool that allows us to make HTTP requests to our service so that 
 we can access it as though we were a real app or client consuming the service.
  
  
 Windows users do not have access to 
 curl
  by default, and will 
  
  
 need to seek an alternative. Check out 
 http://curl.haxx.se/
  
 dlwiz/?type=bin
  or search the Web for ""Windows 
 curl
  alternative"".
  
 In a terminal, let's read all the polls in the database through our API. Navigate to your 
 api
  folder and build and run the project, and also ensure MongoDB is running:
  
 go build –o api
  
 ./api
  
 We then perform the following steps:
  
 1. Enter the following 
 curl
  command that uses the 
 -X
  flag to denote we want 
  
 to make a 
 GET
  request to the specified URL:
  
 curl -X GET http://localhost:8080/polls/?key=abc123
  
 2. The output is printed after you hit 
 Enter
 :
  
 [{""id"":""541727b08ea48e5e5d5bb189"",""title"":""Best 
  
 Beatle?"",""options"":[""john"",""paul"",""george"",""ringo""]},{""id"":""54 
 1728728ea48e5e5d5bb18a"",""title"":""Favorite 
  
 language?"",""options"":[""go"",""java"",""javascript"",""ruby""]}]
  
 3. While it isn't pretty, you can see that the API returns the polls from your 
  
 database. Issue the following command to create a new poll:
  
 curl --data '{""title"":""test"",""options"":[""one"",""two"",""three""]}' -X POST 
 http://localhost:8080/polls/?key=abc123
  
 [
  289 
 ]",NA
A web client that consumes the API ,"We are 
 going to put together an ultra-simple web client that consumes the capabilities 
 and data exposed through our API, allowing users to interact with the polling 
 system we built in the previous chapter and earlier in this chapter. 
  
 Our client will be made up of three web pages:
  
 • 
  
 An 
 index.html
  page that shows all the polls
  
 • 
  
 A 
 view.html
  page that shows the results of a specific poll
  
 • 
  
 A 
 new.html
  page that allows users to create new polls
  
 Create a new folder called 
 web
  alongside the 
 api
  folder, and add the following 
 content to the 
 main.go
  file:
  
 package main
  
 [
  290 
 ]",NA
An index page showing a list of polls ,"Create the 
 public
  folder inside 
 web
  and add the 
 index.html
  file after writing the 
 following HTML code in it:
  
 <!DOCTYPE html> 
  
 <html> 
  
 <head>
  
  
  <title>Polls</title>
  
  
  <link rel=""stylesheet""  
  
  
  href=""//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/ 
  
  
 bootstrap.min.css""> 
  
 </head> 
  
 <body> 
  
 </body> 
  
 </html>
  
 [
  291 
 ]",NA
A page to create a new poll ,"To allow users to create a new poll, create a file called 
 new.html
  inside the 
 public 
 folder, and add the following HTML code to the file:
  
 <!DOCTYPE html> 
  
 <html> 
  
 <head>
  
  
  <title>Create Poll</title>
  
  
  <link rel=""stylesheet""  
  
  
  href=""//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/ 
  
  
  bootstrap.min.css""> 
  
 </head> 
  
 <body>
  
  
  <script  
  
 src=""//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"">< 
 /script>
  
  
  <script  
  
 src=""//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js 
 ""></script> 
  
 </body> 
  
 </html>
  
 We are going to add the elements for an HTML form that will capture the information we 
 need when creating a new poll, namely the title of the poll and the options. Add the 
 following code inside the 
 body
  tags:
  
 <div class=""container"">
  
  
  <div class=""col-md-4""></div>
  
  
  <form id=""poll"" role=""form"" class=""col-md-4"">
  
  <h2>Create Poll</h2>
  
  
  <div class=""form-group"">
  
    
  <label for=""title"">Title</label>
  
 [
  293 
 ]",NA
A page to show details of the poll ,"The final page of our app we need to complete is the 
 view.html
  page where users can 
 see the details and live results of the poll. Create a new file called 
 view.html 
 inside 
 the 
 public
  folder, and add the following HTML code to it:
  
 <!DOCTYPE html> 
  
 <html> 
  
 <head>
  
  
  <title>View Poll</title>
  
  
  <link rel=""stylesheet""  
  
 href=""//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min. 
  
 css""> 
  
 </head> 
  
 <body>
  
  
  <div class=""container"">
  
  
  <div class=""col-md-4""></div>
  
  
  <div class=""col-md-4"">
  
    
  <h1 data-field=""title"">...</h1>
  
    
  <ul id=""options""></ul>
  
    
  <div id=""chart""></div>
  
    
  <div>
  
     
  <button class=""btn btn-sm"" id=""delete"">Delete this  
 poll</button>
  
    
  </div>
  
  
  </div>
  
  
  <div class=""col-md-4""></div>
  
  
  </div> 
  
 </body> 
  
 </html>
  
 [
  295 
 ]",NA
Running the solution,"We have built many components over the last two chapters, and it is now time to see 
 them all working together. This section contains everything you need to get all the items 
 running, assuming you have the environment set up properly as described at the 
 beginning of the previous chapter. This section assumes you have a single folder that 
 contains four subfolders: 
 api
 , 
 counter
 , 
 twittervotes
 , and 
 web
 .
  
 Assuming nothing is running, take the following steps (each step in its own 
 terminal window):
  
 1. In the top-level folder, start the 
 nsqlookupd
  daemon:
  
 nsqlookupd
  
 2. In the same directory, start the 
 nsqd
  daemon:
  
 nsqd --lookupd-tcp-address=localhost:4160
  
 3. Start the MongoDB daemon:
  
 mongod
  
 4. Navigate to the 
 counter
  folder and build and run it:
  
 cd counter
  
 go build –o counter
  
 ./counter
  
 5. Navigate to the 
 twittervotes
  folder and build and run it. Be sure that you 
 have the appropriate environment variables set, otherwise you will see 
 errors when you run the program:
  
 cd ../twittervotes
  
 go build –o twittervotes
  
 ./twittervotes
  
 6. Navigate to the 
 api
  folder and build and run it:
  
 cd ../api
  
 go build –o api
  
 ./api
  
 7. Navigate to the 
 web
  folder and build and run it:
  
 cd ../web
  
 go build –o web
  
 ./web
  
 [
  298 
 ]",NA
Summary,"In this chapter, we exposed the data for our social polling solution through a highly 
 scalable RESTful API and built a simple website that consumes the API to provide an 
 intuitive way for users to interact with it. The website consists of static content only, 
 with no server-side processing (since the API does the heavy lifting for us). 
  
 This allows us to host the website very cheaply on static hosting sites such as 
 bitballoon.com
 , or to distribute the files to content delivery networks.
  
 Within our API service, we learned how to share data between handlers without 
 breaking or obfuscating the handler pattern from the standard library. We also saw 
 how writing wrapped handler functions allows us to build a pipeline of functionality 
 in a very simple and intuitive way.
  
 [
  299 
 ]",NA
Random Recommendations ,NA,NA
Web Service,"The concept behind the project that we will build in this chapter is a simple one: we 
 want users to be able to generate random recommendations for things to do in specific 
 geographical locations based on a predefined set of journey types that we will expose 
 through the API. We will give our project the codename Meander.
  
 Often on projects in the real world, you are responsible for the full stack; somebody else 
 builds the website, a different person still might write the iOS app, and maybe an 
 outsourced company builds the desktop version. On more successful API projects, you 
 might not even know who the consumers of your API are, especially if it's a public API.
  
 In this chapter, we will simulate this reality by designing and agreeing a minimal API 
 design with a fictional partner up front before going on to implement the API. 
  
 Once we have finished our side of the project, we will download a user interface built by 
 our teammates to see the two work together to produce the final application.
  
 In this chapter, you will:
  
 • 
  
 • 
  
 • 
  
 • 
  
 Learn to express the general goals of a project using short and simple 
 Agile user stories
  
 Discover that you can agree a meeting point in a project by agreeing on the 
 design of an API, which allows many people to work in parallel
  
 See how early versions of code can actually have data fixtures written in 
 code and compiled into the program, allowing us to change the 
 implementation later without touching the interface
  
 Learn a strategy that allows structs (and other types) to represent a 
 public version of themselves for cases when we want to hide or 
 transform internal representations",NA
Project overview,"Following Agile methodologies, let's write two user stories that describe the 
 functionality of our project. User stories shouldn't be comprehensive documents 
 describing the entire set of features of an application; rather small cards are perfect for 
 not only describing what the user is trying to do, but why. Also, we should do this 
 without trying to design the whole system up front or delve too deep into 
 implementation details.
  
 First we need a story about seeing the different journey types from which our 
 users may select:
  
 As a
  
 traveler
  
 I want
  
 to see the different types of journeys I can get recommendations for
  
 So that
  
 I can decide what kind of evening to take my partner on
  
 Secondly, we need a story about providing random recommendations for a 
 selected journey type:
  
 As a
  
 traveler
  
 I want
  
 to see a random recommendation for my selected journey type
  
 So that
  
 I know where to go, and what the evening will entail
  
 [
  302 
 ]",NA
Project design specifics ,"In order to turn our stories into an interactive application, we are going to provide two 
 JSON endpoints; one to deliver the kinds of journeys users will be able to select in the 
 application, and another to actually generate the random recommendations for the 
 selected journey type.
  
 GET /journeys
  
 The above call should return a list such as the following:
  
 [
  
  
  {
  
  
  name: ""Romantic"",
  
  
  journey: ""park|bar|movie_theater|restaurant|florist""
  
  },
  
  
  {
  
  
  name: ""Shopping"",
  
  
  journey: ""department_store|clothing_store|jewelry_store""
  
  } 
  
 ]
  
 The 
 name
  field is a human-readable label for the type of recommendations the app 
 generates, and the 
 journey
  field is a pipe-separated list of supported journey types. It is 
 the journey value that we will pass, as a URL parameter, into our other endpoint, which 
 generates the actual recommendations:
  
 GET /recommendations?
  
  lat=1&lng=2&journey=bar|cafe&radius=10&cost=$...$$$$$
  
 [
  303 
 ]",NA
Representing data in code,"We are first going to expose the journeys that users can select from, so create a new 
 folder called 
 meander
  in 
 GOPATH
 , and add the following 
 journeys.go
  code:
  
 package meander
  
 type j struct {
  
  Name       string
  
  PlaceTypes []string
  
 }
  
 var Journeys = []interface{}{
  
  
  &j{Name: ""Romantic"", PlaceTypes: []string{""park"", ""bar"",  
 ""movie_theater"", ""restaurant"", ""florist"", ""taxi_stand""}},
  
  
  &j{Name: ""Shopping"", PlaceTypes: []string{""department_store"",  
 ""cafe"", ""clothing_store"", ""jewelry_store"", ""shoe_store""}},
  
  
  &j{Name: ""Night Out"", PlaceTypes: []string{""bar"", ""casino"",  
 ""food"", ""bar"", ""night_club"", ""bar"", ""bar"", ""hospital""}},
  
  
  &j{Name: ""Culture"", PlaceTypes: []string{""museum"", ""cafe"",  
 ""cemetery"", ""library"", ""art_gallery""}},
  
  
  &j{Name: ""Pamper"", PlaceTypes: []string{""hair_care"",  
 ""beauty_salon"", ""cafe"", ""spa""}},
  
 }
  
 Here we define an internal type called 
 j
  inside the 
 meander
  package, which we 
 then use to describe the journeys by creating instances of them inside the 
 Journeys
  slice. This approach is an ultra-simple way of representing data in the 
 code, without building in a dependency on an external data store.
  
  
 As an additional assignment, why not see if you can keep 
 golint
  
  
 happy throughout this process? Every time you add some code, run 
  
 golint
  for the packages and satisfy any suggestions that emerge. It 
  
 cares a lot about exported items having no documentation, so adding 
  
 simple comments in the correct format will keep it happy. To learn 
  
 more about 
 golint
 , see 
 https://github.com/golang/lint
 .
  
 Of course, this would likely evolve into just that later, maybe even with the ability for 
 users to create and share their own journeys. Since we are exposing our data via an 
 API, we are free to change the internal implementation without affecting the interface, 
 so this approach is great for a version 1.0.
  
  
 We are using a slice of type 
 []interface{}
  because we will 
  
  
 later implement a general way of exposing public data regardless 
  
 of actual types.
  
 [
  305 
 ]",NA
Public views of Go structs ,"In order to control the public view of structs in Go, we need to invent a way to allow 
 individual 
 journey
  types to tell us how they want to be exposed. In the 
 meander
  
 folder, create a new file called 
 public.go
 , and add the following code:
  
 package meander 
  
 type Facade interface {
  
  
  Public() interface{} 
  
 } 
  
 func Public(o interface{}) interface{} {
  
  
  if p, ok := o.(Facade); ok {
  
  
  return p.Public()
  
  
  }
  
  
  return o 
  
 }
  
 [
  307 
 ]",NA
Generating random recommendations ,"In 
 order to obtain the places from which our code will randomly build up 
 recommendations, we need to query the Google Places API. In the 
 meander 
 folder, add the following 
 query.go
  file:
  
 package meander 
  
 type Place struct {
  
  
  *googleGeometry `json:""geometry""`
  
  
  Name            string         `json:""name""`
  
  
 Icon            string         `json:""icon""`
  
  
 Photos          []*googlePhoto `json:""photos""`
  
  
 Vicinity        string         `json:""vicinity""` 
 } 
  
 type googleResponse struct {
  
  
  Results []*Place `json:""results""` 
  
 } 
  
 type googleGeometry struct {
  
  
  *googleLocation `json:""location""` 
  
 } 
  
 type googleLocation struct {
  
  
  Lat float64 `json:""lat""`
  
  
  Lng float64 `json:""lng""` 
  
 } 
  
 type googlePhoto struct {
  
  
  PhotoRef string `json:""photo_reference""`
  
  
  URL      string `json:""url""` 
  
 }
  
 This code defines the structures we will need to parse the JSON response from the 
 Google Places API into usable objects.
  
  
 Head over to the Google Places API documentation for an example of 
  
  
 the response we are expecting. See 
 http://developers.google.
  
 com/places/documentation/search
 .
  
 Most of the preceding code will be obvious, but it's worth noticing that the 
 Place 
 type embeds the 
 googleGeometry
  type, which allows us to represent the nested 
 data as per the API, while essentially flattening it in our code. We do the same with 
 googleLocation
  inside 
 googleGeometry
 , which means that we will be able to 
 access the 
 Lat
  and 
 Lng
  values directly on a 
 Place
  object, even though they're 
 technically nested in other structures.
  
 [
  309 
 ]",NA
Google Places API key ,"Like with most APIs, we will need an API key in order to access the remote services. Head 
 over to the Google APIs Console, sign in with a Google account, and create a key for the 
 Google Places API. For more detailed instructions, see the documentation on Google's 
 developer website.
  
 Once you have your key, let's make a variable inside the 
 meander
  package that can 
 hold it. At the top of 
 query.go
 , add the following definition:
  
 var APIKey string
  
 Now nip back into 
 main.go
 , remove the double slash 
 //
  from the 
 APIKey
  line, and 
 replace the 
 TODO
  value with the actual key provided by the Google APIs console.",NA
Enumerators in Go ,"To handle the various cost ranges for our API, it makes sense to use an enumerator (or 
 enum
 ) to denote the various values and to handle conversions to and from string 
 representations. Go doesn't explicitly provide enumerators, but there is a neat way of 
 implementing them, which we will explore in this section.
  
 [
  310 
 ]",NA
Test-driven enumerator ,"To be sure that our enumerator code is working correctly, we are going to write 
 unit tests that make some assertions about expected behavior.
  
 Alongside 
 cost_level.go
 , add a new file called 
 cost_level_test.go
 , and add the 
 following unit test:
  
 package meander_test 
  
 import (
  
  
  ""testing""
  
  
  ""github.com/cheekybits/is""
  
  
  ""path/to/meander"" 
  
 ) 
  
 func TestCostValues(t *testing.T) {
  
  
  is := is.New(t)
  
  
  is.Equal(int(meander.Cost1), 1)
  
  
  is.Equal(int(meander.Cost2), 2)
  
  
  is.Equal(int(meander.Cost3), 3)
  
  
  is.Equal(int(meander.Cost4), 4)
  
  
  is.Equal(int(meander.Cost5), 5) 
  
 }
  
 You will need to run 
 go get
  to get the CheekyBits' 
 is
  package (from 
 github.com/ 
 cheekybits/is
 ).
  
  
 The 
 is
  package is an alternative testing helper package, but this one is 
  
  
 ultra-simple and deliberately bare-bones. You get to pick your favorite 
  
 when you write your own projects.
  
 [
  312 
 ]",NA
Querying the Google Places API ,"Now that we are capable of representing the results of the API, we need a way to 
 represent and initiate the actual query. Add the following structure to 
 query.go
 :
  
 type Query struct {
  
  
  Lat          float64
  
  
  Lng          float64
  
  
  Journey      []string
  
  
  Radius       int
  
  
  CostRangeStr string 
  
 }
  
 This structure contains all the information we will need to build up the query, all of 
 which will actually come from the URL parameters in the requests from the client. 
  
 Next, add the following 
 find
  method, which will be responsible for making the 
 actual request to Google's servers:
  
 func (q *Query) find(types string) (*googleResponse, error) {
  
  u :=  
  
 ""https://maps.googleapis.com/maps/api/place/nearbysearch/json
 ""
  
  vals := make(url.Values)
  
  
  vals.Set(""location"", fmt.Sprintf(""%g,%g"", q.Lat, q.Lng))
  
  vals.Set(""radius"", fmt.Sprintf(""%d"", q.Radius))
  
  
  vals.Set(""types"", types)
  
  
  vals.Set(""key"", APIKey)
  
  
  if len(q.CostRangeStr) > 0 {
  
  
  r := ParseCostRange(q.CostRangeStr)
  
  
  vals.Set(""minprice"", fmt.Sprintf(""%d"", int(r.From)-1))
  
  
 vals.Set(""maxprice"", fmt.Sprintf(""%d"", int(r.To)-1))
  
  }
  
 [
  316 
 ]",NA
Building recommendations ,"Next we need to write a method that will allow us to make many calls to find, for the 
 different steps in a journey. Underneath the 
 find
  method, add the following 
 Run
  
 method to the 
 Query
  struct:
  
 // Run runs the query concurrently, and returns the results.
  
 func (q *Query) Run() []interface{} {
  
  rand.Seed(time.Now().UnixNano())
  
  var w sync.WaitGroup
  
  var l sync.Mutex
  
  places := make([]interface{}, len(q.Journey))
  
 [
  317 
 ]",NA
Handlers that use query parameters,"Now we need to wire up our 
 /recommendations
  call, so head back to 
 main.go
  in 
 the 
 cmd
  folder, and add the following code inside the 
 main
  function:
  
 http.HandleFunc(""/recommendations"", func(w http.ResponseWriter, r 
 *http.Request) {
  
  q := &meander.Query{
  
  Journey: strings.Split(r.URL.Query().Get(""journey""), ""|""),
  
  }
  
  q.Lat, _ = strconv.ParseFloat(r.URL.Query().Get(""lat""), 64)
  
  q.Lng, _ = strconv.ParseFloat(r.URL.Query().Get(""lng""), 64)
  
  q.Radius, _ = strconv.Atoi(r.URL.Query().Get(""radius""))
  
  q.CostRangeStr = r.URL.Query().Get(""cost"")
  
  places := q.Run()
  
  respond(w, r, places)
  
 })
  
 This handler is responsible for preparing the 
 meander.Query
  object and calling its 
 Run
  method, before responding with the results. The 
 http.Request
  type's URL value 
 exposes the 
 Query
  data that provides a 
 Get
  method that, in turn, looks up a value for a 
 given key.
  
 [
  319 
 ]",NA
CORS ,"The final piece of the first version of our API will be to implement CORS as we did in 
 the previous chapter. See if you can solve this problem yourself before reading on to 
 the solution in the next section.
  
  
 If you are going to tackle this yourself, remember that your aim is to 
  
  
 set the 
 Access-Control-Allow-Origin
  response header to 
 *
 . Also 
  
 consider the 
 http.HandlerFunc
  wrapping we did in the previous 
  
 chapter. The best place for this code is probably in the 
 cmd
  program, 
  
 since that is what exposes the functionality through an HTTP endpoint.
  
 In 
 main.go
 , add the following 
 cors
  function:
  
 func cors(f http.HandlerFunc) http.HandlerFunc {
  
  
  return func(w http.ResponseWriter, r *http.Request) {
  
  w.Header().Set(""Access-Control-Allow-Origin"", ""*"")
  
  f(w, r)
  
  
  } 
  
 }
  
 This familiar pattern takes in an 
 http.HandlerFunc
  type and returns a new one 
 that sets the appropriate header before calling the passed-in function. Now we can 
 modify our code to make sure the 
 cors
  function gets called for both of our 
 endpoints. Update the appropriate lines in the 
 main
  function:
  
 func main() {
  
  
  runtime.GOMAXPROCS(runtime.NumCPU())
  
  
  meander.APIKey = ""YOUR_API_KEY""
  
  
  http.HandleFunc(""/journeys"", cors(func(w http.ResponseWriter, r  
 *http.Request) {
  
  
  respond(w, r, meander.Journeys)
  
  
  }))
  
  
  http.HandleFunc(""/recommendations"", cors(func(w  
  
 http.ResponseWriter, r *http.Request) {
  
  
  q := &meander.Query{
  
    
  Journey: strings.Split(r.URL.Query().Get(""journey""), ""|""),
  
  }
  
 [
  320 
 ]",NA
Testing our API ,"Now that we are ready to test our API, head to a console and navigate to the 
 cmd 
 folder. Because our program imports the 
 meander
  package, building the program 
 will automatically build our 
 meander
  package too.
  
 Build and run the program:
  
 go build –o meanderapi
  
 ./meanderapi
  
 To see meaningful results from our API, let's take a minute to find your actual 
 latitude and longitude. Head over to 
 http://mygeoposition.com/
  and use the 
 web tools to get the 
 x,y
  values for a location you are familiar with.
  
 Or pick from these popular cities:
  
 • 
  
 London, England: 
 51.520707 x 0.153809
  
 • 
  
 New York, USA: 
 40.7127840 x -74.0059410
  
 • 
  
 Tokyo, Japan: 
 35.6894870 x 139.6917060
  
 • 
  
 San Francisco, USA: 
 37.7749290 x -122.4194160
  
 Now open a web browser and access the 
 /recommendations
  endpoint with some 
 appropriate values for the fields:
  
 http://localhost:8080/recommendations?
  
  lat=51.520707&lng=-0.153809&radius=5000&
  
  journey=cafe|bar|casino|restaurant&
  
  cost=$...$$$
  
 [
  321 
 ]",NA
Web application,"We are going to download a complete web application built to the same API 
 specifications, and point it at our implementation to see it come to life before our eyes. 
 Head over to 
 https://github.com/matryer/goblueprints/tree/master/ 
 chapter7/meanderweb
  and download the 
 meanderweb
  project into your 
 GOPATH
 .
  
 In a terminal, navigate to the 
 meanderweb
  folder, and build and run it:
  
 go build –o meanderweb
  
 ./meanderweb
  
 [
  322 
 ]",NA
Summary,"In this chapter, we built an API that consumes and abstracts the Google Places API to 
 provide a fun and interesting way of letting users plan their days and evenings.
  
 We started by writing some simple and short user stories that described at a really high 
 level what we wanted to achieve, without trying to design the implementation up front. 
 In order to parallelize the project, we agreed the meeting point of the project as the API 
 design, and we built towards it (as would our partners).
  
 We embedded data directly in code, avoiding the need to investigate, design, and 
 implement a data store in the early stages of a project. By caring instead about how 
 that data is accessed (via the API endpoint), we allowed our future selves to 
 completely change how and where the data is stored, without breaking any apps that 
 have been written to our API.
  
 We implemented the 
 Facade
  interface, which allows our structs and other types to 
 provide public representations of them, without revealing messy or sensitive details 
 about our implementation.
  
 Our foray into enumerators gave us a useful starting point to build enumerated types, 
 even though there is no official support for them in the language. The 
 iota 
 keyword 
 that we used lets us specify constants of our own numerical type, with incrementing 
 values. The common 
 String
  method that we implemented showed us how to make 
 sure our enumerated types don't become obscure numbers in our logs. At the same 
 time, we also saw a real-world example of TDD, and red/green programming where 
 we wrote unit tests that first fail, but which we then go on to make pass by writing the 
 implementation code.
  
 [
  323 
 ]",NA
Filesystem Backup,"There are many solutions that provide filesystem backup capabilities. These include 
 everything from apps such as Dropbox, Box, Carbonite to hardware solutions such as 
 Apple's Time Machine, Seagate, or network-attached storage products, to name a few. 
 Most consumer tools provide some key automatic functionality, along with an app or 
 website for you to manage your policies and content. Often, especially for developers, 
 these tools don't quite do the things we need them to. However, thanks to Go's standard 
 library (that includes packages such as 
 ioutil
  and 
 os
 ) we have everything we need to 
 build a backup solution that behaves exactly as we need it to.
  
 For our final project, we will build a simple filesystem backup for our source code 
 projects that archive specified folders and save a snapshot of them every time we 
 make a change. The change could be when we tweak a file and save it, or if we add new 
 files and folders, or even if we delete a file. We want to be able to go back to any point 
 in time to retrieve old files.
  
 Specifically in this chapter, you will learn:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 How to structure projects that consist of packages and 
  
 command-line tools 
  
 A pragmatic approach to persisting simple data across tool executions 
 How the 
 os
  package allows you to interact with a filesystem 
  
 How to run code in an infinite timed loop, while respecting 
 Ctrl
  + 
 C 
 How 
 to use 
 filepath.Walk
  to iterate over files and folders 
  
 How to quickly determine if the contents of a directory have changed 
 How to use the 
 archive/zip
  package to zip files 
  
 How to build tools that care about a combination of command-line flags 
 and normal arguments",NA
Solution design,"We will start by listing some high-level acceptance criteria for our solution and the 
 approach we want to take:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 The solution should create a snapshot of our files at regular intervals, as 
 we make changes to our source code projects
  
 We want to control the interval at which the directories are checked for 
 changes
  
 Code projects are primarily text-based, so zipping the directories to 
 generate archives will save a lot of space
  
 We will build this project quickly, while keeping a close watch over 
 where we might want to make improvements later
  
 Any implementation decisions we make should be easily modified if 
 we decide to change our implementation in the future
  
 We will build two command-line tools, the backend daemon that does 
 the work, and a user interaction utility that will let us list, add, and 
 remove paths from the backup service",NA
Project structure,"It is common in Go solutions to have, in a single project, both a package that allows other 
 Go programmers to use your capabilities, and a command-line tool that allows end users 
 to use your code.
  
 A convention is emerging to structure the project by having the package in the main 
 project folder, and the command-line tool inside a subfolder called 
 cmd
 , or 
 cmds
  if you 
 have multiple commands. Because all packages (regardless of the directory tree) are 
 equal in Go, you can import the main package from the subpackages, knowing you'll 
 never need to import the commands from the main package. This may seem like an 
 unnecessary abstraction, but is actually quite a common pattern and can be seen in the 
 standard Go tool chain with examples such as 
 gofmt
  and 
 goimports
 .
  
 For example, for our project we are going to write a package called 
 backup
 , and two 
 command-line tools: the daemon and the user interaction tool. We will structure our 
 project in the following way:
  
 /backup - package
  
 /backup/cmds/backup – user interaction tool
  
 /backup/cmds/backupd – worker daemon
  
 [
  326 
 ]",NA
Backup package,"We are first going to write the 
 backup
  package, of which we will become the first 
 customer when we write the associated tools. The package will be responsible for 
 deciding whether directories have changed and need backing up or not, as well as 
 actually performing the backup procedure too.",NA
Obvious interfaces?,"The first thing to think about when embarking on a new Go program is whether any 
 interfaces stand out to you. We don't want to over-abstract or waste too much time up 
 front designing something that we know will change as we start to code, but that doesn't 
 mean we shouldn't look for obvious concepts that are worth pulling out. 
  
 Since our code will archive files, the 
 Archiver
  interface pops out as a candidate.
  
 Create a new folder inside your 
 GOPATH
  called 
 backup
 , and add the following 
 archiver.go
  code:
  
 package backup
  
 type Archiver interface {
  
  Archive(src, dest string) error
  
 }
  
 An 
 Archiver
  interface will specify a method called 
 Archive
  that takes source and 
 destination paths and returns an error. Implementations of this interface will be 
 responsible for archiving the source folder, and storing it in the destination path.
  
  
 Defining an interface up front is a nice way to get some concepts out 
  
  
 of our heads and into code; it doesn't mean this interface can't change 
  
 as we evolve our solution as long as we remember the power of simple 
  
 interfaces. Also, remember that most of the I/O interfaces in the 
 io
  
 package expose only a single method.
  
 From the very beginning, we have made the case that while we are going to 
 implement ZIP files as our archive format, we could easily swap this out later with 
 another kind of 
 Archiver
  format.
  
 [
  327 
 ]",NA
Implementing ZIP,"Now that we have the interface for our 
 Archiver
  types, we are going to implement one 
 that uses the ZIP file format.
  
 Add the following 
 struct
  definition to 
 archiver.go
 :
  
 type zipper struct{}
  
 We are not going to export this type, which might make you jump to the conclusion that 
 users outside of the package won't be able to make use of it. In fact, we are going to 
 provide them with an instance of the type for them to use, to save them from having to 
 worry about creating and managing their own types.
  
 Add the following exported implementation:
  
 // Zip is an Archiver that zips and unzips files.
  
 var ZIP Archiver = (*zipper)(nil)
  
 This curious snippet of Go voodoo is actually a very interesting way of exposing the 
 intent to the compiler, without using any memory (literally 0 bytes). We are defining a 
 variable called 
 ZIP
  of type 
 Archiver
 , so from outside the package it's pretty clear that 
 we can use that variable wherever 
 Archiver
  is needed—if you want to zip things. 
  
 Then we assign it with 
 nil
  cast to the type 
 *zipper
 . We know that 
 nil
  takes no 
 memory, but since it's cast to a 
 zipper
  pointer, and given that our 
 zipper
  struct has no 
 fields, it's an appropriate way of solving a problem, which hides the complexity of code 
 (and indeed the actual implementation) from outside users. There is no reason anybody 
 outside of the package needs to know about our 
 zipper
  type at all, which frees us up to 
 change the internals without touching the externals at any time; the true power of 
 interfaces.
  
 Another handy side benefit to this trick is that the compiler will now be checking 
 whether our zipper type properly implements the 
 Archiver
  interface or not, so if 
 you try to build this code you'll get a compiler error:
  
 ./archiver.go:10: cannot use (*zipper)(nil) (type *zipper) as type Archiver in assignment:
  
  *zipper does not implement Archiver (missing Archive method)
  
 We see that our 
 zipper
  type does not implement the 
 Archive
  method as mandated in 
 the interface.
  
 [
  328 
 ]",NA
Has the filesystem changed?,"One of the biggest problems our backup system has is deciding whether a folder has 
 changed or not in a cross-platform, predictable, and reliable way. A few things spring 
 to mind when we think about this problem: should we just check the last modified date 
 on the top-level folder? Should we use system notifications to be informed whenever a 
 file we care about changes? There are problems with both of these approaches, and it 
 turns out it's not a trivial problem to solve.
  
 We are instead going to generate an MD5 hash made up of all of the information that 
 we care about when considering whether something has changed or not.
  
 Looking at the 
 os.FileInfo
  type, we can see that we can find out a lot of 
 information about a file:
  
 type FileInfo interface {
  
  Name() string       // base name of the file
  
  Size() int64        // length in bytes for regular files; 
  
  system-dependent for others
  
  Mode() FileMode     // file mode bits
  
  ModTime() time.Time // modification time
  
  IsDir() bool        // abbreviation for Mode().IsDir()
  
  Sys() interface{}   // underlying data source (can return nil)
  
 }
  
 To ensure we are aware of a variety of changes to any file in a folder, the hash will be 
 made up of the filename and path (so if they rename a file, the hash will be different), size 
 (if a file changes size, it's obviously different), last modified date, whether the item is a file 
 or folder, and file mode bits. Even though we won't be archiving the folders, we still care 
 about their names and the tree structure of the folder.
  
 Create a new file called 
 dirhash.go
  and add the following function:
  
 package backup
  
 import (
  
  ""crypto/md5""
  
 [
  331 
 ]",NA
Checking for changes and initiating a backup ,"Now 
 that we have the ability to hash a folder, and to perform a backup, we are going to put the 
 two together in a new type called 
 Monitor
 . The 
 Monitor
  type will have a map of paths 
 with their associated hashes, a reference to any 
 Archiver
  type (of course, we'll use 
 backup.ZIP
  for now), and a destination string representing where to put the archives.
  
 Create a new file called 
 monitor.go
  and add the following definition:
  
 type Monitor struct {
  
  
  Paths       map[string]string
  
  
  Archiver    Archiver
  
  
  Destination string 
  
 }
  
 In order to trigger a check for changes, we are going to add the following 
 Now 
 method:
  
 func (m *Monitor) Now() (int, error) {
  
  
  var counter int
  
  
  for path, lastHash := range m.Paths {
  
  
  newHash, err := DirHash(path)
  
  
  if err != nil {
  
    
  return 0, err
  
  
  }
  
  
  if newHash != lastHash {
  
    
  err := m.act(path)
  
    
  if err != nil {
  
     
  return counter, err
  
    
  }
  
    
  m.Paths[path] = newHash // update the hash
    
  counter++
  
  
  }
  
  
  }
  
  
  return counter, nil 
  
 }
  
 The 
 Now
  method iterates over every path in the map and generates the latest hash of 
 that folder. If the hash does not match the hash from the map (generated the last time it 
 checked), then it is considered to have changed, and needs backing up again. We do this 
 with a call to the as yet unwritten 
 act
  method, before then updating the hash in the map 
 with this new hash.
  
 [
  333 
 ]",NA
Hardcoding is OK for a short while,"Hardcoding the file extension like we have is OK in the beginning, but if you think 
 about it we have blended concerns a little here. If we change the 
 Archiver 
 implementation to use RAR or a compression format of our making, the 
 .zip 
 extension would no longer be appropriate.
  
  
 Before reading on, think about what steps you might take to 
  
  
 avoid hardcoding. Where does the filename extension decision 
  
 live? What changes would you need to make in order to avoid 
  
 hardcoding properly?
  
 [
  334 
 ]",NA
The user command-line tool,"The first of two tools we will build allows the user to add, list, and remove paths for 
 the backup daemon tool (which we will write later). You could expose a web 
 interface, or even use the binding packages for desktop user interface integration, 
 but we are going to keep things simple and build ourselves a command-line tool.
  
 Create a new folder called 
 cmds
  inside the 
 backup
  folder and create another 
 backup 
 folder inside that.
  
  
 It's good practice to name the folder of the command and the 
  
  
 command binary itself the same.
  
 [
  335 
 ]",NA
Persisting small data ,"In order to keep track of the paths, and the hashes that we generate, we will need some 
 kind of data storage mechanism that ideally works even when we stop and start our 
 programs. We have lots of choices here: everything from a text file to a full horizontally 
 scalable database solution. The Go ethos of simplicity tells us that building-in a database 
 dependency to our little backup program would not be a great idea; rather we should ask 
 what is the simplest way we can solve this problem?
  
 The 
 github.com/matryer/filedb
  package is an experimental solution for just this 
 kind of problem. It lets you interact with the filesystem as though it were a very simple 
 schemaless database. It takes its design lead from packages such as 
 mgo
 , and can be used 
 in the cases where data querying needs are very simple. In 
 filedb
 , a database is a 
 folder, and a collection is a file where each line represents a different record. Of course, 
 this could all change as the 
 filedb
  project evolves, but the interface hopefully won't.
  
 [
  336 
 ]",NA
Parsing arguments ,"When we call 
 flag.Args
  (as opposed to 
 os.Args
 ), we receive a slice of arguments 
 excluding the flags. This allows us to mix flag arguments and non-flag arguments in the 
 same tool.
  
 We want our tool to be able to be used in the following ways:
  
 • 
  
 To add a path:
  
 backup -db=/path/to/db add {path} [paths...]
  
 [
  337 
 ]",NA
Listing the paths ,"To list the paths in the database, we are going to use a 
 ForEach
  method on the 
 path's 
 col
  variable. Add the following code to the list case:
  
 var path path 
  
 col.ForEach(func(i int, data []byte) bool {
  
  
  err := json.Unmarshal(data, &path)
  
  
  if err != nil {
  
  
  fatalErr = err
  
  
  return false
  
  
  }
  
  
  fmt.Printf(""= %s\n"", path)
  
  
  return false 
  
 })
  
 We pass in a callback function to 
 ForEach
  that will be called for every item in that 
 collection. We then 
 Unmarshal
  it from JSON, into our 
 path
  type, and just print it out 
 using 
 fmt.Printf
 . We return 
 false
  as per the 
 filedb
  interface, which tells us that 
 returning 
 true
  would stop iterating and that we want to make sure we list them all.
  
 [
  338 
 ]",NA
String representations for your own types,"If you print structs in Go in this way, using the 
 %s
  format verbs, you can get some 
 messy results that are difficult for users to read. If, however, the type implements a 
 String()
  string method, that will be used instead and we can use this to control what 
 gets printed. Below the path struct, add the following method:
  
 func (p path) String() string {
  
  return fmt.Sprintf(""%s [%s]"", p.Path, p.Hash)
  
 }
  
 This tells the 
 path
  type how it should represent itself as a string.",NA
Adding paths,"To add a path, or many paths, we are going to iterate over the remaining arguments and 
 call the 
 InsertJSON
  method for each one. Add the following code to the 
 add
  case:
  
 if len(args[1:]) == 0 {
  
  fatalErr = errors.New(""must specify path to add"")
  
  return
  
 }
  
 for _, p := range args[1:] {
  
  path := &path{Path: p, Hash: ""Not yet archived""}
  
  if err := col.InsertJSON(path); err != nil {
  
  fatalErr = err
  
  return
  
  }
  
  fmt.Printf(""+ %s\n"", path)
  
 }
  
 If the user hasn't specified any additional arguments, like if they just called 
 backup add
  
 without typing any paths, we will return a fatal error. Otherwise, we do the work and 
 print out the path string (prefixed with a 
 +
  symbol) to indicate that it was successfully 
 added. By default, we'll set the hash to the 
 Not yet archived
  string literal—this is an 
 invalid hash but serves the dual purposes of letting the user know that it hasn't yet been 
 archived, as well as indicating as such to our code (given that a hash of the folder will 
 never equal that string).
  
 [
  339 
 ]",NA
Removing paths ,"To remove a path, or many paths, we use the 
 RemoveEach
  method for the path's 
 collection. Add the following code to the 
 remove
  case:
  
 var path path 
  
 col.RemoveEach(func(i int, data []byte) (bool, bool) 
 {
  
  err := json.Unmarshal(data, &path)
  
  
  if err != nil {
  
  
  fatalErr = err
  
  
  return false, true
  
  
  }
  
  
  for _, p := range args[1:] {
  
  
  if path.Path == p {
  
    
  fmt.Printf(""- %s\n"", path)
  
    
  return true, false
  
  
  }
  
  
  }
  
  
  return false, false 
  
 })
  
 The callback function we provide to 
 RemoveEach
  expects us to return two bool 
 types: the first one indicates whether the item should be removed or not, and the 
 second one indicates whether we should stop iterating or not.",NA
Using our new tool ,"We have completed our simple 
 backup
  command-line tool. Let's see it in action. 
 Create a folder called 
 backupdata
  inside 
 backup/cmds/backup
 ; this will become 
 the 
 filedb
  database.
  
 Build the tool in a terminal by navigating to the 
 main.go
  file and running:
  
 go build -o backup
  
 If all is well, we can now add a path:
  
 ./backup -db=./backupdata add ./test ./test2
  
 You should see the expected output:
  
 + ./test [Not yet archived]
  
 + ./test2 [Not yet archived]
  
 [
  340 
 ]",NA
The daemon backup tool ,"The 
 backup
  tool, which we will call 
 backupd
 , will be responsible for periodically 
 checking the paths listed in the 
 filedb
  database, hashing the folders to see whether 
 anything has changed, and using the 
 backup
  package to actually perform the archiving 
 of folders that need it.
  
 Create a new folder called 
 backupd
  alongside the 
 backup/cmds/backup
  folder, 
 and let's jump right into handling the fatal errors and flags: 
  
  
 func main() {
  
  
  
  var fatalErr error
  
  
  
  defer func() {
  
  
  
  if fatalErr != nil {
  
 [
  341 
 ]",NA
Duplicated structures,"Since we're going to use the same path structure as in our user command-line tool 
 program, we need to include a definition of it for this program too. Insert the 
 following structure above the 
 main
  function:
  
 type path struct {
  
  Path string
  
  Hash string
  
 }
  
 The object-oriented programmers out there are no doubt by now screaming at the 
 pages demanding for this shared snippet to exist in one place only and not be 
 duplicated in both programs. I urge you to resist this compulsion of early abstraction. 
 These four lines of code hardly justify a new package and therefore dependency for 
 our code, when they can just as easily exist in both programs with very little overhead. 
 Consider also that we might want to add a 
 LastChecked
  field to our 
 backupd
  program 
 so that we could add rules where each folder only gets archived at most once an hour. 
 Our 
 backup
  program doesn't care about this and will chug along perfectly happy with 
 its view into what fields constitute a path.",NA
Caching data,"We can now query all existing paths and update the 
 Paths
  map, which is a useful 
 technique to increase the speed of a program, especially given slow or disconnected 
 data stores. By loading the data into a cache (in our case, the 
 Paths 
 map), we can 
 access it at lightening speeds without having to consult the files each time we need 
 information.
  
 [
  343 
 ]",NA
Infinite loops ,"The next thing we need to do is to perform a check on the hashes right away to see 
 whether anything needs archiving, before entering into an infinite timed loop 
 where we check again at regular specified intervals.
  
 An infinite loop sounds like a bad idea; in fact to some it sounds like a bug. 
 However, since we're talking about an infinite loop within this program, and since 
 infinite loops can be easily broken with a simple 
 break
  command, they're not as 
 dramatic as they might sound.
  
 [
  344 
 ]",NA
Updating filedb records ,"All that is left is for us to implement the 
 check
  function that should call the 
 Now 
 method on the 
 Monitor
  type and update the database with new hashes if there are 
 any.
  
 Underneath the 
 main
  function, add the following code:
  
 func check(m *backup.Monitor, col *filedb.C) {
  
  
  log.Println(""Checking..."")
  
  
  counter, err := m.Now()
  
  
  if err != nil {
  
  
  log.Fatalln(""failed to backup:"", err)
  
  
  }
  
  
  if counter > 0 {
  
  
  log.Printf(""  Archived %d directories\n"", counter)
  
  
  // update hashes
  
  
  var path path
  
  
  col.SelectEach(func(_ int, data []byte) (bool, []byte, bool) {
    
  if err := json.Unmarshal(data, &path); err != nil {
  
     
  log.Println(""failed to unmarshal data (skipping):"", err)
     
  return true, data, false
  
    
  }
  
    
  path.Hash, _ = m.Paths[path.Path]
  
    
  newdata, err := json.Marshal(&path)
  
    
  if err != nil {
  
     
  log.Println(""failed to marshal data (skipping):"", err)
  
    
  return true, data, false
  
    
  }
  
    
  return true, newdata, false
  
  
  })
  
  
  } else {
  
  
  log.Println(""  No changes"")
  
  
  } 
  
 }
  
 [
  346 
 ]",NA
Testing our solution,"Let's see whether our two programs play nicely together and what affects the code 
 inside our 
 backup
  package. You may want to open two terminal windows for this, 
 since we'll be running two programs.
  
 We have already added some paths to the database, so let's use 
 backup
  to see them:
  
 ./backup -db=""./backupdata"" list
  
 You should see the two test folders; if you don't, refer back to the 
 Adding paths 
 section.
  
 = ./test [Not yet archived]
  
 = ./test2 [Not yet archived]
  
 In another window, navigate to the 
 backupd
  folder and create our two test folders 
 called 
 test
  and 
 test2
 .
  
 Build 
 backupd
  using the usual method:
  
 go build -o backupd
  
 Assuming all is well, we can now start the backup process being sure to point the 
 db
  
 path to the same path as we used for the 
 backup
  program, and specify that we want to 
 use a new folder called 
 archive
  to store the ZIP files. For testing purposes, let's 
 specify an interval of 
 5
  seconds to save time:
  
 ./backupd -db=""../backup/backupdata/"" -archive=""./archive"" - interval=5
  
 Immediately, 
 backupd
  should check the folders, calculate the hashes, notice that they 
 are different (to 
 Not yet archived
 ), and initiate the archive process for both folders. 
 It will print the output telling us this:
  
 Checking...
  
 Archived 2 directories
  
 [
  347 
 ]",NA
Summary,"In this chapter, we successfully built a very powerful and flexible backup system for 
 your code projects. You can see how simple it would be to extend or modify the 
 behavior of these programs. The scope for potential problems that you could go on to 
 solve is limitless.
  
 Rather than having a local archive destination folder like we did in the previous section, 
 imagine mounting a network storage device and using that instead. Suddenly, you have 
 off-site (or at least off-machine) backups of those vital files. You could easily set a 
 Dropbox folder as the archive destination, which would mean not only do you get access 
 to the snapshots yourself, but also a copy is stored in the cloud and can even be shared 
 with other users.
  
 Extending the 
 Archiver
  interface to support 
 Restore
  operations (which would just use 
 the 
 encoding/zip
  package to unzip the files) allows you to build tools that can peer 
 inside the archives and access the changes of individual files much like Time Machine 
 allows you to do. Indexing the files gives you full search across the entire history of your 
 code, much like GitHub does.
  
 [
  348 
 ]",NA
Module 3,"Mastering Concurrency in Go
  
 Discover and harness Go's powerful concurrency features to develop and build fast, 
  
 scalable network systems",NA
An Introduction to ,NA,NA
Concurrency in Go,"While Go is both a great general purpose and low-level systems language, one of its 
 primary strengths is the built-in concurrency model and tools. Many other 
 languages have third-party libraries (or extensions), but inherent concurrency is 
 something unique to modern languages, and it is a core feature of Go's design.
  
 Though there's no doubt that Go excels at concurrency—as we'll see in this 
 book—what it has that many other languages lack is a robust set of tools to 
 test and build concurrent, parallel, and distributed code.
  
 Enough talk about Go's marvelous concurrency features and tools, let's jump in.",NA
Introducing goroutines,"The primary method of handling concurrency is through a goroutine. Admittedly, our 
 first piece of concurrent code (mentioned in the preface) didn't do a whole lot, simply 
 spitting out alternating ""hello""s and ""world""s until the entire task was complete.",NA
A patient goroutine,"From here, we'll implement a 
 WaitGroup
  struct to ensure our goroutines run entirely 
 before moving on with our application. In this case, when we say patient, it's in contrast to 
 the way we've seen goroutines run outside of a parent method with our previous 
 example. In the following code, we will implement our first 
 Waitgroup 
 struct:
  
 package main
  
 import (
  
  ""fmt""
  
  ""sync""
  
  ""time""
  
 )
  
 [
  355 
 ]",NA
Implementing the defer control ,NA,NA
mechanism,"While we're here, we should take a moment and talk about defer. Go has an elegant 
 implementation of the defer control mechanism. If you've used defer (or something 
 functionally similar) in other languages, this will seem familiar—it's a useful way of 
 delaying the execution of a statement until the rest of the function is complete.
  
 [
  357 
 ]",NA
Using Go's scheduler,"With a lot of concurrent and parallel applications in other languages, the 
  
 management of both soft and hard threads is handled at the operating system level. This 
 is known to be inherently inefficient and expensive as the OS is responsible for context 
 switching, among multiple processes. When an application or process can manage its 
 own threads and scheduling, it results in faster runtime. The threads granted to our 
 application and Go's scheduler have fewer OS attributes that need to be considered in 
 context to switching, resulting in less overhead.
  
 If you think about it, this is self-evident—the more you have to juggle, the slower it is 
 to manage all of the balls. Go removes the natural inefficiency of this mechanism by 
 using its own scheduler.
  
 There's really only one quirk to this, one that you'll learn very early on: if you don't 
 ever yield to the main thread, your goroutines will perform in unexpected ways (or 
 won't perform at all).
  
 [
  359 
 ]",NA
Using system variables,"So what if you want to know how many threads your code has made available to you?
  
 Go has an environment variable returned from the runtime package function 
 GOMAXPROCS
 . To find out what's available, you can write a quick application similar to 
 the following code:
  
 package main
  
 import (
  
  
  ""fmt""
  
  
  ""runtime"" 
  
 )
  
 func listThreads() int {
  
  
  threads := 
 runtime.GOMAXPROCS(0)
  
  
  return threads 
  
 }
  
 func main() {
  
  runtime.GOMAXPROCS(2)
  
  fmt.Printf(""%d thread(s) available to Go."", listThreads())
  
 }
  
 A simple Go build on this will yield the following output:
  
 2 thread(s) available to Go.
  
 The 
 0
  parameter (or no parameter) delivered to 
 GOMAXPROCS
  means no change is 
 made. You can put another number in there, but as you might imagine, it will only 
 return what is actually available to Go. You cannot exceed the available cores, but you 
 can limit your application to use less than what's available.
  
 [
  364 
 ]",NA
Understanding goroutines versus ,NA,NA
coroutines,"At this point, you may be thinking, ""Ah, goroutines, I know these as coroutines."" Well, 
 yes and no.
  
 A coroutine is a cooperative task control mechanism, but in its most simplistic sense, a 
 coroutine is not concurrent. While coroutines and goroutines are utilized in similar 
 ways, Go's focus on concurrency provides a lot more than just state control and yields. 
 In the examples we've seen so far, we have what we can call 
 dumb
  goroutines. 
  
 Although they operate in the same time and address space, there's no real 
  
 communication between the two. If you look at coroutines in other languages, you may 
 find that they are often not necessarily concurrent or asynchronous, but rather they 
 are step-based. They yield to 
 main()
  and to each other, but two coroutines might not 
 necessarily communicate between each other, relying on a centralized, explicitly 
 written data management system.
  
 [
  365 
 ]",NA
Implementing channels,"So far, we've dabbled in concurrent processes that are capable of doing a lot but not 
 effectively communicating with each other. In other words, if you have two processes 
 occupying the same processing time and sharing the same memory and data, you must 
 have a way of knowing which process is in which place as part of a larger task.
  
 Take, for example, an application that must loop through one paragraph of Lorem 
 Ipsum and capitalize each letter, then write the result to a file. Of course, we will not 
 really need a concurrent application to do this (and in fact, it's an endemic function of 
 almost any language that handles strings), but it's a quick way to demonstrate the 
 potential limitations of isolated goroutines. Shortly, we'll turn this primitive example 
 into something more practical, but for now, here's the beginning of our capitalization 
 example:
  
 package main
  
 import (
  
  ""fmt""
  
  ""runtime""
  
  ""strings""
  
 )
  
 [
  366 
 ]",NA
Channel-based sorting at the letter ,NA,NA
capitalization factory ,"Let's take the last example and do something (slightly) more purposeful by 
 attempting to capitalize the preamble of Abraham Lincoln's Gettysburg address 
 while mitigating the sometimes unpredictable effect of concurrency in Go, as shown 
 in the following code:
  
 package main
  
 import(
  
  
  ""fmt""
  
  
  ""sync""
  
  
  ""runtime""
  
  
  ""strings"" 
  
 )
  
 var initialString string 
  
 var finalString string
  
 var stringLength int
  
 func addToFinalStack(letterChannel chan string, wg 
  
  *sync.WaitGroup) {
  
  
  letter := <-letterChannel
  
  
  finalString += letter
  
  
  wg.Done() 
  
 }
  
 func capitalize(letterChannel chan string, currentLetter string, 
  
  wg *sync.WaitGroup) {
  
  thisLetter := strings.ToUpper(currentLetter)
  
 [
  369 
 ]",NA
Cleaning up our goroutines,"You may be wondering why we need a 
 WaitGroup
  struct when using channels. 
 After all, didn't we say that a channel gets blocked until it receives data? This is 
 true, but it requires one other piece of syntax.
  
 A nil or uninitialized channel will always get blocked. We will discuss the potential uses 
 and pitfalls of this in 
 Chapter 7
 , 
 Performance and Scalability
 , and 
 Chapter 10
 , 
 Advanced 
 Concurrency and Best Practices
 .
  
 You have the ability to dictate how a channel blocks the application based on a 
 second option to the 
 make
  command by dictating the channel buffer.",NA
Buffered or unbuffered channels,"By default, channels are unbuffered, which means they will accept anything sent on 
 them if there is a channel ready to receive. It also means that every channel call will 
 block the execution of the application. By providing a buffer, the channel will only block 
 the application when many returns have been sent.
  
 A buffered channel is synchronous. To guarantee asynchronous performance, 
 you'll want to experiment by providing a buffer length. We'll look at ways to 
 ensure our execution falls as we expect in the next chapter.
  
  
 Go's channel system is based on 
 Communicating Sequential 
  
  
 Processes
  (
 CSP
 ), a formal language to design concurrent patterns 
  
 and multiprocessing. You will likely encounter CSP on its own 
  
 when people describe goroutines and channels.",NA
Using the select statement,"One of the issues with first implementing channels is that whereas goroutines were 
 formerly the method of simplistic and concurrent execution of code, we now have a 
 single-purpose channel that dictates application logic across the goroutines. Sure, the 
 channel is the traffic manager, but it never knows when traffic is coming, when it's no 
 longer coming, and when to go home, unless being explicitly told. It waits passively for 
 communication and can cause problems if it never receives any.
  
 [
  373 
 ]",NA
Closures and goroutines ,"You may have noticed the anonymous goroutine in Lorem Ipsum:
  
  go func() {
  
  go capitalize(index, length, letters, &finalIpsum) 
 }()
  
 While it isn't always ideal, there are plenty of places where inline functions work 
 best in creating a goroutine.
  
 [
  377 
 ]",NA
Building a web spider using goroutines ,NA,NA
and channels ,"Let's take the largely useless capitalization application and do something practical with 
 it. Here, our goal is to build a rudimentary spider. In doing so, we'll accomplish the 
 following tasks:
  
 • 
  
 Read five URLs
  
 • 
  
 Read those URLs and save the contents to a string
  
 • 
  
 Write that string to a file when all URLs have been scanned and read
  
 These kinds of applications are written every day, and they're the ones that benefit the 
 most from concurrency and non-blocking code.
  
 It probably goes without saying, but this is not a particularly elegant web scraper. For 
 starters, it only knows a few start points—the five URLs that we supply it. Also, it's 
 neither recursive nor is it thread-safe in terms of data integrity.
  
 That said, the following code works and demonstrates how we can use channels and 
 the 
 select
  statements:
  
 package main
  
 import(
  
  
  ""fmt""
  
  
  ""io/ioutil""
  
  
  ""net/http""
  
  
  ""time"" 
  
 )
  
 [
  379 
 ]",NA
Summary,"In this chapter, we learned how to go from simple goroutines and instantiating channels 
 to extending the basic functionality of goroutines and allowing cross-channel, 
 bidirectional communication within concurrent processes. We looked at new ways to 
 create blocking code to prevent our main process from ending before our goroutines. 
 Finally, we learned about using select statements to develop reactive channels that are 
 silent unless data is sent along a channel.
  
 In our rudimentary web spider example, we employed these concepts together to 
 create a safe, lightweight process that could extract all links from an array of URLs, 
 grab the content via HTTP, and store the resulting response.
  
 In the next chapter, we'll go beneath the surface to see how Go's internal scheduling 
 manages concurrency and start using channels to really utilize the power, thrift, and 
 speed of concurrency in Go.
  
 [
  384 
 ]",NA
Understanding the ,NA,NA
Concurrency Model,"Now that we have a sense of what Go is capable of and how to test drive some 
 concurrency models, we need to look deeper into Go's most powerful features to 
 understand how to best utilize various concurrent tools and models.
  
 We played with some general and basic goroutines to see how we can run concurrent 
 processes, but we need to see how Go manages scheduling in concurrency before we get 
 to communication between channels.",NA
Understanding the working of goroutines,"By this point, you should be well-versed in what goroutines do, but it's worth 
 understanding 
 how
  they work internally in Go. Go handles concurrency with 
 cooperative scheduling, which, as we mentioned in the previous chapter, is 
 heavily dependent on some form of blocking code.
  
 The most common alternative to cooperative scheduling is preemptive scheduling, 
 wherein each subprocess is granted a space of time to complete and then its execution 
 is paused for the next.
  
 Without some form of yielding back to the main thread, execution runs into 
  
 issues. This is because Go works with a single process, working as a conductor for an 
 orchestra of goroutines. Each subprocess is responsible for announcing its own 
 completion. As compared to other concurrency models, some of which allow for direct, 
 named communication, this might pose a sticking point, particularly if you haven't 
 worked with channels before.",NA
Synchronous versus asynchronous ,NA,NA
goroutines,"Understanding the concurrency model is sometimes an early pain point for 
 programmers—not just for Go, but across languages that use different models as 
 well. Part of this is due to operating in a 
 black box
  (depending on your terminal 
 preferences); a developer has to rely on logging or errors with data consistency to 
 discern asynchronous and/or multiple core timing issues.
  
 As the concepts of synchronous and asynchronous or concurrent and nonconcurrent 
 tasks can sometimes be a bit abstract, we will have a bit of fun here in an effort to 
 demonstrate all the concepts we've covered so far in a visual way.
  
 There are, of course, a myriad of ways to address feedback and logging. You can write to 
 files in 
 console/terminal/stdout…
 , most of which are inherently linear in nature. 
 There is no concise way to represent concurrency in a logfile. Given this and the fact that 
 we are dealing with an emerging language with a focus on servers, let's take a different 
 angle.
  
 Instead of simply outputting to a file, we'll create a visual feedback that shows 
 when a process starts and stops on a timeline.",NA
Designing the web server plan,"To show how approaches differ, we'll create a simple web server that loops through 
 three trivial tasks and outputs their execution marks on an X-second timeline. We'll do 
 this using a third-party library called 
 svgo
  and the built-in 
 http
  package for Go.
  
 To start, let's grab the 
 svgo
  library via 
 go get
 :
  
 go get github.com/ajstarks/svgo
  
 [
  386 
 ]",NA
Visualizing concurrency,"Our first attempt at visualizing concurrency will have two simple goroutines running the 
 drawPoint
  function in a loop with 100 iterations. After running this, you can visit 
 localhost:1900/visualize
  and see what concurrent goroutines look like.
  
 If you run into problems with port 1900 (either with your firewall or through a port 
 conflict), feel free to change the value on line 99 in the 
 main()
  function. You may also 
 need to access it through 
 127.0.0.1
  if your system doesn't resolve localhost.
  
 [
  388 
 ]",NA
RSS in action,"Let's take the concept of 
 Rich Site Summary
  / 
 Really Simple Syndication
  (
 RSS
 ) and 
 inject some real potential delays to identify where we can best utilize goroutines in an 
 effort to speed up execution and prevent blocking code. One common way to bring real-
 life, potentially blocking application elements into your code is to use something 
 involving network transmission.
  
 This is also a great place to look at timeouts and close channels to ensure that our 
 program doesn't fall apart if something takes too long.
  
 To accomplish both these requirements, we'll build a very basic RSS reader that will 
 simply parse through and grab the contents of five RSS feeds. We'll read each of these as 
 well as the provided links on each, and then we'll generate an SVG report of the process 
 available via HTTP.
  
 [
  393 
 ]",NA
An RSS reader with self diagnostics,"Let's take a look at what we've learned so far, and use it to fetch and parse a set of RSS 
 feeds concurrently while returning some visual feedback about the process in an 
 internal web browser, as shown in the following code:
  
 package main
  
 import(
  
  
  ""github.com/ajstarks/svgo""
  
  
  rss ""github.com/jteeuwen/go-pkg-rss""    
  
  
  ""net/http""
  
  
  ""log""
  
  
  ""fmt""
  
  
  ""strconv""
  
  
  ""time""
  
  
  ""os""
  
  
  ""sync""
  
  
  ""runtime"" 
  
 )
  
 type Feed struct 
 {
  
  url string
  
  status int
  
  itemCount int
  
 [
  394 
 ]",NA
Imposing a timeout,"So what happens if nothing runs within our timeline? As you might expect, we'll get 
 three bars with no activity in them. It's important to consider how to kill processes that 
 aren't doing what we expect them to. In this case, the best method is a timeout. 
  
 The 
 Get
  method in the 
 http
  package does not natively support a timeout, so you'll have 
 to roll your own 
 rssFeed.Fetch
  (and underlying 
 http.Get()
 ) implementation if you 
 want to prevent these requests from going into perpetuity and killing your application. 
 We'll dig into this a bit later; in the mean time, take a look at the 
  
 Transport
  struct, available in the core 
 http
  package at 
 http://golang.org/pkg/ 
 net/http/#Transport
 .",NA
A little bit about CSP,"We touched on CSP briefly in the previous chapter, but it's worth exploring a bit 
 more in the context of how Go's concurrency model operates.
  
 CSP evolved in the late 1970s and early 1980s through the work of Sir Tony Hoare and 
 is still in the midst of evolution today. Go's implementation is heavily based on CSP, but 
 it neither entirely follows all the rules and conventions set forth in its initial description 
 nor does it follow its evolution since.
  
 One of the ways in which Go differs from true CSP is that as it is defined, a process in 
 Go will only continue so long as there exists a channel ready to receive from that 
 process. We've already encountered a couple of deadlocks that were the result of a 
 listening channel with nothing to receive. The inverse is also true; a deadlock can 
 result from a channel continuing without sending anything, leaving its receiving 
 channel hanging indefinitely.
  
 This behavior is endemic to Go's scheduler, and it should really only pose problems 
 when you're working with channels initially.
  
  
 Hoare's original work is now available (mostly) free from a number of 
  
  
 institutions. You can read, cite, copy, and redistribute it free of charge 
  
 (but not for commercial gain). If you want to read the whole thing, 
  
 you can grab it at 
 http://www.cs.ucf.edu/courses/cop4020/
  
 sum2009/CSP-hoare.pdf
 .
  
 The complete book itself is also available at 
 http://www.
  
 usingcsp.com/cspbook.pdf
 .
  
 As of this publishing, Hoare is working as a researcher at Microsoft.
  
 [
  401 
 ]",NA
The dining philosophers problem,"You may have heard of the dining philosophers problem, which describes the kind of 
 problems concurrent programming was designed to solve. The dining philosophers 
 problem was formulated by the great Edsger Dijkstra. The crux of the problem is a 
 matter of resources—five philosophers sit at a table with five plates of food and five 
 forks, and each can only eat when he has two forks (one to his left and another to his 
 right). A visual representation is shown as follows:
  
  
 With a single fork on either side, any given philosopher can only eat when he has a fork 
 in both hands and must put both back on the table when complete. The idea is to 
 coordinate the meal such that all of the philosophers can eat in perpetuity without any 
 starving—two philosophers must be able to eat at any moment and there can be no 
 deadlocks. They're philosophers because when they're not eating, they're thinking. In a 
 programming analog, you can consider this as either a waiting channel or a sleeping 
 process.
  
 [
  402 
 ]",NA
Go and the actor model,"The actor model is something that you'll likely be very familiar with if you're an Erlang or 
 Scala user. The difference between CSP and the actor model is negligible but important. 
 With CSP, messages from one channel can only be completely sent if another channel is 
 listening and ready for them. The actor model does not necessarily require a ready 
 channel for another to send. In fact, it stresses direct communication rather than relying 
 on the conduit of a channel.
  
 Both systems can be nondeterministic, which we've already seen demonstrated in 
 Go/CSP in our earlier examples. CSP and goroutines are anonymous and 
 transmission is specified by the channel rather than the source and destination. 
  
 An easy way to visualize this in pseudocode in the actor model is as follows:
  
 a = new Actor
  
 b = new Actor
  
 a -> b(""message"")
  
 In CSP, it is as follows:
  
 a = new Actor
  
 b = new Actor
  
 c = new Channel
  
 a -> c(""sending something"")
  
 b <- c(""receiving something"")
  
 Both serve the same fundamental functionality but through slightly different ways.",NA
Object orientation,"As you work with Go, you will notice that there is a core characteristic that's often 
 espoused, which users may feel is wrong. You'll hear that Go is not an object-oriented 
 language, and yet you have structs that can have methods, those methods in turn can 
 have methods, and you can have communication to and from any instantiation of it. 
 Channels themselves may feel like primitive object interfaces, capable of setting and 
 receiving values from a given data element.
  
 The message passing implementation of Go is, indeed, a core concept of object-
 oriented programming. Structs with interfaces operate essentially as classes, and Go 
 supports polymorphism (although not parametric polymorphism). Yet, many who 
 work with the language (and who have designed it) stress that it is not object oriented. 
 So what gives?
  
 [
  404 
 ]",NA
Demonstrating simple polymorphism in Go,"As mentioned before, if you expect polymorphism to resemble object-oriented 
 programming, this may not represent a syntactical analogue. However, the use of 
 interfaces as an abstraction of class-bound polymorphic methods is just as clean, 
 and in many ways, more explicit and readable. Let's look at a very simple 
 implementation of polymorphism in Go:
  
 type intInterface struct {
  
 }
  
 type stringInterface struct {
  
 }
  
 func (number intInterface) Add (a int, b int) int {
  
  return a + b;
  
 }
  
 func (text stringInterface) Add (a string, b string) string {
  
  return a + b
  
 }
  
 func main() {
  
  number := new (intInterface)
  
  fmt.Println( number.Add(1,2) )
  
  text := new (stringInterface)
  
  fmt.Println( text.Add(""this old man"","" he played one""))
  
 }
  
 [
  405 
 ]",NA
Using concurrency,"It hasn't yet been mentioned, but we should be aware that concurrency is not always 
 necessary and beneficial for an application. There exists no real rule of thumb, and it's 
 rare that concurrency will introduce problems to an application; but if you really think 
 about applications as a whole, not all will require concurrent processes.
  
 So what works best? As we've seen in the previous example, anything that 
  
 introduces potential latency or I/O blocking, such as network calls, disk reads, third-
 party applications (primarily databases), and distributed systems, can benefit from 
 concurrency. If you have the ability to do work while other work is being done on an 
 undetermined timeline, concurrency strategies can improve the speed and reliability of 
 an application.
  
 The lesson here is you should never feel compelled to shoehorn concurrency into an 
 application that doesn't really require it. Programs with inter-process dependencies (or 
 lack of blocking and external dependencies) may see little or no benefit from 
 implementing concurrency structures.",NA
Managing threads,"So far, you've probably noticed that thread management is not a matter that requires 
 the programmer's utmost concern in Go. This is by design. Goroutines aren't tied to a 
 specific thread or threads that are handled by Go's internal scheduler. However, this 
 doesn't mean that you neither have access to the threads nor the ability to control what 
 individual threads do. As you know, you can already tell Go how many threads you have 
 (or wish to use) by using 
 GOMAXPROCS
 . We also know that using this can introduce 
 asynchronous issues as it pertains to data consistency and execution order.
  
 At this point, the main issue with threads is not how they're accessed or utilized, but how 
 to properly control execution flow to guarantee that your data is predictable and 
 synchronized.
  
 [
  406 
 ]",NA
Using sync and mutexes to lock data,"One issue that you may have run into with the preceding examples is the notion of 
 atomic data. After all, if you deal with variables and structures across multiple 
 goroutines, and possibly processors, how do you ensure that your data is safe across 
 them? If these processes run in parallel, coordinating data access can sometimes be 
 problematic.
  
 Go provides a bevy of tools in its 
 sync
  package to handle these types of problems. How 
 elegantly you approach them depends heavily on your approach, but you should never 
 have to reinvent the wheel in this realm.
  
 We've already looked at the 
 WaitGroup
  struct, which provides a simple method to tell 
 the main thread to pause until the next notification that says a waiting process has 
 done what it's supposed to do.
  
 Go also provides a direct abstraction to a mutex. It may seem contradictory to call 
 something a direct abstraction, but the truth is you don't have access to Go's 
 scheduler, only an approximation of a true mutex.
  
 We can use a mutex to lock and unlock data and guarantee atomicity in our data. 
  
 In many cases, this may not be necessary; there are a great many times where the order 
 of execution does not impact the consistency of the underlying data. However, when we 
 do have concerns about this value, it's helpful to be able to invoke a lock explicitly. Let's 
 take the following example:
  
 package main
  
 import(
  
  ""fmt""
  
  ""sync""
  
 )
  
 func main() {
  
  current := 0
  
  iterations := 100
  
  wg := new (sync.WaitGroup);
  
  for i := 0; i < iterations; i++ {
  
  wg.Add(1)
  
 [
  407 
 ]",NA
Summary,"In this chapter, we've tried to remove some of the ambiguity of Go's concurrency 
 patterns and models by giving visual, real-time feedback to a few applications, 
 including a rudimentary RSS aggregator and reader. We examined the dining 
 philosophers problem and looked at ways you can use the Go concurrency topics to 
 solve the problem neatly and succinctly. We compared the way CSP and actor models 
 are similar and ways in which they differ.
  
 In the next chapter, we will take these concepts and apply them to the process of 
 developing a strategy to maintain concurrency in an application.
  
 [
  409 
 ]",NA
Developing a Concurrent ,NA,NA
Strategy,"In the previous chapter, we looked at the concurrency model that Go relies on to 
 make your life as a developer easier. We also saw a visual representation of 
 parallelism and concurrency. These help us to understand the differences and 
 overlaps between serialized, concurrent, and parallel applications.
  
 However, the most critical part of any concurrent application is not the concurrency 
 itself but communication and coordination between the concurrent processes.
  
 In this chapter, we'll look at creating a plan for an application that heavily factors 
 communication between processes and how a lack of coordination can lead to 
 significant issues with consistency. We'll look at ways we can visualize our concurrent 
 strategy on paper so that we're better equipped to anticipate potential problems.",NA
Applying efficiency in complex ,NA,NA
concurrency,"When designing applications, we often eschew complex patterns for simplicity, with 
 the assumption that simple systems are often the fastest and most efficient. It seems 
 only logical that a machine with fewer moving parts will be more efficient than one 
 with more.
  
 The paradox here, as it applies to concurrency, is that adding redundancy and 
 significantly more movable parts often leads to a more efficient application. If we consider 
 concurrent schemes, such as goroutines, to be infinitely scalable resources, employing 
 more should always result in some form of efficiency benefit. This applies not just to 
 parallel concurrency but to single core concurrency as well.",NA
Identifying race conditions with race ,NA,NA
detection,"If you've ever written an application that depends on the exact timing and 
 sequencing of functions or methods to create a desired output, you're already 
 quite familiar with race conditions.
  
 These are particularly common anytime you deal with concurrency and far more so 
 when parallelism is introduced. We've actually encountered a few of them in the first 
 few chapters, specifically with our incrementing number function.
  
 The most commonly used educational example of race conditions is that of a bank 
 account. Assume that you start with $1,000 and attempt 200 $5 transactions. Each 
 transaction requires a query on the current balance of the account. If it passes, the 
 transaction is approved and $5 is removed from the balance. If it fails, the transaction is 
 declined and the balance remains unchanged.
  
 This is all well and good until the query happens at some point during a concurrent 
 transaction (in most cases in another thread). If, for example, a thread asks ""Do you have 
 $5 in your account?"" as another thread is in the process of removing $5 but has not yet 
 completed, you can end up with an approved transaction that should have been 
 declined.
  
 Tracking down the cause of race conditions can be—to say the least—a gigantic 
 headache. With Version 1.1 of Go, Google introduced a race detection tool that can 
 help you locate potential issues.
  
 [
  412 
 ]",NA
Using mutual exclusions,"Typically, mutual exclusion is considered a low-level and best-known approach to 
 synchronicity in your application—you should be able to address data consistency 
 within communication between your channels. However, there will be instances 
 where you need to truly block read/write on a value while you work with it.
  
 At the CPU level, a mutex represents an exchange of binary integer values across 
 registers to acquire and release locks. We'll deal with something on a much higher 
 level, of course.
  
 We're already familiar with the sync package from our use of the 
 WaitGroup
  struct, but 
 the package also contains the conditional variables 
 struct Cond
  and 
 Once
 , which will 
 perform an action just one time, and the mutual exclusion locks 
 RWMutex 
 and 
 Mutex
 . As 
 the name 
 RWMutex
  implies, it is open to multiple readers and/or writers to lock and 
 unlock; there is more on this later in this chapter and in 
 Chapter 5
 , 
 Locks, Blocks, and 
 Better Channels
 .
  
 [
  416 
 ]",NA
Exploring timeouts,"Another noteworthy thing we can do with channels is explicitly kill them after a 
 specified amount of time. This is an operation that will be a bit more involved 
 should you decide to manually handle mutual exclusions.
  
 The ability to kill a long-running routine through the channel is extremely helpful; 
 consider a network-dependent operation that should not only be restricted to a short 
 time period but also not allowed to run for a long period. In other words, you want to 
 offer the process a few seconds to complete; but if it runs for more than a minute, our 
 application should know that something has gone wrong enough to stop attempting to 
 listen or send on that channel. The following code demonstrates using a timeout channel 
 in a 
 select
  call:
  
 func main() {
  
  ourCh := make(chan string,1)
  
 [
  421 
 ]",NA
Importance of consistency,"In our example, we'll build an events scheduler. If we are available for a meeting and we 
 get two concurrent requests for a meeting invite, we'll get double-booked should a race 
 condition exist. Alternately, locked data across two goroutines may cause both the 
 requests to be denied or will result in an actual deadlock.
  
 We want to guarantee that any request for availability is consistent—there should 
 neither be double-booking nor should a request for an event be blocked incorrectly 
 (because two concurrent or parallel routines lock the data simultaneously).",NA
Synchronizing our concurrent operations,"The word synchronization literally refers to temporal existence—things occurring at the 
 same time. It seems then that the most apt demonstration of synchronicity will be 
 something involving time itself.
  
 [
  422 
 ]",NA
The project – multiuser appointment ,NA,NA
calendar,"What do you do when you decide to write a program?
  
 If you're like a lot of people, you think about the program; perhaps you and a team will 
 write up a spec or requirements document, and then you'll get to coding. 
  
 Sometimes, there will be a drawing representing some facsimile of the way the 
 application will work.
  
 Quite often, the best way to nail down the architecture and the inner workings of an 
 application is to put pencil to paper and visually represent the way the program will 
 work. For a lot of linear or serial applications, this is often an unnecessary step as 
 things will work in a predictable fashion that should not require any specific 
 coordination within the application logic itself (although coordinating third-party 
 software likely benefits from specification).
  
 [
  423 
 ]",NA
Visualizing a concurrent pattern,"As we have already discussed, we wish to create a basic blueprint of how our application 
 should function as a starting point. Here, we'll implement some control flow, which 
 relates to user activity, to help us decide what functionality we'll need to include. The 
 following diagram illustrates how the control flow may look like:
  
  
  
  
 In the previous diagram, we anticipate where data can be shared using concurrent and 
 parallel processes to locate points of failure. If we design concurrent applications in such 
 graphical ways, we're less likely to find race conditions later on.
  
 While we talked about how Go helps you to locate these after the application has 
 completed running, our ideal development workflow is to attempt to cut these 
 problems off at the start.
  
 [
  425 
 ]",NA
Developing our server requirements,"Now that we have an idea of how the scheduling process should work, we need to 
 identify components that our application will need. In this case, the components are as 
 follows:
  
 • 
  
 A web server handler
  
 • 
  
 A template for output
  
 • 
  
 A system for determining dates and times",NA
Web server,"In our visualizing concurrency example from the previous chapter, we used Go's built-
 in 
 http
  package, and we'll do the same here. There are a number of good frameworks 
 out there for this, but they primarily extend the core Go functionality rather than 
 reinventing the wheel. The following are a few of these functionalities, listed from 
 lightest to heaviest:
  
 • 
  
 Web.go: 
 http://webgo.io/
  
 Web.go is very lightweight and lean, and it provides some routing 
 functionality not available in the 
 net
 /
 http
  package.
  
 • 
  
 Gorilla: 
 http://www.gorillatoolkit.org/
  
 Gorilla is a Swiss army knife to augment the 
 net
 /
 http
  package. It's not 
 particularly heavy, and it is fast, utilitarian, and very clean.
  
 • 
  
 Revel: 
 http://robfig.github.io/revel/
  
 Revel is the heaviest of the three, but it focuses on a lot of intuitive code, 
 caching, and performance. Look for it if you need something mature that will 
 face a lot of traffic.
  
 In 
 Chapter 6
 , 
 C10K – A Non-blocking Web Server in Go
 , we'll roll our own web server 
 and framework with the sole goal of extreme high performance.",NA
The Gorilla toolkit,"For this application, we'll partially employ the Gorilla web toolkit. Gorilla is a fairly 
 mature web-serving platform that fulfills a few of our needs here natively, namely the 
 ability to include regular expressions in our URL routing. (Note: Web.Go also extends 
 some of this functionality.) Go's internal HTTP routing handler is rather simplistic; you 
 can extend this, of course, but we'll take a shortcut down a well-worn and reliable path 
 here.
  
 [
  426 
 ]",NA
Using templates,"As Go is intended as a system language, and as system languages often deal with the 
 creation of servers with clients, some care was put into making it a well-featured 
 alternative to create web servers.
  
 Anyone who's dealt with a ""web language"" will know that on top of that you'll need a 
 framework, ideally one that handles the presentation layer for the web. While it's true 
 that if you take on such a project you'll likely look for or build your own framework, Go 
 makes the templating side of things very easy.
  
 The template package comes in two varieties: 
 text
  and 
 http
 . Though they both serve 
 different end points, the same properties—affording dynamism and flexibility—apply 
 to the presentation layer rather than strictly the application layer.
  
  
 The 
 text
  template package is intended for general plaintext 
  
  
 documents, while the 
 http
  template package handles the generation 
  
 of HTML and related documents.
  
 These templating paradigms are all too common these days; if you look at the 
 http
 /
 template
  package, you'll find some very strong similarities to Mustache, one 
 of the more popular variants. While there is a Mustache port in Go, there's nothing 
 there that isn't handled by default in the template package.
  
  
 For more information on Mustache, visit 
 http://mustache.
  
  
 github.io/
 .
  
 One potential advantage to Mustache is its availability in other languages. If you ever 
 feel the need to port some of your application logic to another language (or existing 
 templates into Go), utilizing Mustache could be advantageous. That said, you sacrifice a 
 lot of the extended functionality of Go templates, namely the ability to take out Go code 
 from your compiled package and move it directly into template control structures. 
 While Mustache (and its variants) has control flows, they may not mirror Go's 
 templating system. Take the following example:
  
 <ul> 
  
 {{range .Users}} 
  
 <li>A User </li> 
  
 {{end}} 
  
 </ul>
  
 [
  427 
 ]",NA
Time,"We're not doing a whole lot of math here; time will be broken into hour blocks and 
 each will be set to either occupied or available. At this time, there aren't a lot of 
 external 
 date
 /
 time
  packages for Go. We're not doing any heavy-date math, but it 
 doesn't really matter because Go's 
 time
  package should suffice even if we were.
  
 In fact, as we have literal hour blocks from 9 a.m. to 5 p.m., we just set these to 
 the 24-hour time values of 9-17, and invoke a function to translate them into 
 linguistic dates.",NA
Endpoints,"We'll want to identify the REST endpoints (via 
 GET
  requests) and briefly 
 describe how they'll work. You can think of these as modules or methods in 
 the model-view-controller architecture. The following is a list of the endpoint 
 patterns we'll use:
  
 • 
  
 • 
  
 • 
  
 entrypoint/register/{name}
 : This is where we'll go to add a name to 
 the list of users. If the user exists, it will fail.
  
 entrypoint/viewusers
 : Here, we'll present a list of users with their 
 timeslots, both available and occupied.
  
 entrypoint/schedule/{name}/{time}
 : This will initialize an attempt 
 to schedule an appointment.
  
 Each will have an accompanying template that will report the status of the 
 intended action.
  
 [
  428 
 ]",NA
Custom structs ,"We'll deal with users and responses (web pages), so we need two structs to represent 
 each. One struct is as follows:
  
 type User struct 
 {
  
  
  Name string
  
  
  email string
  
  
  times[int] bool 
  
 }
  
 The other struct is as follows:
  
 type Page struct 
 {
  
  
  Title string
  
  
  Body string 
  
 }
  
 We will keep the page as simple as possible. Rather than doing a lot of iterative 
 loops, we will produce the HTML within the code for the most part.
  
 Our endpoints for requests will relate to our previous architecture, using the 
 following code:
  
 func users(w http.ResponseWriter, r *http.Request) { } 
  
 func register(w http.ResponseWriter, r *http.Request) { 
 } 
  
 func schedule(w http.ResponseWriter, r *http.Request) { 
 }",NA
A multiuser Appointments Calendar ,"In this section, we'll quickly look at our sample Appointments Calendar application, 
 which attempts to control consistency of specific elements to avoid obvious race 
 conditions. The following is the full code, including the routing and templating:
  
 package main
  
 import(
  
  ""net/http""
  
  ""html/template""
  
  ""fmt""
  
 [
  429 
 ]",NA
A note on style,"You'll note that despite preferring camelCase for most of our variables, we have some 
 uppercase variables within structs. This is an important Go convention worth 
 mentioning: any struct variable that begins with a capital letter is 
 public
 . Any variable 
 that begins with a lowercase letter is 
 private
 .
  
 If you attempt to output a private (or nonexistent) variable in your template files, 
 template rendering will fail.
  
 [
  437 
 ]",NA
A note on immutability,"Note that whenever possible, we'll avoid using the string type for comparative 
 operations, especially in multithreaded environments. In the previous example, we 
 use integers and Booleans to decide availability for any given user. In some 
 languages, you may feel empowered to assign the time values to a string for ease of 
 use. For the most part, this is fine, even in Go; but assuming that we have an infinitely 
 scalable, shared calendar application, we run the risk of introducing memory issues if 
 we utilize strings in this way.
  
 The string type is the sole immutable type in Go; this is noteworthy if you end up 
 assigning and reassigning values to a string. Assuming that memory is yielded after a 
 string is converted to a copy, this is not a problem. However, in Go (and a couple of other 
 languages), it's entirely possible to keep the original value in memory. 
  
 We can test this using the following example:
  
 func main() {
  
  testString := ""Watch your top / resource monitor""
  
  for i:= 0; i < 1000; i++ {
  
  testString = string(i)
  
  }
  
  doNothing(testString)  
  
  time.Sleep(10 * time.Second)
  
 }
  
 When run in Ubuntu, this takes approximately 1.0 MB of memory; some of that no doubt 
 overhead, but a useful reference point. Let's up the ante a bit—though having 1,000 
 relatively small pointers won't have much impact—using the following line of code:
  
 for i:= 0; i < 100000000; i++ {
  
 Now, having gone through 100 million memory assignments, you can see the impact 
 on memory (it doesn't help that the string itself is at this point longer than the initial, 
 but it doesn't account for the full effect). Garbage collection takes place here too, which 
 impacts CPU. On our initial test here, both CPU and memory spiked. If we substitute 
 this for an integer or a Boolean assignment, we get much smaller footprints.
  
 [
  438 
 ]",NA
Summary,"This chapter has hopefully directed you towards exploring methods to plan and 
 chart out your concurrent applications before delving in. By briefly touching on 
 race conditions and data consistency, we attempted to highlight the importance of 
 anticipatory design. At the same time, we utilized a few tools for identifying such 
 issues, should they occur.
  
 Creating a robust script flowchart with concurrent processes will help you locate 
 possible pitfalls before you create them, and it will give you a better sense of how 
 (and when) your application should be making decisions with logic and data.
  
 In the next chapter, we'll examine data consistency issues and look at advanced 
 channel communication options in an effort to avoid needless and often expensive 
 mitigating functions, mutexes, and external processes.
  
 [
  439 
 ]",NA
Data Integrity in ,NA,NA
an Application,"By now, you should be comfortable with the models and tools provided in Go's core to 
 provide mostly race-free concurrency.
  
 We can now create goroutines and channels with ease, manage basic communication 
 across channels, coordinate data without race conditions, and detect such conditions as 
 they arise.
  
 However, we can neither manage larger distributed systems nor deal with potentially 
 lower-level consistency problems. We've utilized a basic and simplistic mutex, but we 
 are about to look at a more complicated and expressive way of handling mutual 
 exclusions.
  
 By the end of this chapter, you should be able to expand your concurrency patterns from 
 the previous chapter into distributed systems using a myriad of concurrency models 
 and systems from other languages. We'll also look—at a high level—at some consistency 
 models that you can utilize to further express your precoding strategies for single-
 source and distributed applications.",NA
Getting deeper with mutexes and sync,"In 
 Chapter 2
 , 
 Understanding the Concurrency Model
 , we introduced 
 sync.mutex
  and 
 how to invoke a mutual exclusion lock within your code, but there's some more nuance 
 to consider with the package and the mutex type.
  
 We've mentioned that in an ideal world, you should be able to maintain 
  
 synchronization in your application by using goroutines alone. In fact, this would 
 probably be best described as the canonical method within Go, although the 
 sync 
 package does provide a few other utilities, including mutexes.",NA
The cost of goroutines,"As you work with goroutines, you might get to a point where you're spawning dozens or 
 even hundreds of them and wonder if this is going to be expensive. This is particularly 
 true if your previous experience with concurrent and/or parallel programming was 
 primarily thread-based. It's commonly accepted that maintaining threads and their 
 respective stacks can begin to bog down a program with 
  
 performance issues. There are a few reasons for this, which are as follows:
  
 • 
  
 • 
  
 • 
  
 Memory is required just for the creation of a thread 
  
 Context switching at the OS level is more complex and expensive than in-
 process context switching 
  
 Very often, a thread is spawned for a very small process that could be 
 handled otherwise
  
 It's for these reasons that a lot of modern concurrent languages implement something 
 akin to goroutines (C# uses the async and await mechanism, Python has greenlets/ green 
 threads, and so on) that simulate threads using small-scale context switching.
  
 However, it's worth knowing that while goroutines are (or can be) cheap and cheaper 
 than OS threads, they are not free. At a large (perhaps enormous) measure, even cheap 
 and light goroutines can impact performance. This is particularly important to note as we 
 begin to look at distributed systems, which often scale larger and at faster rates.
  
 The difference between running a function directly and running it in a goroutine is 
 negligible of course. However, keep in mind that Go's documentation states:
  
 It is practical to create hundreds of thousands of goroutines in the same 
 address space.
  
 Given that stack creation uses a few kilobytes per goroutine, in a modern 
  
 environment, it's easy to see how that could be perceived as a nonfactor. However, 
 when you start talking about thousands (or millions) of goroutines running, it can and 
 likely will impact the performance of any given subprocess or function. 
  
 You can test this by wrapping functions in an arbitrary number of goroutines and 
 benchmarking the average execution time and—more importantly—memory usage. 
  
 At approximately 5KB per goroutine, you may find that memory can become a factor, 
 particularly on low-RAM machines or instances. If you have an application that runs 
 heavy on a high-powered machine, imagine it reaching criticality in one or more 
 lower-powered machines. Consider the following example:
  
 for i:= 0; i < 1000000000; i++ {
  
  go someFunction()
  
 }
  
 [
  444 
 ]",NA
Working with files,"Files are a great example of areas where data consistency issues such as race conditions 
 can lead to more permanent and catastrophic problems. Let's look at a piece of code that 
 might continuously attempt to update a file to see where we could run into race 
 conditions, which in turn could lead to bigger problems such as an application failing or 
 losing data consistency:
  
 package main
  
 import(
  
  ""fmt""
  
  ""io/ioutil""
  
  ""strconv""
  
  ""sync""
  
 )
  
 func writeFile(i int) {
  
  rwLock.RLock();
  
  ioutil.WriteFile(""test.txt"", 
  
  []byte(strconv.FormatInt(int64(i),10)), 0x777)
  
  rwLock.RUnlock();
  
 [
  445 
 ]",NA
Getting low – implementing C,"One of the most interesting developments in language design in the past decade or two 
 is the desire to implement lower-level languages and language features via API. Java lets 
 you do this purely externally, and Python provides a C library for interaction between 
 the languages. It warrants mentioning that the reasons for doing this vary—among them 
 applying Go's concurrency features as a wrapper for legacy C code—and you will likely 
 have to deal with some of the memory management associated with introducing 
 unmanaged code to garbage-collected applications.
  
 Go takes a hybrid approach, allowing you to call a C interface through an import, 
 which requires a frontend compiler such as GCC:
  
 import ""C""
  
 So why would we want to do this?
  
 There are some good and bad reasons to implement C directly in your project. An 
 example of a good reason might be to have direct access to the inline assembly, which 
 you can do in C but not directly in Go. A bad reason could be any that has a solution 
 inherent in Golang itself.
  
 To be fair, even a bad reason is not bad if you build your application reliably, but it does 
 impose an additional level of complexity to anyone else who might use your code. If Go 
 can satisfy the technical and performance requirements, it's always better to use a single 
 language in a single project.
  
 There's a famous quote from C++ creator Bjarne Stroustrup on C and C++:
  
 C makes it easy to shoot yourself in the foot; C++ makes it harder, but when you 
 do, it blows your whole leg off.
  
 Jokes aside (Stroustrup has a vast collection of such quips and quotes), the 
 fundamental reasoning is that the complexity of C often prevents people from 
 accidentally doing something catastrophic.
  
 [
  447 
 ]",NA
Touching memory in cgo,"The most important takeaway from the preceding example is to remember that 
 anytime you go into or out of C, you need to manage memory manually (or at least 
 more directly than with Go alone). If you've ever worked in C (or C++), you know that 
 there's no automatic garbage collection, so if you request memory space, you must also 
 free it. Calling C from Go does not preclude this.",NA
The structure of cgo,"Importing C into Go will take you down a syntactical side route, as you probably 
 noticed in the preceding code. The first thing that will appear glaringly different is the 
 actual implementation of C code within your application.
  
 [
  448 
 ]",NA
The other way around,"Using C within Go is obviously a potentially powerful tool for code migration, 
 implementing lower-level code, and roping in other developers, but what about the 
 inverse? Just as you can call C from within Go, you can call Go functions as external 
 functions within your embedded C.
  
 The end game here is the ability to work with and within C and Go in the same 
 application. By far the easiest way to handle this is by using gccgo, which is a 
 frontend for GCC. This is different than the built-in Go compiler; it is possible to go 
 back and forth between C and Go without gccgo, but using it makes this process 
 much simpler.
  
 [
  449 
 ]",NA
Getting even lower – assembly in Go,"If you can shoot your foot off with C and you can blow your leg off with C++, just 
 imagine what you can do with assembly in Go.
  
 It isn't possible to use assembly directly in Go, but as Go provides access to C directly and 
 C provides the ability to call inline assembly, you can indirectly use it in Go.
  
 But again, just because something is possible doesn't mean it should be done—if you find 
 yourself in need of assembly in Go, you should consider using assembly directly and 
 connecting via an API.
  
 Among the many roadblocks that you may encounter with assembly in (C and then in) 
 Go is the lack of portability. Writing inline C is one thing—your code should be 
 relatively transferable between processor instruction sets and operating systems—but 
 assembly is obviously something that requires a lot of specificity.
  
 All that said, it's certainly better to have the option to shoot yourself in the foot whether 
 you choose to take the shot or not. Use great care when considering whether you need C 
 or assembly directly in your Go application. If you can get away with communicating 
 between dissonant processes through an API or interprocess conduit, always take that 
 route first.
  
 One very obvious drawback of using assembly in Go (or on its own or in C) is you lose 
 the cross-compilation capabilities that Go provides, so you'd have to modify your code 
 for every destination CPU architecture. For this reason, the only practical times to use 
 Go in C are when there is a single platform on which your application should run.
  
 Here's an example of what an ASM-in-C-in-Go application might look like. Keep in 
 mind that we've included no ASM code, because it varies from one processor type to 
 another. Experiment with some boilerplate assembly in the following 
 __asm__ 
 section:
  
 package main
  
 /*
  
 #include <stdio.h>
  
 void asmCall() {
  
 __asm__( """" );
  
  printf(""I come from a %s"",""C function with embedded asm\n"");
  
 [
  453 
 ]",NA
Distributed Go,"So far, we've talked quite a bit about managing data within single machines, though with 
 one or more cores. This is complicated enough as is. Preventing race conditions and 
 deadlocks can be hard to begin with, but what happens when you introduce more 
 machines (virtual or real) to the mix?
  
 [
  455 
 ]",NA
Some common consistency models,"Luckily, there are some non-core Go solutions and strategies that we can utilize to 
 improve our ability to control data consistency.
  
 Let's briefly look at a few consistency models that we can employ to manage our data 
 in distributed systems.",NA
Distributed shared memory,"On its own, a 
 Distributed Shared Memory
  (
 DSM
 ) system does not intrinsically 
 prevent race conditions, as it is merely a method for more than one system to share 
 real or partitioned memory.
  
 In essence, you can imagine two systems with 1 GB of memory, each allocating 500 MB to 
 a shared memory space that is accessible and writable by each. Dirty reads are possible as 
 are race conditions unless explicitly designed. The following figure is a visual 
 representation of how two systems can coordinate using shared memory:
  
  
 We'll look at one prolific but simple example of DSM shortly, and play with a library 
 available to Go for test driving it.
  
 [
  457 
 ]",NA
First-in-first-out – PRAM,"Pipelined RAM
  (
 PRAM
 ) consistency is a form of first-in-first-out methodology, in 
 which data can be read in order of the queued writes. This means that writes read 
 by any given, separate process may be different. The following figure represents 
 this concept:",NA
Looking at the master-slave model,"The master-slave consistency model is similar to the leader/follower model that we'll 
 look at shortly, except that the master manages all operations on data and broadcasts 
 rather than receiving write operations from a slave. In this case, replication is the primary 
 method of transmission of changes to data from the master to the slave. 
  
 In the following diagram, you will find a representation of the master-slave model with 
 a master server and four slaves:
  
  
 While we can simply duplicate this model in Go, we have more elegant solutions 
 available to us.
  
 [
  458 
 ]",NA
The producer-consumer problem,"In the classic producer-consumer problem, the producer writes chunks of data to a 
 conduit/buffer, while a consumer reads chunks. The issue arises when the buffer is full: 
 if the producer adds to the stack, the data read will not be what you intend. To avoid 
 this, we employ a channel with waits and signals. This model looks a bit like the 
 following figure:
  
  
 If you're looking for the semaphore implementation in Go, there is no explicit usage of the 
 semaphore. However, think about the language here—fixed-size channels with waits and 
 signals; sounds like a buffered channel. Indeed, by providing a buffered channel in Go, you 
 give the conduit here an explicit length; the channel mechanism gives you the 
 communication for waits and signals. This is incorporated in Go's concurrency model. 
 Let's take a quick look at a producer-consumer model as shown in the following code:
  
 package main
  
 import(
  
  ""fmt""
  
 )
  
 var comm = make(chan bool)
  
 var done = make(chan bool)
  
 func producer() {
  
  for i:=0; i< 10; i++ {
  
  comm <- true
  
  }
  
 [
  459 
 ]",NA
Looking at the leader-follower model ,"In the leader/follower model, writes are broadcasted from a single source to any 
 followers. Writes can be passed through any number of followers or be restricted to 
 a single follower. Any completed writes are then broadcasted to the followers. 
  
 This can be visually represented as the following figure:
  
  
 We can see a channel analog here in Go as well. We can, and have, utilized a single 
 channel to handle broadcasts to and from other followers.
  
 [
  460 
 ]",NA
Atomic consistency / mutual exclusion,"We've looked at atomic consistency quite a bit. It ensures that anything that is not 
 created and used at essentially the same time will require serialization to guarantee 
 the strongest form of consistency. If a value or dataset is not atomic in nature, we can 
 always use a mutex to force linearizability on that data.
  
 Serial or sequential consistency is inherently strong, but can also lead to performance 
 issues and degradation of concurrency.
  
 Atomic consistency is often considered the strongest form of ensuring consistency.",NA
Release consistency,"The release consistency model is a DSM variant that can delay a write's 
 modifications until the time of first acquisition from a reader. This is known as 
 lazy release consistency. We can visualize lazy release consistency in the 
 following serialized model:
  
  
 This model as well as an eager release consistency model both require an 
  
 announcement of a release (as the name implies) when certain conditions are met. In 
 the eager model, that condition requires that a write would be read by all read 
 processes in a consistent manner.
  
 In Go, there exists alternatives for this, but there are also packages out there if 
 you're interested in playing with it.
  
 [
  461 
 ]",NA
Using memcached,"If you're not familiar with memcache(d), it's a wonderful and seemingly obvious way to 
 manage data across distributed systems. Go's built-in channels and goroutines are 
 fantastic to manage communication and data integrity within a single machine's 
 processes, but neither are built for distributed systems out of the box.
  
 Memcached, as the name implies, allows data sharing memory among multiple 
 instances or machines. Initially, memcached was intended to store data for quick 
 retrieval. This is useful for caching data for systems with high turnover such as web 
 applications, but it's also a great way to easily share data across multiple servers 
 and/or to utilize shared locking mechanisms.
  
 In our earlier models, memcached falls under DSM. All available and invoked 
 instances share a common, mirrored memory space within their respective 
 memories.
  
 It's worth pointing out that race conditions can and do exist within memcached, and you 
 still need a way to deal with that. Memcached provides one method to share data across 
 distributed systems, but does not guarantee data atomicity. Instead, memcached operates 
 on one of two methods for invalidating cached data as follows:
  
 • 
  
 • 
  
 Data is explicitly assigned a maximum age (after which, it is removed from the 
 stack)
  
 Or data is pushed from the stack due to all available memory being used by 
 newer data
  
 It's important to note that storage within memcache(d) is, obviously, ephemeral and not 
 fault resistant, so it should only be used where data should be passed without threat of 
 critical application failure.
  
 At the point where either of these conditions is met, the data disappears and the next 
 call to this data will fail, meaning the data needs to be regenerated. Of course, you can 
 work with some elaborate lock generation methods to make memcached operate in a 
 consistent manner, although this is not standard built-in functionality of memcached 
 itself. Let's look at a quick example of memcached in Go using Brad Fitz's gomemcache 
 interface (
 https://github.com/bradfitz/gomemcache
 ):
  
 package main
  
 import (
  
  ""github.com/bradfitz/gomemcache/memcache""
  
  ""fmt""
  
 )
  
 [
  462 
 ]",NA
Circuit,"An interesting third-party library to handle distributed concurrency that has 
 popped up recently is Petar Maymounkov's Go' circuit. Go' circuit attempts to 
 facilitate distributed coroutines by assigning channels to listen to one or more 
 remote goroutines.
  
 The coolest part of Go' circuit is that simply including the package makes your 
 application ready to listen and operate on remote goroutines and work with 
 channels with which they are associated.
  
 Go' circuit is in use at Tumblr, which proves it has some viability as a large-scale and 
 relatively mature solutions platform.
  
 [
  463 
 ]",NA
Summary,"Equipped now with some methods and models to manage not only local data across 
 single or multithreaded systems, but also distributed systems, you should start to 
 feel pretty comfortable with protecting the validity of data in concurrent and parallel 
 processes.
  
 We've looked at both forms of mutual exclusions for read and read/write locks, 
 and we have started to apply these to distributed systems to prevent blocks and 
 race conditions across multiple networked systems.
  
 In the next chapter, we'll explore these exclusion and data consistency concepts a 
 little deeper, building non-blocking networked applications and learn to work with 
 timeouts and give parallelism with channels a deeper look.
  
 We'll also dig a little deeper into the sync and OS packages, in particular looking at 
 the 
 sync.atomic
  operations.
  
 [
  465 
 ]",NA
"Locks, Blocks, and ",NA,NA
Better Channels,"Now that we're starting to get a good grasp of utilizing goroutines in safe and 
 consistent ways, it's time to look a bit more at what causes code blocking and 
 deadlocks. Let's also explore the 
 sync
  package and dive into some profiling and 
 analysis.
  
 So far, we've built some relatively basic goroutines and complementary channels, but we 
 now need to utilize some more complex communication channels between our 
 goroutines. To do this, we'll implement more custom data types and apply them directly 
 to channels.
  
 We've not yet looked at some of Go's lower-level tools for synchronization and 
 analysis, so we'll explore 
 sync.atomic
 , a package that—along with 
 sync. 
 Mutex
 —allows for more granular control over state.
  
 Finally, we'll delve into pprof, a fabulous tool provided by Go that lets us analyze our 
 binaries for detailed information about our goroutines, threads, overall heap, and 
 blocking profiles.
  
 Armed with some new tools and methods to test and analyze our code, we'll be 
 ready to generate a robust, highly-scalable web server that can be used to safely 
 and quickly handle any amount of traffic thrown at it.",NA
Understanding blocking methods in Go ,"So far, 
 we've encountered a few pieces of blocking code, intentional and unintentional, through 
 our exploration and examples. At this point, it's prudent to look at the various ways we 
 can introduce (or inadvertently fall victim to) blocking code.
  
 By looking at the various ways Go code can be blocked, we can also be better prepared to 
 debug cases when concurrency is not operating as expected in our application.",NA
"Blocking method 1 – a listening, waiting ",NA,NA
channel ,"The most concurrently-focused way to block your code is by leaving a serial channel 
 listening to one or more goroutines. We've seen this a few times by now, but the 
 basic concept is shown in the following code snippet:
  
 func thinkAboutKeys() {
  
  
  for {
  
  
  fmt.Println(""Still Thinking"")
  
  
  time.Sleep(1 * time.Second)
  
  
  } 
  
 }
  
 func main() {
  
  
  fmt.Println(""Where did I leave my keys?"")
  
  blockChannel := make(chan int)
  
  go thinkAboutKeys()
  
  <-blockChannel
  
  
  fmt.Println(""OK I found them!"") 
  
 }
  
 [
  468 
 ]",NA
Sending more data types via channels,"Go's use of channels (structs and functions) as first-class citizens provides us 
 with a lot of interesting ways of executing, or at least trying, new approaches of 
 communication between channels.
  
 One such example is to create a channel that handles translation through a function 
 itself, and instead of communicating directly through the standard syntax, the channel 
 executes its function. You can even do this on a slice/array of functions iterating through 
 them in the individual functions.
  
 [
  469 
 ]",NA
Creating a function channel ,"So far, we've almost exclusively worked in single data type and single value channels. 
 So, let's try sending a function across a channel. With first-class channels, we need no 
 abstraction to do this; we can just send almost anything directly over a channel as 
 shown in the following code snippet:
  
 func abstractListener(fxChan chan func() string ) {
  
  fxChan <- func() string {
  
  
  return ""Sent!""
  
  
  } 
  
 }
  
 func main() {
  
  fxChan := make (chan func() string)
  
  defer close(fxChan)
  
  go abstractListener(fxChan)
  
  select {
  
  case rfx := <- fxChan:
  
  msg := rfx()
  
  fmt.Println(msg)      
  
  fmt.Println(""Received!"")
  
  }
  
 }
  
 This is like a callback function. However, it also is intrinsically different, as it is not just 
 the method called after the execution of a function, but also serves as the mode of 
 communication between functions.
  
 Keep in mind that there are often alternatives to passing functions across channels, so 
 this will likely be something very specific to a use case rather than a general practice.
  
 Since your channel's type can be virtually any available type, this functionality opens 
 up a world of possibilities, which can be potentially confusing abstractions. A struct or 
 interface as a channel type is pretty self-explanatory, as you can make application-
 related decisions on any of its defined properties.
  
 Let's see an example of using an interface in this way in the next section.
  
 [
  470 
 ]",NA
Using an interface channel ,"As with our function channel, being able to pass an interface (which is a 
 complementary data type) across a channel can be incredibly useful. Let's look at 
 an example of sending across an interface:
  
 type Messenger interface 
 {
  
  
  Relay() string 
  
 }
  
 type Message struct {
  
  
  status string 
  
 }
  
 func (m Message) Relay() string {
  
  
  return m.status 
  
 }
  
 func alertMessages(v chan Messenger, i int) {
  
  
  m := new(Message)
  
  
  m.status = ""Done with "" + 
 strconv.FormatInt(int64(i),10)
  
  v <- m 
  
 }
  
 func main () {
  
  msg := make(chan Messenger)
  
  for i:= 0; i < 10; i++ {
  
  go alertMessages(msg,i)
  
  }
  
  
  select {
  
  
  case message := <-msg:
  
    
  fmt.Println (message.Relay())
  
  
  }
  
  
  <- msg 
  
 }
  
 This is a very basic example of how to utilize interfaces as channels; in the previous 
 example, the interface itself is largely ornamental. In actuality, we're passing newly-
 created message types through the interface's channel rather than interacting directly 
 with the interface.
  
 [
  471 
 ]",NA
"Using structs, interfaces, and more complex channels","Creating a custom type for our channel allows us to dictate the way our intra-channel 
 communication will work while still letting Go dictate the context switching and behind-
 the-scenes scheduling.
  
 Ultimately, this is mostly a design consideration. In the previous examples, we used 
 individual channels for specific pieces of communication in lieu of a one-size-fits-all 
 channel that passes a multitude of data. However, you may also find it advantageous to 
 use a single channel to handle a large amount of communication between 
  
 goroutines and other channels.
  
 The primary consideration in deciding whether to segregate channels into individual bits 
 of communication or a package of communications depends on the aggregate mutability 
 of each.
  
 For example, if you'll always want to send a counter along with a function or string and 
 they will always be paired in terms of data consistency, such a method might make 
 sense. If any of those components can lose synchronicity en route, it's more logical to 
 keep each piece independent.
  
  
 Maps in Go
  
  
 As mentioned, maps in Go are like hash tables elsewhere and 
  
 immediately related to slices or arrays.
  
 In the previous example we were checking to see if a username/
  
 key exists already; for this purpose Go provides a simple method for 
  
 doing so. When attempting to retrieve a hash with a nonexistent key, 
  
 a zero value is returned, as shown in the following lines of code:
  
 if Users[user.name] {
  
  fmt.Fprintln(conn, ""Unfortunately, that username 
  
 is in 
  
  use!"");
  
 }
  
 This makes it syntactically simple and clean to test against a map 
  
 and its keys.
  
 One of the best features of maps in Go is the ability to make keys out 
  
 of any comparable type, which includes strings, integers, Booleans 
  
 as well as any map, struct, slice, or channel that is comprised 
  
 exclusively of those types.
  
 This one-to-many channel can work as a master-slave or broadcaster-subscriber model. 
 We'll have a channel that listens for messages and routes them to appropriate users and a 
 channel that listens for broadcast messages and queues them to all users.
  
 [
  472 
 ]",NA
The net package – a chat server with interfaced ,NA,NA
channels,"Here, we'll need to introduce a relevant package that will be required to handle most of 
 the communication for our application(s). We've touched on the 
 net
  package a bit while 
 dabbling in the SVG output generation example to show concurrency—
 net
 / 
 http
  is just a 
 small part of a broader, more complex, and more feature-full package.
  
 The basic components that we'll be using will be a TCP listener (server) and a TCP 
 dialer (client). Let's look at the basic setup for these.
  
 Server
  
 Listening on a TCP port couldn't be easier. Simply initiate the 
 net.Listen() 
 method and handle the error as shown in the following lines of code:
  
  listener, err := net.Listen(""tcp"", "":9000"")
  
  if err != nil {
  
  fmt.Println (""Could not start server!"")
  
  }
  
 If you get an error starting the server, check your firewall or modify the port—it's 
 possible that something is utilizing port 9000 on your system.
  
 As easy as that is, it's just as simple on our client/dialer side.
  
 Client
  
 In this case, we have everything running on localhost as shown in the following lines of 
 code. However, in a real-world application we'd probably have an intranet address 
 used here:
  
  conn, err := net.Dial(""tcp"",""127.0.0.1:9000"")
  
  if err != nil {
  
  fmt.Println(""Could not connect to server!"")
  
  }
  
 In this application, we demonstrate two different ways to handle byte buffers of 
 unknown lengths on 
 Read()
 . The first is a rather crude method of trimming a string 
 using 
 strings.TrimRight()
 . This method allows you to define characters you aren't 
 interested in counting as part of the input as shown in the following line of code. Mostly, 
 it's whitespace characters that we can assume are unused parts of the buffer length.
  
 sendMessage := []byte(cM.name + "": "" + 
  
  strings.TrimRight(string(buf),"" \t\r\n""))
  
 [
  474 
 ]",NA
Handling direct messages,"For the most part, this chat client is a simple echo server, but as mentioned, we also 
 include an ability to do non-globally broadcast messages by invoking the Twitter style 
 @
  syntax.
  
 We handle this mainly through regular expressions, wherein if a message matches 
 @user
  then only that user will see the message; otherwise, it's broadcasted to all. This is 
 somewhat inelegant, because senders of the direct message will not see their own direct 
 message if their usernames do not match the intended names of the users.
  
 [
  475 
 ]",NA
Examining our client ,"Our client application is a bit simpler primarily because we don't care as much 
 about blocking code.
  
 While we do have two concurrent operations (wait for the message and wait for user 
 input to send the message), this is significantly less complicated than our server, 
 which needs to concurrently listen to each created user and distribute sent 
 messages, respectively.
  
 Let's now compare our chat client to our chat server. Obviously, the client has less 
 overall maintenance of connections and users, and so we do not need to use nearly as 
 many channels. Let's take a look at our chat client's code:
  
 chat-client.go 
  
 package main
  
 import 
  
 (
  
  
  ""fmt""
  
  
  ""net""
  
  
  ""os""
  
  
  ""bufio""
  
  
  ""strings"" 
  
 )
  
 [
  481 
 ]",NA
Blocking method 2 – the select statement in a ,NA,NA
loop ,"Have you noticed yet that the 
 select
  statement itself blocks? Fundamentally, the 
 select
  statement is not different from an open listening channel; it's just wrapped in 
 conditional code.
  
 [
  483 
 ]",NA
Cleaning up goroutines,"Any channel that is left waiting and/or left receiving will result in a deadlock. Luckily, 
 Go is pretty adept at recognizing these and you will almost without fail end up in a 
 panic when running or building the application.
  
 Many of our examples so far have utilized the deferred 
 close()
  method of 
 immediately and cleanly grouping together similar pieces of code that should 
 execute at different points.
  
 While garbage collection handles a lot of the cleanup, we're largely left to take care of 
 open channels to ensure we don't have a process waiting to receive and/or something 
 waiting to send, both waiting at the same time for each other. Luckily, we'll be unable 
 to compile any such program with a detectable deadlock condition, but we also need to 
 manage closing channels that are left waiting.
  
 Quite a few of the examples so far have ended with a generic integer or Boolean 
 channel that just waits—this is employed almost exclusively for the channel's 
 blocking effect and allows us to demonstrate the effects and output of concurrent 
 code while the application is still running. In many cases, this generic channel is an 
 unnecessary bit of syntactical cruft as shown in the following lines of code:
  
 <-youMayNotNeedToDoThis
  
 close(youmayNotNeedToDoThis)
  
 The fact that there's no assignment happening is a good indicator this is an example of 
 such cruft. If we had instead modified that to include an assignment, the previous code 
 would be changed to the following instead:
  
 v := <-youMayNotNeedToDoThis
  
 It might indicate that the value is useful and not just arbitrary blocking code.
  
 [
  484 
 ]",NA
Blocking method 3 – network connections ,NA,NA
and reads,"If you run the code from our earlier chat server's client without starting the server, you'll 
 notice that the 
 Dial
  function blocks any subsequent goroutine. We can test this by 
 imposing a longer-than-normal timeout on the connection or by simply closing the client 
 application after logging in, as we did not implement a method for closing the TCP 
 connection.
  
 As the network reader we're using for the connection is buffered, we'll always have a 
 blocking mechanism while waiting for data via TCP.",NA
Creating channels of channels,"The preferred and sanctioned way of managing concurrency and state is exclusively 
 through channels.
  
 We've demonstrated a few more complex types of channels, but we haven't looked at 
 what can become a daunting but powerful implementation: channels of channels. This 
 might at first sound like some unmanageable wormhole, but in some situations we want 
 a concurrent action to generate more concurrent actions; thus, our 
  
 goroutines should be capable of spawning their own.
  
 As always, the way you manage this is through design while the actual code may simply 
 be an aesthetic byproduct here. Building an application this way should make your code 
 more concise and clean most of the time.
  
 Let's revisit a previous example of an RSS feed reader to demonstrate how we could 
 manage this, as shown in the following code:
  
 package main
  
 import (
  
  ""fmt""
  
 )
  
 type master chan Item
  
 var feedChannel chan master
  
 var done chan bool
  
 [
  485 
 ]",NA
Pprof – yet another awesome tool,"Just when you think you've seen the entire spectrum of Go's amazing tool set, there's 
 always one more utility that, once you realize it exists, you'll wonder how you ever 
 survived without it.
  
 Go format is great for cleaning up your code; the 
 -race
  flag is essential for detecting 
 possible race conditions, but an even more robust, hands-in-the-dirt tool exists that is 
 used to analyze your final application, and that is pprof.
  
 Google created pprof initially to analyze loop structures and memory allocation 
 (and related types) for C++ applications.
  
 It's particularly useful if you think you have performance issues not uncovered by the 
 testing tools provided in the Go runtime. It's also a fantastic way to generate a visual 
 representation of the data structures in any application.
  
 Some of this functionality also exists as part of the Go testing package and its 
 benchmarking tools—we'll explore that more in 
 Chapter 7
 , 
 Performance and Scalability
 .
  
 Getting the runtime version of pprof to work requires a few pieces of setup first. 
 We'll need to include the 
 runtime.pprof
  package and the 
 flag
  package, which 
 allows command-line parsing (in this case, for the output of pprof).
  
 [
  487 
 ]",NA
Handling deadlocks and errors ,"Anytime you encounter a deadlock error upon compilation in your code, you'll see the 
 familiar string of semi-cryptic errors explaining which goroutine was left holding the bag, 
 so to speak.
  
 However, keep in mind you always have the ability to invoke your own panic using 
 Go's built-in panic, and this can be incredibly useful for building your own error-
 catching safeguards to ensure data consistency and ideal operation. The code is as 
 follows:
  
 package main
  
 impor
 t 
  
 (
  
  
  
 ""os"" 
  
 )
  
 func main() {
  
  
  panic(""Oh No, we forgot to write a program!"")
  
  os.Exit(1) 
  
 }
  
 This can be utilized anywhere you wish to give detailed exit information to either 
 developers or end users.
  
 [
  494 
 ]",NA
Summary,"Having explored some new ways to examine the way that Go code can block and 
 deadlock, we also have some tools at our disposal that can be used to examine CPU 
 profiles and resource usage now.
  
 Hopefully, by this point, you can build some complex concurrent systems with simple 
 goroutines and channels all the way up to multiplexed channels of structs, interfaces, 
 and other channels.
  
 We've built some somewhat-functional applications so far, but next we're going to 
 utilize everything we've done to build a usable web server that solves a classic 
 problem and can be used to design intranets, file storage systems, and more.
  
 In the next chapter, we'll take what we've done in this chapter with regard to 
 extensible channels and apply it to solving one of the oldest challenges the Internet has 
 to offer: concurrently serving 10,000 (or more) connections.
  
 [
  495 
 ]",NA
C10K – A Non-blocking ,NA,NA
Web Server in Go,"Up to this point, we've built a few usable applications; things we can start with and 
 leapfrog into real systems for everyday use. By doing so, we've been able to 
 demonstrate the basic and intermediate-level patterns involved in Go's concurrent 
 syntax and methodology.
  
 However, it's about time we take on a real-world problem—one that has vexed 
 developers (and their managers and VPs) for a great deal of the early history of the 
 Web.
  
 In addressing and, hopefully, solving this problem, we'll be able to develop a high-
 performance web server that can handle a very large volume of live, active traffic.
  
 For many years, the solution to this problem was solely to throw hardware or 
 intrusive caching systems at the problem; so, alternately, solving it with 
 programming methodology should excite any programmer.
  
 We'll be using every technique and language construct we've learned so far, but we'll do 
 so in a more structured and deliberate way than we have up to now. Everything we've 
 explored so far will come into play, including the following points:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 Creating a visual representation of our concurrent application 
  
 Utilizing goroutines to handle requests in a way that will scale 
  
 Building robust channels to manage communication between goroutines and the 
 loop that will manage them 
  
 Profiling and benchmarking tools (JMeter, ab) to examine the way our event 
 loop actually works 
  
 Timeouts and concurrency controls—when necessary—to ensure data and 
 request consistency",NA
Attacking the C10K problem,"The genesis of the C10K problem is rooted in serial, blocking programming, which 
 makes it ideal to demonstrate the strength of concurrent programming, especially in 
 Go.
  
 The proposed problem came from developer Dan Kegel, who famously asked:
  
 It's time for web servers to handle ten thousand clients simultaneously, don't you 
 think? After all, the web is a big place now.
  
 - Dan Kegel (http://www.kegel.com/c10k.html)
  
 When he asked this in 1999, for many server admins and engineers, serving 10,000 
 concurrent visitors was something that would be solved with hardware. The notion that 
 a single server on common hardware could handle this type of CPU and network 
 bandwidth without falling over seemed foreign to most.
  
 The crux of his proposed solutions relied on producing non-blocking code. Of course, 
 in 1999, concurrency patterns and libraries were not widespread. C++ had some 
 polling and queuing options available via some third-party libraries and the earliest 
 predecessor to multithreaded syntaxes, later available through Boost and then C++11.
  
 Over the coming years, solutions to the problem began pouring in across various flavors 
 of languages, programming design, and general approaches. At the time of publishing 
 this book, the C10K problem is not one without solutions, but it is still an excellent 
 platform to conduct a very real-world challenge to high-performance Go.
  
 Any performance and scalability problem will ultimately be bound to the underlying 
 hardware, so as always, your mileage may vary. Squeezing 10,000 concurrent connections 
 on a 486 processor with 500 MB of RAM will certainly be more 
  
 challenging than doing so on a barebones Linux server stacked with memory and multiple 
 cores.
  
 It's also worth noting that a simple echo server would obviously be able to assume 
 more cores than a functional web server that returns larger amounts of data and 
 accepts greater complexity in requests, sessions, and so on, as we'll be dealing with 
 here.
  
 [
  498 
 ]",NA
"Failing of servers at 10,000 concurrent ",NA,NA
connections,"As you may recall, when we discussed concurrent strategies back in 
 Chapter 3
 , 
 Developing a Concurrent Strategy
 , we talked a bit about Apache 
 and its load-balancing tools.
  
 When the Web was born and the Internet commercialized, the level of interactivity 
 was pretty minimal. If you're a graybeard, you may recall the transition from 
 NNTP/IRC and the like and how extraordinarily rudimentary the Web was.
  
 To address the basic proposition of [page request] → [HTTP response], the 
 requirements on a web server in the early 1990s were pretty lenient. Ignoring 
 all of the error responses, header readings and settings, and other essential (but 
 unrelated to the in → out mechanism) functions, the essence of the early servers 
 was shockingly simple, at least compared to the modern web servers.
  
  
 The first web server was developed by the father of the Web, Tim 
  
  
 Berners-Lee.
  
 Developed at CERN (such as WWW/HTTP itself), CERN httpd 
  
 handled many of the things you would expect in a web server 
  
 today—hunting through the code, you'll find a lot of notation 
  
 that will remind you that the very core of the HTTP protocol is 
  
 largely unchanged. Unlike most technologies, HTTP has had an 
  
 extraordinarily long shelf life.
  
 Written in C in 1990, it was unable to utilize a lot of concurrency 
  
 strategies available in languages such as Erlang. Frankly, doing 
  
 so was probably unnecessary—the majority of web traffic was a 
  
 matter of basic file retrieval and protocol. The meat and potatoes 
  
 of a web server were not dealing with traffic, but rather dealing 
  
 with the rules surrounding the protocol itself.
  
 You can still access the original CERN httpd site and download 
  
 the source code for yourself from 
 http://www.w3.org/
  
 Daemon/
 . I highly recommend that you do so as both a history 
  
 lesson and a way to look at the way the earliest web server 
  
 addressed some of the earliest problems.
  
 However, the Web in 1990 and the Web when the C10K question was first posed 
 were two very different environments.
  
 [
  499 
 ]",NA
Using concurrency to attack C10K,"There are two primary approaches to handle a large volume of concurrent requests. 
 The first involves allocating threads per connection. This is what Apache (and a few 
 others) do.
  
 On the one hand, allocating a thread to a connection makes a lot of sense—it's 
 isolated, controllable via the application's and kernel's context switching, and can 
 scale with increased hardware.
  
 [
  500 
 ]",NA
Taking another approach,"In an attempt to create our web server that can handle 10,000 concurrent connections, 
 we'll obviously leverage our goroutine/channel mechanism to put an event loop in front 
 of our content delivery to keep new channels recycled or created constantly.
  
 For this example, we'll assume we're building a corporate website and infrastructure for 
 a rapidly expanding company. To do this, we'll need to be able to serve both static and 
 dynamic content.
  
 The reason we want to introduce dynamic content is not just for the purposes of 
 demonstration—we want to challenge ourselves to show 10,000 true concurrent 
 connections even when a secondary process gets in the way.
  
 As always, we'll attempt to map our concurrency strategy directly to goroutines and 
 channels. In a lot of other languages and applications, this is directly analogous to an 
 event loop, and we'll approach it as such. Within our loop, we'll manage the available 
 goroutines, expire or reuse completed ones, and spawn new ones where necessary.
  
 In this example visualization, we show how an event loop (and corresponding 
 goroutines) can allow us to scale our connections without employing too many 
 hard
  resources such as CPU threads or RAM:
  
  
  
 [
  502 
 ]",NA
Building our C10K web server,"Our web server will be responsible for taking requests, routing them, and serving 
 either flat files or dynamic files with templates parsed against a few different data 
 sources.
  
 As mentioned earlier, if we exclusively serve flat files and remove much of the 
 processing and network latency, we'd have a much easier time with handling 10,000 
 concurrent connections.
  
 Our goal is to approach as much of a real-world scenario as we can—very little of the Web 
 operates on a single server in a static fashion. Most websites and applications utilize 
 databases, 
 CDNs
  (
 Content Delivery Networks
 ), dynamic and uncached template parsing, 
 and so on. We need to replicate them whenever possible.
  
 For the sake of simplicity, we'll separate our content by type and filter them through 
 URL routing, as follows:
  
 • 
  
 • 
  
 • 
  
 /static/[request]
 : This will serve 
 request.html
  directly
  
 /template/[request]
 : This will serve 
 request.tpl
  after its been parsed 
 through Go
  
 /dynamic/[request][number]
 : This will also serve 
 request.tpl
  and parse it 
 against a database source's record
  
 By doing this, we should get a better mixture of possible HTTP request types that 
 could impede the ability to serve large numbers of users simultaneously, especially in 
 a blocking web server environment.
  
 We'll utilize the 
 html/template
  package to do parsing—we've briefly looked at the 
 syntax before, and going any deeper is not necessarily part of the goals of this book. 
 However, you should look into it if you're going to parlay this example into something you 
 use in your environment or have any interest in building a framework.
  
  
 You can find Go's exceptional library to generate safe data-driven 
  
  
 templating at 
 http://golang.org/pkg/html/template/
 .
  
 [
  503 
 ]",NA
Benchmarking against a blocking web server,"It's only fair to add some starting benchmarks against a blocking web server first so 
 that we can measure the effect of concurrent versus nonconcurrent architecture.
  
 For our starting benchmarks, we'll eschew any framework, and we'll go with our old 
 stalwart, Apache.
  
 For the sake of completeness here, we'll be using an Intel i5 3GHz machine with 8 GB of 
 RAM. While we'll benchmark our final product on Ubuntu, Windows, and OS X here, we'll 
 focus on Ubuntu for our example.
  
 Our localhost domain will have three plain HTML files in 
 /static
 , each trimmed to 80 
 KB. As we're not using a framework, we don't need to worry about raw dynamic 
 requests, but only about static and dynamic requests in addition to data source 
 requests.
  
 For all examples, we'll use a MySQL database (named 
 master
 ) with a table called 
 articles
  that will contain 10,000 duplicate entries. Our structure is as follows:
  
 CREATE TABLE articles (
  
  article_id INT NOT NULL AUTO_INCREMENT,
  
  article_title VARCHAR(128) NOT NULL,
  
  article_text VARCHAR(128) NOT NULL,
  
  PRIMARY KEY (article_id)
  
 )
  
 With ID indexes ranging sequentially from 0-10,000, we'll be able to generate random 
 number requests, but for now, we just want to see what kind of basic response we can get 
 out of Apache serving static pages with this machine.
  
 For this test, we'll use Apache's ab tool and then gnuplot to sequentially map the 
 request time as the number of concurrent requests and pages; we'll do this for our 
 final product as well, but we'll also go through a few other benchmarking tools for it to 
 get some better details.
  
 [
  504 
 ]",NA
Handling requests,"In an earlier chapter, we handled URL routing with Gorilla, a compact but feature-full 
 framework. The Gorilla toolkit certainly makes this easier, but we should also know how 
 to intercept the functionality to impose our own custom handler.
  
 Here is a simple web router wherein we handle and direct requests using a custom 
 http.Server
  struct, as shown in the following code:
  
 var routes []string
  
 type customRouter struct {
  
 }
  
 func (customRouter) ServeHTTP(rw http.ResponseWriter, r 
  
  
 *http.Request) {
  
  
  
 fmt.Println(r.URL.Path); 
  
 }
  
 func main() {
  
  var cr customRouter;
  
  server := &http.Server {
  
  Addr: "":9000"",
  
  Handler:cr,
  
  ReadTimeout: 10 * time.Second,
  
  WriteTimeout: 10 * time.Second,
  
  MaxHeaderBytes: 1 << 20,
  
  }
  
  
  server.ListenAndServe() 
  
 }
  
 [
  506 
 ]",NA
Routing requests,"So, let's take a step back and look again at routing our traffic through a traditional web 
 server to include not only our static content, but also the dynamic content.
  
 [
  509 
 ]",NA
Serving pages,"First up are our static pages. While we handled this the idiomatic way earlier, there 
 exists the ability to rewrite our requests, better handle specific 404 error pages, and so 
 on by using the 
 http.ServeFile
  function, as shown in the following code:
  
  path := r.URL.Path;
  
  staticPatternString := ""static/(.*)""
  
  templatePatternString := ""template/(.*)""
  
  dynamicPatternString := ""dynamic/(.*)""
  
  staticPattern := regexp.MustCompile(staticPatternString)
  
  templatePattern := regexp.MustCompile(templatePatternString)
  
  dynamicDBPattern := regexp.MustCompile(dynamicPatternString)
  
  if staticPattern.MatchString(path) {
  
  page := staticPath + staticPattern.ReplaceAllString(path, 
  
  ""${1}"") + "".html""
  
  http.ServeFile(rw, r, page)
  
  }
  
 Here, we simply relegate all requests starting with 
 /static/(.*)
  to match the 
 request in addition to the 
 .html
  extension. In our case, we've named our test file (the 
 80 KB example file) 
 test.html
 , so all requests to it will go to 
 /static/test
 .
  
 We've prepended this with 
 staticPath
 , a constant defined upcode. In our case, it's 
 /var/www/
 , but you'll want to modify it as necessary.
  
 [
  510 
 ]",NA
Parsing our template,"In our next phase, we'll measure the impact of reading and parsing a template. To 
 effectively match the previous tests, we'll take our HTML static file and impose some 
 variables on it.
  
 [
  511 
 ]",NA
External dependencies,"Finally, we need to bring in our biggest potential bottleneck, which is the database. As 
 mentioned earlier, we'll simulate random traffic by generating a random integer 
 between 1 and 10,000 to specify the article we want.
  
 Randomization isn't just useful on the frontend—we'll want to work around any 
 query caching within MySQL itself to limit nonserver optimizations.",NA
Connecting to MySQL,"We can route our way through a custom connection to MySQL using native Go, but as is 
 often the case, there are a few third-party packages that make this process far less 
 painful. Given that the database here (and associated libraries) is tertiary to the 
 primary exercise, we'll not be too concerned about the particulars here.
  
 The two mature MySQL driver libraries are as follows:
  
 • 
  
 Go-MySQL-Driver
  (
 https://github.com/go-sql-driver/mysql
 )
  
 • 
  
 MyMySQL
  (
 https://github.com/ziutek/mymysql
 )
  
 For this example, we'll go with the Go-MySQL-Driver. We'll quickly install it using the 
 following command:
  
 go get github.com/go-sql-driver/mysql
  
 [
  515 
 ]",NA
Multithreading and leveraging multiple ,NA,NA
cores,"You may be wondering how performance may vary when invoking additional processor 
 cores—as mentioned earlier, this can sometimes have an unexpected effect.
  
 In this case, we should expect only improved performance in our dynamic requests and 
 static requests. Any time the cost of context switching in the OS might outweigh the 
 performance advantages of additional cores, we can see paradoxical performance 
 degradation. In this case, we do not see this effect and instead see a relatively similar line, 
 as shown in the following graph:",NA
Exploring our web server,"Our final web server is capable of serving static, template-rendered, and dynamic 
 content well within the confines of the goal of 10,000 concurrent connections on 
 even the most modest of hardware.
  
 The code—much like the code in this book—can be considered a jumping-off point and 
 will need refinement if put into production. This server lacks anything in the form of 
 error handling but can ably serve valid requests without any issue. Let's take a look at 
 the following server's code:
  
 package main
  
 impor
 t 
  
 (
  
 [
  518 
 ]",NA
Timing out and moving on,"One thing we did not focus on in our server is the notion of lingering connection 
 mitigation. The reason we didn't worry much about it is because we were able to hit 
 10,000 concurrent connections in all three approaches without too much issue, 
 strictly by utilizing Go's powerful built-in concurrency features.
  
 [
  522 
 ]",NA
Summary,"The C10K problem may seem like a relic today, but the call to action was 
 symptomatic of the type of approaches to systems' applications that were 
 primarily employed prior to the rapid expansion of concurrent languages 
 and application design.
  
 Just 15 years ago, this seemed a largely insurmountable problem facing systems 
 and server developers worldwide; now, it's handled with only minor tweaking and 
 consideration by a server designer.
  
 Go makes it easy to get there (with a little effort), but reaching 10,000 (or 100,000 or 
 even 1,000,000) concurrent connections is only half the battle. We must know what to 
 do when problems arise, how to seek out maximum performance and responsiveness 
 out of our servers, and how to structure our external dependencies such that they do 
 not create roadblocks.
  
 In our next chapter, we'll look at squeezing even more performance out of our 
 concurrent applications by testing some distributed computing patterns and best 
 utilizing memory management.
  
 [
  524 
 ]",NA
Performance and Scalability,"To build a high-powered web server in Go with just a few hundred lines of code, you 
 should be quite aware of how concurrent Go provides us with exceptional tools for 
 performance and stability out of the box.
  
 Our example in 
 Chapter 6
 , 
 C10K – A Non-blocking Web Server in Go
 , also showed how 
 imposing blocking code arbitrarily or inadvertently into our code can introduce some 
 serious bottlenecks and quickly torpedo any plans to extend or scale your application.
  
 What we'll look at in this chapter are a few ways that can better prepare us to take our 
 concurrent application and ensure that it's able to continuously scale in the future and 
 that it is capable of being expanded in scope, design, and/or capacity.
  
 We'll expand a bit on 
 pprof
 , the CPU profiling tool we looked at briefly in previous 
 chapters, as a way to elucidate the way our Go code is compiled and to locate possible 
 unintended bottlenecks.
  
 Then we'll expand into distributed Go and into ways to offer some performance-
 enhancing parallel-computing concepts to our applications. We'll also look at the 
 Google App Engine, and at how you can utilize it for your Go-based applications to 
 ensure scalability is placed in the hands of one of the most reliable hosting 
 infrastructures in the world.
  
 Lastly, we'll look at memory utilization, preservation, and how Google's garbage 
 collector works (and sometimes doesn't). We'll finally delve a bit deeper into using 
 memory caching to keep data consistent as well as less ephemeral, and we will also see 
 how that dovetails with distributed computing in general.",NA
High performance in Go,"Up to this point, we've talked about some of the tools we can use to help discover 
 slowdowns, leaks, and inefficient looping.
  
 Go's compiler and its built-in deadlock detector keep us from making the kind of 
 mistake that's common and difficult to detect in other languages.
  
 We've run time-based benchmarks based on specific changes to our concurrency 
 patterns, which can help us design our application using different methodologies to 
 improve overall execution speed and performance.",NA
Getting deeper into pprof,"The pprof tool was first encountered in 
 Chapter 5
 , 
 Locks, Blocks, and Better Channels
 , and 
 if it still feels a bit cryptic, that's totally understandable. What pprof shows you in export 
 is a 
 call graph
 , and we can use this to help identify issues with loops or expensive calls 
 on the heap. These include memory leaks and processor-intensive methods that can be 
 optimized.
  
 One of the best ways to demonstrate how something like this works is to build 
 something that doesn't. Or at least something that doesn't work the way it should.
  
 You might be thinking that a language with garbage collection might be immune to these 
 kinds of memory issues, but there are always ways to hide mistakes that can lead to 
 memory leakage. If the GC can't find it, it can sometimes be a real pain to do so yourself, 
 leading to a lot of—often feckless—debugging.
  
 To be fair, what constitutes a memory leak is sometimes debated among computer 
 science members and experts. A program that continuously consumes RAM may not be 
 leaking memory by technical definition if the application itself could re-access any given 
 pointers. But that's largely irrelevant when you have a program that crashes and burns 
 after consuming memory like an elephant at a buffet.
  
 The basic premise of creating a memory leak in a garbage-collected language relies on 
 hiding the allocation from the compiler—indeed, any language in which you can access 
 and utilize memory directly provides a mechanism for introducing leaks.
  
 We'll review a bit more about garbage collection and Go's implementation later in this 
 chapter.
  
 So how does a tool like pprof help? Very simply put, by showing you 
 where
  your 
 memory and CPU utilization goes.
  
 [
  526 
 ]",NA
Parallelism's and concurrency's impact on ,NA,NA
I/O pprof ,"One issue you'll likely run into pretty quickly when using pprof is when you've 
 written a script or application that is especially bound to efficient runtime 
 performance. This happens most frequently when your program executes too 
 quickly to properly profile.
  
 A related issue involves network applications that require connections to profile; in 
 this case, you can simulate traffic either in-program or externally to allow proper 
 profiling.
  
 We can demonstrate this easily by replicating something like the preceding example 
 with goroutines as follows:
  
 const TESTLENGTH = 20000
  
 type DataType struct 
 {
  
  
  a,b,c,d,e,f,g int64
  
  
  longByte []byte  
  
 }
  
 func (dt DataType) init() {
  
 }
  
 var profile = flag.String(""cpuprofile"", """", ""output pprof data to 
  
  file"")
  
 func main() {
  
  flag.Parse()
  
  if *profile != """" {
  
  
  flag,err := os.Create(*profile)
  
  
  if err != nil {
  
    
  fmt.Println(""Could not create profile"",err)
  
  }
  
  
  pprof.StartCPUProfile(flag)
  
  
  defer pprof.StopCPUProfile()
  
  }
  
 [
  532 
 ]",NA
Using the App Engine,"While not right for every project, Google's App Engine can open up a world of 
 scalability when it comes to concurrent applications, without the hassle of VM 
 provisioning, reboots, monitoring, and so on.
  
 The App Engine is not entirely dissimilar to Amazon Web Services, DigitalOcean, and 
 the ilk, except for the fact that you do not need to necessarily involve yourself in the 
 minute details of direct server setup and maintenance. All of them provide a single 
 spot to acquire and utilize virtual computing resources for your applications.
  
 Rather, it can be a more abstract environment within Google's architecture with which 
 to house and run your code in a number of languages, including—no surprise here—the 
 Go language itself.
  
 While large-scale apps will cost you, Google provides a free tier with reasonable 
 quotas for experimentation and small applications.
  
 The benefits as they relate to scalability here are two-fold: you're not responsible for 
 ensuring uptime on the instances as you would be in an AWS or DigitalOcean scenario. 
 Who else but Google will have not only the architecture to support anything you can 
 throw at it, but also have the fastest updates to the Go core itself?
  
 There are some obvious limitations here that coincide with the advantages, of course, 
 including the fact that your core application will be available exclusively via 
 http 
 (although it will have access to plenty of other services).
  
  
 To deploy apps to the App Engine, you'll need the SDK for Go, 
  
  
 available for Mac OS X, Linux, and Windows, at 
 https://
  
 developers.google.com/appengine/downloads#Google_
  
 App_Engine_SDK_for_Go
 .
  
 Once you've installed the SDK, the changes you'll need to make to your code are 
 minor—the most noteworthy point is that for most cases, your Go tool command will 
 be supplanted by 
 goapp
 , which handles serving your application locally and then 
 deploying it.
  
 [
  535 
 ]",NA
Distributed Go,"We've certainly covered a lot about concurrent and parallel Go, but one of the biggest 
 infrastructure challenges for developers and system architects today has to do with 
 cooperative computing.
  
 Some of the applications and designs that we've mentioned previously scale from 
 parallelism to distributed computing.
  
 Memcache(d) is a form of in-memory caching, which can be used as a queue among 
 several systems.
  
 Our master-slave and producer-consumer models we presented in 
 Chapter 4
 , 
 Data 
 Integrity in an Application
 , have more to do with distributed computing than single-
 machine programming in Go, which manages concurrency idiomatically. These models 
 are typical concurrency models in many languages, but can be scaled to help us design 
 distributed systems as well, utilizing not just many cores and vast resources but also 
 redundancy.
  
 The basic premise of distributed computing is to share, spread, and best absorb the 
 various burdens of any given application across many systems. This not only 
 improves performance on aggregate, but provides some sense of redundancy for the 
 system itself.
  
 This all comes at some cost though, which are as follows:
  
 • 
  
 Potential for network latency
  
 • 
  
 Creating slowdowns in communication and in application execution
  
 • 
  
 Overall increase in complexity both in design and in maintenance
  
 • 
  
 Potential for security issues at various nodes along the distributed route(s)
  
 • 
  
 Possible added cost due to bandwidth considerations
  
 This is all to say, simply, that while building a distributed system can provide great 
 benefits to a large-scale application that utilizes concurrency and ensures data 
 consistency, it's by no means right for every example.",NA
Types of topologies,"Distributed computing recognizes a slew of logical topologies for distributed design. 
 Topology is an apt metaphor, because the positioning and logic of the systems involved 
 can often represent physical topology.
  
 Out of the box, not all of the accepted topologies apply to Go. When we design 
 concurrent, distributed applications using Go, we'll generally rely on a few of the 
 simpler designs, which are as follows.
  
 [
  536 
 ]",NA
Type 1 – star,"The star topology (or at least this particular form of it), resembles our master-slave or 
 producer-consumer models as outlined previously.
  
 The primary method of data passing involves using the master as a message-passing 
 conduit; in other words, all requests and commands are coordinated by a single 
 instance, which uses some routing method to pass messages. The following diagram 
 shows the star topology:
  
  
  
 We can actually very quickly design a goroutine-based system for this. The following code 
 is solely the master's (or distributed destination's) code and lacks any sort of security 
 considerations, but shows how we can parlay network calls to goroutines:
  
 package main
  
 import 
  
 (
  
  
  ""fmt""
  
  
  ""net""
  
 )
  
 Our standard, basic libraries are defined as follows:
  
 type Subscriber struct {
  
  
  Address net.Addr
  
  
  Connection net.Conn
  
  
  do chan Task  
  
 }
  
 type Task struct 
 {
  
  
  name string 
  
 }
  
 [
  537 
 ]",NA
Type 2 – mesh ,"The mesh is very similar to the star with one major difference: each node is able to 
 communicate not just through the master, but also directly with other nodes as well. 
 This is also known as a 
 complete graph
 . The following diagram shows a mesh 
 topology:
  
  
  
 For practical purposes, the master must still handle assignments and pass 
 connections back to the various nodes.
  
 This is actually not particularly difficult to add through the following simple 
 modification of our previous server code:
  
 func serverListen (listener net.Listener) {
  
  
  for {
  
  
  conn,_ := listener.Accept()
  
  SubscriberCount++
  
  
  subscriber := Subscriber{ Address: conn.RemoteAddr(), 
  
   
  Connection: conn }
  
  
  subscriber.awaitTask()
  
  
  _ = append(Subscribers,subscriber)
  
  
  broadcast()
  
  
  } 
  
 }
  
 [
  540 
 ]",NA
The Publish and Subscribe model,"In both the previous topologies, we've replicated a Publish and Subscribe model with a 
 central/master handling delivery. Unlike in a single-system, concurrent pattern, we lack 
 the ability to use channels directly across separate machines (unless we use something 
 like Go's Circuit as described in 
 Chapter 4
 , 
 Data Integrity in an Application
 ).
  
 Without direct programmatic access to send and receive actual commands, we rely on 
 some form of API. In the previous examples, there is no actual task being sent or 
 executed, but how could we do this?
  
 Obviously, to create tasks that can be formalized into non-code transmission, we'll 
 need a form of API. We can do this one of two ways: serialization of commands, 
 ideally via JSONDirect transmission, and execution of code.
  
 As we'll always be dealing with compiled code, the serialization of commands option 
 might seem like you couldn't include Go code itself. This isn't exactly true, but 
 passing full code in any language is fairly high on lists of security concerns.
  
 But let's look at two ways of sending data via API in a task by removing a URL from a 
 slice of URLs for retrieval. We'll first need to initialize that array in our 
 main 
 function 
 as shown in the following code:
  
 type URL struct {
  
  URI string
  
  Status int
  
  Assigned Subscriber
  
  SubscriberID int
  
 }
  
 Every URL in our array will include the URI, its status, and the subscriber address to 
 which it's been assigned. We'll formalize the status points as 0 for unassigned, 1 for 
 assigned and waiting, and 2 for assigned and complete.
  
 [
  541 
 ]",NA
Serialized data ,"In our first option in the API, we'll send and receive serialized data in JSON. Our master 
 will be responsible for formalizing its command and associated data. In this case, we'll 
 want to transmit a few things: what to do (in this case, retrieve) with the relevant data, 
 what the response should be when it is complete, and how to address errors.
  
 We can represent this in a custom struct as follows:
  
 type Assignment struct {
  
  
  command string
  
  
  data string
  
  
  successResponse string
  
  
  errorResponse string 
  
 } 
  
 ...
  
  asmnt := Assignment{command:""process"",
  
  url:""http://www.golang.org"",successResponse:""success"",
  
  
 errorResponse:""error""}
  
  json, _ := json.Marshal(asmnt )
  
  send(string(json))",NA
Remote code execution ,"The remote code execution option is not necessarily separate from serialization of 
 commands, but instead of structured and interpreted formatted responses, the 
 payload could be code that will be run via a system command.
  
 [
  542 
 ]",NA
Other topologies,"There exist quite a few topology types that are more complicated to manage as part of a 
 messaging queue.
  
 The following diagram shows the bus topology:
  
  
 The bus topology network is a unidirectional transmission system. For our purposes, it's 
 neither particularly useful nor easily managed, as each added node needs to announce its 
 availability, accept listener responsibility, and be ready to cede that responsibility when a 
 new node joins.
  
 The advantage of a bus is quick scalability. This comes with serious disadvantages 
 though: lack of redundancy and single point of failure.
  
 Even with a more complex topology, there will always be some issue with potentially 
 losing a valuable cog in the system; at this level of modular redundancy, some additional 
 steps will be necessary to have an always-available system, including automatic double or 
 triple node replication and failovers. That's a bit more than we'll get into here, but it's 
 important to note that the risk will be there in any event, although it would be a little 
 more vulnerable with a topology like the bus.
  
 [
  543 
 ]",NA
Message Passing Interface,"There exists a slightly more formalized version of what we built previously, called 
 Message Passing Interface. MPI was borne from early 1990s academia as a standard for 
 distributed communication.
  
 Originally written with FORTRAN and C in mind, it is still a protocol, so it's largely 
 language agnostic.
  
 MPI allows the management of topology above and beyond the basic topologies we were 
 able to build for a resource management system, including not only the line and ring but 
 also the common bus topology.
  
 For the most part, MPI is used by the scientific community; it is a highly concurrent and 
 analogous method for building large-scale distributed systems. Point-to-point 
 operations are more rigorously defined with error handling, retries, and dynamic 
 spawning of processes all built in.
  
 [
  544 
 ]",NA
Some helpful libraries,"There's little doubt that Go provides some of the best ancillary tools available to 
 any compiled language out there. Compiling to native code on a myriad of 
 systems, deadlock detection, pprof, fmt, and more allow you to not just build 
 high-performance applications, but also test them and format them.
  
 This hasn't stopped the community from developing other tools that can be used for 
 debugging or aiding your concurrent and/or distributed code. We'll take a look at a 
 few great tools that may prove worthy of inclusion in your app, particularly if it's 
 highly visible or performance critical.",NA
Nitro profiler,"As you are probably now well aware, Go's pprof is extremely powerful and useful, if 
 not exactly user-friendly.
  
 If you love pprof already, or even if you find it arduous and confusing, you may love 
 Nitro profiler twice as much. Coming from Steve Francia of spf13, Nitro profiler allows 
 you to produce even cleaner analyses of your application and its functions and steps, as 
 well as providing more usable a/b tests of alternate functions.
  
  
 Read more about Nitro profiler at 
 http://spf13.com/project/
  
  
 nitro
 .
  
 You can get it via 
 github.com/spf13/nitro
 .
  
 [
  545 
 ]",NA
Heka,"Heka is a data pipeline tool that can be used to gather, analyze, and distribute raw 
 data. Available from Mozilla, Heka is more a standalone application rather than a 
 library, but when it comes to acquiring, analyzing, and distributing data such as server 
 logfiles across multiple servers, Heka can prove itself worthy.
  
 Heka is also written in Go, so make sure to check out the source to see how Mozilla 
 utilizes concurrency and Go in real-time data analysis.
  
  
 You can visit the Heka home page at 
 http://heka-docs.
  
  
 readthedocs.org/en/latest/
  and the Heka source page 
  
 at 
 https://github.com/mozilla-services/heka
 .",NA
GoFlow,"Finally, there's GoFlow, a flow-based programming paradigm tool that lets you 
 segment your application into distinct components, each capable of being bound to 
 ports, channels, the network, or processes.
  
 While not itself a performance tool, GoFlow might be an appropriate approach to 
 extending concurrency for some applications.
  
  
 Visit GoFlow at 
 https://github.com/trustmaster/goflow
 .",NA
Memory preservation,"At the time of this writing, Go 1.2.2's compiler utilizes a naive mark/sweep garbage 
 collector, which assigns a reference rank to objects and clears them when they are no 
 longer in use. This is noteworthy only to point out that it is widely considered a 
 relatively poor garbage collection system.
  
 [
  546 
 ]",NA
Garbage collection in Go,"To get an idea of how the garbage collector is managing the stack at any time, take a look 
 at the 
 runtime.MemProfileRecord
  object, which keeps track of presently living objects 
 in the active stack trace.
  
 You can call the profile record when necessary and then utilize it against the 
 following methods to get a few interesting pieces of data:
  
 • 
  
 • 
  
 • 
  
 InUseBytes()
 : This method has the bytes used presently as per the 
 memory profile 
  
 InUseObjects()
 :This method has the number of live objects in use 
 Stack()
 : This method has the full stack trace
  
 You can place the following code in a heavy loop in your application to get a peek at all 
 of these:
  
  var mem runtime.MemProfileRecord
  
  obj := mem.InUseObjects();
  
  bytes := mem.InUseBytes();
  
  stack := mem.Stack();
  
  fmt.Println(i,obj,bytes)",NA
Summary,"We can now build some pretty high-performance applications and then utilize some of 
 Go's built-in tools and third-party packages to seek out the most performance in a 
 single instance application as well as across multiple, distributed systems.
  
 In the next chapter, we're going to wrap everything together to design and build a 
 concurrent server application that can work quickly and independently, and easily 
 scale in performance and scope.
  
 [
  547 
 ]",NA
Concurrent Application ,NA,NA
Architecture,"By now, we've designed small bits of concurrent programs, primarily in a single 
 piece keeping concurrency largely isolated. What we haven't done yet is tie 
 everything together to build something a little more robust, complex, and more 
 daunting to manage from an administrator's perspective.
  
 Simple chat applications and web servers are fine and dandy. However, you will 
 eventually need more complexity and require external software to meet all of the 
 more advanced requirements.
  
 In this case, we'll build something that's satisfied by a few dissonant services: a file 
 manager with revision control that supplies web and shell access. Services such as 
 Dropbox and Google Drive allow users to keep and share files among peers. On the 
 other hand, GitHub and its ilk allow for a similar platform but with the critical added 
 benefit of revision control.
  
 Many organizations face problems with the following sharing and distribution options:
  
 • 
  
 Limitations on repositories, storage, or number of files
  
 • 
  
 Potential inaccessibility if the services are down
  
 • 
  
 Security concerns, particularly for sensitive information
  
 Simple sharing applications such as Dropbox and Google Drive are great at storing data 
 without a large amount of revision control options. GitHub is an excellent collaborative 
 revision control and distribution system, but comes with many costs and the mistakes by 
 developers can lead to large and potentially serious security lapses.",NA
Designing our concurrent application,"When designing a concurrent application, we will have three components running in 
 separate processes. A file listener will be alerted to make changes to files in specified 
 locations. A web-CLI interface will allow users to augment or modify files, and a backup 
 process will be bound to the listener to provide automated copies of new file changes. 
 With that in mind, these three processes will look a bit like 
  
 what is shown in the following diagram:
  
  
 Our file listener process will do the following three things:
  
 • 
  
 Keep an eye on any file changes
  
 • 
  
 Broadcast to our web/CLI servers and the backup process
  
 • 
  
 Maintain the state of any given file in our database / data store
  
 [
  550 
 ]",NA
Identifying our requirements,"The most critical step in our architectural design process is really zooming in on the 
 required features, packages, and technologies that we'll need to implement. For our file 
 management and revision control application, there are a few key points that will stand 
 out:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 A web interface that allows file uploads, downloads, and revisions. A 
 command-line interface that allows us to roll back changes and modify files 
 directly.
  
 A filesystem listener that finds changes made to a shared location.
  
 A data store system that has strong Go tie-in and allows us to maintain 
 information about files and users in a mostly consistent manner. This 
 system will also maintain user records.
  
 A concurrent log system that maintains and cycles logs of changed files.
  
 We're somewhat complicating things by allowing the following three different ways to 
 interface with the overall application:
  
 • 
  
 • 
  
 • 
  
 Via the Web that requires a user and login. This also allows our users to access 
 and modify files even if they happen to be somewhere not connected to the 
 shared drive.
  
 Via the command line. This is archaic but also extremely valuable anytime a user 
 is traversing a filesystem, particularly power users not in a GUI.
  
 Via the filesystem that changes itself. This is the shared drive mechanism 
 wherein we assume that any user with access to this will be making valid 
 modifications to any files.
  
 [
  551 
 ]",NA
Using NoSQL as a data store in Go,"One of the biggest concessions with using NoSQL is, obviously, the lack of 
 standardization when it comes to CRUD operations (create, read, update, and 
 delete). SQL has been standardized since 1986 and is pretty airtight across a 
 number of databases—from MySQL to SQL Server and from Microsoft and Oracle 
 all the way down to PostgreSQL.
  
 [
  552 
 ]",NA
MongoDB,"MongoDB is one of the most popular NoSQL platforms available. Written in 2009, it's 
 also one of the most mature platforms, but comes with a number of tradeoffs that have 
 pushed it somewhat out of favor in the recent years.
  
 Even so, Mongo does what it does in a reliable fashion and with a great deal of speed. 
 Utilizing indices, as is the case with most databases and data stores, improves query 
 speed on reads greatly.
  
 Mongo also allows for some very granular control of guarantees as they apply to reads, 
 writes, and consistency. You can think of this as a very vague analog to any language 
 and/or engine that supports syntactical dirty reads.
  
 [
  553 
 ]",NA
Redis,"Redis is another key/value data store and, as of recently, took the number one spot in 
 terms of total usage and popularity. In an ideal Redis world, an entire dataset is held in 
 memory. Given the size of many datasets, this isn't always possible; however, coupled 
 with Redis' ability to eschew durability, this can result in some very high performance 
 results when used in concurrent applications.
  
 Another useful feature of Redis is the fact that it can inherently hold different data 
 structures. While you can make abstractions of such data by unmarshalling JSON 
 objects/arrays in Mongo (and other data stores), Redis can handle sets, strings, arrays, 
 and hashes.
  
 There are two major accepted libraries for Redis in Go:
  
 • 
  
 Radix
 : This is a minimalist client that's barebones, quick, and dirty. To 
 install Radix, run the following command:
  
 go get github.com/fzzy/radix/redis
  
 • 
  
 Redigo
 : This more robust and a bit more complex, but provides a lot of the 
 more intricate functionality that we'll probably not need for this project. To 
 install Redigo, run the following command:
  
 go get github.com/garyburd/redigo/redis
  
 We'll now see a quick example of getting a user's name from the data store of 
 Users 
 in Redis using Redigo:
  
 package main
  
 import
  
 (
  
  ""fmt""
  
  ""github.com/garyburd/redigo/redis""
  
 )
  
 [
  555 
 ]",NA
Tiedot,"If you've worked a lot with NoSQL, then the preceding engines all likely seemed very 
 familiar to you. Redis, Couch, Mongo, and so on are all virtual stalwarts in what is a 
 relatively young technology.
  
 Tiedot, on the other hand, probably isn't as familiar. We're including it here only 
 because the document store itself is written in Go directly. Document manipulation is 
 handled primarily through a web interface, and it's a JSON document store like several 
 other NoSQL solutions.
  
 As document access and handling is governed via HTTP, there's a somewhat 
 counterintuitive workflow, shown as follows:
  
  
 As that introduces a potential spot for latency or failure, this keeps from being an ideal 
 solution for our application here. Keep in mind that this is also a feature of a few of the 
 other solutions mentioned earlier, but since Tiedot is written in Go, it would be 
 significantly easier to connect to it and read/modify data using a package. While this 
 book was being written, this did not exist.
  
 Unlike other HTTP- or REST-focused alternatives such as CouchDB, Tiedot relies on 
 URL endpoints to dictate actions, not HTTP methods.
  
 You can see in the following code how we might handle something like this through 
 standard libraries:
  
 package main
  
 import
  
 (
  
  ""fmt""
  
  ""json""
  
  ""http""
  
 )
  
 type Collection struct {
  
  Name string
  
 }
  
 [
  557 
 ]",NA
CouchDB,"CouchDB from Apache Incubator is another one of the big boys in NoSQL big data. As a 
 JSON document store, CouchDB offers a great deal of flexibility when it comes to your 
 data store approach.
  
 CouchDB supports ACID semantics and can do so concurrently, which provides a 
 great deal of performance benefit if one is bound to those properties. In our 
 application, that reliance on ACID consistency is somewhat flexible. By design, it will 
 be failure tolerant and recoverable, but for many, even the possibility of data loss 
 with recoverability is still considered catastrophic.
  
 Interfacing with CouchDB happens via HTTP, which means there is no need for a 
 direct implementation or Go SQL database hook to use it. Interestingly, CouchDB 
 uses HTTP header syntax to manipulate data, as follows:
  
 • 
  
 GET
 : This represents read operations
  
 • 
  
 PUT
 : This represents creation operations
  
 • 
  
 DELETE
 : This represents deletion and update operations
  
 [
  558 
 ]",NA
Cassandra,"Cassandra, another Apache Foundation project, isn't technically a NoSQL solution but a 
 clustered (or cluster-able) database management platform.
  
 Like many NoSQL applications, there is a limitation in the traditional query methods in 
 Cassandra, for example, subqueries and joins are generally not supported.
  
 We're mentioning it here primarily because of its focus on distributed computing as 
 well as the ability to programmatically tune whether data consistency or performance 
 is more important. Much of that is equally expressed in our solution, Couchbase, but 
 Cassandra has a deeper focus on distributed data stores.
  
 Cassandra does, however, support a subset of SQL that will make it far more familiar to 
 developers who have dabbled in MySQL, PostgreSQL, or the ilk. Cassandra's built-in 
 handling of highly concurrent integrations makes it in many ways ideal for Go, although it 
 is an overkill for this project.
  
 The most noteworthy library to interface with Cassandra is gocql, which focuses on 
 speed and a clean connection to the Cassandra connection. Should you choose to use 
 Cassandra in lieu of Couchbase (or other NoSQL), you'll find a lot of the methods that 
 can be simply replaced.
  
 [
  559 
 ]",NA
Couchbase,"Couchbase is a relative newcomer in the field, but it was built by people from both 
 CouchDB and memcached. Written in Erlang, it shares many of the same focuses on 
 concurrency, speed, and non-blocking behavior that we've come to expect from a great 
 deal of our Go applications.
  
 Couchbase also supports a lot of the other features we've discussed in the previous 
 chapters, including easy distribution-based installations, tuneable ACID compliance, and 
 low-resource consumption.
  
 [
  560 
 ]",NA
Setting up our data store,"After installing Couchbase, you can access its administration panel by default at 
 localhost and port 8091.
  
 You'll be given an opportunity to set up an administrator, other IPs to connect (if 
 you're joining a cluster), and general data store design.
  
 After that, you'll need to set up a bucket, which is what we'll use to store all 
 information about individual files. Here is what the interface for the bucket 
 setup looks like:
  
  
 [
  563 
 ]",NA
Monitoring filesystem changes ,"When it came to NoSQL options, we had a vast variety of solutions at our disposal. This 
 is not the case when it comes to applications that monitor filesystem changes. While 
 Linux flavors have a fairly good built-in solution in inotify, this does restrict the 
 portability of the application.
  
 So it's incredibly helpful that a cross-platform library for handling this exists in 
 Chris Howey's fsnotify.
  
 Fsnotify works on Linux, OSX, and Windows and allows us to detect when files in any 
 given directory are created, deleted, modified, or renamed, which is more than 
 enough for our purposes.
  
 Implementing fsnotify couldn't be easier, either. Best of all it's all non-blocking, so if 
 we throw the listener behind a goroutine, we can have this run as part of the 
 primary server application code.
  
 The following code shows a simple directory listener:
  
 package main
  
 import (
  
  
  ""github.com/howeyc/fsnotify"" 
  
  
  ""fmt""
  
  
  ""log"""" 
  
 )
  
 func main() {
  
  scriptDone := make(chan bool)
  
  dirSpy, err := fsnotify.NewWatcher()
  
  if err != nil {
  
  
  log.Fatal(err)
  
  }
  
  go func() {
  
  
  for {
  
  
  
  select {
  
  
  
  case fileChange := <-dirSpy.Event:
  
  
  
  
  log.Println(""Something happened to a file:"", 
  
  
  
  
  fileChange)
  
  
  
  case err := <-dirSpy.Error:
  
  
  
  
  log.Println(""Error with fsnotify:"", err)
  
  
  }
  
 [
  565 
 ]",NA
Managing logfiles,"Like many basic features in a developer's toolbox, Go provides a fairly complete 
 solution built-in for logging. It handles many of the basics, such as creating 
 timestamp-marked log items and saving to disk or to console.
  
 One thing the basic package misses out on is built-in formatting and log rotation, 
 which are key requirements for our file manager application.
  
 Remember that key requirements for our application include the ability to work 
 seamlessly in our concurrent environment and be ready to scale to a distributed 
 network if need be. This is where the fine 
 log4go
  application comes in handy. Log4go 
 allows logging to file, console, and memory and handles log rotation inherently.
  
  
 Log4go can be found at 
 https://code.google.com/p/
  
  
 log4go/
 .
  
 To install Log4go, run the following command:
  
 go get code.google.com/p/log4go
  
 Creating a logfile that handles warnings, notices, debug information, and critical 
 errors is simple and appending log rotation to that is similarly simple, as shown in 
 the following code:
  
 package main
  
 import
  
 (
  
  logger ""code.google.com/p/log4go""
  
 )
  
 func main() {
  
  logMech := make(logger.Logger);
  
 [
  566 
 ]",NA
Handling configuration files ,"When it comes to configuration files and parsing them, you have a lot of options, 
 from simple to complicated.
  
 We could, of course, simply store what we want in JSON, but that format is a little 
 tricky to work directly for humans—it will require escaping characters and so on, 
 which makes it vulnerable to errors.
  
 Instead, we'll keep things simple by using a standard 
 ini config
  file library in gcfg, 
 which handles 
 gitconfig
  files and traditional, old school 
 .ini
  format, as shown in the 
 following code snippet:
  
 [revisions] 
  
 count = 2 
  
 revisionsuffix = .rev 
  
 lockfiles = false
  
 [logs] 
  
 rotatelength = 86400
  
 [alarms] 
  
 emails = sysadmin@example.com,ceo@example.com
  
  
 You can find gcfg at 
 https://code.google.com/p/gcfg/
 .
  
  
 [
  567 
 ]",NA
Detecting file changes ,"Now we need to focus on our file listener. You may recall this is the part of the 
 application that will accept client connections from our web server and our backup 
 application and announce any changes to files.
  
 The basic flow of this part is as follows:
  
 1. Listen for changes to files in a goroutine.
  
 2. Accept connections and add to the pool in a goroutine.
  
 3. If any changes are detected, announce them to the entire pool.
  
 [
  568 
 ]",NA
Sending changes to clients ,"Here is the broadcast message that goes to all existing connections. We pass along our 
 JSON-encoded 
 Message
  struct with the current version, the current location, and the 
 hash for reference. Our other servers will then react accordingly:
  
 func alertServers(hash string, name string, action string, location 
 string, version int) {
  
 [
  570 
 ]",NA
Checking records against Couchbase ,"When it comes to checking for existing records against Couchbase, we check whether a 
 hash exists in our Couchbase bucket. If it doesn't, we create it. If it does, we do nothing. To 
 handle shutdowns more robustly, we should also ingest existing records into our 
 application. The code for doing this is as follows:
  
 var Clients []Client 
  
 var Files map[string] 
 File
  
 func main() {
  
  Files = make(map[string]File)
  
  endScript := make(chan bool)
  
  couchbaseClient, err := couchbase.Connect(""http://localhost:8091/"") 
 if err != nil {
  
 [
  573 
 ]",NA
Backing up our files ,"Since we're sending our commands on the wire, so to speak, our backup process needs 
 to listen on that wire and respond with any changes. Given that modifications will be 
 sent via localhost, we should have minimal latency on both the network and the file side.
  
 We'll also return some information as to what happened with the file, although at this 
 point we're not doing much with that information. The code for this is as follows:
  
 package main
  
 import 
  
 (
  
  
  ""fmt""
  
  
  ""net""
  
  
  ""io""
  
  
  ""os""
  
  
  ""strconv""
  
  
  ""encoding/json"" 
  
 )
  
 var backupFolder = ""mnt/backup/""
  
 Note that we have a separate folder for backups, in this case, on a Windows machine. 
  
 If we happen to accidentally use the same directory, we run the risk of infinitely 
 duplicating and backing up files. In the following code snippet, we'll look at the 
 Message
  struct itself and the 
 backup
  function, the core of this part of the application:
  
 type Message struct {
  
  
  Hash string ""json:hash""
  
  
  Action string ""json:action""
  
  
  Location string ""json:location""
  
  
  Name string ""json:name""  
  
  
  Version int ""json:version"" 
  
 }
  
 func backup (location string, name string, version int) {
  
  
  newFileName := backupFolder + name + ""."" + 
  
  strconv.FormatInt(int64(version),10)
  
  
  fmt.Println(newFileName)
  
  
  org,_ := os.Open(location)
  
  
  defer org.Close()
  
  
  cpy,_ := os.Create(newFileName)
  
  
  defer cpy.Close()
  
  
  io.Copy(cpy,org) 
  
 }
  
 [
  575 
 ]",NA
Designing our web interface ,"To interact with the filesystem, we'll want an interface that displays all of the current 
 files with the version, last modified time, and alerts to changes, and allows drag-and-
 drop creation/replacement of files.
  
 Getting a list of files will be simple, as we'll grab them directly from our 
 file_manager 
 Couchbase bucket. Changes will be sent through our file manager process via TCP, which 
 will trigger an API call, illuminating changes to the file for our web user.
  
 A few of the methods we've used here are duplicates of the ones we used in the 
 backup process and could certainly benefit from some consolidation; still, the 
 following is the code for the web server, which allows uploads and shows 
 notifications for changes:
  
 package main
  
 import 
  
 (
  
  
  ""net""
  
  
  ""net/http""
  
  
  ""html/template""
  
  
  ""log""
  
  
  ""io""
  
  
  ""os""
  
  
  ""io/ioutil""
  
  
  ""github.com/couchbaselabs/go-couchbase""
  
  
  ""time""  
  
  
  ""fmt""
  
  
  ""crypto/md5""
  
  
  ""encoding/hex""
  
  
  ""encoding/json"" 
  
 )
  
 type File struct {
  
  
  Hash string ""json:hash""
  
  
  Name string ""json:file_name""
  
  
  Created int64 ""json:created""
  
  
  CreatedUser  int ""json:created_user""
  
  
  LastModified int64 ""json:last_modified""
  
  
  LastModifiedUser int ""json:last_modified_user""
  
  Revisions int ""json:revisions""
  
  
  Version int ""json:version"" 
  
 }
  
 [
  577 
 ]",NA
Reverting a file's history – command line,"The final component we'd like to add to this application suite is a command-line file 
 revision process. We can keep this one fairly simple, as we know where a file is located, 
 where its backups are located, and how to replace the former with the latter. As with 
 before, we have some global configuration variables and a replication of our 
 generateHash()
  function:
  
 [
  582 
 ]",NA
Using Go in daemons and as a service ,"A minor note on running something like this part of the application—you'll ideally 
 wish to keep these applications as active, restartable services instead of standalone, 
 manually executed background processes. Doing so will allow you to keep the 
 application active and manage its life from external or server processes.
  
 This sort of application suite would be best suited on a Linux box (or boxes) and 
 managed with a daemon manager such as daemontools or Ubuntu's built-in Upstart 
 service. The reason for this is that any long-term downtime can result in lost data and 
 inconsistency. Even storing file data details in the memory (Couchbase and memcached) 
 provides a vulnerability for lost data.
  
 [
  584 
 ]",NA
Checking the health of our server,"Of the many ways to check general server health, we're in a good position here without 
 having to build our own system, thanks in great part to Couchbase itself. If you visit the 
 Couchbase web admin, under your cluster, server, and bucket views, clicking on any will 
 present some real-time statistics, as shown in the following screenshot:
  
  
 These areas are also available via REST if you wish to include them in the application to 
 make your logging and error handling more comprehensive.
  
 [
  585 
 ]",NA
Summary,"We now have a top to bottom application suite that is highly concurrent, ropes in 
 several third-party libraries, and mitigates potential failures with logging and 
 catastrophe recovery.
  
 At this point, you should have no issue constructing a complex package of software with a 
 focus on maintaining concurrency, reliability, and performance in Go. Our file monitoring 
 application can be easily modified to do more, use alternative services, or scale to a 
 robust, distributed environment.
  
 In the next chapter, we'll take a closer look at testing our concurrency and 
  
 throughput, explore the value of panic and recover, as well as dealing with logging 
 vital information and errors in a safe, concurrent manner in Go.
  
 [
  586 
 ]",NA
Logging and Testing ,NA,NA
Concurrency in Go,"At this stage, you should be fairly comfortable with concurrency in Go and should be 
 able to implement basic goroutines and concurrent mechanisms with ease.
  
 We have also dabbled in some distributed concurrency patterns that are managed not 
 only through the application itself, but also through third-party data stores for 
 networked applications that operate concurrently in congress.
  
 Earlier in this book, we examined some preliminary and basic testing and logging. 
  
 We looked at the simpler implementations of Go's internal test tool, performed some 
 race condition testing using the race tool, and performed some rudimentary load and 
 performance testing.
  
 However, there's much more to be looked at here, particularly as it relates to the 
 potential black hole of concurrent code—we've seen unexpected behavior among 
 code that runs in goroutines and is non-blocking.
  
 In this chapter, we'll further investigate load and performance testing, look at unit 
 testing in Go, and experiment with more advanced tests and debugging. 
  
 We'll also look at best practices for logging and reporting, as well as take a 
 closer look at panicking and recovering.
  
 Lastly, we'll want to see how all of these things can be applied not just to our 
 standalone concurrent code, but also to distributed systems.
  
 Along the way, we'll introduce a couple of frameworks for unit testing in a 
 variety of different styles.",NA
Handling errors and logging ,"Though we haven't specifically mentioned it, the idiomatic nature of error handling in 
 Go makes debugging naturally easier by mandate.
  
 One good practice for any large-scale function inside Go code is to return an error as a 
 return value—for many smaller methods and functions, this is potentially burdensome 
 and unnecessary. Still, it's a matter for consideration whenever we're building 
 something that involves a lot of moving pieces.
  
 For example, consider a simple 
 Add()
  function:
  
 func Add(x int, y int) int {
  
  
  return x + y 
  
 }
  
 If we wish to follow the general rule of ""always return an error value"", we may be 
 tempted to convert this function to the following code:
  
 package main 
  
 import 
  
 (
  
  
  ""fmt""
  
  
  ""errors""
  
  
  ""reflect"" 
  
 )
  
 func Add(x int, y int) (int, error) {
  
  
  var err error
  
  
  xType := reflect.TypeOf(x).Kind()
  
  
  yType := reflect.TypeOf(y).Kind()
  
  
  if xType != reflect.Int || yType != reflect.Int {
  
  
  fmt.Println(xType)
  
  
  err = errors.New(""Incorrect type for integer a or b!"")
  
  
 }
  
  
  return x + y, err 
  
 }
  
 func main() {
  
  
  sum,err := Add(""foo"",2)
  
  
  if err != nil {
  
  
  fmt.Println(""Error"",err)
  
  
  }
  
  
  fmt.Println(sum) 
  
 }
  
 [
  588 
 ]",NA
Breaking out goroutine logs ,"One way of handling messaging and logging that keeps a focus on concurrency and 
 isolation is to shackle our goroutine with its own logger that will keep everything 
 separate from the other goroutines.
  
 At this point, we should note that this may not scale—that is, it may at some point 
 become expensive to create thousands or tens of thousands of goroutines that have 
 their own loggers, but at a minimal size, this is totally doable and manageable.
  
 To do this logging individually, we'll want to tie a 
 Logger
  instance to each goroutine, as 
 shown in the following code:
  
 package main
  
 import 
  
 (
  
  
  ""log""
  
 [
  590 
 ]",NA
Using the LiteIDE for richer and easier ,NA,NA
debugging,"In the earlier chapters of this book, we briefly addressed IDEs and gave a few 
 examples of IDEs that have a tight integration with Go.
  
 As we're examining logging and debugging, there's one IDE we previously and 
 specifically didn't mention before, primarily because it's intended for a very small 
 selection of languages—namely, Go and Lua. However, if you end up working 
 primarily or exclusively in Go, you'll find it absolutely essential, primarily as it relates 
 to debugging, logging, and feedback capabilities.
  
 LiteIDE
  is cross-platform and works well on OS X, Linux, and Windows. The number of 
 debugging and testing benefits it presents in a GUI form are invaluable, particularly if 
 you're already very comfortable with Go. That last part is important because developers 
 often benefit most from ""learning the hard way"" before diving in with tools that simplify 
 the programming process. It's almost always better to know how and why something 
 works or doesn't work at the core before being presented with pretty icons, menus, and 
 pop-up windows. Having said that, LiteIDE is a fantastic, free tool for the advanced Go 
 programmer.
  
 By formalizing a lot of the tools and error reporting from Go, we can easily plow 
 through some of the more vexing debugging tasks by seeing them onscreen.
  
 LiteIDE also brings context awareness, code completion, 
 go fmt
 , and more into 
 our workspace. You can imagine how an IDE tuned specifically for Go can help you 
 keep your code clean and bug free. Refer to the following screenshot:
  
 [
  592 
 ]",NA
Sending errors to screen,"Throughout this book, we have usually handled soft errors, warnings, and general 
 messages with the 
 fmt.Println
  syntax by sending a message to the console.
  
 While this is quick and easy for demonstration purposes, it's probably ideal to use 
 the 
 log
  package to handle these sorts of things. This is because we have more 
 versatility, as 
 log
  relates to where we want our messages to end up.
  
 [
  593 
 ]",NA
Logging errors to file,"There are a lot of ways to send an error to a logfile—we can, after all, handle this 
 with built-in file operation OS calls. In fact, this is what many people do.
  
 However, the 
 log
  package offers some standardization and potential symbiosis 
 between the command-line feedback and more permanent storage of errors, 
 warnings, and general information.
  
 The simplest way to do this is to open a file using the 
 os.OpenFile()
  method (and 
 not the 
 os.Open()
  method) and pass that reference to our log instantiation as 
 io.Writer
 .
  
 [
  594 
 ]",NA
Logging errors to memory ,"When we talk about logging errors to memory, we're really referring to a data store, 
 although there's certainly no reason other than volatility and limited resources to reject 
 logging to memory as a viable option.
  
 While we'll look at a more direct way to handle networked logging through 
  
 another package in the next section, let's delineate our various application errors in a 
 concurrent, distributed system without a lot of hassle. The idea is to use shared memory 
 (such as Memcached or a shared memory data store) to pass our log messages.
  
 While these will technically still be logfiles (most data stores keep individual records 
 or documents as JSON-encoded hard files), it has a distinctively different feel than 
 traditional logging.
  
 Going back to our old friend from the previous chapter—CouchDB—passing our logging 
 messages to a central server can be done almost effortlessly, and it allows us to track not 
 just individual machines, but their individual concurrent goroutines. 
  
 The code is as follows:
  
 package main
  
 import 
  
 (
  
  
  ""github.com/couchbaselabs/go-couchbase""
  
  
  ""io""
  
  
  ""time""
  
  
  ""fmt""
  
  
  ""os""
  
  
  ""net/http""
  
  
  ""crypto/md5""
  
  
  ""encoding/hex"" 
  
 ) 
  
 type LogItem struct {
  
  
  ServerID string ""json:server_id""
  
  
  Goroutine int ""json:goroutine""
  
  
  Timestamp time.Time ""json:time""
  
  
  Message string ""json:message""
  
  
  Page string ""json:page"" 
  
 }
  
 [
  596 
 ]",NA
Using the log4go package for robust ,NA,NA
logging ,"As with most things in Go, where there's something satisfactory and extensible in the 
 core page, it can be taken to the next level by a third party—Go's wonderful logging 
 package is truly brought to life with 
 log4go
 .
  
 Using log4go greatly simplifies the process of file logging, console logging, and 
 logging via TCP/UDP.
  
  
 For more information on log4go, visit 
 https://code.google.
  
  
 com/p/log4go/
 .
  
 Each instance of a 
 log4go Logger
  interface can be configured by an XML 
 configuration file and can have filters applied to it to dictate where messaging goes. 
 Let's look at a simple HTTP server to show how we can direct specific logs to 
 location, as shown in the following code:
  
 package main
  
 import (
  
  
  ""code.google.com/p/log4go""
  
  
  ""net/http""
  
  
  ""fmt""
  
  
  ""github.com/gorilla/mux"" 
  
 )
  
 [
  598 
 ]",NA
Panicking,"With all the discussion of capturing errors and logging them, we should probably 
 consider the 
 panic()
  and 
 recover()
  functionality in Go.
  
 As briefly discussed earlier, 
 panic()
  and 
 recover()
  operate as a more basic, 
 immediate, and explicit error detection methodology than, say, 
 try
 /
 catch
 /
 finally 
 or 
 even Go's built-in error return value convention. As designed, 
 panic()
  unwinds the 
 stack and leads to program exit unless 
 recover()
  is invoked. This means that unless 
 you explicitly recover, your application will end.
  
 So, how is this useful other than for stopping execution? After all, we can catch an 
 error and simply end the application manually through something similar to the 
 following code:
  
 package main
  
 import
  
 (
  
  ""fmt""
  
 [
  603 
 ]",NA
Recovering ,"The 
 panic()
  function on its own is fairly simple, and it really becomes useful when 
 paired with 
 recover()
  and 
 defer()
 .
  
 Take, for example, an application that returns meta information about a file from the 
 command line. The main part of the application will listen for user input, pass this into a 
 function that will open the file, and then pass that file reference to another function that 
 will get the file's details.
  
 [
  604 
 ]",NA
Logging our panics,"In the preceding code, we can integrate a logging mechanism pretty simply in addition to 
 catching our panics.
  
 One consideration about logging that we haven't discussed is the notion of when to 
 log. As our previous examples illustrate, we can sometimes run into problems that 
 should be logged but may be mitigated by future user action. As such, we can choose 
 to log our errors immediately or save it until the end of execution or a greater 
 function.
  
 The primary benefit of logging immediately is that we're not susceptible to an 
 actual crash preventing our log from being saved. Take the following example:
  
 type LogItem struct {
  
  Message string
  
  Function string
  
 }
  
 var Logs []LogItem
  
 We've created a log 
 struct
  and a slice of 
 LogItems
  using the following code:
  
 func SaveLogs() {
  
  logFile := log4go.NewFileLogWriter(""errors.log"",false)
  
  logFile.SetFormat(""%d %t - %M (%S)"")
  
  logFile.SetRotate(true)
  
  logFile.SetRotateSize(0)
  
  logFile.SetRotateLines(500)
  
  logFile.SetRotateDaily(false)
  
  errorLog := make(log4go.Logger)
  
  errorLog.AddFilter(""file"",log4go.DEBUG,logFile)
  
 [
  607 
 ]",NA
Catching stack traces with concurrent code,"In earlier Go releases, the ability to properly execute a stack trace from our source was a 
 daunting task, which is emblematic of some of the many complaints and concerns users 
 had early on about general error handling in Go.
  
 While the Go team has remained vigilant about the 
 right
  way to do this (as they have 
 with several other key language features such as a lack of generics), stack traces and 
 stack info have been tweaked a bit as the language has grown.",NA
Using the runtime package for granular ,NA,NA
stack traces,"In an effort to capture stack traces directly, we can glean some helpful pieces of 
 information from the built-in runtime package.
  
 Specifically, Go provides a couple of tools to give us insight into the invocation 
 and/or breakpoints of a goroutine. The following are the functions within the 
 runtime package:
  
 • 
  
 • 
  
 • 
  
 runtime.Caller()
 : This returns information about the parent function of a 
 goroutine
  
 runtime.Stack()
 : This allocates a buffer for the amount of data in a stack 
 trace and then fills that with the trace
  
 runtime.NumGoroutine()
 : This returns the total number of open goroutines
  
 We can utilize all three preceding tools to better describe the inner workings of any 
 given goroutine and related errors.
  
 [
  609 
 ]",NA
Summary,"Debugging, testing, and logging concurrent code can be particularly cumbersome, often 
 when concurrent goroutines fail in a seemingly silent fashion or fail to execute 
 whatsoever.
  
 We looked at various methods of logging, from file to console to memory to 
 network logging, and examined how concurrent application pieces can fit into these 
 various implementations.
  
 By now, you should be comfortable and natural in creating robust and expressive 
 logs that rotate automatically, impose no latency or bottlenecks, and assist in 
 debugging your applications.
  
 You should feel comfortable with the basics of the runtime package. We'll dive into 
 the testing package, controlling goroutines more explicitly, and unit testing as we 
 dig deeper in the next chapter.
  
 In addition to further examining the testing and runtime packages, in our final 
 chapter, we'll also broach the topic of more advanced concurrency topics in Go as 
 well as review some overall best practices as they relate to programming in the Go 
 language.
  
 [
  613 
 ]",NA
Advanced Concurrency ,NA,NA
and Best Practices,"Once you're comfortable with the basic and intermediate usage of concurrency 
 features in Go, you may find that you're able to handle the majority of your 
 development use cases with bidirectional channels and standard concurrency tools.
  
 In 
 Chapter 2
 , 
 Understanding the Concurrency Model
 , and 
 Chapter 3
 , 
 Developing a 
 Concurrent Strategy
 , we looked at the concurrency models, not just of Go but of other 
 languages as well, and compared the way they—and distributed models—can work. In 
 this chapter, we'll touch on those and some higher level concepts with regard to 
 designing and managing your concurrent application.
  
 In particular, we're going to look at central management of goroutines and their 
 associated channels—out of the box you may find goroutines to be a set-it-and-forget-it 
 proposition; however, there are cases where we might want more granular control of a 
 channel's state.
  
 We've also looked quite a bit at testing and benchmarking from a high level, but we'll look 
 at some more detailed and complex methods for testing. We'll also explore a primer on 
 the Google App Engine, which will give us access to some specific testing tools we haven't 
 yet used.
  
 Finally, we'll touch upon some general best practices for Go, which will surely 
 pertain not just to concurrent application design but your future work in general 
 with the language.",NA
Going beyond the basics with channels,"We've talked about quite a few different channel implementations—channels of 
 different type (interfaces, functions, structs, and channels)—and touched upon the 
 differences in buffered and unbuffered channels. However, there's still a lot more we 
 can do with the design and flow of our channels and goroutines.
  
 By design, Go wants you to keep things simple. And that's fantastic for 90 percent of 
 what you'll do with Go. But there are other times where you'll need to dig a little 
 deeper for a solution, or when you'll need to save resources by preserving the amount 
 of open goroutine processes, channels, and more.
  
 You may, at some point, want some hands on control of the size and state, and 
 also the control of a running or closed goroutine, so we'll look at doing that.
  
 Just as importantly, designing your goroutines to work in concert with the 
 application design as a whole can be critical to unit testing, which is a topic 
 we'll touch on in this final chapter.",NA
Building workers,"Earlier in this book, we talked about concurrency patterns and a bit about workers. We 
 even brought the workers concept into play in the previous chapter, when we were 
 building our logging systems.
  
 Truly speaking, ""worker"" is a fairly generic and ambiguous concept, not just in Go, but 
 in general programming and development. In some languages, it's an object/ 
 instantiated class, and in others it's a concurrent actor. In functional programming 
 languages, worker is a graduated function return passed to another.
  
 If we go back to the preface, we will see that we have literally used the Go gopher as an 
 example of a worker. In short, a worker is something more complex than a single 
 function call or programmatic action that will perform a task one or more times.
  
 So why are we talking about it now? When we build our channels, we are creating a 
 mechanism to do work. When we have a struct or an interface, we're combining 
 methods and values at a single place, and then doing work using that 
 object
  as both a 
 mechanism for the work as well as a place to store information about that work.
  
 This is particularly useful in application design, as we're able to delegate various 
 elements of an application's functionality to distinct and well-defined workers. 
 Consider, for example, a server pinging application that has specific pieces doing 
 specific things in a self-contained, compartmentalized manner.
  
 [
  616 
 ]",NA
Implementing nil channel blocks ,"One of the bigger problems in designing something like a pipeline or producer/ 
 consumer model is there's somewhat of a black hole when it comes to the state of 
 any given goroutine at any given time.
  
 Consider the following loop, wherein a producer channel creates an arbitrary set of 
 consumer channels and expects each to do one and only one thing:
  
 package main
  
 import (
  
  
  ""fmt""
  
  
  ""time"" 
  
 )
  
 const CONSUMERS = 5
  
 func main() {
  
  Producer := make(chan (chan int))
  
  for i := 0; i < CONSUMERS; i++ {
  
  go func() {
  
  
  time.Sleep(1000 * time.Microsecond)
  
  
  conChan := make(chan int)
  
  go func() {
  
  
  for {
  
  
  select {
  
  
  case _,ok := <-conChan:
  
    
  if ok  {
  
    
  Producer <- conChan
  
    
  }else {
  
    
  return
  
    
  }
  
  
  default:
  
  
  }
  
  
  }
  
  }()
  
  
  conChan <- 1
  
  
  close(conChan)
  
  }()
  
  }
  
 [
  622 
 ]",NA
Using nil channels,"In the earlier versions of Go, you could communicate across uninitialized, thus nil or 0-
 value channels without a panic (although your results would be unpredictable). 
  
 Starting from Go Version 1, communication across nil channels produced a 
 consistent but sometimes confusing effect.
  
 It's vital to note that within a select switch, transmission on a nil channel on its own will 
 still cause a deadlock and panic. This is something that will most often creep up when 
 utilizing global channels and not ever properly initializing them. The following is an 
 example of such transmission on a nil channel:
  
 func main() {
  
  var channel chan int
  
  channel <- 1
  
  for {
  
  select {
  
  
  case <- channel:
  
  
  default:
  
  }
  
  }
  
 }
  
 As the channel is set to its 
 0
  value (nil, in this case), it blocks perpetually and the Go 
 compiler will detect this, at least in more recent versions. You can also duplicate this 
 outside of a 
 select
  statement, as shown in the following code:
  
  var done chan int
  
  defer close(done)
  
  defer log.Println(""End of script"")
  
  go func() {
  
  time.Sleep(time.Second * 5)
  
  done <- 1
  
  }()
  
  for {
  
  select {
  
  
  case <- done:
  
    
  log.Println(""Got transmission"")
  
    
  return
  
  
  default:
  
  }
  
  }
  
 [
  624 
 ]",NA
Implementing more granular control over ,NA,NA
goroutines with tomb,"As with many such problems—both niche and common—there exists a third-party 
 utility for grabbing your goroutines by the horns.
  
 Tomb is a library that provides diagnostics to go along with any goroutine and 
 channel—it can tell a master channel if another goroutine is dead or dying.
  
 In addition, it allows you to explicitly kill a goroutine, which is a bit more nuanced than 
 simply closing the channel it is attached to. As previously mentioned, closing the channel 
 is effectively neutering a goroutine, although it could ultimately still be active.
  
 You are about to find a simple fetch-and-grab body script that takes a slice of URL 
 structs (with status and URI) and attempts to grab the HTTP response for each and 
 apply it to the struct. But instead of just reporting information from the goroutines, 
 we'll have the ability to send ""kill messages"" to each of a ""master"" struct's child 
 goroutines.
  
 In this example, we'll run the script for 10 seconds, and if any of the goroutines fail to do 
 their job in that allotted time, it will respond that it was unable to get the URL's body due 
 to a kill send from the master struct that invoked it:
  
 package main
  
 import (
  
  
  ""fmt""
  
  
  ""io/ioutil""
  
  
  
 ""launchpad.net/tomb""
  
  
  ""net/http""
  
  
  ""strconv""
  
  
  ""sync""
  
  
  ""time"" 
  
 )
  
 var URLS []URL
  
 type GoTomb struct {
  
  
  tomb tomb.Tomb 
  
 }
  
 [
  625 
 ]",NA
Timing out with channels ,"One somewhat critical point with channels and 
 select
  loops that we haven't 
 examined particularly closely is the ability—and often necessity—to kill a 
 select 
 loop after a certain timeout.
  
 Many of the applications we've written so far are long-running or perpetually-running, 
 but there are times when we'll want to put a finite time limit on how long goroutines can 
 operate.
  
 The 
 for { select { } }
  switch we've used so far will either live perpetually 
 (with a default case) or wait to be broken from one or more of the cases.
  
 There are two ways to manage interval-based tasks—both as part of the time 
 package, unsurprisingly.
  
 The 
 time.Ticker
  struct allows for any given operation after the specified period of 
 time. It provides C, a blocking channel that can be used to detect activity sent after 
 that period of time; refer to the following code:
  
 package main
  
 import (
  
  
  ""log""
  
  
  ""time"" 
  
 )
  
 [
  628 
 ]",NA
Building a load balancer with concurrent ,NA,NA
patterns ,"When we built our server pinging application earlier in this chapter, it was probably 
 pretty easy to imagine taking this to a more usable and valuable space.
  
 Pinging a server is often the first step in a health check for a load balancer. Just as Go 
 provides a usable out-of-the-box web server solution, it also presents a very clean 
 Proxy
  
 and 
 ReverseProxy
  struct and methods, which makes creating a load balancer rather 
 simple.
  
 Of course, a round-robin load balancer will need a lot of background work, 
 specifically on checking and rechecking as it changes the 
 ReverseProxy 
 location between requests. We'll handle these with the goroutines triggered 
 with each request.
  
 Finally, note that we have some dummy URLs at the bottom in the configuration—
 changing those to production URLs should immediately turn the server that runs this 
 into a working load balancer. Let's look at the main setup for the application:
  
 package main
  
 import (
  
  
  ""fmt""
  
  
  ""log""
  
  
  ""net/http""
  
  
  ""net/http/httputil""
  
  
  ""net/url""
  
  
  ""strconv""
  
  
  ""time"" 
  
 )
  
 const MAX_SERVER_FAILURES = 10 
  
 const DEFAULT_TIMEOUT_SECONDS = 5 
  
 const MAX_TIMEOUT_SECONDS = 60 
  
 const TIMEOUT_INCREMENT = 5 
  
 const MAX_RETRIES = 5
  
 [
  630 
 ]",NA
Choosing unidirectional and bidirectional ,NA,NA
channels,"For the purpose of simplicity, we've designed most of our applications and sample code 
 with bidirectional channels, but of course any channel can be set unidirectionally. This 
 essentially turns a channel into a ""read-only"" or ""write-only"" channel.
  
 If you're wondering why you should bother limiting the direction of a channel 
 when it doesn't save any resources or guarantee an issue, the reason boils down to 
 simplicity of code and limiting the potential for panics.
  
 By now we know that sending data on a closed channel results in a panic, so if we 
 have a write-only channel, we'll never accidentally run into that problem in the 
 wild. Much of this can also be mitigated with 
 WaitGroups
 , but in this case that's a 
 sledgehammer being used on a nail. Consider the following loop:
  
 const TOTAL_RANDOMS = 100
  
 func concurrentNumbers(ch chan int) {
  
  for i := 0; i < TOTAL_RANDOMS; i++ {
  
  ch <- i
  
  }
  
 }
  
 func main() {
  
  ch := make(chan int)
  
 [
  636 
 ]",NA
Using receive-only or send-only channels,"When we limit the direction or the read/write capability of our channels, we also 
 reduce the potential for closed channel deadlocks if one or more of our processes 
 inadvertently sends on such a channel.
  
 So the short answer to the question ""When is it appropriate to use a unidirectional 
 channel?"" is ""Whenever you can.""
  
 Don't force the issue, but if you can set a channel to read/write only, it may preempt 
 issues down the road.",NA
Using an indeterminate channel type,"One trick that can often come in handy, and we haven't yet addressed, is the ability to 
 have what is effectively a typeless channel.
  
 If you're wondering why that might be useful, the short answer is concise code and 
 application design thrift. Often this is a discouraged tactic, but you may find it useful from 
 time to time, especially when you need to communicate one or more disparate concepts 
 across a single channel. The following is an example of an indeterminate channel type:
  
 [
  637 
 ]",NA
Using Go with unit testing,"As with many of the basic and intermediate development and deployment 
 requirements you may have, Go comes with a built-in application for handling unit 
 tests.
  
 The basic premise behind testing is that you create your package and then create a 
 testing package to run against the initial application. The following is a very basic 
 example:
  
 mathematics.go
  
 package mathematics
  
 func Square(x int) int {
  
  return x * 3
  
 }
  
 mathematics_test.go
  
 package mathematics
  
 import
  
 (
  
  ""testing""
  
 )
  
 func Test_Square_1(t *testing.T) {
  
  if Square(2) != 4 {
  
  t.Error(""Square function failed one test"")
  
  }
  
 }
  
 A simple Go test in that subdirectory will give you the response you're looking for. While 
 this was admittedly simple—and purposefully flawed—you can probably see how easy it 
 is to break apart your code and test it incrementally. This is enough to do very basic unit 
 tests out of the box.
  
 Correcting this would then be fairly simple—the same test would pass on the 
 following code:
  
 func Square(x int) int {
  
  return x * x
  
 }
  
 The testing package is somewhat limited; however, as it provides basic pass/fails 
 without the ability to do assertions. There are two third-party packages that can step 
 in and help in this regard, and we'll explore them in the following sections.
  
 [
  639 
 ]",NA
GoCheck,"GoCheck
  extends the basic testing package primarily by augmenting it with 
 assertions and verifications. You'll also get some basic benchmarking utility out of it 
 that works a little more fundamentally than anything you'd need to engineer using 
 Go.
  
  
 For more details on GoCheck visit 
 http://labix.org/gocheck
  
  
 and install it using 
 go get gopkg.in/check.v1
 .",NA
Ginkgo and Gomega,"Unlike GoCheck, Ginkgo (and its dependency Gomega) takes a different approach to 
 testing, utilizing the 
 behavior-driven development
  (
 BDD
 ) model. Behavior-driven 
 development is a general model for making sure your application does what it should at 
 every step, and Ginkgo formalizes that into some easily parseable properties.
  
 BDD tends to complement test-driven development (for example, unit testing) rather than 
 replacement. It seeks to answer a few critical questions about the way people (or other 
 systems) will interact with your application. In that sense, we'll generally describe a 
 process and what we expect from that process in fairly human-friendly terms. The 
 following is a short snippet of such an example:
  
 Describe(""receive new remote TCP connection"", func() {
  
  Context(""user enters a number"", func() {
  
  It(""should be an integer"", func() {
  
  })
  
  })
  
 })
  
 This allows testing to be as granular as unit testing, but also expands the way we 
 handle application usage in verbose and explicit behaviors.
  
 If BDD is something you or your organization is interested in, this is a fantastic, 
 mature package for implementing deeper unit testing.
  
  
 For more information on Ginkgo go to 
 https://github.com/
  
  
 onsi/ginkgo
  and install it using 
 go get github.com/onsi/
  
 ginkgo/ginkgo
 .
  
 For more information on dependency, refer to 
 go get github.com/
  
 onsi/gomega
 .
  
 [
  640 
 ]",NA
Using Google App Engine,"If you're unfamiliar with Google App Engine, the short version is it's a cloud 
 environment that allows for simple building and deployment of 
 Platform-As-A-
 Service
  (
 paas
 ) solutions.
  
 Compared to a lot of similar solutions, Google App Engine allows you to build and test 
 your applications in a very simple and straightforward way. Google App Engine allows 
 you to write and deploy in Python, Java, PHP, and of course, Go.
  
 For the most part, Google App Engine provides a standard Go installation that 
 makes it easy to dovetail off of the 
 http
  package. But it also gives you a few 
 noteworthy additional packages that are unique to Google App Engine itself:
  
 Package
  
 Description
  
  
 appengine/memcache
  
 appengine/mail
  
 appengine/log 
  
 appengine/user
  
 appengine/search
  
 appengine/xmpp
  
 appengine/urlfetch
  
 appengine/aetest
  
 This provides a distributed memcache 
  
 installation unique to Google App Engine This 
 allows you to send e-mails through an SMTP-
 esque platform 
  
 Given your storage may be more ephemeral 
 here, it formalizes a cloud version of the log 
 This opens both identity and OAuth 
  
 capabilities 
  
 This gives your application the power of 
  
 Google search on your own data via datastore 
 This provides Google Chat-like capabilities
  
 This is a crawler functionality
  
 This extends unit testing for Google App 
 Engine
  
 While Go is still considered beta for Google App Engine, you can expect that if anyone 
 was able to competently deploy it in a cloud environment, it would be Google.",NA
Utilizing best practices,"The wonderful thing with Go when it comes to best practices is that even if you 
 don't necessarily do everything right, either Go will yell at you or provide you with 
 the tools necessary to fix it.
  
 If you attempt to include code and not use it, or if you attempt to initialize a variable and 
 not use it, Go will stop you. If you want to clean up your code's formatting, Go enables it 
 with 
 go fmt
 .
  
 [
  641 
 ]",NA
Structuring your code ,"One of the easiest things you can do when building a package from scratch is to 
 structure your code directories in an idiomatic way. The standard for a new 
 package would look something like the following code:
  
 /projects/
  
  
  thisproject/
  
  
  bin/
  
  
  pkg/
  
  
  src/
  
    
  package/
  
     
  mypackage.go
  
 Setting up your Go code like this is not just helpful for your own organization, but 
 allows you to distribute your package more easily.",NA
Documenting your code ,"For anyone who has worked in a corporate or collaborative coding environment, 
 documentation is sacrosanct. As you may recall earlier, using the 
 godoc
  command 
 allows you to quickly get information about a package at the command line or via an ad 
 hoc localhost server. The following are the two basic ways you may use 
 godoc
 :
  
 Using godoc
  
 Description
  
 godoc fmt 
  
 godoc -http=:3000
  
 This brings 
 fmt
  documentation to the screen 
 This hosts the documentation on port 
 :3030
  
 Go makes it super easy to document your code, and you absolutely should. By 
 simply adding single-line comments above each identifier (package, type, or 
 function), you'll append that to the contextual documentation, as shown in the 
 following code:
  
 // A demo documentation package 
  
 package documentation
  
 // The documentation struct object 
  
 // Chapter int represents a document's chapter // 
 Content represents the text of the documentation 
 type Documentation struct {
  
  
  Chapter int
  
  
  Content string 
  
 }
  
 [
  642 
 ]",NA
Making your code available via go get,"Assuming you've kept your code in a manner consistent with the organizational 
 techniques as listed previously, making your code available via code repositories and 
 hosts should be a cinch.
  
 Using GitHub as the standard, here's how we might design our third-party 
 application:
  
 1. Make sure you stick to the previous structural format.
  
 2. Keep your source files under the directory structures they'll live in 
 remotely. In other words, expect that your local structure will reflect the 
 remote structure.
  
 3. Perhaps obviously, commit only the files you wish to share in the 
  
 remote repository.
  
 Assuming your repository is public, anyone should be able to get (
 go get
 ) and 
 then install (
 go install
 ) your package.",NA
Keeping concurrency out of your packages,"One last point that might seem somewhat out of place given the context of the book—if 
 you're building separate packages that will be imported, avoid including concurrent 
 code whenever possible.
  
 This is not a hard-and-fast rule, but when you consider potential usage, it makes 
 sense—let the main application handle the concurrency unless your package 
 absolutely needs it. Doing so will prevent a lot of hidden and difficult-to-debug 
 behavior that may make your library less appealing.
  
 [
  643 
 ]",NA
Summary,"It is my sincere hope that you've been able to explore, understand, and utilize the 
 depths of Go's powerful abilities with concurrency through this book.
  
 We've gone over a lot, from the most basic, channel-free concurrent goroutines to 
 complex channel types, parallelism, and distributed computing, and we've brought some 
 example code along at every step.
  
 By now, you should be fully equipped to build anything your heart desires in code, in a 
 manner that is highly concurrent, fast, and error-free. Beyond that, you should be able to 
 produce well-formed, properly-structured, and documented code that can be used by 
 you, your organization, or others to implement concurrency where it is best utilized.
  
 Concurrency itself is a vague concept; it's one that means slightly different things to 
 different people (and across multiple languages), but the core goal is always fast, 
 efficient, and reliable code that can provide performance boosts to any application.
  
 Armed with a full understanding of both the implementation of concurrency in Go as 
 well as its inner workings, I hope you continue your Go journey as the language 
 evolves and grows, and similarly implore you to consider contributing to the Go 
 project itself as it develops.
  
 [
  644 
 ]",NA
Bibliography,"This book is a blend of text and projects, all packaged up keeping your journey in mind. It 
  
 includes content from the following Packt books:
  
 f 
  
 Learning Go Web Development, Nathan Kozyra
  
 f 
  
 Go Programming Blueprints, Mat Ryer
  
 f 
  
 Mastering Concurrency in Go, Nathan Kozyra",NA
Go: Building Web Applications,NA,NA
About Packt Publishing ,"Packt, pronounced 'packed', published its first book, 
 Mastering phpMyAdmin for Effective MySQL 
 Management
 , in April 2004, and subsequently continued to specialize in publishing highly 
 focused books on specific technologies and solutions.
  
 Our books and publications share the experiences of your fellow IT professionals in adapting and 
 customizing today's systems, applications, and frameworks. Our solution-based books give you 
 the knowledge and power to customize the software and technologies you're using to get the job 
 done. 
  
 Packt books are more specific and less general than the IT books you have seen in the past. Our 
 unique business model allows us to bring you more focused information, giving you more of 
 what you need to know, and less of what you don't.
  
 Packt is a modern yet unique publishing company that focuses on producing quality, 
 cutting-edge books for communities of developers, administrators, and newbies 
 alike. For more information, please visit our website at 
 www.packtpub.com
 .",NA
Writing for Packt ,"We welcome all inquiries from people who are interested in authoring. Book proposals should 
 be sent to 
 author@packtpub.com
 . If your book idea is still at an early stage and you would 
 like to discuss it first before writing a formal book proposal, then please contact us; one of our 
 commissioning editors will get in touch with you.
  
 We're not just looking for published authors; if you have strong technical skills but no writing 
 experience, our experienced editors can help you develop a writing career, or simply get some 
 additional reward for your expertise.
  
 Please check 
 www.PacktPub.com
  for information on our titles",NA
