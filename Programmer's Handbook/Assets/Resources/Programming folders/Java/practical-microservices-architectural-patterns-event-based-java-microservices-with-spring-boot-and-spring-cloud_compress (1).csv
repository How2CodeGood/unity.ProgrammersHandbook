Larger Text,Smaller Text,Symbol
Practical ,NA,NA
Microservices ,NA,NA
Architectural ,NA,NA
Patterns,NA,NA
Event-Based Java Microservices ,NA,NA
with Spring Boot and Spring ,NA,NA
Cloud—,NA,NA
Binildas Christudas,NA,NA
"Foreword by Guy Pardon, Allard Buijze ",NA,NA
and Schahram Dustdar,NA,NA
Practical ,NA,NA
Microservices ,NA,NA
Architectural ,NA,NA
Patterns,NA,NA
Event-Based Java Microservices ,NA,NA
with ,NA,NA
Spring Boot and Spring Cloud,NA,NA
Binildas Christudas,NA,NA
"Foreword by Guy Pardon, Allard Buijze ",NA,NA
and Schahram Dustdar,NA,NA
"To Sowmya, Ann, and Ria.",NA,NA
Table of Contents,"About the Author xxi
  
 About the Technical Reviewer xxiii
  
 Acknowledgments xxv
  
 Foreword xxvii
  
 Introduction xxxi
  
 Chapter 1
 : 
 Distributed Computing Architecture Landscape  1 
 System Architectures  
 2 Mainframe Architecture  4 Client-Server Architecture  4 Three-Tier Architecture 4 N-
 Tier Architecture  5 Network Architectures  5 Point to Point  6 Hub and Spoke  6 
 Enterprise Message Bus  6 Enterprise Service Bus (ESB)  7 Software Architectures  7 
 Application Tiers  7 Application Layers  8 The Application Architecture Landscape  8 
 Typical Application Architecture  9 Typical Deployment Architecture  11 The Scalability 
 Dilemma  13 Application State  13
  
 v",NA
About the Author,"Binildas Christudas
  provides technical architecture 
 consultancy for IT solutions. He has over 20 years of IT 
 experience, mostly in Microsoft and Oracle technologies. 
 Distributed computing and service-oriented integration 
 are his main skills, with extensive hands-on experience 
 in Java and C# programming. A well- known and highly 
  
 sought-after thought leader, Binil has designed and built 
 many highly scalable middle-tier and integration solutions for several top-notch 
 clients including Fortune 500 companies. He has been employed by multiple IT 
 consulting firms including Infosys and Tata Consultancy Services and currently works 
 for IBS Software Private Limited as the Chief Architect. In his role as VP and Head of 
 Technology, he leads technology and architecture strategies for IBS’s product portfolio.
  
 Binil is a Sun Certified Programmer (SCJP), Developer (SCJD), Business Component 
 Developer (SCBCD), and Enterprise Architect (SCEA), Microsoft Certified Professional 
 (MCP), and Open Group (TOGAF8) Certified Enterprise Architecture Practitioner. He is 
 also a Licensed Zapthink Architect (LZA) in SOA. Binil has his B.Tech. in Mechanical 
 Engineering from the College of Engineering, Trivandrum (CET) and MBA in Systems 
 from the Institute of Management Kerala (IMK). Binil was the captain of the Kerala 
 University Power Lifting team and was the national champion during his university 
 studies. IBS has applied for his proposal titled “A Method and a System for Facilitating 
 Multitenancy of Services” to be a patent with the USPTO. Binil can be contacted through 
 www.linkedin.com/in/binildasca/
  or 
 www.facebook.com/binildas.christudas
 . 
  
 xxi",NA
About the Technical Reviewer,"Arun Prasanth
  has 12 years of experience as a hands-on 
 software architect involved in the architecture, design, 
  
 coding, and implementation of Java/J2EE-based 
  
 microservices architecture and service-oriented 
 architecture. 
  
 He is currently working as senior technical architect in IBS 
 software services in Japan. Previously, he worked in the 
 banking domain at Societe Generale Global Solutions. 
  
 xxiii",NA
Acknowledgments,"A big thanks to Apress Media for having trust in me and giving me the opportunity to 
 write this book. Nikhil Karkal and Divya Modi from Apress have been very helpful in 
 making the process seamless and quick for me. I want to thank Siddhi Chavan for 
 collaborating with me and providing detailed instructions on how to make the content 
 even better. I also thank Matthew Moodie for providing the shape of this book through 
 the initial chapters.
  
 The tech-friendly workplace at IBS Software has been a boon for me. Many thanks to 
 Mr. V. K. Mathews, Executive Chairman, IBS Group, for consistent motivation throughout 
 my literary journey. I also need to thank Mr. Arun Hrishikesan, Chief Technology Officer, 
 IBS, for his constant reminders and support for completing this book, especially in 
 providing his broader views on technology areas, which has influenced the content and 
 style of this book to a great extent.
  
  
 I thank Dr. Schahram for the many hours of interactions where he shared his views 
 on CAP theorem and its implications in practical software architectures.
  
  
 Special thanks are due to Mr. Allard Buijze, CTO & Founder at AxonIQ, who extended 
 all support in completing this book.
  
 My note of thanks to Dr. Guy Pardon, PhD, Global Solutions Architect at Atomikos, 
 for providing his insights into my book proposal and contents. Guy kept us honest, 
 picking up technical errors and ambiguities. The complete weekend dedicated to 
 making the chapters on transactions so detailed was invaluable, and I am so thankful.
  
 Arun Prasanth made sure all the examples within this book were working as 
 expected. I thank him for reviewing the code content and also for doing the technical 
 review for the book.
  
  
 Finally, special thanks to my wife, Sowmya Hubert, who knows how strong my 
 passion for technology is and who never complains about the time I spend writing. 
  
 I would like to thank my daughters, Ann S. Binil and Ria S. Binil, who were way too 
 understanding and supportive over the last many months while I was locked away with 
 my laptop instead of spending time with them. A huge thanks is due to my father, 
 Christudas Y., and mother, Azhakamma J., for their selfless support, which helped me 
 reach where I am today. Also my note of thanks to my in-laws, Hubert Daniel and Pamala 
 Percis. Finally, thanks to my sister, Dr. Binitha, her husband, Dr. Segin Chandran, and 
 their daughter, Aardra.
  
 xxv",NA
Foreword,"This book you currently hold in your hands is clearly the result of many years of hands- 
 on experience of a software engineer and architect. Binildas Christudas has written a 
  
 comprehensive volume guiding software engineers and software architects through the 
 jungle of conceptual decisions to be made in the realm of distributed systems 
 architectures.
  
 The chapters are structured in a logical manner so that the reader is guided through 
 a set of important questions that need to be asked in all large-scale distributed systems 
 projects. In particular, it deserves to be highlighted that the author spends a good 
 amount of the book explaining in detail all questions software architects and software 
 engineers need to ask before embarking on projects considering the use of microservices 
 and architecting the transition from monolithic architectures towards microservices- 
 based architectures. Furthermore, this book also discusses issues related to cloud 
 deployments, which constitutes a significant aspect of such systems.
  
 The set of exciting and advanced issues discussed in this book covers a range of 
 topics from fundamentals of microservices to questions related to transactions, eventual 
 consistency, cloud deployments, and CAP theorem-related issues.
  
 This volume can serve as a guiding book on all matters related to microservices. It’s a 
 step-by-step manual on which questions to ask and subsequently which steps to take in 
 order to implement microservices-based distributed systems.
  
 Thank you.
  
  
 Schahram Dustdar 
  
 Fellow, IEEE, & Head, Distributed Systems Group 
  
 TECHNISCHE UNIVERSITAT, WEIN (Vienna University of Technology)
  
 xxvii",NA
Introduction,"We have been developing and deploying distributed applications for about two decades, 
 and microservices lays down architectural principles and patterns using many shortfalls 
 in developing, deploying, and maintaining distributed applications can be dealt with. 
 Microservices, also known as the microservice architecture, is an architectural style that 
 structures an application as a collection of loosely coupled, independently deployable 
 services that are highly maintainable and testable and are organized around business 
 capabilities. 
 Practical Microservices Architectural Patterns
  is a practical introduction to 
 writing microservices in Java using lightweight and common technologies like Spring 
 Boot, Spring Cloud and Axon. I present the material in a way that will enable you to use 
 what you learn right away. To that end, I include code samples for all main concepts and 
 show you exactly how to build and execute them.
  
 The book exposes many architectural complexities you will deal with when 
  
 designing microservices, and it uses code samples in solving challenging scenarios. 
  
 Practical Microservices Architectural Patterns is an architect’s book first, but developers 
 and technical managers can benefit from it too. I wrote it keeping in mind Java architects 
 who want to build serious distributed server-side applications in general and 
 microservices in particular. Focus is on what an architect should be aware of on aspects 
 like event-based systems, transactional integrity, data consistency, and so on; 
 developers too will find the exhaustive code useful in their everyday work. Working 
 knowledge of Java, Spring, and a bit of HTTP is assumed to get the samples up and 
 running quickly. If you do not have background in Java and Spring, still the utility build 
 scripts and step-by-step instructions should help you. Further, even though the samples 
 are in Java, all the architectural aspects and many of the chapters are not specific to Java, 
 hence architects with any technology background dealing with distributed systems 
 should benefit from this book.
  
 The book introduces a complete microservices sample e-commerce application. 
  
 The readers can straightaway use it as a template to start building their production 
 systems. Of all the books available in the Java world, this is the first one exclusively 
 demonstrating by simulation all success and failure scenarios of a two-phase commit 
 transaction leveraging an XA transaction manager and two different XA transactional 
  
 xxxi",NA
CHAPTER 1,NA,NA
Distributed ,NA,NA
Computing ,NA,NA
Architecture ,NA,NA
Landscape,"The technology landscape within any given enterprise of considerable size is often very 
 complex, with aging legacy systems, fragmented by business verticals, internal 
 departments, a supply chain, and so on. In some cases, enterprises have more than one 
 system per business process, given that many enterprises have grown through mergers 
 and acquisitions and thus kept multiple systems and also operate internationally and 
 need to maintain links to different partners and service providers. As a result, the 
 technology infrastructure is often described as “spaghetti architecture,” with many-to- 
 many direct dependencies between business systems, partner and supply chain systems, 
 and other service providers.
  
 Starting from the early computer era, we have been developing software to build the 
 above mentioned systems. We evolved from the early punch cards to the next generation 
 assembly languages and then to the era of FORTRAN and COBOL, which further got 
 replaced with C, Smalltalk, and others, and then to C++, Java, and C#. The evolution 
 continues. Architecture has to be adaptable to the programming paradigm, including to 
 the programming language and tools of choice. Any software system of considerable 
 functionality and size has to be built as an afterthought of a suitable software 
  
 architecture. Sticking to a single or similar software architecture, we can build software 
 systems for varied domains and functionality, but no one can build all kinds of systems 
 adopting the same architecture. Thus, the architectural style of software systems must 
 be adapted based on a plethora of considerations, including but not limited to
  
 • 
  
 Business domain
  
 • 
  
 Functionality and usage scenarios",NA
 System Architectures,"If we trace back, we have been happily and successfully building software systems 
 using 
  
 a variety of system architectures. Notable among them in the last few years are the 
  
 following:
  
 • Mainframe architecture
  
 • Client-server architecture
  
 • Three-tier architecture
  
 • N-tier architecture
  
 Let’s look at some of the salient features of these architectures with the help of 
  
 Figure 
 1-1
 .
  
 2",NA
 Mainframe Architecture,"In the mainframe-based architecture, processing power is centralized and multiple 
 clients can be connected to this central compute source using low-powered terminals. 
  
 The terminals are more or less dumb in the sense that they are simple screens that can 
 only assemble character-oriented commands and these commands can be then sent to 
 the central mainframe computer, where the commands get executed. Any response from 
 the mainframe computer is also received back by these terminals as character streams 
 and rendered so that the user can read through them for human interpretation.",NA
 Client-Server Architecture,"The client-server architecture is characterized by one high-powered server to which 
 multiple clients can be connected using comparatively low-powered systems called 
 clients. The server hosts data validation rules, business logic to modify data, and data 
 storage functionality whereas the client hosts data entry mechanisms, data validation 
 rules, and some or nil business logic. These kinds of clients are also called thick clients 
 since in many cases the client-side code is written in languages native to the client 
 operating system, making it easy to fulfil rich user interface (UI) requirements.",NA
 Three-Tier Architecture,"Similar to two-tier architecture, the three-tier architecture also has a client tier. The 
 client hosts data entry mechanisms, data validation rules, and some or nil business logic. 
  
 These clients may be built using languages native to the client operating system, thus 
 providing a rich UI; alternatively, the clients can also be built using HTTP- and HTML- 
 based web browser-compatible languages. In the latter case, the client tier can also be 
 split into another tier called the presentation tier, where the client tier only has data 
 input, data validation, and UI rendering logic, and most of the business logic is moved to 
 the next tiers (the presentation tier or the middle tier). The major difference from two-
 tier architecture is on the server side where the data management and storage logic are 
 separated out from the data validation rules and business logic and are kept on a 
 separate server of their own, often termed as a database server. Similar to that in the 
 two- tier architecture, the data validation rules and business logic are retained in the 
 middle- level server, often termed as the middle tier. As of the last few years, mobile 
 devices also interface with the middle tier.
  
 4",NA
 N-Tier Architecture,"N-tier architecture can be viewed as an extended kind of three-tier architecture where 
 there are multiple middle tier servers with their own database servers, and many of 
 these middle tier servers are interconnected to leverage functionality reuse. The client 
 tier can either directly connect to the middle tier or it can first connect to a presentation 
 tier which in turn talks to the middle tier. Here again, clients in the client tier can be 
 native thick clients or browser-based thin clients or any other variant of mobile client.
  
 I will not explore further details of the above mentioned system architectures since 
 it is assumed that you are knowledgeable in those aspects; otherwise you probably 
 wouldn’t be reading a book like this.",NA
 Network Architectures,"While I covered system architectures of relevance in the previous section, equally 
 important are the different topologies by which software systems can be interconnected 
 so as to enable integration. Here again I will cover the broader classifications by which 
 networks can be configured so as to enable systems to talk each other, with the help of 
 Figure 
 1-2
 .
  
  
 Figure 1-2. 
 Network integration topologies
  
 5",NA
 Point to Point,"In point-to-point architecture, we define interconnections for a pair of applications. 
  
 Thus we have two end points to be integrated. We can build protocol and/or format 
 adaptors/transformers at one or either end. This is the easiest way to integrate, as long 
 as the volume of integration is low. We normally use technology-specific APIs like FTP, 
 IIOP, remoting, or batch interfaces to realize integration. Between any two integration 
 points, there is tight coupling, since both ends have knowledge about their peers.",NA
 Hub and Spoke,"Hub-and-spoke architecture is also called the 
 message broker
  and provides a 
  
 centralized hub (broker) to which all applications are connected. The distinguishing 
 feature of the hub-and-spoke architecture is that each application connects with the 
 central hub through lightweight connectors. The lightweight connectors facilitate 
 application integration with minimum or no changes to the existing applications. 
 Message transformation and routing takes place within the hub. Since the applications 
 do not connect to other applications directly, they can be removed from the integration 
 topology by plugging off from the hub. Since the hub is a central portion of this kind of 
 topology, the hub is a single point of failure of the entire topology itself.",NA
 Enterprise Message Bus,"In an enterprise message bus topology, there is a common communication 
  
 infrastructure which acts as a platform-neutral and programming language-neutral 
 adaptor between applications. This communication infrastructure may include a 
 message router and/or publish-subscribe channels. So applications interact with each 
 other through the message bus with the help of request-response queues. Sometimes the 
 applications have to use adapters that handle scenarios like invoking CICS
 1
  (Customer 
 Information Control System) transactions. Such adapters may provide connectivity 
 between the applications and the message bus using proprietary bus APIs and 
  
 application APIs.
  
 1
  Customer Information Control System (CICS) is a family of mixed language application servers 
 that provide online transaction management and connectivity for applications on IBM 
 mainframe systems under z/OS and z/VSE.
  
 6",NA
 Enterprise Service Bus (ESB),"The service bus approach to integration makes use of a technology solution to provide a 
 bus for application integration. Different applications will not communicate directly with 
 each other for integration; instead they communicate through this middleware service-
 oriented architecture (SOA) backbone. The most distinguishing feature of the ESB 
 architecture is the distributed nature of the integration topology. Most ESB solutions are 
 based on Web Services Description Language (WSDL) technologies, and they use 
 Extensible Markup Language (XML) formats for message translation and transformation. 
 Compared to an enterprise message bus, the ESB topology requires less adaptors, since 
 interoperability is high due to the SOA nature of the interfaces.",NA
 Software Architectures,"Having seen the system architectures and network architectures in general, let’s now 
 look at leveraging the notion of tiers and layers to bring modularity and manageability to 
 software application architectures.",NA
 Application Tiers,"Tiers generally provide distributed deployment capability for application concerns. 
 Typical application tiers can be listed as follows:
  
 • Client tier
  
 • Presentation tier
  
 • Business tier
  
 • Integration tier
  
 • Resources tier
  
 The above list is not exhaustive. Again, I do not intend to explain these tiers in detail, 
 but generally they enable us to group non-functional and technical capabilities and to 
 provide varied operational abilities for these tiers during production deployments.
  
 7",NA
 Application Layers,"Layers help to separate concerns based on the single responsibility pattern. For 
 example, there can be a controller layer which can provide a central entry point to the 
 application tier where we can perform authentication and authorization checks, 
 application entry logging, routing to right modules, and so on. Similarly, an ORM (object-
 relational mapping) layer may perform the required persistence services to transform 
 application domain objects to storage schemas in a persistence disk and vice versa.
  
  
 Each application tier can be logically separated out into one or more application 
 layers.",NA
 The Application Architecture Landscape,"If we look back a decade, we have been leveraging the n-tier or distributed way of 
 building application architectures. Multiple applications can talk to each other since 
 they are interconnected based on any of the above network topologies.
  
 You will now concentrate on building a single such application. When I talk about 
 a “single application,” I am constraining that application as targeted to perform a set 
 of related or grouped functionalities. An example is an e-commerce application that 
 helps an enterprise to list products for selling purposes and helps its customers to 
 pay and buy these products online with the help of a web browser. Similarly, a stock 
 trading application is another application with a group of functionalities related to 
 trading stocks. Typically we do not club these two applications together since they 
 represent grouping two different sets of functionality. A CRM (customer-relationship 
 management) application, a loyalty application, an airline booking application, and a 
 taxi hiring application are few examples of different such applications.
  
 There can be scenarios where two or more applications need to talk to each other or 
 when we want to mash up functionality from two or more applications. For example, a 
 holiday booking company’s booking application may want to mash up services from the 
 airline booking application of the selected airline and the taxi hiring application of the 
 selected cab service provider mentioned above. These scenarios are outside the scope of 
 a single application architecture but need to be considered at an application integration 
 level. I do not intend to cover aspects like inter application integration or application 
 mashups in the scope of our discussion. Instead, I want to concentrate on the 
  
 architecture of a “single application,” the size of which can vary from small to medium to 
 large based on the volume of functionality we want to group together.
  
 8",NA
 Typical Application Architecture,"Many modern applications used by enterprises today have been built using the n-tier 
 architecture and object-oriented programming languages and are capable of being 
 deployed using distributed technologies and infrastructure. The selection of appropriate 
 layers and tiers enables deployment in a flexible manner to meet scalability 
 requirements. Let’s now look at a typical application architecture for an e-commerce 
 application deployed in a distributed manner.
  
 Figure 
 1-3
  represents a typical application architecture. It is a three-tier application 
 in the sense that the presentation tier is separated out from the business tier, and there 
 is a third database tier too. The presentation tier is packaged as a .war file and 
 encompasses all artifacts required to render the UI in a web browser. The business tier is 
 packaged in a .jar format and contains most of the business functionality and business 
 rules. You may also club the presentation tier and the business tier together and create 
 an application artifact in an .ear format.
  
 The presentation tier and the business tier can be deployed separately into their 
 own set of dedicated server hardware configured either as a simple server farm or as a 
 server cluster. A server farm is a set of server instances hosting application 
 components in such a fashion that subsequent traffic from a single browser instance 
 can be routed to any one instance irrespective of which server instance the previous 
 request was routed to. 
  
 Typically a load balancer sitting in front of the farm will distribute the traffic. Further, 
 application components deployed in a server farm will typically be stateless, which 
 means traffic from a single browser instance can be routed to any one instance 
 irrespective of which server instance the previous request was routed to. In this manner, 
 the requests are “not sticky,” whereas in a server cluster, typically the server instances 
 coordinate themselves with heartbeats and state replication. Here, the requests are 
 sticky, which means requests from a single browser will always be routed to the same 
 server instance in the cluster as long as that server instance is live. However, non-sticky 
 requests can also be served by a cluster depending on how the cluster and load balancer 
 is configured.",NA
 Typical Deployment Architecture,"As mentioned, we can club the presentation tier and the business tier together and 
 create an application artifact in a .ear format for deployment, or they can be kept 
 separate as .war and .jar files, which will allow a more flexible deployment where the 
 presentation tier and the business tier are separated. If these two tiers are deployed 
 together, it will allow for optimized intermodule communications by making local 
 method calls. The reason to separate them is to allow differentiated scale-out 
 deployments between these two tiers, and when we do that, a suitable remoting 
 methodology has to be adopted to facilitate intertier communication. Generally we use 
 Java RMI or more generic IIOP or more flexible protocols like HTTP for this intertier 
 communication.
  
 As shown in Figure 
 1-4
 , there can be one or more network layer firewalls 
 positioned in front of these tiers to control the level of access to functionality to clients 
 from known networks alone. It’s the same case with the database tier. This means we 
 will be able to apply configurations so as to allow only valid application-related calls 
 from the Internet to the presentation tier, and then put more strict rules in front of the 
 other tiers to allow calls to the business tiers only from known and valid IPs.
  
 11",NA
 The Scalability Dilemma,"You have seen the degree of scalability achievable following a well-designed application 
 architecture. However, the technology landscape is evolving at a faster pace, and newer 
 devices and access channels provide continuous pressure to the application architect in 
 terms of increasing the scalability. This new trend is called “web scale,” where the 
 scalability of the application is limited by nothing but the Web itself. By web, we mean 
 the network or the Internet helping unlimited users and devices get connected to the 
 application and access the services.",NA
 Application State,"How many of you don’t like the javax.servlet.http.HttpSession API or the EJB (Enterprise 
 Java Bean) deployment descriptor element called session-type, which can take a value of 
 stateful? For readers unfamiliar with these APIs, here is a short description:
  
 13",NA
 The Dependency Nightmare,"The single responsibility pattern and principles of abstraction advocate building 
 functionality in software using a modular approach. Functionalities that are closely 
 related and similar are grouped together to form a software module. Any application of 
 considerable size will have more than one module.
  
 It is also common to have functionality in one module depend directly on 
  
 functionality in another module within the same application. This dependency is often 
 expressed in terms of method or service invocation across modules. Figure 
 1-5
  shows a 
 request from a user to create an e-commerce order. Once the request comes to the Order 
 module, the module internally does a series of activities:
  
 • Creates an Order entity and associated line items in the database
  
 • Makes a call to the inventory database to deplete inventory
  
 • If required, also invokes a call to the Order History module to make 
 suitable entries
  
 • Internally invokes the Notification module, which subsequently 
 sends an order confirmation notification to the user
  
 Often such intermodule calls are characterized by
  
 • Synchronous Request Response style
  
 • Binary dependency like Java interfaces, stubs, etc.
  
 • Dependency on shared entities
  
 When multiple teams or multiple people develop these modules separately, due to 
 the nature of above intermodule calls, dependency exists across modules, people, and 
 teams. Common libraries and common entities are to be shared. When something 
 changes in a module, the associated libraries need to be updated and redistributed 
 across people and teams so that they can still continue with the development of their 
 individual modules.
  
  
 Further, as discussed, due to these intermodule communications, it is not easy to 
 further divide the application and deploy heterogeneously, if there is a need to do so.
  
 15",NA
 The Application Monolith,"If you closely observe Figure 
 1-4
 , you can understand how to scale the different tiers of 
 an application. Since the application tier is designed as a single whole with intermodule 
 communications as required, it is not easy to further divide the application and deploy 
 heterogeneously. Then the question is, why do we ever want to deploy heterogeneously? 
  
 Out of the different modules like Product, Order, and Shipping, many people might be 
 browsing the product catalogue and the product details whereas only a percentage of 
 these users will actually check out and buy, thus creating an order in the system. 
 Further, we only want to ship orders that are actually paid and confirmed. So, the 
 Product module needs to take more traffic and the Order module needs to handle 
 comparatively less traffic. It would be good if we could deploy more instances of the 
 Product module and fewer instances of the Order module to optimally utilize resources, 
 but since the application tier is designed as a single whole, heterogeneous deployment is 
 not straightforward.
  
 Next, if we want to accommodate change requests in the software, whenever 
 there is a change to be applied to some piece of code in the application, we want to 
 upgrade the application as a whole. Downtime will be considerable, which will affect 
 normal business operations.
  
  
 Further, if there is a bug in the software or if there is some other defect that affects 
 the running application, it is likely that the entire application is affected.
  
 All of these downsides are in spite of the best architecture principles described 
 earlier, and this is the side effect of the monolith architecture, since the application is 
 one single, big block. See Figure 
 1-5
 .
  
 16",NA
 The Scalable Architecture ,"Now let’s look at few aspects of how to make the application architecture web scale.
  
 17",NA
 Stateless Design,"The first principle is to design the application services as stateless. Any state that is 
 permanent can be kept at the database tier whereas any temporary state can be kept at 
 the client tier itself. The downside of this design is that we may have to pass identifiers 
 or tokens along with requests so that at the server side the components will have the 
 right context to execute the requests. But the advantage of such a design is that since the 
 application is stateless, any request from any user can be routed to any instance of the 
 server. This means that even if one of the server instances goes down, the subsequent 
 requests can be served by any other instance in the server farm. Similarly, when you 
 want to scale up the application on the fly, any new server instance added to the farm 
 can also be accounted to load balance all subsequent requests from any client.",NA
 Divide and Conquer,"Next, let’s address the problems associated with the monolith style. We want to abide by 
 the principles of abstraction and build software in a modular way. The moment we break 
 the monolith into multiple modules, there arises the requirement for these modules to 
 depend on each other in terms of service invocations. So there has to be a trade-off 
 between the collocated approach and the divided approach. When the modules are 
 together and co-located, deployment can also happen to a single runtime process, which 
 means intermodule communications are straightforward local invocations. When we 
 divide, again there are two options of deployment: either all of these divided modules 
 can still be deployed in a single process, or for greater operational optimization, they can 
 be deployed into multiple processes. In the latter case, the modules can no longer 
 communicate using local invocations and instead require suitable remoting mechanisms. 
  
 However, the major advantage of a divided approach is that multiple repositories can 
 be maintained for the development artifacts with indirect interdependency and also 
 the development and release processes can happen in many parallel teams. 
 Moreover, modules deployed across processes can be scaled independently, hence 
 this kind of selective scaling will address optimize resources based on actual business 
 needs, not based on constraints dictated due to not-so-well-thought-out architecture 
 approaches.
  
 18",NA
 Summary,"This chapter concentrated on few major characteristics of distributed software 
  
 architecture and its evolution from the early years of software to today. I offered a bird’s 
 eye view of the topics discussed, but the idea was to set the context and look at the 
 different options existing. Towards the end, I touched upon the options for setting the 
 software structure and its impact when we keep the modules together vs. when we 
 separate them out. There are advantages and disadvantages in both of these approaches, 
 but if the benefits we reap when we keep them separated is considerable, we then need 
 to find out ways to manage the not-so-straightforward concerns surrounding 
 manageability and the intermodule communication. I will briefly discuss these aspects in 
 the next chapter. In the following chapters, you will see how all these theories can be put 
 to practice with concrete code examples that you can build and run on your own 
 inexpensive desktops or laptops.
  
 19",NA
CHAPTER 2,NA,NA
Introducing ,NA,NA
Microservices,"The complexity of enterprise software systems increases with increase in the 
  
 functionalities and features supported. As you saw in Chapter 
 1
 , every enterprise system 
 today needs to transfer information seamlessly with many other systems, both internal 
 and external to the organization. Traditionally we have been building software systems 
 as a “modular monolith.” By modular, we mean to say that they follow the principles of 
 modules, layers, and tiers and hence there exists a logical modularity for elements 
 within the software system. By monolith, we mean to say that the entire system is built 
 with a specific scenario of deployment and operation in mind; most of the time, they are 
 deployed as a single process or at the maximum they are distributed following the 
 three-tier or n-tier architecture you saw in Chapter 
 1
 . But there ends the flexibility of 
 deployment. Equally important is the process to be followed in getting such a system 
 built in a multiteam or a distributed team organization.
  
 In this chapter, you will look at few selected concerns enterprises face in building 
 today’s software applications. Once you understand these problems, you will then look 
 at a new style of building software applications where you have increased flexibility in 
 the build, deploy, or operations phases.",NA
 The Modular Monolith,"I chose to call today’s typical enterprise systems as modular monoliths, because they are 
 characterized by many patterns and also not-so-obvious anti-patterns we have been 
 religiously following while defining software architectures. Towards the end of this 
 section, you will appreciate the reason why I use this phrase.",NA
 The Modular Organization,"Since the days of structured programming languages, we have mastered the style of 
 breaking software programs into smaller elements in terms of multiple files, include 
 libraries, backing beans, and such, so that it is easy for a software developer to manage 
 multiple files from within an integrated development environment (IDE) and still 
 develop big applications, complex algorithms, and logic.
  
 The next level of modularization is done at a module level or at a packaging level. 
  
 A module is a collection of related functionalities organized together in the form of 
 multiple program files, libraries, and so on, and which can be managed within the IDE 
 with the help of a top-level build script. Thus one application can be composed of 
 multiple such modules.
  
 When we look at the next stage of the software life cycle where we build and 
 package application, the concept of packages will come to play. Here we address the 
 concerns of building the modules and making it manageable to distribute them to other 
 environments, whether it is for the testing, staging, or production environments. 
  
 Sometimes we also want to distribute software to third-party consumers in the form of 
 libraries.
  
 In the next stage of deployment, we may want to deploy the software packages into 
 one or more computer process or computer runtimes. This is to address different 
 runtime qualities of the system, usually defined in terms of non-functional requirements 
 (NFR) and service level agreements (SLA).
  
 Chapter 
 1
  briefly touched upon the different options by which we can build 
  
 distributed systems, and deploy and operate them in a flexible manner. Now the 
 question is, how flexible they are? To answer this question, look at the typical 
 application architecture shown in Figure 
 1-3
  in Chapter 
 1
 . It consists of the presentation 
 tier, the business tier, and the database tier. The majority of today’s enterprise systems 
 follow such an architecture, and systems with this kind of architectures will keep 
 existing for few more years, at least till the end-of-life (EOL) for which they are built. 
 What is wrong here? It is flexible to be deployed in a distributed fashion into its own 
 tiers. But the flexibility ends there. So what additional flexibility would we require?
  
 22",NA
 The Monolith Application,"Before I attempt to answer the question asked in the previous section, let me define one 
 main nomenclature and its interpretations, which we are going to follow in the rest of 
 this book.
  
 Figure 
 2-1
  shows just the business tier from Figure 
 1-3
 . Typically this tier hosts 
 most of the core logic or the business logic of the software system. Let’s refer to this tier 
 with the name application tier or services tier. This tier has a clear separation from the 
 presentation tier, normally by a controller layer through which all service calls are 
 routed. This tier may expose either a local interface or a remote interface. A local 
 interface is sufficient if the presentation tier and the services tier are deployed in the 
 same process whereas a remote interface like Java RMI, RMI-IIOP or .NET Remoting will 
 be required if these two tiers are deployed in separate processes. In the service-oriented 
 architecture (SOA) paradigm, a suitable SOA interface will replace plain remoting. SOAP 
 over HTTP, REST, etc. are examples of such SOA-friendly interfaces.
  
  
 Figure 2-1. 
 The services tier
  
 Figure 
 2-1
  shows that even though the modules or functional groups are separated 
 from each other, the boundary is only logical and blurred (shown with dotted lines). 
 This means there is no clear-cut separation between the modules. You may also note 
 that it is typical for such architectures still to have an application boundary. But that 
  
 23",NA
 Monolith Application Boundary,"Figure 
 2-2
  depicts more than one monolith application. This is again typical for many 
 existing enterprises where more than one application is required to meet the 
 enterprise’s various functionalities. Since applications in isolation cannot benefit much, 
 they are interconnected at times.
  
  
 Figure 2-2. 
 The monolith application boundary
  
 In Figure 
 2-2
 , there are two types of communications or interactions depicted. 
  
 Within an application, the modules talk to each other either using a local invocation 
 protocol or using a suitable remoting protocol. Equally important is the communication 
 between applications. Typically enterprises use enterprise application integration (EAI) 
 technologies to integrate between applications. The “Network Architectures” section in 
 Chapter 
 1
  discussed briefly how applications can integrate with each other. You might 
 have noticed that most of the time application boundaries are clearly defined and 
 separated, hence most of the time they are deployed out into separate processes or 
 runtime. Due to this reason, they require a suitable remoting mechanism to talk to each 
  
 24",NA
 Monolith Intermodule Dependency,"Modules within an application in a monolith architecture are tightly coupled. These 
 modules talk to each other either using a local invocation protocol or a suitable remoting 
 protocol. Most of the time these calls are synchronous in nature, which means every 
 request transaction also expects a response or an exception back.
  
 When all the modules of a monolith application are packaged and deployed together 
 in the same process, local method invocation is the best option to communicate. In such 
 a deployment, either the entire application is always up, or if there are any issues in any 
 part of any module, the application can also go down in its entirety. If some of the 
 modules are separated out and deployed into a different process, then the health of the 
 process where we have deployed the separated modules will not affect the other 
 dependent process. However, when we look at such a separately deployed module 
 application from its entirety, if the separated modules are down for any reason, then the 
 dependent modules can still be affected. This is because intermodule communication is 
 defined as direct and synchronous method call dependencies, so if the called 
  
 module does not respond or exist, the caller module will be affected. They either get 
 blocked indefinitely or wait for some amount of time and then respond reporting error 
 conditions. Figure 
 2-3
  depicts this.
  
 25",NA
 The Scalability Dilemma,"Modern application architectures are horizontally scalable. By horizontal scalability, we 
 mean more than one instance of the same functionality can be deployed into different 
 processes, and traffic from clients to the same functionality can be served by any one 
 among the server processes where there is duplicated functionality. Such topologies are 
 called server farms. Ideally, requests from the same client (browser or mobile app) can 
 also be routed to any instance of this server farm, irrespective of which server instance 
 served the previous request from the same client.
  
 Figure 
 2-1
  depicts different modules of an e-commerce application. If you think 
 about how a user typically interacts with an e-commerce application, the series of steps 
 may go as follows:
  
  1. Access the home page of the e-commerce application.
  
  2. Browse through the product categories.
  
 26",NA
 Monolith Technology Constraints,"Monolith applications can be considerably large in size. Depending on the life span of the 
 application, it can still evolve in terms of features and functionality, hence its size can 
 keep increasing. Over time, technologies and mechanisms available in the industry can 
 also change. Unfortunately, monolith application architectures have serious limitations 
 in terms of adapting to latest technologies and trends. Most of the platform, technology, 
 tool, and framework choices were decided and baselined during the initial architecture 
 phase, and those decisions are etched in stone. It is not easy to change the solution for a 
 concern from one to another. For example, if the platform of choice has been fixed as 
 Java, then it won’t be easy to use a .NET solution for part of the solution of the 
 application or for building new features. Similarly, if it uses a relational database 
 management system (RDBMS) for persistence related purposes, most of the time it 
 should also use an ORM (object-relational mapping) framework like Hibernate or a data 
 mapping framework like iBatis. For consistency as well as for economies of scale within 
 the whole application, it’s not advisable to introduce a new such framework in place of 
 them for all future extensions. Last but not the least, loading the codebase of a single 
 project into the IDE is memory intensive and will often impede the productivity of the 
 developers.
  
 28",NA
 Introducing Microservices,"Microservices are a different approach to architecting software application. They 
 attempt to address many modern application architecture challenges. We will look at the 
 different architectural challenges we face today and set a base by which we can solve our 
 issues and keep moving.
  
  
 Before we delve deep, here’s one more important nomenclature: the “service” in the 
 context of a microservice.
  
 In SOA, a service is a first-class business functionality that can be accessed by any 
 clients using a standard access protocol over the network. SOA services are autonomous 
 and typically idempotent and stateless. By autonomous, we mean the service by itself is 
 self-sufficient in providing the functionality. By idempotent, we mean invoking the 
 service more than once, knowingly or by error, will not have any side effect. To make it 
 simple, a client can make the same request repeatedly while producing the same result. 
 In other words, making multiple identical requests has the same effect as making a single 
 request. By stateless, we mean we do not store any state on behalf of a specific client in 
 the server, when the service is invoked (this was discussed in the “Stateless Design” 
 section in Chapter 
 1
 ).
  
 You are yet to see what a microservice is, so to keep our current discussion moving, a 
 microservice is analogous to an SOA service. Sometimes a collection of many such 
 services that are functionally related can also be called by the term microservice. We will 
 look at different meanings of this statement later.
  
  
 Let’s revisit few of the challenges we discussed with the monolith approach and see 
 how to address them.",NA
 Independent Modules,"The first and best distinguishable and observable characteristic I want to introduce to 
 the monolith is to convert the monolith into a collection of discrete and independent 
 modules. By making the modules independent, we want to bring all or most of the 
 following flexibilities to the software paradigm:
  
 • 
 Parallel development
 : Each module can be source controlled as a 
 separate repository, hence distributed teams can build these 
 modules independently and in parallel.
  
 29",NA
 Intermodule Communication,"Most of the intermodule communications we have with existing systems are direct and 
 synchronous method invocations. Even if we design these communications as 
 idempotent and stateless, one of the side effects of such calls is that the called module 
 has to be up and live to respond to the caller module, or exceptions and errors can occur. 
 Even if we separate the different modules as independent and deploy them into multiple 
 processes, this side effect still exists and propagates backwards in the call stack. The 
 thread in the caller process making the request to the called process will wait until it 
 gets a valid response with or without data, or until the called method raises an 
 exception. 
  
 This blocks the thread making the request in the caller process and renders the thread 
 useless until the method call returns. So, not only is there a dependency to the called 
 process, but resources in the caller process are also blocked, hence they cannot be 
 multiplexed and reused.
  
 There is, however, one advantage in this synchronous style of intermodule 
 communication. The caller can take the next action after inspecting the response data 
 send by the called process. Also, in a case where the called process doesn’t return 
 expected results, the caller can instantaneously hint that to the user or the client tier 
 agent so as to leverage manual intervention for the next step.
  
 The asynchronous or fire-and-forget style of intermodule communication can relieve 
 the caller resources to be reusable instantaneously after making the call to the 
  
 30",NA
 The Microservices,"You have looked at two main aspects in modernizing the monolith application 
 architecture, They are
  
 • Making the modules independent
  
 • Redesigning the intermodule communications
  
 Figure 
 2-5
  depicts the two architecture modernizations we have discussed. You may 
 want to spend some time observing the diagram in detail, since this is going to be the 
 basic construct upon which you are going to build a lot more improvisations.
  
 31",NA
Note,NA,NA
 “Microservices are a software development technique — a variant ,NA,NA
of the service-oriented architecture (soa) architectural style that ,NA,NA
structures an application as a collection of loosely coupled services. In a ,NA,NA
"microservice architecture, services are fine-grained and the protocols ",NA,NA
are lightweight. the benefit of decomposing an application into different ,NA,NA
smaller services is that it improves modularity. this makes the ,NA,NA
"application easier to understand, develop, test, and become more ",NA,NA
resilient to architecture erosion. It parallelizes development by enabling ,NA,NA
"small autonomous teams to develop, deploy, and scale their respective ",NA,NA
services independently. It also allows the architecture of an individual ,NA,NA
service to emerge through continuous refactoring.”,"Many of the aspects mentioned in this definition have been discussed in these first 
 two chapters. You will now look into this definition from more perspectives and also 
 much more in the next two chapters.",NA
 Summary,"In this chapter, you looked at the state of traditional distributed or n-tier application 
 architectures and explored a few shortcomings due to the monolithic nature of such 
 architectures. There are many other advantages and disadvantages of the monolith 
 architecture that have not been discussed yet, but such a discussion is not in scope since 
 I just wanted to set the context to discuss the alternative way of doing things: using 
 microservices. Now you know that when you switch your thoughts from the monolith to 
 the microservice style, you need to inverse lot of concepts like the application boundary, 
 intercommunications, etc. In the next chapter, you will revisit the microservice 
  
 architecture in detail, relating the concept to real-world enterprise applications.
  
 34",NA
CHAPTER 3,NA,NA
Microservices in ,NA,NA
Depth,"As you saw in Chapter 
 2
 , using microservices is an approach in architecting today’s 
 distributed software solutions. The software industry has gained experience in 
  
 developing and deploying distributed applications over the past two decades, and 
 microservices lay down architectural principles and patterns for dealing with many 
 shortfalls in developing, deploying and maintaining distributed applications. We 
 discussed the context and necessity for the microservices architecture in the previous 
 two chapters and in this chapter we will look at it into more detail. I will again attempt 
 to explain concepts in the context of a real-world application, the e-commerce 
 application I introduced in Chapter 
 1
 . This will help you to quickly relate aspects to 
 practical scenarios in your real-world experience.
  
 You will explore the following aspects in this chapter:
  
 • What the e-commerce architecture will look like in the microservices 
 context
  
 • The relationship between the classic tiered and layered approach in a 
 microservices context
  
 • The autonomous nature of microservices
  
 • The relationship between microservices and traditional SOA 
 and MOM
  
 • The scalability and extensibility characteristics of the microservices 
 architecture",NA
 Look and Feel of a Microservice,"You just learned that, compared to a traditional monolith application, many 
  
 characteristics and distinguishing features are inversed when talking about 
  
 microservices. To better understand what this inversion is all about, let’s look at a 
 practical enterprise application scenario and understand the big picture first so that 
 the fine-grained and most important details are easier to understand.",NA
 The E-Commerce Microservice,"The “Typical Application Architecture” section in Chapter 
 1
  introduced the e-commerce 
 application. I explained how such applications are built following a traditional approach. 
  
 Figure 
 1-3
  in Chapter 
 1
  depicted different tiers and a modular approach to managing 
 software complexity. Even with the principles of tiers, layers, and modules, you saw 
 that there’s still the problem of undue dependency between modules, which impedes 
 all stages in the software engineering life cycle. I will portray that monolith 
 architecture in a slightly different style following the first principle of microservices 
 introduced in Chapter 
 2
 .
  
 Figure 
 3-1
  shows what the architecture will look like if we redraw the traditional 
 monolith-based architecture shown in Figure 
 1-3
  in Chapter 
 1
 . Compared to the 
 monolith architecture representation in Figure 
 1-3
 , I have softened the application 
 boundary represented by the dotted and dashed line styles in the diagram. This is to 
 emphasize the point that in the microservices architecture, it is not the application 
 boundary that matters, it’s the microservice boundary. The microservice boundary is 
 shown with thick rectangles. There are many such microservices depicted in the 
 diagram. In short, the single monolith application boundary represented in the 
  
 traditional architecture has vanished and in that place, many microservices have popped 
 up, and all of them have clear and concrete boundaries.
  
 36",NA
" No Tier, Distributed","I discussed the three-tier and n-tier distributed architectures in the “System 
  
 Architectures” section in Chapter 
 1
 . Going by that, it’s not wrong to call the microservices 
 architecture by the name “no tier, distributed.” To make it clear, if you relook at the 
 three-tier or n-Tier distributed architectures, within an application there are multiple 
  
 37",NA
 The Micromonolith,"Microservices are micromonoliths in the sense that they are built by following layer and 
 tier practices, but the boundary of a microservice should be clearly distinguishable and a 
 microservice should encompass all that is required for that microservice to live and 
 serve by itself without any external dependency. This is true in terms of physical 
 artifacts like binaries, libraries, and scripts, which are required for the microservice to 
 be up and running. This has to be also true in terms of any dependencies like container 
 services or persistence services required during the runtime of the microservice. The 
 physically bundled microservice artifact which when deployed to the runtime process 
 has to exhibit complete autonomy in terms of its capability to provide its functionality. 
 This is explained further in the next section.
  
 Since we are organizing microservices as all-encompassing bundles with little or no 
 external dependency, this provides certain advantages in terms of platform and 
 technology choices. Any platform, technology, tool, or framework decision taken for a 
 microservice shouldn’t be a constraint for those of the other microservice. This provides 
 freedom of choice of technology and architecture for teams across microservices. But at 
 the same time, this autonomy also brings additional responsibility to the microservice; it 
 has to own and manage all the resources necessary for its healthy existence, including 
  
 38",NA
 Understanding Self-Contained Microservices,"Since microservices are SOA friendly (which we will discuss in the next section), they 
 require HTTP server services to expose SOA or REST interfaces. While we deploy 
 traditional monolith packages into the web-app folder of the HTTP container, in the case 
 of a 
  
 microservice, a lightweight HTTP listener is embedded within the microservice, thereby 
 eliminating the need to have any external or standalone container or server 
 requirement. In the Java paradigm, in the case of a traditional deployment, we used to 
 deploy an .ear or a .war file into a full encompassing application server like JBoss or a 
 web server like Tomcat. 
  
 In contrast, in the case of a microservice there is no web server or .war file; instead, 
 each service has its own embedded HTTP listener such as Jetty, Tomcat, or Undertow 
 in a JAR file. While we build a microservice, the build stage will create this “executable 
 fat JAR” file, including the service runtime such as the HTTP listener mentioned 
 previously.",NA
Note,NA,NA
 Java does not provide a standard way to load nested Jar files (Jar ,NA,NA
files that are themselves contained within a Jar). this can be ,NA,NA
problematic if you are looking to distribute a self-contained ,NA,NA
microservice.,NA,NA
"to solve this problem, many developers use “uber” Jars. an uber Jar ",NA,NA
packages all the classes from all the dependent Jars into a single archive. ,NA,NA
they are also called fat Jars. the problem with this approach is that it ,NA,NA
becomes hard to see which libraries are in your microservice. it can also ,NA,NA
be problematic if the same filename is used (but with different content) in ,NA,NA
multiple Jars.,"The previous section indicated that microservices should encompass all of the 
 physical artifacts like binaries, libraries, and scripts, required for the microservice to be 
 up and running. In the traditional monolith deployment, we could place these kinds of 
 dependencies in the lib folder of the application server. In the microservices world,",NA
 Resemblance of Microservices to SOA,"As discussed, multiple microservices make up an application. Microservices must be 
 accessible from other microservices or from other components like the presentation 
 components. For intermicroservice communication, a suitable interprocess 
  
 communication mechanism is required, since most of the time microservices are 
 deployed into separate processes. You shouldn’t reinvent the wheel. You should adopt 
 all the best practices you have been leveraging from the SOA bibles. Just like in SOA, 
  
 41",NA
 Message-Oriented Microservices,"When we say that microservices must be accessible from other microservices as well as 
 from other components, we are talking about the communication mechanism by which 
 microservices depend on each other. In the “Intermodule Communication” section in 
 Chapter 
 2
 , we discussed the pros and cons of synchronous and asynchronous methods of 
 communication. There is no hard-and-fast rule that we shouldn’t use synchronous calls 
 between microservices. Carefully designed SOA interfaces are one of the best ways of 
 designing microservice interfaces. Sending requests and receiving responses using the 
 JSON (Java Script Object Notation) format over REST interfaces is very much advocated 
 since services can be reused, whether a web client or a mobile client or any other 
 Internet of Things (IoT) client. However, even SOA interfaces will make a microservice 
 depend on other microservices. If the called microservice is not functioning properly, the 
 caller microservice functionality cannot complete and the transaction is prone to failure. 
 In the specific example in Figure 
 3-3
 , suppose either the Shipping microservice or the 
 Order History microservice is not functioning. This will make the Create Order 
 transaction fail. Careful analysis reveals that this need not be the case. If the Order 
 microservice does not depend on the Shipping microservice or the Order History 
 microservice, even if either the Shipping microservice or the Order History microservice 
 doesn’t function properly, the Create Order transaction in the Order microservice can 
 still succeed. How is this possible?
  
 The asynchronous or fire-and-forget style of intermodule communication can detach 
 microservices from hard dependency between each other. We can use message queues 
 between microservices so that in place of direct synchronous calls, microservices can 
 communicate sending messages through queue between them. In Figure 
 3-4
 , the 
 architecture has been adjusted so as to bring a message queue system between 
 microservices. The other SOA-based interfaces of the microservices have not been 
 completely eliminated; they are retained but a message queue is also introduced. 
  
 This is because any external component or service has to use the SOA interfaces of the e-
 commerce application or the e-commerce microservices. Along with that, any 
 intermicroservice communication may be done using message queues. So, a request 
 from the browser to confirm an order will hit the Order microservice using its SOA-
 based REST interface. The Order microservice will access its Order database and create 
 the order. It should also make changes to the inventory database to deplete the 
 inventory level by the amount just ordered.
  
 44",NA
 Advanced Microservices Capabilities,"You saw how to break a monolith application into a microservices-based architecture. 
 You also learned about message queues in the microservices-based architecture, which 
 help reduce intermicroservice coupling. Now let’s look at the advantages.",NA
 Fail-Safe Microservices,"In the message-oriented microservices paradigm, the only essential condition for the 
 Create Order transaction to succeed is that the Create Order microservice (which 
 encompasses the Order and Inventory database too) and its associated message queue 
 infrastructure should be up and running. It doesn’t matter whether the Shipping 
 microservice and the Order History microservice are up and running or not. Assume 
 that the Shipping microservice and the Order History microservice are down while 
 creating an order. Any messages placed by the Order microservice as an outcome of 
 order creation will be safe in the queue. Here again, we can assume that multiple 
 instances of Order microservice can exist for redundancy and also clustered message 
 queues will increase the reliability of queues. Persistent messages will be written to 
 disk too as soon as they reach the queue. So if the message queue is persistent, even if 
 one or all of the messaging infrastructure servers in the cluster go down after the 
 Create Order transaction succeeds, the messages are still safe on disk. When we bring 
 the queue up again, the message is still available for consumption. Durable queues keep 
 messages around persistently for any suitable consumer to consume them, if the 
 consumer was not live at the time when the message was reached. Durable queues do 
 not need to concern themselves with which consumer is going to consume the 
 messages at some point in the future. There is just one copy of a message that any 
 consumer in the future can consume. Durable topics, however, are different because 
 they must logically persist an instance of each suitable message for every durable 
 consumer, since each durable consumer gets their own copy of the message. Thus, by 
 judiciously combining the persistence and durability capability of queues or topics 
 available within the messaging infrastructure, we can eliminate the dependency of the 
 Order microservice from the Shipping microservice and the Order History 
 microservice. At some later point in time when the Shipping microservice or the Order 
 History microservice comes up again, they will consume the messages intended to be 
 consumed by them and the rest of the functional flow will be continued by the 
 respective microservices.
  
 46",NA
 Scalable Microservices,"In the “Scalability Dilemma” section in Chapter 
 2
  we discussed that many logged in and 
 anonymous users will browse through many product categories and product detail web 
 pages, and the microservice serving those requests via the Product microservice will be 
 stressed more compared to the stress felt by the Order microservice. This is because 
 only a portion of the traffic due to browsing through the product category or the 
 product detail web pages will finally get converted to a confirmed order transaction. So 
 we need the capability to selectively scale the microservices of an application. We have 
 already broken down the monolith e-commerce application into a microservices-based 
 e-commerce application. The capability to selectively scale is a free offer we get with the 
 microservices architecture. Figure 
 3-5
  depicts exactly this.
  
 47",NA
 Extensible Microservices,"Most applications are built with a predicted end of life (EoL). Even if this EoL is too far in 
 the future, applications keep evolving in terms of functional capability as well as non-
 functional capability. As a business expands and as new acquisitions and mergers 
 happen, applications must be altered as well as extended. To extend or alter a monolith 
 is more risky than to do it to microservices architecture. This is because, just like the 
 manner by which we enabled selective scalability to microservices architecture, we can 
 also extend or alter microservices selectively. This brings a lot of relief to application 
 developers and the operations team.
  
  
 I would like to borrow the “honeycomb analogy” used by Rajesh R. V. in his book 
 “Spring Microservices” (Packt Publishing). Figure 
 3-7
  shows my own 
 representation.
  
  
 Figure 3-7. 
 Microservices: The honeycomb analogy",NA
 Summary,"You just touched upon few practical capabilities needed in the microservices-based 
 architecture if you want to get the real benefits over the traditional monolith. You have 
 learned about the concerns and have been introduced to solution complexities one at a 
 time so that your understanding is gradual and continuous. Selective scalability and 
 seamless extensibility in production deployments are the deal makers for modern 
  
 52",NA
CHAPTER 4,NA,NA
Microservices ,NA,NA
Architecture,"After the initial three chapters, you now have set a solid knowledge base to distinguish 
 between the microservices style of software architecture and the architecture of a 
 traditional monolith. You learned the technique of breaking down the monolith into 
 multiple small logical and physically separate groupings called microservices, thereby 
 improving the scale out capability in a flexible manner. While in the traditional monolith 
 schema of architecture you have one single, big application to manage, the same 
 application when redesigned into a microservices architecture will be more than one 
 single deployment and hence many more concerns like the intermicroservice 
 communications, will pop up. You will explore the details of this new set of architectural 
 concerns in this chapter. You will also explore a few relevant trends in the software 
 paradigm that have compelled software architects to move away from traditional 
 architectural styles.
  
 You will learn in detail the following in this chapter:
  
 • The digital context and the Mesh App and Service 
 Architecture (MASA)
  
 • Service granularity and where microservices fit in
  
 • Domain-based partitioning for microservices
  
 • The cloud native shift to address web scale scenarios
  
 • The cloud architecture and services model, setting the environment 
 for your deployment
  
 • 
  
 Virtualization and containers, and how they influence microservices
  
 55
  
 • 
  
 The macro and micro architecture perspective of microservices",NA
 Architecture for Digital Business,"We have evolved from the era of mainframes to desktops to laptops to mobile, and the 
 evolution continues. The era of smartphones brought a hell of a lot of possibilities for 
 how a mobile device can become the intimate companion of an individual. We have all 
 skipped our lunches on some days either because of a meeting with our boss or 
 customers extended endlessly or a family emergency. But how many of us can live for 
 an hour without looking at the social apps or the chat apps on our mobile? Devices 
 have started to become so intimate and essential, just like food, water, and air! This 
 has brought new challenges for software developers. I’ll explain more in this section.",NA
 The Digital Era,"The human race is now in the era of digital business. Gartner offers the following 
 definition of digital business:
  
 Digital business is the creation of new business designs by blurring the 
 digital and physical worlds.
  
 —Gartner
  
 You can easily relate this definition to few real-world scenarios such as:
  
 • You use Google Maps to lead you to your destinations by providing 
 maps or driving directions.
  
 • The Electronic Stability Program (ESP) in your cab improves your car’s 
 stability by detecting and reducing loss of traction (skidding) at 
 unexpected times.
  
 • People are starting to travel to space for recreational, leisure, or 
 business purposes.
  
 • Skinput provides an on-body finger input system that is always 
 available, naturally portable, and minimally invasive.
  
 • Bionics makes brain-computer, the next user interface (UI), a reality by 
 which you can control artificial limbs.
  
 56",NA
 The Digital App,"Digital business is taking microbrowsers and native apps to the next level by redefining 
 what an app means. In the context of the digital era described in the previous section, 
 the concept of the app is extended to any client software that can access back-end 
 services, piercing the enterprise firewalls or otherwise. This client software can be 
 executed in the embedded form or otherwise from any of the digital client devices 
 mentioned earlier. 
  
 Such client programs may not always follow the 
 WORA
  (
 Write Once, Run Anywhere
 ) 
 principles; instead they are “fit for purpose” and act as the human’s extension in the 
 physical world. They can be activated autonomously, based on a human trigger, or based 
 on a trigger from anything on the Internet in the IoT world. See Figure 
 4- 1
 .
  
 57",NA
 The Mesh App and Service Architecture,"Gartner
 1
  provides the following definition for the MASA architecture:
  
 The MASA (Mesh App and Service Architecture) is a multichannel solution 
 architecture that supports multiple users in multiple roles using multiple 
 devices and communicating over multiple networks to access application 
 functionality. In this architecture, mobile apps, web apps, desktop apps, 
  
 1
  Gartner, “An Introduction to How Software-Defined Application Services Enable the Apps and 
 Services Architecture,” 
 www.gartner.com/doc/2924317/introduction-softwaredefined-
 application-services-enable
 , November 25, 2014.
  
 58",NA
 The Context for Microservices,"Microservices are not a revolutionary new trend; instead, they are an evolution in the 
 context of recent trends in the software computing landscape. Even before anyone first 
 used the term microservices, many of you may have been following similar approaches 
 in your enterprises. Componentization, service orientation, and SaaS (Software as a 
 Service) are trends with principles similar to microservices. Miniaturization of these 
 trends (components and services) are linked with recent trends like the public cloud 
 and auto scale, so let’s briefly look into this background to better understand 
 microservices",NA
 Granularity of Services,"You can classify services into different categories based on the granularity at which it is 
 designed and built. Even though the term microservice implies small, the degree to 
 which it is small compared to other services is often relative. In other words, the size is 
 only an indicative characteristic; the more explicit characteristics listed below decide 
 the granularity:
  
 • Agility
  
 • Deployability
  
 • Selective scalability
  
 • Independence
  
  
 To aid in your understanding, you can bucket all of the above characteristics under a 
 single umbrella called “cloud nativeness.” See Figure 
 4-3
 .
  
 60",NA
 The Gateway,"Let’s revisit our e-commerce microservice application. Assuming that the web page is 
 displaying the Product Detail page, it doesn’t just display the product details alone, like 
 the name, description, and price; it also displays other details like
  
 • Number of items in the cart
  
 • Order history
  
 • Low inventory warning
  
 • Shipping options
  
 • Various recommendations, reviews, and offers
  
 All of this information has to be retrieved from different, respective microservices. 
  
 The web page has to access them from respective microservices whereas while in a 
 monolithic application architecture the browser can retrieve this data by making a 
 single REST call (GET
 api.acme.com/productdetails/productId
 ) to the application. There 
 are challenges and limitations with this option of accessing multiple microservices from 
 the browser. Even if a client attempts to make that many requests over a LAN, it will 
 probably be too inefficient over the Internet and will face serious performance 
 overhead, especially if the communication is over a mobile network. Also, if all the 
 microservices don’t expose web-friendly interfaces, which they are not mandated to 
 expose, this can be another challenge. Further, extensions to or evolution of the 
 application might necessitate splitting or merging existing microservices, which should 
 be shielded from the APIs exposed publicly.
  
 An API gateway can come to the rescue here. External-facing APIs can be coarse 
 grained and can aggregate responses from multiple internal microservices and provide 
 the aggregated response in a single go to the client device. Moreover, such external 
 facing APIs can also do some kind of transformation based on the kind of client device 
  
 64",NA
 Domain-Centric Partition,"Traditionally, we have been following the “one size fits all” approach for meeting non- 
 functional requirements of an application. This is very true when it comes to scaling the 
 application. A monolith can be scaled only uniformly for all of its functional or module 
 boundaries, whereas the microservices principles advocate defining the boundaries 
 based on business domains.
  
 As is seen from Figure 
 4-5
 , in a technology-centric approach, the layers or tiers of an 
 application can be scaled altogether. In the microservices approach, since each 
 microservice’s boundary is defined based on the business or functional domain, and 
 since this boundary definition is also evident in the physical organization of the 
 application, functions or domains can be scaled selectively. Such a selective approach in 
 combating non-functional requirements also offers the flexibility of defining service- 
 level agreements (like service uptime, etc.) against each microservice level.
  
 65",NA
 The Cloud Native Shift,"For ages we have been relying on dedicated infrastructures to address growing business 
 demands, whether in a scale out or in a scale up philosophy. We add redundant and 
 bigger pipes (Infinibands) for network connectivity, invest in engineered systems 
 (Exalogic) to add compute power, and so on. Recent insights and incidents have opened 
 the eyes of enterprise architects and they realize that these systems have limitations, and 
 sooner than later they will be constrained by these limitations. The high throughputs 
 provided by fiber optics or the high performance provided by in-memory computing all 
 can provide exponential performance during the initial portions of a graph, but then will 
 meet the limit, after which you get only little improvement even if you add more CPUs or 
 bandwidth. Advancements in quantum computing and similar technologies will shift the 
 plane, but again, businesses cannot wait until these technologies are commoditized and 
 accessible at reasonable cost.
  
 The public cloud is available today, which is of comparable and reasonable cost, if 
 not cheaper. Cloud platform providers like Amazon and Azure provision commodity 
 hardware in datacenters, which can be instantaneously provisioned as per your needs. 
 When your business is faced with unpredicted hypergrowth or hyperscale requirements, 
 the cloud is a reasonably right approach to keep your overall cost under control but at 
 the same time provides the required agility. I do not intend to cover the features or 
 characteristics of cloud computing or cloud service providers (CSP) here, but I surely 
 want to discuss what cloud native means.
  
 In an on-premises model, the availability policies and SLA management are in the 
 hands of data center administrators. When you move to a public cloud model, such 
 policies are transformed and abstracted to higher levels at your application stack. In the 
 IaaS (Infrastructure as a Service) or PaaS (Platform as a Service) model provided by the 
 CSPs, you have little control over the availability or storage policies, so you need better 
 controls and tool provisioning at your application stack layer. Your software layer should 
 by itself be geared to provide you hooks and controls for unprecedented scenarios. So in 
 order for the applications to truly benefit from the advantages of CSPs, the applications 
 should be smart enough in terms of recovering from failures, non-availability of 
 resources, abrupt spikes in traffic, etc. Cloud native architecture speaks about the 
  
 67",NA
 Web Scale Computing,"Web-scale IT applies to designing, deploying, and managing infrastructure at any scale. 
 Leveraging the capabilities of a web-scale IT, a business or enterprise can scale at 
 massive levels. IT principles and practices are a priority when it comes to web-scale IT; 
 of course cloud, microservices, and Dev Ops practices are to be named specifically. 
 Companies like Google, Amazon, Facebook, and Netflix are to be mentioned here since 
 by the mere nature of their business, their IT systems and practices fall in this category. 
 Distributed Everything, fault tolerance, self-healing, and API-driven approaches are just 
 few of the principles around web-scale computing.",NA
 The Indispensable Cloud,"The cloud aims to provide distributed compute, storage, and network infrastructures in 
 an autonomous manner at a comparatively reduced cost. A cloud-based architecture 
 may be based on multiple models (i.e., IaaS, PaaS, and SaaS), and suitable provisioning 
 can lead to a flexible environment for the customers. In the cloud, the customers can use 
 the clouds’ APIs to allocate the resources on demand and in near real time.",NA
 Cloud Architecture Model,"The industry has divided the cloud architecture into four layers:
  
 • 
 Hardware layer
 : The hardware layer contains the physical resources 
 of the cloud, such as CPUs, disks, and networks.
  
 • 
 Infrastructure as a Service
 : The IaaS layer abstracts physical 
 resources using virtualization techniques, thus creating a pool of 
 computing resources to be exposed as integrated resources to the 
 layer above and to the end users. Features such as on-demand 
 resource allocation happen at this layer.
  
 68",NA
 Cloud Service Model,"The cloud service model is based on the kind of control users may have over how the 
 resources are being utilized. Figure 
 4-7
  shows the different models.
  
  
 Figure 4-7. 
 Cloud service models
  
 Typically the cloud architecture itself can be mapped to the cloud service model. In 
 the traditional service model, the user or the enterprise itself is responsible for 
 managing the whole stack (e.g., hardware, data center facilities, software, and data) 
 whereas in the cloud service model it varies as follows:
  
 • 
 Infrastructure as a Service
 : In the IaaS service model, the users 
 request compute power, storage, network, and their associated 
 resources alone and pay for what they use.
  
 • 
 Platform as a Service
 : In PaaS model, the users have zero control 
 over the underlying infrastructure, such as CPU, network, and storage, 
 as they are abstracted away below the platform. Instead, it allows 
 application development platforms that allow the creation of 
 applications with supported programming languages and related tools 
 hosted in the cloud and accessed through an interface, mainly a 
 browser. Many times the application runtime and middleware are also 
 provided by the CSP, and the user develops, installs, manages, and 
 operates the software application alone and its data.
  
 71",NA
 SaaS Maturity Models,"The SaaS maturity model was coined by Microsoft
 2
  more than a decade ago, and since 
 then this information has been mentioned by me many times during my discussions 
 with architects. I will repeat it here, since an understanding is indispensable when we 
 map it later to how microservices can be scaled for different levels. Figure 
 4-8
  depicts 
 the different levels of SaaS maturity. The term “tenant” is used here to denote an 
 enterprise on whose behalf the application is hosted; the end users access services from 
 these hosted instances of the applications. So, two different airlines or two different e-
 commerce enterprises are two different tenants. The different levels of SaaS maturity 
 are as follows:
  
 • 
 Level 1 – Ad Hoc/Custom
 : At this level of SaaS maturity, each 
 enterprise or tenant has its own custom-developed application. The 
 source code of these applications is different, and the separate 
 application instance is hosted either on premise or in a public cloud for 
 each tenant.
  
 • 
 Level 2 – Configurable
 : At this level of SaaS maturity, there is only 
 one code base. The code base is configurable separately for each 
 tenant, and each separate application instance is hosted either on 
 premise or in a public cloud for each tenant.
  
 • 
 Level 3 – Configurable, Multi-Tenant Efficient
 : At this level of SaaS 
 maturity, there is only one code base. A single instance of this single 
 code base is hosted either on premise or in a public cloud, which serves 
 the end users of all tenants. The configuration of the code done while 
 instantiating the application is in such a way that the 
  
 2
  “Architecture Strategies for Catching the Long Tail,” Microsoft
  
 72",NA
 Virtualization,"Virtualization is a process of providing an abstract machine that uses device drivers 
 targeting the abstract machine so as to provide virtual replication of hardware. Type 1 
 hypervisors
 3
  run on bare metal and most mid-end to high-end microprocessors can be 
 virtualized. Server processors like Intel’s Xeon and application processors like the Arm 
 Cortex-A series are hardware with same capability. When virtualized, the VM (virtual 
 machine) will run any software that runs on the bare metal hardware while providing 
 isolation from the real hardware. See Figure 
 4-9
 .
  
  
 Figure 4-9. 
 SaaS over abstract hardware
  
  
 Instances of multiple applications or multiple instances of the same application can 
 be run in a single hardware effectively by virtualization techniques.",NA
 Virtualized Servers vs. Containers,"Containers provide a way to isolate applications and provide a virtual platform for 
 applications to run on. The container’s system requires an underlying operating 
 system and this OS provides the basic services to all of the containerized applications 
  
 3
  Hypervisors are a way to manage VMs and Type 2 Hypervisors have an underlying operating 
 system called the host OS.
  
 75",NA
 The Architecture of Microservices,"Microservices architecture (MSA) can be defined as a way of designing software 
 applications with an aim to achieve agility of delivery, flexibility of deployment, 
 and precision of scalability. There are a lot of associated benefits, and also a set of 
 complexities you must deal with. Let’s look at few of them and the bigger picture 
 associated with them in this section.",NA
 Inversion of Architecture,"In MSA, applications are composed of small, independently deployable processes 
 communicating with each other using platform-agnostic and programming language- 
 agnostic APIs and protocols. Each of these processes hosts application components that 
 expose closely related business capabilities. Many such processes expose many such 
 capabilities for an enterprise application. Thus in a MSA, a single capability or a single 
 process or a single microservice alone may not be sufficient to represent an enterprise 
 application of any considerable size.
  
 In the monolith, it is one single (main) process that hosts the entire application 
 package. Hence all or most of the following concerns within a monolith application are 
 encompassed within the single process space itself:
  
 • Service dependency management
  
 • Service configuration management
  
 • Service instrumentation
  
 • Service SLA
  
 • Service management and monitoring
  
 In MSA, since there are many processes communicating with each other, all or most 
 of the above concerns are not limited to a single process alone, unlike the scenario with 
 a monolith. They are to be dealt with for all these coordinating processes and this means 
 extra process complexities. And this is the next most distinguishable characteristic of a 
 microservice, where the inner concerns of a single process of the earlier monolith are 
 now exploded to the outside of many microservices. This is called the “Inversion of 
 Architecture” (IoA).
  
 79",NA
 The Inner Architecture Perspective,"Since microservices are independent, autonomous, and self-encompassing packages 
 deployable to their own process space, they are to be complete in terms of its own 
 architecture. Figure 
 4-5
  shows that microservices host their own presentation, 
 business, and data components and also hosts their own messaging infrastructure. 
 Hence all or most of the architectural concerns in terms of separation of concerns, 
 layering, and interface-oriented design still exist and should be dealt with in the 
 architecture of each and every microservice; this is the “inner architecture” of a 
 microservice.
  
 Gartner has four examples to explain the inner architecture of microservices:
  
 • Simple/Scaled
  
 • Complex/Scaled
  
 • Externalized Persistence
  
 • Command Query Responsibility Segregation
  
 Figure 
 4-12
  represents these example scenarios schematically. Let’s cover 
 these example scenarios with suitable analogies so that the concept is clear and so 
 you understand the options available and the complexities involved.
  
 80",NA
 The Outer Architecture Perspective,"I mentioned that due to the Inversion of Architecture, many of the concerns that used to 
 be solved at the inner architecture level of the monolith have now become the outer 
 architecture concerns. Figure 
 4-14
  attempts to show schematically the concerns we 
 need to address at the outer architecture level of a microservice. Microservices interact 
 with each other and this chattiness between process spaces increases the overall 
 complexity. Concerns like fault tolerance, graceful retry, and alternate code execution 
 are few among them and this necessitates strong management, monitoring, and control 
 of microservices at its outer architecture level. The goal is to achieve agility of delivery, 
 flexibility of deployment, and the precision of scalability in a microservices architecture. 
  
 In order to do this, a new set of concerns must be addressed and this increases the 
 complexity of microservices manyfold compared to that of a monolith.
  
 83",NA
 The Big Picture of MASA,"Having discussed the separation between the inner architecture and outer architecture 
 concerns of microservices, it is time now to look at the big picture.
  
 Figure 
 4-15
  combines the inner architecture and the outer architecture of 
  
 microservices to provide a view of a typical Mesh App and Services Architecture. 
 Microservices interact with their environment and with other microservices, leveraging 
 the outer architecture provisions, whereas each of the microservices’ ability to scale 
 selectively is built and managed using its inner architecture organization.
  
  
 Figure 4-15. 
 The outer architecture of microservices
  
 Figure 
 4-15
  shows only a few microservices. For any enterprise application of 
 considerable size, this is not the case. There can be a number of microservices, 
  
 starting at over a dozen and reaching the hundreds in number. Unlike how the name 
 “microservices” sounds, microservices are not simple. They are far more complex than 
 the traditional monolith, and in fact have all the complexities of the monolith. So, the 
 decision to adopt microservices is to be taken with care. Microservices are not an option 
 if the enterprise’s development team doesn’t have experienced guides. The scenario is 
 changing as you read this book, since tool vendors and cloud providers are coming 
  
 85",NA
 Summary,"In this chapter you looked at the forces that led to the evolution of microservices. 
  
 The digital app, which connects humans with physical things, has necessitated this 
 evolution. Inversion of Architecture is a normal outcome of this evolution, and the 
 overall complexity of the software landscape has increased manyfold and is now visible 
 outside to a microservice and has to be explicitly managed across microservices. While 
 the urge to adopt microservices is tempting, a quantitative cost benefit analysis must be 
 done before any such attempt. Once decided, the next most important aspect is to think 
 about the inner architecture organization for your microservices. While the outer 
 architecture concerns remain more or less same across context and scenarios, your inner 
 architecture can be designed with varying trade-offs. You will look into this in more 
 detail in Chapter 
 5
 .
  
 86",NA
CHAPTER 5,NA,NA
Essential ,NA,NA
Patterns for ,NA,NA
Microservices,"Software architectures are comparatively easy to comprehend, especially if there is 
 enough documentation on the subject. The hardship will emerge when you start 
 implementing them to solve real-world problems. This is where architectural patterns 
 will come to your rescue. If you understand the problem at hand and if you can 
 reasonably attach this problem to a scenario similar to a problem you have already 
 addressed, it’s rather easy to follow an approach similar to what you adopted earlier. 
 Architecture and design patterns help you to choose and adopt solutions to problems 
 that are similar in nature. A pattern is a reusable solution to repetitive problems of a 
 similar nature that occur in a particular context.
  
 Having discussed the necessity of splitting monolith applications into multiple 
 microservices, let’s now take a pragmatic view of one of the major concerns any 
 application architect will face in designing scalable application: scaling the write and 
 read clusters of any application independently. You will look into this aspect in detail 
 in this chapter. In doing so, you will also explore a powerful pattern that will help solve 
 many concerns of a microservices architecture by adopting various flavors of it.
  
 The concepts you are going to do a deep dive into in this chapter are as follows:
  
 • The need to independently scale the read and write transactional 
 capabilities of an architecture
  
 • The CQRS pattern
  
 • A metamodel for the CQRS pattern and more sample scenarios that 
 will be explained in later chapters in the book",NA
 Orthogonal Scale Out of Services,"If we put aside the other rationales behind the microservices architecture, one 
  
 main requirement is to selectively scale out components or services within a single 
 application. You know that in a monolith it is nearly impossible to easily split out 
 components or services and then deploy them at a selected degree of scalability; 
 however, this is one major advantage we get in adopting the microservices 
 architecture. 
  
 In previous chapters I discussed the need to instantiate more numbers of Product 
 Catalogue and Product Details microservices as compared to the number of instances 
 of the Order microservice required. A similar requirement is also relevant in scaling 
 the transactions handling the state change and state view of application domains 
 heterogeneously, so let’s try to understand that in detail.",NA
 Write vs. Read Transactions,"Any transaction originated through a B2B or a B2C channel, or for that matter through 
 an IoT or Wearable channel, typically falls into one of the two categories of 
 transactions:
  
 • 
 Write transactions
 : A write transaction will typically change the state 
 of entities in the application. An e-commerce check out, a credit card 
 payment, and a flight seat confirmation are first-class examples of a write 
 transaction, since all of them change the state of entities, are usually kept 
 in the server-side memory, and in many cases the state change also gets 
 reflected in the backing persistent store as well as in any other 
 counterpart B2B interfaces with which the application interfaces. 
 Generally, write transactions are non-idempotent
 1
  unless they are 
 designed with special care to behave differently. This means a credit card 
 payment transaction, if it is intended to be executed once and if due to 
 some reason it is executed twice (played once and replayed one more 
 time) and if both these transactions are successful, then the payment will 
 be processed twice, which may not be the desired outcome
  
 1
  Idempotence is the property of certain operations in mathematics and computer science 
 whereby they can be applied multiple times without changing the result beyond the initial 
 application.
  
 88",NA
 The Look-to-Book Challenge,"I assume any of you reading this book have already have done online transactions, 
 especially in an e-commerce application. If so, you can appreciate the fact that it will 
 take more than one step, traversing through web pages, filling out forms, and so on, 
 before you actually do the confirmation for your first write transaction, which is 
 creating the order. To make it more clear, if you are shopping online for some retail item 
 like an electronic gadget, you follow these steps:
  
  1. Type the URL for the home page.
  
  2. Browse through the product categories and select the product of 
 interest.
  
  3. Retrieve the product details, including reviews, contents, 
 and media.
  
  4. Decide to purchase the item, add it to the shopping cart, and fill out 
 payment information.
  
  5. Click to confirm the purchase.
  
 If you examine the minimum steps listed above, you can differentiate the last 
 transaction which is the actual confirm purchase transaction from the rest of the 
 transactions. While the confirm purchase transaction can be put under the write 
 transaction category, most of the other previous transactions listed above come under 
 the read transactions category.
  
 89",NA
Note,NA,NA
" for every single write transaction, you do many more read ",NA,NA
transactions.,"In the classic airline seat booking scenario, the ratio of reads to writes for every 
 realized booked PNR comes in the range of 500 or even 1,000 or more. This is called 
 look to book. When we say the look to book is 1,000 on average, this means is that for 
 every write (book) transaction on behalf of a PNR created for a new booking, 1,000 or 
 more read (look) transactions should have already hit the application. During peak 
 season or during peak times of the week when sales are happening, this number can rise 
 to the order of many thousands for a single booking! It is in this context, a microservice’s 
 selective scale out capability is relevant.",NA
 CQRS: Command Query Responsibility ,NA,NA
Segregation,"The capability to selectively scale out is one of the advantages of microservices 
  
 architecture, provided we design the microservice to have this characteristic. In the 
 “Inner Architecture Perspective” section in Chapter 
 4
 , I discussed the various levels of 
 maturity with which you can design your microservices architecture. I introduced the 
 CQRS (Command Query Responsibility Segregation) pattern there, so let’s look into the 
 details of it at an architecture and design level. In the later part of this book you will see 
 many samples and even a full-fledged application implemented using this pattern.",NA
 Traditional vs. CQRS-Based Software Systems,"In traditional and monolith systems, both writes (updates to the entity) and reads 
 (requests for viewing entity) are executed against the same set of entities in a single 
 data repository. Usually these entities are a subset of the rows in one or more tables in a 
 relational database such as MySQL or PostgreSQL. Figure 
 5-1
  represents this design.",NA
 The Nomenclature in CQRS,"CQRS is based on the notion of two concepts, commands and events. Commands and 
 events are explained as follows:
  
 • 
 Commands
 : The intent to change the state of an entity is modelled as a 
 command.
  
 • 
 Events
 : Once there is a change in the state of an entity, events 
 represent what has changed.
  
 Referring to Figure 
 5-3
 , a write transaction coming from the client to the 
 presentation tier is represented by commands, which will encapsulate all the 
 information required to effect a state change. Any such state change will result in a 
 corresponding write to the data persistent store. Due to this action or effect of state 
 change, there can be components or services elsewhere in the application that are 
 interested in what has changed and there should be a mechanism to propagate these 
 changes to those interested services. Events come handy in this case. So, if a change has 
 happened to the state of a write data entity, it can be propagated to the read data entity 
 counterparts in terms of events.",NA
 Event-Based CQRS Architecture,"Earlier I discussed the need to synchronize the read model whenever there is a change 
 in the write model. This is an after-effect of splitting the single model into its write and 
 read counterparts. The scene becomes worse when we realize that most enterprise 
 applications have more than one view or for that matter more than one read model for 
 the same entity. The read and write stores may have a different structure altogether; 
 multiple read stores or models will also have different data structures so that using 
 multiple read-only replicas of the read store can considerably increase query 
 performance and application UI responsiveness. There are more intricacies so let’s dig 
 into these aspects next.",NA
 A Meta Model for Event-Based CQRS Design,"You started this book by looking at the monolith model of application architecture and 
 then you were introduced to microservices. You also looked at the associated increase in 
 complexities, especially in the outer architecture between microservices. In this chapter, 
  
 96",NA
 Command Query Segregation Using Events,"CQRS architecture may be utilized to better architect microservices-based systems. 
  
 By doing a little fine tuning to the CQRS meta model, it is easy to segregate the read and 
 write portions of your application entity into completely different techno-business 
 domains. By techno, we mean to segregate into different process spaces, and by domain, 
 we mean to segregate into different write and read transactional requirements of your 
 business.",NA
 Scale Out for CQRS-Based Microservices,"Refer to Figure 
 3-6
 , which shows the scaling message-oriented microservices. You can 
 extend the same principles to scale out the Command and Query services of your CQRS- 
 based microservices, and this is represented in Figure 
 5-7
 . This is just another view of 
 the “scale out using separate read and write processes” represented in Figure 
 5-4
 ; 
 however, this view is more in sync with the “scaling message-oriented microservices” in 
 Figure 
 3- 6 
 with the additional capability of the CQRS pattern. Again, in Figure 
 5-7
  I have 
 not repeated all of the components of the CQRS described in Figure 
 5-6
 , so assume that 
 all of them still exist and have been abstracted in the diagram to retain clarity.
  
 102",NA
 Summary,"Maintaining more than one view for business entities is a technique we have been 
 following for many years, and materialized views, caches, read replicas, and so on are all 
 mechanisms to that end. CQRS is a more formalized pattern to improve the inner 
 architecture of microservices, thus elevating the scalability options of a microservice 
 manyfold. While CQRS addresses the scalability for the read part of the business entities, 
 the write part is deployed separately to take care of data consistency, which will also 
 take the lead in propagating changes to the entity state to all read parts. Even though the 
 architecture is complex when compared to that of a simple microservice, the extra 
 complexity will pay off by the exponential increase in the scalability of the microservice. 
 Having split the read and the write part into separate microservices, you should now 
 look at the outer architecture concerns between them in the synchronization of changes 
 and the need for other kinds of intermicroservice communication in a reliable and 
 flexible manner, so move on to Chapter 
 6
 .
  
 104",NA
CHAPTER 6,NA,NA
Distributed Messaging,"One of the most powerful mechanisms used in building enterprise grade software 
 applications is messaging. Had we not invented messaging, all of the software 
  
 applications around the globe would be like a complete workforce, needing to be 
 working 24 x 7, 365 days a year without any room for downtime or failure. But in 
 practice we know that every software application is prone downtime or failure; rather, 
 every software application should be designed to have downtime or failure. Since 
 enterprise applications don’t live in isolation, instead they talk to each other in a 
 distributed manner, what an application tried to talk to an application that is down? 
 Messaging helps to gracefully accommodate unexpected downtime and failure of 
 coordinating applications. In this chapter, you will look into a few messaging scenarios 
 that will help you understand how these messaging functionalities play a vital role in 
 distributed software architectures, especially in the context of microservices. Here again 
 my intention is not to start from the basics of messaging or to get into all scenarios of 
 messaging, which would be a book unto itself. Instead, I will show a few scenarios that 
 are very critical in understanding the role of messaging in microservices architecture.",NA
 Messaging for Resiliency,"Assuming that you are aware of the basic constructs in a messaging architecture, let’s 
 first look at some basics of how to bring resiliency to a messaging setup.",NA
 Message Persistence,"Message persistence is a mechanism by which you can keep the messages delivered to 
 a message broker in a persistent store. This will elevate the state of the messages on 
 the wire or on main memory from a volatile state to a permanent safe state. This is 
 very important in a microservices environment since coordinating microservices can 
 come and go, fail or rejuvenate, etc.
  
 © Binildas Christudas 2019 
  
 105
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_6",NA
 Design for Various Operational ,NA,NA
Characteristics of Microservices,"One of the prime objectives in splitting the monolith into microservices is to bring 
 complete independence for individual microservices in terms of architecture, 
 technology, build, and operational constraints. This means microservices don’t care if 
 the other interacting microservices are up and running or not. Whether the dependent 
 microservices are up and running or not, the independent microservice should be able 
 to complete its operations and move forward. Let me bring clarity to my usage of 
 “dependence” here since I started this paragraph talking about the ability to “bring 
 complete independence for individual microservices” and then in the very next line I 
 talk about their dependencies. Understand that in a distributed environment many or 
 all of these microservices are dependent since they want to share information. Hence 
 when I say “bring complete independence for individual microservices,” what I mean is 
 to change the style of dependency from direct to indirect, or in more technical terms, to 
 prefer an asynchronous style in place of a synchronous style.
  
 Using message brokers between microservices is a highly recommended approach 
 to independence. Figure 
 6-2
  shows a single message producer and two message 
 consumers. Assume that they represent three different microservices and they are 
 communicating through a message broker in an asynchronous manner. 
  
 As you can agree, the moment the message producer publishes a message to the message 
 channel, it can be sure that the message will be safe with the broker infrastructure and it 
 can ignore the published message. When the time comes, interested subscribers can 
 consume these messages from the message broker through their subscribed channel. It 
 is not the business of the Producer microservice or the Consumer microservice to 
 validate whether the other Consumer microservice has received the message or not. If 
 the other microservice is up and running and is fast enough at consuming messages, it 
 will receive the message from the message broker more or less instantaneously, thus 
 responding with a performance grade more or less comparable to a synchronous style of 
 communication between 
  
 microservices. However, if that Consumer microservice is either too slow to consume or 
 if that microservice is not up and running by the time the Producer published the 
 messages, the message store may help by safely persisting the messages until the 
 message has been consumed by all the registered, interested microservices.
  
 107",NA
 A Chain Is As Strong As Its Weakest Link,"This is extremely important in distributed applications especially when you expect 
 application resiliency: a software application is only as resilient or available as its 
 weakest resilient or available microservice or as the weakest component (link) in the 
 entire infrastructure.
  
 In Figure 
 6-2
 , the components of considerable significance are
  
 • The Producer microservice
  
 • The Consumer microservice
  
 • The message broker
  
 Of course there are other components in the architecture shown, but let’s assume 
 that those mechanisms to deal with their resiliency are known to us since we have been 
 dealing with distributed systems for two or more decades.
  
  
 We also acknowledge that the Producer and Consumer microservices also need 
 to be resilient, but in this section we will look at the resilience of the message broker. 
  
 The message broker is the central, single point of failure in the architecture shown in 
 Figure 
 6-2
 . Figure 
 1-2
  in Chapter 
 1
  shows how to address this by adopting suitable 
 network integration topologies. However, those basic topologies alone are not sufficient, 
 so let’s rearchitect the message broker infrastructure to avoid this single point of failure.
  
 108",NA
 Synchronous vs. Asynchronous,"Let’s now look at two main styles of communication between microservices: 
 synchronous and asynchronous communications.",NA
 Synchronous Interactions Between Microservices,"The synchronous style of interaction between microservices is analogous to two 
 people shaking hands. You extend your hand to shake your counterpart’s hand, which 
 is analogous to one microservice initiating the request. Your hand and henceforth your 
 handshake will be received if and only if your counterpart is also awake and 
 acknowledges that he or she is willing to shake hands with you and further attempts 
  
 110",NA
 Asynchronous Interactions Between ,NA,NA
Microservices,"In Figure 
 6-1
 , you saw how a message broker can be introduced to make the interactions 
 between components or microservices asynchronous. Let’s look into further details of 
 this kind of interaction.
  
 113",NA
 Send and Receive Messages to a Single ,NA,NA
Node RabbitMQ Broker,"You will now look at some code for sending messages to a RabbitMQ message broker 
 and receiving the same using a listener to the broker. Refer to Appendix B to follow 
 step-by-step instructions to install and bring up a RabbitMQ broker. The complete and 
 running code samples for this exercise are kept in the folder named ch06-01, which is 
 bundled along with the book.",NA
 RabbitMQ Message Sender,"You need to make a connection to a RabbitMQ Message broker and send a message. For 
 this, you can use the client package from RabbitMQ libraries. Listing 
 6-1
  shows the 
 steps involved in doing so.
  
 Listing 6-1. 
 RabbitMQ Message Sender (ch06\ch06-
 01\src\main\java\com\ acme\ch06\ex01\Send.java)
  
 import com.rabbitmq.client.Channel; 
  
 import com.rabbitmq.client.Connection; 
  
 import com.rabbitmq.client.ConnectionFactory;
  
 public class Send {
  
  private final static String QUEUE_NAME = ""hello"";
  
  public static void main(String[] argv) throws Exception{
  
  ConnectionFactory factory = new ConnectionFactory();
  
  factory.setHost(""localhost"");
  
  Connection connection = factory.newConnection();
  
  Channel channel = connection.createChannel();
  
  channel.queueDeclare(QUEUE_NAME, false, false, false, null); String 
 message = ""Hello World!"";
  
  
  channel.basicPublish("""", QUEUE_NAME, null, message.
  
  
 getBytes(""UTF-8""));
  
  LOGGER.debug("" [!] Sent '"" + message + ""'"");
  
 118",NA
 RabbitMQ Message Receiver,"Listing 
 6-2
  shows the code required to listen to a RabbitMQ Message broker to consume 
 messages.
  
 Listing 6-2. 
 RabbitMQ Message Receiver (ch06\ch06-01\src\main\java\com\ 
 acme\ch06\ex01\Receive.java)
  
 import com.rabbitmq.client.Channel; 
  
 import com.rabbitmq.client.Connection; 
  
 import com.rabbitmq.client.ConnectionFactory; 
 import com.rabbitmq.client.Consumer;
  
 119",NA
 Build and Run the RabbitMQ Sample,"You will now build and run the code samples. Both Ant and Maven scripts are provided 
 along with the code.",NA
 Maven Build,"ch06-01\pom.xml contains the Maven scripts required to run the samples. Make sure 
 the RabbitMQ broker is up and running.
  
  
 You first build and bring up the consumer so that the consumer is ready to pick up 
 messages (see Figure 
 6-10
 ):
  
 cd ch06-01 
  
 D:\binil\gold\pack03\ch06\ch06-01>listen 
  
 D:\binil\gold\pack03\ch06\ch06-01>mvn test -Plisten
  
  
 Figure 6-10. 
 Maven building and running a RabbitMQ consumer
  
 121",NA
 Ant Build,"ch06-01\build.xml contains the Ant scripts required to run the samples. Again, make 
 sure the RabbitMQ broker is up and running.
  
 You need to first build the sample. Execute the following commands:
  
 cd ch06-01 
  
 D:\binil\gold\pack03\ch06\ch06-01>ant
  
  
 Now bring up the consumer and have it ready to pick up messages. Execute the 
 following command and see Figure 
 6-12
 :
  
 D:\binil\gold\pack03\ch06\ch06-01>ant listen
  
 122",NA
 Send and Receive Messages to RabbitMQ ,NA,NA
Using Spring AMQP,"Spring AMQP makes it easy to develop AMQP-based messaging solutions. The Spring 
 AMQP template provides a high-level abstraction for sending and receiving messages. 
 There are two parts to the Spring AMQP, which is the spring boot default with Rabbit 
 MQ:
  
 • spring-amqp: A base abstraction, and
  
 • spring-rabbit: A RabbitMQ-specific implementation
  
 The major features abstracted by Spring AMQP are
  
 • A Listener container: For asynchronous processing of inbound 
 messages
  
 • A RabbitTemplate: A RabbitMQ-specific template for sending and 
 receiving messages
  
 • A Rabbit admin: Helpful in fast and automatic declaration of queues, 
 exchanges, and bindings
  
 Let’s now look at some code for sending messages to a RabbitMQ message broker 
 and receiving the same using a listener to the broker using Spring AMQP. Refer to 
 Appendix B to follow step-by-step instructions to install and bring up a RabbitMQ 
 broker. The complete and running code samples for this exercise are kept in the folder 
 named ch06-02, which is bundled along with the book.",NA
 Spring AMQP Message Listener,"Using Spring has the advantage of wiring much of the configurations in XML, and 
 Listing 
 6-3
  shows how to wire a message listener to the RabbitMQ broker.
  
 Listing 6-3. 
 Spring AMQP Listener Configuration (ch06\ch06-02\src\main\ 
 resources\rabbit-listener-context.xml)
  
 <?xml version=”1.0” encoding=”UTF-8” ?> 
 <beans >
  
  <rabbit:connection-factory id=""connectionFactory"" host=""localhost""
  
  
 port=""5672"" username=""guest"" password=""guest"" />
  
 124",NA
 Spring AMQP Message Producer,"Here again you first create a rabbit connection factory with specified parameters. 
 RabbitTemplate provides a convenient abstraction for sending and receiving 
 messages, and Listing 
 6-7
  shows the configuration.
  
 Listing 6-7. 
 Spring AMQP Sender Configuration (ch06\ch06-02\src\main\ 
 resources\rabbit-sender-context.xml)
  
 <beans ...>
  
  
  <rabbit:connection-factory id=""connectionFactory"" host=""localhost""
  
  
  port=""5672"" username=""guest"" password=""guest"" />
  
  
  <rabbit:admin connection-factory=""connectionFactory"" />
  
  
  <rabbit:template id=""sampleTemplate"" connection-factory=
  
  
  
  ""connectionFactory"" exchange=""SAMPLE_EXCHANGE""/> 
  
 </beans>
  
  
 In Listing 
 6-8
 , you create a template of the bean defined in the previous Spring XML 
 file and send few messages.
  
 Listing 6-8. 
 Spring AMQP Message Sender (ch06\ch06-
 02\src\main\java\com\ acme\ch06\ex02\Sender.java)
  
 import org.springframework.amqp.core.AmqpTemplate;
  
 public class Sender {
  
  
  private static final Logger LOGGER = LoggerFactory.getLogger 
  
 (Sender.class);
  
  
  private static final String SENDER_CONTEXT = ""rabbit-sender- 
  
 context.xml"";
  
  private static final String BEAN_NAME = ""sampleTemplate"";
  
  public static void main(String[] args) throws Exception {
  
 127",NA
 Build and Run the Spring AMQP RabbitMQ ,NA,NA
Sample,"You will now build and run the code samples. Both Ant and Maven scripts are provided 
 along with the code.
  
 ch06-02\pom.xml contains the Maven scripts required to run the samples. Make 
 sure the RabbitMQ broker is up and running. You first build and bring up the consumer 
 so that the consumer is ready to pick up messages. Execute the following commands and 
 see Figure 
 6-14
 :
  
 cd ch06-02 
  
 D:\binil\gold\pack03\ch06\ch06-02>listen 
  
 D:\binil\gold\pack03\ch06\ch06-02>mvn test -Plisten
  
 128",NA
 Send and Receive Messages to Multi-,NA,NA
Node RabbitMQ Cluster,"You will now look at code for sending messages to a RabbitMQ cluster. Refer to Appendix 
 B again to follow step-by-step instructions to install and bring up a RabbitMQ cluster. 
 This section assumes that you already have a running RabbitMQ cluster with a minimum 
 of two nodes. You further need to refer to Appendix C to follow step-by-step instructions 
 to set up a TCP load balancer using Nginx so that traffic (rather, connections) from both 
 consumer and producer can be multiplexed to at least one of the active nodes of a 
 multinode cluster, if the other nodes are down.
  
 This section is so important because in a microservices environment backed with a 
 messaging infrastructure, the high availability of the messaging infrastructure by itself 
 will decide the overall reliability of the infrastructure. You have seen that 
 microservices instances can be coming (instantiated, restarted, etc.) and going 
 (graceful shutdown, crashed, restarted, forcefully killed, etc.) in any order or at any 
 pace in an enterprise production setup. Each of these microservice instances 
 communicate with others through the messaging infrastructure or the event-based 
 infrastructure by sending messages. So, when one microservice instance sends a 
 message to the messaging infrastructure successfully, it assumes that the message will 
 reach the receiver 
  
 “eventually,” as expected. The high availability of the messaging infrastructure must 
 live up to this promise.
  
 Assuming you have a multinode RabbitMQ cluster in high availability mode and you 
 also have a TCP load balancer (Nginx configured as a TCP reverse proxy), you are all set 
 to try out little trials to verify that your RabbitMQ cluster is up and running.
  
 The sample you saw in the previous section (ch06-02) can be tweaked to 
 demonstrate the cluster setup and is kept in folder ch06-03. You can follow a quick 
 demonstration by executing the sample in the following order.
  
 If you didn’t do it earlier, copy the following files from the samples directory 
 (ch06\ch06-03\) to the sbin folder of your RabbitMQ server, and execute the scripts in 
 the following order in separate windows:
  
 cd D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin 
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>rabbitmq-server1.bat
  
 cd D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin 
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>rabbitmq-server2.bat
  
 130",NA
 Tying the Knots Between the ,NA,NA
Consumer and Producer,"The very advantage of using a messaging infrastructure–making the message producer 
 and message consumer flows disjoint–by itself can sometimes be a challenge for the 
 application developer.
  
 In a typical synchronous request response call by a client, the server can accept 
 connections from the client in a single thread, process the request in that thread, and 
 provide a response to the client in the same thread. However, connections and threads 
 are scarce resources and you want to utilize them effectively. If the server-side 
 processing is going to take a lot of time, or if the server thread is getting blocked in idling 
 mode like waiting for I/O operations, blocking the thread is not desired. Instead, you 
 want to design in such a way that the thread that accepted the connections is released to 
 accept more connections and the processing and subsequent response to the client is 
 handled in the background by different threads, that too just in time whenever the 
 processing can proceed or just in time whenever the response is ready to be delivered 
 back to the client. This is trivial to implement if you have one server and one client. The 
 moment you have numerous clients all connecting to a server, also concurrently, if you 
 release the thread that accepted the socket connection just after the connection is made 
 but before the server provides a response back to the client, then later when the 
 response is ready, it will pose a challenge to the server to correlate to which client all the 
 responses are to be sent back.",NA
 Correlation ID,"In the scenario presented above, you can create a callback queue for every request. 
  
 But that’s pretty inefficient. Fortunately there is a better way: by creating a single 
 callback queue per client. But it raises a new issue; having received a response in that 
 queue, it’s not clear to which specific request from the same client the response belongs. 
 That’s where the correlationId property is used. You can set it to a unique value for every 
 request. Later, when you receive a message in the callback queue, you’ll look at this 
 property, and based on it you’ll be able to match a response with a request.
  
 134",NA
 Code a Custom Network Server to Handle ,NA,NA
Concurrent Heavy Traffic,"In this section, you will design and implement a network server listening using a TCP/IP 
 server socket. Multiple clients or multiple threads from same client can open 
 connections to this server and submit jobs; these clients or threads expect a response to 
 the job back. You want the design to handle heavy traffic. Let’s visit the architecture and 
 control flow in the server. Figure 
 6-16
  shows the architecture of the entire setup.
  
 135",NA
 The Simultaneous Exhibition Game,"Go back to Figure 
 6-16
 . Let’s discuss a little more in the context of resource sharing 
 and resource utilization.
  
 You might have observed the single server socket instance listening for client 
 connections. It is this single server socket’s duty to handle all incoming client 
  
 connections. This is typical of many web servers existing today. A typical web server 
 that produces relatively short content like a web page with text or an image will be 
 100KB in 
  
 143",NA
 Message Correlation and Microservices,"In microservices architecture, different pieces of the enterprise application are divided 
 into multiple microservices and still they have to talk to each other. To get the real 
 benefit of microservices, intermicroservice calls must be through a messaging 
 infrastructure. This means the production ecosystem of an enterprise application with 
 a microservices architecture will consist of many microservices, and many instances of 
 these microservices, are interconnected with one or more messaging infrastructures. 
  
 When you adopt an asynchronous style of communication between these instances, the 
 main dilemma is how to effectively solve the routing of messaging between them. 
 Previous sections in this chapter gave you a bird’s eye view on the internal complexities 
 involved in connecting microservices including the message correlation. If a developer 
 has to do all of this wiring himself, it will bloat the code too much. You need a better way 
 to handle this. I will introduce ways of handling this in Chapter 
 12
  when I introduce the 
 Axon framework (which will do this for you implicitly).",NA
 Summary,"Messaging brings the power of detached processing to help enterprise applications deal 
 with many real-world scenarios including downtime and failure. In this chapter, you 
 looked at some of the powerful applications of messaging, including clustering and high 
 availability. You also read through a few code samples, which showed the complexities 
 involved if you hand-code cross-cutting concerns like message correlation, etc. By 
 combining the multiple techniques discussed in this chapter, you’ll be in a position to 
 increase the reliability of your microservices infrastructure manyfold. You will see some 
 of these messaging techniques applied in a different context in subsequent chapters 
 since messaging is a core lever in the developer’s toolset.
  
 145",NA
CHAPTER 7,NA,NA
Spring Boot,"In the previous chapter, you looked at messaging. You used Spring to configure the 
 message senders and listeners, and you did explicit wiring of beans and required 
 infrastructure in Spring. So far, so good. Now how can you make aspects even simpler? 
  
 You’ll look at Spring Boot in this chapter, which makes use of an opinionated view of the 
 Spring platform and many third-party Java libraries so that it is easy and 
  
 straightforward to create stand-alone, production-grade, Spring-based applications that 
 you can “just run.” Since Boot follows many conventions and usage patterns followed by 
 developers, which they have been leveraging while using Spring and other third-party 
 libraries, most Spring Boot applications need very little Spring configuration. You will 
 use Spring Boot to develop the few samples relevant to the discussion in this chapter. 
 Again, the intention is not to cover Spring Boot in detail; that is outside the scope of this 
 chapter. Readers familiar with Java or Spring should have no problem getting started by 
 visiting the Spring Boot home page. I will spend time on very essential tools required for 
 the discussion so that I don’t deviate from the intention of this book, which is explaining 
 practical microservices. However, by the time you start looking at the code samples in 
 later chapters, you should be familiar with the basic building block code constructs.
  
 You will learn the following in this chapter:
  
 • How to use Spring Initializer to create a Boot project template
  
 • How to use cURL to access a Boot sample for CRUD operations 
 against MongoDB
  
 • An HATEOAS and HAL introduction, and how to access data using 
 RestTemplate
  
 • How to developing an end-to-end Boot sample for performing CRUD 
 operations against REST
  
 © Binildas Christudas 2019 
  
 147
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_7",NA
 Performing Data Operations Using ,NA,NA
Spring Boot and MongoDB,"Polyglot persistence is a key aspect in the microservices architecture. While you still 
 need ACID-compliant data stores with local and/or distributed transaction capabilities, 
 careful analysis will reveal that majority of the data storage and retrieval operations 
 don’t need these rigid capabilities, which always come at a price. Today, many NoSQL 
 databases are designed to operate over large clusters and can tackle very large volumes 
 of data; they can also efficiently respond to read requests with traffic increasing 
 exponentially, still performing more or less linearly. So, it is natural within a single 
 application to address data store requirements addressing both kinds (SQL and NoSQL), 
 and this is where polyglot persistence comes into play. In a microservice context, you 
 may use multiple data storage technologies, chosen based upon the way data is used by 
 individual microservices or components of a single large enterprise application. 
 MongoDB is a best choice in scenarios when you need to store data in document format, 
 so you’ll look at a MongoDB sample over the rest of the chapters in this book.
  
 You will implement a “Hello World” kind of Spring Boot application in this section. 
 There is more than one way to start developing a Spring Boot application, and the main 
 ways are
  
 • Using the Spring Boot command line interface (CLI) as a command- line 
 tool
 1
  
 • Using IDEs such as Eclipse and Spring Tool Suite (STS) to provide 
 Spring Boot support
 2
  
 • Using the Spring Initializer project
  
 You will follow the last method in this section.
  
 1
 https://docs.spring.io/spring-boot/docs/current/reference/html/cli-using-the- cli.html 
  
 2
 www.eclipse.org/community/eclipse_newsletter/2018/february/springboot.php
  
 148",NA
 Creating a Spring Boot Project Template Using ,NA,NA
the Spring Initializer,"You will use the Spring Initializer to create a Spring Boot project here. The Spring 
 Initializer is a drop-in replacement for the Eclipse-based Spring Tool Set (STS) project 
 wizard and provides an online web UI to configure and generate different flavors of a 
 Spring Boot project. Using the Spring Initializer, you can generate a project through the 
 online interface, which can then be imported into any IDE.
  
  
 The aim is to quickly develop an application that will help you to achieve the 
 following:
  
 • Get introduced to Spring Boot
  
 • Get introduced to MongoDB
  
 • Get introduced to basic CRUD operations using Spring Data
  
 The Spring Initializer project is available at 
 http://start.spring.io
 .
  
 You need to fill in the details, such as whether it is a Maven project and whether you 
 need to use Java for the Boot project and the Spring Boot version. Other details include 
 group and artifact ID, as shown in Figure 
 7-1
 . Next, click Switch to go to the full version 
 link under the Generate Project button. Here you can select MongoDB and Rest 
 Repositories as the dependencies. You also need to make sure that the Java version is 8 
 and the package type is selected as JAR. Once the dependencies are selected, you may hit 
 the Generate Project button. This will generate a Maven project. 
  
 This project can be downloaded as a ZIP file into the default download directory of 
 your browser.
  
 149",NA
 Spring Boot Starter Parent,"Typically your Maven pom.xml file will inherit from the spring-boot-starter-parent 
 project and declare dependencies to one or more “starters.” In Figure 
 7-1
  you can see 
 two such starters: MongoDB and Rest Repositories.
  
  
 Listing 
 7-1
  mentions your POM inheritance hierarchy, which is a Bill of Materials 
 (BOM) to manage the different libraries and the versions required for a project.
  
 151",NA
 Spring Boot Dependencies,"Next, if you can review the dependency section, you can see that the POM file mentions 
 only three dependencies, as shown in Listing 
 7-2
 .
  
 Listing 7-2. 
 Spring Boot Dependencies
  
 <dependencies>
  
  
  <dependency>
  
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  
  <artifactId>spring-boot-starter-data-mongodb</artifactId>
  
  
 </dependency>
  
  
  <dependency>
  
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  
  <artifactId>spring-boot-starter-data-rest</artifactId>
  
  
 </dependency>
  
  
  <dependency>
  
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  <artifactId>spring-boot-starter-test</artifactId>
  
  
  
 <scope>test</scope>
  
  
  </dependency> 
  
 </dependencies>
  
 152",NA
 Spring Boot Maven Plugin,"Next, let’s look at the Spring Boot Maven plugin. See Listing 
 7-3
 .
  
 Listing 7-3. 
 Spring Boot Maven Plugin
  
 <build>
  
  
  <plugins>
  
  
  
  <plugin>
  
  
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  
  <artifactId>spring-boot-maven-plugin</artifactId>
  
  
  
 </plugin>
  
  
  </plugins> 
  
 </build>
  
 The Spring Boot Maven plugin in Listing 
 7-3
  helps to create the single executable 
 JAR. The single executable JAR is a self-contained executable JAR file that you can run in 
 production.
  
 153",NA
 Design and Code the Domain Entities,"For the sake of the sample in this section, you will keep the domain entity very simple. 
  
 Your entity is a typical product that can be listed in an e-commerce site. Multiple 
 products fall into a product category, so on the site you can first show product 
 categories and an online user can explore or browse through the product categories to 
 see all products available under the selected category. Figure 
 7-2
  shows the design for 
 your domain entity. This is a basic design that will help you manage product category vs. 
 product relationship to meet the requirement of listing all products available under the 
 selected product category.
  
  
 Figure 7-2. 
 Product/product category domain model
  
 Listing 
 7-4
  shows the code required to do this.
  
 154",NA
 Code the Repositories,"The repository is an interface and it allows you to perform various operations 
  
 involving Product and ProductCategory objects. It gets these operations by extending 
 the MongoRepository interface defined in the Spring MongoDB project API. Basic 
 functionalities provided by MongoRepository are
  
 155",NA
 Code the Boot Application Executable,"You can modify the EcomProductMicroserviceApplication.java file if required. Listing 
 7-6
  shows the default code generated earlier. This is a simple Java class with a main() 
 method so that it can be run as a standalone Java application with an embedded 
 Tomcat servlet container as the HTTP runtime.
  
 Listing 7-6. 
 Spring Boot Application (ch07\ch07-
 01\src\main\java\com\acme\ 
 ch07\ex01\product\EcomProductMicroserviceApplication.java)
  
 @SpringBootApplication 
  
 public class EcomProductMicroserviceApplication {
  
  
  public static void main(String[] args) {
  
  
  
  SpringApplication.run(EcomProductMicroserviceApplication.class,
  
  
  
  args);
  
  
  } 
  
 }
  
 While the main() method uses Spring Boot’s SpringApplication.run() method to 
 launch an application, Spring Boot internally spins up Spring Data JPA to create concrete 
 implementation classes of the ProductRepository and ProductCategoryRepository and 
 configure it to integrate to the back-end database using JPA.",NA
 Build and Package the Spring Boot Application,"The Spring Boot style is to build and package the example by creating a completely self-
 contained executable JAR file that you can run in production. As explained the 
 “Microservices Are Self-Contained” section in Chapter 
 3
 , executable JARs are also called 
 fat JARs and are archives that contain your compiled classes along with all of the other 
 JAR dependencies that your code needs to run, which gets resolved when you interpret 
 your POM dependency.
  
 ch07-01\pom.xml contains the Maven scripts required to build run the samples. 
  
 Make sure MongoDB is up and running. You may want to refer to Appendix A to get 
 started with MongoDB.
  
 157",NA
 Run and Test the Spring Boot Application,"In the Windows command prompt where the mongo shell is connected to a running 
 mongod instance, you may want to first clean up any required collections:
  
 > show collections 
  
 product 
  
 productCategory 
  
 > db.productCategory.drop() 
  
 true 
  
 > db.product.drop() 
  
 true 
  
 > show collections 
  
 >
  
 158",NA
" Developing Using the Spring HAL Browser, ",NA,NA
HATEOAS,"A very convenient aspect of the hypermedia-driven REST interface is how you can 
 discover all the RESTful endpoints using cURL (or whatever REST client you are using). 
 There is no need to exchange a formal contract or interface document with your 
 customers prior to the method invocation (query), if each response also provides 
 information on what options are available next for the user to act on. The HAL format 
 provides a consistent and easy way to hyperlink between resources in your API. HAL 
 will make your REST API explorable, and its documentation is easily discoverable from 
 within the API itself. This will make your API easier to work with in both manual and 
 machine-readable mode and therefore more attractive to client developers. HATEOAS 
 (Hypertext As The Engine Of Application State) is a REST pattern where the navigation 
 links are provided as part of the response payload. The client can then determine the 
 state and follow the transition URLs provided as part of that state.
  
 Open source libraries available for most major programming languages are available 
 in HAL, so APIs that adopt HAL can be easily served and consumed in multiple 
  
 platforms and programming languages. It’s so simple that you can just deal with it as 
 you would with any other JSON.",NA
 The HAL Browser,"The HAL Browser is a useful application based on the HAL specification for handling 
 HAL+JSON data. It’s a web app with HAL-powered JavaScript. You can point it to any 
 HAL-compliant Spring Data REST API and use it to navigate the app and traverse 
 through linked resources.
  
 163",NA
 Test HAL REST End Points Using RestTemplate,"You may now execute the Junit tests using Maven. The tests are provided in the folder 
 ch07-02\src\test\java\com\acme\ch07\ex02\product. The tests in the previous 
 section of this chapter directly accessed the Mongo repository and did data operations; 
 however, the tests in this section will hit the REST API automatically generated by 
 Spring Data REST. Listings 
 7-10
  through 
 7-12
  examine the code required to do data 
 operations hitting the HAL REST end points using RestTemplate. Listing 
 7-10
  shows 
 how to create new resources in the server by invoking the HTTP POST method. It also 
 shows how to invoke the HTTP DELETE method, which you do in the test initialization 
 setup.
  
 Listing 7-10. 
 Testing HAL REST End Points Using RestTemplate (ch07\ch07-02\ 
 src\test\java\com\acme\ch07\ex02\product\ProductHalRestTemplateTest.jav
 a)
  
 public class ProductHalRestTemplateTest {
  
  private static String PRODUCT_SERVICE_URL =
  
  
 ""http://127.0.0.1:8080/products"";
  
  @Before
  
  public void setUp(){
  
  
  deleteAllProducts();
  
  }
  
  @Test
  
  public void testPostProduct(){
  
  try{
  
  
  Product productNew1 = createProduct(""1"");
  
  
  Product productNew2 = createProduct(""2"");
  
  
  RestTemplate restTemplate = restTemplate();
  
  
  Product productRetreived1 = restTemplate.postForObject(
  
  
  PRODUCT_SERVICE_URL, productNew1, Product.class);
  
  Product 
 productRetreived2 = restTemplate.postForObject(
  
  
  
 PRODUCT_SERVICE_URL, productNew2, Product.class);
  
  
 assertTrue(""successfully saved"",true);",NA
 Develop a RESTful Web Service,"REST (Representational State Transfer) is an architectural style for designing distributed 
 systems which was introduced by Roy Fielding in his doctoral dissertation in the year 
 2000. REST is a generic set of constraints applied to resources; however, it is commonly 
 associated with HTTP. This section will introduce REST concepts and you will look at a 
 complete implementation of a complete REST provider as well as a REST consumer 
 using Spring Boot.",NA
 REST Basics,"REST recommends a set of constraints, such as being stateless, having a client/server 
 relationship, providing a uniform interface, request-response cycles being idempotent, 
 and so on. REST is not strictly related to HTTP, but it is most commonly associated with 
 it.
  
 171",NA
 HTTP Methods for CRUD Resources,"The main methods in HTTP you can leverage for implementing REST are listed here:
  
 • GET: GET is the simplest HTTP operation and its intention is to retrieve 
 a resource from the server. 200 OK is the status code for a successful 
 operation. All GET operations should be idempotent, which means 
 regardless of how many times you repeat the operation with the same 
 parameters, there should not be any change in state for the resource.
  
 172",NA
 Develop a REST Controller in Spring Boot,"You will use the same Product entity described in previous sections to build a fully 
 functional REST service to do CRUD operations. Spring’s approach in building RESTful 
 web services is to use a controller to handle HTTP requests. Listings 
 7-13
  through 
 7-16 
 show the complete code for building a HATEOS-based REST controller using Spring. 
  
 Listing 
 7-13
  shows how a product with a particular ID can be retrieved. The 
 @RequestMapping annotation ensures that HTTP requests to /products/{id} are 
 mapped to the getProduct() method.
  
 3
  As per strict HTTP specifications, the difference between a POST and PUT is in how the server 
 interprets the URI. In a POST, the URI normally identifies an object on the server that can process 
 the included data. In a PUT, the URI identifies a resource in which the server should place the 
 data. So a POST URI generally indicates a program or a script that can do processing; a PUT URI 
 is usually the path and name for a resource.
  
 173",NA
 Test the REST Controller Using RestTemplate,"Once the application is up, you can test it. You can use any REST client you wish. 
  
 Listing 
 7-17
  shows how to code a Java client using RestTemplate to consume the 
 HATEOAS service. RestTemplate is Spring’s central class for synchronous client-side 
 HTTP invocations. RestTemplate simplifies communication with HTTP servers, and 
 enforces REST principles. RestTemplate handles low-level HTTP connections, leaving 
 application code to provide URLs (with possible template variables) and extract the 
 responses back. RestTemplate by default relies on JDK facilities to establish HTTP 
 connections; however, you may switch to use a different HTTP library such as Apache 
 HttpComponents, Netty, or OkHttp.
  
 Listing 7-17. 
 Client Code Using RestTemplate to Consume a HATEOAS 
 Service (ch07\ch07-03\src\test\java\com\acme\ch07\ex03\product\ 
 ProductControllerRestTemplateTest.java)
  
 public class ProductControllerRestTemplateTest {
  
  private static String PRODUCT_SERVICE_URL =
  
  
 ""http://localhost:8080/products"";
  
  @Test
  
  public void testPostProduct(){
  
  
  Product productNew1 = createProduct(""1"");
  
  
  RestTemplate restTemplate = restTemplate();
  
  
  Product productRetreived1 = restTemplate.postForObject(
   
  
 PRODUCT_SERVICE_URL,       productNew1, Product.class); }
  
  @Test
  
  public void testGetAProduct(){
  
  Product productNew2 = createProduct(""2"");
  
  RestTemplate restTemplate = restTemplate();
  
  Product productRetreived2 = restTemplate.postForObject(
  
  
 PRODUCT_SERVICE_URL, productNew2, Product.class);
  
 179",NA
 Summary,"In this chapter, you learned about Spring Boot and how its opinionated view of the 
 Spring platform and many other third-party Java libraries provides an easy and less 
 scripted way of getting things done, leveraging code, and packaging by conventions. 
  
 You then played with MongoDB, putting code to execute CRUD events over a custom 
 entity or resource. You used both Postman and Curl to do simple testing. Code in later 
 sections also introduced the concepts of HATEOAS and HAL. Next, you developed a 
 complete REST controller sample so that you have a place on the server side where you 
 can put complex business logic and custom rules and validations if required. In 
 succeeding chapters, more code samples will be built over the samples present in this 
 chapter. Further, most of the succeeding chapters leverage Spring Boot, so this chapter is 
 a foundation for you to get the code working in the rest of the chapters. After Spring 
 Boot, the next framework you want to look into is Spring Cloud, which provides 
 implementations for common patterns in distributed microservices ecosystems. You will 
 do so in the next chapter.
  
 182",NA
CHAPTER 8,NA,NA
Spring Cloud,"In Chapter 
 7
 , you were introduced to the Spring Boot. You explored several examples 
 built with Spring Boot so now you have the building blocks for an enterprise-level 
 application, whether the application is medium scale or large scale. In this chapter, you 
 will look into the next indispensable piece of Spring called Spring Cloud, which is built 
 over Spring Boot itself. There are a bunch of common patterns in distributed, 
 microservices ecosystems that can help you integrate the core services as a loosely 
 coupled continuum, and Spring Cloud provides many powerful tools that enhance the 
 behavior of Spring Boot applications to implement those patterns. You will learn only 
 the major and critical blocks required to keep the discussion continuing in subsequent 
 chapters, again with the help of concrete code samples. The samples in this chapter are 
 incrementally built over the preceding samples, so please don’t skip any section or you 
 may not get the succeeding samples to run smoothly.
  
 You will learn about the following in this chapter:
  
 • The Feign client to make HTTP API calls
  
 • Hystrix, the circuit breakers to gracefully degrade
  
 • The Hystrix dashboard, showing a graphical overview of a circuit 
 breaker in the system
  
 • Ribbon, the client-side load balancer
  
 • Eureka, a REST-based registry service
  
 • Zuul, the API gateway, which is the front controller for your 
 microservices
  
 • The Config Server to externalize version control and manage 
 configuration parameters for microservices
  
 © Binildas Christudas 2019 
  
 183
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_8",NA
 Spring Cloud for Microservices Architecture,"The “The Architecture of Microservices” section in Chapter 
 4
  talked about the major 
 new concerns you need to deal with when you move from a traditional architecture to a 
 microservices-based architecture. Due to the inversion effect in microservices 
 architecture, many of the intra-application concerns now get moved to the inter (micro) 
 services level, and when the number of microservices keeps growing, so does the 
 inherent growth in associated outer architecture complexity.
  
 Spring Cloud provides good out-of-the-box support for typical use cases and 
 extensibility mechanisms required in the microservices ecosystem. A few of them are 
 listed here:
  
 • Distributed/versioned configuration
  
 • Service registration and discovery
  
 • Routing and load balancing
  
 • Interservice calls
  
 • Circuit breakers
  
 • Distributed messaging
  
 Similar to Spring Boot, Spring Cloud takes a very declarative approach, and often 
 you get a lot of features with just an inclusion of a dependency in a classpath and/or an 
 annotation. Let’s look into a few of them now.",NA
 Feign Client Usage in Spring Cloud,"The Feign client is a Java-to-HTTP client-side binder inspired by libraries like Retrofit, 
 JAXRS-2.0, and WebSocket. Feign’s intent is to reduce the complexity of invoking HTTP 
 APIs by generalizing the binding denominator uniformly to HTTP APIs regardless of the 
 maturity of the REST APIs (a.k.a. the restfulness of the APIs). Feign makes HTTP API 
 calls simple by processing annotations into a templatized request. Just before sending 
 the requests, arguments are applied to these templates in a straightforward fashion. 
 However, Feign only supports text-based APIs. Nevertheless, Feign dramatically 
 simplifies system aspects like replaying requests, unit testing, etc. You will look at 
 invoking HTTP APIs in this section.
  
 184",NA
 Design a Feign Client Scenario,"Starting with this section and for all other examples in Spring Cloud in this chapter, you 
 will use a simple yet representative real-world use case. You will look into the design of 
 the use case first and then learn more. Figure 
 8-1
  illustrates a simple scenario where 
 there are two separate applications or, in our terms, two separate microservices: 
 Product Web and Product Server.
  
  
 Figure 8-1. 
 A Feign client usage scenario
  
 185",NA
 Code Using Feign Client,"Since Feign is a declarative HTTP client, with one spring-cloud-starter-feign 
  
 dependency mentioned in your Maven POM and with another single annotation of 
 @EnableFeignClients, you have a fully functional HTTP client with a sensible, ready- to- 
 go default configuration. Visit pom.xml to see the explicit mention of the Feign client 
 dependency. See Listing 
 8-1
 .
  
 Listing 8-1. 
 Feign Client Dependency in Maven (ch08\ch08-01\ProductWeb\ 
 pom.xml)
  
 <dependency>
  
  
  <groupId>org.springframework.cloud</groupId>
  
  
  <artifactId>spring-cloud-starter-feign</artifactId> 
 </dependency>
  
 With Feign added on the classpath, only one more annotation is needed to make 
 everything work with the default configuration properties. This is mentioned in Listing 
 8-2
 .
  
 Listing 8-2. 
 Enable Feign Client (ch08\ch08-01\ProductWeb\src\main\java\ 
 com\acme\ecom\product\controller\ProductRestController.java)
  
 import org.springframework.cloud.netflix.feign.EnableFeignClients;
  
 @EnableFeignClients(basePackageClasses = ProductServiceProxy.class) 
 @ComponentScan(basePackageClasses = ProductServiceProxy.class) 
 @CrossOrigin 
  
 @RestController 
  
 public class ProductRestController implements ProductService{
  
 private ProductServiceProxy productServiceProxy;
  
  @Autowired
  
  public ProductRestController(ProductServiceProxy productServiceProxy){
  
  
 this.productServiceProxy = productServiceProxy;
  
  }
  
 188",NA
 Build and Test the Feign Client,"The complete code required to demonstrate the Feign client is in folder ch08-01. Make 
 sure MongoDB is up and running. You may want to refer to Appendix A to get started 
 with MongoDB.
  
 You first build and package the executables for the Product Server microservice and 
 bring up the server. There is a utility script provided which you can easily execute in 
 folder ch08\ch08-01\ProductServer\make.bat:
  
 cd ch08\ch08-01\ProductServer 
  
 D:\binil\gold\pack03\ch08\ch08-01\ProductServer>make 
  
 D:\binil\gold\pack03\ch08\ch08-01\ProductServer>mvn -Dmaven.test.skip=true 
 clean package
  
  
 You can run the Spring Boot application in more than one way. The straightforward 
 way is to execute the JAR file via the following commands:
  
 D:\binil\gold\pack03\ch08\ch08-01\ProductServer>run 
  
 D:\binil\gold\pack03\ch08\ch08-01\ProductServer>java -jar -Dserver.
  
 port=8080 ./target/Ecom-Product-Microservice-0.0.1-SNAPSHOT.jar
  
 These commands will bring up the Product Server in port 8080. Note that an 
 initialization component kept in the following place will pump a few Product instances 
 into the MongoDB during startup, which will be handy for demonstrating your 
 application later:
  
 ch08\ch08-01\ProductServer\src\main\java\com\acme\ecom\ 
 productInitializationComponent.java
  
  
 Next, build and package the executables for the Product Web microservice and bring 
 up the server:
  
 cd ch08\ch08-01\ProductWeb 
  
 D:\binil\gold\pack03\ch08\ch08-01\ProductWeb>make 
  
 D:\binil\gold\pack03\ch08\ch08-01\ProductWeb>mvn -Dmaven.test.skip=true clean 
 package 
  
 D:\binil\gold\pack03\ch08\ch08-01\ProductWeb>run 
  
 D:\binil\gold\pack03\ch08\ch08-01\ProductWeb>java -jar -Dserver.port=8081 
 .\target\Ecom-Product-Microservice-0.0.1-SNAPSHOT.jar
  
 190",NA
 Hystrix Fallback,"There are times when a particular microservice is busy—or a particular database, or for 
 that matter any resource—so it is not in a position to respond back within the expected 
 SLA. In such scenarios, the caller service cannot wait on the dependent service endlessly, 
 so there should be alternate strategies. You’ll handle a scenario with the Hystrix circuit 
 breaker falling back to an alternate strategy.
  
 Circuit breakers can gracefully degrade functionality when a method call to a service 
 or to a resource fails. Use of the circuit breaker pattern can allow a microservice to 
 continue its operations when a dependent service fails. This will prevent the failure from 
 cascading, thus giving the failing service enough time to recover.",NA
 Design a Hystrix Fallback Scenario,"You are going to expand the sample from the previous section (illustrated in Figure 
 8-1
 ). 
 Figure 
 8-4
  illustrates the simple scenario where there are three separate applications or, 
 in our terms, three separate microservices: Product Web, Product Server 1, and Product 
 Server 2.
  
  
 Figure 8-4. 
 A Hystrix fallback usage scenario
  
 192",NA
 Code the Hystrix Fallback Scenario,"You have already seen how the Feign client is declared in your POM. Similarly, you 
 can bring the Hystrix dependencies by declaring them again in the POM. All the code 
 samples for this section are placed in folder ch08\ch08-02. Visit pom.xml to see the 
 explicit mention of the Hystrix dependency. See Listing 
 8-4
 .
  
 Listing 8-4. 
 Spring Cloud Hystrix Dependency (ch08\ch08-02\ProductWeb\ 
 pom.xml)
  
 <dependency>
  
  <groupId>org.springframework.cloud</groupId>
  
  <artifactId>spring-cloud-starter-hystrix</artifactId> 
 </dependency>
  
 195",NA
 Build and Test the Hystrix Fallback Scenario,"The complete code required to demonstrate the Hystrix fallback is kept inside folder 
 ch08-02. Make sure MongoDB is up and running. You may want to refer to Appendix A 
 to get started with MongoDB.
  
 You first build and package the executables for the Product Server 1 
 microservice and bring up the server. A utility script that you can easily execute is in 
 folder ch08\ ch08- 02\ProductServer\make.bat.
  
 cd ch08\ch08-02\ProductServer 
  
 D:\binil\gold\pack03\ch08\ch08-02\ProductServer>make 
  
 D:\binil\gold\pack03\ch08\ch08-02\ProductServer>mvn -Dmaven.test.skip=true 
 clean package
  
  
 You can run the Spring Boot application in more than one way. The straightforward 
 way is to execute the JAR file via the following commands:
  
 cd ch08\ch08-02\ProductServer 
  
 D:\binil\gold\pack03\ch08\ch08-02\ProductServer>run 
  
 D:\binil\gold\pack03\ch08\ch08-02\ProductServer>java -jar -Dserver.
  
 port=8080 .\target\Ecom-Product-Microservice-0.0.1-SNAPSHOT.jar
  
 These commands will bring up the Product Server in port 8080. You will now build 
 and package the executables for the Product Server 2 microservice and bring up the 
 server in a new command window:
  
 cd ch08\ch08-02\ProductServerAlternate 
  
 D:\binil\gold\pack03\ch08\ch08-02\ProductServerAlternate>make 
  
 D:\binil\gold\pack03\ch08\ch08-02\ProductServerAlternate>mvn -Dmaven.test.
  
 skip=true clean package 
  
 D:\binil\gold\pack03\ch08\ch08-02\ProductServerAlternate>run 
  
 D:\binil\gold\pack03\ch08\ch08-02\ProductServerAlternate>java -jar -
 Dserver.port=8079 .\target\Ecom-Product-Microservice-0.0.1-SNAPSHOT.jar
  
 198",NA
 Hystrix Dashboard,"A Hystrix dashboard can be used to provide a graphical overview of a circuit breaker in 
 the system. In a typical microservices architecture, there will be more than one 
 microservice processes and in such cases, you will need to monitor more than one 
 circuit breaker in the application. For this, you can use Turbine, which is not explained 
 here. In this section, you will see how to enable a Hystrix dashboard.",NA
 Redesign a Hystrix Fallback Method,"You will now slightly modify the Feign and Hystrix design from the “Hystrix Fallback” 
 section. The idea is to first demonstrate yet another way of defining a Hystrix fallback 
 and afterwards demonstrate the Hystrix dashboard. The refactored design is shown in 
 Figure 
 8-7
 .
  
 200",NA
 Code the New Design of Hystrix,"All the code samples for this section are placed in folder ch08\ch08-03. The Hystrix 
 dashboard application is yet another Spring Boot application. To enable it, you need to 
 follow a few steps. Visit pom.xml to see the explicit mention of the Hystrix dashboard 
 dependency in Listing 
 8-9
 .
  
 201",NA
 Build and Test the Hystrix Fallback Scenario,"The complete code required to demonstrate the Hystrix fallback is kept inside folder 
 ch08-03. Make sure MongoDB is up and running. You can then build, pack, and run the 
 three microservices in the following order:
  
 cd ch08\ch08-03\ProductServer 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductServer>make 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductServer>mvn -Dmaven.test.skip=true clean 
 package 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductServer>run 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductServer>java -jar -Dserver.
  
 port=8080 .\target\Ecom-Product-Microservice-0.0.1-SNAPSHOT.jar
  
 cd ch08\ch08-03\ProductServerAlternate 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductServerAlternate>make 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductServerAlternate>mvn -Dmaven.test.
  
 skip=true clean package 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductServerAlternate>run 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductServerAlternate>java -jar -
 Dserver.port=8079 .\target\Ecom-Product-Microservice-0.0.1-SNAPSHOT.jar
  
 cd ch08\ch08-03\ProductWeb 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductWeb>make 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductWeb>mvn -Dmaven.test.skip=true clean 
 package 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductWeb>run 
  
 D:\binil\gold\pack03\ch08\ch08-03\ProductWeb>java -jar -Dserver.port=8081 
 .\target\Ecom-Product-Microservice-0.0.1-SNAPSHOT.jar
  
 205",NA
 Inspect Hystrix Dashboard,"The Hystrix dashboard (Figure 
 8-8
 ) is available at the following URL in your case:
  
 http://localhost:8081/hystrix
  
  
 Figure 8-8. 
 Hystrix dashboard
  
 206",NA
" Ribbon, the Client-Side Load Balancer","Having looked at the Feign client and the Hystrix fallback, now is the right time to 
 introduce the next important component in Spring Cloud: Ribbon. Ribbon is a client- 
 side load balancer that gives you extra control over the behavior of HTTP and TCP 
 clients. Feign already uses Ribbon, so understanding Ribbon is crucial.
  
 Load balancing distributes incoming traffic between two or more microservices. 
  
 It enables you to achieve fault tolerance in your microservice applications. Load 
 balancing aims to optimize resource usage, maximize throughput, minimize response 
 time, and avoid overloading any single microservice. Using multiple microservice 
 instances of the same service with load balancing instead of a single instance may 
 increase reliability and availability at the cost of redundancy.
  
 Ribbon offers configuration options such as connection timeouts, retries, retry 
 algorithms (exponential, bounded back off), load balancing, fault tolerance, support for 
 multiple protocols (HTTP, TCP, UDP), support in an asynchronous and reactive model, 
 caching, and batching.",NA
 Design a Ribbon Client Scenario,"You will use the same design you used in the section for the Feign client. However, 
 you will enhance the Feign client to internally leverage Ribbon. The design is shown in 
 Figure 
 8-10
 .
  
 208",NA
 Code to Use Ribbon Client,"All the code samples for this section are placed in folder ch08\ch08-04. Visit pom.xml to 
 see the explicit mention of the Ribbon dependency. See Listing 
 8-13
 .
  
 209",NA
 Build and Test the Ribbon Client,"The complete code required to demonstrate Ribbon is kept inside folder ch08-04. 
 Make sure MongoDB is up and running. You can then build, pack, and run the three 
 microservices in the following order:
  
 cd ch08\ch08-04\ProductServer 
  
 D:\binil\gold\pack03\ch08\ch08-04\ProductServer>make 
  
 D:\binil\gold\pack03\ch08\ch08-04\ProductServer>mvn -Dmaven.test.skip=true 
 clean package
  
 210",NA
" Eureka, the Service Registry","Eureka is a REST-based registry service that is primarily used in public cloud-based 
 deployments, especially in the AWS cloud. Using Eureka you can locate microservices for 
 the purpose of load balancing and failover. Eureka is Spring Cloud’s service registry, 
 which acts as a phone book for your microservices. Each microservice self-registers with 
 the service registry, telling the registry where it lives (host, node name, port, etc.) and 
 perhaps other service-specific metadata. Eureka has two parts, the Eureka Server and a 
 client component, the Eureka Client, which makes interactions with the registry service 
 much easier. The client also has a built-in load balancer that does basic round-robin load 
 balancing.
  
 A service registry like Eureka has another feature that provides one or more levels of 
 indirection for service consumers. This means service consumers can do a registry look-
 up using a logical service name, and this logical service name may be mapped to a 
 different actual deployed service whose physical address entries are mapped against the 
 above logical name. This insulates the service consumers from any changes happening to 
 actual service details or whatever in the physical deployment environment. In the 
 sample explained in the “Ribbon” section, you might have noticed hard-coded values for 
 the service URL like:
  
 localhost:8080,localhost:8081
  
 This is not a good practice. A DNS (Domaine Name System) is used to resolve similar 
 problems; however, a DNS is comparatively heavy when you consider hundreds of 
 microservices within an enterprise application. Further, you do not want to expose the 
 server details of your microservices outside your perimeter or DMZ (Demilitarized 
 Zone). Typically the service consumers in a microservice-based enterprise application 
 are other microservices. Hence these microservice have to ask questions like service 
 topology (“Are there any ‘product-services’ available, and if so, where?”) and service 
 capabilities (“Can you handle A, B, and C?”). This is where service registries like Eureka 
 and Consul come into play. Eureka does not impose any restrictions on the protocol or 
 method of communication, so you can use Eureka to use protocols such as thrift, http(s) 
 or any other RPC mechanisms.
  
 You might still doubt the need for Eureka when there are already many software and 
 hardware load balancers, including AWS Elastic Load Balancer and AWS Route 53. 
  
 AWS Elastic Load Balancer is used to expose edge services, which typically connect to 
 end-user web traffic whereas Eureka fills the need for mid-tier load balancing or, in our 
  
 212",NA
 Design a Eureka-Enabled Scenario,"You will modify the design by introducing few new components, as shown in 
  
 Figure 
 8- 11
 . Here you replace ProductServiceProxy with RestTemplate. This 
  
 means the Product Web microservice will now use RestTemplate to consume any of the 
 instances of the Product Server microservice. RestTemplate simplifies communication 
 with HTTP servers, and the “Develop a RESTful Web Service” section in Chapter 
 7
  
 already explained how to use RestTemplate to communicate with RestController. You 
 will extend that here. Another intention of using 
  
 RestTemplate is that you can use Ribbon indirectly via an autoconfigured 
  
 RestTemplate when RestTemplate is on the classpath and a LoadBalancerClient bean is 
 defined so that you build over the previous sample of Ribbon itself.
  
 213",NA
 Code to Use Eureka,"All the code samples for this section are placed in folder ch08\ch08-05. Visit pom.xml to 
 see the explicit mention of the Eureka Server dependency. See Listing 
 8-15
 .
  
 Listing 8-15. 
 Eureka Dependency (ch08\ch08-05\Eureka\pom.xml)
  
 <dependency>
  
  
  <groupId>org.springframework.cloud</groupId>
  
  
  <artifactId>spring-cloud-starter-eureka-server</artifactId> 
 </dependency>
  
 214",NA
 Build and Test the Eureka Sample,"The complete code required to demonstrate the Eureka registry is kept inside folder 
 ch08-05. Make sure MongoDB is up and running. You can then build, pack, and run the 
 different microservices in the following order: 
  
  
 You first bring up the Eureka registry microservices:
  
 cd ch08\ch08-05\Eureka 
  
 D:\binil\gold\pack03\ch08\ch08-05\Eureka>make 
  
 D:\binil\gold\pack03\ch08\ch08-05\Eureka>mvn -Dmaven.test.skip=true clean 
 package 
  
 D:\binil\gold\pack03\ch08\ch08-05\Eureka>run1 
  
 D:\binil\gold\pack03\ch08\ch08-05\Eureka>java -jar -Dserver.port=8761 -
 Dspring.application.name=eureka-registry1 .\target\Ecom-Product- 
  
 Microservice-0.0.1-SNAPSHOT.jar
  
 When the first Eureka starts up, it will complain with a stack trace in the console, 
 since the registry cannot find a replica node to connect to. In a production environment, 
 you will want more than one instance of the registry. For your sample purposes, you will 
 bring up one more instance of Eureka.
  
 220",NA
 Bootstrap Your Bootstrap Server,"You should understand by now that every service instance in a microservice-based 
 enterprise application can be registered with the Eureka registry, and this is the case 
 with Eureka registry instances. There is one exception to this, which is the API gateway, 
 which you will look at the next section; until then, ignore this exception. I have said that 
 the Eureka registry is the directory of services for any interested service consumer, so if 
 the service consumer can somehow reach the registry with the name of the service it 
 wants to consume, the registry will provide the information (host, port, etc.) on how to 
 reach that service. Now the golden question is, how does any service consumer reach a 
 registry to start with? In other words, the Eureka registry will help any microservice to 
 bootstrap and advertise itself. But how can a Eureka registry ever advertise itself? How 
 does the bootstrap server bootstrap itself?!
  
 You need a standard set of well-identifiable addresses for Eureka servers. One 
 mechanism is to have an internal DNS or similar service. However, such pinned (IP) 
 addresses will only work in a traditional LAN environment. The moment we talk about 
 deployment in a public cloud like AWS, the scenario changes. In a cloud like AWS, 
 instances come and go. This means you cannot pin Eureka servers with a standard 
 hostname or an IP address. Mechanisms like AWS EC2 Elastic IP addresses must be 
  
 225",NA
" Zuul, the API Gateway","Any service needs to be reached by using an address—more correctly, using a well- 
 known address. Addresses like 
 www.google.com
  or 
 www.apple.com
  are examples. 
  
 Similarly, when you host an enterprise application, it will need to have an address, 
 specifically a home page URL. Such an URL when typed in a browser will lead your 
 request to the landing resource in your web site. Typically, these names or well-known 
 URLs are DNS resolved and directed to a physical IP or a combination of physical IPs. 
 When you deploy applications in a cluster or farm for scalability reasons, you also need a 
 load balancer, which will act as a reverse proxy where the request will land first and 
 then will be load balanced to any one instance in the farm. Apache HTTP server and F5 
 are similar devices. AWS ELB (Elastic Load Balancer) is a load balancing solution for web 
 services exposed to end-user traffic in an AWS cloud scenario. In all these cases, once 
 you advertise the publicly exposed IP, from there onwards the internal details of the 
 enterprise application, including the network and deployment details, are hidden from 
 the outside world. This is a recommended pattern and you will follow the same in your 
 microservice applications.",NA
 The Bootstrap URL,"In the previous section, you saw that every microservice can self-register to the Eureka 
 registry as and when they come up so that consumers can be directed to those services 
 by the registry. In order to discover where the registry is, you will use well-known and 
 fixed addresses for the registries. These registries only contain route mappings to 
 internal microservices. Externally accessible resources and addresses are typically not 
 indexed in the registry; instead, you need to expose them using other ways. DNS is one 
 such mechanism. But you also know that subsequent queries or requests arising from 
 those publicly accessible resources (like many AJAX calls from the home page and other 
  
 226",NA
 Design a Zuul-Enabled Scenario,"You will modify your design in Figure 
 8-13
  by introducing the Zuul API gateway; the 
 modified design is shown in Figure 
 8-16
 . The flow is as explained in the previous 
 section; however, I will not introduce all the complexities of DNS, etc. here. Let’s look at 
 the flow.
  
 The client device, which is the browser in your case, will be used to render the 
 product.html (Label 1). Once the product.html is loaded into the browser, it will fire a 
 request to the Product Web microservice. You will not bind the Product Web 
 microservice into the API gateway in this sample to keep it simple, so you will only bind 
 the Product Server microservice to the API gateway. Hence the request from the client 
 device to the Product Web microservice is a direct hit not through the API gateway 
 (Label 3). 
  
 The Product Web microservice now has to delegate the request to the Product Server 
 microservice and in order to do so, it will route the request through the API gateway 
 (Label 4). The API gateway will do a registry look up (Label 5) and return the server 
 details where the Product Server microservices are hosted back to the Ribbon client 
 in the Product Web microservice. The Product Web microservice takes this info and 
 load balances the request to any one of the instances of the Product Server 
 microservice (Label 6), since you will have two instances of Product Server 
 microservices hosted.",NA
 Code to Use Zuul,"All the code samples for this section are in folder ch08\ch08-06.Visit pom.xml to see 
 the explicit mention of the Zuul dependency. See Listing 
 8-24
 .
  
 Listing 8-24. 
 Zuul dependency (ch08\ch08-06\ProductApiZuul\pom.xml)
  
 <dependency>
  
  
  <groupId>org.springframework.cloud</groupId>
  
  
  <artifactId>spring-cloud-starter-zuul</artifactId> 
 </dependency> 
  
 <dependency>
  
  
  <groupId>org.springframework.cloud</groupId>
  
  
  <artifactId>spring-cloud-starter-eureka</artifactId> 
 </dependency>
  
 Note that Zuul by itself is a microservice, so it has to register itself to the registry 
 just like any other normal microservice. Hence Zuul also needs a Eureka dependency, 
 as shown in Listing 
 8-25
 .
  
 Next, you need Spring Cloud’s @EnableZuulProxy to stand up an API gateway that 
 other microservices can bind to. This is done in your regular Spring Boot application 
 main class with one annotation added to enable the Zuul gateway.
  
 Listing 8-25. 
 Enable Zuul (ch08\ch08-
 06\ProductApiZuul\src\main\java\com\ 
 acme\ecom\infra\ProductServerApiApplication.java)
  
 @EnableZuulProxy 
  
 @EnableDiscoveryClient 
  
 @SpringBootApplication 
  
 public class ProductServerApiApplication {
  
 public static void main(String[] args) {
  
  
  
  SpringApplication.run(ProductServerApiApplication.class, args);
  
  } 
  
 }
  
 232",NA
 Build and Test the Zuul Sample,"The complete code required to demonstrate the Eureka registry is in folder ch08-06. You 
 don’t require MongoDB for this sample. You can build, pack, and run the different 
 microservices in the following order. You first bring up the Eureka registry 
 microservices:
  
 cd ch08\ch08-06\Eureka 
  
 D:\binil\gold\pack03\ch08\ch08-06\Eureka>make 
  
 D:\binil\gold\pack03\ch08\ch08-06\Eureka>mvn -Dmaven.test.skip=true clean 
 package 
  
 D:\binil\gold\pack03\ch08\ch08-06\Eureka>run 
  
 D:\binil\gold\pack03\ch08\ch08-06\Eureka>java -jar -Dserver.
  
 port=8761 -Dspring.application.name=eureka-registry -Deureka.
  
 client.registerWithEureka=false -Deureka.client.fetchRegistry=true -
 Deureka.client.server.waitTimeInMsWhenSyncEmpty=0 -Deureka.client.
  
 serviceUrl.defaultZone=http://localhost:8761/eureka/ -Deureka.server.
  
 enableSelfPreservation=false .\target\Ecom-Product-Microservice-0.0.1- 
 SNAPSHOT.jar
  
 You next bring up the Zuul API gateway:
  
 D:\binil\gold\pack03\ch08\ch08-06\ProductApiZuul>make 
  
 D:\binil\gold\pack03\ch08\ch08-06\ProductApiZuul>mvn -Dmaven.test.skip=true 
 clean package 
  
 D:\binil\gold\pack03\ch08\ch08-06\ProductApiZuul>run 
  
 D:\binil\gold\pack03\ch08\ch08-06\ProductApiZuul>java -Dserver.port=8082 -
 Dspring.application.name=product-service-api -Deureka.client.serviceUrl.
  
 defaultZone=http://localhost:8761/eureka/ -jar ./target/Ecom-Product- 
 Microservice-0.0.1-SNAPSHOT.jar
  
 235",NA
 The Config Server,"Externalizing configuration parameters is a critical characteristic that 
  
 microservices exhibit. This is true for both application parameters and 
  
 infrastructure parameters. When there are many microservices, maintaining the 
 configuration parameters externally is a non-trivial task and Spring Cloud’s Config 
 Server comes to your rescue here.
  
 237",NA
 Design a Configuration Scenario,"You will introduce Config Server into your sample without doing many changes to the 
 other microservices. In your design, you will utilize Config Server only for the Product 
 Server microservices, even though it can be utilized for all other microservices. As shown 
 in Figure 
 8-18
 , the Product Server microservice utilizes the Spring Cloud Config Server to 
 manage the values for one of its configuration parameters.
  
  
 Figure 8-18. 
 Design for a Config Server scenario",NA
 Code to Use Config Server,"All the code samples for this section are in folder ch08/ch08-07. Visit pom.xml to see 
 the explicit mention of the Config Server dependency. See Listing 
 8-28
 .
  
 238",NA
 Build and Test the Config Server,"The complete code required to demonstrate the Config Server is in folder ch08-07. You 
 don’t require MongoDB for this sample too. You can build, pack, and run the different 
 microservices in the following order.
  
 You first bring up the Config Server microservices:
  
 cd ch08\ch08-07\ConfigServer 
  
 D:\binil\gold\pack03\ch08\ch08-07\ConfigServer>make 
  
 D:\binil\gold\pack03\ch08\ch08-07\ConfigServer>mvn -Dmaven.test.skip=true clean 
 package 
  
 D:\binil\gold\pack03\ch08\ch08-07\ConfigServer>run 
  
 D:\binil\gold\pack03\ch08\ch08-07\ConfigServer>java -Dserver.port=8888 -
 Dspring.application.name=productservice -jar .\target\Ecom-Product- Microservice-
 0.0.1-SNAPSHOT.jar
  
 Once the Config Server is up, the configuration parameters in productservice.
  
 yml listed in Listing 
 8-33
  can be inspected by typing http://localhost:8888/ 
 productservice/default.
  
 The first part in the URL is the microservice name. In your case, the microservice 
 name is productservice. The microservice name is a logical name given to the 
  
 application, using the 
 spring.application.name
  property in application.yml of the 
 Spring Boot (Product Server) application. Each application should have a unique name. 
 The Config Server will use this name to resolve and pick up the appropriate .yml or 
 .properties files from the Config Server repository. The application name is also 
 referred to as a service ID. See Figure 
 8-19
 .
  
 242",NA
 Summary,"You explored the major building blocks of Spring Cloud in this chapter. Since Spring 
 Cloud provides simple, easy-to-use, and Spring-friendly APIs and further since it’s built 
 on Spring’s “convention over configuration” approach, Spring Cloud defaults all 
 configurations and helps you to get off to a quick start. Many of the Spring Cloud 
 features will be used to build your e-commerce sample application in later chapters, so 
 the introductory level of knowledge provided in this chapter is essential for you to 
 connect multiple microservices and visualize the complete picture. As you may have 
 surmised, many of the Spring Cloud components are built from the ground up with the 
 characteristics of fail safe and high availability in mind. This is of priority with increased 
 outer architecture complexity for the microservices scenarios and you will do an end- 
 to- end analysis of various essential high availability aspects and features in the next 
 chapter.
  
 1
  The Spring Cloud Bus provides an easy and automatic mechanism to refresh 
 configurations across multiple instances without knowing how many instances there are or 
 their locations, which is not covered here.
  
 244",NA
CHAPTER 9,NA,NA
High Availability ,NA,NA
and Microservices,"High availability (HA) describes periods of time in which software services are available, 
 as well as the time required by these systems to respond to a request made by a user. 
  
 Eliminating single points of failure in your infrastructure that can cause a service 
 interruption is key in designing HA systems. Duplicating or designing redundant 
 components at every layer and at every stage is important to achieve HA, that too end to 
 end. The “Outer Architecture Perspective” section in Chapter 
 4
  talked about the outer 
 architecture concerns of a microservices architecture. Various sections and samples in 
 the last chapter provided you with concrete solutions to address a few of the concerns 
 from that section in Chapter 
 4
 . You saw how to bring up more than one instance of a 
 microservice. You also brought more than one instance of Eureka in the last chapter. In 
 this chapter, you will explore further details of HA in general and HA of microservices in 
 particular. You will also look at a comprehensive sample demonstrating end-to-end HA 
 of a microservices architecture.
  
 You will learn about the following in this chapter:
  
 • Defining and measuring HA
  
 • Decomposing HA at every layer, from the DNS lookup to storage 
 backup
  
 • 
  
 Relooking at HA aspects in the context of microservices
  
 245
  
 • 
  
 A code demonstration for HA using microservices and Spring Cloud
  
 © Binildas Christudas 2019 
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_9",NA
 High Availability,"High availability planning involves the identification of services that must be available 
 for business continuity. Components that comprise each service should be identified, 
 and list of possible points of failure for these systems should be made. A failure 
 tolerance baseline should be established for each of them and failover strategies should 
 be designed.",NA
 Measuring High Availability,"Software availability is expressed as a percentage of yearly uptime. Using the nearly 
 unachievable ideal of 100% availability as a baseline, the goal of the highest levels 
 of service availability is considered to be “five nines,” or 99.999% availability.
  
 Downtime (usually expressed in outage minutes per year) is another way of 
 expressing availability. Table 
 9-1
  shows comparisons of different levels of 
 availability.
  
 Table 9-1. 
 Levels of Availability
  
 Availability
  
 Unavailability
  
 Five Nines
  
 Downtime per Year
  
 0.9
  
 0.1
  
 1
  
 36 Days
  
 0.99
  
 0.01
  
 2
  
 87.7 Hours
  
 0.999
  
 0.001
  
 3
  
 8 Hours, 46 Minutes
  
 0.9999
  
 0.0001
  
 4
  
 52.5 Minutes
  
 0.99999
  
 0.00001
  
 5
  
 5 Minutes 16 Seconds
  
 0.999999
  
 0.000001
  
 6
  
 32 Seconds
  
 I will not explain these levels or explore specific means to attain these levels of 
 availability, since we have been describing and practicing them for decades and there 
 are separate books
 1
  and references
 2
  to explain them. Our discussion will be just 
 enough background for you to relate it to this microservices HA discussions.
  
 1
 www.amazon.com/Blueprints-High-Availability-Evan-Marcus/dp/0471430269 
 2
 http://highscalability.com/
  
 246",NA
 Baselining High Availability,"High availability baselines can be defined based on two parameters:
  
 • 
 Recovery Time Objective (RTO)
 : The amount of time a business can 
 function without the system’s availability
  
 • 
 Recovery Point Objective (RPO)
 : How old the data will be once 
 systems do recover
  
 Based on the RTO and RPO baseline objectives and further based on the available 
 budgets, accessible technologies, business criticality, and available technical expertise, 
 software components are to be designed to attain the required level of availability.",NA
 Decomposing High Availability,"If you have an infrastructure consisting of two identical, redundant web servers behind a 
 load balancing router, traffic coming from client devices can be equally distributed 
 between the web servers. However, if one of the servers goes down, the load balancer 
 will redirect all subsequent traffic to the remaining online server. This is a simple 
 mechanism which, if carefully extended, can be utilized to design HA for different 
 elements. 
  
 The Internet, internal networks, network devices, and software components are all 
 elementary links of an end-to-end HA chain. You will look at the essential links required 
 for our discussion so that the concepts and the sample demonstrated towards the end of 
 the chapter will make sense to you. Also, I will explain aspects in the context of an on-
 premises or private data center in this chapter. In Chapter 
 16
 , when I describe advanced 
 HA patterns, I will explain in the context of a public cloud so that you will have a broader 
 view of how HA has to be looked at both in the context of a private and a public cloud.",NA
 DNS Redundancy,"The “The Bootstrap URL” section in Chapter 
 8
  introduced the Domain Name System 
 (DNS) into the microservices architecture. Since the DNS serves as the phone book for 
 the Internet by translating human-friendly computer hostnames into IP addresses, it 
 serves as the bootstrap mechanism for most of the software-related operations 
 through the Internet. It makes sense to understand availability starting from this point 
 onwards. This means you need to understand mechanisms for DNS redundancy.
  
 247",NA
 DNS Load Balancing,"Once DNS redundancy is taken care, you need to think about DNS load balancing. A DNS 
 load balancer reviews a list of servers and sends one connection to each server in turn. 
 When a DNS change takes place, it has to be recorded on the ISP (Internet Service 
 Provider) level. ISPs only refresh their DNS cache once every TTL (time to live) cycle. 
  
 This implies that until the cache is updated, the ISPs are unaware of any changes that 
 took place and continue to route traffic to the wrong server.
  
 3
  A primary DNS server is the first point of contact for a browser, application, or device that 
 needs to translate a human-readable hostname into an IP address. The primary DNS server 
 contains a DNS record that has the correct IP address for the hostname. If the primary DNS 
 server is unavailable, the device contacts a secondary DNS server, containing a recent copy of 
 the same DNS records.
  
 249",NA
 ISP Redundancy,"ISPs provide you with pipes (or connections) from your enterprise to the Internet 
 (Figure 
 9-4
 ). If this pipe or path is down, it affects your network connectivity, which in 
 turn affects your enterprise application availability. This is where ISP redundancy comes 
 to your rescue.
  
  
 Figure 9-4. 
 Enterprise connectivity to an ISP
  
 251",NA
 Application Architecture Redundancy,"As illustrated in the previous section, the Internet-facing border routers peer directly to 
 the ISPs. Intrusion prevention appliances that guard against worms, viruses, denial- of- 
 service (DoS) traffic, and such, plus appliances like web security appliances (WSA) reside 
 in this 
  
 253",NA
 Data and Storage Redundancy,"Data is stored on either block-level storage arrays as in SANs (storage area networks), 
 or file-based arrays (also known as NASs or network-attached storage arrays). 
  
 They provide various levels of redundancy, so that if a single component in the 
 array (whether a disk drive, controller, SAN or LAN access port, etc.) fails, it will 
 not completely compromise the setup and data will still be accessible to the user. 
  
 Server hardware based on x86 architecture is typically configured with redundant 
 connections to SANs and Ethernet networks. Such connections to heterogeneous 
 devices are done using dual port adapters or by using multiple (single port) adapters. 
  
 The options of adapters depend on the space available in the servers (that is, the 
 number of I/O expansion slots) as well as the level of hardware redundancy required. 
  
 In short, the infrastructure is set up in such a way that it uses redundant paths, 
 switches, and access ports for network and storage resources.
  
 Figure 
 9-7
  reveals that the paths are redundant and do not permit a single point 
 of failure. If one of the Ethernet or SAN paths fails, there is still connectivity across a 
 surviving path. In such a failure, failover will be triggered by some type of multipath 
 or failover software.
  
 255",NA
 Highly Available Microservices,"You can now extend the application deployment architecture explained in the 
  
 “Application Architecture Redundancy” section earlier to accommodate the Mesh App 
 and Service Architecture explained earlier. This is shown in Figure 
 9-10
 . Note that in the 
 MASA style, apps are executed from the client device. They can be web apps, native 
 mobile apps, IoT apps, etc. However, there is nothing wrong in representing them within 
 the core data center behind the firewalls, which is the case in most of the web apps that 
 also have server-side execution capability. If the apps are mobile apps, typically they are 
 represented by an App Store (like Playstore, etc.). Further, if the apps don’t have any 
 server-side execution capability but get executed only in the client device, then they can 
 also be hosted in the DMZ or closer to the perimeter for easy distribution to client 
 devices. In such cases, the security concerns and other similar concerns will be further 
 intercepted by the API layer, which you visited in the previous chapter.
  
 259",NA
 A Highly Available Spring Cloud ,NA,NA
Microservice Demonstration,"The previous section explained how the microservices architecture fits into the high 
 availability reference architecture model from a deployment perspective. In this section, 
 you will look at a real-world scenario where you will simulate many aspects of HA 
 already discussed from a microservices perspective. You will simulate the HA building 
 blocks essential for a microservices scenario alone; however, you will not attempt to 
 demonstrate the rest of the general principles of infrastructure-level HA explained 
 earlier in this chapter, since they are well proven and nothing is different even when 
 applied to the microservices context.",NA
 Design a Highly Available Microservice Scenario,"For the demonstration purpose of the microservices HA scenario, you will utilize the 
 Eureka and Zuul components you used in Chapter 
 8
 . The scenario you will design is 
 shown in Figure 
 9-11
 .
  
 261",NA
 Code to Demonstrate Highly Available ,NA,NA
Microservices,"All the code samples for this section are in folder ch09\ch09-01. Note that you are 
 building over the examples in the previous chapter, especially the Eureka and Zuul 
 examples in Chapter 
 8
 , so you should get an overview of those examples first before 
 attempting to run this one. However, even if you skip those examples, you should still be 
 able to run and understand this one. See Figure 
 9-12
 .
  
 263",NA
Note,NA,NA
 you need to replace tiger in listing ,NA,NA
9-1,NA,NA
 with the name of your host.,"This file is usually found within the Nginx distribution. You need to edit the nginx. 
 conf file to reflect the above changes within the Nginx distribution, which I found on my 
 machine at the following location: nginx-1.13.5\conf.
  
 You may also want to refer to Appendix C to get familiarized with Nginx.
  
 The right way to use different names reflecting different sites is to use a local DNS 
 server and then create some CNAMEs in DNS and refer them to the Nginx configuration. 
 However, you will use a simple tweak here to get things running quickly. The hostname 
 of my windows machine is tiger, and localhost also refers to this machine, so I can use 
 these two different names to reference in my Nginx configuration to configure two 
 different reverse proxy setups. So, http://myapp1 and http://myapp2 are the two 
 reverse proxy setups, and http://myapp1 refers to the API gateway whereas 
 http://myapp2 refers to the web app server farms where the default home page of the 
 application can be fetched from.
  
  
 You start Nginx only after you bring up the API gateway and the web app servers so 
 that Nginx will start without any errors in its logs.
  
 265",NA
 Build and Test the Microservices High Availability,"The complete code required to demonstrate the Eureka registry is kept inside folder 
 ch09\ch09-01. You don’t need MongoDB for this sample. You can build, pack, and run 
 the different microservices in the following order.
  
 You first bring up the two instances of the Eureka microservices:
  
 cd ch09\ch09-01\Eureka 
  
 D:\binil\gold\pack03\ch09\ch09-01\Eureka>make 
  
 D:\binil\gold\pack03\ch09\ch09-01\Eureka>mvn -Dmaven.test.skip=true clean 
 package 
  
 D:\binil\gold\pack03\ch09\ch09-01\Eureka>run1 
  
 D:\binil\gold\pack03\ch09\ch09-01\Eureka>java -jar -Dserver.
  
 port=8761 -Dspring.application.name=eureka-registry1 -Deureka.client.
  
 registerWithEureka=false -Deureka.client.fetchRegistry=true -Deureka.
  
 client.server.waitTimeInMsWhenSyncEmpty=0-Deureka.client.serviceUrl.
  
 271",NA
 Summary,"A chain is as strong as its weakest link, and the same saying holds true for many aspects 
 of high availability. I have provided a ten-thousand-foot view of how HA and redundancy 
 looks at every stage of an end-to-end deployment, starting from the client browser 
 where data is originated and then to the web and application servers and further to the 
 data management and data storage layer and finally to the archiving or the DR part. 
  
 In Chapter 
 16
 , you will also look into advanced constructs and patterns in improving HA 
 with an aim of making sure the sanity of every byte created by the user is preserved as 
 per the intended data consistency rules in the end-to-end chain, regardless of whether 
  
 276",NA
CHAPTER 10,NA,NA
Microservice ,NA,NA
Performance,"When you move from the traditional three-tier or n-tier architecture to the 
 microservices architecture, one main observable characteristic is the increased number 
 of 
  
 interconnections between microservice processes. A computation that once took place 
 completely within a single process now might get split into many microcomputations 
 spanning across processes. This increases the number of interprocess communications, 
 the number of context switches, the number of I/O operations involved, and so on. So it 
 makes right sense to have a look at these aspects in more detail. In this chapter, you will 
 explore a few performance aspects to be considered in microservices and you will look 
 into the following:
  
 • Synchronous vs. asynchronous HTTP
  
 • The Servlet 3.0 spec for asynchronous HTTP
  
 • Code to demonstrate asynchronous HTTP between browser and 
 microservice
  
 • Code to demonstrate asynchronous HTTP between microservices
  
 • The Google Protocol Buffer
  
 • Code to demonstrate using the Google Protocol Buffer between 
 microservices",NA
 Communication Across the Outer ,NA,NA
Architecture,"The “Outer Architecture Perspective” section in Chapter 
 4
  introduced the outer 
  
 architecture of microservices. There you saw how the internal complexities of a typical 
 monolith architecture pop out to the “surface” when you move to a microservices-based 
 architecture. One obvious change is the split of a single or a few computational processes",NA
 Asynchronous HTTP,"You briefly looked at distributed messaging in Chapter 
 6
 , where you also appreciated 
 the differences between the synchronous and asynchronous style of communications 
 between microservices. You saw that messaging is a first-class technology by which 
 microservices can communicate asynchronously, and you saw via examples how you 
 can correlate many asynchronous message transmissions so as to weave them 
 together as pieces of a single, end-to-end request/response cycle. However, all of the 
 samples in Chapter 
 8
  used the HTTP protocol for intercommunications between 
 microservices. 
  
 You will look at the nature of these communications more closely in this section.",NA
 The Bad and the Ugly Part of HTTP,"As stated, all of the samples in Chapter 
 8
  use the HTTP protocol for 
  
 intercommunications between microservices. If you examine these interactions again, 
 you can observe that most of them are synchronous HTTP calls. Close observation of 
 these communications reveals that an incoming request from a consumer 
  
 microservice to your provider microservice server will capture one servlet connection 
 and perform a blocking call to the remote service before it can send a response to the 
 consumer microservice. It works, but it does not scale effectively if you have many such 
 concurrent clients. Synchronous HTTP is a best fit for a user using a client application to 
 get instant feedback or a response; however, that is not the case when it comes to 
 server-side processing.",NA
 APIs for Asynchronous HTTP Processing,"Typical containers in application servers like in Apache Tomcat normally use a server 
 thread per client request. Under increased load conditions, this necessitates containers 
 to have a large amount of threads to serve all the client requests. This limits scalability, 
 which can arise due to running out of memory or exhausting the pool of container 
 threads. Java EE has added asynchronous processing support for servlets and filters 
 from the Servlet 3.0 spec onwards. A servlet or a filter, on reaching a potentially 
 blocking operation when processing a request, can assign the operation to an 
 asynchronous execution context and return the thread associated with the request 
 immediately to the container without waiting to generate a response. The blocking 
 operation can later complete in the asynchronous execution context in some different 
 thread, which can",NA
 Design a Scenario to Demo Async HTTP ,NA,NA
Between Microservices,"You will use a trimmed down version of the same components used for previous 
 examples. So your sample here will consist of three main components: an HTML- based 
 client app and two microservices, as shown in Figure 
 10-2
 . I have removed all 
 complexities of HATEOAS and any data repositories so that you can concentrate on 
 async HTTP alone. Once you appreciate the design and the main components used to 
 implement it, then you should be able to use a similar pattern for your other complex 
 business scenarios.
  
 In the design shown, the client app communicates with the Product Web 
  
 microservice using the HTTP protocol; however, you want the client to do it using the 
 async HTTP model. Similarly, the Product Web microservice communicates with the 
 Product Server microservice, again using the HTTP protocol, and this intermicroservices 
 communication is designed using the async HTTP model.
  
  
 Figure 10-2. 
 Design an async HTTP scenario in Spring Boot
  
 285",NA
 Code to Use Async HTTP in Spring Boot,"All the code samples for this section are in folder ch10\ch10-01. Visit pom.xml to see the 
 explicit mention of the spring-boot-starter-web dependency for your Product Server 
 microservice. See Listing 
 10-5
 .
  
 Listing 10-5. 
 Adding spring-boot-starter-web to Spring Boot (ch10\ch10-
 01\ ProductServer\pom.xml)
  
 <dependency>
  
  
  <groupId>org.springframework.boot</groupId>
  
  
 <artifactId>spring-boot-starter-web</artifactId> 
 </dependency>
  
  
 spring-boot-starter-web will add Tomcat and Spring MVC to the Product Server 
 microservice.
  
 Next, look at the Boot main application class shown in Listing 
 10-6
 .
  
 Listing 10-6. 
 Async Enabled Spring Boot Application (ch10\ch10-
 01\ProductServer\src\main\java\com\acme\ecom\product\ 
 EcomProductMicroserviceApplication.java)
  
 @SpringBootApplication 
  
 @EnableAsync 
  
 public class EcomProductMicroserviceApplication {
  
  
  public static void main(String[] args) {
  
  
  
  SpringApplication.run(EcomProductMicroserviceApplication.class, args);
  
  } 
  
 }
  
 The @EnableAsync annotation switches on Spring’s ability to run @Async methods 
 in a background thread pool. This class also customizes the Executor backing the thread 
 pool. By default, a SimpleAsyncTaskExecutor is used. The SimpleAsyncTaskExecutor 
 does not reuse threads. Even though it supports limiting concurrent threads through 
  
 286",NA
 Build and Test Asynchronous HTTP ,NA,NA
Between Microservices,"The complete code required to demonstrate asynchronous HTTP between microservices 
 is in folder ch10\ch10-01. You don’t require MongoDB for this sample. You can build, 
 pack, and run the different microservices in the following order.
  
 291",NA
 Google Protocol Buffer Between ,NA,NA
Spring Boot Microservices,"The previous section talked about effectively utilizing the microservices’ server 
 resources like HTTP connections and threads. Equally important are the other possible 
 optimizations in intercommunications between microservices. Since microservices are 
 spread across process boundaries, the amount of data sent across microservices 
 matter. This boils down to the marshalling and unmarshalling of data structures across 
 microservices. You will look into this with examples in this section.",NA
 Protocol Buffer,"Protocol buffers are Google’s platform-neutral and language-neutral mechanism for 
 marshalling and unmarshalling structured data. You need to define how you want your 
 data to be structured to use Protocol Buffer, and then you can use generated source code 
 in multiple platforms and languages to easily write and read your structured data to and 
 from a variety of data streams. One benefit of using Protocol Buffer is that you can even 
 update your data structure without breaking already deployed application code that is 
 compiled against the “old” format. This is especially important in architecting 
 applications capable of adapting or evolving to future requirement changes.
  
 You will now look into the dynamics of using Protocol Buffer. You first need to 
 specify how you want the information you’re serializing to be structured in .proto files. 
 In doing so, you use the Protocol Buffer message types. Each Protocol Buffer message is a 
 logical grouping of information, containing a series of name-value pairs. Listing 
 10-13
  is 
 a sample of a .proto file that defines a message containing information about a Product, 
 which you used in all of your previous samples.
  
 Listing 10-13. 
 Sample .proto File
  
 message Product {
  
  string productId = 1;
  
  string name = 2;
  
  string code = 3;
  
  string title = 4;
  
  string description = 5;
  
 296",NA
 A Scenario to Demonstrate Protocol Buffer ,NA,NA
Between Microservices,"You will modify the same example you used in your earlier demonstrations to leverage 
 Protocol Buffer. You will use a trimmed down version of the same components used in 
 Chapter 
 8
 . So your example here will consist of three main components: an HTML-based 
 client app and two microservices, as shown in Figure 
 10-3
 . Here again I have removed all 
 complexities of HATEOAS and data repositories so that you can concentrate on the usage 
 of Protocol Buffer alone.
  
  
 Figure 10-3. 
 Use Protocol Buffer between microservices
  
 In your example design, you use a .proto file where you spec out the entities you 
 want to use. The next step is to run the Protocol Buffer compiler for the application’s 
 programming language (Java, in your case) on your .proto file to generate similar 
 classes. Now both the dependent and the independent microservices can be 
 programmed against the generated entity classes, thus making intermicroservices 
 communication using protocol buffer a straightforward step.
  
 299",NA
 Code to Use Protocol Buffer in Spring Boot,"All the code samples for this section are in folder ch08\ch10-02. You will look at the 
 code for the independent microservice first, the Product Server microservice. Visit 
 pom.xml to see the explicit mention of the protobuf-java and the protobuf-java-format 
 dependency for your Product Server microservice. See Listing 
 10-16
 .
  
 Listing 10-16. 
 Adding a Protocol Buffer Compiler and Runtime to the Maven 
 Build (ch10\ch10-02\ProductServer\pom.xml)
  
 <project>
  
  <properties>
  
  
  <protobuf-java.version>3.1.0</protobuf-java.version>
  
  
  <protobuf-java-format.version>1.4</protobuf-java-format.version> 
 </properties>
  
  <dependencies>
  
  
  <dependency>
  
  
  
  <groupId>com.google.protobuf</groupId>
  
  
  
  <artifactId>protobuf-java</artifactId>
  
  
  
  <version>${protobuf-java.version}</version>
  
  
  </dependency>
  
  
  <dependency>
  
  
  
  <groupId>com.googlecode.protobuf-java-format</groupId>
  
  
  <artifactId>protobuf-java-format</artifactId>
  
  
  
  <version>${protobuf-java-format.version}</version>
  
  
 </dependency>
  
  
  <dependency>
  
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  
  <artifactId>spring-boot-starter-web</artifactId>
  
  
 </dependency>
  
  </dependencies>
  
 300",NA
 Build and Test the Protocol Buffer Between ,NA,NA
Microservices,"Once your message structure is defined in a .proto file, you need a protoc compiler to 
 convert this language-neutral content to Java code. Follow the instructions in the 
 Protocol Buffer’s repository (
 https://github.com/google/protobuf
 ) in order to get an 
 appropriate compiler version. Alternatively, you can download a prebuilt binary 
 compiler from the Maven central repository by searching for the com.google. 
 protobuf:protoc artifact and then picking an appropriate version for your platform. 
  
 Next, you need to run the compiler, specifying the path to search for the .proto files, 
 the destination directory where you want the generated code to go, and the absolute 
 path to your .proto. In your case, it will look like:
  
 D:\Applns\Google\ProtocolBuffer\protoc-3.4.0-win32\bin\protoc --proto_path 
 .\src\main\resources --java_out .\src\main\java .\src\main\resources\ product.proto
  
  
 Because you want Java classes, you use the --java_out option; however, similar 
 options are provided for other supported languages.
  
 The above steps are handy, but they are not straightforward to weave into the 
 Maven build. That’s why you used the protoc-jar-maven-plugin in the pom.xml in Listing 
 10-16
 ; it performs protobuf code generation using the multiplatform executable protoc-
 jar. 
  
 Hence no manual steps are needed to build and run the samples. Let’s get started.
  
 The complete code required to demonstrate intermicroservices communication 
 using Protocol Buffer is kept inside folder ch10\ch10-02. You don’t need MongoDB for 
 this sample. You can build, pack, and run the different microservices in the following 
 order.
  
 Bring up the Product Server microservice first:
  
 cd ch10\ch10-02\ProductServer 
  
 D:\binil\gold\pack03\ch10\ch10-02\ProductServer>make 
  
 D:\binil\gold\pack03\ch10\ch10-02\ProductServer>rem D:\Applns\Google\ 
 ProtocolBuffer\protoc-3.4.0-win32\bin\protoc --proto_path .\src\main\ resources --
 java_out .\src\main\java .\src\main\resources\product.proto 
 D:\binil\gold\pack03\ch10\ch10-02\ProductServer>mvn -Dmaven.test.skip=true 
 clean package 
  
 D:\binil\gold\pack03\ch10\ch10-02\ProductServer>run 
  
 D:\binil\gold\pack03\ch10\ch10-02\ProductServer>java -jar -Dserver.
  
 port=8080 .\target\Ecom-Product-Microservice-0.0.1-SNAPSHOT.jar",NA
 The Impact of Using Protocol Buffer,"Let’s inspect the response content length while using Protocol Buffer for 
 intermicroservices communications. For this comparison, you will look at three 
 scenarios.",NA
 Protocol Buffer Encoding,"The sample demonstration in the previous section explained how to use Protocol Buffer 
 for intermicroservices communications. You can observe the TCPMon Proxy console 
 where you should be able to validate that the communication between the two 
 microservices uses Protocol Buffer. It will also say that the response content length is 
 265 (which is representative). See Figure 
 10-5
 .
  
 309",NA
 XML Encoding,"You can use Chrome and hit the TCPMon Proxy directly so that the client doesn’t 
 explicitly ask for Protocol Buffer during content negotiation using the URL http:// 
 localhost:8081/products/. This will show the response in XML format; see Figure 
 10- 
 6
 .
  
 310",NA
 JSON Encoding,"One easy method to force JSON encoding between the microservices call is to slightly 
 change the application code in the Product Server microservice. See Listing 
 10-22
 .
  
 Listing 10-22. 
 Enforce JSON Encoding (ch10\ch10-02\ProductServer\src\main\ 
 java\com\acme\ecom\product\controller\ProductRestController.java)
  
 @RequestMapping(value = ""/products"", method = RequestMethod.GET,
  
  
 produces = {MediaType.APPLICATION_JSON_VALUE}) 
  
 //@RequestMapping(value = ""/products"", method = RequestMethod.GET) 
 public  Products getAllProducts() {
  
 312",NA
 Summary,"Microservices are like double-edged swords: they provide extra leverage but should 
 be used with care. This is mainly due to the Inversion of Architecture discussed in 
 Chapter 
 4
 . You learned two refactoring processes you can bring to your 
 microservices architecture to influence the performance to a greater extent. There 
 are more optimizations; however, I will limit them to the two discussed in this 
 chapter. A major chunk of the rest of the book will talk about event-based 
 microservices where the asynchronous nature of intermicroservices communications 
 is leveraged by default using messaging instead of HTTP. You’ll start getting into 
 those aspects in the next chapter.
  
 314",NA
CHAPTER 11,NA,NA
"Events, Eventuality, ",NA,NA
and Consistency,"A handshake with one of your colleagues provides you back the same feeling of the 
 handshake, instantaneously. Similar is the case of a hug or a kiss with your partner—
 you also receive the same back, instantaneously (assuming your partner’s mood doesn’t 
 invite a slap as response!). What if your partner in any of the above described contexts is 
 not near you but you still want to pass similar greetings to him or her? You can send an 
 email or a message through any kind of digital media available today. Your partner will 
 (sooner or later) receive your message and will be able to respond to you. The end effect 
 is that, even though your partner is not nearby or even listening to you at the exact time 
 you initiate your gesture, you will sooner or later get the response gesture back. These 
 scenarios and gestures are typical of a microservices application too. Once you have 
 split your application into microservices based on domain boundaries, which can be 
 deployed, brought up, and operated on their own, independent of other microservices, it 
 also means that those microservices should have the capability to continue providing 
 functionality irrespective of their counterpart microservices. This is where the 
  
 importance of event-driven architecture (EDA) must be discussed. You will look into 
 EDA in general plus a selected few concerns in this chapter. At the end, you will be in a 
 position to appreciate events and EDA, and you’ll be better equipped to decide whether 
 you want asynchronous events or synchronous request/response-style interactions 
 between microservices.
  
 You will learn the following in this chapter:
  
 • 
  
 Introduction to EDA
  
 315
  
 • 
  
 Different styles of EDA
  
 • 
  
 Relevance of EDA in the evolution of a microservices architecture
  
 © Binildas Christudas 2019 
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_11",NA
 Event-Driven Architecture,"Event-driven architecture is a software architecture pattern promoting the production, 
 detection, consumption, and reaction to events. An event-driven system typically 
 consists of event emitters (or agents), event consumers (or sinks), and event channels 
 through which the events propagate. Let’s look into these components in detail.",NA
 Events,"An event is an occurrence or a happening within a particular system or domain; it is 
 something that has occurred or is contemplated as having occurred in that domain.
  
 An event can be defined as a change in state. For example, when an order is shipped, 
 the order's state changes from “pending” to “shipped.” An e-commerce microservices 
 architecture may treat this state change as an event whose occurrence can be made 
 known to other microservices within the architecture or for that matter even to other 
 components outside the microservices boundary. From a formal perspective, what is 
 produced, published, propagated, detected, or consumed is a (typically asynchronous) 
 message called the event notification, and not the event itself. If so, the event is the state 
 change that triggered the message emission. Events do not travel; they just occur. 
 However, the terms “event” and “event notifications” are often used interchangeably to 
 denote the notification message itself.",NA
 EDA Components,"An EDA-based application typically consists of event emitters (source or agents), event 
 consumers (sinks), and event channels. Event emitters have the responsibility to 
 generate, detect, gather, and transfer events. When an event emitter does so, it doesn’t 
 know the consumers of the event, it doesn’t even know if any consumer exists, and if it 
  
 316",NA
 Microservices and Event-Driven ,NA,NA
Architecture,"Having talked about the point-to-point and publish-subscribe patterns of EDA, let’s now 
 look into some concerns you will face when designing microservices in the flexible, 
 publish-subscribe pattern.",NA
 Evolution of Microservices,"Most of the software applications are built with a set of requirements in mind to start 
 with, and then have a natural evolution over a period of a few years. Incorporating 
 change requests and new requirements will happen over the years until the application 
 is finally retired. Traditional or monolith applications are changed at the source code 
 level to accommodate these changes and then the entire application has to be regression 
 tested, performance validated, and redeployed. There will be inevitable downtime, also.
  
  
 Figure 
 11-4
  shows an e-commerce application that uses the publish-subscribe 
 microservices pattern.
  
 319",NA
 Eventual Consistency and Microservices,"Let’s now explore the interesting intricacies of microservices. Monolithic applications 
 typically use a single relational database. A key benefit of using a relational database 
 is that your application can leverage ACID transactions. Figure 
 11-7
  depicts a typical 
 monolithic application.
  
  
 Figure 11-7. 
 An e-commerce monolith application
  
 323",NA
 Microservices and the CAP Theorem,"This discussion leads to another interesting constraint in distributed computing 
 postulated as the CAP Theorem, which you will look in the context of microservices in 
 this section.
  
 326",NA
 The Scale Cube,"Highly transactional systems have to serve millions of requests per unit of time and the 
 transactions per second (TPS) in such systems is high. This is particularly true when we 
 talk about web scale architectures. By increasing the compute power of nodes serving 
 the requests, we can increase throughput; this is called vertical scaling. However, there is 
 a limit beyond which an increase in compute will not yield proportionately in the same 
 node, and this is shown in Figure 
 11-9
 .
  
  
 Figure 11-9. 
 Vertical scaling
  
 Further increase in throughput can be attained by horizontal scaling techniques. 
 Here, operating software at web scale requires distributing many copies of the software 
 runtime. This also means there are many copies of the data sets distributed across many 
 nodes.
  
 327",NA
 The CAP Theorem,"The CAP Theorem describes the three architectural properties that are linked together 
 with mutual dependencies as
  
 • Consistency
  
 • Availability
  
 • Partition tolerance
  
 The theorem states that you can guarantee any two of the three properties. If you 
 add or increase one of these properties, you do it by taking away from one (or both) of 
 the others. In other words, you can have a highly available, consistent system but its 
 partitionability will be low, or you can have a highly available and partitionable system 
 but you would likely need to give up on consistency.
  
 Figure 
 11-11
  depicts the CAP Theorem pictorially. It says, you can pick any two from 
 the list of C, A, and P, but you can’t achieve all three at the same time. Let’s understand 
 better what that means. First, let’s look at the definition of C, A, and P in the CAP 
 Theorem.
  
 329",NA
" BASE (Basically Available, Soft State, ",NA,NA
Eventually Consistent) Systems,"Having touched upon the CAP Theorem and assuming that you are well versed with the 
 familiar and perfectly consistent ACID transactions, let’s look at the BASE alternative to 
 ACID. BASE is the acronym for Basically Available, Soft state, Eventually consistent, 
 which is diametrically opposed to the ACID principles. While ACID is based on 
 pessimistic assumptions and forces consistency at the end of every operation, BASE is 
 based on optimistic assumptions and accepts that the database consistency will be in a 
 state of flux to a level acceptable to the business transaction in consideration. BASE 
 design encourages designing systems in such a way that
  
 • If a portion of the application is down or not functioning properly, a 
 few other functionalities of the application should still work, or
  
 • If a few nodes’ failure of the customer database impacts only the 30 
 percent of the customers on that particular host, the rest of the 
 customers should still be able to use the system.
  
 • Etc.
  
  
 All or most of the above characteristics can be realistically met if you define a set of 
 properties for coordination of systems or services as follows:
  
 • A system is basically available when supporting partial failures, 
 which may be appreciated than total system failure.
  
 • The state of the system is “soft” in that it can change over time even 
 in cases where no further updates are made, because some of the past 
 changes are yet to be applied since they are “still on the fly”, originated 
 from other partitions.
  
 • The system will eventually become consistent if no more new updates 
 are made to the system.
  
 332",NA
 CAP Pyramid,"The CAP Pyramid is an inverted tetrahedron
 4
  pivoted on its vertex with the opposite face 
 (base) kept parallel to the pivoted plane (ground), as shown in Figure 
 11-12
 .
  
  
 Figure 11-12. 
 The CAP Pyramid in unstable equillibrium
  
  
 If we assume the height from the pivot plane of each corner of the top face of the CAP 
 Pyramid representing consistency, availability, and partition tolerance, you will always 
 have a balance between these three characteristics in the equilibrium state, which is a 
 BASE state. At the BASE state, all of the three characteristics are not too low or not too 
 high; instead, they are at a nominal level to keep the CAP Pyramid in an unstable 
 equilibrium.
 5 
  
  
 The CAP Theorem says you can pick any two from the list of consistency, availability, 
 and partition tolerance, but you can’t achieve all three at the same time.
  
 4
  A tetrahedron is a four-sided pyramid (base plus three sides). The tetrahedron has the 
 extra interesting property of having all four triangular sides congruent. The base is a 
 triangle (any of the four faces can be considered the base), so a tetrahedron is also known as 
 a “triangular pyramid.” An Egyptian pyramid has a square base and four triangular sides.
  
 5
  Unstable equilibrium is a state of equilibrium of a body (as a pendulum standing directly 
 upward from its point of support) such that when the body is slightly displaced, it departs 
 further from the original position.
  
 333",NA
 Summary,"Architecture is all about trade-offs, and judicious trade-offs are of increased importance 
 in microservices architecture. You saw the Inversion of Architecture in the context of 
 microservices in Chapter 
 4
 , which has increased the outer architecture complexities to 
 an exponential level. This has made networks inevitable, so techniques to attain partition 
 tolerance must be built into the architecture by design, not as an afterthought. 
  
 The amount of partition tolerance will influence the application’s availability and 
 consistency, and deciding the balance between these three characteristics is key in 
 architecting microservices applications. In Chapter 
 5
 , you separated out the Command 
 and Query parts of the application in the CQRS pattern, and this is a fine example of 
 introducing partitions in the architecture. It’s now time to look at some code in action to 
 explain many of these concepts so turn to Chapter 
 12
 .
  
 335",NA
CHAPTER 12,NA,NA
Axon for CQRS ,NA,NA
Architecture,"In Chapter 
 11
 , you learned about events and event-driven architecture, and you also 
 looked into the theorems and constraints within which any EDA-based application can 
 operate. Microservices architecture inherently bring partitions, hence concrete 
 mechanisms to attain partition tolerance are of great importance. You will do that in this 
 chapter with the help of Axon. Axon is a lightweight framework that will help you 
 develop applications following the CQRS pattern. The Axon framework is licensed under 
 the Apache 2 license so you can use the framework in any application for free. However, 
 if you need professional services around Axon, they are provided by AxonIQ B.V., which 
 is based in Amsterdam.
  
 Axon is not mandatory to build CQRS-based systems, nor is a CQRS pattern 
 mandatory to build systems using Axon. However, any new framework is an additional 
 layer of debt in your application stack, so one of the primary reasons for you to use Axon 
 in your application would be your urge to follow the CQRS pattern in building 
 applications. Again, CQRS is not a mandatory prerequisite for you to architect 
  
 microservices; however, CQRS provides leverage to address distributed enterprise 
 software system concerns about scalability, so Axon and microservices go hand in hand.
  
 You went into enough depth on Spring Boot and Spring Cloud in Chapter 
 7
  and 
 Chapter 
 8
 , and you will be leveraging both extensively while using Axon in this chapter. 
 This marriage of CQRS with Spring Cloud will arm you with the combination of the most 
 powerful tools from both worlds.
  
 You will do the following in this chapter:
  
 • 
  
 Meet Axon, the Java CQRS framework
  
 337
  
 • 
  
 Understand the building blocks of Axon
  
 • 
  
 Build and run an introductory CQRS example
  
 • 
  
 Build and run a fully distributed CQRS microservices example",NA
" Introducing Axon, the CQRS Framework","There are quite a few frameworks that allow you to architect CQRS-based solutions in 
 the open source community and in the commercial world, both in Java and the .NET 
 platforms. I picked Axon due to its free nature of the open source license and its 
 integration options with other mainstream languages and platforms, including Java and 
 Spring.
  
 In this chapter, you will look at working examples using both Axon and Spring Boot. 
  
 As I introduce the examples, I will also cover the essential concepts and APIs. You are 
 advised to refer to the Axon documentation for detailed coverage on the usage of the 
 framework since I will not attempt to duplicate the Axon documentation here. Instead, 
 I will walk you through the core concepts with examples so that you are geared up to 
 speed quickly.
  
 You will be using two different versions of Axon for these examples. You will first use 
 Axon 2.4.1. Here, you require explicit wiring of components, either through annotations 
 or using XML configurations. Moreover, the Axon 2.4.1 example will leverage the 
 1.3.5.RELEASE version of Spring Boot. Later in the book, you will also look at examples in 
 Axon 3.0.5 where you use the Spring Boot 1.5.3.RELEASE version. In Axon 3.0.5, a lot of 
 explicit wiring can be avoided since Axon uses the Spring Application Context to locate 
 specific implementations of building blocks and provides a default for those that are not 
 there. Even though this will make life easier for the developer, if you are not an 
 experienced Axon developer, you may not be able to appreciate what is happening under 
 the hood. In Axon 2.4.1, much of this wiring is explicit and thus visible in code as 
 annotations or in configurations as XML, so you can get a better understanding what is 
 happening in the underlying layers. For that reason, you will use the previous (2.4.1) 
 version
 1
  of Axon for the examples to start with. However, I will give you an easy 
 roadmap for later Axon versions
 2
  by providing the same examples in those versions too.",NA
 What Is Axon?,"The Axon framework helps developers apply the CQRS architectural pattern and build 
 modular, SOA-based solutions. Traditional SOA architecture addresses some 
 mainstream concerns in software architectures; however, Axon fills the gap that has 
 been found in the experience while using SOA over the last two decades. 
  
 1
  Axon framework 2.4 Reference guide: 
 www.axonframework.org/docs/2.4/ 
 2
  Axon framework 2.4 API Documentation: 
 https://axoniq.io/apidocs/2.4/
  
 338",NA
 Where Can You Use Axon?,"Axon is free and open source, and has the tag line of 
 The Jargon CQRS
  (which many of 
 your peers are still searching the Internet to understand what it means), which is quite 
 enough to maintain the attention of executive management for a long time, so why not 
 use it in every new application you build? Unfortunately, CQRS is not simple and 
 straightforward compared to traditional one-to-one and synchronous architecture 
 styles. Conceiving future complexities to an extent at the start of architecture design is 
 required; further your design has to accommodate and evolve more combinations of 
 scenarios, states, and flows compared to traditional SOA or for that matter even 
 compared to microservices without CQRS. However, if you understand this and if you 
 attempt it, the effort will be paid back in more than one way. Here are some scenarios 
 where CQRS makes more sense:
  
 • 
 Extensible architectures
 : Typical applications are built with a span of 
 life in mind, say 10, 20, or even 50 years (if you still program in assembly 
 or mainframe); however, during this span many of these applications are 
 likely to be extended with more functionality. It’s the same story for 
 applications built today, getting deployed to clouds and containers. 
 However, business continuity is paramount, and extensions both in 
 terms of functionality and quality of system (QoS) have to be effected 
 with zero disruption to running systems. Can you do this? Is this 
 expectation realistic or still a myth? Well, the answer depends not on the 
 technologies and frameworks available alone. You need to combine them 
 with your architectural thoughts too, put aside all other advancements in 
 DevOps, etc.
  
 339",NA
 What You Need to Run Axon,"The Axon framework has been built and tested against Java 6, making that more or less 
 the only requirement. You can use Gradle or Maven for the build and also use any IDE of 
 your choice. Since Axon doesn’t create any connections or threads by itself, it is safe to 
 run on an application server. Axon abstracts all asynchronous behavior by using 
 executors, which decouple task submission from the mechanics of how each task will be 
 run. So you can even easily pass a container-managed thread pool, for example. If you 
 don’t use an application server (e.g. Tomcat, Jetty, or a stand-alone app), you can use the 
 Executors class or the Spring Framework to create and configure thread pools.
  
 You will now look at some concrete examples and see Axon code in action.",NA
 Command and Event Handling in the Same ,NA,NA
JVM,"Simple things first, so let’s keep the first example in Axon simple. However, I can’t 
 make it simpler. To introduce Axon, you must first understand a simple scenario in the 
 Axon way and then look at the details of what each of the steps mean in Axon.",NA
 The Sample Scenario,"The first Axon example is a single microservice from an e-commerce application. There 
 are two entities in the domain, order and product. Users can buy a product, which will 
 create a new order. When a new order is created, the product stock will get depreciated. 
 Just that. Figure 
 12-1
  depicts the architecture with the complete flow labelled.
  
 342",NA
 Code the Sample Scenario,"All the code examples for this section are in folder ch12\ch12-01. Visit pom.xml to see 
 the explicit mention of the Axon dependency. See Listing 
 12-1
 .
  
 Listing 12-1. 
 Axon Maven Dependency (ch12\ch12-01\Ax2-Commands-Events-
 Same-JVM\pom.xml)
  
 <dependency>
  
  
  <groupId>org.axonframework</groupId>
  
  <artifactId>axon-core</artifactId>
  
  
 <version>2.4.1</version> 
  
 </dependency>
  
  
 This first Axon example is a first class Spring Boot citizen, hence there is nothing 
 special in the main application class; still you can look at the code in Listing 
 12-2
 .
  
 Listing 12-2. 
 Spring Boot Application Class (ch12\ch12-01\Ax2-Commands- 
 Events-Same-JVM\src\main\java\com\acme\ecom\EcomApplication.java)
  
 @SpringBootApplication 
  
 public class EcomApplication {
  
  public static void main(String[] args) {
  
  
  
  SpringApplication.run(EcomApplication.class, args);
  
  } 
  
 }
  
  
 Next is the most important class of this example where you do the setup of all Axon 
 components; see Listing 
 12-3
 .
  
 345",NA
 Build and Test the Example Scenario,"The complete code required to demonstrate this simple Axon example is in folder ch12\ 
 ch12-01. First, update the configuration files to suit to your environment:
  
 ch12\ch12-01\Ax2-Commands-Events-Same-JVM\src\main\resources\application.
  
 properties 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
  
 Make sure MySQL is up and running. You may want to refer to Appendix H to get 
 started with MySQL.
  
 First Bring Up MySQL Server.
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysqld --console
  
 Now Open MySQL prompt 
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysql -u root –p
  
 mysql> use ecom01; 
  
 Database changed 
  
 mysql>
  
  
 To start with clean tables, delete any tables with the names you want for 
 your examples:
  
 mysql> drop table ecom_order; 
  
 mysql> drop table ecom_product; 
  
 mysql> drop table ecom_order_view; 
  
 mysql> drop table ecom_product_view;
  
  
 Now, the ecom_order and ecom_product tables will be created when the 
 microservice starts up. However, you need to explicitly create the Read DB 
 tables:
  
 mysql> create table ecom_product_view(id INT , price DOUBLE, stock INT 
 ,description VARCHAR(255)); 
  
 mysql> create table ecom_order_view(id INT , price DOUBLE, number INT 
 ,description VARCHAR(225),status VARCHAR(50));
  
 357",NA
 Distributed Command and Event Handling,"Enterprise-grade applications distribute processing into multiple compute nodes and 
 multiple processes to leverage the full power of multicore processors as well as to 
 attain maximum parallelism so as to improve overall performance. The microservices 
 architecture is no exception, and in this example you are going to completely distribute 
 the different Axon components across JVMs. Since the example is distributed across 
 processes, you can practically distribute them across nodes too; however, you will 
 execute the examples with each main Axon components in a single node (my personal 
 laptop, in my case) for simplicity.
  
 360",NA
 The Example Scenario,"You are using the same scenario as in the previous section. While the previous example 
 was implemented as a single microservice, you will split the same functionality into four 
 different microservices in this example and you will additionally introduce another 
 microservice too. This new, fifth microservice is the Event Handler Audit microservice. 
 The Event Handler Audit microservice has an event handler, AuditEventHandler, which 
 too is subscribed to the order created event. So, you now have two microservices (the 
 Event Handler Audit microservice and the Event Handle Core microservice) with two 
 event handler types, both interested in the same order created event! Figure 
 12-4
  shows 
 the design.
  
 361",NA
 Code the Example Scenario,"The complete code required to demonstrate the simple Axon example is in folder 
 ch12\ch12-02. There are five microservices to be coded, and you will look into them one 
 by one.",NA
 Microservice 1: 01-Ecom-web,"This microservice is a typical Spring Boot web application without any Axon 
 components, so I will not discuss it.
  
 364",NA
 Microservice 2: 02-Ecom-,NA,NA
CreateCommandRestController,"Visit pom.xml to see the axon-distributed-commandbus dependency; see Listing 
 12-13
 .
  
 Listing 12-13. 
 Axon Distributed Command Bus Maven Dependency (ch12\ 
 ch12-02\Ax2-Commands-Multi-Event-Handler-Distributed\02-Ecom- 
 CreateCommandRestController\pom.xml)
  
 <dependency>
  
  
  <groupId>org.axonframework</groupId>
  
  
  <artifactId>axon-distributed-commandbus</artifactId>
  
  
 <version>2.4.1</version> 
  
 </dependency>
  
 A major part of the code for this example is similar to the previous example, so I will 
 not repeat it here; instead, I will explain all new code as well as any changes to the code 
 from the previous example. The most important class of this example is where you do 
 the setup of all the distributed Axon components, shown in Listing 
 12-14
 .
  
 Listing 12-14. 
 Distributed Command Bus Configuration (ch12\ ch12-
 02\Ax2-Commands-Multi-Event-Handler-Distributed\02-Ecom- 
 CreateCommandRestController\src\main\java\com\acme\ecom\ 
 EcomAppConfiguration.java)
  
 @Configuration 
  
 public class EcomAppConfiguration {
  
  @Bean
  
  public XStreamSerializer xstreamSerializer() {
  
  
 return new XStreamSerializer();
  
  }
  
  @Bean
  
  @Qualifier(""distributedCommandGateway"")
  
  public CommandGatewayFactoryBean<CommandGateway>
  
  
  
  commandGatewayFactoryBean() {
  
  
  CommandGatewayFactoryBean<CommandGateway> factory 
 =
  
  
  new CommandGatewayFactoryBean<>();
  
 365",NA
 Microservice 3: 03-Ecom-,NA,NA
HandleCommandAndCreateEvent,"This microservice has to handle any commands created by the 02-Ecom- Create 
 CommandRestController microservice and reaching through the 
 DistributedCommandBus from the remote JVM. Further, this microservice also creates 
 events that are supposed to be consumed by distributed event handlers in remote JVMs 
 or foreign microservices. 
  
 Hence the configuration of this microservice is going to be little complex in order to 
 accommodate all those connectors and routings.
  
 Visit EcomAppConfiguration.java to see the main configuration, shown in Listing 
 12-
 15
 .
  
 Listing 12-15. 
 Distributed Command Bus Configuration (Visit ch12\ 
 ch12-02\Ax2-Commands-Multi-Event-Handler-Distributed\03- Ecom- 
 HandleCommandAndCreateEvent\src\main\java\com\acme\ecom\ 
 EcomAppConfiguration.java)
  
 @Configuration 
  
 public class EcomAppConfiguration {
  
  @PersistenceContext
  
  private EntityManager entityManager;
  
  @Qualifier(""transactionManager"")
  
  @Autowired
  
  protected PlatformTransactionManager txManager;
  
  @Bean
  
  @Qualifier(""distributedCommandGateway"")
  
  public 
 CommandGatewayFactoryBean<CommandGateway>
  
  
 commandGatewayFactoryBean() {
  
  
  CommandGatewayFactoryBean<CommandGateway> factory 
 =
  
  
  new CommandGatewayFactoryBean<>();
  
  
  factory.setCommandBus(distributedCommandBus());
  
  
 return factory;
  
  }
  
  @Bean
  
  @Qualifier(""localCommandGateway"")",NA
 Microservice 4: 04-Ecom-EventHandleCore,"Again, if you have followed the previous example, there is nothing new in this 
  
 microservice, so I will not do a code walkthrough. As the name of the microservice hints, 
 it contains the two main event handlers, OrderEventHandler and ProductEventHandler, 
 and the functionality and code snippets are similar to those in the previous example.
  
 374",NA
 Microservice 5: 05-Ecom-EventHandlerAudit,"This is a new microservice. The intention is to demonstrate the extensibility of the Axon-
 based CQRS architecture where, in the future if you have a new functionality that wants 
 to subscribe to existing events and add to the existing overall functionality of the 
 application, you should be able to do that without any downtime of the existing running 
 application.
  
  
 Listing 
 12-17
  shows the code for the newly added event handler, which is 
 expecting to be notified of the previously handled event itself.
  
 Listing 12-17. 
 Event Handler for the newly introduced Microservice 
 (ch12\ch12-02\ Ax2-Commands-Multi-Event-Handler-Distributed\05-Ecom- 
 EventHandlerAudit\ 
 src\main\java\com\acme\ecom\order\eventhandler\AuditEventHandler.java)
  
 @Component 
  
 public class AuditEventHandler {
  
  @Autowired
  
  DataSource dataSource;
  
  @EventHandler
  
  public void handleOrderCreatedEvent(OrderCreatedEvent event) {
  
  
  
  JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource);
  
  
  
  jdbcTemplate.update(""INSERT INTO ecom_order_audit VALUES(?,?,?)"",
  
  
  
  new Object[]{event.getId(),
  
  
  
  event.getOrderStatus(), new Date()});
  
  
  } 
  
 }",NA
 Build and Test the Example Scenario,"As the first step, you need to bring up the RabbitMQ server. You may want to refer 
 to Appendix B to get started with RabbitMQ server.
  
  D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>D:\Applns\RabbitMQ\rabbitmq_ 
 server- 3.6.3\sbin\rabbitmq-server.bat
  
 375",NA
 Microservice 1: 01-Ecom-web,"First, update the configuration files to suit to your environment:
  
 ch12\ch12-02\Ax2-Commands-Multi-Event-Handler-Distributed\01-Ecom-web\src\ 
 main\resources\application.properties 
  
 server.port=8080
  
 376",NA
 Microservice 2: 02-Ecom-,NA,NA
CreateCommandRestController,"The JGroups configuration is provided at ch12\ch12-02\Ax2-Commands-Multi-Event-
 Handler- Distributed\02-Ecom-CreateCommandRestController\src\main\resources\ 
 udp_config.xml.
  
 However, don’t worry about the contents of this file too much for now.
  
 Update the configuration files to suit to your environment:
  
 ch12\ch12-02\Ax2-Commands-Multi-Event-Handler-Distributed\02-Ecom- 
 CreateCommandRestController\src\main\resources\application.properties 
 server.port=8081 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
  
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 377",NA
 Microservice 3: 03-Ecom-,NA,NA
HandleCommandAndCreateEvent,"Update the configuration files to suit to your environment:
  
 ch12\ch12-02\Ax2-Commands-Multi-Event-Handler-Distributed\03-Ecom- 
 HandleCommandAndCreateEvent\src\main\resources\application.properties 
 server.port=8082 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
  
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 ecom.amqp.rabbit.address= 127.0.0.1:5672 
 ecom.amqp.rabbit.username= guest 
  
 ecom.amqp.rabbit.password= guest 
  
 ecom.amqp.rabbit.vhost=/ 
  
 ecom.amqp.rabbit.exchange=Ecom-02 
  
 ecom.amqp.rabbit.queue=Ecom-createcommand
  
 378",NA
 Microservice 4: 04-Ecom-EventHandleCore,"Update the configuration files to suit to your environment:
  
 ch12\ch12-02\Ax2-Commands-Multi-Event-Handler-Distributed\04-Ecom- 
 EventHandleCore\src\main\resources\application.properties 
  
 server.port=8083 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
  
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 ecom.amqp.rabbit.address= 127.0.0.1:5672 
 ecom.amqp.rabbit.username= guest 
  
 ecom.amqp.rabbit.password= guest 
  
 ecom.amqp.rabbit.vhost=/ 
  
 ecom.amqp.rabbit.exchange=Ecom-02 
  
 ecom.amqp.rabbit.queue=Ecom-event-core
  
 379",NA
 Microservice 5: 05-Ecom-EventHandlerAudit,"This is the last microservice you want to bring up in this example. Update the 
 configuration files to suit to your environment:
  
 ch12\ch12-02\Ax2-Commands-Multi-Event-Handler-Distributed\05-Ecom- 
 EventHandlerAudit\src\main\resources\application.properties 
  
 server.port=8084 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
  
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 ecom.amqp.rabbit.address= 127.0.0.1:5672 
 ecom.amqp.rabbit.username= guest 
  
 ecom.amqp.rabbit.password= guest 
  
 ecom.amqp.rabbit.vhost=/ 
  
 ecom.amqp.rabbit.exchange=Ecom-02 
  
 ecom.amqp.rabbit.queue=Ecom-event-history
  
 380",NA
 Summary,"You have reached a major milestone in this book by executing the examples in this 
 chapter, since they are live code in action and they explain many of the concepts 
 discussed in this book so far. You saw what a CQRS application will look like in the 
 familiar Spring Boot framework, and you also saw how to distribute one into multiple 
 microservices, also communicating with other using events over a messaging 
  
 middleware. So far, so good; however, you have now invited “Satan”
 3
  into your 
  
 architecture: the partition. By bringing the capability to partition your single JVM CQRS 
 application in the first example into multiple microservices in the second example, you 
 now need to address the consistency aspects you explored via the CAP theorem in 
 Chapter 
 11
 . To discuss that in detail further, you should first know the foundations of 
 consistency in the context of microservices, so move on to Chapter 
 13
 .
  
 3
  Satan is the name used by Christians and Jews for the Devil (= a powerful evil force and the 
 enemy of God).
  
 383",NA
CHAPTER 13,NA,NA
Distributed ,NA,NA
Transactions,"You looked at using the Axon framework to implement different scenarios of the CQRS 
 pattern in the previous chapter. In this chapter, you will be revisiting Axon for more 
 scenarios in the microservices context, including executing long-running computational 
 processing. To do that effectively, let’s start the discussion with a few basics, including 
 transactions. A transaction in its simple form is a change or exchange of values between 
 entities. The parties involved can be a single entity or more than one entity. When the 
 party involved is a single entity, typically the transaction is a local transaction. If more 
 than one party is involved, the transaction can be classified as either a local transaction 
 or a distributed transaction, depending on the nature and location of the entities 
 involved.
  
 A transaction may involve a single step or multiple steps. Whether a single step or 
 multiple steps, a transaction is a single unit of work that embodies these individual 
 steps. 
  
 For the successful completion of a transaction, each of the involved individual steps 
 should succeed. If any of the individual steps fail, the transaction should undo any of the 
 effects of the other steps it has already done within that transaction.
  
 With this preface, you will look into the details of transactions, especially distributed 
 transactions. I will only touch base on the essentials of transactions; I’ll spend more time 
 on the practical implication aspects, especially in the context of microservices. 
  
 Detailing out transactions to any more depth would require its own complete book, so 
 this coverage will be limited to discussions around microservices and few practical tools 
 you can use to build reliable microservices.
  
 In this chapter you will learn about
  
 • 
  
 The indeterministic characteristics of computer networks
  
 385
  
 • 
  
 Transaction aspects in general",NA
 The Two Generals Paradox,"In computer networking (particularly with regard to the Transmission Control 
 Protocol), literature shows that TCP can't guarantee (complete) state consistency 
 between endpoints. This is illustrated by the Two Generals Paradox (also known as the 
 Two Generals Problem or the Two Armies Problem or the Coordinated Attack Problem), 
 which is a thought experiment illustrating the pitfalls and connected design challenges 
 while attempting to coordinate an action by communicating over an unreliable link.
  
 The Two Generals Paradox is unsolvable in the face of arbitrary communication 
 failures; however, the same problem provides a base for realistic expectations for any 
 distributed consistency protocols. So to understand the problem, you need to 
 understand the associated indeterminism involved, which will provide a perfect analogy 
 to learn more about transactions.",NA
 Illustrating the Two Generals Paradox,"This section will illustrate the Two Generals Paradox with the classical example 
 scenario. Figure 
 13-1
  shows two armies, each led by a different general who are jointly 
 preparing to attack a fortified city, shown in the center. Both armies are encamped near 
 the city, but in their own valleys. A third valley separates the two hills of the valleys 
 occupied by the two generals, and the only way for the two generals to communicate is 
 by sending messengers across the third valley. The third valley is occupied by the city's 
 defenders, so there's a chance that any messenger sent through the valley may be 
 captured.
  
 386",NA
 Solution Approaches,"Computer networks are the spine of distributed systems; however, the reliability of any 
 network has to be examined. Distributed systems are required to address scalability and 
 flexibility of software systems, so a network is a necessary evil. Schemes should accept 
 the uncertainty of the networks and not attempt to eliminate it; rather, they should 
 mitigate it to an acceptable degree.
  
  
 In the Two Generals Paradox, you can think of many acceptable mechanisms, 
 such as
  
 • The first general can send 50 messengers, anticipating that the 
 probability of all 50 being captured is low. This general will have fixed the 
 time of attack to include enough time for all or a few or many of those 50 
 messengers to reach the other general. He will then attack at the 
 communicated time no matter what, and the second general will also 
 attack if any of the messages are received.
  
 387",NA
 Microservices as Generals,"When you have split the state of a monolith that has been “living happily thereafter, 
 together” to the state of “living happily ever after, separated,” you have split the army 
 from one general into multiple generals. Each microservice has their own general or is a 
 general by itself, and more than one general may be required to coordinate any useful 
 functionality. By adopting polyglot, each microservice will have its own resource, 
 whether it’s a database or file storage. The network is the only way these microservices 
 can coordinate and communicate. The effect of changes made to resources cross- 
 microservices has to be made consistent. This consistency depends on which schema or 
 protocol you choose to coordinate and communicate the commands to make changes 
 and the acknowledgements, which act as the agreement to effect that change between 
 microservices.",NA
" TCP/IP, the Valley Between the Generals","The Internet Protocol (IP) is not reliable. It may be delayed or dropped or duplicate data 
 can come or data can come in order not as per the original intention. The Transmission 
 Control Protocol adds a more reliable layer over IP. TCP can retransmit missing packets, 
 eliminate duplicates, and assemble packets in the order in which the sender intended to 
 transmit. However, while TCP can hide packet loss, duplication, 
  
 388",NA
 Transactions,"Transactions help you control how access is given to the same data set, whether it is for 
 read or write purposes. Data in a changing state might be inconsistent, hence other 
 reads and writes should have to wait while the state transitions from “changing” to 
 either “committed” or “rolled back.” You will look at the details related to transactions 
 now.",NA
 Hardware Instruction Sets at the Core of ,NA,NA
Transactions,"For transactions at a single database node, atomicity is implemented at the storage level. 
 When a transaction commits, the database makes the transaction’s writes durable 
 (typically in a write-ahead log
 2
 ) and subsequently appends a commit record to the log 
 on disk. So, the controller of the disk drive handling that write takes a crucial role in 
 asserting that the write has happened.
  
 A transaction once committed cannot be undone. You cannot change your mind 
 and retroactively undo a transaction after it has been committed. This is because, once 
 data has been committed, it may become visible to other transactions and thus other 
 transactions may have already started relying on that data.",NA
 The ACID in the Transaction,"For a transaction to comply with the specification, it should exhibit the ACID (Atomicity, 
 Consistency, Isolation, and Durability) properties. Let’s look into them one by one.
  
 • 
 Atomicity:
  The outcome of a transaction, if it’s a commit, is that all of 
 the transaction’s writes are made durable as a single unit of work. If it’s 
 an abort, then all of the transaction’s writes are rolled back (i.e., undone 
 or discarded) as a single unit of work. If you go back to the previous 
 section where I described that it’s the single controller of one particular 
 disk drive that sits in the core and takes the commit or rollback decision, 
 you need to appreciate that whether it’s the write 
  
 2
  Write-ahead logging (WAL) is a family of techniques for providing atomicity and durability (two 
 of the ACID properties) in database systems. The changes are first recorded in the log, which 
 must be written to stable storage, before the changes are written to the database.",NA
 Transaction Models,"Transaction models refer to how the coordination of individual transactions under the 
 context of an enclosing transaction are structured. You will look at the major 
 transaction models here:
  
 • 
 Flat transactions:
  In a flat transaction, when one of the steps fails, the 
 entire transaction is rolled back. In a flat transaction, the transaction 
 completes each of its steps before going on to the next one. Each step 
 accesses corresponding resources sequentially. When the transaction 
 uses locks, it can only wait for one object at a time.
  
 • 
 Nested transactions:
  In a nested transaction, atomic transactions 
 are embedded in other transactions. The top-level transaction can 
 open subtransactions, and each subtransaction can open further 
 subtransactions, and this nesting can continue. The effect of an 
 individual embedded transaction will not affect the parent transaction. 
 When a parent aborts, all of its subtransactions are aborted. However, 
 when a subtransaction aborts, the parent can decide whether to abort 
 or not. In a nested transaction, a subtransaction can be another nested 
 transaction or a flat transaction.
  
 392",NA
 Transaction Attributes in EJB vs. Spring,"Both Spring and EJB give the user the freedom to choose from programmatic and 
 declarative transaction management. For programmatic transaction management, you 
 need to code against the JDBC and JTA APIs. With the declarative approach, you 
 externalize transaction control to configuration files. Also, you need to choose from the 
 available transaction attributes to get the required behavior. The EJB specification 
 defines six basic transaction attributes. Subsequently, Spring has counterparts for all six 
 transaction attributes. In fact, Spring has more:
  
 • 
 PROPAGATION_REQUIRED (REQUIRED in EJB):
  Supports a 
 current transaction; creates a new one if none exist.
  
 • 
 PROPAGATION_REQUIRES_NEW (REQUIRES_NEW in EJB): 
 Creates a new transaction; suspends the current transaction if one 
 exists.
  
 • 
 PROPAGATION_NOT_SUPPORTED (NOT_SUPPORTED in EJB): 
 Executes non-transactionally; suspends the current transaction if one 
 exists.
  
 • 
 PROPAGATION_SUPPORTS (SUPPORTS in EJB):
  Supports a 
 current transaction; executes non-transactionally if none exist.
  
 393",NA
 Transaction Isolation Mechanisms,"Transaction isolation refers to the protection of one transaction from the effects of 
 the other, when multiple concurrent transactions happen, often on the same data set. 
  
 Transaction managers rely on two mechanisms to achieve transaction isolation:
  
 • 
 Locking:
  Locking controls access to a transaction to a particular data 
 set. Read locks are non-exclusive and allow multiple transactions to read 
 data concurrently. However, write locks are exclusive locks and only a 
 single transaction is allowed to update data.
  
 • 
 Serialization:
  When multiple transactions happen concurrently, 
 serialization is a mechanism to guarantee that the effects are as if they 
 are executing sequentially, not concurrently. Locking is a means of 
 enforcing serialization.",NA
 Transaction Isolation Levels,"The types of serialization and locks used as well as the extent to which they are 
 affected determine the level of isolation that a transaction will execute under. Java 
 Enterprise Edition specifies the following types of isolation levels, as defined in the 
 java.sql.
  
 Connection interface:
  
 • 
 TRANSACTION_NONE:
  Indicates that transactions are not 
 supported.
  
 394",NA
 Transaction Concurrency,"When multiple concurrent transactions happen, often on the same data set, the effect 
 of one transaction from the effects of the other can be controlled via the level of 
 concurrency the application is willing to tolerate. The levels are the following:
  
 • 
 Dirty read:
  Dirty reads happen when a transaction reads data that 
 has been written by another transaction but has not yet been 
 committed by the other transaction.
  
 4
  A phantom read occurs when, in the course of a transaction, new rows are added or removed by 
 another transaction to the records being read.
  
 395",NA
 Transaction Isolation Control Methods,"Strict levels of transaction isolation may cause negative performance scenarios, and in 
 such cases there are two general approaches to locking:
  
 • 
 Optimistic locking:
  Optimistic locking takes a pragmatic approach and 
 encourages clients to be “optimistic” that data will not change while they 
 are using it and allows them to access same data 
  
 concurrently. If for any reason the transaction on behalf of any particular 
 client wants to update, the update is committed if and only if the data that 
 was originally provided to the client is the same as the current data in the 
 database. This approach is less ideal for hot-spot data because the 
 comparison will fail often.
  
 • 
 Pessimistic locking:
  Pessimistic locking may use semaphore
 5
  or any of 
 the transaction mechanisms previously discussed. For every read, you 
 need a read lock, and for every write, you need a write lock. Read locks 
 are not exclusive whereas write locks are. A typical read lock may be 
 obtained when you query similar to
  
 SELECT ∗ FROM QUOTES_TABLE WHERE QUOTES_ID=5 FOR UPDATE;
  
 5
  A semaphore is a variable or abstract data type used to control access to a common resource 
 by multiple processes in a concurrent system such as a multitasking operating system. A 
 trivial semaphore is a plain variable that is changed (for example, incremented, decremented, 
 or toggled) depending on programmer-defined conditions.
  
 396",NA
 Enterprise Transaction Categories,"Transactions have different connotations depending on the context in which we use 
 them. It can be in the context of multiple operations within a monolith system, or in the 
 context of multiple monoliths or multiple microservices, or in the context of multiple 
 enterprises with common (or conflicting) interests. You will briefly look at the different 
 transaction categories in this context.",NA
 ACID Transactions,"ACID transactions are related to atomic transactions where multiple steps or operations 
 are executed with the intent that either all of them succeed together or all of them 
 return back to the previous state due to the failure of one or more of the steps. A major 
 portion of the discussion in previous sections of this chapter concerned ACID 
 transactions, so enough explanation has already been done. You will now look at the 
 architecture of an ACID transaction processing (TP) system. Figure 
 13-2
  depicts a 
 typical architecture consisting of multiple resource managers.
  
 397",NA
 BASE = ACID in Slices,"ACID is the only style that can guarantee data consistency. However, if a distributed 
 system uses ACID transactions, everything has to happen in lockstep mode, everywhere. 
  
 This requires all components to be available and it also increases the lock times on the 
 data. BASE is an architectural style that relaxes these requirements, simply by cutting 
 the (overall, ideal) ACID transaction into smaller pieces, each of them still ACID in 
 themselves.
  
 Messaging is used to make changes ripple through the system, where each change is 
 ideally processed by an ACID transaction. The messages are asynchronous rather than 
 synchronous, meaning that there is a delay between the first and last ACID transaction in 
 a BASE system.
  
 This is why this style exhibits “eventual consistency:” one has to wait for all 
  
 messages to ripple through the system and be applied where appropriate. The “Eventual 
 Consistency of Microservices” section in Chapter 
 11
  discussed this in detail.
  
  
 I’ll now introduce BASE in various incremental steps, by cutting more and more into 
 the ACID transaction scope.
  
 398",NA
 BASE Transactions,"Figure 
 13-3
  shows a BASE architecture with four different microservices. Each 
 microservice still has ACID properties (independent of the other microservices of the 
 system).
  
  
 Figure 13-3. 
 BASE architecture where each microservice still has ACID guarantees 
 by means of XA transactions
  
 This is the architecture of a microservice ecosystem in BASE style that sends or 
 receives messages in ACID style. You will look at the functionality of each microservice in 
 a later section (the “Design the Example Scenario” subsection under the “Distributed 
 Transaction Example” section); however, pay attention to the technical components 
 depicted here for the time being. It is BASE because via ActiveMQ you don’t know or care 
 where the messages go to or come from; all that the quote processing and quote 
 settlement see between them is the queues (whereas a classical ACID architecture would 
 create one big ACID transaction for quote settlement and quote processing). You use 
 JTA/XA to ensure that messages are processed exactly once, since you don’t want to lose 
  
 399",NA
 Relaxed BASE Transactions,"In some cases, you don’t care a lot about message loss or duplicates, and the scope of 
 your ACID transactions can be limited to single resource managers, like purely local 
 transactions only. This offers more performance but it has a cost: whereas so far the 
 BASE system had eventual consistency, this architecture no longer guarantees that by 
 default.
  
 As will be shown in the next chapter, to get some level of consistency, a lot more 
 work has to be done by the application developers; in some cases, eventual consistency 
 may even be impossible, notably in the case of message loss.
  
  
 Figure 
 13-4
  shows a typical architecture consisting of multiple resource managers in 
 a relaxed BASE transaction.
  
 400",NA
 ACID vs. BASE,"Such a comparison is like comparing apples and oranges: they are not intended to 
 replace each other, and both are equally good (or bad) at serving their own purpose. 
  
 This is an easily said statement; however, no CTO-level discussion can end with that 
 straight explanation. Having said that, understanding this distinction is key in 
 “mastering microservices.” If you understand this difference, the main intention of this 
 book is met!
  
 BASE transactions are the base for microservices architecture where we want to 
 stay away from ACID transactions. However, they serve different purposes. There is 
 not much point in debating one over the other, since both solve orthogonal concerns–
 the 
  
 403",NA
 Distributed Transactions Revisited,"Before you look into concrete examples, you need to understand a few concepts that will 
 set the context for the examples you will explore.",NA
 Local Transactions,"If you take a typical resource manager, typically that single resource will be 
 confined to a single host or node (even though that may not be the case 
 mandatorily). Operations confined to such a single resource are local transactions 
 and they affect only one transactional resource. Within a single node, there are less 
 (or for practical considerations, nil) nondeterministic operations, hence a command 
 sent to a single node must be considered deterministic, and in case of any 
 catastrophes, there are local recovery mechanisms. These resources have their own 
 transactional APIs, 
  
 404",NA
 Distributed Transactions,"Typically for the scenario of a distributed transaction to exist, it must span at least two 
 resource managers. Databases, message queues, transaction processing (TP) monitors 
 like IBM’s CICS, BEA’s Tuxedo, SAP Java Connector, and Siebel Systems are common 
 transactional resources, and often, if the transactions has to be distributed, it has to span 
 a couple of such resources. A distributed transaction can be seen as an atomic operation 
 that must be synchronized (or provide ACID properties) among multiple participating 
 resources that are distributed among different physical locations.
  
  
 Java EE application servers like Oracle Weblogic and IBM Websphere support JTA 
 out of the box, and there are third-party, standalone implementations of JTA like
  
 • 
 JOTM:
  JOTM is an open source transaction manager implemented in 
 Java. It supports several transaction models and specifications 
 providing transaction support for clients using a wide range of 
 middleware platforms (J2EE, CORBA, Web Services, OSGi).
  
 • 
 Narayana:
  Narayana, formerly known as JBossTS and Arjuna 
 Transaction Service, comes with a very robust implementation that 
 supports both the JTA and JTS APIs. It supports three 
  
 extended transaction models: nested top-level transactions, nested 
 transactions, and a compensation-based model based on sagas. Further, 
 it also supports web service and RESTful transactions. There is a need for 
 manual integration with the Spring framework, but it provides out-of-
 the-box integration with Spring Boot.
  
 • 
 AtomikosTransactionsEssentials:
  Atomikos TransactionsEssentials is 
 a production quality implementation that also supports recovery and 
 some exotic features beyond the JTA API. It provides out-of-the- box 
 Spring integration and support for pooled connections for both database 
 and JMS resources.
  
 • 
 Bitronix JTA:
  Bitronix claims to support transaction recovery as well 
 as or even better than some of the commercial products. Bitronix also 
 provides connection pooling and session pooling out of the box.
  
 406",NA
 Distributed Transactions in Java,"Coordination of transactions spanning multiple resources are specified by the X/ Open 
 standards by opengroup. Java supports X/Open standards by providing two interfaces: 
 JTA (Java Transaction API) and JTS (Java Transaction Service). As shown in Figure 
 13-2
 , 
 JTA is used by application developers to communicate to transaction managers. Since 
 resources can be provided by multiple vendors following different platforms and 
 programming languages, if all of these resources must be coordinated, they have to 
 agree again to the X/Open standards. Here, JTS, which follows CORBA OTS (Object 
 Transaction Service), provides the required interoperability between different 
 transaction managers sitting with distributed resources.
  
 I have discussed the “distributed nature” in distributed transactions. The two-phase 
 commit protocol is used for coordination of transactions across multiple resource 
 managers.",NA
 Distributed Transaction Example Using ,NA,NA
"MySQL, ActiveMQ, Derby, and Atomikos","The easiest way to do away with many data consistency problems, especially when 
 multiple resource managers are involved, is to use XA or distributed transactions even 
 in BASE, as in Figure 
 13-3
 . However, if you want to transition to even more relaxed 
 BASE microservices, the design mechanisms have to be more fault tolerant since your 
 XA transaction managers are absent, and they would have done all the hard work. 
  
 You will walk through the major consistency concern scenarios with the help of an 
 example. Again, I could have demonstrated the concern scenarios straight without 
 using distributed transactions in the example; however, I will take the reverse route 
 and use XA transactions to illustrate the perfect scenario and simulate the various fault 
 conditions by cutting down the ACID scope even more since it is rather easy for you, 
 the reader, to comprehend aspects in this manner. XA transactions allow us to do that 
 by “abusing” the transaction attributes to make the transaction scope smaller than it 
 would normally be. This means that I can reuse the same code to illustrate the 
 anomalies of relaxed BASE incrementally.
  
 407",NA
 The Example Scenario,"The example is not trivial, as shown in Figure 
 13-3
 , so the scenario requires a little 
 explanation. The example scenario is a simple stock trade processing system. Here are 
 the building blocks:
  
  1. New quotes for stock transactions can be pushed to the Broker 
 Web microservice. New quotes get inserted into a Quotes table, 
 which is in a MySQL DB, with a status of “New.”
  
  2. The Quotes processor task is a quartz scheduled task and it polls the 
 Quotes table in the MySQL DB for any new quotes with a status of 
 “New.”
  
  3. When a new quote with a status of “New” is found, it invokes the 
 processNewQuote method of the broker service, always with a 
 transaction, passing the unique identifier for the new quote into 
 the Quotes table.
  
  4. The broker service makes use of the other transactional services, the 
 auction service and the stock order service, and the execution of 
 both has to be atomic.
  
  5. The auction service confirms the quote received by changing the 
  
 status of the quote to “Confirmed” within a transaction.
  
  6. The stock order service creates a JMS message out of the 
 information contained in the new quote and is sent to an 
 ActiveMQ queue for settlement of the quote, again within the 
 above (5) transaction.
  
  7. The settlement listener service is listening on the ActiveMQ queue for 
 any new confirmed quote. All confirmed quotes on reaching the 
 ActiveMQ queue are picked up by onMessage of the settlement 
 listener service, within a transaction.
  
  8. The settlement listener service invokes the quotes reconcile service 
 for reconciliation of the quote, again within the above (7) 
 transaction.
  
 408",NA
 Code the Example Scenario,"The complete code required to demonstrate the distributed transaction example is in 
 folder ch13\ch13-01. There are four microservices to be coded. You will look into 
 them one by one.",NA
 Microservice 1: Quote Processing (Broker-MySQL-,NA,NA
ActiveMQ),"Visit pom.xml to see the Atomikos distributed transaction manager dependency. 
 See Listing 
 13-2
 .
  
 Listing 13-2. 
 Maven Dependencies for the Distributed Transactions Example 
 Using MySQL and ActiveMQ (ch13\ch13-01\XA-TX-Distributed\Broker-MySQL- 
 ActiveMQ\pom.xml)
  
 <dependencies>
  
  <dependency>
  
  
  <groupId>javax.transaction</groupId>
  
  <artifactId>jta</artifactId>
  
  
  <version>1.1</version>
  
  </dependency>
  
 409",NA
 Microservice 2: Broker-Web,"This microservice is straightforward, with REST controllers. You can invoke the test 
 cases by sending HTTP requests to this microservice. You can also keep watching the 
 dashboard, which will provide you with view for the Quotes table so that you can 
 visualize the effect of your test. Figure 
 13-6
  shows how various interactions can be done 
 with the Broker Web microservice.
  
 430",NA
 Microservice 3: Quote Settlement (Settlement-,NA,NA
ActiveMQ-Derby),"Visit pom.xml to see the Atomikos distributed transaction manager dependency. You 
 have all of the dependencies described already in Microservice 2, the Broker-MySQL- 
 ActiveMQ microservice. However, as depicted in the architecture diagram, you are using 
 a Derby database in place of MySQL for the downstream settlement of quotes. I will not 
 repeat the dependencies you have already seen; Listing 
 13-12
  shows the dependency for 
 the Derby client alone.
  
 Listing 13-12. 
 Maven Dependency for the Derby Client (ch13\ch13-01\XA-TX- 
 Distributed\Settlement-ActiveMQ-Derby\pom.xml)
  
 <dependencies>
  
  
  <dependency>
  
  
  
  <groupId>org.apache.derby</groupId>
  
  
  <artifactId>derbyclient</artifactId>
  
  
  <version>10.14.1.0</version>
  
  
  </dependency> 
  
 </dependencies>
  
 My intention with using a Derby database in place of MySQL is just to make you, the 
 reader, comfortable using XA transactions with an additional XA-compliant resource, a 
 Derby database, so that as a subsequent exercise you have all the tools to try for yourself 
  
 431",NA
 Microservice 4: Settlement-Web,"This microservice is again straightforward, with REST controllers. You can also keep 
 watching the dashboard, which will provide you with view for the User table so that you 
 can visualize the effect of your test. You will also use this microservice to create a few 
 initial users in the system for test purposes. Figure 
 13-7
  shows how various interactions 
 can be done with the Settlement Web microservice.
  
  
 Figure 13-7. 
 The Settlement Web console
  
 There is a junit Test class that simply loads the bean definitions into spring-sender- 
 mysql.xml and puts the main test application in sleep mode so that the scheduler can time 
 out to check for any new quotes received at predefined intervals. See Listing 
 13-17
 .
  
 Listing 13-17. 
 Main Test Class at the Quote Processor End (ch13\ch13-01\ XA-
 TX-Distributed\Broker-MySQL-ActiveMQ\src\test\java\com\acme\ecom\ 
 test\BrokerServiceTest.java)
  
 @RunWith(SpringJUnit4ClassRunner.class) 
  
 @ContextConfiguration(locations=""classpath:spring-sender-mysql.xml"") public 
 class BrokerServiceTest {
  
  @Autowired
  
  @Qualifier(""brokerServiceRequired_TX"") 
 BrokerService brokerService;
  
 441",NA
 Build and Test the Example’s Happy Flow,"As the first step, you need to bring up the ActiveMQ server. You may want to refer to 
 Appendix F to get started with ActiveMQ.
  
 You configure a queue that will act as the bridge between the upstream and 
 downstream processing. Listing 
 13-19
  gives the configuration of a queue that can be 
 done in activemq.xml.
  
 442",NA
Note,NA,NA
 You are using the ij tool from a base location different from your ,NA,NA
"Derby installation, assuming that your database is in a location different ",NA,NA
"from that of the Derby installation, which is a best practice. For further ",NA,NA
"details on how to create a new database, refer to appendix ",NA,NA
G,NA,NA
.,"Here again you will start with clean tables. Delete any tables with the names 
 you want for your examples:
  
 ij> drop table stockuser;
  
 Next, create the table with the schema required for this example:
  
 ij> create table stockuser (id bigint not null, amountbought double, amountsold double, 
 createdat timestamp not null, lastquoteat timestamp, name varchar(10) not null, 
 updatedat timestamp not null, primary key (id)); ij> CREATE SEQUENCE 
 hibernate_sequence START WITH 1 INCREMENT BY 1;
  
 This completes the infrastructure required to build and run the example.
  
  
 Next, there are four microservices to build and get running. You will do this one by 
 one.
  
 444",NA
 Microservice 1: Quote Processing Microservice,"See Listing 
 13-9
  to tweak the ActiveMQ-specific configuration in
  
 ch13\ch13-01\XA-TX-Distributed\Broker-MySQL-ActiveMQ\src\main\resources\ 
 spring-sender-mysql.xml
  
 <property name=""brokerURL"" value=""tcp://127.0.0.1:61616""/>
  
 Also, you need to tweak the MySQL-specific configuration:
  
 <bean id=""xaDataSourceMySQL-01"" class=""com.mysql.cj.jdbc.
  
 MysqlXADataSource"">
  
  
  <property name=""url"">
  
  
  
  <value>jdbc:mysql://localhost:3306/ecom01</value>
  
  
  </property>
  
  
  <property name=""user""><value>root</value></property>
  
  
  <property name=""password""><value>rootpassword</value></property> 
 </bean>
  
 Now build and package the executables for the Quote Processing microservice and 
 bring up the scheduled processor. There is a utility script provided that you can easily 
 execute in folder ch13\ch13-01\XA-TX-Distributed\Broker-MySQL-
 ActiveMQ\make.bat:
  
 cd  D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-MySQL- ActiveMQ 
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-MySQL- 
 ActiveMQ>make D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-
 MySQL- 
  
 ActiveMQ>mvn -Dmaven.test.skip=true clean install
  
 Now, the junit test can be run by using the script provided:
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-MySQL- 
 ActiveMQ>run D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-
 MySQL- 
  
 ActiveMQ>mvn -Dtest=BrokerServiceTest#testSubmitQuote test",NA
 Microservice 2: Broker Web Microservice,"First, you want to update the configuration files to suit to your environment:
  
 ch13\ch13-01\XA-TX-Distributed\Broker-Web\src\main\resources\application. 
 properties
  
 server.port=8080 
  
 spring.datasource.url = jdbc:mysql://localhost:3306/ecom01?autoReconnect=true& 
 useUnicode=true&characterEncoding=UTF-8&allowMultiQueries=true&useSSL=false 
 spring.datasource.username = root 
  
 spring.datasource.password = rootpassword 
  
 spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.
  
 MySQL5Dialect 
  
 spring.jpa.hibernate.ddl-auto = update 
 spring.freemarker.cache=false
  
 You can now build and package the executables for the Broker Web microservice 
 and bring up the server. There is a utility script provided in folder ch13\ch13-01\XA-
 TX- Distributed\Broker-Web\make.bat:
  
 cd D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-Web 
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-Web>make 
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-Web>mvn -Dmaven.
  
 test.skip=true clean package
  
  
 You can run the Spring Boot application, again in more than one way. The 
 straightforward way is to execute the JAR file via the following commands:
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-Web>run 
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Broker-Web>java -jar -
 Dserver.port=8080 .\target\quotes-web-1.0.0.jar
  
 This will bring up the Broker Web Spring Boot Server in port 8080.
  
  
 You can use a browser (preferably Chrome) and point to the following URL to keep 
 monitoring the processing of all new incoming quotes: http://localhost:8080/.
  
 446",NA
 Microservice 3: Quote Settlement Microservice,"See Listing 
 13-16
  to tweak the ActiveMQ-specific configuration in
  
 ch13\ch13-01\XA-TX-Distributed\Settlement-ActiveMQ-Derby\src\main\ 
 resources\spring-listener-derby.xml
  
 <property name=""brokerURL"" value=""failover:(tcp://127.0.0.1:61616)? 
 timeout=10000""/>
  
 Also, you need to tweak the Derby-specific configuration:
  
 <property name=""xaProperties""> 
  
 <props>
  
  
  <prop 
 key=""databaseName"">D:/Applns/apache/Derby/derbydb/exampledb</prop>
  
  
 <prop key=""serverName"">localhost</prop>
  
  
  <prop key=""portNumber"">1527</prop>
  
  
  </props> 
  
 </property>
  
 Now build and package the executables for the Quote Settlement microservice and 
 bring up the message listener. There is a utility script provided in folder  ch13\ch13-
 01\ XA-TX-Distributed\Settlement-ActiveMQ-Derby\make.bat:
  
 cd D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-ActiveMQ- 
 Derby 
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-ActiveMQ- 
 Derby>make 
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-ActiveMQ- 
 Derby>mvn -Dmaven.test.skip=true clean install
  
 Now, the junit test can be run by using the script provided:
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-ActiveMQ- 
 Derby>run 
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-ActiveMQ- 
 Derby>mvn -Dtest=SettlementListenerServiceTest#testSettleQuote test
  
 447",NA
 Microservice 4: Settlement Web Microservice,"First, you want to update the configuration files to suit to your environment:
  
 ch13\ch13-01\XA-TX-Distributed\Settlement-Web\src\main\resources\ 
 application.properties
  
 server.port=8081 
  
 spring.datasource.url=jdbc:derby://localhost:1527/D:/Applns/apache/Derby/ 
 derbydb/exampledb;create=false 
  
 spring.datasource.initialize=false 
  
 spring.datasource.driver-class-name=org.apache.derby.jdbc.ClientDriver 
 spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.
  
 DerbyTenSevenDialect 
  
 spring.freemarker.cache=false
  
 Now build and package the executables for the Settlement Web microservice and 
 bring up the server. There is a utility script provided in folder ch13\ch13-01\XA-TX- 
 Distributed\Settlement-Web\make.bat:
  
 cd D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-Web 
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-Web>make 
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-Web>mvn -
 Dmaven.test.skip=true clean package
  
  
 You can run the Spring Boot application in more than one way. The straightforward 
 way is to execute the JAR file via the following commands:
  
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-Web>run 
 D:\binil\gold\pack03\ch13\ch13-01\XA-TX-Distributed\Settlement-Web>java -jar -
 Dserver.port=8081 .\target�ser-web-1.0.0.jar
  
 This will bring up the Settlement Web Spring Boot Server in port 8080.
  
 You can use a browser (preferably Chrome) and point to the following URL to keep 
 monitoring the running account status of the users and how the account balance 
 changes as each new incoming quote is settled: http://localhost:8081/.
  
  
 There are altogether eight test cases that you will execute one by one to validate 
 the example. See Figure 
 13-8
 .
  
 448",NA
 Test the Transaction Rollback Scenario,"To test the Transaction Rollback test case, take Postman again and create another new 
 quote, as shown in Figure 
 13-11
 :
  
 453",NA
Caution,NA,NA
" as a reader, if you follow the execution of tests mentioned in this ",NA,NA
"chapter exactly, it is easy for you to visualize the effects and understand ",NA,NA
based on the explanation and screenshots provided here. so you are ,NA,NA
"strongly advised to follow exactly as directed. Further, this setup ",NA,NA
automatically makes the first pass fail and the second pass succeed for ,NA,NA
few of the test cases. this mechanism is designed in that manner to make ,NA,NA
intervention from the reader at a minimum during the test execution. ,NA,NA
"however, the test fixtures will work only if you execute tests cases with a ",NA,NA
single test client (postman browser client). so do not (monkey) test the ,NA,NA
"example with concurrent test clients. Later, when you are comfortable ",NA,NA
executing the tests as described and can follow the explanations ,NA,NA
"provided, then you may start tweaking the code and test fixtures to test ",NA,NA
further scenarios of your own.,NA,NA
 Simulating Relaxed Base Anomalies,"So far you implemented a BASE system with a reasonable degree of ACID transactions 
  
 so you are sure that eventual consistency is preserved. Now, let’s abuse the transaction",NA
 Test the Lost Message Scenario,"To test the Lost Message test case, take Postman again and create another new quote:
  
 http://localhost:8080/api/quotes 
  
 METHOD: POST; BODY: Raw JSON
  
 { ""symbol"" : ""GOOG"", ""sellerId"" : 11, ""buyerId"" : 21, ""amount"" : 300, ""test"" : 3, 
 ""delay"" : 2 }
  
 Figure 
 13-19
  shows the new quote for Test Case 3. It has a status of “New.” When 
 settled, the quote amount, 300, should get added to the respective running balances of 
 the buyer and seller shown in the figure.
  
  
 Figure 13-19. 
 Test Case 3 console at first
  
 Let’s now look at the transaction semantics. See Figure 
 13-20
 .
  
 458",NA
 Test the Duplicate Message Sent Scenario ,"To validate the Duplicate Message Sent test case, take Postman again and create another 
 new quote: 
  
 http://localhost:8080/api/quotes 
  
 METHOD: POST; BODY: Raw JSON 
  
 { ""symbol"" : ""NFLX"", ""sellerId"" : 11, ""buyerId"" : 21, ""amount"" : 400, ""test"" : 4, ""delay"" : 2 }
  
 460",NA
 Test the Duplicate Message Consumption Scenario,"To test the Duplicate Message Consumption test case, take Postman again and create 
 another new quote:
  
 http://localhost:8080/api/quotes 
  
 METHOD: POST; BODY: Raw JSON
  
 { ""symbol"" : ""TSLA"", ""sellerId"" : 11, ""buyerId"" : 21, ""amount"" : 500, ""test"" : 5, 
 ""delay"" : 2 }
  
 464",NA
" Test the Message Consumed, Processing Failure ",NA,NA
Scenario,"To test the Message Consumed, Processing Failure test case, take Postman again and 
 create another new quote:
  
 http://localhost:8080/api/quotes 
  
 METHOD: POST; BODY: Raw JSON
  
 { ""symbol"" : ""MSFT"", ""sellerId"" : 11, ""buyerId"" : 21, ""amount"" : 600, ""test"" : 6, 
 ""delay"" : 2 }
  
 Figure 
 13-29
  shows the new quote for Test Case 6. It has a status of “New.” 
 When settled, the quote amount, 600, should get added to the respective running 
 balances of the buyer and seller, as shown in the figure.
  
  
 Figure 13-29. 
 Test Case 6 console, initially
  
 468",NA
 Test the Message Redelivery Scenario,"JMS offers no ordering guarantees regarding message delivery, so messages sent first 
 can arrive after messages sent at a later time. This holds regardless of whether you use 
 XA transactions or not.
  
  
 To test the Message Redelivery test case, take Postman again and create another 
 new quote:
  
 http://localhost:8080/api/quotes 
  
 METHOD: POST; BODY: Raw JSON
  
 { ""symbol"" : ""ORCL"", ""sellerId"" : 11, ""buyerId"" : 21, ""amount"" : 700, ""test"" : 7, 
 ""delay"" : 2 }
  
 470",NA
 Common Messaging Pitfalls,"In this section, I will demonstrate few common messaging pitfalls which can occur in 
 distributed scenarios if you have not designed the system carefully.
  
 473",NA
 Test the Message Received Out of Order Scenario,"Testing for this scenario is slightly tricky since you need to coordinate the timing of 
 each action as per the test fixtures. I will explain based on the configuration for my 
 test fixtures, and they should work for you too if you have not done any changes to the 
 example configurations.
  
 You need to send a new quote for upstream processing but you want to delay the 
 processing for a little. While this quote is waiting for the delay to be over, you also want 
 to fire one more new quote for upstream processing, which will get processed nearly 
 straight through without any delay. As a result, the quote created later has to reach the 
 downstream system for further processing first, followed by the quote created initially. 
 In this manner, you need to simulate messages arriving out of order at the downstream 
 system.
  
 Before you start firing requests for this test case, read the rest of this section 
 completely once to understand the preparations you need to make mentally so as to fire 
 new quotes as per instructions. Then come back to this point of the explanation again, 
 read it again, and continue the actual test.
  
 Figure 
 13-35
  shows the transaction semantics for this test case.
  
 474",NA
 Summary,"Transactions are the bread and butter for the dynamics of any enterprise-class 
  
 application. Local transactions are good; however, distributed transactions across 
 partitioned domains are not among the good guys. When you shift from a monolith- 
 based architecture to a microservices-based architecture, you still need transactions; 
 however, you are better off with BASE transactions in place of ACID transactions for 
 domains across partitions and keep ACID or XA compliant transactions within partitions 
 or domains. In this chapter, you saw many error scenarios possible in distributed 
 enterprise systems, and you also saw how such error scenarios could be avoided had 
 you been using ACID transactions. When you shift from monolith- to microservices- 
 based architecture, there is no reduction in the above error scenarios; instead, there is a 
 magnitude of increase in such error scenarios since the degree of distribution of 
 microservices-based architectures are increased manyfold. In the next chapter, you will 
 see techniques you can use in architecting distributed systems to safeguard against such 
 error scenarios, so continue happy reading!
  
 481",NA
CHAPTER 14,NA,NA
Transactions ,NA,NA
and ,NA,NA
Microservices,"Chapter 
 13
  covered distributed transactions extensively. You now understand 
  
 distributed transactions clearly so you use them judiciously. To make it clear, you want 
 to avoid distributed transactions as much as possible in the microservices world across 
 partitions and domains. I do not say that distributed transactions should be deprecated 
 completely in microservices architecture because there are areas where you want to use 
 them by trading loose coupling for reliability; however, the essence is that you can do 
 most of the design without actually using distributed transactions when cross-partitions 
 and cross-domains are involved. You will look at how to do this in detail
 1
  in this chapter. 
 The examples in this chapter are a continuation of the examples from Chapter 
 13
 , so you 
 may want to read and understand Chapter 
 13
  before you attempt to run the examples in 
 this chapter.
  
 You will look into these aspects in this chapter:
  
 • The effect of distributing data across microservices
  
 • Distinguishing between global and local transactions
  
 • Enhancing the example in Chapter 
 13
  to make it fault tolerant
  
 • Exploring further design refactorings that you can use in your actual 
 microservices work
  
 1
  For more details, visit the online course at 
 https://atomikos.teachable.com/p/ 
 microservice-transaction-patterns",NA
 Partitioning and Microservices,"The best method to maximize consistency is to avoid partitions. No partitions means you 
 have a single software process handling all of your processing. Time has revealed that 
 software processes have limitations, and vertical scaling cannot be increased linearly if 
 not exponentially after a certain limit; this was discussed in Chapter 
 11
 ’s “The Scale 
 Cube” section. It is in this context that people use horizontal scaling methodologies to 
 improve scalability. The moment you split processing into more than one software 
 process, you have introduced probability for partitions, and the more partitions you 
 have, the less consistency you can achieve. Microservices are no exception. When you 
 split a monolith application into a microservices-based architecture, you have increased 
 the number of nodes or software processes across which you have split your processing 
 logic, and the coordination of this processing has to be done using a network. Network or 
 process boundaries bring all the associated complexities and uncertainties, and you can 
 no longer be certain on how and when end-to-end software processing will complete. It 
 is in this context that you have been leveraging two-phase commit protocols to decrease 
 uncertainty.
  
 Software processes that execute requests as part of a two-phase commit protocol 
 need to be able to communicate with one another to coordinate their actions when the 
 transaction commits. In the first phase of the two-phase commit protocol, the 
 coordinator, which is typically the process originating the transaction, will ask all the 
 participants if they are prepared to commit; in the second phase, the coordinator 
 instructs them to commit (or abort) the transaction. If a participant resource manager 
 can commit its part of a transaction, it will agree as soon as it has recorded the changes it 
 has made (to the resources) and its status in permanent storage, and is therefore 
 prepared to commit. Thus the two-phase commit protocol consists of a voting phase and 
 a completion phase. All of these additional steps add to the main processing instructions 
 and in this manner two-phase commit protocols are comparatively expensive since they 
 take more time to complete compared to local transactions.
  
 Even two-phase commit protocols are not completely error free. There are cases 
 where towards the end of the two-phase commit protocol, after all of the participants 
 have agreed to commit, some resources can go out of order where the commit will not 
 get completed. However, the protocol by design can tolerate such failures (server 
 crashes, network failures, or lost messages) and is guaranteed to complete eventually, 
 with or without manual intervention, although it is not possible to specify a time limit 
 within which it will be completed.
  
 484",NA
 Microservices and Distributed Data,"Typical monolith applications have all or most data collocated in a single database, and 
 this offers simplicity and many control options for the application in terms of 
 consistency. For example, look at the two data tables introduced in Chapter 
 13
 , shown 
 here as Figure 
 14-1
 .
  
  
 Figure 14-1. 
 The User Balance table
  
 Figure 
 14-1
  shows the User Balance table, which is an aggregated view of the 
 running balance for the users. Figure 
 14-2
  shows the Quotes table, which maintains 
 the transaction history.
  
  
 Figure 14-2. 
 The Quotes table
  
 You know that when a new quote is created, its status is “New.” When a quote is 
 processed and settled, its status gets updated to “Confirmed” and simultaneously the 
 value of the quote gets added to the running balances of both the buyer and the seller 
 in the User Balance table. These two actions must be atomic, and if it’s a monolith 
 system, you can make the operations atomic within the span of a local transaction. 
 See Listing 
 14-1
 .
  
 485",NA
 Idempotent Operations and Microservices,"One easy way to handle the error scenario in Listing 
 14-4
  is to simply reverse the order 
 of transactions. See Listing 
 14-5
 .",NA
Note,NA,NA
 this reversal of order of transaction works in this specific scenario; ,NA,NA
"for your case, it may require a different approach.","Listing 14-5. 
 Local Transactions in Microservice Scenario Reversed
  
 Start Local Transaction
  
  
  Increment or Decrement User Balance End 
 Local Transaction 
  
 Start Local Transaction
  
  
  Update Quote Status 
  
 End Local Transaction
  
 By reversing the order of transactions as listed above, you can always make sure 
 that you will attempt to change the quote status if and only if you are sure that the user 
 balance update is successful. In this manner, you can be sure that if the quote processing 
 is completed by changing the quote status from “New” to “Confirmed,” the quote is 
 already settled for sure by making corresponding changes in the User Balance table.
  
 There arises a new scenario then. What if the quote processing fails after the quote 
 is settled in the User Balance table? Here, the user balance is updated; however, the 
 quote remains in the status of “New,” as shown in Listing 
 14-6
 .
  
 Listing 14-6. 
 Local Transactions in Microservice Scenario Reversed Error
  
 Start Local Transaction
  
  
  Increment or Decrement User Balance End 
 Local Transaction 
  
 Start Local Transaction
  
  
  Update Quote Status 
  
 End Local Transaction !ERROR
  
 488",NA
 Global vs. Local Resources,"Chapter 
 13
  discussed ACID transactions, and Figure 
 13-2
  showed a typical scenario of 
 two separate resources, one a database resource and another a message middleware 
 resource. Queues of message middleware resources are first class citizens for storing the 
 state of entities in motion, temporarily in a node, or in a process. When you split the 
 monolith Quote application into two microservices, the Quote Processing microservice 
 and the Quote Settlement microservice, you need a communication mechanism between 
 them. If you prefer reactive or event-based approaches for this communication over 
 synchronous-style REST calls, message middleware resources are good choices, and that 
 is what is represented in Figure 
 13-2
 . However, this figure depicts a completely 
  
 2
 www.atomikos.com/Blog/IdempotentJmsConsumerPitfalls
  
 489",NA
 Distributed Transactions Example: ,NA,NA
Refactoring Towards Less ACID,"In the “Idempotent Operations and Microservices” section, you saw the problem arising 
 due to partial failures in enterprise systems. When you relax ACID constraints, there 
 should be mechanisms to take care of scenarios including but not limited to
  
 • Partial failures
  
 • Lost messages
  
 • Duplicate messages
  
 • Retry attempts
  
 • Message redelivery
  
 • Message received out of order
  
 As you know, all of the above scenarios were covered in Chapter 
 13
 . The end goal 
 is to choose between distributed transactions and local transactions based on the 
 nature and context of the use case involved. But Figure 
 14-7
  illustrates that you can 
 live with local transactions alone if your application is a monolith. The moment you 
 split your monolith into microservices, you introduce partitions in the architecture and 
 there you need to trade off. Option 1 in Figure 
 14-7
  is the preferred option where you 
 avoid 
  
 495",NA
 Towards Relaxed BASE: Redesign For ,NA,NA
Dealing with Duplicates and Out-Of-,NA,NA
Order Messages,"The aim here is not to deprecate distributed transactions straight away. Instead, you will 
 bring relaxations to the design from Chapter 
 13
 , simulate failure scenarios, and see if 
 you are able to overcome the shortcomings seen in Chapter 
 13
 . Once you understand 
 this enhanced design, you will have a good grip of the underlying basics in designing 
 distributed systems that are more resilient and fault tolerant. Once you have these 
 basics in your toolset, then it’s a matter of architectural creativity in designing fault 
 tolerant microservices.
  
  
 The main design change I introduce here is to have a new table with the name 
 QuotesTX in the downstream system, as shown in Figure 
 14-8
 .
  
  
 Figure 14-8. 
 Quotes Transactions table
  
 You need a way to track which quotes received through the messaging middleware 
 have been settled and which are still outstanding. The transactions to the QuotesTX 
 table have been handled by a new entity in the system called StockTransaction, and all 
 actions on this entity are owned by a new transactional component service, 
 QuotesTransactionService. The enhanced architecture is shown in Figure 
 14-9
 .
  
 496",NA
 Code the Relaxed Example Scenario,"The complete code required to demonstrate the distributed transaction example with 
 enhanced resiliency for relaxed BASE anomalies is in folder ch14\ch14-01. There are no 
 major changes in the code of the upstream microservices from what you saw in Chapter 
 13
 , so I will not duplicate the code here. I have introduced new code as well as updates 
 to existing code in the downstream microservices, so I will explain it all here. The main 
 changes are in the Quote Settlement downstream microservice.",NA
 Microservice 3: Quote Settlement (Settlement-,NA,NA
ActiveMQ-Derby),"When a new quote message reaches the ActiveMQ queue, it will be picked up 
 instantaneously by the settlement listener. The settlement listener code has changed 
 from what you saw in Chapter 
 13
 , so look at Listing 
 14-7
 .
  
 Listing 14-7. 
 Settlement Listener Orchestrator (ch14\ch14-01\XA-TX- 
 Resilient\ Settlement-ActiveMQ-
 Derby\src\main\java\com\acme\ecom\messaging\ SettlementListener.java)
  
 public class SettlementListener implements MessageListener {
  
  @Autowired
  
  @Qualifier(""quotesTransactionServiceRequired_TX"")
  
  QuotesTransactionService quotesTransactionServiceRequired_TX;
  
  @Autowired
  
  @Qualifier(""quotesTransactionServiceRequiresNew_TX"")
  
  QuotesTransactionService quotesTransactionServiceRequiresNew_TX;
  
 500",NA
 Build and Test the Duplicate Message Being Sent ,NA,NA
Scenario,"Since this example is a continuation of the example in Chapter 
 13
 , I won’t explain the 
 scenario in detail. Instead, your aim is to understand how to manage the duplicate 
 messages and the messages coming out of order so that you know how to better design 
 for them in a microservices architecture. Hence you will look into three test cases in 
 detail, shown in Figure 
 14-10
 .
  
  
 Figure 14-10. 
 XA transaction resiliency test cases
  
 510",NA
Note,NA,NA
 You are using the ij tool from a base location different from your ,NA,NA
"derby installation, assuming that your database is in a location ",NA,NA
"different from that of the derby installation, which is a best practice. ",NA,NA
"For further details on how to create a new database, refer to appendix ",NA,NA
G.,512,NA
 Microservice 1: Quote Processing Microservice,"Tweak the ActiveMQ-specific configuration in spring-sender-mysql.xml:
  
 ch14\ch14-01\XA-TX-Resilient\Broker-MySQL-ActiveMQ\src\main\resources\ 
 spring-sender-mysql.xml
  
 <property name=""brokerURL"" value=""tcp://127.0.0.1:61616""/>
  
 Also, tweak the MySQL-specific configuration:
  
 <bean id=""xaDataSourceMySQL-01"" class=""com.mysql.cj.jdbc.
  
 MysqlXADataSource"">
  
  
  <property name=""url"">
  
  
  
  <value>jdbc:mysql://localhost:3306/ecom01</value>
  
  </property>
  
 513",NA
 Microservice 2: Broker Web Microservice,"First, update the configuration files to suit to your environment:
  
 ch14\ch14-01\XA-TX-Resilient\Broker-Web\src\main\resources\application. 
 properties
  
 server.port=8080 
  
 spring.datasource.url = jdbc:mysql://localhost:3306/oauth2?autoReconnect=true 
 &useUnicode=true&characterEncoding=UTF-8&allowMultiQueries=true&useSSL=false 
 spring.datasource.username = root 
  
 spring.datasource.password = rootpassword 
  
 spring.jpa.properties.hibernate.dialect = org.hibernate.dialect.
  
 MySQL5Dialect 
  
 spring.jpa.hibernate.ddl-auto = update 
  
 spring.freemarker.cache=false
  
 514",NA
 Microservice 3: Quote Settlement Microservice,"Tweak the ActiveMQ-specific configuration in
  
 ch13\ch13-01\XA-TX-Distributed\Settlement-ActiveMQ-Derby\src\main\ 
 resources\spring-listener-derby.xml
  
 <property name=""brokerURL""
  
  
  value=""failover:(tcp://127.0.0.1:61616)?timeout=10000""/>
  
 Also, you need to tweak the Derby-specific configuration:
  
 <property name=""xaProperties"">
  
  
  
  <props>
  
  <prop key=""databaseName"">D:/Applns/apache/Derby/derbydb/exampledb</prop>
  
  
  <prop key=""serverName"">localhost</prop>
  
  
  
  <prop key=""portNumber"">1527</prop>
  
  
  
  </props> 
  
 </property>
  
 515",NA
 Microservice 4: Settlement Web Microservice,"First, update the configuration files to suit to your environment:
  
 ch14\ch14-01\XA-TX-Resilient\Settlement-Web\src\main\resources\application. 
 properties
  
 server.port=8081 
  
 spring.datasource.url=jdbc:derby://localhost:1527/D:/Applns/apache/Derby/ 
 derbydb/exampledb;create=false 
  
 spring.datasource.initialize=false 
  
 spring.datasource.driver-class-name=org.apache.derby.jdbc.ClientDriver 
 spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.
  
 DerbyTenSevenDialect 
  
 spring.freemarker.cache=false
  
 I advise you not to make any changes here.
  
 Now build and package the executables for the Settlement Web microservice and 
 bring up the server. There is a utility script provided in folder  ch13\ch13-01\XA-TX- 
 Distributed\Settlement-Web\make.bat:
  
 516",NA
 Test the Duplicate Message Consumption ,NA,NA
Scenario,"To test the Duplicate Message Consumption test case, take Postman again and create 
 another new quote, as shown (see Figure 
 14-17
 ):
  
 http://localhost:8080/api/quotes 
  
 METHOD: POST; BODY: Raw JSON
  
 { ""symbol"" : ""TSLA"", ""sellerId"" : 11, ""buyerId"" : 21, ""amount"" : 500, ""test"" : 5, 
 ""delay"" : 2 }
  
  
 Figure 14-17. 
 Test Case 5 console, initially
  
 In this test case, all works fine in the upstream microservices. You settle the quote 
 message at the downstream microservice and then you simulate an error in the reading 
 of message by the downstream microservice’s message listener. The state at this point is 
 shown in Figure 
 14-18
 .
  
 523",NA
 Test the Message Received Out of Order Scenario,"You have now executed up to Test Case 5. Before you execute Test Case 8 to simulate a 
 message reaching out of order, you will execute Test Case 6 and Test Case 7, but I won’t 
 explain further because I don’t want to showcase anything extra from what you already 
 saw in the corresponding sections in Chapter 
 13
 .
  
 For Test Case 6, take Postman and create a new quote, as shown:
  
 http://localhost:8080/api/quotes 
  
 METHOD: POST; BODY: Raw JSON
  
 { ""symbol"" : ""MSFT"", ""sellerId"" : 11, ""buyerId"" : 21, ""amount"" : 600, ""test"" : 6, 
 ""delay"" : 2 }
  
 Keep watching all three consoles. Once you make sure Test Case 6 is completed, 
 execute Test Case 7 by again taking Postman and creating another new quote, as 
 shown:
  
 { ""symbol"" : ""ORCL"", ""sellerId"" : 11, ""buyerId"" : 21, ""amount"" : 700, ""test"" : 7, 
 ""delay"" : 2 }
  
  
 If you have followed along exactly as directed, at the completion of Test Case 7, 
 your consoles will look like Figure 
 14-20
  and Figure 
 14-21
 .
  
 526",NA
 Choosing Transaction Options,"You concluded the “Global vs. Local Resource” section by justifying that if you chose 
 Option 1 for the architecture, then when you dequeue messages from the queue for 
 settlement by the Quotes Settlement microservice, you still have the two-phase 
 transaction problem. If you consider quote settlement as a pure back-office process, one 
 justification for you to still continue with the two-phase transactions is that you 
 maximized the throughput and hence the availability of your customer-facing 
 microservices while trading off comparatively lower responsiveness for your back-office 
 microservices.
  
 But what if a two-phase commit transaction is never acceptable in some parts of 
 your microservice architecture? There are a bunch of implications associated with a 
  
 536",NA
" Message Queues, Peek, and Client Acknowledge","Suppose that you want to adopt the Architecture Option 1 shown in Figure 
 14-7
  and still 
 want to avoid two-phase commit transactions between the Quote Settlement 
 microservice and the ActiveMQ message broker. When you avoid two-phase commit 
 transactions, if the database operations and the message queue operations are backed 
 up by partitioned resources, they can’t be effected atomically. If they cannot be effected 
 atomically, you don’t want to encapsulate the read and read-acknowledgement of 
 messages from the queue to happen automatically; rather, the client program or the 
 client code should control that. The JMS specification supports two types of message 
  
 4
 www.atomikos.com/Documentation/LogCloud
  shows a new generation of coordinator.
  
 537",NA
Note,NA,NA
" Unlike Xa transactions, JMs transactions concern only on the JMs ",NA,NA
messages of a single connection. a rollback or commit does not extend ,NA,NA
beyond a single connection.,"In the examples in the current chapter and in Chapter 
 13
 , you use the following 
 configuration:
  
 <bean id=""jmsTemplate"" class=""org.springframework.jms.core.JmsTemplate"">
  
  
 <property name=""sessionTransacted"" value=""true""/> 
  
 </bean>
  
 Alternatively, the SESSION_TRANSACTED value may be passed as the argument to 
 the method createSession(int sessionMode) on the Connection object to specify that the 
 session should use a local transaction. When used, it rolls up acknowledgments with 
 Session.commit().
  
 Session session = connection.createSession(true, Session.SESSION_TRANSACTED);
  
 By specifying false and AUTO_ACKNOWLEDGE, you can create a nontransacted 
 session and the session automatically acknowledges messages. A message is 
  
 automatically acknowledged when it successfully returns from the receive() method or 
 the onMessage() method. If a failure occurs while executing the receive() method or the 
 onMessage() method, the message is automatically redelivered. The JMS provider 
 manages message redelivery and guarantees once-only delivery semantics. However, 
  
 538",NA
 Summary,"Just like many of my colleagues, I too loved transactions. I have been using declarative 
 transaction management since 1999 where we were thrilled to be among the first few to 
 download the 
 Sun’s Reference Implementation of J2EE Server with EJB
 6
 (Enterprise Java 
 Beans) Containers
  in the process of implementing an expert system for optimizing 
 operations of an airline passenger reservation system for a European airline. It’s been 20 
 years since then, and we still love transactions, both local and distributed. However, the 
 point is that the choice between distributed and local transactions has to be done on a 
 case-by-case basis based on the context, functionality, and criticality of the microservice 
 involved. Designing systems leveraging distributed transaction managers in cases where 
 you don’t mandatorily need them will be costly since it may increase the operations cost 
 as well as slightly affect the performance. You saw a few techniques in this chapter that 
 you can use to design fault-tolerant microservices that must be eventually consistent, 
 although I did not address all possible anomalies. In the next chapter, you will extend 
 this learning to look at few other scenarios including but not limited to long-running 
 transactions.
  
 5
 www.atomikos.com/Blog/IdempotentJmsConsumerPitfalls 
  
 6
  The EJB specification was originally developed in 1997 by IBM and later adopted by Sun 
 Microsystems (EJB 1.0 and 1.1) in 1999 and enhanced under the Java Community Process as JSR 
 19 (EJB 2.0), JSR 153 (EJB 2.1), JSR 220 (EJB 3.0), JSR 318 (EJB 3.1) and JSR 345 (EJB 3.2).
  
 541",NA
CHAPTER 15,NA,NA
Transactions ,NA,NA
Optimized for ,NA,NA
Microservices,"While Chapter 
 13
  covered distributed transactions with working code, you relooked at 
 those examples with an enhanced design in Chapter 
 14
  with an aim to understand the 
 nitty-gritty details and concerns while architecting solutions for BASE 
  
 transactional support. So far, so good, but the question is whether there is a way to 
 abstract the details you saw in those two chapters and still attain the required level of 
 data consistency in a microservices architecture. You will look at this in detail in this 
 chapter. The examples in this chapter are not a continuation of the examples you 
 covered in Chapters 
 13
  and 
 14
 , so you can skip those two chapters if you are in a hurry 
 to understand the examples in this chapter. However, you are going to leverage Axon 
 framework again in this chapter, so you are strongly advised to go through Chapter 
 12
  
 first to get an introduction to Axon so that you know the programming paradigm during 
 this discussion.
  
 You will be looking into the following in this chapter:
  
 • An introduction to saga
  
 • Distributed saga and microservices
  
 • A complete saga example using Axon 2",NA
 Saga for Microservices Transactions,"The section titled “Transaction Models” in Chapter 
 13
  introduced the concept of saga, 
 and in this section you will look at saga in detail.",NA
 Saga Explained,"The concept of saga was first introduced in a paper in 1987, and the concept gained 
 traction in the context of microservices. Sagas are similar to nested transactions. In a 
 nested transaction, atomic transactions are embedded in other transactions. In sagas, 
 each of these transactions has a corresponding compensating transaction. If any of the 
 transactions in a saga fails, the compensating transactions for each transaction that 
 was successfully run previously will be invoked so as to nullify the effect of previously 
 successful transactions.
  
 Sagas are typically used for modelling long-lived transactions like those involved in 
 workflows. It is not advisable to use two-phase transactions to control long-lived 
 transactions since the locking of resources for prolonged durations is not at all 
 advisable. In the context of microservices, sagas become relevant even when long-lived 
 transactions are not involved due to the reason why you want to say NO to two-phase 
 commit transactions. When two-phase commit transactions can’t be used and when you 
 still want to exercise control at each stage of a multi-step transaction, sagas will help 
 you.
  
 Even before the evolution of microservices, the concept of saga was very popular, 
 and in the truest sense many real-world problems have been addressed using sagas. 
 Maintaining consistency across location and/or trust boundaries can’t easily be handled 
 using the classic ACID model and many real-world scenarios involve these complexities. 
 A transfer of money from an account in one bank to another account in another bank is a 
 classic example where there is no reason to assume that the software systems of these 
 banks are near or together. And you can relate to this from your daily experience when 
 you do such fund transfers. Even if a money transfer happens near real time so that it 
 appears to be instantaneous in every aspect, most probably the involved transactions 
 were not carried out in a two-phase commit transaction, but instead in some kind of 
 saga. This means, when you do a fund transfer, the associated debit and credit in most 
 cases will happen as two correlated steps, coordinated by some means other than a two- 
 phase transaction coordinator so that all the involved steps will either happen or all the 
 involved steps will be rolled back eventually.
  
 Another classical example is when you book a flight, hotel, and rental cab. It’s very 
 unlikely that a single enterprise owns inventory for all these resources, but it’s highly 
 likely that end user wants to book one or more of these resources in a single transaction, 
 because a confirmed hotel booking with a non-confirmed flight booking is not very 
 useful for him. Another aspect here is that, if you look at the resource managers or the 
  
 544",NA
 Distributed Saga,"The concept of saga as described in the previous section is rather trivial to build, since 
 many of the workflow and Business Process Model and Notation (BPMN) frameworks 
 are built using the same analogy where you want to orchestrate long-running 
  
 transactions. If you want to coordinate the same in a microservices environment, this 
 involves coordinating multiple decentralized nodes and processes, which is non-trivial.
  
  
 You will first look at the various components needed for a distributed saga at 
 the conceptual level. See Figure 
 15-2
 .
  
 • Transactions and compensation transactions:
  
 A saga transaction in a microservices context is better called a 
 request (HTTP) or an event (commands and events); however, 
 for the simplicity of our discussion, we will retain the term 
 transactions.
  
 545",NA
 Saga Example Code Using Axon,"You are going to extend the example code from in Chapter 
 12
 , which is a portion of an 
 e-commerce application. There are two entities in your domain, the order and the 
 product. Users can buy a product, which will create a new order. When a new order is 
 created, the status of the order will be in a “New” state and the product stock will get 
 depreciated. Creating a new order will also make an entry to the Audit table. The 
 example application is shown in Figure 
 15-9
 .
  
 555",NA
 Design the Example Saga Scenario,"This example is similar to the example in the section titled “Distributed Command and 
 Event Handling” in Chapter 
 12
 , except for the addition of a saga transaction manager in 
 the Handle Command and Create Event microservice. There are 
  
 five microservices. The Event Handle Core microservice has an event handler, 
 OrderEventHandler, and the Event Handler Audit microservice has an event handler, 
 AuditEventHandler. Both are subscribed to the order created event. So, you have two 
 microservices (the Event Handler Audit microservice and the Event Handle Core 
 microservice) with two event handler types, both interested in the same order created 
 event. Also, the Handle Command and Create Event microservice has a saga, 
 OrderProcessSaga, which is also interested in the order created event. Figure 
 15-10 
 shows the design.
  
 556",NA
 Code the Example Saga Scenario,"The complete code required to demonstrate the simple Axon example is in ch15\ ch15- 
 01. Since this example is an extension of the example in the “Distributed Command and 
 Event Handling” section in Chapter 
 12
 , I will explain only the newly added or changed 
 code, so refer back to that section to get the explanation of the rest of the code. There 
 are five microservices to be coded, and you will look into them one by one.",NA
 Microservice 1: 01-Ecom-web,"This microservice is a typical Spring Boot web application without any Axon 
 components, so I will not discuss it further.",NA
 Microservice 2: 02-Ecom-,NA,NA
CreateCommandRestController,"You will start with the order controller, which handles the HTTP requests to create a 
 new order and to confirm or cancel the order. See Listing 
 15-1
 .
  
 Listing 15-1. 
 Order Controller (ch15\ch15-01\Ax2-Saga\02-Ecom- Create 
 CommandRestController\src\main\java\com\acme\ecom\web\controller\ 
 OrderController.java)
  
 @RestController 
  
 public class OrderController {
  
  @Autowired
  
  private DataSource dataSource;
  
  @Autowired
  
  @Qualifier(""distributedCommandGateway"") 
 private CommandGateway commandGateway;
  
  @RequestMapping(value = ""/orders"", method = RequestMethod.GET,
  
  
 produces = { MediaType.APPLICATION_JSON_VALUE }) public 
 ResponseEntity<List<OrderDTO>> getAllOrders() {
  
 567",NA
 Microservice 3: 03-Ecom-,NA,NA
HandleCommandAndCreateEvent,"This microservice has to handle any commands created by the 02-Ecom- 
  
 CreateCommandRestController microservice and reaching through the distributed 
 command bus from the remote JVM. Further, this microservice also creates events, 
 which are supposed to be consumed by distributed event handlers in remote JVMs or 
 foreign microservices. Listing 
 15-2
  shows the order command handler first.
  
 Listing 15-2. 
 Order Command Handler (ch15\ch15-01\Ax2-Saga\03-Ecom- 
 HandleCommandAndCreateEvent\src\main\java\com\acme\ecom\order\ 
 commandhandler\OrderCommandHandler.java)
  
 @Component 
  
 public class OrderCommandHandler {
  
  @Autowired
  
  @Qualifier(""orderRepository"")
  
  private Repository<Order> orderRepository;
  
  @Autowired
  
  @Qualifier(""productRepository"")
  
  private Repository<Product> productRepository;
  
  @CommandHandler
  
  public void handleNewOrder(NewOrderCommand 
 newOrderCommand){
  
  Product product =
  
  
  productRepository.load(newOrderCommand.getProductId()); 
 product.depreciateStock(newOrderCommand.getNumber()); Integer 
 id = new Random().nextInt();",NA
 Microservice 4: 04-Ecom-EventHandleCore,"As the name of the microservice hints, it contains the two main event handlers, 
 OrderEventHandler and ProductEventHandler, and their functionality is to update the 
 views of Order and Product respectively, in response to the following events:
  
 • OrderCreatedEvent
  
 • OrderConfirmedEvent
  
 • OrderCancelledEvent
  
 • StockUpdatedEvent
  
 Listing 
 15-5
  shows the order event handler code, which updates the order view.
  
 Listing 15-5. 
 Order Event Handler (ch15\ch15-01\Ax2-Saga\04-Ecom- 
 EventHandleCore\src\main\java\com\acme\ecom\order\eventhandler\ 
 OrderEventHandler.java)
  
 @Component 
  
 public class OrderEventHandler {
  
  @Autowired
  
  DataSource dataSource;
  
  @EventHandler
  
  public void handleOrderCreatedEvent(OrderCreatedEvent event) {
  
  
  JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource);
  
  
  jdbcTemplate.update(""INSERT INTO ecom_order_view VALUES(?,?,?,?,?)"",
  
  
  new Object[]{event.getOrderId(), event.getPrice(),
  
  
  
  event.getNumber(), event.getProductDescription(), NEW}); }
  
 574",NA
 Microservice 5: 05-Ecom-EventHandlerAudit,"This microservice makes audit entries to all major events happening against the domain 
 entities. Listing 
 15-7
  shows the audit event handler.
  
 Listing 15-7. 
 Audit Event Handler (ch15\ch15-01\Ax2-Saga\05-Ecom- 
 EventHandlerAudit\src\main\java\com\acme\ecom\order\eventhandler
 \ AuditEventHandler.java)
  
 @Component 
  
 public class AuditEventHandler {
  
  @Autowired
  
  DataSource dataSource;
  
  @EventHandler
  
  public void handleOrderCreatedEvent(OrderCreatedEvent event) {
  
  
  JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource);
  
  
  jdbcTemplate.update(""INSERT INTO ecom_order_audit VALUES(?,?,?)"",
  
  
  new Object[]{event.getOrderId(), event.getOrderStatus(),
  
  
  
  
 new Date()});
  
  }
  
  @EventHandler
  
  public void handleOrderConfirmedEvent(OrderConfirmedEvent event) {
  
  
  JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource);
  
  
  jdbcTemplate.update(""INSERT INTO ecom_order_audit VALUES(?,?,?)"",
  
  
  new Object[]{event.getOrderId(), CONFIRMED, new Date()}); }
  
  @EventHandler
  
  public void handleOrderCancelledEvent(OrderCancelledEvent event) {
  
  
  
  JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource);
  
  
  
  jdbcTemplate.update(""INSERT INTO ecom_order_audit VALUES(?,?,?)"",
  
  
  
  new Object[]{event.getOrderId(), CANCELLED, new Date()});
  
  } 
  
 }
  
 576",NA
 Build and Test the Saga Example,"As the first step, you need to bring up MongoDB. You may want to refer to Appendix A to 
 get started with MongoDB.
  
 D:\Applns\MongoDB\Server\3.2.6\bin>mongod.exe --dbpath D:\Applns\MongoDB\ 
 Server\3.2.6\data
  
  
 Next, you need to bring up the RabbitMQ server. You may want to refer to 
 Appendix B to get started with the RabbitMQ server.
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>D:\Applns\RabbitMQ\rabbitmq_ 
 server- 3.6.3\sbin\rabbitmq-server.bat
  
  
 Make sure MySQL is up and running. You may want to refer to Appendix H to get 
 started with MySQL.
  
 Bring Up MySQL Server 
  
 cd D:\Applns\MySQL\mysql-8.0.14-winx64\bin 
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysqld --console
  
 Now Open MySQL prompt 
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysql -u root -p
  
 mysql> use ecom01; 
  
 Database changed 
  
 mysql>
  
  
 To start with clean tables, delete any tables with the names you want for 
 your examples:
  
 mysql> drop table ecom_order; 
  
 mysql> drop table ecom_product; 
  
 mysql> drop table ecom_order_view;
  
 577",NA
 Microservice 1: 01-Ecom-web,"First, update the configuration files to suit to your environment:
  
 ch15\ch15-01\Ax2-Saga\01-Ecom-web\src\main\resources\application.properties 
 server.port=8080",NA
Note,NA,NA
 i advise you not to make any changes here.,578,NA
 Microservice 2: 02-Ecom-,NA,NA
CreateCommandRestController,"The JGroups configuration is provided in the following file:
  
 ch15\ch15-01\Ax2-Saga\02-Ecom-CreateCommandRestController\src\main\ 
 resources�p_config.xml
  
 However, let’s not worry about the contents of this file too much for 
 now. Update the next configuration file to suit to your environment:
  
 ch15\ch15-01\Ax2-Saga\02-Ecom-CreateCommandRestController\src\main\ 
 resources\application.properties 
  
 server.port=8081 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
  
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 cd D:\binil\gold\pack03\ch15\ch15-01\Ax2-Saga\02-Ecom- CreateCommandRest 
 Controller 
  
 D:\binil\gold\pack03\ch15\ch15-01\Ax2-Saga\02-Ecom- CreateCommandRest 
 Controller>make 
  
 D:\binil\gold\pack03\ch15\ch15-01\Ax2-Saga\02-Ecom- CreateCommandRest 
 Controller>mvn clean install
  
 579",NA
 Microservice 3: 03-Ecom-,NA,NA
HandleCommandAndCreateEvent,"Update the configuration files to suit to your environment and see Listing 
 15-8
 :
  
 ch12\ch12-02\Ax2-Commands-Multi-Event-Handler-Distributed\03-Ecom- Handle 
 CommandAndCreateEvent\src\main\resources\application.properties
  
 Listing 15-8. 
 Microservice 3 Configuration Parameters
  
 spring.data.mongodb.uri=mongodb://localhost:27017/test
  
 server.port=8082 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 ecom.amqp.rabbit.address= 127.0.0.1:5672 
 ecom.amqp.rabbit.username= guest 
  
 ecom.amqp.rabbit.password= guest 
  
 ecom.amqp.rabbit.vhost=/ 
  
 ecom.amqp.rabbit.exchange=Ecom-02 
  
 ecom.amqp.rabbit.queue=Ecom-createcommand_01
  
 580",NA
Note,NA,NA
 the mongodB UrL is used by the microservice to persist the saga. ,NA,NA
"even though you provide the full path to the test database, the ",NA,NA
microservice will create any saga-related collections only in a different ,NA,NA
database called axonframework.,"cd D:\binil\gold\pack03\ch15\ch15-01\Ax2-Saga\03-Ecom- HandleCommandAnd 
 CreateEvent 
  
 D:\binil\gold\pack03\ch15\ch15-01\Ax2-Saga\03-Ecom- 
 HandleCommandAndCreate Event>make 
  
 D:\binil\gold\pack03\ch15\ch15-01\Ax2-Saga\03-Ecom- 
 HandleCommandAndCreate Event>mvn clean install
  
 You can run the 03-Ecom-HandleCommandAndCreateEvent Axon Spring Boot 
 application, again in more than one way. The straightforward way is to execute the JAR 
 file via the following commands:
  
 D:\binil\gold\pack03\ch15\ch15-01\Ax2-Saga\03-Ecom- 
 HandleCommandAndCreate Event>run 
  
 D:\binil\gold\pack03\ch15\ch15-01\Ax2-Saga\03-Ecom- HandleCommandAnd 
 CreateEvent>java -Dserver.port=8082 -Dlog4j.configurationFile=log4j2-spring.xml -jar 
 .\target\03-Ecom- HandleCommandAndSaga- 0.0.1-SNAPSHOT.jar
  
  
 This will bring up the 02-Ecom-CreateCommandRestController Axon Spring Boot 
 Server in port 8082.",NA
 Microservice 4: 04-Ecom-EventHandleCore,"Update the configuration files to suit to your environment and see Listing 
 15-9
 :
  
 ch15\ch15-01\Ax2-Saga\04-Ecom-EventHandleCore\src\main\resources\ 
 application.properties
  
 Listing 15-9. 
 Microservice 4 Configuration Parameters
  
 server.port=8083 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 581",NA
 Microservice 5: 05-Ecom-EventHandlerAudit,"This is the last microservice you want to bring up in this example. Update the 
 configuration files to suit to your environment and see Listing 
 15-10
 :
  
 ch15\ch15-01\Ax2-Saga\05-Ecom-EventHandlerAudit\src\main\resources\ 
 application.properties
  
 Listing 15-10. 
 Microservice 5 Configuration Parameters
  
 server.port=8084 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 ecom.amqp.rabbit.address= 127.0.0.1:5672 
 ecom.amqp.rabbit.username= guest 
  
 ecom.amqp.rabbit.password= guest
  
 582",NA
Note,NA,NA
 if the microservices are not responding as per the intended ,NA,NA
"manner, you may want to flush the rabbitmQ queues. this can be done ",NA,NA
"easily by bringing down rabbitmQ, deleting the data folders, and then ",NA,NA
bringing back rabbitmQ. refer to appendix B for related details.,NA,NA
 Summary,"While Chapters 
 13
  and 
 14
  covered transactions in detail, this chapter covered 
 transactions specifically in the context of microservices. You learned about saga and 
 how distributed sagas can be utilized by grouping a given transaction into a sequence 
 of subtransactions and corresponding compensating transactions. All transactions in 
 a saga either complete successfully or, in the event of a failure, the compensating 
 transactions are rolled back. You also saw the complete working code of how to 
 implement saga using the Axon 2 framework. Having looked at transactions, next you 
 will relook at high availability and scalability with an emphasis on CQRS design in 
 Chapter 
 16
 .
  
 587",NA
CHAPTER 16,NA,NA
Advanced High ,NA,NA
Availability and ,NA,NA
Scalability,"In Chapter 
 9
 , you looked at various elements contributing to high availability (HA) for a 
 software architecture, most of which are relevant for both a microservices architecture 
 and a monolith architecture. There you looked at the various components of a private 
 cloud or an on-premises deployment infrastructure and glanced through the HA aspects. 
 In this chapter, you will look into details of selected concerns that have significant 
 impact in designing CQRS-based systems. To make things simple and relatable to 
 concepts you already know or have been using, I will examine these concerns in the 
 context of a database familiar to most of us, Oracle. Once you understand the concepts, 
 then it’s straightforward to extend that learning to any other vendor’s solution or to 
 other free and open source solutions. Interestingly, you will look at many of these 
 concepts in the context of Oracle just to make sure you leverage such solutions only 
 when it’s absolutely required, which again leads to the core point that in many situations 
 there are alternate and possibly cheaper solutions.
  
 You will be exploring the following in this chapter:
  
 • Architecture templates to address an increasing amount of scalability
  
 • Code samples demonstrating HA and scalability design using 
 Axon 2 CQRS
  
 • Read scalability vs. write scalability
  
 • Techniques to allow concurrent modification of entities
  
 • Code samples demonstrating concurrent modification of entities 
 using Axon 2 CQRS",NA
 High Availability and Scalability ,NA,NA
Templates Using an Oracle DB as a ,NA,NA
Reference,"As mentioned, you will use an Oracle database as a solution to explain various HA 
 templates. While doing so, you will also use the public cloud, Amazon Web Services 
 (AWS) in your case, as the deployment environment. This is because, as you will shortly 
 see, there are some caveats to the templates, which I will explain when it comes to the 
 public cloud.
  
 You will consider the application architecture as a life cycle, each stage of the cycle 
 representing the various stages of growth, from inception until the level when the 
 architecture reaches maturity and operates at economies and efficiencies of scale, and 
 further beyond where you need to web scale at an exponential or infinite level.",NA
" The Simple, Inception Architecture","This is the simplest form of any distributed or microservices architecture and will suit 
 only for serving application services for personal use or for the use of small start-ups. In 
 its basic form, it consists of a middle tier providing application services, and this middle 
 tier connects to a single, simple database instance for persistence services. Figure 
 16-1
  
 depicts how this looks when deployed in a public cloud, Amazon Web Services.
  
 590",NA
" The Simple, Scaled Out Architecture","The simple inception architecture described in the previous section is a bare minimum, 
 and is the one with less hassles. If circumstances permit, you may want to live with that 
 minimalist architecture, since it will give you peace of mind. However, if your business is 
 successful with that architecture, that in a sense implies that you are going to need an 
 enhanced architecture for scalability, since a growing business can in no way be served 
 by the above minimalist architecture. The simple, scaled out architecture is shown in 
 Figure 
 16-2
 .
  
  
 Figure 16-2. 
 The simple, scaled out architecture
  
 593",NA
 Architecture to Address the Database Bottleneck,"The improvement you want to bring to the simple, scaled out architecture is required to 
 address the scalability of the database instance too. Oracle Real Application Cluster 
 (RAC) is a cluster database with a shared cache architecture that overcomes the 
 limitations of traditional shared-nothing and shared-disk approaches to provide high 
 scalability and availability to database. In a RAC environment, the database itself is 
 shared across a pool of servers, which means that if any server in the server pool fails, 
 the database continues to run on surviving servers, thus avoiding any single point of 
 failure. Since there are a pool of servers, the combined memory capacity and processing 
 power of the clustered database servers provide high scalability too. RAC is an active- 
 active distributed architecture with shared database storage. The shared storage plays a 
 central role in enabling automatic failover, no data loss, 100% data consistency, and in 
 preventing application downtime.
  
 There is a catch when it comes to a public cloud like AWS. As of this writing, Amazon 
 Web Services does not currently enable Oracle RAC natively on Amazon EC2 or  Amazon 
 RDS. Oracle RAC has the following infrastructure requirements that are not directly 
 available in AWS:
  
 • Shared high-performance storage accessible from all nodes in the 
 cluster
  
 • Multicast-enabled network between all nodes in the cluster
  
 • Separate networks for different types of traffic: client, cluster 
 interconnect, and storage
  
 But the happy news is that there are solutions by third-party providers that allow 
 you to run Oracle RAC on AWS using AWS-native components, such as Amazon EC2, 
 Amazon Elastic Block Store (Amazon EBS), and Amazon VPC. Figure 
 16-3
  depicts a 
 possible architecture approach leveraging Oracle RAC to improve on the simple, scaled 
 out architecture.
  
 596",NA
 Independent Read and Write Scalability to ,NA,NA
Improve Efficiency,"In the RAC-based architecture you saw in the previous section, I discussed how to bring 
 additional redundancy by extending RAC across multiple availability zones. When you 
 do that, you also want to architecturally manage the higher network latencies and 
 comparatively lower network bandwidth between the nodes. The architecture variation 
 depicted in Figure 
 16-4
  shows one such option.
  
 2
  NVMe (non-volatile memory express) is a host controller interface and storage protocol created 
 to accelerate the transfer of data between enterprise and client systems and solid-state drives 
 (SSDs) over a computer’s high-speed Peripheral Component Interconnect Express (PCIe) bus.
  
 3
  Automatic Storage Management (ASM) is a feature provided by Oracle within the Oracle 
 Database from release Oracle 10g (revision 1) onwards. ASM aims to simplify the management 
 of database datafiles, control files, and log files. To do so, it provides tools to manage file systems 
 and volumes directly inside the database, allowing database administrators (DBAs) to control 
 volumes and disks with familiar SQL statements in standard Oracle environments. Thus DBAs do 
 not need extra skills in specific file systems or volume managers (which usually operate at the 
 level of the operating system).
  
 598",NA
 Sharding for Web Scale Architecture,"Having managed to separate the management of write scalability from that of read 
 scalability, it’s yet not time for you to rest and relax. Sooner or later you will start to 
 feel that your separated read nodes or if your business is too successful (like many 
 businesses today), even your write nodes by themselves are putting limitations, many 
 times due to the sheer volume of transactions it has to handle or due to the volume of 
 data it has to manage. This is especially true when enterprises operate globally and 
 open up their applications for global customer use. Many social network applications 
 and messaging applications fall in this category, which are to be web scale. “Divide and 
 rule” is the mantra, and sharding is one such approach. 
  
 Sharding can be applied to a services layer or a data layer. The architecture in 
 Figure 
 16-5
  shows one such concept.
  
  
 Figure 16-5. 
 Data architecture to improve read scalability
  
 601",NA
" Good Architecture, But We Need Better and ",NA,NA
Simpler,"Having seen the different options available with Oracle database as the database 
 solution, let’s consider alternate options! All of the solution templates you saw 
 previously exists to solve different problems at hand, and whether to use them or not 
 is an architectural decision to be made by considering many aspects including the 
 enterprise’s long-term technology strategy. Throughout the book I have been talking 
 about the importance of polyglot (data) architecture and the importance of each 
 microservice governing its own data completely. Going by that, you also want to think 
 about architectures that can provide similar scalability and availability grades but 
 without depending too much on any specific vendor’s costly stack.
  
 602",NA
 Highly Available and Scalable CQRS ,NA,NA
Example in Axon,"Leaving behind the various vendor offerings from the previous section in defining HA 
 templates, you will return to Axon CQRS, which was introduced in Chapter 
 12
 . There you 
 looked at a working code where you completely distribute the different Axon 
 components across JVMs. Since that example was distributed across processes, you can 
 practically distribute them across nodes too; however, you demonstrated the examples 
 with each Axon processor in a single node for simplicity. In the current example, you are 
 going to distribute them into multiple instances of Axon components to validate how to 
 bring redundancy and subsequently HA and scalability to an Axon-based CQRS 
 architecture.",NA
 Design the Sample Scenario,"You are going to follow the same design as in the “Distributed Command and Event 
 Handling” section in Chapter 
 12
 , so I won’t repeat all the explanations. There are two 
 entities in your domain, the order and the product. Users can buy a product, which will 
 create a new order. When a new order is created, the product stock will get depreciated. 
 Just that. Revisit that section to get a detailed overview of the architecture of the 
 business scenario you are going to execute in the example here.
  
 You will extend the deployment architecture of the example in Chapter 
 12
  to bring 
 redundancy. You may want to refer to the section titled “Design a Microservice HA 
 Scenario” in Chapter 
 9
  where you already demonstrated the high availability concepts 
 in Spring Cloud. You will follow a similar deployment topology in the current example; 
 however, to make the overall complexity of the example within a certain limit and to 
  
 603",NA
 Code the Sample Scenario,"The complete code required to demonstrate the simple Axon sample is in folder ch16\ 
 ch16-01. There is no major difference in the code from that of Chapter 
 12
 , so I won’t 
 reproduce it.",NA
 Build and Test the High Availability Scenario,"As the first step, bring up the RabbitMQ server. You may want to refer to Appendix B to 
 get started with RabbitMQ server.
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>D:\Applns\RabbitMQ\rabbitmq_ 
 server-3.6.3\sbin\rabbitmq-server.bat
  
  
 Make sure MySQL is up and running. You may want to refer to Appendix H to get 
 started with MySQL.
  
 First Bring Up MySQL Server 
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysqld --console
  
 605",NA
 Microservice 1: 01-Ecom-web,"First, update the configuration files to suit to your environment:
  
 ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-Instance\01-Ecom-web\ 
 src\main\resources\application.properties 
  
 server.port=8080",NA
Note,NA,NA
 don’t make any changes here.,"Now build and package the executables for the Ecom-web microservice and bring 
 up the server. There is a utility script provided at ch16\ch16-01\Ax2-Multi-Command-
 Multi-Event-Handler-Instance\01-Ecom-web\make.bat.
  
 cd D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\01-Ecom-web 
  
 D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\01-Ecom-web>make 
  
 D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\01-Ecom-web>mvn clean install
  
 607",NA
 Microservice 2: 02-Ecom-,NA,NA
CreateCommandRestController,"The JGroups configuration is provided in the following file:
  
 ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-Instance\02-Ecom-
 CreateCommandRestController\src\main\resources�p_config.xml
  
 However, let’s not worry about the contents of this file too much for 
 now. Update the configuration files to suit to your environment:
  
 ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-Instance\02-Ecom-
 CreateCommandRestController\src\main\resources\application.properties 
 server.port=8082 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
  
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 cd D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\02-Ecom-CreateCommandRestController
  
  D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\02-Ecom-CreateCommandRestController>make 
  
 D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\02-Ecom-CreateCommandRestController>mvn clean install
  
 You can run the 02-Ecom-CreateCommandRestController Axon Spring Boot 
 application in more than one way. The straightforward way is to execute the JAR file via 
 the following commands:
  
 608",NA
 Microservice 3: 03-Ecom-,NA,NA
HandleCommandAndCreateEvent,"Update the configuration files to suit to your environment; see Listing 
 16-1
 .
  
 Listing 16-1. 
 Microservice 3 Configuration (ch16\ch16-01\Ax2-Multi-Command-
 Multi-Event-Handler-Instance\03-Ecom-HandleCommandAndCreateEvent\src\ 
 main\resources\application.properties)
  
 server.port=8084 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 ecom.amqp.rabbit.address= 127.0.0.1:5672 
 ecom.amqp.rabbit.username= guest 
  
 ecom.amqp.rabbit.password= guest 
  
 ecom.amqp.rabbit.vhost=/
  
 609",NA
 Microservice 4: 04-Ecom-EventHandleCore,"Update the configuration files to suit to your environment, as shown in Listing 
 16-2
 .
  
 610",NA
 Microservice 5: 05-Ecom-EventHandlerAudit,"This is the last microservice you want to bring up in this sample. Update the 
 configuration files to suit to your environment, as shown in Listing 
 16-3
 .
  
 Listing 16-3. 
 Microservice 5 Configuration Parameters (ch16\ch16-01\Ax2-
 Multi-Command-Multi-Event-Handler-Instance\05-Ecom-EventHandlerAudit\ 
 src\main\resources\application.properties)
  
 server.port=8088 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword
  
 ecom.amqp.rabbit.address= 127.0.0.1:5672 
 ecom.amqp.rabbit.username= guest 
  
 ecom.amqp.rabbit.password= guest 
  
 ecom.amqp.rabbit.vhost=/ 
  
 ecom.amqp.rabbit.exchange=Ecom-02 
  
 ecom.amqp.rabbit.queue=Ecom-event-history_03
  
 cd D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\05-Ecom-EventHandlerAudit 
  
 D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\05-Ecom-EventHandlerAudit>make 
  
 D:\binil\gold\pack03\ch16\ch16-01\Ax2-Multi-Command-Multi-Event-Handler-
 Instance\05-Ecom-EventHandlerAudit>mvn clean install
  
 612",NA
 Scaling Aggregate Root Entities in Write ,NA,NA
Nodes for AXON CQRS,"The previous section demonstrated how to scale the CQRS architecture in Axon by 
 adding more nodes to handle commands and events. Let’s explore the caveats involved 
 in scaling the write node or the command handling node.",NA
 Concurrently Modify Requests to Clone of Same ,NA,NA
Entity,"In the section titled “Independent Read and Write Scalability to improve Efficiency” 
 you saw the architecture template based on Oracle where there is a single write node 
 or primary database where you route all writes and multiple read nodes or a 
 secondary database to manage queries. You know the reason to favor this kind of 
 architecture:",NA
 Optimistic Locking,"Optimistic locking assumes that multiple transactions can complete without affecting 
 each other, and therefore these transactions can proceed without locking the data 
 resources that they affect. However, before committing, each transaction verifies that 
 no other transaction has modified its data. If the validation conflicts, the committing 
 transaction rolls back.
  
 618",NA
 Conflict Detection and Resolution in Axon,"One of the major advantages of being explicit about the meaning of changes is that you 
 can detect conflicting changes with more precision. Typically, these conflicting changes 
 occur when two users are acting on the same data more or less concurrently. Referring 
 to Figure 
 16-8
 , if Ann and Ria, both looking at a specific version of the data, believe that 
 the status of the last seat they both looked is “Available for Booking,” then they both can 
 decide to make a change to that data. They will both send a command like “on version X 
 of this aggregate, do that,” where X is the expected version of the aggregate on which the 
 changes are to be applied; at least, this is what both Ann and Ria expect. In this case, one 
 of them will have the changes actually applied to the expected version. By the time the 
  
 619",NA
 Example Demonstrating Optimistic ,NA,NA
Locking in Axon CQRS,"In this section, you will look at a working example demonstrating the optimistic 
 locking strategy of Axon. You will set up an environment similar to that shown in 
 Figure 
 16-8
 ; however, you will not deploy in the cloud. Instead you will run in your 
 own PC and also you will have only two instances of the microservices, since if the 
 working can be demonstrated for two microservices it can be assumed to work in 
 scenarios involving more than two instances of the microservice.",NA
 Design the Sample Scenario,"You will simulate two users attempting to modify the same entity concurrently. For 
 that, you will have a simple Axon microservice consisting of a REST Controller and a 
 command handler. The REST Controller can accept POST and PUT requests to create 
 and modify records of the User entity. See Figure 
 16-9
 .
  
 620",NA
 Code the Sample Scenario,"The code is straightforward., but I will show it here for completeness of the example. All 
 the code samples for this section are in folder ch16\ch16-02\Ax2-Cuncurrency-Test. 
  
 First, you will look at the User Entity class. See Listing 
 16-5
 .
  
 Listing 16-5. 
 User Entity Getting Modified Concurrently (ch16\ch16-02\Ax2-
 Cuncurrency-
 Test\src\main\java\com\axon\concurrency�ser\model�ser.java)
  
 import org.axonframework.domain.AbstractAggregateRoot;
  
 @Entity 
  
 @Table(name = ""USER"") 
  
 public class User extends AbstractAggregateRoot<Long> {
  
  @Id
  
  private Long id;
  
  
 @Column(name=""USER_NAM
 E"")
  
  private String userName;
  
  
  @Column(name=""AGE"")
  
  
  private Integer age; 
  
 }
  
  
 You extend the AbstractAggregateRoot to create this basic aggregate entity for you 
 to test concurrent modification.
  
  
 The REST Controller is again simple, with methods to create and modify the User 
 entities. See Listing 
 16-6
 .
  
 Listing 16-6. 
 REST Controller creating Commands (ch16\ch16-02\Ax2-
 Cuncurrency-Test\src\main\java\com\axon\concurrency�ser\web\ 
 UserController.java)
  
 @RestController 
  
 public class UserController {
  
  @Autowired
  
  private CommandGateway 
 commandGateway;",NA
 Build and Test the Sample Scenario,"As the first step, you need to bring up MySQL Server. You may want to refer to Appendix 
 H to get started with MySQL Server.
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysqld --console
  
 Now open a MySQL prompt:
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysql -u root –p
  
 mysql> use ecom01; 
  
 Database changed 
  
 mysql>
  
  
 To start with clean tables, delete any tables with the names you want for 
 your samples:
  
 mysql> drop table user;
  
 Update the configuration files to suit to your environment; see Listing 
 16-8
 .
  
 Listing 16-8. 
 MySQL Configuration (ch16\ch16-02\Ax2-Cuncurrency-
 Test\src\ main\resources\application.properties)
  
 server.port: 8080 
  
 spring.datasource.url=jdbc:mysql://localhost/ecom01 
 spring.datasource.username=root 
  
 spring.datasource.password=rootpassword",NA
Note,NA,NA
 don’t make any changes here.,"You will now build and package the executables for the Concurrency Test 
  
 microservice and bring up two instances of the server. There is a utility script in 
 folder ch16\ch16-02\Ax2-Cuncurrency-Test\make.bat.
  
 cd D:\binil\gold\pack03\ch16\ch16-02\Ax2-Cuncurrency-Test 
  
 D:\binil\gold\pack03\ch16\ch16-02\Ax2-Cuncurrency-Test>make 
  
 D:\binil\gold\pack03\ch16\ch16-02\Ax2-Cuncurrency-Test>mvn clean install
  
 625",NA
 Summary,"Provisioning for HA and scalability is an art as well as an engineering activity. There can 
 be more than one design suitable for a specific scenario, and choosing the right one with 
 future requirements in mind is a challenging task. This chapter covered a few 
 techniques, starting from the simple to more advanced to complex scenarios of HA 
 design. In doing so, you also relooked at the CQRS pattern and dissected core aspects of 
 scaling read and write nodes independently. While scaling read nodes is rather 
 straightforward, the same is not the case when scaling write nodes, since you need to 
 deal with concurrency issues while changing entity states. However, nothing is 
 impossible, and you saw code in action on how to scale write nodes too, utilizing the 
 basic principles of transaction control you learned in Chapter 
 14
 . With this, you have 
 reached yet another milestone in your journey in this book. Accumulating all the 
 knowledge gained thus far, it’s time now to look into more serious code, and you will do 
 so in the next chapter when you look at complete end-to-end enterprise-grade 
 microservices application. Take a break. When you’re ready, start the next chapter.
  
 637",NA
CHAPTER 17,NA,NA
Axon CQRS ,NA,NA
Microservices E-,NA,NA
Commerce,"By now, you have covered selected and basic minimum technical details from multiple 
 frameworks, including but not limited to Spring Boot, Spring Cloud, and Axon CQRS. 
  
 Now let’s see how they fit together so that you can architect and build real-world 
 applications. For this purpose, you will design and build a basic e-commerce web site.
  
 As you can appreciate by now, microservices architecture is not simple or 
  
 straightforward compared to traditional or monolith architecture, so even the little e-
 commerce web site you are going to build in this chapter is non-trivial and requires 
 dedication in terms of time and effort on your part so that all the critical aspects are 
 understood by you. To help you in this objective, I will not repeat any aspect you have 
 already seen and felt in previous chapters like high availability, high scalability, etc. This 
 means you will play around with only a single instance of the microservice. However, 
 nothing limits you from playing with the example in your own way by instantiating 
 more instances of the same microservice.
  
 Secondly, since this chapter will be long, I will cover only a few critical and basic 
 flows. I have omitted other aspects like payment integration and so on. Even though 
 nothing limits you from extending the code to add more features to make it production 
 ready (which by itself is one of the aims of microservices), the current scope of the 
 example in this chapter is minimalistic and I advise you to test the example as is 
  
 prescribed in this chapter in the first pass so that you have a fairly good understanding 
 of what is happening under the hood. You may monkey test it to fail in a subsequent 
 pass of the test.
  
 You are going to explore the following in this chapter:
  
 • A traditional monolithic style architecture for an e-commerce 
 application",NA
Note,NA,NA
 This chapter uses Axon 2 for building the example. In Chapter ,NA,NA
19,NA,NA
", ",NA,NA
we will refactor the same application using a later version of Axon.,NA,NA
 Revisiting a Traditional E-Commerce ,NA,NA
Application,"Let’s start the discussion from the basic requirements for an online e-commerce web 
 site. Once you cover the requirements, you will look at how a typical logical architecture 
 of the basic building blocks will look if you architect it using the traditional or the 
 monolith approach. In the next section, you will look at what changes are required if you 
 rearchitect the design using a microservices-based approach.",NA
 The E-Commerce Business Summarized,"The sample e-commerce enterprise is named ACME Shop. ACME has an online 
  
 presence, and customers or end users can do online shopping at the web site. The ACME 
 back office employees also interact with the same web site to fulfill customer orders.
  
 ACME Shop specializes in selling fashion accessories, and it has classified its product 
 portfolio under different categories called product categories. Under each product 
 category, ACME Shop lists a set of products for sale. When an (anonymous) user accesses 
 the ACME home page, all of the product categories are listed and by default, the products 
 under one of the categories are expanded and listed further. The user can click one of the 
 products to view the product details. The product details also show the 
  
 640",NA
 E-Commerce Architecture Revisited,"A typical monolith architecture for the above described business application is depicted 
 in Figure 
 17-1
 .
  
 641",NA
 The E-Commerce Microservice Application,"In previous chapters, I described the need for microservices-based architecture, so I 
 won’t repeat that information. Instead, let’s relook at the architecture represented in the 
 previous section to see what is to be changed.
  
 It is clear that you need similar or enhanced features, functional as well as non-
 functional, in the new architecture. At the same time, you want to reduce the ill 
 effects of the architecture depicted in the previous section, so let’s do that.
  
 643",NA
 Logical Architecture for a Microservice-,NA,NA
Based E-Commerce Architecture,"It is imperative that the first aspect you take care when refactoring is to separate 
 out functionalities into microservices, as shown in Figure 
 17-3
 .
  
  
 Figure 17-3. 
 E-commerce microservices dependency
  
 There is little or zero direct dependency between microservices; instead, 
  
 microservices communicate with each other through the event-based infrastructure. All 
 of these microservices will be deployed in separate processes, and may or may not be in 
 separate physical nodes too.
  
 644",NA
 The ACID Within the BASE,"Compare the architectures in Figures 
 17-2
  and 
 17-3
  one more time. Careful observation 
 will reveal two notable aspects:
  
 • 
 Replicated read models
 : You can see that inventory data is 
  
 replicated and kept at more than one microservice level. This is to take 
 care of query requirements of data not owned by the host microservice, 
 which is what you saw in detail in the CQRS pattern in Chapter 
 12
 . To 
 make it clear, when product details are displayed, the available stock 
 information too need to be displayed on the screen and this can be 
 done from the inventory materialized view maintained at the Product 
 microservice level.
  
 • 
 Domain affinity for enhanced consistency
 : Figure 
 17-2
  depicts 
 Order and Inventory as two separate domains. However, in the redesign 
 in Figure 
 17-3
  you can see that both of these domain entities are brought 
 together and maintained in same space (process or node). The reason is 
 that you want to have stronger data consistency across the Order and 
 Inventory domain entities.
  
 While you want ACID-similar consistency across these two entities, you want to 
 avoid distributed transactions across nodes. But there is a caveat here: for whatever 
 reason you are attempting to split the monolith into microservices, the same forces are 
 now putting constraints to join them back together at the cost of consistency! While you 
 don’t want to join everything back to attain strongest consistency with zero partitions, 
 let’s keep Order and Inventory for the time being and live with the “ACID within the 
 BASE” scenario.
  
  
 Worry not; you are going to look into a further refactored design where you have 
 true BASE transaction characteristics in Chapter 
 19
  when you look at Axon 3.",NA
 The Design of the E-Commerce Microservices,"The Business Domain Object Model (BDOM) or the Common Information Model (CIM) 
 for the e-commerce application is shown in Figure 
 17-4
 .
  
 645",NA
 Technical Architecture for the ,NA,NA
Microservice-Based E-Commerce ,NA,NA
Architecture,"Having looked at the rationale behind the approach to be taken in architecting the 
 microservices-based e-commerce application, you can arrive at the initial view of the 
 technical architecture, shown in Figure 
 17-5
 .
  
 646",NA
 Design and Code the E-Commerce ,NA,NA
Microservice Application,"Before you get into the design and code, let’s clarify the boundaries within which you are 
 going to understand the example. The scope of this book is limited to microservices in 
 the context of middleware microservices. To build a complete working sample of the e-
 commerce microservices application, you would also want to develop HTML-based 
 screens based on a web framework. All of these elements of the web app are contained 
 in a microservice not shown in Figure 
 17-5
 ; however I will introduce that microservice 
 in the subsequent sections. Detailed review or explanations of building HTML screens 
 and associated web technologies is outside the scope of this book. Readers are advised 
 to refer to other textbooks for detailed explanations on how to build web apps. 
 However, the code provided with the example in building the web app is trivial, so the 
 required parts of the same should be self-explanatory and you can browse through 
 them.
  
 Excluding the web app, there are seven other application microservices, as depicted 
 in Figure 
 17-5
 . Again, I won’t list every Java file within the microservices; instead, I’ll 
 take the significant use cases one by one and explain the server side or the 
 microservices code required for that use case.
  
  
 The complete code for the application is in folder ch17\ch17-01\Ax2-Ecom-No-
 Security.",NA
 Listing Product Categories and Products,"Product categories and products listed under a default selected category are to be 
 shown on the ACME Shop home page. Listing 
 17-1
  shows this portion of the code.
  
 Listing 17-1. 
 ProductCategoryRepository (ch17\ch17-01\Ax2-Ecom-No-
 Security\Ecom-product\src\main\java\com\acme\ecom\product\repository\ 
 ProductCategoryRepository.java)
  
 @RepositoryRestResource(collectionResourceRel = ""categories"", path = 
 ""categories"") 
  
 public interface ProductCategoryRepository extends MongoRepository 
 <ProductCategory, String>  {
  
 }
  
 648",NA
Note,NA,NA
 All of the code for the web application is in the folder ,NA,NA
ch17\ch17-01\ Ax2-Ecom-No-Security\Ecom-,NA,NA
web\src\main\resources\static.,"Next, you should be able to retrieve all of the products under a product category 
 with the code in Listing 
 17-2
 .
  
 Listing 17-2. 
 productsByCategory (ch17\ch17-01\Ax2-Ecom-No-Security\ 
 Ecom-product\src\main\java\com\acme\ecom\product\controller\ 
 ProductRestController.java)
  
 @RestController 
  
 public class ProductRestController {
  
  @RequestMapping(value = ""/productsByCategory"", method = RequestMethod.GET,
  
  produces = { MediaType.APPLICATION_JSON_VALUE })
  
  public ResponseEntity<Resources<Resource<Product>>>getAllProductsByCategory
   
  (@RequestParam(""category"") String category) {
  
  List<Product> products =
  
  
  productRepository.findByProductCategoryName(category); Link 
 links[] = { };
  
  if (products.isEmpty()) {
  
  
  return new ResponseEntity<Resources<Resource<Product>>>(
  
  
  HttpStatus.NOT_FOUND);
  
  }
  
 649",NA
 Listing Product Details Mashed Up with ,NA,NA
Inventory Data,"The next main use case is to retrieve information when a user clicks on a specific 
 product to list the product details. The product details can be retrieved using the code 
 in Listing 
 17-3
 .
  
 Listing 17-3. 
 Get Product Details (ch17\ch17-01\Ax2-Ecom-No-
 Security\ Ecom-
 product\src\main\java\com\acme\ecom\product\controller\ 
 ProductRestController.java)
  
 @RestController 
  
 public class ProductRestController {
  
  @RequestMapping(value = ""/products/{id}"", method = RequestMethod.GET,
  
  
 produces = MediaType.APPLICATION_JSON_VALUE)
  
  public ResponseEntity<Resource<Product>> getProduct(
  
  
  @PathVariable(""id"") String id) {
  
  Product product = productRepository.findOne(id);
  
  if (product == null) {
  
  
  return new ResponseEntity<Resource<Product>>(HttpStatus.NOT_ 
  
 FOUND);
  
  }",NA
 Add a Product to the Cart,"This is a straightforward implementation of adding items selected to order into an org. 
 springframework.cache.CacheManager and retrieving it back, so the code snippets are 
 not shown here. The code is placed in folder ch17\ch17-01\Ax2-Ecom-No-Security\ 
 Ecom-cart.",NA
 Create a New Order,"The use cases you are going to explore from now on are non-trivial since there are 
 multiple directions for the control flow across the microservices. As explained, you are 
 not using any synchronous style intermicroservices communication; instead, you 
 leverage the Axon CQRS event-driven infrastructure to facilitate end-to-end control flow. 
 You will use a representation similar to that shown in Figure 
 17-6
  so that it will be easy 
 to understand the control flow and state changes during the execution of the use cases.
  
 652",NA
 Cancel an Order,"A newly created order, if it’s not being processed in the fulfilment cycle, can be cancelled 
 by the user. Figure 
 17-7
  depicts the various states different entities undergo once the 
 Cancel command is initiated.
  
 662",NA
 Ship an Order Received,"In the “Create a New Order” subsection you the flow of creating a new order. All 
  
 new orders created will be available for the back office admin to take and trigger the 
 fulfilment processing. The first step in order fulfilment is to trigger a shipping command. 
  
 Figure 
 17-8
  illustrates the state changes of various entities during the shipping step.
  
 668",NA
 Deliver a Shipped Order,"You just saw the flow of shipping a new order. All shipped orders will be available 
 further for the back office admin to pick and trigger the last step in the fulfilment cycle, 
 the order delivery. Figure 
 17-9
  illustrates the state changes of various entities during the 
 delivery step.
  
 673",NA
 Delivery Failure for a Shipped Order,"The example application has a provision to simulate a delivery failure for an already 
 shipped order. This event can happen for many reasons, like unable to locate the 
 delivery address, consignment rejected by the customer, a natural calamity en route 
 the consignment delivery, etc. Whatever the case, once the consignment comes back to 
 the warehouse, there is no need to keep the products within that order in that packed 
 state; instead the products can be released to inventory (if found fit, of course) for sales 
 again. You will look at the flows and state changes when such a scenario is simulated in 
 Figure 
 17-10
 .
  
 678",NA
 Retrieve Order History Views,"The order history is required to render all orders of a particular user, that too filtered 
 by status. This is effected by the Order History Mongo Repository. The interesting part 
 is that there is no REST controller in the Order History microservice; instead you use 
 the @RepositoryRestResource. See Listing 
 17-28
 .
  
 Listing 17-28. 
 OrderHistoryRepository (ch17\ch17-01\Ax2-Ecom-No-
 Security\ Ecom-
 history\src\main\java\com\acme\ecom\order\history\repository\ 
 OrderHistoryRepository.java)
  
 @RepositoryRestResource(collectionResourceRel = ""orderHistory"",
  
  path 
 = ""orderHistory"") 
  
 public interface OrderHistoryRepository extends
  
  
  
  MongoRepository<Order, String>  {
  
 683",NA
 Design and Code the E-Commerce ,NA,NA
Microservice Infrastructure,"Apart from the business microservices in the previous section, you also have a set of 
 infrastructure microservices in the example application. The code base for the 
 microservices is straightforward and understandable, and most of them were covered in 
 the “Spring Cloud” section of Chapter 
 8
  so I will not cover them in detail here. You will, 
 however, see how they fit together in the overall architecture.",NA
 Config Server,"The Config Server microservice hosts the configuration parameters for all the other 
 business microservices and infrastructure microservices. Due to this aspect, a healthy 
 running state of the Config Server microservice is required for the startup of all other 
 microservices. You point to this microservice to find the configuration files for all other 
 microservices from a single location. In a production environment, this location will 
 point to a GIT repository so that the configuration files themselves are version 
 controlled.
  
 684",NA
 Service Registry,"You use the Eureka server as the service registry. All of the business microservices 
 register themselves to the service registry during startup, and this registration is 
 labelled with 2 in Figure 
 17-11
 .
  
  
 The code for the Service Registry microservice is again trivial, as shown in 
 Listing 
 17-30
 .
  
 Listing 17-30. 
 Service Registry (ch17\ch17-01\Ax2-Ecom-No-
 Security\Ecom-registry\src\main\java\com\acme\ecom\registry\ 
 EcomServiceRegisterApplication.java)
  
 @SpringBootApplication 
  
 @EnableEurekaServer 
  
 public class EcomServiceRegisterApplication {
  
  public static void main(String[] args) {
  
  
  
  SpringApplication.run(EcomServiceRegisterApplication.class, args);
  
  } 
  
 }",NA
 API Gateway,"You enable Zuul as the API gateway. Any requests from the web app will only hit the 
 API gateway and it’s up to the API gateway to resolve the request target by contacting 
 the service registry and routing the request to the respective service. See Listing 
 17-31
 .
  
 Listing 17-31. 
 Zuul API Gateway (ch17\ch17-01\Ax2-Ecom-No-
 Security\Ecom-
 gateway\src\main\java\com\acme\ecom\gateway\ 
 EcomApiGatewayApplication.java)
  
 @SpringBootApplication 
  
 @EnableZuulProxy 
  
 @EnableDiscoveryClient 
  
 @EnableCircuitBreaker 
  
 @EnableHystrix 
  
 @EnableHystrixDashboard
  
 686",NA
 Configure the E-Commerce ,NA,NA
Microservice Application,"You need to make the required configuration changes in the microservices. You will do 
 so one by one.
  
  1. Microservice 1: Ecom-config. See Listing 
 17-32
 .
  
 Listing 17-32. 
 Ecom-config Microservice Configuration (ch17\ch17-01\Ax2-
 Ecom-No-Security\Ecom-config\src\main\resources\application.yml)
  
 spring:
  
  
  cloud:
  
   
  config:
  
    
  server:
  
     
  git:
  
      
  uri: file://D:/binil/gold/pack03/ch17/ch17-01/Ax2-Ecom-No-
  
     
 Security/config-repo",NA
Note,NA,NA
 Make any changes required for your environment. ensure that the ,NA,NA
config UrI is proper. You will need to later start the config server before ,NA,NA
"any other server. Further, the retrieval of the configuration parameters ",NA,NA
for all other microservices will depend on the proper configuration of this ,NA,NA
Config Server microservice.,693,NA
Note,NA,NA
 Don’t make any changes here.,"3. Microservice 3: Ecom-gateway. See Listing 
 17-34
 .
  
 Listing 17-34. 
 Ecom-gateway Microservice Configuration (ch17\ch17-01\Ax2-
 Ecom-No-Security\config-repo\ecom-gateway.yml)
  
 zuul:
  
  
  routes:
  
   
  ecom-core:
  
    
  path: /core/∗∗
  
    
  service-id: ecom-core
  
   
  ecom-user:
  
    
  path: /customer/∗∗
  
    
  service-id: ecom-user
  
   
  ecom-cart:
  
    
  path: /cart/∗∗
  
    
  service-id: ecom-cart
  
   
  ecom-product:
  
    
  path: /product/∗∗
  
    
  service-id: ecom-product
  
 694",NA
Note,NA,NA
 Don’t make any changes here.,"4. Microservice 4: Ecom-cart. See Listing 
 17-35
 .
  
 Listing 17-35. 
 Ecom-cart Microservice Configuration (ch17\ch17-01\Ax2-Ecom-
 No-Security\config-repo\ecom-cart.yml)
  
 eureka:
  
  
  client:
  
   
  serviceUrl:
  
    
  defaultZone: http://localhost:8761/eureka/",NA
Note,NA,NA
 Don’t make any changes here.,"5. Microservice 5: Ecom-core. See Listing 
 17-36
 .
  
 Listing 17-36. 
 Ecom-core Microservice Configuration (ch17\ch17-01\Ax2-
 Ecom-No-Security\config-repo\ecom-core.yml)
  
 spring:
  
  data:
  
 695",NA
Note,NA,NA
 Make any changes required for your environment.,"6. Microservice 6: Ecom-delivery. See Listing 
 17-37
 .
  
 Listing 17-37. 
 Ecom-delivery Microservice Configuration (ch17\ch17-01\Ax2-
 Ecom-No-Security\config-repo\ecom-delivery.yml)
  
 eureka:
  
  
  client:
  
   
  serviceUrl:
  
    
  defaultZone: http://localhost:8761/eureka/
  
 696",NA
Note,NA,NA
 Make any changes required for your environment.,"7. Microservice 7: Ecom-history. See Listing 
 17-38
 .
  
 Listing 17-38. 
 Ecom-history Microservice Configuration (ch17\ch17-01\Ax2-
 Ecom-No-Security\config-repo\ecom-history.yml)
  
 spring:
  
  
  data:
  
   
  mongodb:
  
    
  uri:mongodb://localhost:27017/ecom
  
 eureka:
  
  
  client:
  
   
  serviceUrl:
  
    
  defaultZone: http://localhost:8761/eureka/
  
 ecom:
  
  
  amqp:
  
   
  rabbit:
  
    
  address: localhost:5672
  
    
  username: guest
  
    
  password: guest
  
    
  vhost: /
  
    
  exchange: Ecom-exchange
  
    
  queue: Ecom-order-histo-queue
  
 697",NA
Note,NA,NA
 Make any changes required for your environment.,"8. Microservice 8: Ecom-product. See Listing 
 17-39
 .
  
 Listing 17-39. 
 Ecom-product Microservice Configuration (ch17\ch17-01\Ax2-
 Ecom-No-Security\config-repo\ecom-product.yml)
  
 spring:
  
  
  data:
  
   
  mongodb:
  
    
  uri: mongodb://localhost:27017/ecom
  
 eureka:
  
  
  client:
  
   
  serviceUrl:
  
    
  defaultZone: http://localhost:8761/eureka/
  
 ecom:
  
  
  amqp:
  
    
  rabbit:
  
     
  address: localhost:5672
  
     
  username: guest
  
     
  password: guest
  
     
  vhost: /
  
     
  exchange: Ecom-exchange
  
     
  queue: Ecom-product-queue
  
   
  product.img.location: D:/binil/gold/pack03/ch17/ch17-01/Ax2-Ecom-No-
   
 Security/Ecom-xtra-setup/productImg/",NA
Note,NA,NA
 Make any changes required for your environment.,698,NA
Note,NA,NA
 Make any changes required for your environment.,"10. Microservice 10: Ecom-user. See Listing 
 17-41
 .
  
 Listing 17-41. 
 Ecom-user Microservice Configuration (ch17\ch17-01\Ax2-
 Ecom-No-Security\config-repo\ecom-user.yml)
  
 spring:
  
  
  datasource:
  
   
  url: jdbc:mysql://localhost/ecom
  
   
  username: root
  
   
  password: rootpassword
  
 eureka:
  
  
  client:
  
   
  serviceUrl:
  
    
  defaultZone: http://localhost:8761/eureka/
  
 699",NA
Note,NA,NA
 Make any changes required for your environment.,"11. Microservice 11: Ecom-web. See Listing 
 17-42
 .
  
 Listing 17-42. 
 Ecom-web (ch17\ch17-01\Ax2-Ecom-No-Security\Ecom-web\ 
 src\main\resources\application.yml)
  
 spring:
  
  
  application:
  
   
  name: ecom-web
  
  
  server:
  
   
  port: 8080
  
  
  ecom:
  
   
  apigateway:
  
   
  url: http://localhost:9000
  
  
 The web app will make use of the above configured API gateway URL to route 
 all requests to the microservices. Don’t make any changes here.",NA
 Set Up the Environment Infrastructure ,NA,NA
for the E-Commerce Microservice ,NA,NA
Application,"Next, you need to set up few infrastructure settings to run the example. Let’s do that 
 too one by one.
  
  1. Set up RabbitMQ Server.
  
 As the first step, you need to bring up RabbitMQ Server. You may 
 want to refer to Appendix B to get started with RabbitMQ server.
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>D:\Applns\RabbitMQ\ 
 rabbitmq_server-3.6.3\sbin\rabbitmq-server.bat
  
  2. Set up MongoDB Server.
  
 Next, make sure MongoDB is up and running. You may want to 
 refer to Appendix A to get started with MongoDB.
  
 700",NA
 Build and Run E-Commerce Microservice ,NA,NA
Application,"You have already seen that there are 11 microservices in the application, so you are 
 advised to use an IDE, preferably Eclipse to better manage the build and run complexity.
  
  
 You need to first set up your 11 microservices projects as Eclipse Projects. Go to the 
 below root folder first:
  
 cd ch17\ch17-01\Ax2-Ecom-No-Security
  
 To generate the Eclipse project files from your POM, execute the following command:
  
 mvn eclipse:eclipse
  
 The Maven Eclipse Plugin is used to generate Eclipse IDE files (∗.classpath, 
 ∗.project, ∗.wtpmodules, and the .settings folder) for use with the project. If your 
 Maven project has dependencies, the eclipse classpath will be synchronized with the 
 current list of Maven dependencies as well as any transitive Maven dependencies.
  
 The Maven project for the sample application consists of a number of aggregated 
 projects with a common root pom, and some of these aggregated projects depend on 
 each other. The eclipse:eclipse goal will configure each dependent project in Eclipse as 
 an Eclipse project dependency, rather than an Eclipse jar dependency. By doing this, 
 changes to code within project A will be available immediately to project B, assuming 
 that project B defines a dependency on project A.
  
 Next, you have to import the project into your Eclipse workspace (from the menu 
 bar, select File 
 ➤
  Impor 
 ➤
  Existing Projects into Workspace). Here the project 
 (directory) should not be located in your workspace because Eclipse might come into 
 trouble, especially if you want to use Eclipse as the scm client.",NA
Note,NA,NA
 You won’t be utilizing the roles added here until you reach Chapter ,NA,NA
18,NA,NA
.,710,NA
 Test the E-Commerce Microservice Use ,NA,NA
Cases,"You can test the application using your preferred browser. You can take two browser 
 windows, one for the normal customer or end user and another for the back office 
 admin.
  
 Typing this URL will bring up the end user screen shown in Figure 
 17-17
 : http:// 
 localhost:8080/. (Refresh your browser if the full content is not loaded as shown in 
 Figure 
 17-17
 ).
  
  
 Figure 17-17. 
 End user home page",NA
 View Product Category and Product Details,"From the product listing shown in Figure 
 17-17
 , select a product to see the product 
 details and available inventory. You can select the required numbers to buy, as shown in 
 Figure 
 17-20
 .
  
  
 Figure 17-20. 
 Select the number of items to order
  
 713",NA
 Add to Cart,"In the next step, you can add the selected product and the selected numbers of the 
 product to the cart, as shown in Figure 
 17-21
 .
  
  
 Figure 17-21. 
 Add the item to the shopping cart
  
  
 You will be able to see the newly added item in the shopping cart icon at the top of 
 the page. You can click the shopping cart icon to display the cart, as shown in Figure 
 17-
 22
 .
  
 714",NA
 User Profile Creation ,"Proceed to order by clicking the “Order now” button in Figure 
 17-22
 . It will ask the 
 user to log in, as shown in Figure 
 17-23
 .
  
  
 Figure 17-23. 
 User login prompt
  
 715",NA
 Create a New Order,"After logging in, you can once again click the shopping cart icon to view your cart, as 
 shown in Figure 
 17-22
 , and proceed to order by clicking the “Order now” button. In the 
 next window, shown in Figure 
 17-26
 , you can see the order details and then confirm the 
 order by clicking the “Proceed to checkout order” button.
  
  
 Figure 17-26. 
 Confirm to create a new order
  
 718",NA
 Ship a New Order,"At the same time, the newly created order will be made available for the back office 
 admin to trigger the fulfilment process. Click the “To Ship” menu (refresh the browser 
 screen to reflect the changes) to see all newly created orders, as shown in Figure 
 17-
 29
 .
  
  
 Figure 17-29. 
 Back office admin to confirm shipment
  
 The back office admin can simulate the shipping step by clicking the Shipped button 
 in Figure 
 17-29
 . Once shipped, the order will get into the next stage of fulfilment; refresh 
 the browser to see it, as show in Figure 
 17-30
 .
  
  
 Figure 17-30. 
 Order shipped, subsequent order delivery in progress
  
 721",NA
 Deliver Successfully the Shipped Order,"Next, the back office admin needs to simulate the next step of fulfilment. He needs to 
 click the Delivered button in Figure 
 17-30
 . A successful delivery of the order will 
 complete the order process workflow. At this stage, the customer will be able to view his 
 order status in the Completed tab, as shown in Figure 
 17-32
 .
  
  
 Figure 17-32. 
 Customer order fulfilled
  
 723",NA
 Delivery Failure for the Shipped Order,"You will now test the “delivery failure” scenario. Create another order, as shown in 
 Figure 
 17-34
 .
  
  
 Figure 17-34. 
 Create a second order
  
 Next, use the back office admin screen shown in Figure 
 17-29
  to simulate the 
 shipping. After successful shipping, the order will be available for the next step, as 
 shown in Figure 
 17-35
 .
  
  
 Figure 17-35. 
 Second order ready for delivery
  
 725",NA
 Cancel a New Order ,"To test the final use case, create a third order, as shown in Figure 
 17-37
 .
  
  
 Figure 17-37. 
 Create a third order
  
 727",NA
 Reverting the Inventory,"As soon as the order is cancelled, if you view the corresponding product detail page, you 
 will see that the inventory has been reverted so that the number of items corresponding 
 to the cancelled order will be available to order again, as seen in Figure 
 17-41
 .
  
  
 Figure 17-41. 
 Inventory reverted due to cancellation
  
 731",NA
 Summary,"In this chapter, you made a lot of progress on your CQRS-based microservices journey. 
 You are now armed with all the basic tools to build enterprise-grade applications of 
 any scale using event- driven microservices. However, there are two caveats:
  
 • You have not implemented security (authentication and 
 authorization) in your e-commerce microservices application.
  
 • You kept two domain entities together to maintain strong data 
 consistency; otherwise, they would have been separated out into 
 their own separate microservices.
  
 You will look into these aspects in the next two chapters.
  
 732",NA
CHAPTER 18,NA,NA
Microservices ,NA,NA
Security,"In the e-commerce microservice application in Chapter 
 17
 , you should have noticed that 
 there are few API methods, especially those in the product category and product 
 services which are freely accessible by anyone; however, for accessing all other 
 microservices you need to be logged in either as the back office admin or as a customer 
 who has already created a user profile in the application. So far, so good, but how secure 
 are those microservices even though you need to be logged in?
  
 Quite different from the traditional monolith architecture where all the services are 
 centrally located, in a microservices architecture there are many nodes or processes 
 where the services are distributed. Even if you consider the API gateway as a single, 
 central, front controller where all your requests are initially intercepted, the API 
 gateway has to then route the requests to the respective microservices, all through the 
 internal network. Similarly, intermicroservice communication also happens through the 
 same internal network. Even if you have secured the gateway access, your data is not 
 free from insider attacks. One way to achieve security is to share the user credential data 
 for all services and authenticate the user on each service before access. Even though this 
 is actually a working approach, it would be a weird idea to distribute the credentials in 
 multiple places. You should have a better approach.
  
 You will look at the concern of microservices security in this chapter. You will 
 also build security features for the example from Chapter 
 17
  so that you learn how 
 this functions in a real-world situation.
  
 You will be exploring the following in this chapter:
  
 • 
  
 OAuth 2.0
  
 733
  
 • 
  
 Client types in the context of OAuth 2.0
  
 • 
  
 Authorization code grand type in OAuth 2.0
  
 • 
  
 JSON Web Token (JWT)
  
 • 
  
 Enabling security for the microservices e-commerce application",NA
 OAuth 2.0 and Microservices,"With Spring Security and its support for OAuth 2.0, you have everything you need to lock 
 down your API gateway as well as your back-end resource servers. You can set it up to 
 automatically propagate your access tokens from one microservice to the other, 
 ensuring that everything stays secure and encrypted along the way. I won’t cover OAuth 
 2.0 in detail, but I will introduce the minimum aspects required so that you can enable 
 security for your example microservices application.",NA
 OAuth 2.0,"Internet Engineering Task Force (IETF) Request for Comments (RFC) No. 6749 defines 
 the OAuth 2.0 as an authorization framework that enables a third-party application to 
 obtain limited access to a HTTP service, either on behalf of a resource owner by 
 orchestrating an approval interaction between the resource owner and the HTTP 
 service, or by allowing the third-party application to obtain access on its own behalf. The 
 OAuth2.0 specification replaces and obsoletes the OAuth 1.0 protocol.",NA
 OAuth 2.0 Roles,"OAuth defines four roles, which are central to the OAuth interactions:
  
 • 
 Resource owner
 : Any entity capable of granting access to a protected 
 resource. When the resource owner is a human, it is referred to as an end 
 user. A resource owner can grant access, and this grant may be used for 
 subsequent and repeated access of the resource.
  
 • 
 Resource server
 : The server hosting the protected resources, capable 
 of accepting and responding to protected resource requests using access 
 tokens. In your microservices scenario, each microservice may become a 
 resource server, if they own protected resources.
  
 • 
 Client
 : This is an application making protected resource requests on 
 behalf of the resource owner and with its authorization. The client, when 
 it makes a request, may do so on behalf of an end user, who may or may 
 not be the resource owner. The term “client” does not imply any 
 particular implementation characteristics (e.g. whether the application 
 executes on a server, a desktop, or other device).
  
 734",NA
 OAuth 2.0 Client vs. User Agent,"Even though OAuth specifies only four roles, you should also note another entity, which 
 is typical in many cases like when you use a browser-based application:
  
 • 
 User agent
 : The user agent is typically the interface with which the 
 end user or the resource owner interfaces with the client program. 
 Sometimes the user agent and the client can be the same.
  
 To understand the last statement, you need to explore a few typical architectures 
 and understand the difference in the level of exposure of the respective client programs 
 to the external world, and you will do so in the next section.",NA
 Trusted vs. Untrusted Clients,"An OAuth client can be classified under two categories, trusted client or untrusted 
 client. Whether a client falls into the trusted or the untrusted category depends based 
 on whether the client has the ability to securely store and transmit information. The 
 concept can be made clear by revisiting the selected architectural models described 
 below.",NA
 Classic Three-Tier Monolith,"A three-tier monolith architecture has a presentation tier, a middle tier, and a database 
 tier. A classic three-tier architecture is a multipage architecture (MPA), which means 
 that every time the user interface needs to display the data or submit data back to 
 server, it has to request a new page from the server and then render it in the web 
 browser. Java Server Pages (JSP) technology is used in creating MPA web apps; however, 
 there are many other technologies that can be used to build MPA. Figure 
 18-1
  depicts a 
 three-tier monolith MPA.
  
 735",NA
 Classical Three-Tier Monolith with HTTP Front,"In a slightly variant architecture, you will place only a HTTP server in the DMZ and all of 
 the other components shown in the DMZ in Figure 
 18-1
  will be moved to within the 
 internal perimeter. Here, the status of the authentication and authorization steps cached 
 or stored in the presentation server is even safer. Figure 
 18-2
  depicts this deployment 
 setup.
  
 737",NA
 Microservices with an API Gateway,"Figure 
 18-3
  depicts the API gateway-based microservices architecture. You saw 
 many variants of this in previous chapters; however, it’s shown here to emphasize 
 the security flow.
  
 739",NA
 Client App with No Server,"Another variant possible is a case where the complete web app (or the SPA), once 
 downloaded, will then continue executing completely from within the browser, in which 
 case there is no presentation tier, or business tier for that matter. In short, there is no 
 server-side counterpart of the web app in the browser. There can be a scenario where 
 the web app will still need to access some protected resource; however, this time it’s 
 from a third party, as shown in Figure 
 18-4
 .
  
 741",NA
 The Authorization Code Grand Types,"There are several grand types defined by OAuth; however, I will limit this discussion to 
 the authorization code grant type, since it is suitable for OAuth clients that can keep their 
 client credentials confidential when authenticating with the authorization server. For the 
 microservices scenarios, the API gateway is the “client” implemented on a secure server. 
  
 As a redirection-based flow, this OAuth client must be able to interact with the user 
 agent of the resource owner and also must be able to receive incoming requests through 
 redirection from the authorization server.
  
 742",NA
 Tokens for Scalable API Invocations,"Having looked at the dynamics of a typical authorization grand type OAuth flow, you 
 should now look at some aspects of this security schema with respect to microservices 
 architecture, especially in terms of scalability and security of the token themselves.",NA
 Session IDs,"Traditionally, authentication has been done as a stateful operation. When the user inputs 
 his or her credentials, the server generates a unique session ID, stores it on the server 
 side, and hands it back to the user as well. Along with each request that needs access to 
 protected resources, this session ID is passed as a request header and the server will 
 always validate the session ID against the actual user credentials on the server side or 
 with the “sessions on play” cache maintained on the server side. This is near to a perfect 
 solution for monolith applications, where for each request response cycle you need no 
 more than one such validation.
  
 For microservices architectures, this can be limiting. Getting data from the central 
 store for every other operation can be troublesome, especially when a single user-side 
 request-response cycle internally spans across a graph or many intermicroservice 
 calls. 
  
 Even when a single user-side request-response cycle internally gets served by a single 
 microservice, the cumulative process of user authentication and authorization DB (or 
 cache) lookup and validations for all the API methods for a high transactional system is 
 cumbersome, so we need smarter design mechanisms.
  
  
 You should notice one good thing about session IDs: session IDs are opaque, 
 meaning no easily decipherable data can be extracted from session IDs by third parties. 
  
 The linkage between the session ID and its inferable data is entirely done server-side.",NA
 Tokens,"Tokens are an alternative to making session ID-based security design smarter. A token is 
 more than an identifier, with meaningful and inferable data too in it. A token, in addition 
 to the session ID, can also contain less sensitive portions of user credentials, like the user 
 name. In this manner, the user or the service requester detail is already available in the 
 request header, so microservices don’t need to do another I/O (input/output) to the 
 database or cache to interpret the requestor. Now you need to look at the authorization 
 part: who has access to what protected resources, and once accessed, what actions can 
  
 746",NA
 JSON Web Token (JWT),"You may create your own token for the convenience described in the previous 
 section or you can adopt a standard that already exists in the industry called JSON 
 Web Token (JWT).
  
 JWT has three distinct parts that are URL encoded for transport:
  
 • 
 Header
 : The header contains the metadata for the token and at a 
 minimum it contains the type of the signature and/or encryption 
 algorithm.
  
 • 
 Claims
 : The claims contain any information that you want signed.
  
 • 
 JSON Web Signature(JWS)
 : The headers and claims are digitally 
 signed using the algorithm specified in the header.
  
 A JWT encodes a series of claims in a JSON object. Some of these claims have specific 
 meanings, while others are left to be interpreted by the users. Some of the claims you 
 commonly encounter are
  
 • Issuer (iss)
  
 • Subject (sub)
  
 • Audience (aud)
  
 • Expiration time (exp)
  
 • Not before (nbf)
  
 • Issued at (iat)
  
 • JWT ID (jti)
  
 747",NA
 Design Security for the ,NA,NA
Example Microservices ,NA,NA
Application,"You will now secure the microservices application from Chapter 
 17
 . The example from 
 Chapter 
 17
  had very basic authentication implemented. This is the reason why you are 
 able to browse through the initial pages starting from the home page of the example 
 application up to the point where you can add items to your shopping cart; however, 
 for the next step of checking out to be permitted, you should have either already been 
 signed in, you should sign in if you already have a profile in the application, or if you do 
 not have a ready profile in the application, you should create one then and sign in. 
  
 Similarly, for the back-office admin to carry out this functionality in the application, he 
 should also be logged in.
  
 However, this logging-in is only one part of the securing process. For a real 
  
 microservices application to be properly secured, you should also take care of the 
 authorization part. Without proper authorization, even if your web app functionality is 
 limited with the help of authentication, the individual microservices APIs themselves are 
 not secure. So if someone from within the same network of the individual microservice is 
 able to access the individual microservice, they can execute functionality. Of course this 
 can be permitted, but only after the required authorization. This is what you are going to 
 enable in your example application.",NA
 Security Architecture for Microservices,"Refer to Figure 
 17-11
  in Chapter 
 17
  for the basic architecture for the example 
  
 microservices application. Let’s enhance it with the extra pieces required to secure the 
 example application end to end. See Figure 
 18-6
 .
  
 750",NA
 Asymmetric Signing and Reference Tokens,"In the “JSON Web Tokens” subsection earlier, you learned about the need to sign JWTs. 
  
 There are two methods of signing, using symmetric keys or asymmetric keys. While 
 in the symmetric scenario you use the same key to encrypt and decrypt the digital 
 signature, in the asymmetric case you use a private and public key combination.
  
 Another concern you face when using tokens is the length of token in complex 
 authorization scenarios. It is quite possible that the size of the JWT can grow to an extent 
 that it will meet technical hurdles to be passed as the header of the request. Moreover, 
 even though you can sign and encrypt a JWT, it is still “sensitive information” and it is 
 best not to make this information float outside your DMZ. Let’s consider the notion of a 
 reference token here. A reference token is a reference to the actual JWT, and you will 
 pass only the reference token beyond your DMZ (or OAuth client).
  
  
 In securing the example microservice application, you will leverage both the above. 
 See Figure 
 18-7
 .
  
 752",NA
 Code Security into Microservices E-,NA,NA
Commerce Application,"This section is a continuation of the code you saw in Chapter 
 17
 . You are advised to go 
 through Chapter 
 17
  before proceeding further with the example application in this 
 chapter. I will incrementally add and explain the critical code required to establish 
 OAuth-based security for this example. The complete code required to demonstrate 
 establishing OAuth security for the example E-Commerce microservices application is in 
 folder ch18\ch18-01\Ax2-Ecom-With-Security.",NA
 Enable the Web App to Handle Security,"As you have already experienced by running the application in Chapter 
 17
 , there are 
 many screens in the web app that you can browse through without actually logging 
 into the system. However, certain actions require the user to be logged in, as follows:
  
 • The web app will ask you to log in before you confirm your order 
 when checking out. See Listing 
 18-1
 .",NA
" Zuul, the API Gateway as OAuth Client","Security is handled using Zuul filters. You use both a pre-filter and a post-filter to Zuul. A 
 Zuul pre-filter is invoked before Zuul delegates the request to the actual resource server. 
 See Listing 
 18-8
 .
  
 Listing 18-8. 
 Zuul Pre-Filter (ch18\ch18-01\Ax2-Ecom-With-Security\ 
 Ecom-
 gateway\src\main\java\com\acme\ecom\gateway\zuul\auth\filter\ 
 AuthenticationPreFilter.java)
  
 @Component 
  
 public class AuthenticationPreFilter extends ZuulFilter {
  
  @Override
  
  public String filterType() {
  
  
  return ""pre"";
  
  }
  
  @Override
  
  public int filterOrder() {
  
  
  return 1;
  
  }
  
  @Override
  
  public boolean shouldFilter() {
  
  
  return true;
  
  }
  
  @Autowired
  
  private CacheManager cacheManager; 
  
 761",NA
 Authorization Server,"The authorization server forms the core of the OAuth process, which will take care of 
 both authentication and authorization.
  
  
 For authentication, you use Spring Security’s web infrastructure, a collection of 
 standard servlet filters. Here’s a quick look at Spring’s definition of terms:
  
 • 
 Principal
 : A user, device, or a system that performs an action.
  
 • 
 Authentication
 : The process of establishing if a principal’s 
 credentials are valid
  
 765",NA
 Resource Server,"Next, you can enable annotation-based security for your resource servers using 
 the @EnableGlobalMethodSecurity annotation on any @Configuration instance. 
 This enables Spring method-level security. See Listing 
 18-12
 .
  
 Listing 18-12. 
 EnableGlobalMethodSecurity (ch18\ch18-01\Ax2-Ecom- 
 With-Security\Ecom-
 core\src\main\java\com\acme\ecom\core\security\ 
 GlobalMethodSecurityConfiguration.java)
  
 @Configuration 
  
 @EnableGlobalMethodSecurity(prePostEnabled = true) 
 public class GlobalMethodSecurityConfiguration   {
  
 }
  
 @EnableGlobalMethodSecurity can take several arguments:
  
 • prePostEnabled: Determines whether Spring Security’s pre and post 
 annotations (@PreAuthorize,@PostAuthorize,..) should be enabled.
  
 • secureEnabled: Determines if Spring Security’s secured annotation 
 (@Secured) should be enabled.",NA
Note,NA,NA
 the certificates and keystores are included with the code example ,NA,NA
"downloads. the creation of them is not covered here, since it can be ",NA,NA
"done following any standard literature on the subject. Further, the code ",NA,NA
for other resource servers (microservices) of the example application is ,NA,NA
"not explained, since it follows a setup similar to that of the ecom-core ",NA,NA
"microservice, which you saw here.",NA,NA
 Set Up the E-Commerce Microservice ,NA,NA
Application,"In this section, you will configure, build, and run the e-commerce microservice 
 application and execute various test cases.",NA
 Configure the Application,"You need to make the required configuration changes in the microservices. The changes 
 you need to make are similar to what was explained in Chapter 
 17
 .",NA
 Set Up the Environment Infrastructure,"Next, you need to set up a few infrastructure settings to run the example. This again 
 is similar to what was explained in Chapter 
 17
 .",NA
 Build and Run the Application,"There are 12 microservices in the application. The methodology to build and run the 
 application again is similar to what was explained in Chapter 
 17
 .
  
  
 In Chapter 
 17
 , you were required to bring up the servers in the below sequence for 
 the first three microservices:
  
 Ecom-config 
  
 Ecom-registry 
  
 Ecom-gateway",NA
 Test the Application,"You can test the application, preferably in the Chrome browser. Here again, you may 
 refer to the steps described in Chapter 
 17
  to test the complete application end to end.",NA
 Summary,"You just explored OAuth 2.0 in general and looked into specific aspects of selected grand 
 types relevant to the microservices context. You also plugged in authentication and 
 authorization into the microservices e-commerce application. This is a major step 
 forward since security is a prime concern in any enterprise-grade application. What is 
 left from the discussions through the previous chapters is a deep dive into the necessity 
 of keeping the order and inventory domains close and together, and you will do so in the 
 next chapter.
  
 777",NA
CHAPTER 19,NA,NA
Axon Microservices ,NA,NA
and BASE ,NA,NA
Transactions,"You saw Axon 2 in Chapter 
 12
 , and you also saw working examples. As mentioned in that 
 chapter, you will be using multiple versions of Axon in this book. In Chapter 
 12
 , you used 
 Axon 2.4.1. It required explicit wiring of components, either through annotations or 
 using XML configurations. Using Axon 2 and demonstrating examples based on it in 
 Chapter 
 12
  was intentional, since I wanted to make the bean wirings explicit so that the 
 concepts were be clear for you as a first time reader of the concepts of CQRS and as a 
 first time user of the Axon framework.
  
 In this chapter, you will look at examples in the later versions of Axon where you will 
 use Spring version 5.0.7.RELEASE, Spring Boot 2.0.3.RELEASE, Axon 3.3.2, or later 
 versions. Here in Axon 3, a lot of explicit bean wirings can be avoided since Axon uses 
 the Spring Application Context to locate specific implementations of building blocks and 
 provide defaults for those that are not there. Axon 3 contains a complete overhaul of the 
 inner workings of Axon mainly because of a lot of new features in Java 7 and 8. To make 
 it clear, if you add a few starter dependencies, that is enough; the Axon Spring Boot 
 components will set up a basic infrastructure for you depending on the other 
 dependencies you have in the project. As an example, if you have JPA, then Axon will 
 automatically configure all the JPA-based components for you. If you have marked @ 
 Aggregate or @Saga on a class, Axon will automatically configure the components 
 necessary to operate these aggregates and sagas. All of this is going to make your life a 
 lot easier, as you will see shortly in the examples.
  
 Further, if you recollect the discussion in the “The ACID Within the BASE” section in 
 Chapter 
 17
 , you kept the order and inventory aggregates together. By using a single 
 resource manager (the MySQL persistence engine) in that case, you avoided distributed 
 transactions. However, you still used ACID-style transactions. Let’s find out if it’s 
 possible to avoid ACID-style transactions if there is a need to do so.",NA
Note,NA,NA
 You may want to refer to the Axon 3 reference documentation,1,NA
 ,NA,NA
and API documentation,2,NA
 while you go through this chapter.,"You will be doing the following in this chapter:
  
 • Understanding how Axon 3 differs from Axon 2, by looking at code
  
 • Migrating the Axon 2 command and event handling in the single JVM 
 example from Chapter 
 12
  to Axon 3
  
 • Migrating the Axon 2 distributed command and event handling 
 example from Chapter 
 12
  to Axon 3
  
 • Migrating the microservices e-commerce application from Chapters 
 17
  
 and 
 18
  to Axon 3
  
 • Removing the ACID-style transactions used in Chapters 
 17
  and 
 18 
 across multiple aggregates
  
 • Meeting Axon 4 so that you have a smooth roadmap to continue with 
 your own exploration after finishing this last chapter of the book
  
 Let’s straightaway get our hands dirty with Axon 3.",NA
 Command and Event Handling in the ,NA,NA
Same JVM Using Axon 3,"You will migrate the example in the “Command and Event Handling in the Same JVM” 
 section in Chapter 
 12
  from Axon 2 to Axon 3. While doing so, I will highlight the main 
 changes.",NA
 Design the Example Scenario,"Since you are building over the same example, you will follow the same design explained 
 in Chapter 
 12
  for this example in Axon 3. Refer to Figure 
 12-1
 .
  
 1
 https://docs.axoniq.io/reference-guide/v/3.3/ 
 2
 https://axoniq.io/apidocs/3.3/
  
 780",NA
 Code the Example Scenario,"All the code examples for this section are in folder ch19\ch19-01. Visit pom.xml to see 
 the explicit mention of the Axon dependency. See Listing 
 19-1
 .
  
 Listing 19-1. 
 Axon 3 Maven Dependency (ch19\ch19-01\Ax3-Commands-
 Events-Same-JVM\pom.xml)
  
 <dependency>
  
  
  <groupId>org.axonframework</groupId>
  
  
  <artifactId>axon-spring-boot-starter</artifactId>
  
  
 <version>3.3.2</version> 
  
 </dependency>
  
  
 The most important class of this example, where you do the setup of all Axon 
 components is EcomAppConfiguration. See Listing 
 19-2
 .
  
 Listing 19-2. 
 EcomAppConfiguration (ch19\ch19-01\Ax3-Commands-Events-
 Same-JVM\src\main\java\com\acme\ecom\EcomAppConfiguration.java)
  
 @Configuration 
  
 public class EcomAppConfiguration {
  
  @PersistenceContext
  
  private EntityManager entityManager;
  
  @Bean
  
  @Qualifier(""productRepository"")
  
  public GenericJpaRepository<Product> productJpaRepository(
  
  
 EventBus eventBus) {
  
  
  SimpleEntityManagerProvider entityManagerProvider =
  
  
  
  new SimpleEntityManagerProvider(entityManager);
  
  
  GenericJpaRepository<Product> genericJpaRepository =
  
  
  
  new GenericJpaRepository<Product>(entityManagerProvider,
   
  
 Product.class, eventBus, ((String id) -> Integer.valueOf(id)));
  
  return 
 genericJpaRepository;
  
  }
  
 781",NA
 Build and Test the Example Scenario,"The complete code required to demonstrate the simple Axon example is in ch19\ch19-
 01. To build and run this example, refer to the instructions provided in the “Build and 
 Test the Example Scenario” subsection in the “Command and Event Handling in the 
 Same JVM” section in Chapter 
 12
 .
  
 The only difference in the process is in the step where you start with clean tables. 
 In the current example, you want to delete any tables with the names you want for 
 your examples, which may be as many as seven:
  
 drop table association_value_entry; 
  
 drop table domain_event_entry; 
  
 drop table ecom_order; 
  
 drop table ecom_product; 
  
 drop table saga_entry; 
  
 drop table snapshot_event_entry; 
  
 drop table token_entry;
  
 drop table ecom_order_view; 
  
 drop table ecom_product_view;
  
 In the corresponding example in Chapter 
 12
 , you deleted only four tables, and there 
 ends the difference. For the rest of the build and run of the example, just follow the 
 instructions from Chapter 
 12
 .
  
 785",NA
 Distributed Command and Event ,NA,NA
Handling Using Axon 3,"Here again you will refactor the same design from the “Distributed Command and 
 Event Handling” section in Chapter 
 12
  to make it adaptable for Axon 3. However, I 
 will introduce a little change by replacing the JGroups connector with Spring Cloud.",NA
 Design Distributed Command Bus with Spring ,NA,NA
Cloud,"As mentioned, refer to the design illustrated in Figure 
 12-4
  in Chapter 
 12
 . You 
 should already be familiar with the distributed command bus there. Unlike the other 
 command bus implementations, the distributed command bus does not invoke any 
 handlers at all. All it does is form a “bridge” between the command bus 
 implementations on different JVMs.
  
 The distributed command bus consists of two components: a command bus 
 connector and a command router. A command bus connector implements the 
  
 communication protocol between the individual JVMs of the microservices whereas the 
 command router chooses a destination for each incoming command. The router defines 
 to which segment of the distributed command bus a command should be routed based 
 on a routing key calculated by a routing strategy. This asserts that two commands with 
 the same routing key will always be routed to the same segment, provided there is no 
 change in the number and configuration of the segments in the runtime.
  
 In the design in Chapter 
 12
 , you used a JGroupsConnector which used JGroups as the 
 underlying discovery and dispatching mechanism. The JGroups-specific 
  
 components for the distributed command bus are in the axon-distributed-
  
 commandbus-jgroups module. Since JGroups handles both discovery of microservice 
 nodes and the communication between them, the JGroupsConnector acts as both a 
 command bus connector and a command router. There is another method for the 
 interconnection and routing between command buses using the Spring Cloud. You can 
 use either Eureka or Consul for this. Since you know how Eureka works from the 
 “Eureka, the Service Registry” section in Chapter 
 8
 , you will use it in your refactored 
 design for Axon 3.
  
 When you use Spring Cloud, the Spring Cloud command router uses the Spring 
 Cloud-specific ServiceInstance.Metadata field to infer and inform all of the microservice 
 nodes in the system of its message routing information. So, to use it in conjunction 
  
 786",NA
 Code the Example Scenario,"The complete code required to demonstrate the distributed Axon example is in ch19\ 
 ch19-02. There were five microservices in the example code in Chapter 
 12
 . You will add 
 a new microservice for the Eureka-based service registry.
  
 788",NA
 Microservice 1: 00-Ecom-registry,"This microservice is a typical Spring Cloud Eureka microservice application without any 
 Axon components, which you have already seen in many previous examples, so I will not 
 discuss it further.",NA
 Microservice 2: 01-Ecom-web,"This microservice is a typical Spring Boot web application, again without any Axon 
 components, so I will not discuss it further.",NA
 Microservice 3: 02-Ecom-,NA,NA
CreateCommandRestController,"Visit pom.xml to see the axon-distributed-commandbus dependency. See Listing 
 19-5
 .
  
 Listing 19-5. 
 Distributed Command Bus Maven Dependency (ch19\ 
 ch19-02\Ax3-Commands-Multi-Event-Handler-Distributed\02-Ecom-
 CreateCommandRestController\pom.xml)
  
 <project>
  
  <parent>
  
  
  <groupId>org.springframework.boot</groupId>
  
  
  <artifactId>spring-boot-starter-parent</artifactId>
  
  
 <version>2.0.3.RELEASE</version>
  
  
  <relativePath/> <!-- lookup parent from repository --> 
 </parent>
  
  <properties>
  
  
  <springframework.version>5.0.7.RELEASE</springframework.version>
  
  
 <axonVersion>3.3.2</axonVersion>
  
  </properties>
  
  <dependencies>
  
  <dependency>
  
  
  <groupId>org.axonframework</groupId>
  
  
  <artifactId>axon-spring-boot-starter</artifactId>
  
  
 <version>${axonVersion}</version>
  
  </dependency>
  
 789",NA
 Microservice 4: 03-Ecom-,NA,NA
HandleCommandAndCreateEvent,"This microservice has to handle any commands created by the 02-Ecom-
  
 CreateCommandRestController microservice and reaching through the distributed 
 command bus from the remote JVM. The only change in code to this microservice from 
 that in Chapter 
 12
  is the introduction of the Spring Cloud command router by 
 annotating the Spring Boot application with @EnableDiscoveryClient as shown in the 
 previous microservice, so I will just display the code here in Listing 
 19-8
  without any 
 detailed explanation.
  
 Listing 19-8. 
 Main Application Class (ch19\ch19-02\Ax3-Commands-Multi- 
 Event-Handler-Distributed\03-Ecom-HandleCommandAndCreateEvent\ 
 src\main\java\com\acme\ecom\EcomHandleCommandAndCreateEvent 
 Application.java)
  
 @EnableDiscoveryClient 
  
 @SpringBootApplication 
  
 public class EcomHandleCommandAndCreateEventApplication {
  
  public static void main(String[] args) {
  
  
  
  SpringApplication.run(
  
  
  
  
  EcomHandleCommandAndCreateEventApplication.class, args);
  
  } 
  
 }",NA
 Microservice 5: 04-Ecom-EventHandleCore,"Again, since you have already followed the corresponding example in Chapter 
 12
 , 
 there is nothing new in this microservice. So I will not do a detailed code walkthrough. 
  
 As the name of the microservice hints, it contains the two main event handlers, 
 OrderEventHandler and ProductEventHandler, and the functionality and code snippets 
 are similar to those in the previous example in this chapter. However, a little update 
 needs to be mentioned here.
  
 792",NA
 Microservice 6: 05-Ecom-EventHandlerAudit,"The functionality and code for this microservice is the same as what you have already 
 seen for the EventHandlerAudit microservice in Chapter 
 12
 . The only change is similar 
 to what was described in the just previous microservice in attaching the processing 
 group, hence I will not repeat that information.
  
 794",NA
 Build and Test the Example Scenario,"Follow the instructions in the “Build and Test the Example Scenario” subsection under 
 the “Distributed Command and Event Handling” section in Chapter 
 12
  to build and test 
 the example. The only difference for this example is that you have one additional 
 microservice, the Eureka Registry. You should build and run the Eureka Registry 
 microservice as a first step. Then follow the steps described in Chapter 
 12
 .",NA
 Axon 3 CQRS Microservices E-Commerce ,NA,NA
with BASE Transactions,"In this section, your primary objective is to migrate the e-commerce example application 
 you built in Chapters 
 17
  and 
 18
  from Axon 2 to Axon 3. There is a secondary objective, 
 which I will define now.
  
 If you recollect the discussion in the “The ACID Within the BASE” section in Chapter 
 17
 , you kept the order and inventory aggregates together. This may or may not be the 
 scenario in real life. Order or booking entities are driven by sales channels and end user 
 activities, whereas inventory or stock entities are driven by end user and supply chain 
 activities. As such, applications or systems or microservices responsible for the 
 management of these entities may not be one and the same, and in many cases they will 
 be separate microservices. By using a single resource manager (the MySQL persistence 
 engine) in the examples in Chapters 
 17
  and 
 18
 , you avoided distributed transactions. 
 However, you still used ACID-style transactions, since both entities were kept close 
 within a single microservice and you leveraged ACID-style local transactions. But what if 
 you want to keep them separate?",NA
 Removing the ACID Knot Between the Order and ,NA,NA
Inventory Domains,"You will first revisit the code from Chapter 
 17
  where you do ACID-style transactions over 
 two aggregate root entities, order and inventory. Listing 
 17-6
  from Chapter 
 17
  is 
 repeated here as Listing 
 19-12
 .
  
 795",NA
Note,NA,NA
 In the “distributed Command and event handling” example in ,NA,NA
Chapter ,NA,NA
12,NA,NA
", you configured the transaction manager whereas in the ",NA,NA
"Axon 3 migrated version of the same example, you haven’t configured ",NA,NA
or used any explicit transaction manager.,"Axon 3 will complain if you deal with more than one aggregate root in a 
 transactional command handler. That means the combination of Listing 
 19-12
  and 
 Listing 
 19-13
  is not easy to get working in Axon 3. Let’s refactor the design of the e-
 commerce microservice Ecom-core a little.
  
 Listing 
 19-14
  reveals the minimum configurations you need to do to wire in the 
 command bus and the event bus in a distributed manner. You attach a transaction 
 manager to the command bus as well as a saga event processor to the event queue in the 
 code.
  
 Listing 19-14. 
 EcomCoreAppConfiguration (ch19\ch19-03\Ax3-Ecom-With- 
 Security\Ecom-core\src\main\java\com\acme\ecom\core\EcomCoreApp 
 Configuration.java)
  
 @Configuration 
  
 public class EcomCoreAppConfiguration {
  
  @Value(""${axon.amqp.exchange}"")
  
  private String rabbitMQExchange;
  
  @Value(""${axon.amqp.queue}"")
  
  private String rabbitMQQueue;
  
  @Bean
  
  public FanoutExchange eventBusExchange() {
  
  
  return new FanoutExchange(rabbitMQExchange, true, false); }
  
 799",NA
 Partitioning the Order and Inventory ,NA,NA
Domains into Separate Microservices,"You saw that the handleNewOrder processing in the OrderCommandHandler shown in 
 Listing 
 19-12
  is equivalent to an ACID-style operation over the order and inventory 
 entities. However, in the refactoring you have done in this chapter, you transitioned the 
 code to the createOrder HTTP POST method in the OrderController shown in Listing 
 19-
 18
 . The processing here is equivalent to BASE style but without any inherent failover 
 characteristics. Having adopted a BASE style transaction across order and inventory 
 aggregate root entities, the order and inventory domains have now become first class 
 citizens to be domain-independent of each other, so they can be separated out into their 
 own microservices too if required.
  
  
 You won’t implement the refactoring shown in Figure 
 19-2
  here. Instead, it’s an 
 exercise for later. The next subsection will provide more hints for doing so.
  
 808",NA
 Sagas for Deterministic Eventual Consistency,"Having adopted a BASE-style transaction across the order and inventory aggregate 
 root entities, the order and inventory domains can now become separate 
 microservices. However, there is a catch! The moment you separate the order and 
 inventory domain into separate microservices, the following are no more collocated:
  
 • OrderCommandHandler, shown in Listing 
 19-16
  
 • InventoryCommandHandler, shown in Listing 
 19-17
  
 • OrderController, shown in Listing 
 19-18
  
 809",NA
 Configure the E-Commerce Microservice ,NA,NA
Application,"Follow the directions in the “Configure the E-Commerce Microservice Application” and 
 “Set Up the Environment Infrastructure” sections in Chapter 
 18
 .",NA
 Build and Run the E-Commerce Microservice ,NA,NA
Application,"Here again, you should follow the directions in the “Build and Run the Secure 
 E-Commerce Microservice Application” section in Chapter 
 18
 . 
  
  
 Having looked at Axon 3, let’s look at Axon 4 in the next section.",NA
 Command and Event Handling in the ,NA,NA
Same JVM Using Axon 4,"In this section, you will migrate the code discussed in the “Command and Event 
 Handling in the Same JVM” section in Chapter 
 12
  to Axon 4. The migrated codebase 
 is placed in folder ch19\ch19-04. You may want to refer to the Axon 4 Reference 
 documentation
 3
  and the Axon 4 API documentation
 4
  while going through the code.
  
 In fact, this code is a refactoring of the code you saw in the “Command and Event 
 Handling in the Same JVM Using Axon 3” section early in this chapter. To build and 
 execute the example, follow the instructions mentioned there with the exception that 
 you have one additional step to do, which you may do as the first step, and that is to set 
 up the Axon server.
  
 The Axon server complements the Axon framework by having knowledge about 
 the different types of messages that are being exchanged, like events sent from one 
 service to one or many other services, commands that are sent to one service to do 
 something, etc. You can download and expand the Axon server libraries from 
 https://download. axoniq.io/axonserver/AxonServer.zip
 .
  
 cd D:\binil\Study\Sites\axon\AxonQuickStart-4.0.3_2019-02-19\AxonServer java -
 jar axonserver-4.0.3.jar
  
 This will bring up the Axon server. Subsequently, follow the instructions mentioned 
 in the “Command and Event Handling in the Same JVM Using Axon 3” section earlier in 
 this chapter.",NA
 Distributed Command and Event ,NA,NA
Handling Using Axon 4,"In this section, you migrate the code discussed in the “Distributed Command and Event 
 Handling” section in Chapter 
 12
  to Axon 4. The migrated codebase is in folder ch19\ 
 ch19-05.
  
 3
 https://axoniq.io/docs/axon-4 
  
 4
 https://axoniq.io/apidocs/4.0/
  
 811",NA
 Summary,"Every end is a new beginning. You have reached the end of this book; however, you have 
 just started your microservices journey. You have demystified few dilemmas around 
 architecture choices and looked into every detail of few concerns, including data 
 consistencies, which you may come across in your everyday life while adopting the 
 microservices architecture. I hope you have liked many parts of this book in the same 
 way I have liked spending the time to get into the intricacies with code to explain them. I 
 have tried to balance the amount of theory and the amount of code to give you a hands- 
 on feel of almost all concepts explained. Last but not least, I have also attempted to 
 cover even the latest release of the Axon CQRS framework through the current chapter. 
 Frameworks will come and go, and specifications will keep evolving, since “change is the 
 only constant thing.” However, the architectural foundations discussed throughout the 
 book will still be relevant and valid—at least that is what I have experienced in my 25 
 years of an IT career. Keep moving, and keep a fast pace.
  
 812",NA
APPENDIX A,NA,NA
"Install, ",NA,NA
"Configure, and ",NA,NA
Run MongoDB,"MongoDB is an open source document database, the server of which is licensed under 
 Free Software Foundation’s GNU AGPL v3.0, which provides high performance, high 
 availability, and automatic scaling. MongoDB is available for download from 
  
 www.mongodb.com/
 .
  
 You will look at the following in this section:
  
  
 • An introduction to MongoDB 
  
  
 How to download, install, and configure MongoDB• 
  
  
 • How to start MongoDB Server
  
  
 • 
  
 How to connect to MongoDB Server
  
 • How to execute 
 basic operations against MongoDB Server 
  
 How to install and use 
 Robomongo, a UI for MongoDB•",NA
 Introducing MongoDB ,"MongoDB is a kind of document database in the sense that a record in MongoDB is a 
 structured document. Since the document is structured, it has a data structure 
 composed of field and value pairs. MongoDB documents follow a structure similar to 
 JSON (JavaScript Object Notation) objects. As values of fields, a MongoDB document 
 may include other documents, arrays, and/or arrays of other documents.",NA
 The MongoDB Document,"Here is a sample MongoDB document so you can understand what it looks like:
  
 {
  
  
  name: ""bob"",
  
  
  class: 2,
  
  
  division: ""B"",
  
  
  subjects: [""english"", ""science"", ""maths""] }
  
 Since a MongoDB document may contain other documents and arrays of other 
 documents, the data structure is extensible. Further, MongoDB documents are 
 synonymous to data types in a programming language",NA
 Install and Configure MongoDB,"In this section, you will download the community edition of MongoDB. You will also 
 install and configure it and then test the installation",NA
 Download MongoDB Community Edition,"MongoDB is available for download at 
 www.mongodb.com/download-center
 . Detailed 
 installation instructions are also available at 
 https://docs.mongodb.com/manual/ 
 tutorial/install-mongodb-on-windows/
 . A MongoDB installation file can be found at 
 www.mongodb.org/downloads
 .
  
 You must have Windows Server 2008 R2, Windows Vista, or later to install 
 MongoDB Community Edition. The .msi installer includes all the software dependencies 
 required for MongoDB and will also automatically upgrade any older version of 
 MongoDB if found installed in your machine. See Figure 
 A-1
 .
  
 814",NA
 Install and Configure MongoDB,"After you download the MongoDB installation file, locate the downloaded MongoDB .msi 
 file in Windows Explorer, which typically is located in the default Downloads folder. 
 Once you double-click the .msi file, a set of screens will appear to guide you through the 
 installation process. Even though you may choose any location, like
  
 C:\Program Files\MongoDB\Server\3.2\
  
  
 I explicitly avoid a location with a space in the path, like the space in Program Files. 
 Hence in my Windows machine, I use the following location:
  
 D:\Applns\MongoDB\Server\3.2.6
  
 815",NA
 Start Using MongoDB,"In this section, you will connect to the installed MongoDB server and carry out basic 
 data operations.
  
 816",NA
 Start and Connect to MongoDB,"You can now start MongoDB by using this command:
  
 D:\Applns\MongoDB\Server\3.2.6\bin\mongod.exe --dbpath D:\Applns\MongoDB\ 
 Server\3.2.6\data
  
 Listing 
 A-1
  shows starting the MongoDB Server.
  
 Listing A-1. 
 Start MongoDB Server
  
 D:\Applns\MongoDB\Server\3.2.6\bin>D:\Applns\MongoDB\Server\3.2.6\bin\ 
 mongod.exe --dbpath D:\Applns\MongoDB\Server\3.2.6\data 
  
 2019-03-02T19:37:34.958+0530 I CONTROL  [initandlisten] MongoDB starting : 
 pid=7632 port=27017 dbpath=D:\Applns\MongoDB\Server\3.2.6\data 64-bit 
 host=tiger 
  
 2019-03-02T19:37:34.959+0530 I CONTROL  [initandlisten] targetMinOS: Windows 
 7/Windows Server 2008 R2 
  
 2019-03-02T19:37:34.959+0530 I CONTROL  [initandlisten] db version v3.2.6 2019-03-
 02T19:37:34.959+0530 I CONTROL  [initandlisten] git version: 
 05552b562c7a0b3143a729aaa0838e558dc49b25 
  
 2019-03-02T19:37:34.960+0530 I CONTROL  [initandlisten] OpenSSL version: OpenSSL 
 1.0.1p-fips 9 Jul 2015 
  
 2019-03-02T19:37:34.960+0530 I CONTROL  [initandlisten] allocator: tcmalloc 2019-
 03-02T19:37:34.960+0530 I CONTROL  [initandlisten] modules: none 2019-03-
 02T19:37:34.960+0530 I CONTROL  [initandlisten] build environment: 2019-03-
 02T19:37:34.960+0530 I CONTROL  [initandlisten]     distmod: 2008plus-ssl 
  
 2019-03-02T19:37:34.960+0530 I CONTROL  [initandlisten]     distarch: x86_64 2019-
 03-02T19:37:34.960+0530 I CONTROL  [initandlisten]     target_arch: x86_64 2019-03-
 02T19:37:34.960+0530 I CONTROL  [initandlisten] options: { storage: { dbPath: 
 ""D:\Applns\MongoDB\Server\3.2.6\data"" } } 
  
 2019-03-02T19:37:34.967+0530 I -        [initandlisten] Detected data files in 
 D:\Applns\MongoDB\Server\3.2.6\data created by the 'wiredTiger' storage engine, so 
 setting the active storage engine to 'wiredTiger'.
  
 817",NA
 Execute Basic Data Manipulations with MongoDB,"In the Windows command prompt where the mongo shell is connected to a running 
 mongod instance, you can query the currently connected database using this command:
  
 db.getName()
  
 818",NA
" Robomongo, A GUI for MongoDB","Robomongo
 1
  is a cross-platform MongoDB management tool that is mongo shell- 
 centric. It embeds the actual mongo shell in a tabbed interface. It provides access to a 
 shell command line as well as a GUI.",NA
 Download and Install Robomongo Community ,NA,NA
Edition,"The Robomongo community edition is available for download at 
 https://robomongo. 
 org/download
 . See Figure 
 A-3
 .
  
 1
  Robomongo is now Robo 3T
  
 822",NA
 Start and Connect to MongoDB Using Robomongo,"You can execute this file to bring up the GUI:
  
 D:\Applns\Robomongo\robomongo-0.9.0-rc9\Robomongo.exe
  
  
 Once the GUI is up, you can connect to the MongoDB server by selecting the 
 Connect button shown in Figure 
 A-4
 .
  
 823",NA
 Execute Basic Data Manipulation with MongoDB ,"The browser pane allows you to select the required collection in the MongoDB and a 
 right click provides many options to do basic data operations. See Figure 
 A-5
 .
  
 824",NA
 Summary ,"This appendix walked you through installing and using MongoDB. You will be using 
 MongoDB extensively for the samples in this book. Refer this appendix when you want to 
 do operations against MongoDB.
  
 825",NA
APPENDIX B,NA,NA
"Install, Configure, ",NA,NA
and Run RabbitMQ ,NA,NA
Cluster,"RabbitMQ is an open source messaging middleware which can run in all major 
 operating systems and with support of development tools for many platforms. Being a 
 message broker, it allows you to send and receive messages, and your messages can be 
 kept in a safe place to live until received by the consumer. RabbitMQ is available for 
 download from 
 www.rabbitmq.com/
 .
  
 You will explore the following in this appendix:
  
 • How to download and install Erlang, a prerequisite to installing 
 RabbitMQ
  
 • How to install and start RabbitMQ Server
  
 • How to enable RabbitMQ management plugins and view the 
 RabbitMQ management console
  
 • How to set up a RabbitMQ cluster with two nodes
  
 • How to shut down and bring up individual nodes in a 
 RabbitMQ cluster",NA
 Introducing RabbitMQ,"The main distinguishing feature of message brokers is the ability to decouple the 
 message producers from the message consumers. As such, producers and consumers 
 can publish and consume messages at their own pace and convenience. Some of the 
 features of RabbitMQ are",NA
 Set Up RabbitMQ,"In this section, you will download and install Erlang and install and configure RabbitMQ 
 and test the installation.",NA
 Download and Install Erlang,"Erlang is a programming language typically used for building massively real-time 
 and highly available systems. Erlang's runtime has built-in support for concurrency, 
 distribution, and fault tolerance. RabbitMQ requires Erlang to be available in the 
 machine, so you will install Erlang and set it up in this section.
  
 Erlang is available for download at 
 www.erlang.org/downloads
 .
  
 Run the Erlang installation file. Even though you may choose any location, like
  
 C:\Program Files\erlx.x.x\
  
  
 I explicitly avoid a location with a space in the path, like the space in Program Files. 
 Hence in my Windows machine, I use the following location:
  
 D:\Applns\Erlang\erl8.0-otp_win64_19.0
  
 Set ERLANG_HOME to the location where you actually put your Erlang installation. 
 It’s D:\Applns\Erlang\erl8.0-otp_win64_19.0\erl8.0 in my machine. The RabbitMQ 
 startup files expect to execute %ERLANG_HOME%\bin\erl.exe:
  
 set ERLANG_HOME=D:\Applns\Erlang\erl8.0-otp_win64_19.0\erl8.0
  
 828",NA
 Install and Configure RabbitMQ,"RabbitMQ is available for download at 
 www.rabbitmq.com/download.html
 . 
 Detailed installation instructions are also available at 
 www.rabbitmq.com/install-
 windows-manual.html
 .
  
 Download the RabbitMQ installation file named rabbitmq-server-windows- -
 3.6.9.zip. From the zip file, extract the folder named rabbitmq_server-3.6.9 into C:\ 
 Program Files\RabbitMQ (or somewhere suitable for application files).
  
 I explicitly avoid a location with a space in the path, like the space in Program Files. 
  
 Hence in my Windows machine, I use the following location:
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.9
  
 By default, the RabbitMQ logs and Mnesia database are stored in the user's 
  
 application data directory, which is C:�sers\binil\AppData\Roaming\RabbitMQ in my 
 machine.
  
 If you have to run RabbitMQ as a manually installed Windows Service, you need to 
 synchronize the Erlang cookies, too; in other words, the Erlang security cookies used by 
 the service account and the user running rabbitmqctl.bat must be synchronized for 
 rabbitmqctl.bat to function. This can be done by ensuring that the Erlang cookie files 
 contain the same string. To do this, copy the .erlang.cookie file from the Windows 
 directory (C:\WINDOWS\.erlang.cookie in my machine) and replace the user’s .erlang.
  
 cookie, which can be found in the user's home directory (C:�sers\binil\.erlang. 
 cookie in my machine).",NA
 Start Using RabbitMQ,"In this section, you will start and connect to the installed RabbitMQ server and carry out 
 basic data operations.
  
 829",NA
 Enable Management Plugin,"The Rabbitmq-management plugin exposes an HTTP-based API for management and 
 monitoring of the RabbitMQ server. It also includes a browser-based UI utility by which 
 basic management can be done. You need to first enable the management plugin that is 
 included in the RabbitMQ distribution:
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>D:\Applns\RabbitMQ\rabbitmq_ 
 server- 3.6.3\sbin\rabbitmq-plugins enable rabbitmq_management
  
  
 After starting the RabbitMQ (explained in next section), you can view the Web UI at 
 the default URL of 
 http://server-name:15672/
 .",NA
 Start RabbitMQ Server,"You can now start RabbitMQ Server by using this command:
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>D:\Applns\RabbitMQ\rabbitmq_ 
 server- 3.6.3\sbin\rabbitmq-server.bat
  
 Listing 
 B-1
  shows the results.
  
 Listing B-1. 
 Start RabbitMQ Server
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>D:\Applns\RabbitMQ\rabbitmq_ 
 server- 3.6.3\sbin\rabbitmq-server.bat
  
  RabbitMQ 3.6.3. Copyright (C) 2007-2016 Pivotal Software, Inc.
  
  ##  ##      Licensed under the MPL.  See http://www.rabbitmq.com/
  
  ##  ##
  
  ##########  Logs: 
 C:/Users/binil/AppData/Roaming/RabbitMQ/log/RABBIT~1.LOG ######  ##        
 C:/Users/binil/AppData/Roaming/RabbitMQ/log/RABBIT~2.LOG ##########
  
  
  Starting broker...
  
  completed with 6 plugins.
  
 830",NA
 View RabbitMQ Management Console,"You can now connect to the above started RabbitMQ server using your favorite web 
 browser and view the RabbitMQ management console (see Figure 
 B-1
 ):
  
 http://127.0.0.1:15672
  
  
 Figure B-1. 
 RabbitMQ management console login
  
 You can log in to the management console using the default credentials
  
 Username: guest 
  
 Password: guest
  
 831",NA
 Set Up a RabbitMQ Cluster,"A RabbitMQ cluster is a grouping of one or several Erlang nodes, with each node running 
 the RabbitMQ application instance and sharing users, virtual hosts, queues, exchanges, 
 bindings, and other runtime parameters.",NA
 Configure RabbitMQ Cluster,"Explained here is how to set up a two-node RabbitMQ cluster quickly. You may want to 
 create two scripts in the sbin folder of your RabbitMQ installation, as shown:
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin\rabbitmq-server1.bat 
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin\rabbitmq-server2.bat
  
 832",NA
Note,NA,NA
" You may want to replace the hostname, which is tiger in the ",NA,NA
"above scripts, with the name of your host.",833,NA
 Bring Up the RabbitMQ Cluster,"Assuming you have only created the required scripts mentioned in the previous section, 
 and have not started any server yet, you can now bring up the RabbitMQ cluster by 
 executing following commands in the same order in separate command windows:
  
 cd D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin 
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>rabbitmq-server1
  
 Listing 
 B-2
  shows the results.
  
 Listing B-2. 
 Start Node 1 of RabbitMQ Cluster
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>rabbitmq-server1
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>set RABBITMQ_NODE_PORT=5672
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>set 
 RABBITMQ_NODENAME=rabbit1
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>set 
 RABBITMQ_SERVICE_NAME=rabbit1
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>set RABBITMQ_SERVER_START_ 
 ARGS=-rabbitmq_management listener [{port,15672}]
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>REM rabbitmq-server -detached
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin>rabbitmq-server
  
  RabbitMQ 3.6.3. Copyright (C) 2007-2016 Pivotal Software, Inc.
  
  ##  ##      Licensed under the MPL.  See http://www.rabbitmq.com/
  
  ##  ##
  
  ##########  Logs: C:/Users/binil/AppData/Roaming/RabbitMQ/log/rabbit1.log 
 ######  ##        C:/Users/binil/AppData/Roaming/RabbitMQ/log/RABBIT~3.
  
 LOG
  
  
  ##########
  
   
  Starting broker...
  
  completed with 6 plugins.
  
  
 The management console to instance with name rabbit1 can be viewed pointing 
 your browser to 
 http://127.0.0.1:15672/
 . See Figure 
 B-3
 .
  
 834",NA
 Restart a RabbitMQ Cluster,"When the entire cluster is brought down, the last node to go down must be the first 
 node to be brought online. If this doesn't happen, the nodes will wait 30 seconds for 
 the last disc node to come back online, and fail afterwards. You may refer to RabbitMQ 
 documentation online for further details.
  
  
 To restart a node (rabbit2) in your cluster, you can use the script named rabbitmq- 
 cluster2.bat, which you have already seen. To restart rabbit1, use rabbitmq-cluster1.bat:
  
 D:\Applns\RabbitMQ\rabbitmq_server-3.6.3\sbin\rabbitmq-cluster1.bat 
  
 call rabbitmqctl -n rabbit1 stop_app 
  
 call rabbitmqctl -n rabbit1 join_cluster rabbit2@tiger 
  
 call rabbitmqctl -n rabbit1 start_app 
  
 call rabbitmqctl -n rabbit2 set_policy ha-all ""^.∗"" ""{""""ha-mode"""":""""all""""}""
  
 840",NA
 Connect to a RabbitMQ Cluster from a Client,"A client can connect to any single node within a cluster. In the event that this node fails 
 and the rest of the cluster survives, then the client should notice the closed connection 
 and should explicitly reconnect to some surviving member of the cluster. I don’t advise 
 baking in hostnames or IP addresses into client applications, since this is an inflexible 
 approach. Instead, the recommended approach is to adopt any of the below 
 abstractions:
  
 • Use a dynamic DNS service which has a very short TTL configuration.
  
 • Use a plain TCP load balancer.
  
 • Use some sort of mobile IP achieved with a pacemaker or similar 
 technology.
  
 Refer to Appendix C where I explain how to set up a TCP load balancer with Nginx. 
 If you use such a TCP load balancer in between your RabbitMQ cluster and the client 
 program, in the event that one of the nodes in the cluster fails and the rest of the 
 cluster survives, then the client needn't notice the closed connection and will be routed 
 to any surviving member of the cluster implicitly.",NA
 Summary,"RabbitMQ is a reliable and persistent message queue server which can be configured in 
 High Availability mode with multiple nodes in a cluster. I use RabbitMQ for many code 
 demonstrations in this book. In some of the code demonstrations, I use RabbitMQ only 
 as a single-node server; however, in all those scenarios RabbitMQ can be configured in a 
 cluster to test the samples.
  
 841",NA
APPENDIX C,NA,NA
"Install, Configure, ",NA,NA
and ,NA,NA
Run Nginx Reverse ,NA,NA
Proxy,"Nginx is an HTTP and reverse proxy server which can also play as a mail proxy server or 
 as a generic TCP/UDP proxy server. Basic HTTP server features include serving static 
 and index files. Nginx also supports keep-alive and pipelined connections. TCP/UDP 
 proxy server features include generic proxying of TCP and UDP as well as load balancing 
 and fault tolerance. Go to 
 https://nginx.org
  for more information.
  
 I cover the following in this appendix:
  
 • How to install and start using Nginx
  
 • How to set up Nginx as an HTTP reverse proxy
  
 • How to set up Nginx as a TCP reverse proxy",NA
 Install Nginx,"In this section, you will download, install, and configure Nginx and test the installation. 
 Nginx is available for download at 
 https://nginx.org/en/download.html
 .
  
 Save the installation archive file to a suitable location in your hard disk first and 
 then extract the archive to a location of your choice. Even though you may choose any 
 location, like
  
 C:\Program Files\nginx\
  
  
 I explicitly avoid a location with a space in the path, like the space in Program Files. 
 Hence in my Windows machine, I use the following location:",NA
 Start Using Nginx ,"You can now start Nginx  Server by using the following command, shown in Figure 
 C-1
 :
  
 D:\Applns\nginx\nginx-1.10.1>nginx
  
  
 Figure C-1. 
 Start Nginx Server
  
  
 Once Nginx is started, it can be controlled by invoking the executable with the -s 
 parameter, as in
  
 nginx -s flag
  
 where flag may be one of the following:
  
  
 • 
  
 Stop: Forceful shutdown
  
  
 • 
  
 Quit: Graceful shutdown
  
  
 • 
  
 Reload: Reload the configuration file
  
 • 
  
 Reopen: Reopen the log files",NA
 Start Using Nginx as Reverse Proxy ,"Nginx is frequently used for setting up as a reverse proxy server. When set as a 
 reverse proxy server, Nginx receives requests, passes them to the proxied servers, 
 retrieves responses from the proxied servers, and sends them back to the clients.
  
 Configurations in Nginx are effected in the nginx.conf file located in the conf path.
  
 844",NA
 Configure HTTP Reverse Proxy,"An HTTP reverse proxy can be set up in Nginx to proxy requests with the HTTP protocol. 
 Relevant sections in nginx.conf for setting up an HTTP proxy are shown in Listing 
 C-1
 .
  
 Listing C-1. 
 Nginx HTTP Reverse Proxy Configuration
  
 http {
  
  upstream myapp1 {
  
  
  server localhost:8081;
  
  
  server localhost:8082;
  
  }
  
  server {
  
  listen       8080;
  
  server_name  localhost;
  
  location / {
  
  
  proxy_pass http://myapp1;
  
  }
  
  }
  
  
 Now, an HTTP request similar to URL pattern http://localhost:8080 will be 
 proxied to both of the following URLs in a load-balanced fashion:
  
 http://localhost:8081 
  
 http://localhost:80802",NA
 Configure TCP Reverse Proxy,"A TCP reverse proxy can be set up in Nginx to proxy requests with the TCP protocol. 
 Relevant sections in nginx.conf for setting up a TCP proxy are shown in Listing 
 C-2
 .
  
 845",NA
 Summary,"The reverse proxy setup of Nginx can be really useful in load balancing external 
 requests to microservices. Hence I use Nginx to demonstrate many scenarios in this 
 book.
  
 846",NA
APPENDIX D,NA,NA
cURL and Postman,"cURL is a command line tool for getting or sending files using the URL syntax. cURL 
 supports a range of common Internet protocols like HTTP, HTTPS, FTP, FTPS, SCP, SFTP, 
 TFTP, and LDAP, out of which HTTP is of interest for our discussions in this book.
  
  
 Postman is a UI-based app that can be used to carry out all HTTP actions in an easier 
 manner. I will introduce this app, too.
  
 The “Performing Data Operations Using Spring Boot and MongoDB” section in 
 Chapter 
 7
  introduced a sample Spring Boot application. You used Spring Data REST 
 there to create implementations of the MongoDB repository interface automatically. 
 Then Spring Boot directed Spring MVC to create RESTful endpoints at /products and / 
 categories. I will assume that this sample is built and is up and running so that you can 
 perform the basic operations of cURL and Postman using this sample.
  
 I will cover the following in this appendix:
  
 • How to use cURL for HTTP operations
  
 • How to use Postman for HTTP operations",NA
 cURL Operations for HTTP,"Basic cURL operations involve typing curl at the command line, followed by the URL of 
 the output to retrieve. For example, to retrieve the microservices.io homepage, type
  
 curl www.microservices.io
  
 cURL defaults to displaying the output it retrieves from the URL to the standard 
 output specified on the system, normally the terminal window (in Mac). So running the 
 above command will, on most systems, display the 
 www.microservices.io
  source-code 
 web page in the terminal window.
  
 © Binildas Christudas 2019 
  
 847
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_23",NA
 HTTP GET to Retrieve an Entity,"You can use cURL to get a first glimpse of what the server's API endpoint has to offer 
 by issuing the command shown in Listing 
 D-1
 .
  
 Listing D-1. 
 HTTP GET using cURL
  
 binils-MacBook-Pro:~ mike$ curl http://localhost:8080 
  
 {
  
  
  ""_links"": {
  
  
  
  ""categories"": {
  
  
  
  
  ""href"": ""http://localhost:8080/categories{?page,size,sort}"",
  
  
  
  ""templated"": true
  
  
  
  },
  
  
  
  ""products"": {
  
  
  
  
  ""href"": ""http://localhost:8080/products{?page,size,sort}"",
  
  
  
  ""templated"": true
  
  
  
  },
  
  
  
  ""profile"": {
  
  
  
  
  ""href"": ""http://localhost:8080/profile""
  
  
  
  }
  
  
  } 
  
 }
  
 The response says there is a products link located at http://localhost:8080/ 
 products. It has some options such as ?page, ?size, and ?sort. You can check other 
 URLs like
  
 binils-MacBook-Pro:~ mike$ curl http://localhost:8080/ profile 
  
 binils-MacBook-Pro:~ mike$ curl http://localhost:8080/products/search
  
  
 If there is corresponding data available in the backing database, you can also fire 
 custom queries similar to
  
 binils-MacBook-Pro:~ mike$ curl  http://localhost:8080/products/search/findB 
 yProductCategoryName?productCategory=Mobile
  
 848",NA
 HTTP POST to Create an Entity,"You can now create a few product instances, as shown in Listing 
 D-2
 .
  
 Listing D-2. 
 HTTP POST using cURL
  
 binils-MacBook-Pro:~ mike$ curl -i -X POST -H ""Content-Type:application/ json"" -d 
 '{""name"":""Giomi"", ""code"":""GIOME-KL"", ""title"":""Giome 10 inch gold"", ""imgUrl"":""giome.jpg"", 
 ""price"":11000.0, ""productCategoryName"":""Mobile""}' http://localhost:8080/products 
  
 HTTP/1.1 201 
  
 Location: http://localhost:8080/products/595ce0f073ed92061ca85665 
  
 Content-Type: application/hal+json;charset=UTF-8 
  
 Transfer-Encoding: chunked 
  
 Date: Wed, 05 Jul 2017 12:52:00 GMT
  
 {
  
  
  ""name"" : ""Giomi"",
  
  
  ""code"" : ""GIOME-KL"",
  
  
  ""title"" : ""Giome 10 inch gold"",
  
  
  ""description"" : null,
  
  
  ""imgUrl"" : ""giome.jpg"",
  
  
  ""price"" : 11000.0,
  
  
  ""productCategoryName"" : ""Mobile"",
  
  
  ""_links"" : {
  
   
  ""self"" : {
  
    
  ""href"" : ""http://localhost:8080/products/595ce0f073ed92061ca85665""
  
  
  },
  
   
  ""product"" : {
  
    
  ""href"" : ""http://localhost:8080/products/595ce0f073ed92061ca85665""
  
  
  }
  
  
  } 
  
 }
  
 849",NA
 HTTP PUT to Replace an Entity,"If you wish to replace an entire group, use HTTP PUT. The server may opt to create a new 
 group and throw the old one out, so the ids may remain the same. But the client should 
 assume that he gets an entirely new item, based on the server's response.
  
  
 In the case of a PUT request, the client should always send the entire resource, 
 having all the data that is needed to create a new item, as shown in Listing 
 D-4
 .
  
 Listing D-4. 
 HTTP PUT Using cURL
  
 binils-MacBook-Pro:~ mike$ curl -i -X PUT -H ""Content-Type:application/ json"" -d 
 '{""name"":""Giomi-New"", ""code"":""GIOME-KL-NEW"", ""title"":""Giome New 10 inch gold"", 
 ""imgUrl"":""giomenew.jpg"", ""price"":15000.0, ""productCategoryName"" :""Mobile""}' 
 http://localhost:8080/products/595ce0f073ed92061ca85665 
  
 HTTP/1.1 200 
  
 Location: http://localhost:8080/products/595ce0f073ed92061ca85665 
  
 Content-Type: application/hal+json;charset=UTF-8 
  
 Transfer-Encoding: chunked 
  
 Date: Wed, 05 Jul 2017 12:53:27 GMT
  
 {
  
  
  ""name"" : ""Giomi-New"",
  
  
  ""code"" : ""GIOME-KL-NEW"",
  
  
  ""title"" : ""Giome New 10 inch gold"",
  
  
  ""description"" : null,
  
  
  ""imgUrl"" : ""giomenew.jpg"",
  
  
  ""price"" : 15000.0,
  
  
  ""productCategoryName"" : ""Mobile"",
  
  
  ""_links"" : {
  
   
  ""self"" : {
  
    
  ""href"" : ""http://localhost:8080/products/595ce0f073ed92061ca85665""
  
  
  },
  
 851",NA
 HTTP PATCH to Modify an Entity,"If you wish to update an attribute, like the status, which is an attribute of a group that 
 can be set, use PATCH. An attribute such as status is often a good candidate to limit to a 
 whitelist of values, but in Listing 
 D-6
  you use PATCH on the price attribute.
  
 Listing D-6. 
 HTTP PATCH Using cURL
  
 binils-MacBook-Pro:~ mike$ curl -i -X PATCH -H ""Content-Type:application/ json"" -d 
 '{""price"":15000.50}' http://localhost:8080/products/595ce0f073ed92 061ca85665 
  
 HTTP/1.1 200 
  
 Content-Type: application/hal+json;charset=UTF-8 
  
 Transfer-Encoding: chunked 
  
 Date: Wed, 05 Jul 2017 12:54:49 GMT
  
 {
  
  ""name"" : ""Giomi-New"",
  
  ""code"" : ""GIOME-KL-NEW"",
  
  ""title"" : ""Giome New 10 inch gold"",
  
  ""description"" : null,
  
 853",NA
 HTTP DELETE to Delete an Entity,"The same entity you can delete using the DELETE command, as shown in Listing 
 D-7
 .
  
 Listing D-7. 
 HTTP DELETE Using cURL
  
 binils-MacBook-Pro:~ mike$ curl -i -X DELETE http://localhost:8080/products 
 /595ce0f073ed92061ca85665 
  
 HTTP/1.1 204 
  
 Date: Wed, 05 Jul 2017 12:55:40 GMT
  
 Another query will confirm that the entity is in fact deleted! See Listing 
 D-8
 .
  
 Listing D-8. 
 Using cURL to View the Effect of HTTP PUT
  
 binils-MacBook-Pro:~ mike$ curl http://localhost:8080/products {
  
  
  ""_embedded"" : {
  
   
  ""products"" : [ ]
  
  
  },
  
  
  ""_links"" : {
  
   
  ""self"" : {
  
    
  ""href"" : ""http://localhost:8080/products{?page,size,sort}"",
  
  
  
  ""templated"" : true
  
 854",NA
 Postman for HTTP Operations,"Postman is a Google Chrome app for interacting with HTTP APIs. It presents you with a 
 friendly GUI for constructing requests and reading responses. The app is available from 
 www.getpostman.com/
 . As of this writing, the Postman app is available for the Mac, 
 Windows, and Linux platforms.",NA
 HTTP GET Using Postman to Retrieve an Entity,"Once the app is installed, you will want to test all HTTP actions against it. Here again I 
 refer back to Chapter 
 7
  where I introduced a sample Spring Boot application. I also 
 refer to Figure 
 7-4
 , which shows the execution of the GET action on the link http:// 
 localhost:8080/profile/products using Postman.",NA
 Summary,"Both cURL and Postman are great utilities for quickly interacting with REST endpoints 
 and performing basic HTTP operations. You will be using them extensively while 
 executing the samples in this book.
  
 855",NA
APPENDIX E,NA,NA
Apache TCPMon,"Apache TCPMon is a utility that allows traffic, especially HTTP traffic messages, to be 
 viewed and resent. It is useful as a debug tool so you can look into what is being passed 
 through the wire between a client and a server, or for that matter even between two 
 microservices. It was originally part of Axis1 and now stands as an independent project. 
 Go to 
 https://ws.apache.org/tcpmon/
  for more information.
  
 I cover the following in this appendix:
  
 • How to install and start TCPMon
  
 • How to set up TCPMon as a proxy",NA
 Install TCPMon,"In this section, you will download, install, and configure TCPMon and test the 
 installation. TCPMon is available for download at 
 https://ws.apache.org/tcpmon/ 
 download.cgi
 .
  
 Save the installation archive file to a suitable location on your hard disk first and 
 then extract the archive to a location of your choice. Even though you may choose any 
 location, like
  
 C:\Program Files\tcpmon\
  
  
 I explicitly avoid a location with a space in the path, like the space in Program Files. 
 Hence in my Windows machine, I use the following location:
  
 D:\Applns\apache\TCPMon\tcpmon-1.0-bin
  
 © Binildas Christudas 2019 
  
 857
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_24",NA
 Start Using TCPMon,"You can bring up TCPMon by going into the build folder of the TCPMon extracted folder 
 (shown in Figure 
 E-1
 ):
  
 cd D:\Applns\apache\TCPMon\tcpmon-1.0-bin\build 
 D:\Applns\apache\TCPMon\tcpmon-1.0-bin\build>tcpmon
  
  
 Figure E-1. 
 Bring up TCPMon",NA
 Set Up TCPMon as a Proxy,"TCPMon can act as a proxy. To set TCPMon in proxy mode, just select the proxy option 
 from the radio buttons and configure the host and port towards which the calls are to be 
 proxied.
  
 858",NA
 Summary,"TCPMon is a nice utility to inspect HTTP requests and responses. You can install and 
 keep it ready on your machine so that it's easy for you to quickly proxy HTTP 
 requests and responses through TCPMon and inspect the contents of the messages.
  
 860",NA
APPENDIX F,NA,NA
ActiveMQ,"Apache ActiveMQ is an open source messaging and integration patterns server. 
  
 ActiveMQ is fast and supports many cross-language clients and protocols, and it comes 
 with easy-to-use enterprise integration patterns and many advanced features. ActiveMQ 
 fully supports JMS 1.1 and J2EE 1.4 and is released under the Apache 2.0 License. 
 ActiveMQ is available for download from 
 http://activemq.apache.org/
 .
  
 The main distinguishing feature of ActiveMQ is its support for a variety of cross- 
 language clients and protocols including Java, C, C++, C#, Ruby, Perl, Python, and 
 PHP. ActiveMQ supports the following protocols, among others:
  
 • OpenWire for high performance clients in Java, C, C++, and C#
  
 • Stomp support so clients can be written easily in C, Ruby, Perl, 
 Python, PHP, ActionScript/Flash, and Smalltalk to talk to ActiveMQ as 
 well as any other popular message broker
  
 • AMQP v1.0 support
  
 • MQTT v3.1 support allowing for connections in an IoT environment",NA
 Install and Configure ActiveMQ,"ActiveMQ is available for download at 
 http://activemq.apache.org/download.html
 . 
 Detailed installation instructions are also available at 
 http://activemq.apache.org/ 
 getting-started.html#GettingStarted-InstallationProcedureforWindows
 . 
  
  
 Download the ActiveMQ installation file named apache-activemq-5.13.3-bin.zip. 
 From the zip file, extract the folder named apache-activemq-5.13.3 into C:\Program 
 Files\ActiveMQ (or somewhere suitable for application files).
  
 © Binildas Christudas 2019 
  
 861
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_25",NA
 Start Using ActiveMQ,"You can start ActiveMQ Server via the following command:
  
 cd D:\Applns\apache\ActiveMQ\apache-activemq-5.13.3\bin 
  
 D:\Applns\apache\ActiveMQ\apache-activemq-5.13.3\bin>activemq start
  
 Listing 
 F-1
  shows ActiveMQ getting started.
  
 Listing F-1. 
 Start ActiveMQ Server
  
 D:\Applns\apache\ActiveMQ\apache-activemq-5.13.3\bin>activemq start 
  
 Java Runtime: Oracle Corporation 1.8.0_45 D:\Applns\oracle\jdk\jdk1.8.0_45\ jre 
  
 ...
  
 ACTIVEMQ_HOME: D:\Applns\apache\ActiveMQ\apache-activemq-5.13.3\bin\..
  
 ACTIVEMQ_BASE: D:\Applns\apache\ActiveMQ\apache-activemq-5.13.3\bin\.. 
 ACTIVEMQ_CONF: D:\Applns\apache\ActiveMQ\apache-activemq-5.13.3\bin\..\conf 
 ACTIVEMQ_DATA: D:\Applns\apache\ActiveMQ\apache-activemq-5.13.3\bin\..\data 
 Loading message broker from: xbean:activemq.xml
  
  INFO |  Refreshing org.apache.activemq.xbean.XBeanBrokerFactory$1@62ee68d8: 
  
 startup date [Wed Mar 06 13:06:42 IST 2019]; root of context 
  
 hierarchy
  
  INFO |  Using Persistence Adapter: KahaDBPersistenceAdapter[D:\Applns\ 
  
 apache\ActiveMQ\apache-activemq-5.13.3\bin\..\data\kahadb]
  
  INFO | KahaDB is version 6
  
  INFO | Recovering from the journal @4:13937439
  
  INFO | Recovery replayed 28377 operations from the journal in 1.604 seconds.
  
  INFO |  PListStore:[D:\Applns\apache\ActiveMQ\apache-activemq-5.13.3\ 
  
 bin\..\data\localhost\tmp_storage] started
  
  INFO |  Apache ActiveMQ 5.13.3 (localhost, ID:tiger- 61203- 
  
  
 1551857807769-0:1) isstarting
  
 862",NA
 View ActiveMQ Management Console,"You can now connect to the above started ActiveMQ Server using your favorite web 
 browser:
  
 http://127.0.0.1:8161/admin/
  
 You can log into the management console using the following default credentials:
  
 Username: admin 
  
 Password: admin
  
 See Figure 
 F-1
 .
  
 864",NA
 Configure ActiveMQ,"ActiveMQ installation contains a file named activemq.xml that can be used to configure 
 ActiveMQ server. This is typically found at D:\Applns\apache\ActiveMQ\apache- 
 activemq- 5.13.3\conf.
  
 In ActiveMQ, it is not required to explicitly set up/configure the queues you are 
 going to use in your application. When you try to publish or subscribe from any queue or 
 topic, the respective queue or topic will be silently created on the fly. However, if for any 
 reason you want to pre-specify queues and topics, you can do so in the configuration file. 
 For example, do this when you want to put destinations into JNDI so that they can be 
 pulled out by your application without needing to know the real, physical queue/topic 
 name. Listing 
 F-1
  provides a sample configuration of a queue and Figure 
 F-2
  shows the 
 result.
  
 865",NA
 Summary,"This appendix covered the basic installation and setup of Apache ActiveMQ, the open 
 source messaging and integration patterns server. I use ActiveMQ for the samples in few 
 chapters, so please refer this appendix while going through those samples.
  
 867",NA
APPENDIX G,NA,NA
Derby,"Apache Derby is an open source relational database implemented entirely in Java and 
 available under the Apache License. Derby follows Java, JDBC, and SQL standards and 
 supports the client/server mode operation with the Derby Network Client JDBC driver 
 and Derby Network Server. Go to 
 https://db.apache.org/derby/
  for more information.
  
 I will cover the following on Derby in this appendix:
  
 • How to install and configure a Derby database
  
 • How to start and stop Derby in Network mode
  
 • How to creating a new database in Derby
  
 • How to execute basic table creation and table manipulation 
 commands in a Derby database",NA
 Install and Configure Derby,"In this section, you will download, install, and configure Derby and test the 
 installation. Derby is available for download at 
 https://db.apache.org/derby/ 
 derby_downloads.html
 .
  
  
 Since I have Java 8 on my machine, I opted for the 10.14.1.0 release of Derby, which 
 is available at 
 https://db.apache.org/derby/releases/release-10.14.1.0.cgi
 .
  
 Save the installation archive file to a suitable location in your hard disk first and 
 then extract the archive to a location of your choice. Even though you may choose any 
 location, like
  
 C:\Program Files\Derby\
  
 © Binildas Christudas 2019 
  
 869
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_26",NA
 Start and Stop Derby Server in Network ,NA,NA
Mode,"Applications can access a Derby database using the familiar client/server mode. This is 
 achieved via a framework that embeds Derby and handles database requests from 
 applications, including applications running in different JVMs on the same machine or 
 on remote machines. The Derby Network Server embeds Derby and manages requests 
 from network clients.
  
  
 To easily start Derby Network Server, you must first change the working directory 
 to the bin folder within DERBY_HOME (shown in Figure 
 G-1
 ):
  
 cd D:\Applns\apache\Derby\db-derby-10.14.1.0-bin 
  
 D:\Applns\apache\Derby\db-derby-10.14.1.0-bin\bin>startNetworkServer
  
  
 Figure G-1. 
 Start Derby Server in Network mode",NA
 Create a New Derby Database,"It is always good to create and maintain your actual databases in a directory separate 
 from the Derby installation location. In my machine, I created a parent directory to hold 
 all my Derby databases:
  
 D:\Applns\apache\Derby\derbydb
  
 Change your current directory to that folder:
  
 cd D:\Applns\apache\Derby\derbydb
  
 You may now use the Derby embedded driver to create and connect to the sampledb 
 database. The Derby ij tool can be used to create and then to load a Derby database. If 
 you included the DERBY_HOME/bin directory in your PATH environment variable, type
  
 ij
  
  
 If you have not included the DERBY_HOME/bin directory in your PATH 
 environment variable, type
  
 java -jar %DERBY_HOME%\lib\derbyrun.jar ij
  
 In my machine, I used the following command:
  
 D:\Applns\apache\Derby\derbydb>ij 
  
 ij version 10.14 
  
 ij>
  
 871",NA
 Execute Basic Commands in Derby ,NA,NA
Database ,"You can now test your database using the following SQL 
 commands:
  
 CREATE TABLE SIMPLETABLE (ID INT PRIMARY KEY, NAME VARCHAR(12));
  
 DESCRIBE SIMPLETABLE;
  
 874",NA
 Summary,"Derby is a relational database exhibiting strong consistency characteristics, 
 which is why I use Derby to demonstrate the distributed transaction scenarios 
 in this book.
  
 876",NA
APPENDIX H,NA,NA
MySQL,"MySQL is a popular open source SQL database management system that is developed, 
 distributed, and supported by Oracle Corporation. MySQL manages a structured 
 collection of data. A MySQL database helps you to add, access, and process the data 
 stored in the database. MySQL stores data in separate tables. The database structures 
 are organized into physical files optimized for speed. The logical model, with objects 
 such as databases, tables, views, rows, and columns, offers a flexible programming 
 environment. 
  
 The SQL part of “MySQL” stands for “Structured Query Language,” which is the most 
 common standardized language used to access databases. MySQL software uses the GPL 
 (GNU General Public) License and is open source software. You can get more details on 
 MySQL at 
 www.mysql.com/
 .
  
 I will cover the following on MySQL in this appendix:
  
 • How to download and install MySQL
  
 • How to initialize a data directory for MySQL
  
 • How to start MySQL server and connect to the server
  
 • How to test a connection to MySQL server and disconnect from 
 the server
  
 • How to create a database and do basic table operations
  
 • How to add user accounts to the database",NA
 Install MySQL,"In this section, you will download, install, and configure MySQL and test the installation. 
 MySQL is available for download at 
 https://dev.mysql.com/downloads/mysql/
 .
  
 © Binildas Christudas 2019 
  
 877
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9_27",NA
 Initialize the Data Directory,"Since you have installed MySQL using the noinstall package, no data directory, is 
 included. To initialize the data directory, invoke mysqld as shown below from the home 
 folder where you unpacked the archive:
  
 cd D:\Applns\MySQL\mysql-8.0.14-winx64 
  
 D:\Applns\MySQL\mysql-8.0.14-winx64>D:\Applns\MySQL\mysql-8.0.14-winx64\ 
 bin\mysqld --initialize --console 
  
 2019-01-22T13:26:05.124628Z 0 [System] [MY-013169] [Server] D:\Applns\ 
 MySQL\mysql-8.0.14-winx64\bin\mysqld (mysqld 8.0.14) initializing of server in 
 progress as process 14464 
  
 2019-01-22T13:26:54.151969Z 5 [Note] [MY-010454] [Server] A temporary password is 
 generated for root@localhost: S9wdszB#<t.G 
  
 2019-01-22T13:27:16.565870Z 0 [System] [MY-013170] [Server] D:\Applns\ 
 MySQL\mysql-8.0.14-winx64\bin\mysqld (mysqld 8.0.14) initializing of server has 
 completed
  
 D:\Applns\MySQL\mysql-8.0.14-winx64>
  
 878",NA
 Start MySQL Server,"To start the server,, enter this command:
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysqld --console 
  
 2019-01-22T13:34:14.562420Z 0 [System] [MY-010116] [Server] D:\Applns\MySQL\ 
 mysql-8.0.14-winx64\bin\mysqld.exe (mysqld 8.0.14) starting as process 22172 2019-
 01-22T13:34:21.355370Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self 
 signed.
  
 2019-01-22T13:34:21.605828Z 0 [System] [MY-010931] [Server] D:\Applns\ 
 MySQL\mysql-8.0.14-winx64\bin\mysqld.exe: ready for connections. Version: '8.0.14'  
 socket: “  port: 3306  MySQL Community Server - GPL.
  
 2019-01-22T13:34:21.870413Z 0 [System] [MY-011323] [Server] X Plugin ready for 
 connections. Bind-address: '::' port: 33060
  
  
 The server continues to write to the console any further diagnostic output it 
 produces. You can open a new console window in which you can run client programs.
  
  
 Detailed instructions to start the server for the first time are available at 
 https:// 
 dev.mysql.com/doc/refman/8.0/en/windows-server-first-start.html
 .",NA
 Connect to MySQL Server,"Since you used --initialize to initialize the data directory, you connect to the server as 
 root using the random password the server generated during the initialization sequence:
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysql -u root -p 
 Enter password: ∗∗∗∗∗∗∗∗∗∗∗∗
  
 Welcome to the MySQL monitor.  Commands end with ; or \g.
  
 879",NA
 Test the MySQL Server Installation,"You can test whether the MySQL server is working by executing the following  
 commands:
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysqlshow -u root -p 
 Enter password: ∗∗∗∗∗∗∗∗∗∗∗∗
  
 +------------------------------+ 
  
 |     Databases                | 
  
 +------------------------------+ 
  
 | information_schema   | 
  
 | mysql          | 
  
 | performance_schema | 
  
 | sys                          | 
  
 +------------------------------+
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>",NA
 Disconnect from MySQL Server,"If you are connected to the MySQL server using the mysql client, you can disconnect via 
 the following code:
  
 mysql> quit 
  
 Bye
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>",NA
 Create and Select a Database,"You can again connect to the database, as mentioned in the “Connect to MySQL Server” 
 section, by using the new password supplied. Once connected, you can query the 
 connected user and databases like so:
  
 881",NA
 Create Tables,"Once you have selected a database, you can create tables in the database selected:
  
 mysql> CREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20),
  
  
 -> species VARCHAR(20), sex CHAR(1), birth DATE, death DATE); Query OK, 
 0 rows affected (0.63 sec)
  
 mysql>
  
 Next, you can view the schema for the newly created database:
  
 mysql> desc pet; 
  
 +---------+-------------+------+-------+----------+--------+ | Field   | Type        | 
 Null | Key   | Default| Extra | +---------+-------------+------+-------+----------
 +--------+ | name    | varchar(20) | YES  |       | NULL     |        | | owner   | 
 varchar(20) | YES  |       | NULL     |        | | species | varchar(20) | YES  |       
 | NULL     |        | | sex     | char(1)     | YES  |       | NULL     |        | | birth   | 
 date        | YES  |       | NULL     |        | | death   | date        | YES  |       | NULL     
 |        | +---------+-------------+------+-------+----------+--------+ 6 rows in set 
 (0.01 sec)
  
 mysql>
  
 883",NA
 Add User Accounts to MySQL Server ,"You can add new user to access the database server and grant privileges like 
 so:
  
 mysql> CREATE USER 'tutorialuser'@'localhost' IDENTIFIED BY 
  
 'tutorialmy5ql'; 
  
 Query OK, 0 rows affected (0.07 sec) 
  
 mysql> GRANT ALL PRIVILEGES ON ∗.∗ TO 'tutorialuser'@'localhost' WITH GRANT 
 OPTION; 
  
 Query OK, 0 rows affected (0.03 sec)
  
 mysql> CREATE USER 'tutorialuser'@'%' IDENTIFIED BY 'tutorialmy5ql'; Query OK, 0 
 rows affected (0.00 sec) 
  
 mysql> GRANT ALL PRIVILEGES ON ∗.∗ TO 'tutorialuser'@'%' WITH GRANT OPTION; 
 Query OK, 0 rows affected (0.00 sec)
  
 https://dev.mysql.com/doc/refman/8.0/en/adding-users.html",NA
 Stop MySQL Server ,"To stop the server, enter this command:
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>mysqladmin -u root -p shutdown 
 Enter password: ∗∗∗∗∗∗∗∗∗∗∗∗
  
 D:\Applns\MySQL\mysql-8.0.14-winx64\bin>",NA
 Summary ,"MySQL is a relational database that can be used for operations where strong consistency 
 is required like those in ACID transactions. I use MySQL for demonstrating many of the 
 samples in this book.
  
 884",NA
Index,NA,NA
A,"ACID transactions, 
 403,779 
  
  
 vs.
  BASE, 
 403,404 
  
 ActiveMQ, 
 861 
  
  
 configuration, 
 865,866 
  
  
 install, 
 861 
  
  
 management console, 
 864 
  
  
 queue, 
 432 
  
  
 server, 
 443 
  
  
 start, 
 862,863 
  
 ActiveMQXAConnectionFactory, 
 424 
  
 Aggregate, 
 347 
  
 Aggregate root, 
 347 
  
 AggregateRoot.getVersion() method, 
 620 
 Amazon Elastic Compute Cloud 
  
  
  
 (Amazon EC2), 
 592 
  
 Amazon Web Services (AWS), 
 590,592 
 AMQP, 
 124,137 
  
 Apache TCPMon, 
 857 
  
  
 install, 
 857 
  
  
 proxy setup, 
 858,859 
  
  
 start, 
 858 
  
 API gateway, 
 227,686–688 
  
  
 application and infrastructure 
  
  
  
  
 components, 
 689–693 
  
 Application architecture, 
 8 
  
 Application architecture redundancy, 
 259 
 Application load balancer (ALB), 
 595 
  
 Asynchronous network, 
 389
  
 Async HTTP method, 
 286 
  
 Atomicity, 
 390 
  
 Atomicity, Consistency, Isolation, and 
  
 Durability (ACID), 
 390,392 
  
 Atomikos, 
 406,422,427,430,431 
  
 AtomikosDataSourceBean, 
 429 
  
 Audit event handler, 
 577 
  
 AuthenticationEntryPoint, 
 767 
  
 AuthenticationManagerBuilder, 
 768 
  
 Authorization code grand types 
  
  
 OAuth, 
 742 
  
  
 sequence of interactions, 
 744,745 
  
 Authorization server 
  
  
 AuthenticationEntryPoint, 
 768 
  
  
 @EnableAuthorizationServer 
  
  
  
  
 annotation, 
 770 
  
  
 HttpSecurity, 
 767 
  
  
 JwtTokenStore, 
 771,772 
  
  
 OAuth security configuration, 
 769 
  
  
 spring security configuration, 
 766 
  
 AuthorizationServerConfigurerAdapter, 
 770 
 AUTO_ACKNOWLEDGE, 
 538 
  
 Automatic storage management 
  
  
 (ASM), 
 598 
  
 Autonomous system number 
  
  
 (ASN), 
 252 
  
 Auto scaling, 
 594 
  
 Availability zones (AZs), 
 592,594 
  
 AWS regions, 
 592
  
 © Binildas Christudas 2019 
  
 885
  
 B. Christudas, 
 Practical Microservices Architectural Patterns
 , 
 https://doi.org/10.1007/978-1-4842-4501-9",NA
B ,"BASE architecture, 
 399,400
  
  
  
 meta model, 
 342–345 
  
  
 optimistic locking, 
 349 
  
 unit of work, 
 348 
  
 distributed commands and 
  
 BASE transactions 
  
 Axon components, 
 402 
  
 HTTP PUT, 
 402,403 
  
 microservices architecture, 
 399,403
  
 event handling 
  
 relaxed, 
 400,401
  
 clustered event bus, 
 374 
 code sample, 
 364–
 373 
 design, 
 362–364
  
 Basically available, soft state, eventually 
 consistent (BASE) systems, 
 332 
 Bill of 
 Materials (BOM), 
 151
  
 Ecom-EventHandleAudit, 
 375 
  
 Bitronix, 
 406
  
 Ecom-EventHandleCore, 
 374 
 SpringAMQPTerminal, 
 373 
 testing, 
 375–383
  
 Border gateway protocol (BGP), 
 252 
  
 Broker web microservice, 
 430,446,514,515 
 Business Domain Object 
 Model 
  
 event buses, 
 339 
  
 (BDOM), 
 645
  
 executors, 
 342 
  
 Business process model and notation 
  
 extensible 
  
 (BPMN) frameworks, 
 545
  
 architectures, 
 339
  
 the look-to-book, 
 340 
  
 read-to-write ratio, 
 340 
  
 repositories, 
 339 
  
 single source of truth, 
 341",NA
C ,"CAP Pyramid, 
 333–335 
 CAP Theorem
  
  
  
 thread pools, 
 342 
 Axon 3, 
 779
  
 886",NA
D,"read and write 
 transactions database 
 nodes for, 
 94 
 scale out, 
 95
  
 Database administrators (DBAs), 
 598 
 Data consistency, 
 43,645,732 
  
 Demilitarized zone (DMZ), 
 212,737
  
 schema for, 
 91,93 
  
 Derby
  
 read models, 
 92 
  
 client/server mode, 
 870,871
  
 read-only replicas, 
 94,96 
  
 create, 
 871
  
 scale out, 
 95 
  
 database, 
 431
  
 write models, 
 92 
  
 definition, 
 869
  
 Command router, 
 786 
  
 install, 
 869,870
  
 Common information model (CIM), 
 645 
  
 network mode, 
 872,873
  
 Computer networks 
  
 Design security
  
 distributed systems, 
 387 
  
 architecture, microservices, 
 750–
 752
  
 IP, 
 388 
  
 asymmetric encryption, 
 752–754
  
  
 TCP, 
 386,388 
  
 Config server, 
 684,685 
  
  
 build and test, 
 242–244 
  
  
 configuration parameters, 
 241 
  
 controlled repository, 
 238 
  
  
 dependency, 
 239 
  
  
 design, 
 238 
  
  
 @EnableConfigServer, 
 239
  
  
 reference tokens, 
 752–754 
  
  
 web app functionality, 
 750 
  
 Directed acyclic graph (DAG), 
 549 
 Disaster recovery (DR), 
 257 
  
 DisruptorCommandBus, 
 656 
  
 Distributed ACID transactions, 
 398 
 Distributed command bus, 
 786 
  
 Distributed computing architecture
  
 GIT URL, 
 239,240 
  
 application
  
 Maven dependency, 
 240 
  
 typical, 
 9–11
  
  
 microservice configuration, 
 240,241 
  
 Product Server microservice, 
 241,242 
  
 spring-cloud-config-server, 
 238 
  
  
 spring-cloud-starter-config, 
 240 
  
 Connection.rollback(), 
 405 
  
 Consistency, 
 391 
  
 Container-based virtualization, 
 76 
  
 Coordinated attack problem, 
 386
  
 888
  
  
 typical deployment, 
 11–13 
 network integration topologies 
  
  
 (
 see
  Network architectures) 
 scalability dilemma 
  
  
 application monolith, 
 16 
  
  
 application state, 
 13,14 
  
  
 intermodule dependency, 
 17 
  
 modular approach, 
 15",NA
E ,"E-commerce
  
  
  
 wiring, 
 424–426 
  
 XA JMS resources, spring 
  
 wiring, 
 423,424
  
 business, 
 640,641 
  
 class diagram, 
 646 
  
 microservice (
 see
  E-commerce 
  
 quote settlement 
  
 microservice)
  
 890
  
 (Settlement- ActiveMQ- Derby) 
  
 monolith architecture, 
 641–643
  
 Atomikos, 
 431 
  
 E-commerce microservice
  
 Maven dependency, 
  
 ACID within the BASE, 
 645",NA
G ,"getJMSCorrelationID(), 
 135
  
  
  
 point-to-point, 
 317 
  
  
 publish-subscribe, 
 318 
  
  
 queue, 
 317 
  
  
 software architecture pattern, 
 316 
  
  
 tightly coupled, 
 317 
  
 Event-driven infrastructure, 
 652 
  
 Event emitters, 
 316 
  
 Eventual consistency and microservices 
  
 business applications, 
 324 
  
  
 e-commerce monolith application, 
 323 
  
 Mac Book Pro, 
 325 
  
  
 monolithic applications, 
 323 
  
  
 NotEnoughInventory event, 
 326
  
 GET (subscribe), 
 109 
  
 Global 
 vs.
  local resources 
  
  
 architecture options, 
 494,495 
  
  
 distributed ACID transactions 
  
  
  
 distributed resources, 
 490 
  
  
  
 partial optimization, 
 492 
  
  
 local transactions, 
 493 
  
  
 monolith quote application, 
 489 
  
  
 queue participation, 
 490 
  
  
 quotes microservices architecture, 
 491 
 Global two-phase transactions, 
 492 
  
 Global Unique Identifier (GUID), 
 748
  
 OrderCreated events, 
 326 
  
 Order, Item, and Inventory, 
 324 
 race condition, 
 325",NA
H ,"HAL browser, 
 163
  
 HA scenario, build and test",NA
F,"Ecom-EventHandleCore, 
 610,612 
 Ecom-EventHandlerAudit, 
 612–615
  
  
 fat JARs, 
 40,157 
  
 Feign client 
  
  
 build and test, 
 190,191 
  
 components, 
 186,187 
  
 dependency, 
 188
  
 892
  
  
 Ecom-HandleCommandAnd 
  
  
 CreateEvent, 
 609,610 
  
  
 Ecom-web, 
 607–609 
  
  
 RabbitMQ server, 
 605,607 
  
 HibernateJpaVendorAdapter, 
 429",NA
I,"Web App, 
 268–271 
 Zuul, 
 266,267,273
  
 Idempotent operations, 
 488,489 
 Infrastructure as a Service (IaaS), 
 71",NA
M,"Isolation, 
 391",NA
"J, K","JavaScript Object Notation (JSON), 
 813 
 Java Server Pages (JSP) technology, 
 735 
 Java Transaction API (JTA), 
 407 
  
 Java Transaction Service (JTS), 
 407 
  
 java.util.concurrent.Callable, 
 282 
  
 java.util.concurrent.Future, 
 284 
  
 javax.servlet.AsyncContext class, 
 282 
 javax.transaction.UserTransaction 
  
  
 interface, 
 430 
  
 JOTM, 
 406 
  
 JSON web encryption (JWE), 
 749 
  
 JSON web signature (JWS), 
 747 
  
 JSON web token (JWT), 
 747–749 
  
 JtaTransactionManager, 
 427,430 
  
 JwtAccessTokenConverter, 
 772 
  
 JwtTokenStore, 
 771
  
 Mainframe-based architecture, 
 4 
  
 MappingJackson2HttpMessageConverter, 
  
 175 
  
 Maven eclipse plugin, 
 703 
  
 Mesh App and Services Architecture 
  
  
 (MASA), 
 58,85 
  
 Message broker, 
 106,827 
  
 Message consumed, processing failure 
  
 test case, 
 468–470 
  
 Message-oriented microservices, 
 44,45 
 Message received out of order scenario, 
  
 474–480 
  
  
 quote creation, 
 529,532,533 
  
  
 quote processing, 
 530,531 
  
  
 quotes and user table, 
 527 
  
  
 stock transaction table, 
 528,533,534,536 
  
 testing, 
 526,535 
  
 Message redelivery test case, 
 470–473 
  
 Messaging, 
 105 
  
 Meta model",NA
L,"aggregate entities, 
 99 
  
 command gateway, 
 99
  
  
 LoadBalancerClient, 
 213 
  
 localTransactionMode property, 
 424 
 Local transactions 
  
  
 auto-commit, 
 405 
  
  
 Connection.commit(), 
 405 
  
  
 java.sql.Connection interface, 
 405 
  
 session, 
 405 
  
  
 unit of work, 
 405
  
 894
  
 command handler, 
 99 
 commands, 
 99 
  
 controller, 
 98 
  
 CQRS meta model, 
 100 
 domain entities, 
 99 
  
 event bus, 
 99 
  
 event handlers, 
 100 
  
 events, 
 99",NA
N,"scalability dilemma, 
 47,49,51 
  
 to SOA, 
 41–43 
  
 Modular monolith
  
 Nested transaction, 
 392 
  
 Network architectures 
  
  
 enterprise message bus topology, 
 6
  
 application boundary, 
 24 
  
 ESB, 
 7
  
 IDE, 
 22 
  
 hub-and-spoke, 
 6
  
 intermodule communication, 
 25,26 
  
 point-to-point, 
 6
  
 NFR, 
 22 
  
 Network integration topologies, 
 5
  
 scalability, 
 26,27 
  
 services tier application, 
 23
  
 Network interface card (NIC), 
 256 
 Network load balancer (NLB), 
 595
  
 SLA, 
 22 
  
 Nginx
  
 technology constraints, 
 28 
  
 definition, 
 843
  
 MongoDB, 
 148,577,813 
  
 installation, 
 843
  
 document, 
 814 
  
 start, 
 844
  
 installation file, 
 814–
 816 
 manipulations, 
 818–821 
 Robomongo, 
 822–825 
  
 server, 
 700,817,818
  
 Non-functional requirements (NFR), 
 22 
 Non-repeatable read, 
 396 
  
 Non-volatile memory express (NVMe), 
 598 
 N-tier architecture, 
 5
  
 Mongo repository, 
 155,186,649
  
 Monolith application, 
 21,24–25,484 
 Monolithic style architecture, 
 639 
 Multipage architecture (MPA), 
 735 
 Multi-threaded environment, 
 489 
 MySQL",NA
O,"OAuth 2.0 
  
 authorization server, 
 735 
 HTTP service, 
 734
  
  
 connect the server, 
 879,880 
 create and select, 
 881,883 
 create tables, 
 883 
  
 data directory, 
 878,879
  
  
 resource owner, 
 734 
  
  
 resource server, 
 734 
  
  
 vs.
  user agent, 
 735 
  
 OAuth2AuthenticationProcessing 
  
 definition, 
 877 
  
 Filter, 
 773
  
 disconnect, 
 881 
  
 installation, 
 877,878 
 start the server, 
 879
  
 Object-relational mapping (ORM), 
 28 
 Object Transaction Service (OTS), 
 407 
 Online travel agent (OTA) site, 
 618
  
 stop, 
 884 
  
 Operating system-level virtualization, 
 76
  
 896",NA
Q ,"QuartzEventScheduler, 
 667
  
 Quote processing microservice, 
 445,513,514",NA
P ,"PagingAndSortingRepository, 
 649 
 Patterns
  
 Quote settlement 
  
 listener orchestrator, 
 500,501 
 listener reconciliation, 
 502,503 
 microservice, 
 447,489
  
  
 CQRS (
 see
  Command Query 
  
  
 Responsibility Segregation 
 (CQRS))
  
 reconcile service code, 
 508,509 
 reconcile service helper method, 
  
 look to book, 
 90 
  
 509,510
  
 online transactions, 
 89,90 
 read transactions, 
 89
  
 stock transaction entity, 
 504,505 
 transaction service, 
 505–507
  
 traditional 
 vs.
  CQRS-Based software 
  
  
  
 systems, 
 90 
  
 write, 
 88 
  
  
 vs.
  read Transactions, 
 88,89 
  
 scale out, 
 88",NA
R ,"RabbitMQ, 
 373,577,827 
  
 cluster
  
  
 Pessimistic locking, 
 396 
  
 Platform as a Service (Paas), 
 71 
  
 PlatformTransactionManager, 
 430,657 
 Point-to-point architecture, 
 6 
  
 Point-to-point EDA, 
 317
  
 configure, 
 832,833 
  
 dynamic DNS, 
 841 
  
 restart, 
 840,841 
  
 start node, 
 834–840 
  
 TCP load balancer, 
 841",NA
S,"SaaS maturity model, 
 72 
 Saga, 
 393 
  
  
 application, 
 556 
  
  
 code sample
  
 898",NA
T ,"TaskExecutor, 
 282,287
  
  
  
 MongoRepository interfaces, 
 155,156 
  
 @RepositoryRestResource, 
 156 
  
  
 REST client, 
 159 
  
  
 test application, 
 159 
  
  
  
 GET HTTP Request, cURL, 
 159,160 
  
  
 GET HTTP Request, Postman, 
 161 
  
  
 Junit testing, 
 162 
  
 Spring Boot Maven plugin, 
 153–154 
  
 spring-boot-starter-web dependency, 
 286 
 Spring Cloud, 
 183,337 
  
  
 microservices ecosystem, 
 184 
  
  
 command router, 
 787 
  
 spring-cloud-config-server, 
 239 
  
 spring-cloud-starter-config, 
 240 
  
 spring-cloud-starter-eureka, 
 217
  
 TCP IP Network, 
 137 
  
 TCP load balancer, 
 841 
  
 TCP reverse proxy, 
 845 
  
 Technology-centric approach, 
 65 
  
 thenApply() method, 
 288 
  
 Thread.sleep() method, 
 621 
  
 Transaction attributes, 
 393,394 
  
 Transaction ID pattern, 
 499 
  
 Transaction isolation, 
 394,396 
  
 TransactionManager, 
 430 
  
 TransactionManagerLookup, 
 427 
  
 Transaction models, 
 392,393 
  
 Transaction processing (TP), 
 406 
  
 TransactionProxyFactoryBean, 
 422 
  
 Transaction Rollback test case, 
 453–457
  
 spring-cloud-starter-eureka-server, 
 214 
  
 Transactions
  
 spring-cloud-starter-feign 
  
 ACID, 
 390,392
  
 dependency, 
 188 
  
 spring-cloud-starter-hystrix, 
 195
  
 acknowledge(), 
 538,539 
 concurrency levels, 
 395
  
 spring-cloud-starter-hystrix-dashboard, 
 202 
  
 CRUD, 
 92
  
 900",NA
U,"uber JAR, 
 40,154 
  
 Unit of Work (UoW), 
 656,799 
 usersByUsernameQuery, 
 768 
 UserTransactionImp, 
 430 
  
 UserTransactionManager, 
 430 
 Uses cases, e-commerce 
  
  
 add item, cart, 
 714,715 
  
  
 back-office admin 
  
  
  
  
 home page, 
 712 
  
  
 back-office admin 
  
  
  
  
 login page, 
 712 
  
  
 cancel order, 
 727,730 
  
  
 delivery failure, 
 725,726 
  
  
 end user home page, 
 711 
  
  
 new order, creation, 
 718,720 
  
 order deliver, 
 723,724 
  
  
 product category, 
 713 
  
  
 revert inventory, 
 731 
  
  
 shipping order, 
 721,722 
  
  
 user profile 
  
  
  
 creation, 
 716 
  
  
  
 login prompt, 
 715 
  
  
  
 signing in, 
 717
  
  
 web app, 
 741,742 
  
 Two Armies problem, 
 see
  Two Generals",NA
V,"Paradox 
  
 Two Generals Paradox 
  
  
 arbitrary communication 
  
  
  
 failures, 
 386
  
 Vertical scaling, 
 327 
  
 Virtualization, 
 75 
  
 Virtual private cloud (VPC), 
 592
  
 illustration, 
 386,387 
  
 microservices as generals, 
 388",NA
W,"solution approaches, 
 387,388 
  
 TCP/IP, 
 388,389 
  
 Two-phase commit protocols, 
 484
  
 Web app, code security 
  
 doOrder action, routing, 
 756 
 home page, 
 755
  
 Typical application architecture, 
 9 
  
 logged in, 
 754
  
 Typical deployment architecture, 
 12
  
 route mappings, 
 756,757",NA
"X, Y ","XADataSource interface, 
 427
  
 microservice, 
 230 
  
 Product Server 
  
  
 microservice, 
 234",NA
Z,"Zuul, API Gateway 
  
 AWS ELB, 
 226 
  
 bootstrap URL, 
 226–
 230
  
 registry look up, 
 229 
 Ribbon, 
 229 
  
 routes, 
 233 
  
 spring-cloud-starter- 
  
 zuul, 
 232
  
 902",NA
