Larger Text,Smaller Text,Symbol
Learning Boost C++ Libraries,NA,NA
"Solve practical programming problems using powerful, ",NA,NA
"portable, and expressive libraries from Boost",NA,NA
Arindam Mukherjee,BIRMINGHAM - MUMBAI,NA
Learning Boost C++ Libraries,"Copyright © 2015 Packt Publishing
  
 All rights reserved. No part of this book may be reproduced, stored in a retrieval 
 system, or transmitted in any form or by any means, without the prior written 
 permission of the publisher, except in the case of brief quotations embedded in 
 critical articles or reviews.
  
 Every effort has been made in the preparation of this book to ensure the accuracy of 
 the information presented. However, the information contained in this book is sold 
 without warranty, either express or implied. Neither the author, nor Packt 
 Publishing, and its dealers and distributors will be held liable for any damages 
 caused or alleged to be caused directly or indirectly by this book.
  
 Packt Publishing has endeavored to provide trademark information about all of the 
 companies and products mentioned in this book by the appropriate use of capitals. 
  
 However, Packt Publishing cannot guarantee the accuracy of this information.
  
 First published: July 2015
  
 Production reference: 1280715
  
 Published by Packt Publishing Ltd.
  
 Livery Place 
  
 35 Livery Street 
  
 Birmingham B3 2PB, UK.
  
 ISBN 978-1-78355-121-7
  
 www.packtpub.com",NA
Credits,"Author 
  
 Arindam Mukherjee
  
 Reviewers 
  
 Michael Medin
  
 Anthony Shoumikhin
  
 Drew Tennenbaum
  
 Sergey Zubkov
  
 Commissioning Editor 
 Usha Iyer
  
 Acquisition Editor 
 Nikhil Karkal
  
 Content Development Editors 
 Natasha DSouza
  
 Sweny Sukumaran
  
 Technical Editors 
 Pramod Kumavat
  
 Saurabh Malhotra
  
 Mitali Somaiya
  
 Copy Editor 
  
 Rashmi Sawant
  
 Project Coordinator
  
 Vijay Kushlani
  
 Proofreaders
  
 Stephen Copestake
  
 Safis Editing
  
 Indexer
  
 Hemangini Bari
  
 Graphics
  
 Sheetal Aute
  
 Production Coordinator
  
 Komal Ramchandani
  
 Cover Work
  
 Komal Ramchandani",NA
About the Author,"Arindam Mukherjee
  is a senior principal software engineer at Symantec, Pune, 
 India, where he is involved in the research and development of business continuity 
 solutions for enterprises. He has used C++ extensively for developing large-scale 
 distributed systems. He was a speaker at Dr. Dobb's Journal India Conference 2014 
 and is the organizer of regular meets for the Pune C++ and Boost Meetup. He believes 
 that writing books and articles, speaking for interest groups, and engaging with the 
 programming community are the best ways to develop a critical understanding of 
 technology. He is also an amateur musician, dabbles in food photography, and loves 
 profound discussions with his 4-year-old daughter, especially about dinosaurs and 
 their diets.
  
 I would like to express my sincerest gratitude to Sergey Zubkov for 
 helping me refine the content of this book with his critical reviews and 
 observations. Special thanks to Anthony Shoumikhin, Drew 
 Tennenbaum, and Michael Medin for their thoughtful reviews and 
 feedback. A special word of thanks to Nikhil Karkal, Natasha DSouza, 
 Pramod Kumavat, and Sweny Sukumaran at Packt Publishing for their 
 tremendous support and helping me manage all the missed deadlines. 
 Last but not least, I thank my father for making me believe as a child 
 that writing books could be fun, my mother for far more than words 
 can ever express, my wife for believing in my dream, and my daughter 
 for making it all worthwhile.",NA
About the Reviewers,"Michael Medin
  is a senior developer and lead architect of the NSClient++ project. He 
 is an avid C++ developer and has been developing open source software using C++ and 
 the Boost library for longer than he cares to remember.
  
 As always, I would like to thank my beloved, Xiqun, for putting up with 
 me when I spend countless hours working on NSClient++ and my two 
 daughters for always bringing a smile to my face.
  
 Anthony Shoumikhin
  is yet another geek who loves hacking, cycling, 
 swimming, and occasional work at Microsoft.
  
 He grew up in Ukraine and spent his early years in a city of rocket science and 
 secret technologies—Dnipropetrovsk. These days, he works in Redmond, WA, on 
 an upcoming release of Microsoft Office for Mac and iOS.
  
 In his spare time, he creates full-stack mobile apps and funny low-level system hacks 
 on Mac OS X and Linux (mostly in his beloved C++ empowered with Boost).
  
 Drew Tennenbaum
  was introduced to programming at the age of 12. As a present, 
 his parents gave him his first computer, a Commodore 64. A family friend purchased a 
 book titled, 
 Assembly Language for Kids: Commodore 64
 . Bored one night, he began 
 reading the book and instantly found attraction in learning how to make a machine 
 perform specific tasks. He quickly took to assembly language, which is now the 
 foundation for much of what he works on today.",NA
www.PacktPub.com,NA,NA
"Support files, eBooks, discount offers, and more","For support files and downloads related to your book, please visit 
 www.PacktPub.com
 .
  
 Did you know that Packt offers eBook versions of every book published, with PDF and 
 ePub files available? You can upgrade to the eBook version at 
 www.PacktPub. com
  and 
 as a print book customer, you are entitled to a discount on the eBook copy. Get in touch 
 with us at 
 service@packtpub.com
  for more details.
  
 At 
 www.PacktPub.com
 , you can also read a collection of free technical articles, sign up 
 for a range of free newsletters and receive exclusive discounts and offers on Packt 
 books and eBooks.
  
 TM
  
 https://www2.packtpub.com/books/subscription/packtlib
  
 Do you need instant solutions to your IT questions? PacktLib is Packt's online digital 
 book library. Here, you can search, access, and read Packt's entire library of books.",NA
Why subscribe?,"• 
  
 Fully searchable across every book published by Packt
  
 • 
  
 Copy and paste, print, and bookmark content
  
 • 
  
 On demand and accessible via a web browser",NA
Free access for Packt account holders,"If you have an account with Packt at 
 www.PacktPub.com
 , you can use this to access 
 PacktLib today and view 9 entirely free books. Simply use your login credentials for 
 immediate access.",NA
Table of Contents,"Preface 
  
 ix
  
 Chapter 1: Introducing Boost 
  
 1
  
 How it all started 
  
 What is Boost? 
  
 Getting started with Boost libraries 
  
 Necessary software 
  
  
 Linux toolchain 
  
  
 Windows toolchain 
  
 Obtaining and building Boost libraries 
  
  
 Planning your Boost sandbox 
  
  
 Library naming conventions 
  
  
 Library name components 
  
  
 Library name layouts 
  
  
 Installing a Boost binary distribution 
  
  
 Building and installing the Boost libraries from source 
 Using Boost libraries in your projects 
  
  
 Linking against Boost libraries on Linux 
  
  
 Linking against Boost libraries on Windows 
  
 Building the code listings in this book 
  
  
 CMake 
  
  
 Code examples 
  
 Self-test questions 
  
 Summary 
  
 Chapter 2: The First Brush with Boost's Utilities 
  
 1 
  
 2 
  
 3 
  
 3 
  
 4 
  
 4 
  
 5 
  
 5 
  
 5 
  
 5 
  
 6 
  
 8 
  
 10 
  
 15 
  
 16 
  
 17 
  
 20 
  
 20 
  
 20 
  
 23 
  
 23
  
 25
  
 Simple data structures 
  
 Boost.Optional 
  
  
 Accessing values stored in boost::optional 
  
 get_value_or 
  
  
 Boost.Optional versus pointers 
  
 25 
  
 26 
  
 28 
  
 29 
  
 30
  
 [
  i 
 ]",NA
Preface,"Boost is not just a collection of useful, portable, generic C++ libraries. It is an important 
 incubator for ideas and concepts that make their way to the ISO C++ Standard itself. If 
 you are involved in the development of software written in C++, then learning to use the 
 Boost libraries would save you from reinventing the wheel, improve the quality of your 
 software, and very likely push up your productivity.
  
 I first came across the Boost libraries a decade ago, while looking for a portable C++ 
 regular expressions library. Over the next couple of days, porting Perl and Korn Shell text-
 processing code to C++ became a breeze, and I took an instant liking to Boost. In using 
 many more Boost libraries to write software since then, I often found myself digging deep 
 into the documentation, or asking questions on the mailing list and online forums to 
 understand library semantics and nuances. As effective as that was, I always sorely 
 missed a book that would get me started on the most useful Boost libraries and help me 
 become productive faster. 
 This is that book
 .
  
 Boost has a wide array of libraries for solving various kinds of programming tasks. 
  
 This book is a tutorial introduction to a selection of over of the most useful libraries 
 from Boost to solve programming problems effectively. The chosen libraries represent 
 the breadth of cross-cutting concerns from software development, including data 
 structures and algorithms, text processing, memory management, exception safety, date 
 and time calculations, file and directory management, concurrency, and file and network 
 I/O, among others. You will learn about each library by understanding the kind of 
 problems it helps solve, learning the fundamental concepts associated with it, and 
 looking at a series of code examples to understand how the library is used. 
  
 Libraries introduced earlier in this book are freely used in later examples, exposing 
 you to the frequent synergies that occur in practice between the Boost libraries.
  
 [
  ix 
 ]",NA
What this book covers,"Chapter 1
 , 
 Introducing Boost
 , discusses how to set up a development environment to 
 use the Boost libraries. We cover different ways of obtaining Boost library binary 
 packages, building them from source for different configurations, and using them in a 
 development environment.
  
 Chapter 2
 , 
 The First Brush with Boost's Utilities
 , explores a handful of Boost libraries for 
 common programming tasks that include dealing with variant data types, handling 
 command-line arguments, and detecting the configuration parameters of the 
 development environment.
  
 Chapter 3
 , 
 Memory Management and Exception Safety
 , explains what is meant by 
 exception safety, and shows how to write exception-safe code using the different 
 smart pointer types provided by Boost and C++11.
  
 Chapter 4
 , 
 Working with Strings
 , explores the Boost String Algorithms library for 
 performing various computations with character strings, the Boost Range library for 
 elegantly defining subsequences, the Boost Tokenizer library to split strings into tokens 
 using different strategies, and the Boost Regex library to search for complex patterns in 
 text.
  
 Chapter 5
 , 
 Effective Data Structures beyond STL
 , deals with the Boost Container library 
 focusing on containers not available in the C++ Standard Library. We see the Pointer 
 Container library for storing dynamically-allocated objects in action, and use the Boost 
 Iterator library to generate various value sequences from 
  
 underlying containers.
  
 Chapter 6
 , 
 Bimap and Multi-index Containers
 , looks at bidirectional maps and 
 multi-index containers—two nifty container templates from Boost.
  
 Chapter 7
 , 
 Higher Order and Compile-time Programming
 , delves into compile-time 
 programming using Boost Type Traits and Template Metaprogramming libraries. We take 
 a first look at Domain Specific Embedded Languages and use Boost Phoenix to build basic 
 expression templates. We use Boost Spirit to build simple parsers using the Spirit Qi 
 DSEL.
  
 [
  x 
 ]",NA
What you need for this book,"You will need a computer capable of running an operating system that supports a C++ 
 compiler toolchain supported by Boost. You can find more details at 
 http://www. 
 boost.org/doc/libs/release/libs/log/doc/html/log/installation.html
 .
  
 To compile and run the code from this book, you will need to install the Boost 
 libraries version 1.56 or later. See 
 Chapter 1
 , 
 Introducing Boost
 , for more details.
  
 Many code examples in this book require C++11 support, and thus, you should 
 choose versions of your compiler that have good support for C++11. You can find 
 more details at 
 http://en.cppreference.com/w/cpp/compiler_support
 .
  
 A CMake project is provided with the downloadable source code to help you quickly build 
 all the examples using your preferred build system (gmake or Microsoft Visual Studio). In 
 order to use this, you need to install CMake version 2.8 or later. See 
 Chapter 1
 , 
 Introducing 
 Boost
 , for more details.
  
 This book tries not to repeat content from the online reference manual. You should use 
 the Boost library's online reference manuals liberally in conjunction with this book to 
 discover additional properties, functions, and techniques. You can find the 
 documentation at 
 http://www.boost.org/doc/libs/
 .
  
 Finally, the code listings in this book are sometimes abridged for brevity and focus. 
 The code examples accompanying this book are complete versions of these listings, 
 and you should use them when trying to build the examples.
  
 [
  xi 
 ]",NA
Who this book is for,"This book is for every C++ programmer who is interested in learning about Boost. 
  
 In particular, if you have never used the Boost libraries before, 
 Learning Boost 
 C++Libraries
  will get you up to speed with understanding, building, deploying, and 
 using the Boost libraries. If you are familiar with the Boost libraries, but were looking 
 for a springboard to dive deeper and take your expertise to the next level, this book 
 will give you a comprehensive round-up of the most useful Boost libraries and the 
 ways to use them in practical code.
  
 Boost is a collection of C++ libraries, and naturally, C++ is the sole language used in 
 this book. You need to have a good working knowledge of C++. In particular, you 
 should be able to read code that uses C++ templates, understand the C++ compilation 
 model, and be able to use a C++ development environment on Linux, Windows, or Mac 
 OS.
  
 This book does not cover general C++ concepts as a rule, but some useful C++ books and 
 articles, listed at the end of some chapters, should serve as excellent references.",NA
Conventions,"In this book, you will find a number of text styles that distinguish between different 
 kinds of information. Here are some examples of these styles and an explanation of their 
 meaning.
  
 Code words and C++ language keywords 
 in text
  are shown as follows: ""We pass the 
 number of bytes returned by 
 async_receive
  to the handler.""
  
 Folder names, filenames, file extensions, pathnames, include file names in text are 
 shown as follows: ""The header file 
 boost/asio.hpp
  includes most of the types and 
 functions required for using the Asio library"".
  
 A block of code is set as follows:
  
 46 int main() {
  
 47   asio::io_service service;
  
 48   UDPAsyncServer server(service, 55000);
  
 49
  
 50   boost::thread_group pool;
  
 51   pool.create_thread([&service] { service.run(); });
  
 52   pool.create_thread([&service] { service.run(); });
  
 53   pool.join_all();
  
 54 }
  
 [
  xii 
 ]",NA
Reader feedback,"Feedback from our readers is always welcome. Let us know what you think about this 
 book—what you liked or disliked. Reader feedback is important for us as it helps us 
 develop titles that you will really get the most out of.
  
 To send us general feedback, simply e-mail 
 feedback@packtpub.com
 , and mention the 
 book's title in the subject of your message.
  
 If there is a topic that you have expertise in and you are interested in either writing or 
 contributing to a book, see our author guide at 
 www.packtpub.com/authors
 .",NA
Customer support,"Now that you are the proud owner of a Packt book, we have a number of things to help 
 you to get the most from your purchase.",NA
Downloading the example code,"You can download the example code files from your account at 
 http://www.
  
 packtpub.com
  for all the Packt Publishing books you have purchased. If you 
 purchased this book elsewhere, you can visit 
 http://www.packtpub.com/support 
 and register to have the files e-mailed directly to you.
  
 [
  xiii 
 ]",NA
Errata,"Although we have taken every care to ensure the accuracy of our content, mistakes do 
 happen. If you find a mistake in one of our books—maybe a mistake in the text or the 
 code—we would be grateful if you could report this to us. By doing so, you can save 
 other readers from frustration and help us improve subsequent versions of this book. If 
 you find any errata, please report them by visiting 
 http://www.packtpub. 
 com/submit-errata
 , selecting your book, clicking on the 
 Errata Submission Form 
 link, and entering the details of your errata. Once your errata are verified, your 
 submission will be accepted and the errata will be uploaded to our website or added to 
 any list of existing errata under the Errata section of that title.
  
 To view the previously submitted errata, go to 
 https://www.packtpub.com/books/ 
 content/support
  and enter the name of the book in the search field. The required 
 information will appear under the 
 Errata
  section.",NA
Piracy,"Piracy of copyrighted material on the Internet is an ongoing problem across all 
 media. At Packt, we take the protection of our copyright and licenses very 
 seriously. If you come across any illegal copies of our works in any form on the 
 Internet, please provide us with the location address or website name 
 immediately so that we can pursue a remedy.
  
 Please contact us at 
 copyright@packtpub.com
  with a link to the suspected 
 pirated material.
  
 We appreciate your help in protecting our authors and our ability to bring you 
 valuable content.",NA
Questions,"If you have a problem with any aspect of this book, you can contact us at 
 questions@packtpub.com
 , and we will do our best to address the problem.
  
 [
  xiv 
 ]",NA
Introducing Boost,"Welcome to learning about the richest collection of C++ libraries around, that is, 
 Boost. In this introductory chapter, we will take a look at:
  
 • 
  
 The history and evolution of Boost
  
 • 
  
 What is Boost?
  
 • 
  
 Getting started with Boost libraries
  
 Like all the chapters in the book, this is a hands-on chapter that will require you to 
 type in commands, write and test your code. Therefore, you should have access to a 
 computer with a reasonably modern C++ compiler and an internet connection to 
 download free software, including Boost libraries.",NA
How it all started,"Sometime around 1997-98, when the draft of the first C++ Standard was 
  
 being finalized for publication as an ISO/IEC Standard, Robert Klarer from the IBM 
 Labs conceived the idea of a programming language that would be called BOOSE 
 (pronounced ""booz""), and which would compete with Java in the area of high-
 performance embedded software development, which the latter had been aimed at. 
 In a 1998 article for the now defunct 
 C++ Report
  magazine, C++ guru Herb Sutter 
 wrote a tongue-in-cheek spoof on this new language, whose name ostensibly 
 expanded to Bjarne's Object Oriented Software Environment. In this article, he 
 claimed that portability and 
 potability
  were, among other things, key advantages of 
 this language, which also supposedly promoted extraordinary camaraderie in team 
 environments and made developers excessively happy, communicative, and 
 passionate.
  
 [
  1 
 ]",NA
What is Boost?,"Boost is a collection of free, peer-reviewed, portable, open source libraries in C++. Over 
 the last decade and a half, there have been, as of this writing, 57 releases of the Boost 
 libraries. In this span, Boost has released libraries of compelling usefulness that promote 
 correct, portable, efficient, and readable C++ code. A number of prominent Standards 
 Committee members are also the most active participants in Boost and subsequent 
 directions of C++ standardization have been heavily influenced by the work done at Boost. 
 Boost has provided the Standards Committee with the laboratory they need to perfect 
 their ideas for the best new features that C++ should have. Several Boost libraries were 
 included in the 
 Technical Report 1
  of the C++ Standards Committee, which considerably 
 enhanced the functionality defined in the C++ 2003 revised standard; these included both 
 language and library features. Most of these libraries made it to the C++11 Standard 
 published in 2011. A couple more library features that originated in Boost have been 
 added to the latest revision of the C++ Standard known as C++14 (published in 2014).
  
 Over the years, Boost has added libraries for string and text processing, including 
 regular expression handling, generic containers compatible with the Standard Library, 
 smart pointers for efficient exception-safe memory management, concurrent 
 programming, network programming, interprocess communication, filesystem handling, 
 template metaprogramming, and many others. The following table lists some of the 
 prominent Boost libraries grouped by category. This is by no means exhaustive:
  
 Category
  
 Libraries
  
 Memory 
  
 management
  
 Smart Ptr, Align, Pool
  
 Data structures
  
 Container, Array, Multi-Index, Bimap, Pointer Container, Optional, 
 Variant, Any, Tuple, Assign
  
 Algorithms
  
 Algorithm, Range
  
 [
  2 
 ]",NA
Getting started with Boost libraries,"We shall now set up a development sandbox for you to write code using the Boost 
 libraries. We can either install a binary distribution of the Boost libraries, or build them 
 from source. If we build them from source, we have a whole range of concerns to take care 
 of from choosing a suitable naming convention for the library files and building the 
 libraries, to making sure that we are linking them to the correct versions of the library. 
 There are platform-specific differences too that need to be handled; we shall take a look at 
 both the Linux and Windows environments.",NA
Necessary software,"On Linux, we will only consider the C++ compiler (g++) version 4.8.1 or later, 
 distributed with the 
 GNU Compiler Collection
  (
 GCC
 ). On Windows, we will use 
 Visual Studio 2013. You can get more elaborate software support matrices for 
 each Boost release on the Boost website.
  
 [
  3 
 ]",NA
Linux toolchain,"You should be able to build Boost on most major Linux distributions. I use a Lubuntu 
 14.04 32-bit installation with GCC 4.8.1 and Clang 3.4. You can possibly build on much 
 older distributions, as the Boost website lists GCC 3.3 as the minimum supported version. 
 If you also want good C++11 support, use GCC 4.8 or higher.
  
 Required software
  
 Minimum 
 version
  
 Recommended 
 version
  
 Ubuntu package
  
 Fedora/ 
  
 CentOS 
 package
  
 GNU C++ compiler
  
 4.8.x
  
 4.8.4
  
 g++
  
 gcc-c++
  
 GNU Standard C++ 
 Library
  
 4.8.x
  
 4.8.4
  
 libstdc++-dev
  
 libstdc++-
 devel
  
 GNU Standard C++ 
 runtime
  
 4.8.x
  
 4.8.4
  
 libstdc++
  
 libstdc++
  
 If you want to use Clang instead of GCC, the recommended version is 3.4 or higher. Here 
 are the required packages on Ubuntu:
  
 Required software
  
 Minimum 
 version
  
 Recommended 
 version
  
 Ubuntu package
  
 LLVM compiler 
 toolchain
  
 3.2
  
 3.4
  
 llvm
  
 LLVM C, C++, and 
 Objective-C compiler
  
 3.2
  
 3.4
  
 clang
  
 LLVM C++ Standard 
 Library
  
 3.2
  
 3.4
  
 libc++-dev",NA
Windows toolchain,"You should be able to build Boost on Visual Studio 7.1 upwards. I use Visual Studio 2013 
 on a Windows 7 64-bit installation:
  
 Required 
  
 software
  
 Minimum 
 version
  
 Recommended version
  
 Visual Studio with Visual C++
  
 7.1
  
 12 (2013)
  
 I would also recommend installing 7-Zip on Windows to extract Boost sources 
 from the 
 .7z
  or 
 .tar.bz2
  archives, which offer much better compression than 
 the 
 .zip
  archives.
  
 [
  4 
 ]",NA
Obtaining and building Boost libraries,"You can build the Boost libraries from source or install them as an operating system 
 package on platforms where such as package is available. All examples in this book use 
 Boost version 1.57. You may choose to download a more recent version of the sources 
 and most of the discussion here should still hold. However, few details may change from 
 one release to the next, so you should be prepared to dig into the online documentation.",NA
Planning your Boost sandbox,"As part of our day-to-day development work using Boost, we would need access to 
 Boost's header files and Boost's libraries. A vast number of Boost libraries are 
 header-
 only
 , which means that you just need to include the appropriate headers and build 
 your sources. Some others have to be built into binary libraries that can be 
 linked 
 statically or dynamically
  to your application.
  
 If we build from source, we will first identify a directory on our development machine, 
 where we would like to install these files. The choice is arbitrary, but we can follow 
 conventions if they exist. So on Linux, we can choose to install the library headers and 
 binaries under 
 /opt/boost
 . On Windows, this could be 
 f:\code\libraries\Boost
 . 
  
 You are free to choose different paths, just avoid spaces within them for less hassle.",NA
Library naming conventions,"Boost library binaries can have names that are difficult to decipher at first. 
  
 So, we shall learn about what goes into naming the libraries. Library names have different 
 layouts. Depending on the layout, different components are added to the base name in 
 order to identify different facets of the library's binary compatibility and functionality.",NA
Library name components,"Each library, whether static or shared, is named according to a well-defined 
 scheme. The name of a library can be split into several components, not all of 
 which are mandatory:
  
 • 
  
 • 
  
 Prefix
 : Libraries may have a prefix, typically 
 lib
 . On Windows, only static 
 libraries have this prefix while on Unix, all libraries have this prefix.
  
 Toolset identifier
 : Library names may be tagged with the string, identifying the 
 toolset with which it was built. Roughly speaking, a toolset or toolchain is the set 
 of system utilities, including compiler, linker, archiver, and so on, that are used 
 to build libraries and programs. For example, 
 vc120
  identifies the Microsoft 
 Visual C++ 12.0 toolchain.
  
 [
  5 
 ]",NA
Library name layouts,"How a library name is made up of its components determines its name layout. There are 
 three kinds of name layouts supported by Boost: versioned, system, and tagged.",NA
Versioned layout,"It is the most elaborate layout and is the default layout on Windows. The general 
 structure of the versioned layout name is 
 libboost_<name>-<toolset>-
  
 <threading>-<ABI>-<version>.<ext>
 . For example, here is the 
 Boost.Filesystem 
 library debug DLL for Windows: 
 boost_filesystem-vc100-mt-gd-1_57.dll
 . The 
 tokens in the filename tell the complete story. This DLL was built using Visual C++ 10.0 
 compiler (
 -vc100
 ), is thread-safe (
 -mt
 ), and is a debug DLL (
 d
 ) linked dynamically to the 
 debug version of the runtime (
 g
 ). The version of Boost is 1.57 (
 1_57
 ).
  
 [
  6 
 ]",NA
System layout,"The default layout on Unix is the system layout that removes all the name decorations. 
 The general structure of library names in this layout is 
 libboost_<name>.<ext>
 . For 
 example, here is the 
 Boost.System
  shared library on Linux: 
 libboost_filesystem. 
 so.1.57.0
 . Looking at it, there is no way to tell whether it supports multithreading, 
 whether it is a debug library, or any other detail that you could wean from a filename in 
 the versioned layout. The 
 1.57.0
  suffix of the extension indicates the version of the 
 shared library. This is the Unix convention for versioning shared libraries and is not 
 affected by the Boost name layout.",NA
Tagged layout,"There is a third layout called the tagged layout, which is midway between 
  
 the versioned and system layouts in terms of detail. It removes all the version 
 information but retains other information. Its general structure is 
 libboost_<name>-
 <threading>-<ABI>.<ext>
 .
  
 Here is the 
 Boost.Exception
  static library from Windows built using the non-default 
 tagged layout: 
 libboost_filesystem-mt.lib
 . This is a static library as indicated by 
 its 
 lib-
  prefix. Also, 
 -mt
  indicates that this library is thread-safe, and the lack of an ABI 
 indicator means that this is not a debug library (
 d
 ), nor does it link to the static runtime 
 (
 s
 ). Also, it does not link to the debug version of the runtime (
 g
 ).
  
 The versioned layout is a bit unwieldy. On systems where you need to manually 
 specify names of libraries to link against, moving from one version of Boost to the next 
 would require some effort to fix the build scripts. The system layout is a bit 
 minimalistic and is great for environments where you need only one variant of a given 
 library. However, you cannot have both debug and release versions of the library, or 
 thread-safe and thread-unsafe ones side by side, with system layout. For this reason, in 
 the rest of this book, we will only use tagged layout for the libraries. 
  
 We will also only build thread-safe libraries (
 -mt
 ) and shared libraries (
 .dll
  or 
 .so
 ). 
 Some libraries can only be built as static libraries and, as such, would be automatically 
 created by the Boost build system. So now, we finally get to the point where we have 
 enough information to start creating our Boost sandbox.
  
 [
  7 
 ]",NA
Installing a Boost binary distribution,"On Microsoft Windows and several distributions of Linux, you can install a binary 
 distribution of the Boost libraries. The following table lists the methods of installing 
 Boost on some of the popular operating systems:
  
 Operating 
 system
  
 Package name
  
 Install method
  
 Microsoft 
 Windows
  
 boost_1_57_0-
 msvc-12.0-64.
  
 exe
  (64-bit)
  
 boost_1_57_0-
 msvc-12.0-32.
  
 exe
  (32-bit)
  
 Download executable from 
 http://sourceforge.
  
 net/projects/boost/files/boost-
  
 binaries/
  and install it by running the executable
  
 Ubuntu
  
 libboost-all-
 dev
  
 sudo apt-get install libboost-all-dev
  
 Fedora/ 
 CentOS
  
 boost-devel
  
 sudo yum install boost-devel
  
 Installing a binary distribution is convenient because it is the fastest way to be up 
 and running.",NA
Installing on Windows,"Starting with Boost 1.54, you can download a binary distribution of the Boost libraries, 
 built using Microsoft Visual Studio, from SourceForge. The download is available as a 
 64-bit or 32-bit installable executable that contains header files, libraries, sources, 
 documentation, and tools. There are separate distributions for different versions of 
 Visual Studio, from version 12 (VS 2013) backward through version 8 (VS 2005). The 
 name of the executable is of the form 
 boost_ver-msvc-vcver-W.exe
 , where 
 ver
  is 
 the Boost version (for example, 1_57_0), 
 vcver
  is the version of Visual C++ (for 
 example, 12.0 for Visual Studio 2013), and 
 W
  is the native word size of your operating 
 system (for example, 64 or 32).
  
 As part of the installation, you can choose the directory where you want to install the 
 Boost libraries. Let us consider that you choose to install it under 
 boost-dir
 . 
  
 Then, the following directories contain the necessary headers and libraries:
  
 Directory
  
 Files
  
 boost-dir
  
 This is the base directory of the Boost installation. All the header files are 
 present in a hierarchy under the 
 boost
  subdirectory.
  
 [
  8 
 ]",NA
Installing on Linux,"On Ubuntu, you need to install the 
 libboost-all-dev
  package. You need to perform 
 the installation using superuser privileges, so run the following command:
  
 $ sudo apt-get install libboost-all-dev
  
 This installs the necessary headers and libraries in the following directories:
  
 Directory
  
 Files
  
 /usr/include
  
 This contains all the header files present in a hierarchy under the 
 boost
  subdirectory.
  
 /usr/lib/arch-
 linux-gnu
  
 This contains all the Boost libraries, static and shared (DSOs). The 
 library filenames follow the system layout.
  
 Replace arch with 
 x86_64
  for 64-bit operating systems and with 
 i386
  for 32-bit operating systems.
  
 On CentOS/Fedora, you need to install the 
 boost-devel
  package. You need to 
 perform the installation using superuser privileges, so this is the command to run:
  
 $ sudo yum install boost-devel
  
 This installs the necessary headers and libraries in the following directories:
  
 Directory
  
 Files
  
 /usr/include
  
 This contains all the header files present in a hierarchy under the 
 boost directory.
  
 /usr/lib
  
 This contains all the Boost libraries, static and shared (DSOs). 
 The library filenames follow the system layout.
  
 [
  9 
 ]",NA
Building and installing the Boost libraries from ,NA,NA
source,"Building the Boost libraries from source offers more flexibility, as it is easy to customize 
 the build, use alternative compilers/toolchains, and change the default name layout like 
 we plan to. We shall build the Boost libraries from a source archive downloaded from 
 the Boost website 
 http://www.boost.org
  or 
 http:// 
 sourceforge.net/projects/boost
 . I prefer the 7-Zip or the bzip2 archives, as they 
 have the best compression ratios. We will use Boost libraries Version 1.57, and we will 
 look at building them only on Linux and Windows operating systems.",NA
Optional packages,"There are several 
 optional
  packages that are used to provide additional functionality by 
 certain Boost libraries when present. These include:
  
 • 
  
 • 
  
 • 
  
 The
  zlib
  and 
 bzip2
  development libraries, used by 
 Boost.IOStream 
 to read and write compressed archives in 
 gzip
  and 
 bzip2
  formats
  
 The 
 ICU i18n
  development libraries, which are heavily used by 
 Boost. 
 Locale
  and also by 
 Boost.Regex
  to support Unicode regular expressions
  
 The 
 expat
  XML parser library, used by the 
 Boost.Graph
  library to 
 support the GraphML XML vocabulary for describing graphs
  
 Some of these libraries may be made available through your native package 
  
 management systems, particularly on Linux. When installed from such packages, the 
 Boost build system may find these libraries automatically and link them by default. 
  
 If you chose to build these libraries from source and installed them at non-standard 
 locations instead, then you should use specific environment variables to point to the 
 installation directory of these libraries or to the 
 include
  and 
 library
  directories. The 
 following table summarizes these optional libraries, their source websites, Ubuntu 
 package names, and the environment variables needed by Boost to identify them when 
 installed from source:
  
 Library
  
 Details
  
 Zlib library (
 http://www.zlib.net
 )
  
 Environment variable: 
 ZLIB_SOURCE 
 (extracted source directory)
  
 Ubuntu packages: 
 zlib1g
 , 
 zlib1g-
 dev
 , and 
 zlib1c
  
 Bzip2 library (
 http://www.bzip.org/ 
 downloads.html
 )
  
 Environment variable: 
 BZIP2_SOURCE 
 (extracted source directory)
  
 Ubuntu packages: 
 libbz2
  and 
 libbz2-dev
  
 [
  10 
 ]",NA
Building the Boost libraries on Linux,"If you choose not to install a binary distribution of Boost or if such a distribution is not 
 available for your platform, then you must build the Boost libraries from source. 
 Download the source archives for the Boost libraries, 
 zlib
  and 
 bzip2
 . Assuming that you 
 want to install Boost in the
 /opt/boost
  directory, perform the following steps from a 
 shell command prompt to build Boost with the GNU toolchain:
  
 1. Create a directory and extract the Boost source archive in it:
  
 $ mkdir boost-src
  
 $ cd boost-src
  
 $ tar xfj /path/to/archive/boost_1_57_0.tar.bz2
  
 $ cd boost_1_57_0
  
 2. Generate the Boost build system for your toolset. The following should 
  
 work if you are building with 
 g++
 :
  
 $ ./bootstrap.sh
  
 If you are using Clang instead, run the following:
  
 $ ./bootstrap.sh toolset=clang cxxflags=""-stdlib=libc++ -
 std=c++11"" linkflags=""-stdlib=libc++""
  
 3. Extract the 
 bzip2
  and 
 zlib
  source archives and make a note of the 
  
 directories they have been extracted to.
  
 [
  11 
 ]",NA
Building the Boost libraries on Windows,"Once you have downloaded the Boost source archive, from a Windows Explorer 
 session, create a directory called 
 boost-src
  and extract the source archive inside this 
 directory. Assuming that you want to install Boost in the 
 boost-dir
  directory and 
 boost-build
  is the directory in which the intermediate products of the build are kept, 
 perform the following steps from a command prompt:
  
 1. Initialize the 32-bit Visual C++ build environment to build the Boost build 
  
 system (even if you want to build 64-bit):
  
 ""C:\Program Files\Microsoft Visual Studio 12.0\VC\vcvarsall.bat"" 
 x86
  
 2. On a 64-bit system with a 32-bit Visual Studio installation, Visual Studio is 
 typically installed under 
 C:\Program Files (x86)
 , so you will have to 
 run this command instead:
  
 ""C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\vcvarsall. 
 bat"" x86
  
 3. Generate the Boost build system for your toolset:
  
 cd /d drive:\path\to\boost-src
  
 bootstrap.bat
  
 4. If you want to build 64-bit Boost libraries, initialize the 64-bit Visual C++ 
  
 build environment:
  
 ""C:\Program Files\Microsoft Visual Studio 12.0\VC\vcvarsall.bat"" 
 x86_amd64
  
 5. On a 64-bit system with 32-bit Visual Studio installation, you will have to 
  
 run 
 this command instead:
  
 ""C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\vcvarsall. 
 bat"" x86_amd64
  
 6. Extract the 
 bzip2
  and 
 zlib
  source archives, and make a note of the 
  
 directories they have been extracted to.
  
 [
  13 
 ]",NA
Using Boost libraries in your projects ,"We shall now write our first small C++ program that uses the Boost Filesystem library 
 to check for the existence of a file whose name is passed to on the command line and 
 then build on Linux and Windows.
  
 Here is the listing for 
 chkfile.cpp
 :
  
  1 #include <iostream>
  
  2 #include <boost/filesystem.hpp>
  
  3 // define a short alias for the namespace
  
  4 namespace boostfs = boost::filesystem;
  
  5
  
  6 int main(int argc, char *argv[])
  
  7 {
  
  8   if (argc <= 1) {
  
  9     std::cerr << ""Usage: "" << argv[0] << "" <filename>"" 10               
 << std::endl; 
  
 11     return 1; 
  
 12   } 
  
 13 
  
 14   boostfs::path p(argv[1]); 
  
 15 
  
 16   if (boostfs::exists(p)) { 
  
 17     std::cout << ""File "" << p << "" exists."" << std::endl; 18   
 } else { 
  
 19     std::cout << ""File "" << p << "" does not exist."" << '\n'; 
 20   } 
  
 21 
  
 22   return 0; 
  
 23 }
  
 [
  15 
 ]",NA
Linking against Boost libraries on Linux,"If you have installed Boost in a nonstandard location (which is typically the case if you 
 have not installed it from a native package), then you will need to make sure that your 
 preprocessor can find the Boost header files you have included using the 
 –I
  option in 
 the compiler:
  
 $ g++ -c chkfile.cpp -I/opt/boost/include -std=c++11
  
 This step will create an object file called 
 chkfile.o
 , which we will link to the 
 binary. You can specify which library to link to using the 
 -l
  option. In case of a 
 nonstandard installation, you will need to ensure that the linker can find the path to 
 the library you want to link against using the 
 -L
  option:
  
 $ g++ chkfile.o -o chkfile -L/opt/boost/lib -lboost_filesystem-mt 
 -lboost_system-mt -std=c++11
  
  
 Use the 
 -std=c++11
  option only if you built your Boost 
  
  
 libraries using C++11.
  
 The preceding command line will work for either a static or a shared library. 
 However, if both types of library are found, it will use the shared version. 
  
 You can override this with appropriate linker options:
  
 $ g++ chkfile.o -o chkfile -L/opt/boost/lib -Wl,-Bstatic -lboost_ 
 filesystem-mt -Wl,-Bdynamic -lboost_system-mt -std=c++11
  
 In the preceding case, the 
 filesystem
  library is linked statically while others are 
 linked dynamically. The 
 -Wl
  switch is used to pass its arguments to the linker. In this 
 case, it passes the 
 -Bstatic
  and 
 -Bdynamic
  switches.
  
 If it is a shared library that you link against, then at runtime the dynamic linker 
 needs to locate the shared library and load it too. The way to ensure this varies 
 from one version of Unix to the other. One way to ensure this is to embed a search 
 path in your executable using the 
 rpath
  linker directive:
  
 $ g++ -o chkfile chkfile.o -L/opt/boost/lib -lboost_filesystem-mt -
 lboost_system-mt -Wl,-rpath,/opt/boost/lib:/usr/lib/boost -std=c++11
  
 On the target system, where the binary 
 mytest
  is run, the dynamic linker would look 
 for the 
 filesystem
  and 
 system
  shared libraries under 
 /opt/boost/lib 
 and 
 /usr/lib/boost
 .
  
 [
  16 
 ]",NA
Linking against Boost libraries on Windows,"Using the Visual Studio IDE, we will have to tweak certain project settings in order to 
 link against the Boost libraries.
  
 First, ensure that your compiler is able to find the necessary header files:
  
 1. Open your C++ project in Visual Studio. From the menu, select 
  
 Project
  | 
 Project Properties
 .
  
 2. In the 
 Property Pages
  dialog that comes up, expand 
 Configuration 
  
 Properties
  and select 
 C/C++
 .
  
 3. Edit the value of 
 Additional Include Directories
  by adding the path to your 
 Boost, include directories. Separate it from other entries in the field using a 
 semicolon:
  
  
 [
  17 
 ]",NA
Building the code listings in this book,"Each chapter in this book includes the example source code, which is also available for 
 download from the Packt website (
 http://www.packtpub.com
 ). You should 
 download and build these examples on your development machines.",NA
CMake,"In order to build the examples, you need to install CMake, which is one of the most 
 popular cross-platform build tools for C++ programs. With CMake, you can easily 
 generate a build system of your choice on an operating system of your choice, using a 
 single set of CMake specifications.
  
 You can download a binary package for CMake from 
 www.cmake.org
 , or download a 
 source archive and build it on a platform of your choice.
  
  
 Minimum version required
 : CMake 2.8.
  
  
 Windows
 : A 32-bit exe-installer is available for Windows that 
  
 works for both 32-bit and 64-bit builds.
  
 Linux
 : CMake is usually bundled with all major Linux distributions 
  
 and is available as an optional package. Consult your distribution's 
  
 package repository.",NA
Code examples,"Download the source code archive and extract it to a directory on your development 
 machine. The layout of the extracted directory would look like this:
  
  
 The source code archive available for download contains separate directories for each 
 chapter. Within each chapter directory, you will find the complete source code for each 
 example. The source code files are named based on the listing identifier.
  
 [
  20 
 ]",NA
Self-test questions ,"1. What are the different types of name layouts supported by Boost libraries?
  
 a. Tagged, native, and mangled 
  
 b. Tagged, mangled, and versioned 
  
 c. Tagged, versioned, and system 
  
 d. Versioned, systems, and decorated
  
 2. Boost allows you to automatically link to necessary Boost libraries on 
  
 Windows.
  
 a. True 
  
 b. False
  
 3. What does the following filename tell you about the library? 
 boost_date_time-vc100-mt-gd-1_57.dll 
  
 Tick all that apply.
  
 a. It is the DateTime library.
  
 b. It is a thread-safe library.
  
 c. It was built using g++.
  
 d. It is not a debug library.
  
 4. What is the name layout of the following library? 
  
 libboost_exception-mt-gd.lib
  
 a. Tagged 
  
 b. System 
  
 c. Versioned 
  
 d. Default",NA
Summary ,"In this chapter, we got an overview of the Boost C++ libraries and set up a 
 development environment for us, which should help us to easily build and run 
 C++ programs, using Boost libraries that we will learn in the rest of the book.
  
 In the next chapter, we will learn a variety of techniques using different Boost 
 libraries, which simplify some common day-to-day programming tasks and set us 
 up for the heavy lifting to be done in the later chapters.
  
 [
  23 
 ]",NA
The First Brush with ,NA,NA
Boost's Utilities,"Over the course of this book, we will focus on a number of Boost libraries that deal 
 with different subsystems, such as filesystems, threads, network I/O, and a variety of 
 containers, among others. In each chapter, we will delve into the details of a few such 
 libraries. This chapter is different, in the sense that we will pick up a set of useful and 
 varied tricks that will help you in almost all programming situations. 
  
 To that end we have the following topics lined up for us:
  
 • 
  
 Simple data structures
  
 • 
  
 Working with heterogeneous values
  
 • 
  
 Handling command-line arguments
  
 • 
  
 Other utilities and compile-time checks
  
 This is the kitchen-sink chapter that you can keep coming back to and scour for an 
 interesting technique that would seem to apply to a problem at hand.",NA
Simple data structures,"In this section, we will look at two different libraries that will help you create simple 
 data structures of immediate usefulness: Boost.Optional and Boost.Tuple. Boost.
  
 Optional can be used to represent optional values; objects that may or may not be 
 there. Boost.Tuple is used to create ordered sets of heterogeneous values.
  
 [
  25 
 ]",NA
Boost.Optional ,"Let us consider that you need to maintain about musicians in a data store. Among 
 other things, you can look up the latest album released by an artiste. You have written 
 a simple API in C++ for doing this:
  
 std::string find_latest_album_of(const std::string& artisteName);
  
 For simplicity we will ignore the possibility that two or more artistes could share the 
 same name. Here is a simple implementation of this function:
  
  1 #include <string>
  
  2 #include <map>
  
  3
  
  4 typedef std::map<std::string, std::string> artiste_album_map; 
 5
  
  6 extern artiste_album_map latest_albums;
  
  7
  
  8 std::string find_latest_album_of(
  
  9                     const std::string& artiste_name) { 
  
 10   auto iter = latest_albums.find(artiste_name); 
  
 11 
  
 12   if (iter != latest_albums.end()) { 
  
 13     return iter->second; 
  
 14   } else { 
  
 15     return """"; 
  
 16   } 
  
 17 }
  
 We store the names of artistes and their latest albums in a map called 
 latest_albums
 . 
 The 
 find_latest_album_of
  function takes the name of an artiste and uses the 
 find 
 member function of 
 std::map
  to look up the latest album. If it does not find an entry, it 
 returns an empty string. Now, it is possible that some artistes have not released an 
 album yet. Returning an empty string seems legit for such cases until you realize that 
 musicians have their unique whims and sometimes, they release an album without a 
 name. So, how do you distinguish between the cases where the musician is yet to release 
 an album, versus where the musician's latest album was untitled? In one case, there is 
 no value to return while in the other case, it is an empty string.
  
 [
  26 
 ]",NA
Accessing values stored in boost::optional,"You can check whether an 
 optional
  object contains a value or is empty, and extract the 
 value stored in a non-empty 
 optional
  object:
  
  1 std::string artiste(""Korn"");
  
  2 boost::optional<std::string> album = 
  
  3                             find_latest_album_of(artiste);
  
  4 if (album) {
  
 [
  28 
 ]",NA
get_value_or ,"Using 
 optional
 , we indicate that there may or may not be a value present for albums. 
 But we would sometimes need to use APIs that should have taken optional values but do 
 not. In such cases, we may want to return empty values with some default value. 
 Imagine residents of Paris being asked about their favorite city and for those who do not 
 name one, Paris being used as the default favorite:
  
  1 void printFavoriteCity(const std::string& name,
  
  2                        const std::string& city)
  
  3 {
  
  4   std::cout << name ""'s favorite city is "" << city << 
 '\n'; 5 }
  
  6
  
  7 boost::optional<std::string> getFavoriteCity(
  
  8                           const std::string& resident_id); 
 9 ...
  
 [
  29 
 ]",NA
Boost.Optional versus pointers,"If we did not use 
 optional
 , what would the functions 
 find_last_album_of
  or 
 lookup
  
 return in order to indicate that there was no value found? They would either need to 
 return a pointer to a dynamically-allocated object or 
 nullptr
  if there was no value 
 found. Besides using dynamic memory, it requires that the caller function manage the 
 lifetime of the dynamically-allocated object that is returned. This condition can be 
 mitigated using smart pointers (
 Chapter 3
 , 
 Memory Management and Exception Safety
 ), 
 but it does not eliminate free store allocations that are costly. The 
 boost::optional
  
 class eliminates free store allocations and stores the encapsulated object in its layout. In 
 addition, it stores a Boolean flag to keep track of whether it is initialized or not.",NA
Boost.Tuple,"Boost Tuples are a cool way to group disparate types of data together into ordered 
 tuples and pass them around. Structures do the same thing but a couple of things set 
 tuples apart:
  
 • 
  
 • 
  
 You can write generic code to manipulate tuples of all kinds, for example, to 
 print all their members and comparing two tuples for similarity in structure 
 and types.
  
 Each new structure or class defines a new type in your software. Types 
 should represent interfaces and behaviors. Representing every ad hoc 
 clumping of data with a type results in proliferation of types that have no 
 meaning in the problem space or its abstraction.
  
 A Boost Tuple is an incredibly useful library that helps you conveniently create schemas 
 for moving related data around together, such as exchanging data between functions. 
 Boost Tuples are a generalization of 
 std::pair
 , which is used to create 2-element 
 tuples.
  
 [
  30 
 ]",NA
Creating tuples ,"Let us look at an example. Given a series of stock prices at different points in time, we 
 want to find out the best two points in time to buy and sell the stock to maximize the 
 profit. We can assume that there is no option to short-sell, that is, you must buy before 
 you sell. For simplicity, the input can be assumed to be a vector of doubles. In this 
 vector, we are interested in the pair of indices that represent the best time to buy and 
 sell the stock to maximize profit:
  
 Listing 2.3: Using tuples
  
  1 #include <boost/tuple/tuple.hpp>
  
  2 #include <vector>
  
  3
  
  4 boost::tuple<size_t, size_t, double>
  
  5      getBestTransactDays(std::vector<double> prices)
  
  6 {
  
  7   double min = std::numeric_limits<double>::max();
  
  8   double gain = 0.0, max_gain = 0.0;
  
  9   size_t min_day, max_day; 
  
 10   size_t buy_day; 
  
 11   for (size_t i = 0, days = prices.size(); i < days; ++i) 
 { 12     if (prices[i] < min) { 
  
 13       min = prices[i]; 
  
 14       min_day = i; 
  
 15     } else if ((gain = prices[i] - min) > max_gain) { 16       
 max_gain = gain; 
  
 17       buy_day = min_day; 
  
 18       max_day = i; 
  
 19     } 
  
 20   } 
  
 21 
  
 22   return boost::make_tuple(buy_day, max_day, max_gain); 
 23 
 }
  
 [
  31 
 ]",NA
Accessing tuple elements,"There are several ways in which we can access the elements in a tuple. Look at the 
 following example of calling the 
 getBestTransactDays
  function:
  
  1 std::vector<double> stockPrices;
  
  2 ...
  
  3 boost::tuple<size_t, size_t, double> best_buy = 
  
  4                              getBestTransactDays(stockPrices);
  
  5 
  
  6 size_t buyDay = boost::get<0>(best_buy);  // Access 0th element
  
  7 size_t sellDay = boost::get<1>(best_buy); // Access 1st element
  
  8 double profit = boost::get<2>(best_buy); // Access 2nd element
  
 [
  32 
 ]",NA
Comparing tuples,"Tuples of the same length can be compared to relational operators, such as 
 ==
 , 
 <
 , 
 >
 , 
 <=
 , 
 and 
 >=
 . In any such comparison, the corresponding elements at each position are 
 compared. The types of elements at the corresponding positions need not be identical; 
 they just need to be comparable using the relational operator in question:
  
  1 boost::tuple<int, int, std::string> t1 = 
  
  2                          boost::make_tuple(1, 2, ""Hello"");
  
  3 boost::tuple<double, double, const char*> t2 = 
  
  4                         boost::make_tuple(1, 2, ""Hi"");
  
  5 assert(t1 < t2);   // because Hello < Hi
  
 Note that the actual types in tuples 
 t1
  and 
 t2
  are different, but both have the same length, 
 and the elements at corresponding positions are comparable with each other. In general, 
 comparison stops at the first pair of elements that determines the outcome of the 
 comparison. In this example, all three elements are compared because the first two 
 elements compare equal.
  
  1 boost::tuple<int, int, std::string> t1 = 
  
  2                          boost::make_tuple(1, 20, ""Hello"");
  
  3 boost::tuple<double, double, const char*> t2 = 
  
  4                        boost::make_tuple(1, 2, ""Hi"");
  
  5 assert(t1 > t2);    // because 20 > 2
  
 [
  33 
 ]",NA
Writing generic code using tuples,"We will now write a generic function to find the number of elements in a tuple:
  
  1 template <typename T>
  
  2 size_t tuple_length(const T&) {
  
  3   return boost::tuples::length<T>::value;
  
  4 }
  
 This function simply uses the 
 boost::tuples::length<T>
  metafunction to compute the 
 number of elements in the tuple. This computation takes place at compile time. 
  
 A 
 metafunction
  is just a class template that has an accessible static member or a 
 nested type computed at compile time from its template arguments (see 
 Chapter 7
 , 
 Higher Order and Compile-time Programming
 , for a more rigorous definition). In this 
 case, the 
 boost::tuples::length<T>
  metafunction has a public static member 
 called 
 value
 , which is computed as the number of elements in the tuple 
 T
 . If you use 
 tuples from the Standard Library, you should use 
 std::tuple_size<T> 
 instead of 
 boost::tuples::length<T>
 . This is just a small illustration of generic programming 
 using metafunctions and type computation.",NA
Working with heterogeneous values,"The need to have a value that can hold different types of data at different times during the 
 lifetime of a program is not new. C++ supports the 
 union
  construct of C, which essentially 
 allows you to have a single type that can, at different times, assume values of different 
 underlying POD types. 
 POD
  or 
 Plain Old Data
  types, roughly speaking, are types that do 
 not require any special initialization, destruction, and copying steps and whose semantic 
 equivalents may be created by copying their memory layouts byte for byte. 
  
 [
  34 
 ]",NA
Boost.Variant,"Boost Variant avoids all that is wrong with C++ unions and provides a union-like 
 construct defined over a fixed set of arbitrary types, not just POD types. We can define a 
 variant datatype using the Boost Variant header-only library by instantiating the 
 boost::variant
  template with a list of types. The list of types identifies the different 
 types of values that the variant object can assume at different points in time. The different 
 types in the list can be varied and unrelated, conforming to only one binding condition—
 that each of the types be copyable or at least movable. You may even create variants that 
 contain other variants.
  
 In our first example, we create a variant of an integer, a 
 std::string
 , and two user-
 defined types 
 Foo
  and 
 Bar
 . With this, we illustrate the constraints on creating variant 
 types and on operations that can be performed on such variant values:
  
 [
  35 
 ]",NA
Accessing values in a variant,"We use the 
 boost::get<T>
  function template to access the value of type 
 T
  in a variant, 
 where 
 T
  is the concrete type of the value we want. This function, when called on a variant 
 reference, returns a reference to the stored value or throws a 
 boost::bad_get
  exception 
 if the stored value is not of the type specified. When called on a pointer to a variant, it 
 returns the address of the stored value or a null pointer if the stored value is not of the 
 specified type. The latter behavior can be used to test whether a variant stores a 
 particular type of value or not, the way it was used in listing 2.4 (line 23). This behavior of 
 get<>
  closely mirrors that of 
 dynamic_cast
 :
  
 Listing 2.5: Accessing values in a variant
  
  1 #include <boost/variant.hpp>
  
  2 #include <string>
  
  3 #include <cassert>
  
  4 
  
  5 int main() {
  
  6   boost::variant<std::string, int> v1;
  
  7   v1 = ""19937"";                    // sets string
  
  8   int i1;
  
  9 
  
 10   try { 
  
 [
  37 
 ]",NA
Compile-time visitation,"How the value stored in a variant is consumed usually depends on the type of the 
 value. Checking a variant for each possible type using an if-else ladder can quickly 
 aggravate the readability and maintainability of your code. Of course, we can find out 
 the zero-based index of the type of the current value using the 
 which
  member method 
 of the variant, but it would be of little immediate use. Instead, we will look at a very 
 elegant and versatile compile-time visitation mechanism provided by the Boost 
 Variant library without which handling variants would be quite a drag.
  
 The idea is to create a visitor class that contains an overloaded function call operator 
 (
 operator()
 ) to handle each type that may be stored in the variant. Using the function 
 boost::apply_visitor
 , we can invoke the appropriate overload in the visitor class on a 
 variant object, based on the type of value it contains.
  
 [
  38 
 ]",NA
Generic visitors,"You may create a member function template that handles a family of types. In cases where 
 the code for handling different types does not significantly differ, it may make sense to 
 have such member templates. Here is an example of a visitor which prints the contents of 
 the variant:
  
 Listing 2.7: Generic compile-time visitation
  
  1 #include <boost/variant.hpp>
  
  2
  
  3 struct PrintVisitor : boost::static_visitor<>
  
  4 {
  
  5    template <typename T>
  
  6    void operator() (const T& t) const {
  
  7      std::cout << t << '\n';
  
  8    }
  
  9 };
  
 10
  
 11 boost::variant<std::string, double, long, Foo> v1;
  
 12 boost::apply_visitor(PrintVisitor(), v1);
  
 In the preceding code, we define a variant over the types 
 std::string
 , 
 double
 , 
 long
 , 
 and 
 Foo
 . The visitor class 
 PrintVisitor
  contains a generic 
 operator()
 . As long as all 
 the types in the variant are 
 streamable
 , this code will compile and print the value of the 
 variant to the standard output.
  
 [
  40 
 ]",NA
Applying visitors to variants in a container,"Often, we have an STL container of variant objects, and we want to visit each object 
 using our visitor. We can utilize the 
 std::for_each
  STL algorithm and a single-
 argument overload of 
 boost::apply_visitor
  for the purpose. The single-argument 
 overload of 
 boost::apply_visitor
  takes a visitor instance and returns a functor 
 that applies the visitor to a passed element. The following example best illustrates the 
 usage:
  
  1 #include <boost/variant.hpp>
  
  2
  
  3 std::vector<boost::variant<std::string, double, long> > vvec;
  
  4 …
  
  5 std::for_each(vvec.begin(), vvec.end(),
  
  6                  boost::apply_visitor(SimpleVariantVisitor()));",NA
Defining recursive variants,"The last few years have seen a phenomenal growth in the popularity of one 
  
 particular data interchange format—JavaScript Object Notation or JSON. It is a simple 
 text-based format that is often less verbose XML. Originally used as object literals in 
 JavaScript, the format is more readable than XML. It is also a relatively simple format that 
 is easy to understand and parse. In this section, we will represent well-formed JSON 
 content using 
 boost::variants
  and see how variants can handle recursive definitions.",NA
The JSON format,"To start with, we will look at an example of people records in the JSON notation:
  
  {
  
  ""Name"": ""Lucas"",
  
  ""Age"": 38,
  
  ""PhoneNumbers"" : [""1123654798"", ""3121548967""],
  
  ""Address"" : { ""Street"": ""27 Riverdale"", ""City"": ""Newtown"", 
  
  ""PostCode"": ""902739""}
  
  }
  
 [
  41 
 ]",NA
Representing JSON content with recursive variants,"If we were to declare a variant to represent a basic token in a JSON, it would look like 
 this:
  
  1 struct JSONNullType {};
  
  2 boost::variant<std::string, double, bool, JSONNullType> jsonToken;
  
 The type 
 JSONNullType
  is an empty type that may be used to represent a null 
 element in JSON.
  
 To extend this variant to represent more complex JSON content, we will try to 
 represent a JSON object—a key-value pair as a type. The keys are always strings, but 
 the values can be any of the types listed above or another nested object. So, the 
 definition of a JSON object is essentially recursive, and this is why we need a 
 recursive variant definition to model it.
  
 To include the definition of a JSON object in the preceding variant type, we use a 
 metafunction called 
 boost::make_recursive_variant
 . It takes a list of types and 
 defines the resultant recursive variant type as a nested type called 
 type
 . So, here is 
 how we write a recursive definition of the variant:
  
  1 #define BOOST_VARIANT_NO_FULL_RECURSIVE_VARIANT_SUPPORT
  
  2 #include <boost/variant.hpp>
  
  3
  
  4 struct JSONNullType {};
  
  5
  
  6 typedef boost::make_recursive_variant<
  
  7                      std::string,
  
  8                      double,
  
  9                      bool,
  
 10                      JSONNullType,
  
 11                      std::map<std::string,
  
 12                               boost::recursive_variant_>
  
 13                     >::type JSONValue;
  
 The 
 #define
  statement on line 1 may be necessary for many compilers where the 
 support for recursive variants, especially using 
 make_recursive_variant
 , is 
 limited.
  
 [
  43 
 ]",NA
Visiting recursive variants ,"We shall now write a visitor to print JSON data stored in a variant in its standard 
 notation. Visiting a recursive variant is not different from visiting a nonrecursive one. 
 We still need to define overloads that can handle all types of values that the variant 
 may store. In addition, in the overloads for the recursive aggregate types (in this 
 case,
  JSONArray
  and 
 JSONObject
 ), we may need to recursively visit each of its 
 elements:
  
 Listing 2.8b: Visiting recursive variants
  
  1 void printArrElem(const JSONValue& val);
  
  2 void printObjAttr(const JSONObject::value_type& val); 
  
  3
  
  4 struct JSONPrintVisitor : public boost::static_visitor<void> 5 
 {
  
  6   void operator() (const std::string& str) const
  
  7   {
  
  8     std::cout << '""' << escapeStr(str) << '""';
  
  9   } 
  
 10 
  
 11   void operator() (const JSONNullType&) const 
  
 12   { 
  
 13     std::cout << ""null""; 
  
 14   } 
  
 15 
  
 16   template <typename T> 
  
 17   void operator()(const T& value) const 
  
 18   { 
  
 19     std::cout << std::boolalpha << value; 
  
 20   } 
  
 21 
  
 22   void operator()(const JSONArray& arr) const 
  
 23   { 
  
 24     std::cout << '['; 
  
 25 
  
 26     if (!arr.empty()) { 
  
 27       boost::apply_visitor(*this, arr[0]); 
  
 28       std::for_each(arr.begin() + 1, arr.end(), printArrElem); 
 29     } 
  
 30 
  
 [
  45 
 ]",NA
Boost.Any,"The Boost Any library takes a different route to store heterogeneous data than Boost 
 Variant. Unlike Variant, Any allows you to store almost any type of data not limited to a 
 fixed set and maintains the runtime type information of the stored data. Thus, it does not 
 use templates at all and requires that 
 Runtime Type Identification
  (
 RTTI
 ) be enabled, 
 while compiling the code using Boost Any (most modern compilers keep this enabled by 
 default).
  
  
 For the Boost Any library to work correctly, you must not disable 
  
  
 the generation of RTTI for your programs.
  
 In the following example, we create instances of 
 boost::any
  to store numeric data, 
 character arrays, and non-POD type objects:
  
 Listing 2.9: Using Boost Any
  
  1 #include <boost/any.hpp>
  
  2 #include <vector>
  
  3 #include <iostream>
  
  4 #include <string>
  
 [
  47 
 ]",NA
Boost.Conversion,"If you have ever tried parsing a text input (from a file, standard input, network, and so 
 on) and tried a semantic translation of the data in it, you would have possibly felt the 
 need for an easy way to convert text to numeric values. The opposite problem is to 
 write text output based on values of numeric and textual program variables. 
  
 The 
 basic_istream
  and 
 basic_ostream
  classes provide facilities for reading and 
 writing specific types of values. However, the programming model for such uses is not 
 very intuitive or robust. The C++ Standard Library and its extensions offer various 
 conversion functions with various degrees of control, flexibility, and a general lack of 
 usability. For example, there exists a whole slew of functions that convert between 
 numeric and character formats or the other way round (for example, 
 atoi
 , 
 strtol
 , 
 strtod
 , 
 itoa
 , 
 ecvt
 , 
 fcvt
 , and so on). If we were trying to write generic code for 
 converting between types, we would not even have the option of using any of these 
 functions, which only work for conversions between specific types. How can we define a 
 generic conversion syntax that can be extended to arbitrary types?
  
 The Boost 
 Conversion
  library introduces a couple of function templates that provide a 
 very intuitive and uniform conversion syntax, which can also be extended through user-
 defined specializations. We will look at the conversion templates one by one.
  
 [
  50 
 ]",NA
lexical_cast ,"The 
 lexical_cast
  function template can be used to convert a source type to a 
 target type. Its syntax resembles the syntax of various C++ casts:
  
 #include <boost/lexical_cast.hpp> 
  
 namespace boost { 
  
 template <typename T, typename S> 
  
 T lexical_cast (const S& source); 
  
 }
  
 The following example shows how we can use 
 lexical_cast
  to convert a string to an 
 integer:
  
 Listing 2.11: Using lexical_cast
  
  1 std::string str = ""1234"";
  
  2
  
  3 try {
  
  4   int n = boost::lexical_cast<int>(str);
  
  5   assert(n == 1234);
  
  6 } catch (std::exception& e) {
  
  7   std::cout << e.what() << '\n';
  
  8 }
  
 We apply 
 lexical_cast
  (line 4) to convert a value of type 
 std::string
  to a value of 
 int
 . The beauty of this approach is that it can provide a uniform syntax to all 
 conversions and can be extended to new types. If the string does not contain a valid 
 numeric string, then the 
 lexical_cast
  invocation will throw an exception of type 
 bad_lexical_cast
 .
  
 Overloads of the 
 lexical_cast
  function template are provided to allow the 
 conversion of a part of a character array:
  
 #include <boost/lexical_cast.hpp> 
  
 namespace boost { 
  
 template <typename T > 
  
 T lexical_cast (const char* str, size_t 
 size); }
  
 We can use the preceding function in the following way:
  
  1 std::string str = ""abc1234"";
  
  2
  
  3 try {
  
  4   int n = boost::lexical_cast<int>(str.c_str() + 3, 
 4); 5   assert(n == 1234);
  
 [
  51 
 ]",NA
Handling command-line arguments,"Command-line arguments, like API parameters, are the remote control buttons that help 
 you tune the behavior of commands to your advantage. A well-designed set of 
 command-line options is behind much of the power of a command. In this section, we 
 will see how the Boost.Program_Options library helps you add support for a rich and 
 standardized set of command-line options to your own programs.",NA
Designing command-line options,"C provides the most primitive abstraction for the command line of your program. 
  
 Using the two arguments passed to the main function—the number of arguments (
 argc
 ) 
 and the list of arguments (
 argv
 )—you can find out about each and every argument 
 passed to the program and their relative ordering. The following program prints 
 argv[0]
 , which is the path to the program itself with which the program was invoked. 
 When run with a set of command-line arguments, the program also prints each 
 argument on a separate line. 
  
 [
  52 
 ]",NA
The diff command – a case study,"Programs usually document a set of command-line options and switches that modify their 
 behavior. Let us take a look at the example of the 
 diff
  command in Unix. The 
 diff
  
 command is run like this:
  
 $ diff file1 file2
  
 It prints the difference between the content of the two files. There are several ways in 
 which you can choose to print the differences. For each different chunk found, you may 
 choose to print a few additional lines surrounding the difference to get a better 
 understanding of the context in which the differing part appears. These surrounding lines 
 or ""context"" do not differ between the two files. To do this, you can use one of the 
 following alternatives:
  
 $ diff -U 5 file1 file2
  
 $ diff --unified=5 file1 file2
  
 Here, you choose to print five additional lines of context. You can also choose the 
 default of three by specifying:
  
 $ diff --unified file1 file2
  
 In the preceding examples, 
 -U
  or 
 --unified
  are examples of command-line options. 
 The former is a short option consisting of a single leading hyphen and a single letter (
 -
 U
 ). The latter is a long option with two leading hyphens and a multi-character option 
 name (
 --unified
 ).
  
 [
  53 
 ]",NA
Using Boost.Program_Options ,"The Boost Program Options library provides you with a declarative way of parsing 
 command lines. You can specify the set of options and switches and the type of option-
 values for each option that your program supports. You can also specify which set of 
 conventions you want to support for your command line. You can then feed all of this 
 information to the library functions that parse and validate the command line and 
 extract all the command-line data into a dictionary-like structure from which you can 
 access individual bits of data. We will now write some code to model the previously 
 mentioned options for the 
 diff
  command:
  
 Listing 2.12a: Using Boost Program Options
  
  1 #include <boost/program_options.hpp>
  
  2
  
  3 namespace po = boost::program_options;
  
  4 namespace postyle = boost::program_options::command_line_style; 5 
  
  6 int main(int argc, char *argv[])
  
  7 {
  
  8   po::options_description desc(""Options"");
  
  9   desc.add_options() 
  
 10      (""unified,U"", po::value<unsigned int>()->default_value(3), 
 11             ""Print in unified form with specified number of "" 12             
 ""lines from the surrounding context"") 
  
 13      ("",p"", ""Print names of C functions "" 
  
 14             "" containing the difference"") 
  
 15      ("",N"", ""When comparing two directories, if a file exists in"" 
 16             "" only one directory, assume it to be present but "" 
 17             "" blank in the other directory"") 
  
 18      (""help,h"", ""Print this help message"");
  
 In the preceding code snippet, we declare the structure of the command line using an 
 options_description
  object. Successive options are declared using an overloaded 
 function call 
 operator()
  in the object returned by the 
 add_options
 . You can cascade 
 calls to this operator in the same way that you can print multiple values by cascading calls 
 to the insertion operator (
 <<
 ) on 
 std::cout
 . This makes for a highly readable 
 specification of the options.
  
 We declare the 
 --unified
  or 
 -U
  option specifying both the long and short options in a 
 single string, separated by a comma (line 10). The second argument indicates that we 
 expect a numeric argument, and the default value will be taken as 
 3
  if the argument is 
 not specified on the command line. The third field is the description of the option and 
 will be used to generate a documentation string.
  
 [
  55 
 ]",NA
Parsing positional parameters ,"If you were observant, you would have noticed that we did nothing to read the two file 
 names; the two main operands of the 
 diff
  command. We did this for simplicity, and we 
 will fix this now. We run the 
 diff
  command like this:
  
 $ diff -pN --unified=5 old_source_dir new_source_dir
  
 The 
 old_source_dir
  and 
 new_source_dir
  arguments are called positional 
  
 parameters. They are not options or switches, nor are they arguments to any options. 
  
 In order to handle them, we will have to use a couple of new tricks. First of all, we must 
 tell the parser the number and type of these parameters that we expect. Second, we must 
 tell the parser that these are positional parameters. Here is the code snippet:
  
  1 std::string file1, file2;
  
  2 po::options_description posparams(""Positional params"");
  
  3 posparams.add_options()
  
  4         (""file1"", po::value<std::string>(&file1)->required(), """") 
 5         (""file2"", po::value<std::string>(&file2)->required(), """"); 
 6 desc.add(posparams);
  
  7
  
  8
  
  9 po::positional_options_description posOpts; 
  
 10 posOpts.add(""file1"", 1);  // second param == 1 indicates that 11 
 posOpts.add(""file2"", 1);  //  we expect only one arg each 
  
 12 
  
 13 po::store(po::command_line_parser(argc, argv) 
  
 14                 .options(desc) 
  
 15                 .positional(posOpts) 
  
 16                 .style(windows_style) 
  
 17                 .run(), vm);
  
 [
  58 
 ]",NA
Multiple option values,"In some cases, a single option may take multiple option values. For example, during 
 compilation, you will use the 
 -I
  option multiple times to specify multiple directories. 
  
 To parse such options and their option values, you can specify the target type as a 
 vector, as shown in the following snippet:
  
  1 po::options_description desc(""Options"");
  
  2 desc.add_option()
  
  3      (""include,I"", po::value<std::vector<std::string> >(),
  
  4       ""Include files."")
  
  5      (…);
  
 This will work on an invocation like this:
  
 $ c++ source.cpp –o target -I path1 -I path2 -I path3
  
 In some cases, however, you might want to specify multiple option values, but you 
 specify the option itself only once. Let us say that you are running a command to 
 discover assets (local storage, NICs, HBAs, and so on) connected to each of a set of 
 servers. You can have a command like this:
  
 $ discover_assets --servers svr1 svr2 svr3 --uid user
  
 [
  59 
 ]",NA
Other utilities and compile-time checks ,"Boost includes a number of micro-libraries that provide small but useful 
  
 functionalities. Most of them are not elaborate enough to be separate libraries. 
 Instead, they are grouped under 
 Boost.Utility
  and 
 Boost.Core
 . We will look at 
 two such libraries here.
  
 We will also look at some useful ways to detect errors as early as possible, at 
 compile time, and glean information about the program's compilation 
 environment and tool chains using different facilities from Boost.
  
 [
  60 
 ]",NA
BOOST_CURRENT_FUNCTION ,"When writing debug logs, it is incredibly useful to be able to write function names and 
 some qualifying information about functions from where logging is invoked. 
  
 This information is (obviously) available to compilers during the compilation of 
 sources. However, the way to print it is different for different compilers. Even for a 
 given compiler, there may be more than one ways to do it. If you want to write 
 portable code, this is one wart you have to take care to hide. The best tool for this is 
 the macro 
 BOOST_CURRENT_FUNCTION
 , formally a part of 
 Boost.Utility
 , shown in 
 action in the following example:
  
 Listing 2.13: Pretty printing current function name
  
  1 #include <boost/current_function.hpp>
  
  2 #include <iostream>
  
  3
  
  4 namespace FoFum {
  
  5 class Foo
  
  6 {
  
  7 public:
  
  8   void bar() {
  
  9     std::cout << BOOST_CURRENT_FUNCTION << '\n'; 
 10     bar_private(5); 
  
 11   } 
  
 12 
  
 13   static void bar_static() { 
  
 14     std::cout << BOOST_CURRENT_FUNCTION << '\n'; 
 15   } 
  
 16 
  
 17 private: 
  
 18   float bar_private(int x) const { 
  
 19     std::cout << BOOST_CURRENT_FUNCTION << '\n'; 
 20   return 0.0; 
  
 21   } 
  
 22 }; 
  
 23 } // end namespace FoFum 
  
 24 
  
 25 namespace { 
  
 26 template <typename T> 
  
 27 void baz(const T& x) 
  
 28 { 
  
 29   std::cout << BOOST_CURRENT_FUNCTION << '\n'; 
 30 }
  
 [
  61 
 ]",NA
Boost.Swap ,"The Boost Swap library is yet another useful micro library and is part of Boost Core:
  
 #include <boost/core/swap.hpp> 
  
 namespace boost {
  
  
  template<typename T1, typename T2>
  
  
  void swap(T1& left, T2& right); 
  
 }
  
 It wraps a well-known idiom around swapping objects. Let us first look at the 
 problem itself to understand what is going on.
  
 There is one global 
 swap
  function in the 
 std
  namespace. In many cases, for a type 
 defined in a particular namespace, a specialized 
 swap
  overload may be provided in the 
 same namespace. When writing generic code, this can pose some challenges. 
  
 Imagine a generic function that calls 
 swap
  on its arguments:
  
  1 template <typename T>
  
  2 void process_values(T& arg1, T& arg2, …)
  
  3 {
  
  4   …
  
  5   std::swap(arg1, arg2);
  
 In the preceding snippet, we call 
 std::swap
  on line 5 to perform the swapping. While 
 this is well-formed, this may not do what is desired in some cases. Consider the 
 following types and functions in the namespace 
 X
 :
  
  1 namespace X {
  
  2   struct Foo {};
  
  3
  
  4   void swap(Foo& left, Foo& right) { 
  
  5     std::cout << BOOST_CURRENT_FUNCTION << '\n'; 
 6   }
  
  7 }
  
 Of course, 
 X::Foo
  is a trivial type and 
 X::swap
  is a no-op, but they can be replaced 
 with a meaningful implementation and the points we make here would still hold.
  
 [
  63 
 ]",NA
Compile-time asserts,"Compile-time asserts require certain conditions to hold true at some point in the code. 
 Any violation of the condition causes the compilation to fail at the point. It is an effective 
 way to find errors at compile time, which otherwise would cause serious grief at 
 runtime. It may also help reduce the volume and verbosity of compiler error messages 
 of the sort generated due to template instantiation failures.
  
 Runtime asserts are meant to corroborate the invariance of certain conditions that must 
 hold true at some point in the code. Such a condition might be the result of the logic or 
 algorithm used or could be based on some documented convention. For example, if you 
 are writing a function to raise a number to some power, how do you handle the 
 mathematically undefined case of both the number and the power being zero? You can 
 use an assert to express this explicitly, as shown in the following snippet (line 6):
  
  1 #include <cassert>
  
  2
  
  3 double power(double base, double exponent)
  
  4 {
  
  5   // no negative powers of zero
  
  6   assert(base != 0 || exponent > 0);
  
  7   …
  
  8 }
  
 Any violation of such invariants indicates a bug or a flaw, which needs to be fixed, and 
 causes a catastrophic failure of the program in debug builds. Boost provides a macro 
 called 
 BOOST_STATIC_ASSERT
  that takes an expression, which can be evaluated at 
 compile time and triggers a compilation failure if this expression evaluates to false.
  
 For example, you may have designed a memory allocator class template that is 
 meant to be used only with ""small"" objects. Of course, smallness is arbitrary, but 
 you can design your allocator to be optimized for objects of size 16 bytes or 
 smaller. If you want to enforce correct usage of your class, you should simply 
 prevent its instantiation for any class of size greater than 16 bytes. Here is our first 
 example of 
 BOOST_STATIC_ASSERT
  that helps you enforce the small object 
 semantics of your allocator:
  
 Listing 2.16a: Using compile-time asserts
  
  1 #include <boost/static_assert.hpp>
  
  2
  
  3 template <typename T>
  
 [
  65 
 ]",NA
Diagnostics using preprocessor macros,"A number of times in my career as a software engineer, I have worked on products with 
 a single code base that were built on five different flavors of Unix and on Windows, often 
 in parallel. Often these build servers would be big iron servers with hundreds of gigs of 
 attached storage that would be used by multiple products for the purpose of building. 
 There would be myriad environments, tool chains, and configurations cohabiting on the 
 same server. It must have taken ages to stabilize these systems to a point where 
 everything built perfectly. One day, all hell broke loose when, overnight, without any 
 significant check-ins having gone in, our software started acting weird. It took us almost 
 a day to figure out that someone had tinkered with the environment variables, as a 
 result of which we were linking using a different version of the compiler and linking 
 with a different runtime from the one with which our third-party libraries were built. I 
 don't need to tell you that this was not ideal for a build system even at the time that it 
 existed. Unfortunately, you may still find such messed up environments that take a long 
 time to set up and then get undone by a flippant change. What saved us that day after 
 half a day's fruitless toil was the good sense of using preprocessor macros to dump 
 information about the build system, including compiler names, versions, architecture, 
 and their likes at program startup. We could soon glean enough information from this 
 data dumped by the program, before it inevitably crashed and we spotted the compiler 
 mismatch.
  
 Such information is doubly useful for library writers who might be able to provide the 
 most optimal implementation of a library on each compiler or platform by leveraging 
 specific interfaces and doing conditional compilation of code based on preprocessor 
 macro definitions. The bane of working with such macros is, however, the absolute 
 disparity between different compilers, platforms, and environments on how they are 
 named and what their function is. Boost provides a much more uniform set of 
 preprocessor macros for gleaning information about the software build environment 
 through its 
 Config
  and 
 Predef
  libraries. We will look at a handful of useful macros 
 from these libraries.
  
 [
  69 
 ]",NA
Self-test questions ,"For multiple choice questions, choose all the options that apply:
  
 1. What are the advantages of using 
 boost::swap
  over 
 std::swap
 ?
  
 a. There is no real advantage 
  
 b. 
 boost::swap
  invokes swap overloads supplied with the passed type, if 
 any 
  
 c. 
 boost::swap
  is faster than 
 std::swap 
  
 d. 
 boost::swap
  does not throw exceptions
  
 2. Can you apply a visitor to multiple variant arguments in a single call? (
 Hint
 : you 
 may want to look up the online documentation) 
  
 a. Yes. A visitor can only be applied to one or two variant arguments b. Yes. A 
 visitor can be applied to one or more arguments 
  
 c. No. The member operators take only one variant argument 
  
 d. None of the above
  
 3. Is the following a valid compile-time assert? 
  
 BOOST_STATIC_ASSERT(x == 0);  // x is some variable 
  
 a. Yes, provided 
 x
  is of an integral type 
  
 b. Yes, provided 
 x
  is declared as a 
 const static
  numeric variable 
  
 c. No, 
 x
  is a variable, and its value cannot be known at compile time d. Only 
 expressions involving 
 sizeof
  are valid in a 
 BOOST_STATIC_ASSERT
  
 4. What do we mean when we say that a type 
 X
  is a POD type? a. 
 X
  
 does not have a user-defined constructor or destructor b. 
 X
  
 can be copied by copying its memory layout bit-wise c. 
 X
  does 
 not have a user-defined copy constructor or copy assignment 
 operator 
  
 d. All of the above
  
 [
  73 
 ]",NA
Summary,"This chapter was a quick tour of several Boost libraries that help you do important 
 programming chores, such as parsing command lines, creating type-safe variant types, 
 handling empty values, and performing compile-time checks.
  
 Hopefully, you have appreciated the diversity of libraries in Boost and the 
 expressive power they lend to your code. In the process, you would have also 
 become more familiar with compiling code that uses the Boost libraries and 
 linking to the appropriate libraries as needed.
  
 In the next chapter, we will look at how you can deterministically manage heap 
 memory and other resources in exception-safe ways using various flavors of 
 Boost's smart pointers.",NA
References,"Curiously Recurring Template Pattern: 
 https://en.wikibooks.org/wiki/ 
 More_C%2B%2B_Idioms/Curiously_Recurring_Template_Pattern
  
 [
  74 
 ]",NA
Memory Management and ,NA,NA
Exception Safety,"C++ has a great deal of compatibility with the C programming language. C++ retains 
 pointers for representing and accessing specific memory addresses and provides manual 
 memory management primitives via the 
 new
  and 
 delete
  operators. You can also 
 seamlessly access from C++, the C Standard Library functions and C system calls or 
 platform APIs of most major operating systems. Naturally, C++ code often deals with 
 handles
  to various OS resources, like heap memory, open files, sockets, threads, and 
 shared memory. Acquiring such resources and failing to release them could have 
 undesirable consequences for your programs, showing up as insidious bugs, including 
 memory leaks and deadlocks.
  
 In this chapter, we look at ways of encapsulating pointers to dynamically-allocated 
 objects using 
 smart pointers
  to ensure that they are automatically deallocated when 
 they are no longer needed. We then extend these techniques to non-memory 
 resources. In the process, we develop an understanding of what is meant by exception-
 safe code and use smart pointers to write such code.
  
 These topics are divided into the following sections:
  
 • 
  
 Dynamic memory allocation and exception safety
  
 • 
  
 Smart pointers
  
 • 
  
 Unique ownership semantics
  
 • 
  
 Shared ownership semantics
  
 For some sections of this chapter, you will need access to a compiler with C++11 
 support. This will be called out with additional instructions in individual sections.
  
 [
  75 
 ]",NA
Dynamic memory allocation and ,NA,NA
exception safety ,"Imagine that you have to write a program to rotate images. Your program takes the 
 name of the file and the angle of rotation as input, reads the contents of the file, 
 performs the processing, and returns the output. Here is some sample code.
  
  1 #include <istream>
  
  2 #include <fstream>
  
  3 typedef unsigned char byte;
  
  4 
  
  5 byte *rotateImage(std::string imgFile, double angle, 
  
  6                   size_t& sz) {
  
  7   // open the file for reading
  
  8   std::ifstream imgStrm(imgFile.c_str(), std::ios::binary); 
 9 
  
 10   if (imgStrm) { 
  
 11     // determine file size 
  
 12     imgStrm.seekg(0, std::ios::end); 
  
 13     sz = imgStrm.tellg(); 
  
 14     imsStrm.seekg(0);        // seek back to start of stream 
 15 
  
 16     byte *img = new byte[sz]; // allocate buffer and read 17     
 // read the image contents 
  
 18     imgStrm.read(reinterpret_cast<char*>(img), sz); 
  
 19     // process it 
  
 20     byte *rotated = img_rotate(img, sz, angle); 
  
 21     // deallocate buffer 
  
 22     delete [] img; 
  
 23 
  
 24     return rotated; 
  
 25   } 
  
 26 
  
 27   sz = 0; 
  
 28   return 0; 
  
 29 }
  
 [
  76 
 ]",NA
Exception safety and RAII,"In the previous example, we looked informally at the concept of exception safety. We saw 
 that a potential exception thrown from the 
 img_rotate
  API could leak resources in the 
 rotateImage
  function. It turns out that you can reason about the behavior of your code 
 in the face of exceptions in terms of a set of criteria called 
  
 The Abrahams Exception Safety Guarantees
 . They are named after Dave Abrahams, the 
 Boost cofounder and an eminent C++ Standards Committee member, who formalized 
 these guarantees in 1996. They have since been refined further by others, including 
 notably Herb Sutter, and are listed below:
  
 • 
  
 • 
  
 • 
  
 Basic guarantee
 : An operation terminated midway preserves invariants 
 and does not leak resources
  
 Strong guarantee
 : An operation terminated midway will not have any 
 effect, that is, the operation is atomic
  
 No-throw guarantee
 : An operation that cannot fail
  
 An operation that does not satisfy any of these criteria is said to be ""not 
 exception-safe"" or more colloquially, exception-unsafe. The appropriate level of 
 exception safety for an operation is the programmer's prerogative but 
 exception-unsafe code is rarely acceptable.
  
 The most fundamental and effective C++ technique for making code exception-safe goes 
 by the curious name 
 Resource Acquisition is Initialization
  (
 RAII
 ). The RAII idiom 
 proposes the following model for encapsulating resources that require manual 
 management:
  
 1. Encapsulate resource acquisition in the constructor of a wrapper object.
  
 2. Encapsulate resource release in the destructor of the wrapper object.
  
 3. Additionally, define consistent copy and move semantics for the wrapper 
  
 object or disable them.
  
 If the wrapper object is created on the stack, its destructor is called for normal scope 
 exit as well as exit due to exceptions. Otherwise, the wrapper object itself should be 
 managed by the RAII idiom. Loosely speaking, you either create your objects on the 
 stack or manage them using RAII. At this point, some examples are in order, and we can 
 go straight back to the image rotation example and fix it using RAII:
  
  1 struct ScopeGuard
  
  2 {
  
  3   ScopeGuard(byte *buffer) : data_(buffer) {}
  
 [
  78 
 ]",NA
Smart pointers,"A smart pointer, definitively, is a class that encapsulates access to a pointer and often 
 manages memory associated with the pointer. If you paid attention, you would have 
 noticed the similarity smart pointers have with pineapples—smart pointers are classes, 
 not pointers, just as pineapples aren't really apples. Moving away from fruit analogies, 
 different types of smart pointers often have additional features like bounds-checking, 
 null-checking, and access control, among others. In C++, smart pointers usually overload 
 the dereference operator (
 operator->
 ), which allows any method calls invoked on the 
 smart pointer using 
 operator->
  to be bound to the underlying pointer.
  
 Boost includes a set of four different smart pointers with differing semantics. Also, 
 because C++ often uses pointers to identify and manipulate arrays of objects, Boost 
 provides two different smart array templates that encapsulate array access via 
 pointers. In the following sections, we study the different classes of smart pointers 
 from Boost and their semantics. We will also look at 
 std::unique_ptr
 , a C++11 
 smart pointer class that supersedes one of the Boost smart pointers and supports 
 semantics not readily available from Boost.
  
 [
  80 
 ]",NA
Unique ownership semantics ,"Consider the following code snippet for instantiating an object and calling a 
 method on it:
  
  1 class Widget;
  
  2 
  
  3 // …
  
  4 
  
  5 void useWidget()
  
  6 {
  
  7   Widget *wgt = new 
 Widget;
  
  8   wgt->setTitle(...);
  
  9   wgt->setSize(...); 
  
 10   wgt->display(...); 
  
 11   delete wgt; 
  
 12 }
  
 As we saw in the previous section, the preceding code is not exception-safe. 
  
 Exceptions thrown from operations after the 
 Widget
  object is constructed on dynamic 
 memory (line 7) and before the 
 Widget
  object is destroyed (line 11), can cause the 
 dynamically-allocated memory for the 
 Widget
  object to leak. To fix this, we need 
 something akin to the 
 ScopeGuard
  class we wrote in the previous section, and Boost 
 obliges with the 
 boost::scoped_ptr
  template.",NA
boost::scoped_ptr ,"Here is the preceding example fixed using 
 scoped_ptr
 . The 
 scoped_ptr
  template is 
 available from the header file 
 boost/scoped_ptr.hpp
 . It is a header-only library, and 
 you don't need to link your program against any other libraries:
  
 Listing 3.1: Using scoped_ptr
  
  1 #include <boost/scoped_ptr.hpp>
  
  2 #include ""Widget.h""  // contains the definition of Widget 
 3 
  
  4 // …
  
  5 
  
  6 void useWidget()
  
  7 {
  
  8   boost::scoped_ptr<Widget> wgt(new Widget);
  
  9   wgt->setTitle(...); 
  
 10   wgt->setSize(...); 
  
 11   wgt->display(...); 
  
 12 }
  
 [
  81 
 ]",NA
Uses of scoped_ptr,"scoped_ptr
  is a lightweight and versatile smart pointer that is capable of more than 
 just acting as a scope guard. Here is a look at how it can be used in code.",NA
Creating exception-safe scopes,"scoped_ptr
  is useful in creating exception-safe scopes, when objects are 
  
 dynamically-allocated in some scope. C++ allows objects to be created on the stack and 
 often that is the route you would take to create objects instead of allocating them 
 dynamically. But, in some cases, you would need to instantiate an object by calling factory 
 functions that return pointers to the dynamically-allocated objects. This could be from 
 some legacy library and 
 scoped_ptr
  can be a handy wrapper for such pointers. In the 
 following example, 
 makeWidget
  is one such factory function that returns a dynamically-
 allocated 
 Widget
 :
  
  1 class Widget { ... };
  
  2
  
  3 Widget *makeWidget() // Legacy function
  
  4 {
  
  5   return new Widget;
  
  6 }
  
  7 
  
  8 void useWidget()
  
  9 {
  
 10   boost::scoped_ptr<Widget> wgt(makeWidget());
  
 11   wgt->display();              // widget displayed
  
 12 }   // Widget destroyed on scope exit
  
 In general, 
 useWidget
  in the preceding form would be exception-safe, provided the 
 function 
 makeWidget
  called from within 
 useWidget
  also is exception-safe.
  
 [
  84 
 ]",NA
Transferring object ownership across functions ,"As non-copyable objects, 
 scoped_ptr
  objects cannot be passed or returned by value 
 from functions. One may pass a non-const reference to a 
 scoped_ptr
  as an argument 
 to a function, which resets its contents and puts a new pointer into the 
 scoped_ptr
  
 object.
  
 Listing 3.3: Ownership transfer using scoped_ptr
  
  1 class Widget { ... };
  
  2
  
  3 void makeNewWidget(boost::scoped_ptr<Widget>& result)
  
  4 {
  
  5   result.reset(new Widget);
  
  6   result->setProperties(...);
  
  7 }
  
  8 
  
  9 void makeAndUseWidget() 
  
 10 { 
  
 11   boost::scoped_ptr<Widget> wgt; // null wgt 
  
 12   makeNewWidget(wgt);         // wgt set to some Widget 
 object.
  
 13   wgt->display();              // widget #1 displayed 
  
 14 
  
 15   makeNewWidget(wgt);        // wgt reset to some other 
 Widget. 16                              // Older wgt released.
  
 17   wgt->display();            // widget #2 
 displayed 18 }
  
 The 
 makeNewWidget
  function uses the 
 scoped_ptr<Widget>
  reference passed to it as 
 an out parameter using it to return the dynamically-allocated object (line 5). 
  
 Each call to 
 makeNewWidget
  (line 12, 15) replaces its previous content with a new 
 Widget
  object allocated dynamically and deletes the previous object. This is one way to 
 transfer ownership of an object allocated dynamically inside a function to a scope 
 outside the function. It is not frequently used, and there are more idiomatic ways of 
 achieving the same effect in C++11 using 
 std::unique_ptr
 , as discussed in the next 
 section.",NA
As a class member ,"Among the smart pointers from Boost, 
 scoped_ptr
  is often used only as a local scope 
 guard in functions, when in fact, it can be a useful tool for ensuring exception safety as a 
 class member as well.
  
 [
  85 
 ]",NA
boost::scoped_array,"The 
 scoped_ptr
  class template works great for single, dynamically-allocated objects. 
 Now if you remember our motivating example of writing an image rotation utility, we 
 needed to wrap a dynamic array in our custom 
 ScopeGuard
  class to make the 
 rotateImage
  function exception-safe. Boost provides the 
 boost::scoped_ array
  
 template as an array analogue for 
 boost::scoped_ptr
 . The semantics of 
 boost::scoped_array
  are identical to those of 
 boost::scoped_ptr
 , except that this 
 one has an overloaded subscript operator (
 operator[]
 ) to access individual elements of 
 the wrapped array and does not provide overloaded operators for other forms of 
 indirection (
 operator*
  and 
 operator->
 ). Rewriting the 
 rotateImage 
 function using 
 scoped_array
  will be instructive at this point.
  
 Listing 3.5: Using scoped_array
  
  1 #include <boost/scoped_array.hpp>
  
  2
  
  3 typedef unsigned char byte;
  
 [
  90 
 ]",NA
std::unique_ptr,"C++ 11 introduces the 
 std::unique_ptr
  smart pointer template, which supersedes the 
 deprecated 
 std::auto_ptr
 , supports the functionality of 
 boost::scoped_ptr 
 and 
 boost::scoped_array
 , and can be stored in Standard Library containers. 
  
 It is defined in the standard header file 
 memory
  along with other smart pointers 
 introduced in C++11.
  
 The member functions of 
 std::unique_ptr
  are easily mapped to those of 
 boost::scoped_ptr
 :
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 A default-constructed 
 unique_ptr
  contains a null pointer (
 nullptr
 ) just 
 like a default-constructed 
 scoped_ptr
 .
  
 You can call the 
 get
  member function to access the contained pointer.
  
 The 
 reset
  member function frees the older pointer and takes ownership of 
 a new pointer (which could be null).
  
 The 
 swap
  member function swaps contents of two 
 unique_ptr
  instances 
 and always succeeds.
  
 You can dereference non-null 
 unique_ptr
  instances with 
 operator*
  and 
 access members using 
 operator->
 .
  
 You can use 
 unique_ptr
  instances in Boolean contexts to check for nullness just 
 like 
 scoped_ptr
  instances.
  
 However, 
 std::unique_ptr
  is more versatile than 
 boost::scoped_ptr 
 in certain matters.
  
 A 
 unique_ptr
  is movable, unlike 
 scoped_ptr
 . Thus, it can be stored in 
 C++11 Standard Library containers and returned from functions.
  
 You can detach the pointer owned by a 
 std::unique_ptr
  and manage it 
 manually if you have to.
  
 There is a 
 unique_ptr
  partial specialization available for dynamically-
 allocated arrays. 
 scoped_ptr
  does not support arrays, and you have to use 
 the 
 boost::scoped_array
  template for this purpose.",NA
Ownership transfer using unique_ptr,"The 
 std::unique_ptr
  smart pointer can be used as a scope guard just like the 
 boost::scoped_ptr
 . Like 
 boost::scoped_ptr
 , the type of the object pointed to by 
 the encapsulated pointer must be completely known at the point where 
 unique_ptr 
 goes out of scope. However, unlike 
 boost::scoped_ptr
 , 
 a unique_ptr instance 
 need not be bound to a single scope and can be moved from one scope to another. 
  
 [
  92 
 ]",NA
Wrapping arrays in unique_ptr ,"To illustrate the use of 
 unique_ptr
  for wrapping dynamic arrays, we will rewrite 
 the image rotation example (listing 3.5) yet again, replacing 
 scoped_ptr 
 with 
 unique_ptr
 :
  
 Listing 3.7: Using unique_ptr to wrap arrays
  
  1 #include <memory>
  
  2
  
  3 typedef unsigned char byte;
  
  4
  
  5 byte *rotateImage(std::string imgFile, double angle, size_t& sz) 
 6 {
  
  7   // open the file for reading
  
  8   std::ifstream imgStrm(imgFile, std::ios::binary);
  
  9 
  
 10   if (imgStrm) { 
  
 11     imgStrm.seekg(0, std::ios::end); 
  
 12     sz = imgStrm.tellg();      // determine file size 
  
 13     imgStrm.seekg(0); 
  
 14 
  
 15     // allocate buffer and read 
  
 16     std::unique_ptr<byte[]> img(new byte[sz]); 
  
 17     // read the image contents 
  
 18     imgStrm.read(reinterpret_cast<char*>(img.get()),sz); 
  
 19     // process it 
  
 20     byte first = img[0];  // access first byte 
  
 21     return img_rotate(img.get(), sz, angle); 
  
 22   } 
  
 23 
  
 24   sz = 0; 
  
 25   return 0; 
  
 26 }
  
 [
  94 
 ]",NA
make_unique in C++14,"The C++14 Standard Library contains a function template 
 std::make_unique
 , which is a 
 factory function for creating an instance of an object on dynamic memory and wrap it in 
 std::unique_ptr
 . The following example is a rewrite of listing 3.6b that illustrates the 
 use of 
 make_unique
 :
  
 Listing 3.8: Using make unique
  
  1 #include ""Logger.h""  // Listing 3.6a
  
  2 
  
  3 void doLogging(const std::string& msg, ...)
  
  4 {
  
  5   std::string filename = ""/var/MyApp/log/app.log"";
  
  6   std::unique_ptr<Logger> logger = 
  
  7                 std::make_unique<Logger>(filename);
  
  8   logger->log(msg, ...);
  
  9 }
  
 The 
 std::make_unique
  function template takes the type of the underlying object to 
 construct as a template argument and the arguments to the object's constructor as 
 function arguments. We directly pass to 
 make_unique
 , the filename argument, which it 
 forwards to the constructor of 
 Logger
  (line 7). 
 make_unique
  is a variadic template; it 
 takes a variable number of arguments that match the constructor parameters of the type 
 instantiated, in number and type. If there was a two-parameter constructor of 
 Logger
 , say 
 one that took a filename and a default log level, we would pass two arguments to 
 make_unique
 :
  
 // two argument constructor
  
 Logger::Logger(const std::string& filename, loglevel_t level) {
  
  ...
  
 }
  
 std::unique_ptr<Logger> logger =
  
  std::make_unique<Logger>(filename, DEBUG);
  
 [
  95 
 ]",NA
Shared ownership semantics,"Unique ownership semantics with the ability to transfer ownership is good enough for 
 most purposes that you would use a smart pointer for. But in some real-world 
 applications, you will need to share resources across multiple contexts without any of 
 these contexts being a clear owner. Such a resource can be released only when all of the 
 contexts holding references to the shared resource release them. When and where this 
 happens cannot be determined in advance.
  
 Let us understand this with a concrete example. Two threads in a single process read data 
 from different sections of the same dynamically-allocated region in memory. Each thread 
 does some processing on the data and then reads more data. We need to ensure that the 
 dynamically-allocated memory region is cleanly deallocated when the last thread 
 terminates. Either thread could terminate before the other; so who deallocates the buffer?
  
 By encapsulating the buffer in a smart wrapper that can keep a count of the number of 
 contexts referring to it, and deallocating the buffer only when the count goes to zero, we 
 can encapsulate the logic of deallocation completely. The users of the buffer should 
 switch to using a smart wrapper, which they can freely copy, and when all copies go out 
 of scope, the reference count goes to zero and the buffer is deallocated.",NA
boost::shared_ptr and std::shared_ptr,"The 
 boost::shared_ptr
  smart pointer template provides reference-counted shared 
 ownership semantics. It keeps track of the number of references to it using a shared 
 reference count that it maintains alongside the wrapped, dynamically-allocated object. 
 Like other smart pointer templates we have seen so far, it implements the RAII idiom, 
 taking responsibility of destroying and deallocating the wrapped object in its destructor, 
 but it does so only when all references to it are destroyed, that is, the reference count goes 
 to zero. It is a header-only library made available by including 
 boost/shared_ptr.hpp
 .
  
 [
  96 
 ]",NA
Uses of shared_ptr ,"In pre-C++11 code, 
 boost::shared_ptr
  or 
 std::tr1::shared_ptr
  tends to be the 
 default choice for a smart pointer owing to its flexibility and ease of use, compared to 
 boost::scoped_ptr
 . It is used for purposes beyond pure shared-ownership semantics 
 and this makes it the best-known smart pointer template. In C++11, such pervasive use 
 should be curbed in favor of 
 std::unique_ptr
 , and 
 shared_ptr 
 should only be used 
 to model true shared-ownership semantics.",NA
As a class member ,"Consider a scenario where multiple components of an application may share a single 
 database connection for better performance. Such a connection could be created the first 
 time it is requested and cached as long as there is some component using it. 
  
 When all components are done using it, the connection ought to be closed. This is 
 definitive of shared-ownership semantics and 
 shared_ptr
  is useful in this scenario. 
  
 Let us see how an application component might use 
 shared_ptr
  to encapsulate a 
 shared database connection:
  
 Listing 3.10: Using shared_ptr as class members
  
  1 class AppComponent
  
  2 {
  
  3 public:
  
  4  AppComponent() : spconn_(new DatabaseConnection(...))
  5  
 {}
  
  6 
  
  7  AppComponent( 
  
  8         const boost::shared_ptr<DatabaseConnection>& spc) 
 9      : spconn_(spc) {} 
  
 11 
  
 12  // Other public member
  
 [
  99 
 ]",NA
Storing dynamically-allocated objects in Standard Library ,NA,NA
containers,"Objects stored by Standard Library containers are copied or moved into the container and 
 are destroyed with the container. Objects are retrieved too by copying or moving. Prior to 
 C++11, there was no support for move semantics and copying was the sole mechanism for 
 storing objects in containers. Standard Library containers do not support reference 
 semantics. You may store pointers to dynamically-allocated objects in containers but, at 
 the end of its life cycle, the container not attempt to destroy and deallocate these objects 
 via their pointers.
  
 [
  100 
 ]",NA
Nonowning aliases – boost::weak_ptr and std::weak_ptr,"In the last section, one of the examples we looked at was that of a database 
  
 connection shared among multiple application components. This form of use has certain 
 shortcomings. While instantiating application components that are meant to reuse the 
 open database connection, you need to refer to another existing component that uses 
 the connection and pass that connection to the constructor of the new object. A more 
 scalable approach is to decouple the connection creation and application component 
 creation so that application components are not even aware of whether they got a new 
 connection or an existing reusable connection. But the requirement still remains that 
 the connection must be shared across all clients, and it must be closed when the last 
 reference to it has gone.
  
 One approach to building such a mechanism is to use a database connection factory, 
 which creates connections to a specific database instance based on connection 
 parameters passed by the caller. It then passes the connection back to the caller 
 wrapped in a 
 shared_ptr
  and also stores it in a map that can be looked up. When a new 
 client requests a connection to the same instance for the same database user, the factory 
 can simply look up the existing connection from the map and return it wrapped in a 
 shared_ptr
 . The following and illustrative code implements this logic. It assumes that 
 all information needed to connect to a database instance is encapsulated in a 
 DBCredentials
  object:
  
  1 typedef boost::shared_ptr<DatabaseConnection> DBConnectionPtr;
  
  2
  
  3 struct DBConnectionFactory
  
  4 {
  
  5   typedef std::map<DBCredentials, DBConnectionPtr> 
  
  6                                             ConnectionMap;
  
  7
  
  8   static DBConnectionPtr connect(const DBCredentials& creds)
  
  9   {
  
 10     auto iter = conn_map_.find(creds);
  
 11
  
 12     if (iter != conn_map_.end()) {
  
 13       return iter->second;
  
 [
  102 
 ]",NA
A shared_ptr critique – make_shared and enable_shared_,NA,NA
from_this,"shared_ptr
  has been used widely, beyond its appropriate use case for shared-
 ownership semantics. This is partly due to its availability as part of the C++ 
  
 Technical Report 1
  (
 TR1
 ) release in 2007, whereas other viable options like Boost's 
 Pointer Containers (see 
 Chapter 5
 , 
 Effective Data Structures beyond STL
 ) were not part of 
 the TR1. But 
 shared_ptr
  requires an extra allocation for the shared counter, because of 
 which construction and destruction is slower than it is for 
 unique_ptr 
 and 
 scoped_ptr
 . The shared counter itself is an object containing two atomic integers. If 
 you never need shared-ownership semantics but use 
 shared_ptr
 , you pay for one extra 
 allocation of the shared counter and for the increment and decrement operations on 
 atomic counters, which make copying 
 shared_ptr
  slower. If you need shared-
 ownership semantics but don't care about 
 weak_ptr
  observers, you pay for the extra 
 space occupied by the weak reference counter that you would not need.
  
 One way to mitigate this problem is to somehow coalesce the two allocations—one for 
 the object and one for the shared counter—into one. The 
 boost::make_shared 
 function template (also 
 std::make_shared
  in C++11) is a variadic function template 
 that does exactly this. Here is how you would use it:
  
 Listing 3.13: Using make_shared
  
  1 #include <boost/make_shared.hpp>
  
  2
  
  3 struct Foo {
  
  4   Foo(const std::string& name, int num);
  
  5   ...
  
  6 };
  
  7
  
  8 boost::shared_ptr<Foo> spfoo = 
  
  9             boost::make_shared<Foo>(""Foo"", 10);
  
 10
  
 The 
 boost::make_shared
  function template takes the type of object as a template 
 argument and the arguments to the object's constructor as function arguments. We call 
 make_shared<Foo>
 , passing it the arguments we want to construct the 
 Foo
  object with 
 (lines 8-9). The function then allocates a single block of memory in which it lays out the 
 object and also appends the two atomic counts, in one fell swoop. Note that you need to 
 include the header file 
 boost/make_shared.hpp
  to use 
 make_shared
 . 
  
 This is not as perfect as it seems but might be a good enough trade-off. It is not perfect 
 because now it is a single block of memory not two, and is shared between all 
 shared_ptr
  and 
 weak_ptr
  referents. 
  
 [
  106 
 ]",NA
Intrusive smart pointers – boost::intrusive_ptr,"Consider what happens when you wrap the same pointer in two different 
 shared_ptr
  instances that are not copies of each other.
  
  1 #include <boost/shared_ptr.hpp>
  
  2 
  
  3 int main()
  
  4 {
  
  5   boost::shared_ptr<Foo> f1 = boost::make_shared<Foo>();
  
  6   boost::shared_ptr<Foo> f2(f1.get());  // don't try this
  
  7
  
  8   assert(f1.use_count() == 1 && f2.use_count() == 1);
  
  9   assert(f1.get() == f2.get());
  
 10 } // boom!
  
 In the preceding code, we created a 
 shared_ptr<Foo>
  instance (line 5) and a second 
 independent instance of 
 shared_ptr<Foo>
 , using the same pointer as for the first one 
 (line 6). The net effect is that two 
 shared_ptr<Foo>
  instances both have a reference 
 count of 1 (asserts on line 8) and both contain the same pointer (asserts on line 9). At 
 the end of the scope, reference counts of both 
 f1
  and 
 f2
  go to zero and both try to call 
 delete
  on the same pointer (line 10). The code almost certainly crashes as a result of 
 the double delete. The code is well-formed in the sense that it compiles, but hardly well-
 behaved. You need to guard against such usage of 
 shared_ptr<Foo>
  but it also points 
 to a limitation of 
 shared_ptr
 . The limitation is due to the fact that there is no 
 mechanism, given just the raw pointer, to tell whether it is already referenced by some 
 smart pointer. The shared reference count is outside the 
 Foo
  object and not part of it. 
 shared_ptr
  is said to be nonintrusive.
  
 [
  109 
 ]",NA
Using intrusive_ptr,"To manage dynamically-allocated instances of type 
 X
 , you create 
 boost::intrusive_ 
 ptr<X>
  instances just as you would create other smart pointer instances. You just need 
 to make sure that two global functions 
 intrusive_ptr_add_ref(X*)
  and 
 intrusive_ 
 ptr_release(X*)
  are available that take care of incrementing and decrementing the 
 reference counts, and calling 
 delete
  on the dynamically-allocated object if the 
 reference count goes to zero. If 
 X
  be part of a namespace, the two global functions too 
 should ideally be defined in the same namespace to facilitate Argument Dependent 
 Lookup. Thus, the reference counting and deletion mechanisms are both in control of 
 the user, and 
 boost::intrusive_ptr
  provides an RAII framework, which they are 
 hooked into. Do note how the reference count is maintained is the user's prerogative 
 and incorrect implementations could cause leaks, crashes, or at the very least, 
  
 inefficient code. Finally, here is some sample code that uses 
 boost::intrusive_ptr
 :
  
 Listing 3.15: Using intrusive_ptr
  
  1 #include <boost/intrusive_ptr.hpp>
  
  2 #include <iostream>
  
  3 
  
  4 namespace NS {
  
  5 class Bar {
  
  6 public:
  
  7   Bar() : refcount_(0) {}
  
 [
  110 
 ]",NA
shared_array,"Just like 
 boost::scoped_ptr
  had a corresponding template for specifically 
  
 managing dynamically-allocated arrays, there is a template called 
 boost::shared_ 
 array
  that can be used to wrap dynamically-allocated arrays and manage them with 
 shared ownership semantics. Like 
 scoped_array
 , 
 boost::shared_array
  has an 
 overloaded subscript operator (
 operator[]
 ). Like 
 boost::shared_ptr
 , it uses a 
 shared reference count to manage the lifetime of the encapsulated array. Unlike 
 boost::shared_ptr
 , there is no 
 weak_array
  for 
 shared_array
 . It is a convenient 
 abstraction that can be used as a reference counted vector. I leave it to you to explore 
 this further.
  
 [
  113 
 ]",NA
Managing non-memory resources using smart ,NA,NA
pointers ,"All the smart pointer classes we have seen so far assume that their resource is 
 dynamically-allocated using the C++ 
 new
  operator and requires deletion using the 
 delete
  
 operator. The 
 scoped_array
  and 
 shared_array
  classes as well as 
 unique_ ptr
 's array 
 partial specialization assume that their resources are dynamically-
  
 allocated arrays and use the array 
 delete
  operator (
 delete[]
 ) to deallocate them. 
 Dynamic memory is not the only resource that a program needs to manage in an 
 exception-safe way, and smart pointers would be remiss to ignore this use case.
  
 The 
 shared_ptr
  and 
 std::unique_ptr
  templates can work with alternative user-
 specified deletion policies. This makes them fit to manage not just dynamic memory but 
 almost any resource with explicit APIs for creation and deletion, such as C-style heap 
 memory allocation and deallocation using 
 malloc
  and 
 free
 , open file streams, Unix 
 open file descriptors and sockets, platform-specific synchronization primitives, Win32 
 API handles to various resources, and even user-defined abstractions. Here is a short 
 example to round off the chapter:
  
  1 #include <boost/shared_ptr.hpp>
  
  2 #include <stdio.h>
  
  3 #include <time.h>
  
  4 
  
  5 struct FILEDeleter
  
  6 {
  
  7   void operator () (FILE *fp) const {
  
  8     fprintf(stderr, ""Deleter invoked\n"");
  
  9     if (fp) { 
  
 10       ::fclose(fp); 
  
 11     } 
  
 12   } 
  
 13 }; 
  
 14 
  
 15 int main() 
  
 16 { 
  
 18   boost::shared_ptr<FILE> spfile(::fopen(""tmp.txt"", ""a+""), 
 19                                  FILEDeleter()); 
  
 20   time_t t; 
  
 21   time(&t); 
  
 22 
  
 23   if (spfile) { 
  
 24     fprintf(spfile.get(), ""tstamp: %s\n"", ctime(&t)); 25   
 } 
  
 26 }
  
 [
  114 
 ]",NA
Self-test questions,"For multiple choice questions, choose all options that apply:
  
 1. What are the Abraham's Exception Safety Guarantees?
  
 a. Basic, weak, and strong
  
 b. Basic, strong, and no-throw
  
 c. Weak, strong, and no-throw
  
 d. None, basic, and strong
  
 [
  115 
 ]",NA
Summary,"This chapter formalized the requirements for exception safety of a piece of code, and 
 then defined various means of managing dynamically-allocated objects in an 
 exception-safe way using smart pointers. We looked at smart pointer templates both 
 from Boost and ones that have been introduced by the new C++11 Standard, and 
 understood the different ownership semantics and intrusive and nonintrusive 
 reference counting. We also got a chance to look at ways of adapting some of the smart 
 pointer templates for managing non-memory resources.
  
 Hopefully, you have understood the various ownership semantics and would be able to 
 judiciously apply the techniques in this chapter to such scenarios. There are facilities in 
 the smart pointer library that we did not cover in any significant detail, like 
 boost::shared_array
  and 
 boost::enable_shared_from_raw
 . You should explore 
 them further on your own, focusing on their applicability and their pitfalls. In the next 
 chapter, we will learn about some nifty and useful techniques for dealing with text data 
 using Boost's string algorithms.",NA
References,"• 
  
 Rule of Zero: 
 http://en.cppreference.com/w/cpp/language/rule_of_
  
 three
  
 • 
  
 Designing C++ Interfaces - Exception Safety
 , 
 Mark Radford
 : 
 http://accu.org/
  
 index.php/journals/444
  
 • 
  
 Exception Safety Analysis
 , 
 Andrei Alexandrescu and David B. Held
 : 
  
 http://erdani.com/publications/cuj-2003-12.pdf
  
 [
  117 
 ]",NA
Working with Strings,"Text data is the most important and pervasive form of data that modern applications 
 deal with. The ability to process text data efficiently through intuitive abstractions is a 
 key marker of effectiveness in dealing with text data. Boost has a number of libraries 
 dedicated toward effective text processing that enhance and extend the capabilities 
 provided by the C++ Standard Library.
  
 In this chapter, we will look at three key Boost libraries for processing text data. We will 
 start with the Boost String Algorithms library, a library of general-purpose algorithms 
 for text data that provides a host of easy text operations, often missed in the Standard 
 Library. We will then look at the Boost Tokenizer library, an extensible framework for 
 tokenizing string data based on various criteria. Thereafter, we will examine a regular 
 expression library for searching and parsing strings, Boost.Regex, which has been 
 included in the C++11 standard as well. The following topics appear in the following 
 sections:
  
 • 
  
 Text processing with Boost String Algorithms library
  
 • 
  
 Splitting text using the Boost Tokenizer library
  
 • 
  
 Regular expressions with Boost.Regex
  
 This chapter should help you get a good grasp of text processing techniques available 
 in the Boost libraries. We do not deal with internationalization issues in this book, 
 but most of the concepts discussed in this chapter will apply to text in languages with 
 writing systems based on non-Latin character sets.
  
 [
  119 
 ]",NA
Text processing with Boost String ,NA,NA
Algorithms library,"Text data is commonly represented as a sequence or 
 string
  of characters laid out 
 contiguously in memory and terminated by a special marker (the null terminator). 
  
 While the actual data type used to represent a character can vary case by case, the 
 C++ Standard Library abstracts the string concept in the class template 
 std::basic_string
 , which takes the character data type as a parameter. 
  
 The 
 std::basic_string
  template takes three type parameters:
  
 • 
  
 • 
  
 • 
  
 The character type 
  
 Some of the intrinsic properties and behaviors of the character type 
 encapsulated in a traits class
  
 An allocator type that is used to allocate the internal data structures for 
  
 std::basic_string
  
 The traits and allocator parameters are defaulted, as shown in the following snippet:
  
 template <typename charT,
  
  typename Traits = std::char_traits<chart>,
  
  typename Allocator = std::allocator<chart>>
  
 std::basic_string;
  
 The C++03 Standard Library also provides two specializations of 
 std::basic_string
 :
  
 • 
  
 std::string
  for narrow characters (8-bit 
 char
 )
  
 • 
  
 std::wstring
  for wide characters (16- or 32-bit 
 wchar_t
 )
  
  In C++11, we have two more:
  
 • 
  
 std::u16string
  (for 
 u16char_t
 )
  
 • 
  
 std::u32string
  (for 
 u32char_t
 )
  
 In addition to these classes, plain old C-style strings, which are just arrays of 
 char 
 or 
 wchar_t
  terminated by a null character, are also quite commonly used, especially in 
 legacy C++ code.
  
 There are two major shortcomings in the Standard Library, which makes dealing with 
 text data types overly tedious at times. For one, there is only a limited set of readily 
 available algorithms that can be applied to 
 string
  and 
 wstring
 . Moreover, most of 
 these algorithms are member functions of 
 std::basic_string
  and are not applicable 
 to other string representations like character arrays. Even the algorithms available as 
 non-member function templates deal in iterators rather than containers, making the 
 code tedious and less flexible.
  
 [
  120 
 ]",NA
Using Boost String Algorithms ,"In this section, we explore the various string algorithms available to us and understand 
 the conditions under which they can be applied. Before we look at specific algorithms 
 though, we will try to understand the general scheme of things first.
  
 Consider the algorithm 
 boost::contains
 . It checks whether the string passed, as 
 its second argument, is a substring of the string passed as its first argument:
  
 [
  124 
 ]",NA
Find algorithms ,"There are several variants of 
 find algorithm
  available from the Boost String Algorithms 
 library, all of which search for a string or pattern in another input string. Each algorithm 
 takes the input string and the search string as parameters, converts them to ranges, and 
 then performs the search. Each find-variant returns the contiguous subsequence in the 
 input, which matches the search string or pattern, as a range. An empty range is returned 
 if no match was found.",NA
find_first ,"We start by looking at 
 boost::find_first
 , which looks for a string in 
 another string:
  
 Listing 4.8: Using boost::find_first
  
  1 #include <boost/algorithm/string.hpp>
  
  2 #include <string>
  
  3 #include <iostream>
  
  4 
  
  5 int main()
  
  6 {
  
  7   const char *haystack = ""Mary had a little lamb"";
  
  8   const char *needles[] = {""little"", ""Little"", 0};
  
  9 
  
 10   for (int i = 0; needles[i] != 0; ++i) { 
  
 11     auto ret = boost::find_first(haystack, needles[i]); 
  
 12 
  
 13     if (ret.begin() == ret.end()) { 
  
 14       std::cout << ""String ["" << needles[i] << ""] not found 
 in"" 15                 << "" string ["" << haystack << ""\n""; 
  
 16     } else { 
  
 17       std::cout << ""String ["" << needles[i] << ""] found at "" 
 18                 << ""offset "" << ret.begin() - haystack
  
 [
  126 
 ]",NA
find_all ,"To find all matching substrings in an input string, we must use 
 boost::find_all 
 and pass it a sequence container to put all the matched substrings into. Here is a 
 short example of how to do it:
  
 Listing 4.9: Using boost::find_all to find all matching substrings
  
  1 #include <boost/algorithm/string.hpp>
  
  2 #include <string>
  
  3 #include <iostream>
  
  4 #include <vector>
  
  5
  
  6 int main()
  
  7 {
  
  8   typedef boost::iterator_range<std::string::const_iterator> 9                         
 string_range; 10   std::vector<string_range> matches; 
  
 11   std::string str = ""He deserted the unit while they trudged "" 
 12                     ""through the desert one night.""; 
  
 13 
  
 14   boost::find_all(matches, str, ""desert""); 
  
 15   for (auto match : matches) { 
  
 16     std::cout << ""Found ["" << ""desert"" << ""] at offset "" 
 17           
 << match.begin() - str.begin() << "".\n""; 
  
 18   } 
  
 19 }
  
 We first create a typedef 
 string_range
  for the appropriate range type (lines 8-9). 
  
 The 
 boost::find_all
  algorithm copies all the matching ranges into the vector of 
 ranges, 
 matches
  (line 14). We iterate over the vector 
 matches
  using C++11's new 
 range-based for-loop
  syntax (line 15), and print the offsets at which each match was 
 found (line 17). The nifty range-based for-loop declares a loop variable 
 match
  to iterate 
 over successive elements of the container 
 matches
 . Using the 
 auto
  keyword, the type of 
 match
  is automatically deduced based on the type of values contained in 
 matches
 . Using 
 a vector of ranges rather than a vector of strings, we are able to calculate the exact 
 offsets in 
 str
  at which the matches occur.",NA
find_token ,"One more interesting find algorithm is the 
 boost::find_token
  algorithm. Using this 
 algorithm, we can find substrings whose characters satisfy some predicate we specify. 
  
 We can use a set of predefined predicates or define our own, although the latter 
 approach requires a fair bit of work, and we will not attempt it in this book. In the next 
 example, we search for hexadecimal numbers with four or more digits in a string. This 
 will also illustrate how you can use functions to perform repeated searches.
  
 [
  128 
 ]",NA
iter_find ,"Iterating through a string and finding all substrings matching some criterion is a 
 common enough use case, and Boost provides an easier way to do this. By using 
 boost::iter_find
  algorithm, passing it the input string, a finder functor, and a 
 sequence container to hold the matched ranges, we can get the matching substrings 
 back in the container passed. Here is the above example rewritten using 
 boost:: 
 iter_find
 :
  
 Listing 4.11: Using boost::iter_find with boost::token_finder
  
  1 #include <boost/algorithm/string.hpp>
  
  2 #include <string>
  
  3 #include <iostream>
  
  4 #include <vector>
  
  5 #include <iterator>
  
  6 #include <algorithm>
  
  7
  
  8 struct MinLen
  
  9 { 
  
 10   bool operator()(const std::string& s) const 
  
 11   { return s.size() > 3; } 
  
 12 }; 
  
 13 
  
 14 int main() { 
  
 15   std::string str = ""The application tried to read from an "" 
 16                     ""invalid address at 0xbeeffed""; 
  
 17 
  
 18   std::vector<std::string> v; 
  
 19   auto ret = boost::iter_find(v, str, 
  
 20                      boost::token_finder(boost::is_xdigit(), 
 21                                   boost::token_compress_on)); 
 22 
  
 23   std::ostream_iterator<std::string> osit(std::cout, "", ""); 
 24   std::copy_if(v.begin(), v.end(), osit, MinLen()); 
  
 25 }
  
 The 
 boost::find_regex
  algorithm can search a string for substrings that match a 
 regular expression pattern. We will cover this algorithm when we deal with regular 
 expressions using Boost.Regex, later in this chapter.
  
 [
  130 
 ]",NA
find,"There is a generic 
 boost::find
  algorithm in terms of which most of the other find 
 algorithms are implemented. Using the available finder-functor templates, 
  
 as part of the string algorithms library, or writing our own, we can make the generic 
 boost::find
  string algorithm do a variety of search tasks for us. Here is an example of 
 using the 
 boost::last_finder
  functor with 
 boost::find
  algorithm to find the last 
 matching substring—exactly what 
 boost::ifind_last
  does. The 
 boost::last_ 
 finder
  functor and others like it take an optional predicate and can be used to influence 
 how character comparisons are done. To simulate the case-insensitive comparisons that 
 ifind_last
  does, we need to pass a predicate that compares two characters in a case-
 insensitive way. For this, we use the 
 boost::is_iequal
  predicate:
  
  1 std::string haystack = ""How little is too little"";
  
  2 std::string needle = ""Little"";
  
  3 
  
  4 auto ret = boost::find(haystack,
  
  5                       boost::last_finder(needle,
  
  6                                   boost::is_iequal()));
  
 We call 
 boost::find
  on 
 haystack
  passing it the 
 boost::last_finder
  functor. 
 Since we want 
 last_finder
  to perform case insensitive comparisons, we pass it an 
 instance of the 
 boost::is_iequal
  predicate. This works like 
 boost::ifind_last 
 and is essentially the way it is implemented. You can even pass your own predicates 
 for character comparisons. Say you received an encoded message, where each 
 character is shifted by 4, and it wraps around so that 
 a
  is 
 e
  and 
 z
  is 
 d
 . You can use the 
 equalsShift
  functor in the following code to check whether a particular real word 
 exists in the encoded text:
  
 Listing 4.12: Using custom predicates with Boost substring finders
  
  1 struct EqualsShift {
  
  2   EqualsShift(unsigned int n) : shift(n) {}
  
  3 
  
  4   bool operator()(char input, char search) const
  
  5   {
  
  6     int disp = tolower(input) - 'a' - shift;
  
  7     return tolower(search) == (disp >= 0)?'a':'z' + disp;
  
  8   }
  
  9 
  
 10 private:
  
 11   unsigned long shift;
  
 12 };
  
 13
  
 [
  131 
 ]",NA
find_head and find_tail,"There are a few more 
 find
  algorithms like 
 boost::find_head
  and 
 boost::find_ 
 tail
 , which could well have been named 
 prefix
  and 
 suffix
  for that is exactly what 
 they do—carve out a prefix or suffix of a specified length from a string:
  
 1 std::string run = ""Run Forrest run"";
  
 2 assert( boost::find_head(run, 3) == ""Run"");
  
 3 assert( boost::find_head(run, -3) == ""Run Forrest "");
  
 4 assert( boost::find_tail(run, 3) == ""run"");
  
 5 assert( boost::find_ tail(run, -3) == "" Forrest run"");
  
 You call 
 find_head
  with the input string and an offset. If the offset is a positive 
 number 
 N
 , 
 find_head
  returns the first 
 N
  characters in the input string or the whole 
 string if 
 N
  is larger than the size of the string. If the offset is a negative number 
 -N
 , 
 find_head
  returns the first 
 size - N
  characters, where 
 size
  represents the total 
 number of characters in the string 
 run
 .
  
 You call 
 find_tail
  with a string and an integer. When a positive integer 
 N
  is passed, 
 find_tail
  returns the last 
 N
  characters of the input string or the whole string if 
 N
  is 
 larger than the size of the string. When a negative integer 
 -N
  is passed, 
 find_tail 
 returns the last 
 size - N
  characters in the string, where 
 size
  represents the total 
 number of characters in the string, an empty string if 
 N > size
 .
  
 [
  132 
 ]",NA
Other algorithms for testing string properties,"There exist several convenience functions, which make certain common 
  
 operations very easy to code. Algorithms like 
 boost::starts_with
  and 
  
 boost::ends_with
  (and their case-insensitive variants), test whether a particular string 
 is a prefix or suffix of another. To determine the dictionary order of two strings, you can 
 use 
 boost::lexicographical_compare
 . You can check for equality using 
 boost::equals
 , and check whether a string is a substring of another using 
 boost::contains
 . Corresponding case-insensitive variants exist for each of these 
 functions, and the case-sensitive variants take an optional predicate for comparing 
 characters. The Boost online documentation provides an adequately detailed listing of 
 these functions and their behavior.",NA
Case-conversion and trimming algorithms,"Changing the case of a string or some part of it and trimming extra whitespace that is 
 preceding or trailing a string are very common tasks, which take a bit of effort to be done 
 using only the Standard Library. We have already seen 
 boost::to_upper
 , 
 boost::to_lower
 , and their copying versions for performing case changes in action. 
  
 In this section, we will apply these algorithms to more interesting ranges and also 
 look at trimming algorithms.",NA
Case-conversion algorithms,"How does one convert alternate characters in a string to uppercase leaving the rest 
 untouched? Since the 
 boost::to_upper
  function takes a range, we need to somehow 
 generate the range that contains alternate elements from the string. The way to do this is 
 to use 
 range adaptors
 . Boost Range library provides a number of adaptors that allow the 
 generation of newer patterns of ranges from existing ones. The adaptor that we are 
 looking for is the 
 strided
  adaptor that allows traversing the range by skipping a fixed 
 number of elements at each step. We need to skip just one element per step:
  
 Listing 4.13: Generating non-contiguous ranges with Boost.Range adaptors
  
  1 #include <boost/range.hpp>
  
  2 #include <boost/range/adaptors.hpp>
  
  3 #include <string>
  
  4 #include <iostream>
  
  5 #include <boost/algorithm/string.hpp>
  
  6 #include <cassert>
  
  7
  
 [
  133 
 ]",NA
Trimming algorithms ,"For trimming strings, there are three main algorithms: 
 boost::trim_left
  for 
 trimming leading whitespace in a string, 
 boost::trim_right
  for trimming trailing 
 whitespace in a string, and 
 boost::trim
  for trimming both. Trimming algorithms 
 potentially change the length of the output. Each algorithm has an 
 _if
  variant that takes 
 a predicate, which is used to identify what characters to trim. For example, if you want 
 to drop only trailing newlines from a string read from the console (a frequent chore), 
 you may write an appropriate predicate to identify only newlines. Finally, there are copy 
 variants of all these algorithms. If we wrote an expanded list of the available algorithms, 
 there would be twelve of them; four for 
 trim_left
 : 
 trim_ left
 , 
 trim_left_copy
 , 
 trim_left_if
 , and 
 trim_left_if_copy
 ; and similarly four for 
 trim_right
  and 
 trim
  
 each. Here is an example of performing trims on strings:
  
 Listing 4.14: Using boost::trim and its variants
  
  1 #include <boost/algorithm/string.hpp>
  
  2 #include <string>
  
  3 #include <iostream>
  
  4 #include <cassert>
  
  5 
  
  6 bool isNewline(char c) {
  
  7   return c == '\n';
  
  8 }
  
  9 
  
 10 int main() 
  
 11 { 
  
 12   std::string input = ""  Hello  ""; 
  
 13   std::string input2 = ""Hello   \n""; 
  
 14 
  
 15   boost::trim(input); 
  
 16   boost::trim_right_if(input2, isNewline); 
 17 
  
 18   assert(*(input.end() - 1) != ' '); 
  
 19   assert(*(input2.end() - 1) != '\n' && 20          
 *(input2.end() - 1) == ' '); 
  
 21 }
  
 In listing 4.14, we have two strings: 
 input
  with leading and trailing spaces (line 12), 
 and 
 input2
  with trailing spaces and a newline at the end (line 13). By applying 
 boost::trim
  on the 
 input
 , the leading and trailing spaces are trimmed (line 15). If 
 we had applied 
 boost::trim_right
  on 
 input2
 , it would have removed all trailing 
 whitespaces, including the spaces and the newline. We only wanted to drop the 
 newline, not the spaces; so we wrote a predicate 
 isNewline
  to help choose what 
 needs to be trimmed. This technique can be used for non-whitespace characters too.
  
 [
  135 
 ]",NA
The replace and erase algorithms,"The replace and erase algorithms are handy functions to perform search and replace 
 operations on strings. The basic idea is to find one or more matches for a search string 
 and replace the matches with a different string. Erase is a special case of replace, when 
 we replace the matches with a null string.
  
 These operations may change the length of the input when performed in-place 
 because the matched content and its replacement may have different lengths. 
  
 The core algorithm in the library is 
 boost::find_format
  in terms of which all other 
 algorithms are implemented. The algorithms 
 boost::replace_first
 , 
 boost::replace_last
 , 
 boost::replace_nth
 , and 
 boost::replace_all 
  
 respectively replace the first, last, nth, or all matching occurrences of a search string in 
 the input with an alternative string. The corresponding erase algorithms simply erase 
 the matched sections. These algorithms do not work on C-style arrays:
  
 Listing 4.15: Using boost::replace and boost::erase variants
  
  1 #include <boost/algorithm/string.hpp>
  
  2 #include <string>
  
  3 #include <iostream>
  
  4 #include <cassert>
  
  5 
  
  6 int main()
  
  7 {
  
  8   std::string input = ""Hello, World! Hello folks!"";
  
  9   boost::replace_first(input, ""Hello"", ""Hola"");
  
 10   assert(input == ""Hola, World! Hello folks!"");
  
 11   boost::erase_first(input, ""Hello"");
  
 12   assert(input == ""Hola, World!  folks!"");
  
 13 }
  
 In listing 4.15, we first use the 
 boost::replace_first
  algorithm to replace the first 
 instance of the string 
 ""Hello""
  with 
 ""Hola""
  (line 9). Had we used 
 boost::replace_ all
  
 instead, both instances of 
 ""Hello""
  would be replaced, and we would get 
 ""Hola, World! 
 Hola folks!""
 . We then call 
 boost::erase_first
  to remove the remaining 
 ""Hello""
  in 
 the string (line 11). Each of these algorithms has a case-insensitive variant, which 
 matches in a case-insensitive way. Predictably, they are named with an 
 i-
  prefix: 
 ireplace_first
 , 
 ierase_first
 , and so on.
  
 [
  136 
 ]",NA
The split and join algorithms ,"Boost provides an algorithm called 
 boost::split
 , which is essentially used to split an 
 input string into tokens based on some separators. The algorithm is passed an input 
 string, a predicate for identifying separators, and a sequence container to store the 
 parsed tokens. Here is an example:
  
 Listing 4.16: Splitting a string on simple tokens using boost::split
  
  1 #include <boost/algorithm/string.hpp>
  
  2 #include <string>
  
  3 #include <iostream>
  
  4 #include <vector>
  
  5 #include <cassert>
  
  6
  
  7 int main()
  
  8 {
  
  9   std::string dogtypes = ""mongrel, puppy, whelp, hound""; 
 10   std::vector<std::string> dogs; 
  
 11   boost::split(dogs, dogtypes, boost::is_any_of("" ,""), 
 12                boost::token_compress_on); 
  
 13 
  
 14   assert(dogs.size() == 4); 
  
 15   assert(dogs[0] == ""mongrel"" && dogs[1] == ""puppy"" && 
 16          dogs[2] == ""whelp"" && dogs[3] == ""hound""); 17 }
  
 [
  137 
 ]",NA
Splitting text using the Boost Tokenizer ,NA,NA
library,"The 
 boost::split
  algorithm, we saw in the last section, splits a string using a 
 predicate and puts the tokens into a sequence container. It requires extra storage for 
 storing all the tokens, and the user has limited choices for the tokenizing criteria used. 
 Splitting a string into a series of tokens based on various criteria is a frequent 
 programming requirement, and the Boost.Tokenizer library provides an extensible 
 framework for accomplishing this. Also, this does not require extra storage for storing 
 tokens. It provides a generic interface to retrieve successive tokens from a string. 
  
 The criterion to split the string into successive tokens is passed as a parameter. The 
 Tokenizer library itself provides a few reusable, commonly used tokenizing policies for 
 splitting, but, most importantly, it defines an interface using which we can write our own 
 splitting policies. It treats the input string like a container of tokens from which 
 successive tokens may be parsed out.
  
 [
  139 
 ]",NA
Tokenizing based on separators ,"To begin with, let's see how we can split a string into its constituent words:
  
 Listing 4.19: Using Boost Tokenizer to tokenize strings into words
  
  1 #include <iostream>
  
  2 #include <boost/tokenizer.hpp>
  
  3 #include <string>
  
  4 
  
  5 int main()
  
  6 {
  
  7   std::string input = 
  
  8         ""God knows, I've never been a spiritual man!"";
  
  9 
  
 10   boost::tokenizer<> tokenizer(input); 
  
 11 
  
 12   for (boost::tokenizer<>::iterator token = tokenizer.begin(); 
 13         token != tokenizer.end(); ++token) { 
  
 14     std::cout << *token << '\n'; 
  
 15   } 
  
 16 }
  
 The 
 boost::tokenizer
  class template abstracts the tokenization process. We create an 
 instance of the default specialization of 
 boost::tokenizer
 , passing it our input string 
 input
  (line 10). Next, using the iterator interface of 
 boost::tokenizer
 , we split 
 input
  
 into successive tokens (lines 12-14). In general, you can customize how strings are split 
 by passing appropriate tokenizing policies. As we did not pass one explicitly to the 
 boost::tokenizer
  template, the default tokenizing policy splits the string using 
 whitespace and punctuation as token delimiters or separators. The preceding code will 
 print the following output to the standard output:
  
 God 
  
 knows 
  
 I 
  
 ve 
  
 never 
  
 been 
  
 a 
  
 spiritual 
  
 man
  
 Thus, it splits not only on spaces but also commas and apostrophes; 
 ""I've""
  is split 
 into 
 ""I""
  and 
 ""ve""
  due to the apostrophe.
  
 [
  140 
 ]",NA
Tokenizing records with fields containing ,NA,NA
metacharacters,"The 
 boost::char_delimiter
  policy is not the only available splitting policy. 
 Consider a comma-separated data format, as shown in the following output:
  
 Joe Reed,45,Bristol UK
  
 Ophir Leibovitch,28,Netanya Israel
  
 Raghav Moorthy,31,Mysore India
  
 We have one record per line and three fields per record: the name, age, and city of 
 residence of a person. We can parse such records with the 
 boost::char_separator 
 policy, passing it a comma as a separator character. Now, if we want to make the format a 
 little richer, we may include full addresses of people instead of their current city. But 
 addresses are longer fields, sometimes with embedded commas, and such addresses 
 would break the parsing, which is based on using a comma as a separator. 
  
 So, we decide to quote strings that may have embedded commas:
  
 Joe Reed,45,""33 Victoria St., Bristol UK""
  
 Ophir Leibovitch,28,""19 Smilanski Street, Netanya, Israel""
  
 Raghav Moorthy,31,""156A Railway Gate Road, Mysore India""
  
 Quoting itself  may not be enough. Some addresses might have quoted strings, and 
 we would like to preserve those. To fix this, we decide on using backslash (
 \
 ) as an 
 escape character. Here is a fourth record with quoted strings in the address:
  
 Amit Gupta,70,""\""Nandanvan\"", Ghole Road, Pune, India""
  
 The trouble now is that it is no longer possible to parse the preceding records using the 
 boost::char_separator
  policy. For such records, we should instead use 
 boost::escaped_list_char
 . The 
 boost::escaped_list_char
  policy is tailor-made 
 for this kind of use. By default, it uses comma (,) as a field separator, double quotes ("") as 
 the quoting character, and backslash (\) as the escape character. To include commas in 
 fields, quote the fields. To include quotes in the fields, escape the embedded quotes. We 
 can now attempt to parse the most complex of the four persons' records, as discussed 
 earlier:
  
 Listing 4.21: Using boost::tokenizer with boost::escaped_list_separator
  
  1 #include <iostream>
  
  2 #include <boost/tokenizer.hpp>
  
  3 #include <string>
  
  4
  
  5 int main()
  
  6 {
  
 [
  142 
 ]",NA
Tokenizing records with fixed-length fields ,"One 
 class of data formats that frequently occurs in financial transactions and several other 
 domains consists of records at fixed offsets. Consider the following record format 
 representing a payment instruction:
  
 201408091403290000001881303614419ABNANL2AWSSDEUTDEMM720000000412000EUR…
  
 Here, the record is barely human readable and is meant for consumption only by a 
 program. It has fields at fixed offsets whose meanings must be known by the parsing 
 program. The individual fields are described here:
  
 Offset 0, length 8: date of record in YYYYMMDD format.
  
 Offset 8, length 9: time of record in HHMMSSmmm format where mmm 
 represents milliseconds.
  
 Offset 17, length 16: the transaction identifier for the transaction, 
 numeric format.
  
 Offset 33, length 11: the Swift Bank Identifier Code for the bank from 
 which money is transferred.
  
 Offset 44, length 11: the Swift Bank Identifier Code for the bank to 
 which money is transferred.
  
 Offset 55, length 12: the transaction amount.
  
 Offset 67, length 3: the ISO code for the currency of transaction.
  
 In order to parse records like these, we use the 
 boost::offset_separator
  splitting 
 policy. This class (note that it isn't a template) takes lengths of successive tokens to 
 parse in the form of a pair of iterators, bounding the sequence of lengths.
  
 [
  144 
 ]",NA
Writing your own tokenizer functions,"There are many instances when you will need to parse a string according to 
 some criteria that are not available in a reusable class or template in Boost. 
  
 While you could use alternative libraries like 
 boost::split
 , you can use the 
 boost::tokenizer
  facility by plugging in a custom 
 token generator
 . A token 
 generator class encapsulates the tokenizing strategy and is passed as a template 
 argument to 
 boost::tokenizer
 .
  
 A token generator can be defined as a functor that conforms to the 
 following requirements:
  
 • 
  
 Is copy-assignable.
  
 • 
  
 Is copy-constructible.
  
 [
  146 
 ]",NA
Regular expressions using Boost.Regex,"When we write a line of code like 
 boost::find_first(""Where have all the 
 flowers gone?"", ""flowers"")
 , we are asking for the string 
 ""flowers""
  (call it the 
 needle
 ) to be found in the larger string 
 ""Where have all the flowers gone?"" 
 (call it the 
 haystack
 ). The needle is the pattern; seven specific characters in a 
 particular order whose presence must be looked up in the haystack. Sometimes, 
 however, we don't know the exact string we are looking for; we only have an abstract 
 idea or a pattern in mind. Regular expressions is a powerful language to express this 
 abstract pattern.",NA
Regular expression syntax,"Regular expressions are strings that encode a pattern of text using a mix of regular 
 characters and some characters with special interpretation, collectively called 
 metacharacters
 . The Boost.Regex library provides functions that consume regular 
 expression strings and generate the logic to search and verify text conforming to 
 particular patterns. For example, to define the pattern, ""a followed by zero or more 
 b's"", we use the regular expression 
 ab*
 . This pattern will match text like 
 a
 , 
 ab
 , 
 abb
 , 
 abbb
 , and so on.",NA
Atoms,"At a very basic level, regular expressions consist of groups of one or more characters 
 called 
 atoms
 , each with an associated 
 quantifier
  that trails the atom and optionally, 
 anchors
  that define how some text is located relative to the surrounding text. 
  
 The quantifier may be implicit. An atom can be a single character (or an escaped 
 metacharacter), a 
 character class
 , a string, or a 
 wildcard
 . If it is a string, it must be 
 enclosed in parentheses to indicate that it is an atom. A wildcard matches any 
 character (other than a newline) and is written using the dot (.) metacharacter.
  
 [
  152 
 ]",NA
Quantifiers,"A single atom without a trailing quantifier just matches a single occurrence of itself. 
 When present, the trailing quantifier determines the minimum and maximum allowed 
 occurrences of the preceding atom. The general quantifier looks like 
 {m, M}
 , where 
 m
  
 denotes minimum and 
 M
  denotes maximum occurrence frequency. Omitting the 
 maximum as in 
 {m,}
  indicates that the maximum number of times the atom may be 
 present is unbounded. One may also use a single number as 
 {n}
  to match a fixed 
 number of instances. More often, we use the following shortcut quantifiers:
  
 • 
  
 • 
  
 • 
  
 *
 : Equivalent to 
 {0,}
 , called the 
 Kleene star
 . Represents an atom that 
 may not occur, or may occur any number of times.
  
 +
 : Equivalent to 
 {1,}
 . Represents an atom that must occur at least once. 
 ?
 : 
 Equivalent to 
 {0,1}
 . Represents an optional atom.
  
 Using the above syntax rules, we construct summary examples in the following table:
  
 Regular 
  
 Expression
  
 Atoms
  
 Quantifier
  
 Equivalent 
 quantifier
  
 Matching text
  
 W
  
 w
  
 None (implicit)
  
 {1}
  
 w
  
 a*
  
 a
  
 *
  
 {0,}
  
 (blank), a, aa, aaa, aaaa, …
  
 (abba)+
  
 abba
  
 +
  
 {1,}
  
 abba, abbaabba, 
 abbaabbaabba, …
  
 a?b
  
 a, b
  
 ?
  
 {0,1}
  
 b, ab
  
 (ab){2,4}
  
 (ab)
  
 {2,4}
  
 {2,4}
  
 abab, ababab, abababab
  
 .*x
  
 . and x
  
 * and None
  
 {0,}
  and 
 {1}
  
 x and any string ending in 
 x
  
 By default, quantifiers are 
 greedy
  and match as many characters as possible. Thus, given 
 the string 
 ""abracadabra""
 , the regular expression 
 ""a.*a""
  will match the entire string 
 instead of the smaller substrings 
 ""abra""
 , 
 ""abraca""
 , or 
 ""abracada""
 , all of which also 
 start and end in 
 'a'
 . If we want to match only the smallest matching substring, we need 
 to override the greedy semantics. To do this, we put the question mark (?) 
 metacharacter after the quantifier 
 ""a.*?a""
 .
  
 [
  153 
 ]",NA
Character classes,"Characters can also be matched against character classes, which are shorthand 
 representations of a group of functionally related characters. The following is a 
 partial list of predefined character classes in the Boost libraries:
  
 Character class
  
 Short form
  
 Meaning
  
 Complement
  
 [[:digit:]]
  
 \d
  
 Any decimal digit (0-9)
  
 \D
  
 [[:space:]]
  
 \s
  
 Any whitespace character
  
 \S
  
 [[:word:]]
  
 \w
  
 Any word character: letter, 
 number, and underscore
  
 \W
  
 [[:lower:]]
  
 \l
  
 Any lowercase character
  
  
 [[:upper:]]
  
 �
  
 Any uppercase character
  
  
 [[:punct:]]
  
 None
  
 Any punctuation character
  
  
 For example, 
 \d
  is a character class that matches a single decimal digit. Its 
  
 complement \
 D
  matches any single character, except decimal digits. 
 \s
  matches a 
 whitespace character and 
 \S
  matches a non-whitespace character. Ad hoc character 
 classes can be created with square brackets; 
 [aeiouAEIOU]
  matches any character that 
 is an English vowel, 
 [1-5]
  matches a digit between 1 and 5 both inclusive. The 
 expression 
 [^2-4]
  matches any character except 2, 3, and 4, and the leading caret 
 inside the square brackets having the effect of negating the characters following it. We 
 can combine multiple character classes something like—[[:digit:][:lower:]]—to indicate 
 the set of lowercase letters and decimal digits.",NA
Anchors,"Certain metacharacters, referred to as 
 anchors
 , do not match characters but can be 
 used to match specific locations in text. For example, a caret (
 ^
 ) in a regular 
 expression (outside a character class) matches text at the start of a line (just after a 
 newline). A dollar(
 $
 ) matches text before the end of a line (just before a newline). 
 Also, 
 \b
  represents a word boundary, while 
 \B
  matches any location other than a 
 word boundary.",NA
Sub-expressions,"In general, each character in a string of characters is interpreted as a distinct atom. In 
 order to treat a string of characters as a single atom, we must parenthesize it. 
 Parenthesized substrings of a regular expression are called 
 sub-expressions
 . A 
 quantifier following a sub-expression applies to the entire sub-expression:
  
 ([1-9][0-9]*)(\s+\w+)*
  
 [
  154 
 ]",NA
Disjunctions,"You can create a regular expression that is a logical-or of one or more regular 
 expressions. To do this, you use the |
 disjunction operator
 . For example, to match a 
 word that contains a mix of lowercase and uppercase characters, you can use the 
 expression 
 (\l|�)+
 .
  
 You can use the disjunction operator to combine regular expressions and form more 
 complex expressions. For example, to match either a word containing upper or 
 lowercase characters, or a positive integer, we can use the expression 
 (\l|�)+|\d+
 .",NA
Using Boost.Regex to parse regular ,NA,NA
expressions,"Regular expressions are a rich topic that we have barely scratched the surface of in the 
 preceding paragraphs. But this basic familiarity is sufficient for us to start using the 
 Boost.Regex library. The Boost.Regex library was one of the libraries that was accepted 
 into the C++ 11 Standard and is now part of the C++ 11 Standard Library, minus its 
 ability to handle Unicode characters.
  
 [
  155 
 ]",NA
Matching text,"Consider the string 
 ""Alaska area""
 . We want to match this against the regular 
 expression 
 a.*a
  to see whether the string fits the pattern. To do this, we need to 
 call the 
 boost::regex_match
  function, which returns a Boolean true to indicate a 
 successful match and false otherwise. Here is the code for it:
  
 Listing 4.26: Matching a string with a regular expression
  
 1 #include <boost/regex.hpp>
  
 2 #include <string>
  
 3 #include <cassert>
  
 4 int main()
  
 5 {
  
 6   std::string str1 = ""Alaska area"";
  
 7   boost::regex r1(""a.*a"");
  
 8   assert(!boost::regex_match(str1, r1));
  
 9 }
  
 [
  156 
 ]",NA
Searching text ,"If we want to search for substrings of a string that matches a particular regular 
 expression, we should use the 
 boost::regex_search
  function instead of 
  
 boost::regex_match
 . Consider the string 
 ""An array of papers from the 
 academia on Alaska area's fauna""
 . We want to find all substrings that are part of 
 the same word in this phrase and start and end with 
 'a'
 . The regular expression to use 
 would be 
 a\w*a
 . Let us see how we can do this using 
 boost::regex_search
 :
  
 Listing 4.27: Searching for substrings matching a regular expression
  
  1 #include <boost/regex.hpp>
  
  2 #include <string>
  
  3 #include <iostream>
  
  4 
  
  5 int main() {
  
  6   std::string str2 = ""An array of papers from the academia "" 7                      
 ""on Alaska area's fauna"";
  
  8   boost::regex r2(""a\\w*a"");
  
  9   boost::smatch matches; 
  
 10   std::string::const_iterator start = str2.begin(), 
  
 11                               end = str2.end(); 
  
 12 
  
 13   while (boost::regex_search(start, end, matches, r2)) { 
 14     
 std::cout << ""Matched substring "" << matches.str() 
  
 15            << "" at offset "" << matches[0].first - str2.begin() 
 16            << "" of length "" << matches[0].length() << '\n'; 
 17     
 start = matches[0].second; 
  
 18   } 
  
 19 }
  
 [
  157 
 ]",NA
Tokenizing text using regex ,"This is a lot of work to parse an input using a regular expression, and there ought to be 
 better abstractions available for the application programmer. Indeed, this is the kind of 
 job you can simplify using a 
 boost::regex_iterator
  and 
 boost::regex_ 
 token_iterator
 . Let us suppose we want to pick all words in the string that start and 
 end in 
 'a'
 . Here is a relatively painless way to do it:
  
 Listing 4.29: Parsing strings using boost::regex_iterator
  
  1 #include <boost/regex.hpp>
  
  2 #include <string>
  
  3 #include <iostream>
  
  4
  
  5 int main()
  
  6 {
  
  7   std::string str2 = ""An array of papers from the academia "" 8                      
 ""on Alaska area's fauna"";
  
  9   boost::regex r1(""\\ba\\w*a\\b"", boost::regex::icase); 
  
 10   boost::sregex_iterator rit(str2.begin(), str2.end(), r1), rend; 
 11 
  
 12   while (rit != rend) { 
  
 13     std::cout << *rit++ << '\n'; 
  
 14   } 
  
 15 }
  
 This program prints the following text to the output, consisting of the three words that 
 begin and end in 
 'a'
 :
  
 academia
  
 Alaska
  
 area
  
 [
  160 
 ]",NA
Replacing text ,"One frequent use of regular expressions is to search for text and replace matching text 
 by other text. For example, we may want to scan a particular paragraph for possessive 
 phrases (England's Queen, India's culture, people's choice, and so on.) and convert them 
 to an alternative form (Queen of England, culture of India, choice of people, and so on). 
 The 
 boost::regex_replace
  function template can come in handy for the purpose.
  
 To begin with, we define the regular expression 
 \w+'s\s+\w+
 . Since we have to reorder 
 the phrase, we must capture parts of the match using sub-expressions. We use the 
 regular expression 
 (\w+)'s\s+(\w+)
  to match. We can use numbered back-references 
 in the replacement string to refer to the submatches, so the replacement string is 
 ""\2 
 of \1""
 . We pass these along with the input string to 
 boost::regex_ replace
 , which 
 returns a string with the matched sections replaced appropriately. 
  
 Here is the code:
  
 Listing 4.32: Finding/Replacing strings with regular expressions
  
  1 #include <boost/regex.hpp>
  
  2 #include <cassert>
  
  3
  
  4 int main()
  
  5 {
  
  6   std::string str4 = ""England's Queen, India's President, "" 7                      
 ""people's choice"";
  
  8   boost::regex r4(""(\\w+)'s\\s+(\\w+)""); 
  
 10   std::string rep = boost::regex_replace(str4, r4, ""\\2 of \\1""); 
 11 
  
 [
  163 
 ]",NA
Self-test questions ,"For multiple choice questions, choose all options that apply:
  
 1. How does Boost Range help Boost Algorithms provide a better interface?
  
  
 a. Any character range expressed as a single argument, not iterator pair 
  
 b. 
 It is faster than iterator pairs 
  
  
 c. It supports C-style arrays, and is extensible to other abstractions 
  
 d. 
 It provides better exception safety 
  
 2. Which algorithm produces the shortest code for searching all substrings 
  
 matching a search string or pattern?
  
 a. 
 boost::find_all 
  
 b. 
 boost::find_all_regex 
  
 c. 
 boost::find_first 
  
 d. 
 boost::regex_iterator
  
 3. Which of these are tokenizer functions provided by the Boost 
  
 Tokenizer library?
  
 a. 
 boost::char_separator 
  
 b. 
 boost::split 
  
 c. 
 boost::escaped_list_separator 
  
 d. 
 boost::tokenizer
  
 4. The regular expression 
 ""\ba.*a""
  matches which part of the string 
 ""two 
  
 giant anacondas creeping around""
 ?
  
 a. 
 ""ant anacondas creeping a"" 
  
 b. 
 ""anacondas creeping a"" 
  
 c. 
 ""ant anaconda"" 
  
 d. 
 ""anaconda""
  
 [
  164 
 ]",NA
Summary,"In this chapter, we learned the use of miscellaneous functions from the Boost String 
 Algorithms library for performing various operations on string data types. We then 
 looked at the generic Boost String Tokenizer framework that provides an efficient and 
 extensible way to tokenize strings based on criteria that the user can define. We finally 
 looked at regular expressions, and the Boost.Regex library that provides the ability to 
 match character data against regular expressions, search for patterns, tokenize, and 
 replace patterns using regular expressions.
  
 This chapter should have given you a broad perspective of basic text handling facilities 
 available from the Boost libraries. Along the way, we also picked up some useful 
 techniques from the Boost Range abstraction. In the next chapter, we turn our 
 attention to various data structures available from the Boost libraries.
  
 [
  165 
 ]",NA
Effective Data Structures ,NA,NA
beyond STL,"The C++ Standard Library provides a rich set of 
 generic containers
  that can be 
 employed for a wide variety of common programming tasks. These include sequence 
 containers like 
 std::vector
 , 
 std::deque
 , 
 std::list
 , 
 std::forward_ list
 , and 
 ordered and unordered associative containers like 
 std::map
 , 
 std::set
 , 
 std::unordered_map
 , 
 std::unordered_set
 , and so on.
  
 Containers are traversed, and their individual elements accessed, using 
 iterators
 . 
  
 C++ defines a hierarchy of iterator categories based on the kind of access they provide 
 to the elements of the container (read, write, forward traversal, bidirectional traversal, 
 and random access). The type of iterator available for traversing a 
  
 container is dependent on the internal structure of a container.
  
 Available alongside the containers is a library of 
 generic algorithms
  that read and 
 manipulate generic containers, using one or more iterators. These libraries heavily rely 
 on 
 generic programming
 , in which program interfaces are abstracted from and are 
 parameterized in terms of data types.
  
 This collection of generic containers, algorithms, and a bunch of accompanying utilities 
 originated in the 
 Standard Template Library
  or 
 STL
 , developed at HP Labs by Alexander 
 Stepanov and Meng Lee, and were accepted as part of the C++ Standard Library in 1994. 
 The name STL has stuck on for those parts of the Standard Library that originated in this 
 work, and we will loosely use it to mean such parts of the library. STL containers and 
 algorithms have been heavily used in C++ 
  
 software ever since, but have had several limitations. Before C++11, you could only store 
 copyable objects in containers. Certain classes of containers like hash-based associative 
 containers, were absent in the Standard Library while others, like priority queues, were 
 under-represented.
  
 [
  167 
 ]",NA
Boost Container library,"The Boost Container library implements majority of the STL container templates in 
 addition to providing a few nifty nonstandard containers. So, what is the point of 
 reimplementing STL containers? To understand this, let us look at what kind of objects 
 can be stored in STL containers and what kind cannot be.
  
 To store objects of type 
 T
  in a 
 std::vector
 , for example, the type 
 T
  must be a complete 
 type (that is, must be completely defined, not just declared) at the point where the 
 object of type 
 std::vector<T>
  is defined. Moreover, in pre-C++11, objects of type 
 T
  
 must be copyable and assignable. These requirements generally hold for other STL 
 containers besides 
 std::vector
 . In general, till before C++11, STL was a copy-intensive 
 framework: you copied objects into STL containers to store them, the containers copied 
 them around while being resized or restructured, and the containers destroyed those 
 copies when they went out of scope. Copying being an expensive operation in terms of 
 time and memory is also more error prone and thus the exception safety of several 
 operations on STL containers was weak.
  
 [
  168 
 ]",NA
Move-awareness and in-place construction,"Consider the following class for encapsulating 
 char
  strings, which is movable but 
 not copyable. We use the Boost move emulation macros to define its move 
 semantics. In a C++11 environment, this code translates to C++11 move syntax, 
 while on C++03, it emulates the move semantics:
  
 Listing 5.1: Movable but not copyable String
  
  1 #include <boost/move/move.hpp>
  
  2 #include <boost/swap.hpp>
  
  3 #include <cstring>
  
  4
  
  5 class String
  
  6 {
  
  7 private:
  
  8   BOOST_MOVABLE_BUT_NOT_COPYABLE(String)
  
  9
  
 10 public:
  
 [
  169 
 ]",NA
Nonstandard containers,"In addition to the standard containers, the Boost Container library provides several 
 useful nonstandard containers. This section is a quick overview of these containers 
 and their applicability.",NA
Flat associative containers,"There are two flavors of the standard associative containers: 
 ordered
  and 
 unordered
 . 
  
 Ordered containers like 
 std:set
 , 
 std::multiset
 , 
 std::map
 , and 
 std::multimap 
 are typically implemented using a balanced search tree (an optimized Red-Black Tree 
 implementation is 
 de facto
 ). Thus, they store their elements in sorted order. 
  
 The unordered containers 
 std::unordered_set
 , 
 std::unordered_multiset
 , 
 std::unordered_map
 , and 
 std::unordered_multimap
 , are based on hash tables. 
 They originated in the Boost Container library before becoming part of the C++TR1 
 release and C++11 Standard Library. These containers store objects in an array of 
 buckets called a 
 hash table
 , based on hash value computed for the object. There is no 
 inherent ordering in how the objects are stored in the hash tables, hence the name 
 unordered containers.
  
 [
  172 
 ]",NA
slist,"The 
 boost::container::slist
  container is a singly-linked list abstraction similar to a 
 container template of the same name that was available in the SGI STL implementation 
 but never made it to the standard. The 
 std::list
  container is a doubly linked list. 
  
 C++ finally got its own singly linked list with 
 std::forward_list
  introduced in 
 C++11. The 
 slist
  is move-aware.
  
 Singly-linked lists have a lesser memory overhead than doubly linked lists, although 
 the time complexity of certain operations goes from constant to linear. If you need a 
 sequence container that should support relatively frequent insertions and you do not 
 need backward traversals, singly linked lists are a good choice:
  
 Listing 5.5: Using slist
  
  1 #include <boost/container/slist.hpp>
  
  2 #include <iostream>
  
  3 #include <string>
  
  4 
  
 [
  175 
 ]",NA
Splicing ,"Besides 
 insert
  and 
 emplace
 , you can also add elements at any given position in an 
 slist
  using an operation called 
 splice
 . Splicing is a useful operation on linked lists in 
 which one or more successive elements from one given list are moved to a particular 
 position in another linked list or to a different position in the same list. The 
 std::list 
 container provides a 
 splice
  member function that allows you to do this in constant time. 
 In an 
 slist
 , the time complexity of the 
 splice
  member function is linear in the number 
 of elements spliced, due to the need for linear traversal to locate the element before the 
 position of insertion. The 
 splice_after
  member function, like 
 insert_ after
  and 
 emplace_after
 , moves elements into a list after a specified position:
  
 [
  177 
 ]",NA
stable_vector ,"The 
 std::vector
  container stores objects in contiguous memory. The 
 vector 
 reallocates internal storage and copies or moves objects to new storage as needed, so as 
 to accommodate additional new objects. It allows fast random access to the stored 
 objects using an index. Inserting elements at arbitrary positions in the vector is 
 expensive compared to appending elements at the end, because insertion requires 
 elements after the point of insertion to be moved in order to make room for the new 
 element. There is one more implication of this behavior. Consider the following code:
  
 Listing 5.8: Iterator invalidation in std::vector
  
  1 #include <vector>
  
  2 #include <cassert>
  
  3 
  
  4 int main() {
  
  5   std::vector<int>v{1, 2, 3, 5};
  
  6   auto first = v.begin();
  
  7   auto last = first + v.size() - 1;
  
  8   assert(*last == 5);
  
  9   v.insert(last, 4); 
  
 10   // *last = 10;  // undefined behavior, invalid iterator 
 11   for (int i = 0; i < 1000; ++i) { 
  
 12     v.push_back(i); 
  
 13   } 
  
 14 
  
 15   // *first = 0; // likely invalidated 
  
 16 }
  
 [
  181 
 ]",NA
static_vector,"The 
 boost::container::static _vector
  template is a vector-like container with an 
 upper limit on the size defined at compile time. It allocates a fixed size, uninitialized 
 storage in its layout, rather than dynamically in a separate buffer. It does not try to value-
 initialize all the elements upon instantiation, unlike 
 vector
  or 
 stable_vector
 , both of 
 which try to value-initialize elements when an initial size is specified as a constructor 
 argument. The absence of heap allocation and value-initialization makes 
 static_vector
  
 instantiation almost zero overhead.
  
 [
  184 
 ]",NA
Fast lookups using Boost Unordered ,NA,NA
containers,"The four standard associative containers in C++03: 
 std::set
 , 
 std::map
 , 
  
 std::multiset
 , and 
 std::multimap
  are ordered containers and store their keys in 
 some sorted order using balanced binary search trees. They require an ordering 
 relationship to be defined for their keys and provide logarithmic complexity insertions 
 and lookups. Given the ordering relationship and two keys, A and B, we can determine 
 whether A precedes B or B precedes A in the relationship. If neither precedes the 
 other, the keys A and B are said to be equivalent; this does not mean A and B are equal. 
 In fact, the ordered containers are agnostic to equality and there need not be a notion 
 of equality defined at all. This is the reason, such a relation is called a 
 strict weak 
 ordering
 .
  
 Consider the following example:
  
  1 #include <string>
  
  2 #include <tuple>
  
  3 
  
  4 struct Person  {
  
  5   std::string name;
  
  6   int age;
  
  7   std::string profession;
  
  8   std::string nationality;
  
  9 };
  
 10
  
 11 bool operator < (const Person& p1, const Person& p2)
  
 12 {
  
 13   return std::tie(p1.nationality, p1.name, p1.age)
  
 [
  186 
 ]",NA
Containers for dynamically-allocated ,NA,NA
objects,"Object-oriented programming relies heavily on using polymorphic base class references 
 to manipulate objects of an entire class hierarchy. More often than not, these objects are 
 dynamically allocated. When dealing with a whole collection of such objects, STL 
 containers come a cropper; they store concrete objects of a single type and require copy 
 or move semantics. It is impossible to define a single container that can store objects of 
 different classes across a hierarchy. While you may store polymorphic base class pointers 
 in containers, pointers are treated as POD-types and with little support for deep-copy 
 semantics. The life cycle of dynamically-allocated objects is none of STL's business. But it 
 is unwieldy to define a container of pointers whose lifetimes have to be managed 
 separately without any help from the container.
  
 The Boost Pointer Container library addresses these gaps by storing pointers to 
 dynamically-allocated objects and deallocating them at the end of the container's life. 
 The pointer containers provide an interface through which you can operate on the 
 underlying objects without the need for pointer indirection. As they store pointers to 
 objects, these containers naturally support polymorphic containers without any 
 extra machinery.
  
 The following table shows pointer containers and their Standard Library 
 counterparts:
  
 Pointer container from Boost
  
 Standard Library container
  
 boost::ptr_array
  
 std::array
  
 boost::ptr_vector
  
 std::vector
  
 boost::ptr_deque
  
 std::deque
  
 boost::ptr_list
  
 std::list
  
 boost::ptr_set / boost::ptr_multiset
  
 std::set / std::multiset
  
 boost::ptr_unordered_set / boost::ptr_ 
 unordered_multiset 
  
 std::unordered_set / std::unordered_ 
 multiset
  
 boost::ptr_map / boost::ptr_multimap 
  
 std::map / std::multimap
  
 boost::ptr_unordered_map / 
 boost::ptr_unordered_multimap
  
 std::unordered_map / 
  
 std::unordered_multimap
  
 [
  190 
 ]",NA
Ownership semantics of pointer containers,"We have already seen that pointer containers ""own"" the dynamically-allocated objects 
 we store in them, in the sense that the container takes care of deallocating them at the 
 end of its own life. The objects themselves need to support neither copy nor move 
 semantics, so it is natural to wonder what it would mean to copy a pointer container. 
 Actually, the pointer containers are copyable and support simple copy semantics—upon 
 copy-construction or copy assignment of a pointer-container, it dynamically allocates a 
 copy of each object in the source container and stores the pointer to that object. This 
 works fine for any non-polymorphic type that is either a POD-type or has a copy 
 constructor. For polymorphic types, this behavior leads to slicing or failure to compile 
 when the base classes are abstract or noncopyable. In order to create deep copies of 
 containers with polymorphic objects, the objects must support the clone interface.
  
 To support creating copies of objects of a polymorphic type 
 T
 , in a namespace 
 X
 , 
 you must define a free function in the namespace 
 X
  with the following signature:
  
 1 namespace X {
  
 2   // definition of T
  
 3   ...
  
 4 
  
 5   T* new_clone(const T& obj);
  
 6 }
  
 [
  197 
 ]",NA
Null pointers in pointer containers,"Given the fact that pointer containers store pointers and give out references to the 
 underlying objects, what happens if you store a null pointer? By default, pointer 
 containers do not allow null pointers and trying to store a null pointer would duly cause 
 an exception to be thrown at runtime. You can override this behavior and tell the 
 compiler to allow storing nulls. To do this, you have to modify your container definition 
 slightly, to use:
  
 boost::ptr_container<boost::nullable<Animal>> animals;
  
 Instead of:
  
 boost::ptr_container< Animal> animals;
  
 The advantages are limited, and you have to additionally make sure you do not 
 dereference a potential null pointer. Your code becomes complex, and it becomes 
 difficult to use range-based for-loops. Here is an example:
  
  1 std::ptr_vector< boost::nullable<Animal>> animalsAndNulls;
  
  2 ... // assign animals
  
  3
  
  4 for (auto it = animalsAndNulls.begin();
  
  5 it != animalsAndNulls.end(); ++it)
  
  6 {
  
  7    if (!boost::is_null(it)) {
  
  8      Animal& a = *it;
  
  9      // do stuff ...
  
 10    }
  
 11 }
  
 It is best to avoid storing null pointers, and instead, use the Null Object Pattern that 
 the library author recommends. You can see the Boost online documentation for 
 more details on the Null Object Pattern (
 http://www.boost.org/doc/ 
 libs/1_57_0/libs/ptr_container/doc/guidelines.html#avoid-null-
 pointers-in-containers-if-possible
 ).
  
 [
  202 
 ]",NA
Expressive initialization and assignment ,NA,NA
using Boost.Assign,"Initializing an object or assigning some literal value to it using a single statement is a 
 succinct way of generating the contents of the object. It is easy to do this for simple 
 variables like numeric variables or strings, because there are readily available literals. 
  
 On the other hand, there are no simple syntactic means of initializing containers with 
 arbitrary sets of values. This is because expressing more complex objects with 
 nontrivial internal data structures as literals is difficult. Using some ingenious patterns 
 and overloaded operators, the Boost.Assign library makes it possible to initialize and 
 assign values to a whole host of STL and Boost containers, using a very expressive 
 syntax.
  
 With the availability of the new 
 initializer list
  and 
 uniform initialization
 syntax in 
 C++11, these tasks can be accomplished without Boost.Assign. Still Boost.Assign is the 
 only means of getting the job done on pre-C++11, and also provides some nifty 
 additional capabilities not easily available via initializer lists and uniform initialization.",NA
Assigning lists of values to containers,"Boost.Assign is one of those nifty little libraries in Boost, which you get into the 
 habit of using at the smallest opportunity. Here is an example:
  
 Listing 5.18: Assigning a list of values to a vector
  
  1 #include <string>
  
  2 #include <vector>
  
  3 #include <boost/assign.hpp>
  
  4 #include <cassert>
  
  5
  
 [
  203 
 ]",NA
Initializing containers with lists of values ,"In the 
 previous examples, we saw various ways of appending or inserting values into a 
 container, but Boost.Assign also lets you initialize containers with values at the time 
 of construction. The syntax is slightly different from what is used for assignments:
  
 Listing 5.20: Aggregate initialization with Boost Assign
  
  1 #include <boost/assign.hpp>
  
  2 #include <boost/rational.hpp>
  
  3 #include <iterator>
  
  4 
  
 [
  206 
 ]",NA
Initializing pointer containers and assigning ,NA,NA
values,"The Boost Assign library provides special support for assigning values to pointer 
 containers and initializing pointer containers in an exception-safe way.
  
 [
  209 
 ]",NA
Iteration patterns using Boost.Iterator,"Iteration is a fundamental task in most programming problems, whether it is iterating 
 through the elements of a container, a series of natural numbers, or the files in a 
 directory. By abstracting how a collection of values is iterated through, we can write 
 generic code to process such a collection without depending on methods of iteration 
 specific to each collection.
  
 The Standard Library containers expose iterators for this purpose, and the generic 
 algorithms in the Standard Library can operate on any conforming container through 
 its iterators, without depending on the specific type of the container or its internal 
 structure.
  
 The Boost.Iterator library provides a framework for writing iterators for custom 
 classes that conform to the standards and are compatible with algorithms in the 
 Standard Library. It also helps generalize iteration concepts to more abstract object 
 collections, not limited to containers.",NA
Smart iteration using Boost.Iterator,"The Boost Iterator library provides a number of iterator adaptors that make iterating 
 over containers and sequences of values more expressive and efficient. An iterator 
 adaptor wraps an iterator to produce another iterator. The adapted iterator may or may 
 not iterate over the entire range of elements addressed by the underlying iterator. Also, 
 they can be designed to return a different value, potentially of a different type than the 
 underlying iterator. In this section, we look at a few 
  
 examples of such iterator adaptors from Boost.
  
 [
  212 
 ]",NA
Filter Iterator ,"The filter iterators iterate over a subsequence of an underlying sequence of elements. 
  
 They wrap an underlying iterator sequence and take a unary Boolean predicate, which 
 is used to determine which elements to include from the underlying range, and which 
 ones to skip. The predicate takes an element of the underlying sequence as a single 
 argument and returns true or false. The ones for which true is returned are included in 
 the iteration, the rest are filtered out; hence the name.
  
 You can create filter iterators by using the 
 boost::make_filter_iterator
  function 
 template. You pass it a unary function object (functor, lambda, or function pointer) that 
 returns 
 bool
 . You also pass it not one, but two iterators: the one it wraps and another 
 one marking the end of sequence. In the following example, we have a list of 
 Person
  
 objects, and we need to write code to make a payout of 100 dollars to the bank account 
 of each person who is seventy years of age or older:
  
 Listing 5.23: Using filter iterators
  
  1 #include <boost/iterator/filter_iterator.hpp>
  
  2 #include <boost/assign.hpp>
  
  3 #include <vector>
  
  4 #include <string>
  
  5 #include <iostream>
  
  6
  
  7 struct Person
  
  8 {
  
  9   std::string name; 
  
 10   int age; 
  
 11   std::string bank_ac_no; 
  
 12 
  
 13   Person(const std::string& name, int years, 
  
 14          const std::string& ac_no) : 
  
 15          name(name), age(years), bank_ac_no(ac_no) {} 16 
 }; 
  
 17 
  
 17 void payout(double sum, const std::string& ac_no) { 
  
 19   std::cout << ""Credited a sum of ""<< sum 
  
 20             <<"" to bank account number "" << ac_no << '\n'; 
 21 } 
  
 22 
  
 23 template<typename Itertype> 
  
 24 void creditSum(Itertype first, Itertype last, double sum)
  
 [
  213 
 ]",NA
Transform Iterator ,"Transform iterators allow you to traverse a sequence, and when dereferenced, return the 
 result of applying a unary function to the underlying element of the sequence. 
  
 You can construct transform iterators using 
 boost::make_tranform_iterator
 , 
 passing it the unary function object and the underlying iterator.
  
 Consider 
 std::map
  objects containing subject names as keys and subjects scores as 
 values. We use transform iterators to compute the sum of the scores in all the 
 subjects, as shown in the following example:
  
 Listing 5.24: Using transform iterators
  
  1 #include <iostream>
  
  2 #include <string>
  
  3 #include <vector>
  
  4 #include <map>
  
  5 #include <algorithm>
  
  6 #include <functional>
  
  7 #include <boost/assign.hpp>
  
  8 #include <boost/iterator/transform_iterator.hpp>
  
  9 #include <numeric> // for std::accumulate 
  
 10 using namespace boost::assign; 
  
 11 
  
 12 typedef std::map<std::string, int> scoremap; 
  
 13 
  
 14 struct GetScore : std::unary_function< 
  
 15                         const scoremap::value_type&, int> 
 16 { 
  
 17   result_type operator()(argument_type entry) const 
  
 18   { 
  
 19     return entry.second; 
  
 20   } 
  
 21 }; 
  
 22 
  
 23 int main() 
  
 24 { 
  
 25   scoremap subjectScores{{""Physics"", 80}, {""Chemistry"", 78}, 
 26                      {""Statistics"", 88}, {""Mathematics"", 92}}; 
 27 
  
 28   boost::transform_iterator<GetScore,
  
 [
  215 
 ]",NA
Function Output Iterator,"The function output iterators apply a unary function to each element that is assigned 
 to them. You can create a function output iterator using the 
 boost:: 
 make_function_output_iterator
  function template, passing it a unary function 
 object. You can then use 
 std::copy
  or a similar algorithm to assign elements from a 
 sequence to the function output iterator. The function output iterator simply calls the 
 function on each element assigned to it. You can encapsulate any logic in the function 
 object you provide, print them enclosed in quotes, add them to another container, 
 keep a count of elements processed, and so on.
  
 In the following example, we have a list of directory names, and using the 
 boost::function_output_iterator
 , we concatenate them together separated 
 by spaces, making sure to quote any strings with embedded spaces:
  
 [
  216 
 ]",NA
Creating conforming iterators for custom ,NA,NA
classes,"In addition to providing iterator adaptor templates, the Boost.Iterator library provides a 
 framework for creating conforming iterators. In this section, we will use the Boost.
  
 Iterator library to create conforming iterators for a threaded binary search tree. A 
 binary search tree is an abstract data type that stores elements in a tree structure. 
 Loosely speaking, each node in the tree has zero, one, or two children. All elements in 
 the left sub-tree of a node are smaller than the node, and all elements in the right sub-
 tree of a node are larger than the node. Nodes with zero children are called leaves. A 
 threaded binary search tree is optimized for traversing its elements in a sorted order, 
 the so-called 
 inorder traversal
 .
  
 [
  218 
 ]",NA
Self-test questions ,"For multiple choice questions, choose all the options that apply:
  
 1. Which of the following are true for flat associative containers compared to 
  
 ordered/unordered associative containers?
  
 a. Require less memory 
  
 b. Insertion is faster 
  
 c. Traversal is slower 
  
 d. Lookups are faster
  
 2. The 
 std::forward_list
  does not provide a 
 size()
  member function 
 because: 
  
 a. Linear time size members cannot be supported for singly-linked lists b. 
 Both splice and size members cannot be constant time 
  
 c. It would be thread-unsafe 
  
 d. All of the above
  
 3. Where is the internal memory of a 
 static_vector
  allocated: a. 
 Stack 
  
 b. Depends on where the static vector is created 
  
 c. Free store 
  
 d. Depends on the allocator used
  
 4. In order to store objects of type X in an unordered container, which of the 
  
 following must be defined/available for objects of type X?
  
 a. Ordering relation 
  
 b. Hash function 
  
 c. Equality comparison 
  
 d. Copy constructor
  
 5. Which data structure allows random access to its elements and supports 
  
 iterators that are not invalidated upon insertion and erase of other elements?
  
 a. 
 static_vector 
  
 b. 
 unordered_map 
  
 c. 
 stable_vector 
  
 d. 
 circular_buffer
  
 [
  224 
 ]",NA
Summary,"This chapter laid out a wide array of Boost libraries that provide different kinds of 
 containers or make it easier to work with them. We looked at several useful 
 nonstandard containers that extend the Standard Library containers, looked at 
 containers designed to store dynamically-allocated object pointers, saw some 
 expressive ways of assigning elements to containers, learned about hash-based 
 unordered containers, and learned different patterns of iterating over collections and 
 enabling iteration for custom collections.
  
 In the next chapter, we will continue our study of container libraries from Boost and 
 focus on specialized containers that support efficient lookup of objects based on 
 multiple criteria.",NA
References,"Avoid null-pointers in containers (if possible): 
 http://www.boost.org/doc/ 
 libs/1_57_0/libs/ptr_container/doc/guidelines.html#avoid-null-
 pointers-in-containers-if-possible
  
 [
  225 
 ]",NA
Bimap and Multi-index ,NA,NA
Containers,"The Standard Library has ordered and unordered associative containers for storing 
 objects and looking them up efficiently using some 
 key
 . The key could be a text type, 
 numeric type, or first-class objects. For ordered containers such as 
 std::set 
 and 
 std::map
 , the keys must have a well-defined ordering relation that allows any set of 
 keys to be sorted. For unordered containers, it must be possible to compute an integer 
 hash value for each key, and additionally, determine whether any two keys are 
 equivalent for some definition of equivalence. The key represents an index or criterion 
 for lookup, and all the Standard Library associative containers support lookup using 
 only a single criterion. In other words, you cannot efficiently look up objects using 
 multiple, independent criteria.
  
 Let us suppose you have a type called 
 PersonEntry
  to describe a person. The 
 PersonEntry
  type has attributes like name, age, phone number, and so on. You would 
 end up storing several objects of type 
 PersonEntry
  in containers and at different times, 
 you may need to look up 
 PersonEntry
  objects using different attributes like name, age, 
 phone number, and so on. While the Standard Library containers do an admirable job 
 for a lot of common tasks involving collections, they cut a sorry figure when you want a 
 data structure that stores data and searches them efficiently based on multiple criteria. 
 Boost provides a small number of generic containers geared for this need, two of which 
 we study in this chapter. The chapter is divided into the following sections:
  
 • 
  
 Containers for multi-criteria lookups
  
 • 
  
 Boost Multi-index containers
  
 • 
  
 Boost Bimap
  
 [
  227 
 ]",NA
Containers for multi-criteria ,NA,NA
lookups ,"Consider a collection of objects of type 
 PersonEntry
 , as 
 defined in the following code:
  
  1 struct PersonEntry
  
  2 {
  
  3   std::string name;
  
  4   std::string phoneNumber;
  
  5   std::string city;
  
  6 };
  
 An object of this type represents an entry in a telephone directory perhaps. How 
 would you design a data structure that allows you to look up a person by name? We 
 can use a 
 std::set
  of 
 PersonEntry
  objects for it, with an appropriate ordering 
 relation defined for 
 PersonEntry
 . Since we want to search by name, we should 
 define the ordering relationship by name:
  
  1 bool operator<(const PersonEntry& left,  2                
 const PersonEntry& right) { 3   return 
 left.name< right.name;
  
  4 }
  
 Now 
 std::set
  stores only unique elements and any two 
 PersonEntry
  objects with the 
 same name would be considered duplicates. Since namesakes are common in real life, we 
 should choose a container that allows duplicates, that is, 
 std::multiset
 . We can then 
 insert elements and look them up by name using the following code:
  
 Listing 6.1: Lookups using multimaps
  
  1 #include <set>
  
  2 #include <iostream>
  
  3 #include <string>
  
  4
  
  5 struct PersonEntry {
  
  6   std::string name;
  
  7   std::string phoneNumber;
  
  8   std::string city;
  
  9 }; 
  
 10 
  
 11 int main() {
  
 [
  228 
 ]",NA
Boost Multi-index containers ,"The Boost Multi-index library actually provides a single generic container called 
 multi_index_container
  to store your objects and options to specify one or more 
 indexes, using which you may look up the objects. Each index will use a different criterion 
 on potentially different fields of the object. The indexes are defined and specified as 
 template parameters to the container and this does make the container declaration a little 
 daunting. But, this ultimately makes the container implementation tighter with a lot of 
 compile-time optimizations. Indeed, the hardest part of using these containers is really 
 getting their declaration right; so let us deconstruct a declaration of such a container of 
 PersonEntry
  objects:
  
 Listing 6.2: Defining multi-index containers
  
  1 #include <boost/multi_index_container.hpp>
  
  2 #include <boost/multi_index/indexed_by.hpp>
  
  3 #include <boost/multi_index/ordered_index.hpp>
  
  4 #include <boost/multi_index/identity.hpp>
  
  5
  
  6 using namespace boost::multi_index;
  
  7
  
  8 typedef ordered_non_unique<identity<PersonEntry>> by_person; 
 9 typedef multi_index_container<PersonEntry, 
  
 10                       indexed_by<by_person>> directory_t;
  
 In the preceding snippet, we create a typedef for a 
 multi_index_container
  of the 
 PersonEntry
  objects (lines 9-10). We use a single index called 
 person_index 
 that 
 we defined earlier (line 8). The 
 person_index
  is the type of index that will be used for 
 looking up objects in the container. It is defined as 
 ordered_ 
 non_unique<identity<PersonEntry>>
 . This means that the index keeps 
  
 the 
 PersonEntry
  objects ordered by their defined ordering relationship and allows 
 for duplicates (non-unique). This index provides the same semantics as 
 std::multiset<PersonEntry>
 . Now, if we want to look up 
 PersonEntry
  objects by 
 telephone number, we would need to define additional indexes:
  
 Listing 6.3: Defining multi-index containers
  
  1 #include <boost/multi_index_container.hpp> 2 
 #include <boost/multi_index/indexed_by.hpp> 3 
 #include <boost/multi_index/ordered_index.hpp> 4 
 #include <boost/multi_index/identity.hpp>
  
  5 #include <boost/multi_index/member.hpp>
  
 [
  230 
 ]",NA
Index types,"The 
 ordered_unique
  and 
 ordered_non_unique
  indexes correspond to the semantics of 
 std::set
  and 
 std::multiset
  respectively. Using these indexes, you not only get 
 logarithmic lookup and insertions, but can also perform an ordered traversal of the 
 container's elements. If you do not care about ordered traversal, you can also use 
 hashed_unique
  and 
 hashed_non_unique
  indexes, which provide excellent insertion and 
 lookup performance (constant expected time). Naturally, the hashed indexes do not 
 require any ordering relationship to be defined on the elements but require a way to 
 generate their hash values. This can be enabled using the techniques shown for 
 unordered containers in listing 5.11.
  
 Sometimes, it is important to get objects in the order of insertion and also perform 
 lookups based on different criteria. To get objects in the order in which they were 
 inserted, we need to use the 
 sequenced
  index. Sequenced indexes do not take any 
 arguments other than an optional tag. We can add the 
 sequenced<>
  index to the 
 directory_t
  type we defined in listing 6.3, as shown in the following code:
  
  1 #include <boost/multi_index/sequenced_index.hpp>
  
  2 typedef multi_index_container<PersonEntry,
  
  3                             indexed_by<by_name,
  
  4                                        by_phone,
  
  5                             sequenced<>>> directory_t;
  
 We could have passed a tag as a template argument to 
 sequenced
  if we wanted to. If we 
 also want a random access iterator to this sequence in insertion order, we may use the 
 random_access<>
  index instead:
  
  1 #include <boost/multi_index/random_access_index.hpp>
  
  2 typedef multi_index_container<PersonEntry,
  
  3                      indexed_by<by_name,
  
  4                           by_phone,
  
  5                           random_access<>>> directory_t;
  
 [
  233 
 ]",NA
Range lookups using lambda,"Sometimes we want to find elements whose attributes fall in a certain range 
  
 of values. Instead of using the 
 lower_bound
  and 
 upper_bound
  members of the 
 multi_index_container
  and its indexes, we can perform range lookups using a more 
 expressive syntax that uses Boost Lambda. Lambda expressions are discussed later in 
 this book (see 
 Chapter 7
 , 
 Higher Order and Compile-time Programming
 ), but you really 
 do not need to understand any of it to follow the example:
  
 Listing 6.6: Expressive range lookup
  
  1 // include required Boost Multi-index headers
  
  2 #include <boost/lambda/lambda.hpp>
  
  3
  
  4 namespace bl = boost::lambda;  // lambda placeholder
  
  5
  
  6 int main()
  
  7 {
  
  8   directory_t phonedir;  // directory_t defined in listing 6.3
  
  9
  
 10    phonedir.insert(PersonEntry{""Dr. Dolittle"", ""639 420 7624"",
  
 11                                ""Atlanta""});
  
 12    phonedir.insert(PersonEntry{""Arindam Mukherjee"", 
  
 13                                ""990 770 2458"", ""Calcutta""});
  
 14    phonedir.insert(PersonEntry{""Ace Ventura"", ""457 330 1288"",
  
 15                               ""Tampa""});
  
 16    phonedir.insert(PersonEntry{""Arindam Mukherjee"", 
  
 [
  235 
 ]",NA
Insertions and updates,"You can add new elements into the 
 multi_index_container
  and erase them using the 
 container interface or any of its indexes. How you add and erase elements via the index 
 interfaces depends on the type of the index. How you add and erase them via the 
 container's public interface is defined by the type of the first index of the container.
  
 [
  236 
 ]",NA
Boost Bimap,"Storing objects and looking them up using a key is a very common programming chore, 
 and every language has some measure of support for it through native constructs or 
 libraries in the form of dictionaries or lookup tables. In C++, the 
 std::map
  and 
 std::multimap
  containers (and their unordered variants) provide the lookup table 
 abstraction. Traditionally, such libraries support lookups in one direction. Given a key 
 you can look up a value and this is adequate for many cases. But sometimes, we also 
 need a way to look up a key given a value, and the standard library associative 
 containers are of little help in such cases; what we need there is the Boost Bimap library.
  
 [
  239 
 ]",NA
Collection types,"The default behavior of Boost Bimap is one-to-one mapping, that is, unique keys and 
 unique values. But, we can support one-to-many and many-to-many mappings by 
 varying a couple of template parameters. To illustrate such use with an example, we use 
 a map of given names to nicknames (listing 6.9). A given name can sometimes be 
 associated with multiple nicknames and a nickname too can occasionally apply to 
 multiple given names. So we would like to model a many-to-many relationship. 
  
 To define a bimap that allows many-to-many relations, we have to choose a collection 
 type for the left and right containers different from the default (which has set 
 semantics). Since both names and nicknames can be non-unique, both the left and right 
 containers should have the semantics of multisets instead. Boost Bimap provides 
 collection type specifiers (refer to the following table), which can be used as template 
 arguments to the 
 boost::bimap
  template. Depending on the collection type, the 
 semantics of the left or right view of the bimap also change. Here is a short table 
 summarizing the available collection types, their semantics, and the corresponding 
 views (based on the online documentation at 
 www.boost.org
 ):
  
 Collection type
  
 Semantics
  
 View type
  
 set_of
  
 Ordered, unique.
  
 map
  
 multiset_of
  
 Ordered, non-unique.
  
 multimap
  
 unordered_set_of
  
 Hashed, unique.
  
 unordered_map
  
 unordered_multiset_ 
 of
  
 Hashed, non-unique.
  
 unordered_multimap
  
 unconstrained_set_of
  
 Unconstrained.
  
 No view available
  
 list_of
  
 Non-ordered, non-unique.
  
 Linked list of key-value pairs
  
 vector_of
  
 Non-ordered, non-unique, 
 random access sequence.
  
 Vector of key-value pairs
  
 Note that the collection types are defined in the 
 boost::bimaps
  namespace and each 
 collection type comes in its own header, which must be included separately. The following 
 example shows you how to use collection types in conjunction with the 
 boost::bimap
  
 template to define many-to-many relations:
  
 Listing 6.9: Bimaps for many-to-many relations
  
  1 #include <boost/bimap.hpp>
  
  2 #include <boost/bimap/multiset_of.hpp>
  
  3 #include <boost/assign.hpp>
  
  4 #include <string>
  
  5 #include <iostream>
  
 [
  242 
 ]",NA
More ways to use bimaps,"There are several ways to make the use of bimaps more expressive. In this section, we 
 explore a few of these.",NA
Tagged access,"Instead of using 
 left
  and 
 right
  to access each of the two opposing views in the 
 container, you may like to use a more descriptive name to access them. You can do this 
 using tags or empty structures that are used as markers. This is very similar to how 
 indexes in Boost's multi-index containers are accessed by a tag instead of a numeric 
 position. The following code snippet illustrates this technique:
  
  1 struct name {};
  
  2 struct nickname {};
  
  3
  
  4 typedef boost::bimap<
  
  5             boostbi::multiset_of<
  
  6                boostbi::tagged<std::string, name>>,
  
  7             boostbi::multiset_of<
  
  8                boostbi::tagged<std::string, nickname>>>
  
  9         string_bimap_t;
  
 10
  
 11 string_bimap_t namesShortNames;
  
 12
  
 13 auto& names = namesShortNames.by<name>();
  
 14 auto& nicknames = namesShortNames.by<nickname>();
  
 [
  245 
 ]",NA
Projections ,"From an iterator on one view, you can get to an iterator on another view using the 
 project
  member template or the 
 project_left
 /
 project_right
  member functions. 
 Let us suppose that given a name, you want to find out all other names that share the 
 same nickname. Here is one way to do this:
  
  1 auto i1 = names.find(""Edward"");
  
  2 auto i2 = namesShortNames.project<nickname>(i1);
  
  3
  
  4 const auto& range = shortNames.range(_key == i2->first, 
  
 [
  246 
 ]",NA
Self-test questions,"For multiple choice questions, choose all options that apply:
  
 1. The 
 ordered_non_unique
  index on Boost 
 multi_index_container
  has the 
  
 semantics of:
  
 a. 
 std::set
  
 b. 
 std::multiset
  
 c. 
 std::unordered_set
  
 d. 
 std::unordered_multiset
  
 2. Deleting an element in a 
 multi_index_container
  will only invalidate the 
  
 iterator to the deleted element, irrespective of the index.
  
 a. True
  
 b. False
  
 c. Depends on the type of index
  
 [
  247 
 ]",NA
Summary,"In this chapter, we focused on containers specialized for looking up objects based on 
 multiple criteria. Specifically, we looked at Boost Bimap which is a bidirectional map 
 object, whose keys and values can both be looked up efficiently. We also looked at Boost 
 Multi-index containers, which are generic associative containers with multiple 
 associated indexes, each assisting the efficient look up of an object on one criterion.
  
 In the next chapter, we change gears to look at functional composition and 
 metaprogramming techniques that enable us to write powerful and expressive 
 applications with excellent runtime performance.",NA
References,"Multi-index modify method: 
 http://www.boost.org/doc/libs/release/libs/ 
 multi_index/doc/reference/ord_indices.html#modif
  
 [
  248 
 ]",NA
Higher Order and ,NA,NA
Compile-time Programming,"A number of Standard Library algorithms take callable entities called 
 function objects 
 (function pointers, functors, and so on) as parameters. They call these function objects 
 on individual elements of containers to compute some value or perform some action. 
  
 Thus, a part of the runtime logic of the algorithm is encapsulated in a function or functor 
 and supplied as an argument to the algorithm. A function may also return function 
 objects instead of data values. The returned function object can be applied on a set of 
 parameters and may in turn return either a value or another function object. 
  
 This gives rise to higher order transforms. This style of programming involving 
 passing and returning functions is called 
 higher order programming
 .
  
 C++ templates enable us to write type generic code. Using templates, it is possible to 
 execute branching and recursive logic at compile time and conditionally include, 
 exclude, and generate code from simpler building blocks. This style of programming is 
 called 
 compile-time programming
  or 
 template metaprogramming
 .
  
 In the first part of this chapter, we will learn the applications of higher order 
 programming in C++ using the Boost Phoenix Library and C++11 facilities like bind 
 and lambda. In the next part of this chapter, we will learn C++ template 
 metaprogramming techniques that execute at compile time to help generate more 
 efficient and expressive code. In the last part of this chapter we look at domain-
 specific languages created within C++ by applying higher order programming 
 techniques in combination with metaprogramming. The topics of this chapter are 
 divided into the following sections:
  
 • 
  
 Higher order programming using Boost
  
 • 
  
 Compile-time programming using Boost
  
 • 
  
 Domain Specific Embedded Languages
  
 [
  249 
 ]",NA
Higher order programming with Boost ,"Consider a type 
 Book
  with three string fields: the ISBN, title, and author (for our 
 purposes, assume that there is only one author). Here is how we can choose to 
 define this type:
  
  1 struct Book
  
  2 {
  
  3   Book(const std::string& id,
  
  4        const std::string& name,
  
  5        const std::string& auth)
  
  6         : isbn(id), title(name), author(auth) 7   
 {}
  
  8
  
  9   std::string isbn; 
  
 10   std::string title; 
  
 11   std::string author; 
  
 12 }; 
  
 13 
  
 14 bool operator< (const Book& lhs, const Book& rhs) 
 12 {  return lhs.isbn < rhs.isbn;  }
  
 It is a 
 struct
  with three fields and a constructor that initializes these three fields. 
 The 
 isbn
  field uniquely identifies the book and therefore is used to define an 
 ordering of 
 Book
  objects, using the overloaded 
 operator<
  (line 14).
  
 Now imagine that we have a list of these 
 Book
  objects in a 
 std::vector
 , and we 
 want to sort these books. Thanks to the overloaded 
 operator<
 , we can easily sort 
 them using the Standard Library 
 sort
  algorithm:
  
  1 #include <vector>
  
  2 #include <string>
  
  3 #include <algorithm>
  
  4 #include <iostream>
  
  5
  
  6 // include the definition of struct Book
  
  7 
  
  8 int main()
  
  9 {
  
 [
  250 
 ]",NA
Function objects ,"There is a three-argument overload of 
 std::sort
  algorithm that takes a function object 
 for comparing two elements as the third argument. This function object should return 
 true if the first argument appears before the second argument in the final ordering and 
 false otherwise. So, even without an overloaded 
 operator<
 , you can tell 
 std::sort 
 how 
 to compare two elements and sort the vector. Here is how we do the sorting using an 
 ordering function:
  
 Listing 7.1: Passing functions to algorithms
  
  1 bool byDescendingISBN(const Book& lhs, const Book& 
 rhs)
  2 {  return lhs.isbn > rhs.isbn; }
  
  3 
  
  4 ...
  
  5 std::vector<Book> books;
  
  6 ...
  
  7 std::sort(books.begin(), books.end(), byDescendingISBN);
  
 [
  251 
 ]",NA
Lambdas – unnamed function literals ,"The character string 
 ""hello""
  is a valid C++ expression. It has a well-defined type 
 (
 const char[6]
 ), can be assigned to variables of type 
 const char*
 , and passed to 
 functions that take arguments of type 
 const char*
 . Likewise, there are numeric literals 
 like 
 3.1415
  or 
 64000U
 , Boolean literals like 
 true
  and 
 false
 , and so on. C++11 
 introduces 
 lambda expressions
  for generating anonymous functions defined at the 
 site, where they are invoked. Often, simply called 
 lambdas
  (from Alonzo Church's λ-
 calculus), they consist of a function body not bound to a function name and are used to 
 generate a function definition at any point in the lexical scope of a program, where you 
 would expect to pass a function object. Let us first understand how this is done with the 
 help of an example.
  
 We have a list of integers, and we want to find the first odd number in the list using the 
 std::find_if
  algorithm. The predicate passed to 
 std::find_if
  is defined using a 
 lambda.
  
 Listing 7.4: Using lambdas
  
  1 #include <vector>
  
  2 #include <algorithm>
  
  3 #include <cassert>
  
  4 
  
  5 int main() {
  
  6   std::vector<int> vec{2, 4, 6, 8, 9, 1};
  
  7 
  
  8   auto it = std::find_if(vec.begin(), vec.end(),
  9                         
 [](const int& num) -> bool 10                         
 {  return num % 2 != 0; } 
 11                         
 ); 
  
 12 
  
 13   assert(it != vec.end() && *it == 9); 
  
 14 }
  
 [
  255 
 ]",NA
Lambda captures,"The lambda we defined in the previous example was a pure function without any state. 
 In fact, how could a lambda conceivably store the state that persists between calls? 
 Actually, lambdas can access local variables from the surrounding scope (in addition to 
 global variables). To enable such an access, we can specify 
 capture clauses
  in the 
 lambda introducer to list which variables from the surrounding scope are accessible to 
 the lambda and 
 how
 . Consider the following example in which we filter out names 
 longer than a user-specified length from a vector of names and return a vector 
 containing only the shorter names:
  
 Listing 7.5: Lambdas with captures
  
  1 #include <vector>
  
  2 #include <string>
  
  3 #include <algorithm>
  
  4 #include <iterator>
  
  5 typedef std::vector<std::string> NameVec;
  
  6
  
  7 NameVec getNamesShorterThan(const NameVec& names,
  
 [
  256 
 ]",NA
Delegates and closures,"Let us suppose you are writing a high-level C++ API for reading incoming messages on a 
 message queue. The client of your API must register for the types of messages it is 
 interested in and pass a callback—a function object that will be invoked when messages 
 of your interest arrive. Your API could be a member of a 
 Queue
  class. 
  
 Here is one possible API signature:
  
 class Queue
  
 {
  
 public:
  
  ...
  
  template <typename CallbackType>
  
  int listen(MsgType msgtype, CallbackType cb);
  
  ...
  
 };
  
 The 
 listen
  member template takes two parameters: the message type 
 msgtype
 , which 
 identifies the messages of interest, and a callback function object 
 cb
  that will be called 
 when a new message arrives. Since we want the client to be able to pass function pointers, 
 pointer to member functions, functors, as well as lambdas for the callback, we make 
 listen
  a member template parameterized on the type of the callback. Of course, the 
 callback should have a specific signature. Let us suppose it should be compatible with the 
 signature of the following function:
  
 void msgRead(Message msg);
  
 Here, 
 Message
  is the type of messages read from the queue. The 
 listen
  member 
 template is a little too permissive because it can be instantiated with function objects 
 that do not conform to the preceding signature. For a signature-incompatible callback, a 
 compilation error occurs at the point where the callback is invoked inside 
 listen
  
 rather than the point where the nonconforming callback is passed. This can make 
 debugging the compiler errors more difficult.
  
 The Boost.Function library and its C++11 incarnate 
 std::function
  offer function 
 object wrappers that are tailor-made to fix such problems. We can write the type of the 
 function 
 msgRead
  as 
 void (Message)
 . The general syntax for the type of a function of 
 arity N is as follows:
  
 return-type(param1-type, param2-type, ..., paramN-type)
  
 [
  259 
 ]",NA
Partial function application,"Given the Standard Library function 
 pow
 :
  
 double pow(double base, double power);
  
 Consider the effect of the line of code 
 x = pow(2, 3)
 . When this line is encountered, the 
 function 
 pow
  is immediately called with two arguments, the values 2 and 3. The function 
 pow
  computes 2 raised to 3 and returns the value 8.0, which is then assigned to 
 x
 .
  
 Now, say you have a list of numbers, and you want to put their cubes into another list. 
 The Standard Library algorithm 
 std::transform
  is a perfect fit for this. We just need 
 to find the right functor to raise the numbers to their cubic power. The following 
 functor takes a single numeric argument and raises it to a specific power, using the 
 pow
  function:
  
 #include <cmath>
  
 struct RaiseTo {
  
  RaiseTo(double power) : power_(power) {}
  
  double operator()(double base) const {
  
 [
  262 
 ]",NA
Compile-time programming with Boost,"Templates allow us to write C++ code that is independent of specific types of 
  
 operands and can thus work unchanged with a large family of types. We can create both 
 function templates
  and 
 class templates
  (or struct templates), which take type 
 parameters, nontype parameters (like constant integers), as well as template 
 parameters. When a 
 specialization
  of a class template is instantiated, member functions 
 that are not directly or indirectly called are never instantiated.
  
 The power of C++ templates goes beyond the ability to write generic code though. C++ 
 templates are a powerful computation subsystem using which we can introspect C++ 
 types, glean their properties, and write sophisticated recursive and branching logic that 
 executes at compile time. Using these capabilities, it is possible to define generic 
 interfaces to implementations that are highly optimized for each type they operate upon.",NA
Basic compile-time control flow using ,NA,NA
templates,"In this section, we briefly look at branching and recursive logic generated 
 using templates.",NA
Branching,"Consider the function template 
 boost::lexical_cast
 , introduced in 
 Chapter 2
 , 
 The 
 First Brush with Boost's Utilities
 . To convert a 
 string
  to a 
 double
 , we would write code 
 like the following:
  
 std::string strPi = ""3.141595259"";
  
 double pi = boost::lexical_cast<double>(strPi);
  
 The primary template of 
 lexical_cast
  is declared this way:
  
 template <typename Target, typename Source> 
 Target lexical_cast(const Source&);
  
 [
  267 
 ]",NA
Recursion,"Recursion using templates is best illustrated using an example of calculating 
 factorials at compile time. Class templates (as well as function templates) can 
 take integer arguments as long as the values are known at compile time.
  
 [
  269 
 ]",NA
Boost Type Traits ,"The Boost Type Traits library provides a set of templates used to query types for 
 properties and generate derivative types at compile time. They are useful in generic 
 code, that is, code which uses parameterized types, for purposes such as choosing an 
 optimal implementation based on the properties of a type parameter.
  
 [
  270 
 ]",NA
SFINAE and enable_if / disable_if,"Each time a compiler encounters a call to a function with the same name as a 
  
 function template, it creates an overload resolution set of matching template and non-
 template overloads. The compiler deduces template arguments as needed to determine 
 which function template overloads (and specializations thereof) qualify, and the 
 qualifying template overloads are instantiated in the process. If substitution of the 
 deduced type arguments in the template's argument list or the function parameter list 
 causes an error, this does not cause the compilation to abort. Instead, the compiler 
 removes the candidate from its overload resolution set. This is referred to as 
 Substitution Failure Is Not An Error
  or 
 SFINAE
 . The compiler only flags an error if, at 
 the end of the process, the overload resolution set is empty (no candidates) or has 
 multiple equally good candidates (ambiguity).
  
 Using a few clever tricks involving compile-time type computation, it is possible to 
 leverage SFINAE to conditionally include templates or exclude them from the 
 overload resolution set. The most succinct syntax to do this is provided by the 
 boost::enable_if
  / 
 boost::disable_if
  templates that are part of the Boost. 
 Utility library.
  
 Let us write a function template to copy an array of elements into another array. 
 The signature of the primary template is as follows:
  
 template <typename T, size_t N>
  
 void copy(T (&lhs)[N], T (&rhs)[N]);
  
 Thus, you pass two arrays of same size storing the same type of elements, and the 
 elements of the second arguments are copied into the first array in the correct order. We 
 also assume that the arrays never overlap; this keeps the implementation simple. 
 Needless to say this is not the most general setting in which such an assignment can take 
 place, but we will relax some of these restrictions a little later. Here is a generic 
 implementation for this template:
  
  1 template <typename T, size_t N>
  
  2 void copy(T (&lhs)[N], T (&rhs)[N])
  
  3 {
  
  4   for (size_t i = 0; i < N; ++i) {
  
  5     lhs[i] = rhs[i];
  
  6   }
  
  7 }
  
 [
  275 
 ]",NA
The Boost Metaprogramming Library (MPL),"The 
 Boost Metaprogramming Library
 , 
 MPL
  for short, is a general purpose library for 
 template metaprogramming. It is ubiquitous in the Boost codebase, and most libraries 
 use some metaprogramming facility from MPL. Some libraries like Phoenix, BiMap, 
 MultiIndex, and Variant use it very heavily. It is used heavily for type manipulation and 
 optimization through conditional selection of specific template implementations. This 
 section is a short overview of some of the concepts and techniques involving MPL.",NA
Metafunctions,"The heart of the MPL library is a 
 metafunction
 . Formally, a metafunction is either a 
 class template with only type parameters or a class, which exposes a single embedded 
 type called 
 type
 . In effect, type parameters if any are analogous to parameters to a 
 function and the embedded 
 type
 , which is computed at compile time based on the 
 parameters, is analogous to the return value of a function.
  
 Type traits provided by Boost Type Traits library are first-class metafunctions. 
 Consider the 
 boost::add_pointer
  type trait:
  
 template <typename T>
  
 struct add_pointer;
  
 The type 
 add_pointer<int>::type
  is 
 int*
 . The 
 add_pointer
  template is a unary 
 metafunction with a single type parameter and an embedded type called 
 type
 .
  
 Sometimes, the effective result of a type computation is numeric – case in point 
 boost::is_pointer<T>
  (Boolean truth value) or 
 boost::rank<T>
  (a positive integer). 
 In such cases, the embedded 
 type
  will have a static member called 
 value 
 containing this 
 result, and it will also be directly accessible from the metafunction as a non-type member 
 called 
 value
 . Thus, 
 boost::is_pointer<T>::type::value
  and 
 boost::is_pointer<T>::value
  are both valid, the latter being more concise.",NA
Using MPL metafunctions,"The MPL working in conjunction with Boost Type Traits makes a lot of 
  
 metaprogramming jobs easy. For this, the MPL provides a number of metafunctions to 
 compose existing metafunctions together.
  
 [
  278 
 ]",NA
Domain Specific Embedded Languages,"In the last third of this chapter, we look at the applications of higher order and compile-
 time programming mainly in the area Domain Specific Embedded Languages.",NA
Lazy evaluation,"In C++, when we see the following code:
  
 z = x + y();
  
 [
  284 
 ]",NA
Expression templates,"So, how do we express a function 
 f(x)=x+1/x
  in the language of the domain rather than 
 through a syntactic compromise within the confines of C++? To create a generic 
 solution, we must be able to support a variety of algebraic expressions. Let us start 
 with the most basic function—a constant function, such as 
 f(x)=5
 . Irrespective of the 
 value of 
 x
 , this function should always return 5.
  
 [
  285 
 ]",NA
Boost Phoenix,"Boost Phoenix 3 is a library for enabling functional programming constructs in C++. It 
 defines an elaborate and very readable DSEL with scores of functors and operators, 
 which can be used to generate fairly involved lambdas. It provides a comprehensive 
 library for constructing lazy expressions and an excellent example of what expression 
 templates can achieve. This section features a very short introduction to using Phoenix 
 expressions as lambdas, and we will see some examples of using Phoenix with Boost 
 Spirit Parser Framework. It is too extensive a library to cover in a single chapter, let 
 alone a subsection of it, but this introduction should still provide enough tail wind to 
 master Phoenix, with the benefit of the excellent online documentation.
  
 Phoenix expressions are composed of 
 actors
 , which are abstractions for lazy 
  
 functions. Actors are used to generate unnamed functions or lambdas. They support 
 partial function application by binding some arguments to values and keeping others 
 unspecified. They can be composed to generate more complex functors. In that sense, 
 Phoenix is a lambda language library.
  
 [
  290 
 ]",NA
Boost Spirit Parser Framework,"Boost Spirit is a very popular DSEL used for generating lexers and parsers, which uses 
 Boost Phoenix. Writing custom lexers and parsers used to be heavily reliant on 
 specialized tools like lex/flex, yacc/bison, and ANTLR that generated C or C++ code from a 
 language neutral specification in the 
 Extended Backus-Naur Form
  (EBNF). Spirit 
 eliminates the need for creating such a specification outside the language, and for tools to 
 translate from such specifications. It defines a declarative DSEL with intuitive syntax in 
 C++ and uses only the C++ compiler to generate parsers. Spirit makes heavy use of 
 template metaprogramming, resulting in slower compile times but generates parsers that 
 are efficient at runtime.
  
 Spirit is a rich framework that includes Spirit Lex – a lexer, Spirit Qi – a parser, and 
 Spirit Karma – a generat. You can use these separately, or use them all in 
 collaboration to build powerful data translation engines.
  
 [
  296 
 ]",NA
Using Spirit Qi,"Spirit provides 
 predefined parsers
 , which can be combined using 
 parser operators 
 defined by Spirit, to define a parser for our needs. Once defined, we can store the parser 
 or its components as 
 rules
  that can be combined with other rules. Or we can directly 
 pass it to a Qi 
 parsing API
 , such as 
 parse
  or 
 phrase_parse
 , along with the input to 
 parse.",NA
Predefined parsers,"Qi provides a number of predefined parsers that can be used to parse basic pieces of 
 data. The parsers are available or aliased under the namespace 
 boost::spirit::qi
 . 
  
 Here is a listing of these parsers with their purpose:
  
 Input class
  
 Parsers
  
 Purpose
  
 Integers
  
 int_
 , 
 uint_
 , 
 short_
 , 
 ushort_
 , 
 long_
 , 
 ulong_
 , 
 long_long
 , 
  
 ulong_long
  
 Parse signed and unsigned 
 integers
  
 Real numbers
  
 float_
 , 
 double_
 , 
 long_double
  
 Parse real numbers with 
 decimal points
  
 Boolean
  
 bool_
 , 
 true_
 , 
 false_
  
 Parse either or both the 
 strings, 
 true
  and 
 false
  
 Characters
  
 char_
 , 
 alpha
 , 
 lower
 , 
 upper
 , 
 digit
 , 
 xdigit
 , 
 alnum
 , 
  
 space
 , 
 blank
 , 
  
 punct
 , 
 cntrl
 , 
 graph
 , 
 print
  
 Parse characters of different 
 classes, like letters, digits, 
 hexadecimal digits, 
  
 punctuation, etc.
  
 Strings
  
 String
  
 Parse specific strings
  
 [
  297 
 ]",NA
The parsing API,"Qi provides two function templates, 
 parse
  and 
 phrase_parse
 , that are used to parse 
 text input. Each takes a pair of iterators that define the input range and a parser 
 expression. In addition, 
 phrase_parse
  takes a second parser expression that is used to 
 match and skip whitespace. The following short example shows you the essence of using 
 Spirit:
  
 Listing 7.28: A simple Spirit example
  
  1 #include <boost/spirit/include/qi.hpp>
  
  2 #include <cassert>
  
  3 namespace qi = boost::spirit::qi;
  
  4
  
  5 int main()
  
  6 {
  
  7   std::string str = ""Hello, world!"";
  
  8
  
  9   auto iter = str.begin();
  
 10   bool success = qi::parse(iter, str.end(), qi::alpha);
  
 11 
  
 12   assert(!success);
  
 13   assert(iter - str.begin() == 1);
  
 14 }
  
 We include the header file 
 boost/spirit/include/qi.hpp
  in order to access Spirit 
 Qi functions, types, and objects. Our input is the string 
 Hello, world!
 , and using the 
 predefined parser 
 alpha
 , we want to enforce that the first character is a letter from 
 the Latin alphabet, as opposed to a digit or a punctuation symbol. For this, we use the 
 parse
  function, passing it a pair of iterators defining the input and the 
 alpha
  parser 
 (line 10). The 
 parse
  function returns 
 true
  if the parser successfully parses the input 
 and false otherwise. The iterator to the start of the range is incremented to point to the 
 first unparsed character in the input. Since the first character of 
 Hello, world!
  is H, 
 the 
 alpha
  parser parses it successfully, incrementing the 
 iter
  by 1 (line 13) and 
 parse
  returns 
 true
  (line 12). Note that the first iterator is passed as a non-const 
 reference to 
 parse
  and is incremented by parse; the reason we pass a copy of 
 str.begin()
 .
  
 [
  298 
 ]",NA
Parser operators and expressions,"Spirit defines a number of overloaded operators called 
 parser operators
  which can 
 be used to compose a complex parser expression out of simpler parsers, including the 
 predefined ones. The following table summarizes some of these operators:
  
 Operator
  
 Type
  
 Purpose
  
 Example
  
 >> (Sequence 
 operator)
  
 Binary, infix
  
 Two parsers 
  
 serially parse two 
 tokens
  
 string(""Hello"") >> 
 string(""world"")
  
 Matches 
 Helloworld
 .
  
 | (Disjunction 
 operator)
  
 Binary, infix
  
 Any one of the two 
 parsers is able to 
  
 parse the token, 
  
 but not both
  
 string(""Hello"") | 
 string(""world"")
  
 Matches either 
 Hello
  or 
 world 
 but not 
 Helloworld
 .
  
 * (Kleene 
 operator)
  
 Unary, prefix
  
 Parses the empty 
 string or one or 
 more matching 
  
 tokens
  
 *string(""Hello"") 
  
 Matches the empty string, 
 Hello
 , 
 HelloHello,
  and so on.
  
 + (Plus 
  
 operator)
  
 Unary, prefix
  
 Parses one or more 
 matching tokens
  
 +string(""Hello"")
  
 Matches 
 Hello
 , 
 HelloHello, 
 and so on, but not the empty 
 string.
  
 ~ (Negation 
 operator)
  
 Unary, prefix
  
 Parses a token that 
 does not match the 
 parser
  
 ~xdigit 
  
 Will parse any character that is 
 not a hexadecimal digit.
  
 - (Optional 
 operator)
  
 Unary, prefix
  
 Parses the empty 
 string or a single 
 matching token
  
 -string(""Hello"") 
  
 Matches 
 Hello
  or the empty 
 string.
  
 - (Difference 
 operator)
  
 Binary, infix
  
 P1 - P2
  parses 
  
 any token that P1 
 can parse and P2 
 cannot
  
 uint_ - ushort_
  
 Matches any 
 unsigned int
  that is 
 not also an 
 unsigned short
 . 
 Matches 65540 but not 65530 on a 
 system with 2-byte 
 short
 .
  
 % (List 
  
 operator)
  
 Binary, infix
  
 P1 % D
  splits the 
 input into tokens 
 that match P1 at 
 delimiters that 
  
 match D
  
 +alnum % +(space|punct)
  
 Splits input text strings into 
 alphanumeric strings, using 
 spaces and punctuations as 
 delimiters.
  
 || (Sequential 
 OR operator)
  
 Binary, infix
  
 P1 || P2
  is 
  
 equivalent to 
 P1 | 
 (P1 >> P2)
  
 string(""Hello"") || 
 string(""world"")
  
 Matches either 
 Hello
  or 
  
 Helloworld
  but not 
 world
 .
  
 [
  299 
 ]",NA
Parsing directives ,"Parsing directives are modifiers that can be used to alter the behavior of parsers in 
 some way. For example, we can perform case-insensitive parses using the 
 no_case 
 directive, as shown in the following snippet:
  
 1   std::string str = ""Hello, WORLD!""; 
  
 2   iter = str.begin(); 
  
 3   success = qi::phrase_parse(iter, str.end(), 
  
 4                   qi::string(""Hello"") >> 
  
 5                     qi::no_case[qi::string(""world"")], 
 6                   +(qi::space|qi::punct)); 
  
 7   assert(success);
  
 The 
 skip
  directive can be used to skip whitespace over a section of the input:
  
  1   std::string str = ""Hello world"";
  
  2   auto iter = str.begin();
  
  3   bool success = qi::parse(iter, str.end(),
  
  4                   qi::skip(qi::space)[qi::string(""Hello"") >>  
 5                                        qi::string(""world"")]);
  
 6   assert( success); 
  
 The directive 
 qi::skip(qi::space)[parser]
  ignores spaces even though we called 
 parse
  and not 
 phrase_parse
 . It can be selectively applied to parser sub-expressions.",NA
Semantic actions ,"More often than not, while using Spirit, we are not just looking to verify that a piece of text 
 conforms to a certain grammar; we want to extract the tokens and perhaps use them in 
 some kind of calculation or store them away. We can associate some action to a parser 
 instance to be run when it successfully parses text, and this action can perform the 
 necessary computation using the result of the parse. Such actions are defined using a 
 function object enclosed in square brackets, trailing the parser it is associated with.
  
 Listing 7.30: Defining actions associated with parsers
  
  1 #include <boost/spirit/include/qi.hpp>
  
  2 #include <iostream>
  
  3 namespace qi = boost::spirit::qi;
  
  4
  
  5 void print(unsigned int n) {
  
 [
  301 
 ]",NA
Rules,"So far, we have generated parsers using inline expressions. When dealing with more 
 complex parsers, it is useful to cache the components and reuse them. For this purpose, 
 we use the 
 boost::spirit::qi::rule
  template. The rule template takes up to four 
 arguments of which the first, that is, the iterator type for the input, is mandatory. Thus, 
 we can cache a parser that parses spaces in 
 std::string
  objects, as shown here:
  
 qi::rule<std::string::iterator> space_rule = qi::space; 
  
 Notice that 
 space_rule
 , defined as above, is a parser that follows the same 
 grammar as 
 qi::space
 .
  
 More often than not, we are interested in consuming the value parsed by the 
  
 parser. To define a rule containing such a parser, we need to specify the signature of a 
 method that would be used to obtain the parsed value. For example, the 
  
 boost::spirit::qi::double_
  parser's attribute is of type 
 double
 . So, we consider a 
 function taking no arguments and returning a 
 double
  as the appropriate signature 
 double()
  to use. This signature is passed as the second template argument to the rule:
  
 qi::rule<std::string::iterator, double()> double_rule = 
  
  qi::double_;
  
 If the rule is meant to skip spaces, we specify the type of parser that is used to 
 identify the characters to skip as the third template argument to 
 rule
 . Thus, to 
 define a parser for a list of 
 double
 s separated by spaces, we can use the following 
 rule with 
 qi::space_type
 , specifying the type of the space parser:
  
 qi::rule<std::string::iterator, std::vector<double>(), 
  
  qi::space_type> doubles_p = +qi::double_;
  
 [
  304 
 ]",NA
Parsing timestamps,"Consider timestamps of the form YYYY-mm-DD HH:MM:SS.ff, in which the date part 
 is mandatory and the time part is optional. Moreover, the seconds and fractional 
 seconds part of the time are also optional. We need to define a suitable parser 
 expression.
  
 The first thing we require is a way to define parsers for fixed-length unsigned integers. 
  
 The 
 boost::spirit::qi::int_parser
  template comes in handy for this purpose. 
  
 Using template parameters of 
 int_parser
 , we specify the base integral type to use, the 
 radix or base of the number system, and the minimum and maximum number of digits to 
 allow. Thus, for 4-digit years, we can use a parser type 
 int_parser<unsigned short, 
 10, 4, 4>
 , both the minimum and maximum width being 4, as we need fixed-length 
 integers. The following are the rules constructed using 
 int_parser
 :
  
 #include <boost/spirit/include/qi.hpp>
  
 namespace qi = boost::spirit::qi;
  
 qi::int_parser<unsigned short, 10, 4, 4> year_p;
  
 [
  305 
 ]",NA
Self-test questions ,"For multiple choice questions, choose all the options that apply:
  
 1. Which of the following overloads/specializations does the call 
 foo(1.0, 
  
 std::string(""Hello""))
  resolve to?
  
 a. 
 template <typename T, typename U> foo(T, U); 
 b. 
 foo(double, std::string&); 
  
 c. 
 template <> foo<double, std::string> 
  
 d. There is ambiguity
  
 2. What is the interface that a metafunction must satisfy?
  
 a. It must have a static 
 value
  field 
  
 b. It must have an embedded type called 
 type 
  
 c. It must have a static 
 type
  field 
  
 d. It must have an embedded type called 
 result
  
 3. What does the following statement do: 
 boost::mpl::or_<boost::is_ 
  
 floating_point<T>, boost::is_signed<T>>
 ?
  
 a. Checks whether type T is signed and a floating point type b. 
 Generates a metafunction that checks (a) 
  
 c. Checks whether type T is signed or a floating point type d. 
 Generates a metafunction that checks (b)
  
 4. We have a template declared as: 
 template <typename T, typename Enable 
 = void> class Bar
  and does not use the 
 Enable
  parameter in any way. 
 How do you declare a partial specialization of Bar that would be instantiated 
 only when T is a non-POD type?
  
 a. 
 template <T> class Bar<T, boost::is_non_pod<T>> 
  
 b. 
 template <T> class Bar<T, boost::enable_if<is_non_ 
  
 pod<T>>::type> 
  
 c. 
 template <T> class Bar<T, boost::mpl::not<boost::is_pod<T>>> 
 d. 
 template <T> class Bar<T, boost::disable_if<is_pod<T>>::type>
  
 [
  308 
 ]",NA
Summary,"This chapter was an interlude in our exploration of the Boost libraries. There were two 
 key underlying themes: more expressive code and faster code. We saw how higher order 
 programming helps us achieve more expressive syntaxes using functors and operator 
 overloading. We saw how template metaprogramming techniques allow us to write code 
 that executes at compile time and chooses the most optimal implementations for the task 
 at hand.
  
 We covered a diverse amount of material in a single chapter and introduced a paradigm 
 of programming that may be new to some of you. We solved a few problems with 
 different functional patterns and saw the power of C++ functors, templates, and 
 operator overloading put together. Understanding the subject of this chapter will be of 
 immediate help if you are reading the implementation of most Boost libraries or trying 
 to write a fast general purpose library that is efficient, expressive, and extensible.
  
 There is a lot that we did not cover in this chapter and do not cover in this book, 
 including many, but the most basic details of Boost Spirit, a DSEL construction kit, Boost 
 Proto; an expression template-based fast regular expression library, Boost Xpressive; 
 and a more advanced tuple library, Boost Fusion. Hopefully, this chapter gives you 
 enough of a head start to explore them further. Starting with the next chapter, where we 
 cover Boost libraries for date and time calculations, we switch gears to focus on systems 
 programming libraries in Boost.",NA
References,"• 
  
 • 
  
 • 
  
 C++ Common Knowledge
 , 
 Stephen C. Dewhurst
 , 
 Addison Wesley Professional 
 Modern C++ Design
 , 
 Andrei Alexandrescu
 , 
 Addison Wesley Professional C++ 
 Template Metaprogramming
 , 
 David Abrahams and Aleksey Gurtovoy
 , 
 Addison Wesley Professional
  
 [
  309 
 ]",NA
Date and Time Libraries,"This is a short chapter that shows you how to use different Boost libraries for 
  
 performing basic date and time calculations. Most practical software use date and time 
 measurements in some form. Applications compute current date and time to produce 
 chronological logs of application activity. Specialized programs compute schedules for 
 jobs based on complex scheduling policies, and wait for specific points in time, or time 
 intervals to elapse. Sometimes, applications even monitor their own performance and 
 speed of execution, taking remedial steps as needed or raising notifications.
  
 In this chapter, we look at Boost libraries for performing date and time calculations, and 
 measuring code performance. These topics are divided into the following sections:
  
 • 
  
 Date and time calculations with Boost 
 Date Time
  
 • 
  
 Using Boost Chrono to measure time
  
 • 
  
 Measuring program performance using Boost Timer",NA
Date and time calculations with Boost ,NA,NA
Date Time,"Date and time calculations are important in many software applications, yet C++03 had 
 limited support for manipulating dates and performing calculations with them. The 
 Boost 
 Date Time
  library provides a set of intuitive interfaces for representing dates, 
 timestamps, durations, and time intervals. By allowing simple arithmetic operations 
 involving dates, timestamps, durations, and supplementing them with a set of useful 
 date/time algorithms, it enables fairly sophisticated time and calendar calculations 
 using little code.
  
 [
  311 
 ]",NA
Dates from the Gregorian calendar ,"The Gregorian calendar, also known as the Christian calendar, was introduced by 
 Pope Gregory XIII in February 1582 and over the next few centuries, replaced the 
 Julian calendar in the vast majority of the western world. The 
 Date_Time
  library 
 provides a set of types for representing dates and related quantities:
  
 • 
  
 • 
  
 • 
  
 boost::gregorian::date
 : We use this type to represent a date in the 
 Gregorian calendar.
  
 boost::gregorian::date_duration
 : In addition to dates, we also 
 need to represent durations—the length of time between two given 
 dates in the calendar—in the unit of days. For this, we use the type 
 boost::gregorian::date_duration
 . It refers to the same type as 
 boost::gregorian::days
 .
  
 boost::date_period
 : A fixed date period of the calendar starting at a given 
 date and extending for a specific duration is represented using the type 
 boost::date_period
 .",NA
Creating date objects ,"We can create objects of type 
 boost::gregorian::date
  using constituent parts of 
 a date, namely the year, month, and day of the month. In addition, there are a number 
 of factory functions that parse date strings in different formats to create objects of 
 date
 . In the following example, we illustrate the different ways of creating 
 date
  
 objects:
  
 Listing 8.1: Using boost::gregorian::date
  
  1 #include <boost/date_time.hpp>
  
  2 #include <iostream>
  
  3 #include <cassert>
  
  4 namespace greg = boost::gregorian;
  
  5
  
  6 int main() {
  
  7   greg::date d0;  // default constructed, is not a date 8   
 assert(d0.is_not_a_date());
  
  9   // Construct dates from parts 
  
 10   greg::date d1(1948, greg::Jan, 30); 
  
 11   greg::date d2(1968, greg::Apr, 4); 
  
 12 
  
 13   // Construct dates from string representations 
  
 14   greg::date dw1 = greg::from_uk_string(""15/10/1948""); 
  
 15   greg::date dw2 = greg::from_simple_string(""1956-10-29""); 16   
 greg::date dw3 = greg::from_undelimited_string(""19670605"");
  
 [
  312 
 ]",NA
Handling date durations ,"The duration of time between two dates is represented by 
 boost::gregorian::date_ 
 duration
 . In the following example, we compute time durations between dates, and 
 add durations to dates or subtract durations from dates to derive new dates:
  
 Listing 8.2: Basic date arithmetic
  
  1 #include <boost/date_time.hpp>
  
  2 #include <iostream>
  
  3 namespace greg = boost::gregorian;
  
  4
  
  5 int main() {
  
  6   greg::date d1(1948, greg::Jan, 30);
  
  7   greg::date d2(1968, greg::Apr, 4);
  
  8
  
  9   greg::date_duration day_diff = d2 - d1; 
  
 10   std::cout << day_diff.days() 
  
 11             << "" days between the two dates\n""; 
  
 12 
  
 13   greg::date six_weeks_post_d1 = d1 + greg::weeks(6); 
 14   std::cout << six_weeks_post_d1 << '\n'; 
  
 15 
  
 16   greg::date day_before_d2 = d2 - greg::days(1); 
 17   
 std::cout << day_before_d2 << '\n'; 
  
 18 }
  
 We compute durations (which can be negative) as the difference of two dates 
 (line 9), and print it in the unit of days (line 10). The 
 date_duration 
 object 
 internally represents durations in unit of days. We can also use the types 
 boost::gregorian::weeks
 , 
 boost::gregorian::months
 , and 
 boost::gregorian::years
  to construct 
 date_duration
  objects in units of 
 weeks, months, or years. Note that 
 boost::gregorian::days
  and 
 boost::gregorian::date_duration
  refer to the same types. We get new 
 dates by adding durations to or subtracting them from dates (lines 13, 16).",NA
Date periods ,"A period starting at a fixed date is represented by the type 
 boost::gregorian:: 
 date_period
 . In the following example, we construct two date periods, a calendar 
 year, and a US fiscal year. We calculate their overlap period, and then determine the 
 date of the last Friday of each month in the overlapping period.
  
 [
  314 
 ]",NA
Posix time,"The 
 Date_Time
  library also provides a set of types for representing time points, 
 durations, and periods.
  
 • 
  
 • 
  
 • 
  
 boost::posix_time::ptime
 : A specific point in time, or a 
 time point
 , is 
 represented by the type 
 boost::posix_time::ptime
 .
  
 boost::posix_time::time_duration
 : Like date durations, the length of 
 time between two time points is called a 
 time duration
  and is 
  
 represented by the type 
 boost::posix_time::time_duration
 .
  
 boost::posix_time::time_period
 : A fixed interval starting at a specific 
 time point and ending at another is called a 
 time period
  and is represented by 
 the type 
 boost::posix_time::time_period
 .
  
 These types and the operations on them together define a 
 time system
 . Posix Time 
 uses 
 boost::gregorian::date
  to represent the date part of time points.",NA
Constructing time points and durations,"We can create an instance of 
 boost::posix_time::ptime
  from its constituent parts, 
 that is, date, hours, minutes, seconds, and so on or use factory functions that parse 
 timestamp strings. In the following example, we show different ways in which we can 
 create 
 ptime
  objects:
  
 Listing 8.4: Using boost::posix_time
  
  1 #include <boost/date_time.hpp>
  
  2 #include <iostream>
  
  3 #include <cassert>
  
  4 #include <ctime>
  
  5 namespace greg = boost::gregorian;
  
  6 namespace pt = boost::posix_time;
  
  7
  
  8 int main() {
  
  9   pt::ptime pt; // default constructed, is not a time
  
 [
  316 
 ]",NA
Resolution,"The smallest duration that can be represented using a time system is called its resolution. 
 The precision with which time can be represented on a particular system, and therefore, 
 the number of digits of the fractional seconds that are significant, depends on the 
 resolution of the time system. The default resolution used by Posix Time is microsecond 
 (10
 -6
  seconds), that is, it cannot represent durations shorter than a microsecond and 
 therefore cannot differentiate between two time points less than a microsecond apart. 
 The following example demonstrates how to obtain and interpret the resolution of a time 
 system:
  
 Listing 8.5: Time ticks and resolution
  
  1 #include <boost/date_time.hpp>
  
  2 #include <iostream>
  
  3 namespace pt = boost::posix_time;
  
  4 namespace dt = boost::date_time;
  
 [
  318 
 ]",NA
Time periods ,"Just as with dates, we can represent fixed time periods using 
 boost::posix_ 
 time::time_period
 . Here is a short example that shows how you can create time 
 periods and compare different time periods:
  
 Listing 8.6: Using time periods
  
  1 #include <boost/date_time.hpp>
  
  2 #include <iostream>
  
  3 #include <cassert>
  
  4 namespace greg = boost::gregorian;
  
  5 namespace pt = boost::posix_time;
  
  6
  
  7 int main()
  
  8 {
  
  9   // Get current time 
  
 10   pt::ptime now1 = pt::second_clock::local_time(); 
  
 11   pt::time_period starts_now(now1, pt::hours(2)); 
  
 12 
  
 13   assert(starts_now.length() == pt::hours(2)); 
  
 14 
  
 15   auto later1 = now1 + pt::hours(1); 
  
 16   pt::time_period starts_in_1(later1, pt::hours(3)); 
  
 17 
  
 18   assert(starts_in_1.length() == pt::hours(3)); 
  
 19 
  
 20   auto later2 = now1 + pt::hours(3); 
  
 21   pt::time_period starts_in_3(later2, pt::hours(1)); 
  
 22 
  
 23   assert(starts_in_3.length() == pt::hours(1)); 
  
 24 
  
 26   std::cout << ""starts_in_1 starts at "" << starts_in_1.begin() 
 27             << "" and ends at "" << starts_in_1.last() << '\n'; 
 28 
  
 29   // comparing time periods 
  
 30   // non-overlapping 
  
 31   assert(starts_now < starts_in_3); 
  
 32   assert(!starts_now.intersects(starts_in_3)); 
  
 33 
  
 34   // overlapping 
  
 35   assert(starts_now.intersects(starts_in_1)); 
  
 36 
  
 37   assert(starts_in_1.contains(starts_in_3)); 
  
 38 }
  
 [
  320 
 ]",NA
Time iterator,"We can iterate over a time period using 
 boost::posix_time::time_iterator
 , 
 not unlike how we used 
 boost::gregorian::date_iterator
 . The following 
 example shows this:
  
 Listing 8.7: Iterating over a time period
  
  1 #include <boost/date_time.hpp>
  
  2 #include <iostream>
  
  3
  
  4 namespace greg = boost::gregorian;
  
  5 namespace pt = boost::posix_time;
  
  6
  
  7 int main()
  
  8 {
  
  9   pt::ptime now = pt::second_clock::local_time();
  
 [
  321 
 ]",NA
Using Chrono to measure time,"Boost Chrono is a library for time calculations having some overlapping functionality 
 with the Posix Time part of the 
 Date Time
  library. Like Posix Time, Chrono too uses the 
 notion of time points and durations. Chrono does not deal with dates. It is a newer 
 library than 
 Date Time
 , and implements the facilities proposed in a paper from the C++ 
 Standards Committee working group (WG21). Parts of that proposal made it to the 
 C++11 Standard Library as the 
 Chrono
  library, and much of the discussion on Boost 
 Chrono also applies to Chrono Standard Library (
 std::chrono
 ).",NA
Durations,"A duration represents an interval of time. The duration has a numeric magnitude and 
 must be expressed in units of time. The 
 boost::chrono::duration
  template is used 
 to represent any such duration and is declared as follows:
  
 template <typename Representation, typename Period>
  
 class duration;
  
 [
  322 
 ]",NA
Duration arithmetic ,"Durations can be added and subtracted, and durations in different units can be 
 combined to form other durations. Durations in larger units can be implicitly 
 converted to durations in smaller units. Implicit conversion from smaller to larger 
 units is only possible if you are using a floating point representation; with integral 
 representations, such conversions would incur a loss of precision. To handle this, we 
 must use a function akin to a casting operator for explicit conversions from smaller to 
 larger units with integral representations:
  
 Listing 8.8: Using chrono durations
  
  1 #include <boost/chrono/chrono.hpp>
  
  2 #include <boost/chrono/chrono_io.hpp>
  
  3 #include <iostream>
  
  4 #include <cstdint>
  
  5 namespace chrono = boost::chrono;
  
  6
  
  7 int main()
  
  8 {
  
  9   chrono::duration<int64_t, boost::ratio<1, 100>> csec(10); 
 10   std::cout << csec.count() << '\n'; 
  
 11   std::cout << csec << '\n'; 
  
 12 
  
 13   chrono::seconds sec(10); 
  
 14   chrono::milliseconds sum = sec + chrono::milliseconds(20); 
 15   // chrono::seconds sum1 = sec + chrono::milliseconds(20); 
 16 
  
 17   chrono::milliseconds msec = sec; 
  
 18 
  
 19   // chrono::seconds sec2 = sum; 
  
 20   chrono::seconds sec2 = 
  
 21                  chrono::duration_cast<chrono::seconds>(sum); 
 22 }
  
 This example illustrates the different operations you can perform with durations. The 
 boost/chrono/chrono.hpp
  header includes most of the Boost Chrono facilities we 
 need (line 1). We first create a 
 duration
  of 10 centiseconds (line 9). The 
 count 
 member function returns the tick count of the duration, that is, the number of time units 
 in the duration in the chosen unit, centiseconds (line 10). We can directly stream a 
 duration to an output stream (line 11) but need to include the additional header 
 boost/chrono/chrono_io.hpp
  for accessing these operators (line 2). 
  
 Streaming 
 csec
  prints the following:
  
 10 centiseconds
  
 [
  324 
 ]",NA
Clocks and time points,"A time point is a fixed point in time as opposed to a duration. Given a time point, we 
 can add or subtract a duration from it to derive another time point. An epoch is a 
 reference time point in some time system that can be combined with durations to 
 define other time points. The most famous epoch is the Unix or POSIX epoch January 1, 
 1970 00:00:00 UTC.
  
 Boost Chrono provides several clocks for the purpose of measuring time in different 
 contexts. A clock has the following associated members:
  
 • 
  
 A typedef called 
 duration
 , which represents the smallest duration that 
 can be expressed using the clock
  
 [
  326 
 ]",NA
Measuring program performance using ,NA,NA
Boost Timer ,"As programmers, we often need to measure performance of a section of code. While there 
 are several excellent profiling tools available for this purpose, sometimes, being able to 
 instrument our own code is both simple and more precise. The Boost Timer library 
 provides an easy-to-use, portable interface for measuring the execution times and 
 reporting them by instrumenting your code. It is a separately compiled library, not 
 header-only, and internally uses Boost Chrono.",NA
cpu_timer ,"The 
 boost::timer::cpu_timer
  class is used to measure the execution time of a 
 section of code. In the following example, we write a function that reads the contents of 
 a file and returns it in a dynamic array wrapped in a 
 unique_ptr
  (see 
 Chapter 3
 , 
 Memory Management and Exception Safety
 ). It also calculates and prints the time taken 
 to read the file using 
 cpu_timer
 .
  
 Listing 8.10: Using cpu_timer
  
  1 #include <fstream>
  
  2 #include <memory>
  
  3 #include <boost/timer/timer.hpp>
  
  4 #include <string>
  
  5 #include <boost/filesystem.hpp>
  
  6 using std::ios;
  
  7
  
  8 std::unique_ptr<char[]> readFile(const std::string& file_name, 
 9                                  std::streampos& size) 
  
 10 { 
  
 11   std::unique_ptr<char[]> buffer; 
  
 12   std::ifstream file(file_name, ios::binary); 
  
 13 
  
 14   if (file) { 
  
 15     size = boost::filesystem::file_size(file_name); 
  
 16 
  
 17     if (size > 0) { 
  
 18       buffer.reset(new char[size]); 
  
 19 
  
 20       boost::timer::cpu_timer timer;
  
 [
  329 
 ]",NA
auto_cpu_timer,"The 
 boost::timer::auto_cpu_timer
  is a subclass of 
 cpu_timer
  that automatically 
 stops the counter at the end of its enclosing scope and writes the measured execution 
 time to the standard output or another output stream provided by the user. You 
 cannot stop and resume it. When you need to measure the execution of a section of 
 code till the end of a scope, you can use just one line of code using 
 auto_cpu_timer
 , 
 as shown in the following snippet adapted from listing 8.10:
  
 17     if (size > 0) {
  
 18       buffer.reset(new char[size]);
  
 19
  
 20       file.seekg(0, ios::beg);
  
 21
  
 22       boost::timer::auto_cpu_timer timer;
  
 23       file.read(buffer.get(), size);
  
 24     }
  
 This will print the measured execution time in the familiar format to the 
 standard output:
  
 0.102563s wall, 0.000000s user + 0.040000s system = 0.040000s CPU 
 (39.0%)
  
 To print it to a different output stream, we would need to pass the stream as a 
 constructor argument to 
 timer
 .
  
 To measure the time taken to read the file, we simply declare the 
 auto_cpu_timer 
 instance before the call to 
 read
  (line 22). If the call to read was not the last statement in 
 the scope, and we did not want to measure the execution time of what followed, then 
 this would not have worked. Then, we could either use 
 cpu_timer
  instead of 
 auto_cpu_timer
 , or put only the statements that we are interested in a nested scope 
 with an 
 auto_cpu_timer
  instance created at the start:
  
 17     if (size > 0) {
  
 18       buffer.reset(new char[size]);
  
 [
  332 
 ]",NA
Self-test questions ,"For multiple choice questions, choose all options that apply:
  
 1. Which of the following lines of code is/are not well-formed? Assume that the 
  
 symbols are from the 
 boost::chrono
  namespace.
  
 a. 
 milliseconds ms = milliseconds(5) + microseconds(10);
  
 b. 
 nanoseconds ns = milliseconds(5) + microseconds(10);
  
 c. 
 microseconds us = milliseconds(5) + microseconds(10);
  
 d. 
 seconds s = minutes(5) + microseconds(10);
  
 2. What does the type 
 boost::chrono::duration<std::intmax_t, 
  
 boost::ratio<1, 1000000>>
  represent?
  
 a. A millisecond duration with integral representation
  
 b. A microsecond duration with integral representation
  
 c. A millisecond duration with floating point representation
  
 d. A nanosecond duration with integral representation
  
 3. What are the differences between 
 boost::timer::cpu_timer
  and 
  
 boost::timer::auto_cpu_timer
 ?
  
 a. 
 auto_cpu_timer
  calls 
 start
  in the constructor, 
 cpu_timer
  does not
  
 b. 
 auto_cpu_timer
  cannot be stopped and resumed
  
 c. 
 auto_cpu_timer
  writes to an output stream at the end of a scope, 
 cpu_ 
 timer
  does not
  
 d. You can extract the wall, user, and system time from 
 cpu_timer
 , but not 
 auto_cpu_timer
  
 [
  333 
 ]",NA
Summary,"This chapter introduced libraries for measuring time and calculating dates. This 
 chapter gets you up and running with the basics of date and time calculations, without 
 covering the intricate details about sophisticated calendar calculations, time zone 
 awareness, and custom and locale-specific formatting. The Boost online 
 documentation is an excellent source for these details.",NA
References,"• 
  
 • 
  
 The C++ Standard Library: A Tutorial and Reference Guide (2/e)
 , 
 Nicolai M. 
 Josuttis
 , 
 Addison Wesley Professional
  
 A Foundation to Sleep On
 : 
 Howard E. Hinnant
 , 
 Walter E. Brown
 , 
 Jeff Garland
 , 
 and 
 Marc Paterno
  (
 http://www.open-std.org/jtc1/sc22/wg21/docs/ 
 papers/2008/n2661.htm
 )
  
 [
  334 
 ]",NA
"Files, Directories, and ",NA,NA
IOStreams,"Programming for real-world systems requires interacting with various subsystems of 
 the operating system to utilize their services. Starting with this chapter, we look at the 
 various Boost libraries that provide programmatic access to OS subsystems.
  
 In this chapter, we look at the Boost libraries for performing input and output, and 
 interacting with filesystems. We cover these libraries in the following sections of the 
 chapter:
  
 • 
  
 Managing files and directories with Boost Filesystem
  
 • 
  
 Extensible I/O with Boost IOStreams
  
 Using the libraries and techniques covered in this chapter, you will be able to write 
 portable C++ programs that interact with filesystems and perform all kinds of I/O using 
 a standard interface. We do not cover network I/O in this chapter, but devote 
 Chapter 
 10
 , 
 Concurrency with Boost
 , to this topic.
  
 [
  335 
 ]",NA
Managing files and directories with Boost ,NA,NA
Filesystem,"Software written using the Boost libraries runs on multiple operating systems, including 
 Linux, Microsoft Windows, Mac OS, and various other BSD variants. How these operating 
 systems access paths to files and directories may differ in several ways; for example, MS 
 Windows uses backward slashes as the directory separator while all Unix variants, 
 including Linux, BSD, and Mac, use forward slashes. Non-English operating systems may 
 use other characters as directory separators, and sometimes, multiple directory 
 separators may be supported. The Boost Filesystem library hides these platform-specific 
 peculiarities and lets you write code that is much more portable. Using the functions and 
 types in the Boost Filesystem library, you can write OS-agnostic code to perform common 
 operations on the filesystem that an application needs to run, like copying, renaming, and 
 deleting files, traversing directories, creating directories and links, and so on.",NA
Manipulating paths,"Filesystem paths are represented using objects of type 
 boost::filesystem::path
 . 
 Given an object of type 
 boost::filesystem::path
 , we can glean useful information 
 from it and derive other 
 path
  objects from it. A 
 path
  object allows us to model a real 
 filesystem path and derive information from it, but it need not represent a path that really 
 exists in the system.",NA
Printing paths,"Let us look at our first example of using Boost Filesystem to print the current 
 working directory of a process:
  
 Listing 9.1: The first example of using Boost Filesystem
  
  1 #include <boost/filesystem.hpp>
  
  2 #include <iostream>
  
  3
  
  4 namespace fs = boost::filesystem;
  
  5
  
  6 int main() {
  
  7   // Get the current working directory
  
  8   fs::path cwd = fs::current_path();
  
  9
  
 10   // Print the path to stdout
  
 [
  336 
 ]",NA
Constructing paths ,"You can construct instances of 
 boost::filesystem::path
  using one of the 
 path 
 constructors or by combining existing paths in some way. Strings and string literals are 
 implicitly convertible to 
 path
  objects. You can construct relative as well as absolute 
 paths, convert relative paths to absolute paths, append or strip elements from the path 
 and ""normalize"" paths, as shown in listing 9.2:
  
 Listing 9.2a: Constructing empty path objects
  
  1 
 #define BOOST_FILESYSTEM_NO_DEPRECATED
  
  2 #include <boost/filesystem.hpp>
  
  3 #include <iostream>
  
  4 #include <cassert>
  
  5 namespace fs = boost::filesystem;
  
  6 
  
  7 int main() {
  
  8   fs::path p1; // empty path
  
  9   assert(p1.empty());  // does not fire 
  
 10   p1 = ""/opt/boost"";   // assign an absolute path 
 11   assert(!p1.empty()); 
  
 12   p1.clear(); 
  
 13   assert(p1.empty()); 
  
 14 }
  
 A default constructed path object represents an empty path, as illustrated by the 
 preceding example. You can assign a path string to an empty 
 path
  object (line 10) and 
 it ceases to be empty (line 11). On calling the 
 clear
  member function on the path (line 
 12), it once again turns empty (line 13). Over the years, some parts of the Boost 
 Filesystem library have been deprecated and replaced by better alternatives. 
  
 We define the macro 
 BOOST_FILESYSTEM_NO_DEPRECATED
  (line 1) to ensure that 
 such deprecated member functions and types are not accessible.
  
 Listing 9.2b: Constructing relative paths
  
 15 void make_relative_paths() { 
  
 16   fs::path p2(""..""); // relative path 
  
 17   p2 /= ""..""; 
  
 18   std::cout << ""Relative path: "" << p2.string() << '\n'; 19 
  
 20   std::cout << ""Absolute path: "" 
  
 21      << fs::absolute(p2, ""E:\\DATA\\photos"").string() << '\n'; 
 22   std::cout << ""Absolute path wrt CWD: "" 
  
 23             << fs::absolute(p2).string() << '\n'; 
  
 24
  
 [
  340 
 ]",NA
Breaking paths into components,"In the previous section, we saw how we can get the parent directory of a path by calling 
 the 
 parent_path
  member function. In fact, there is a whole slew of member functions 
 in 
 boost::filesystem::path
  to extract the components in a path. Let us first take a 
 look at a path and its components.
  
 We will first understand the Boost Filesystem terminology for path components 
 using the following path from a UNIX system:
  
 /opt/boost/include/boost/filesystem/path.hpp
  
 The leading 
 /
  is called the 
 root directory
 . The last component, 
 path.hpp
 , is called the 
 filename
 , even when the path represents a directory rather than a regular file. The path 
 stripped of the filename (
 /opt/boost/include/boost/filesystem
 ) is called the 
 parent path
 . The part following the leading slash (
 opt/boost/include/boost/ 
 filesystem/path.hpp
 ) is called the 
 relative path
 .
  
 [
  342 
 ]",NA
Traversing directories ,"Boost Filesystem provides two iterator classes, 
 directory_iterator
  and 
  
 recursive_directory_iterator
 , that make iterating through directories fairly 
 simple. Both conform to the 
 input iterator
  concept and provide an 
 operator++
  for 
 forward traversal. In the first example here, we see 
 directory_iterator
  in action:
  
 Listing 9.5: Iterating directories
  
  1 #include <boost/filesystem.hpp>
  
  2 #include <iostream>
  
  3 #include <algorithm>
  
  4 namespace fs = boost::filesystem;
  
  5
  
  6 void traverse(const fs::path& dirpath) {
  
  7   if (!exists(dirpath) || !is_directory(dirpath)) {
  
  8     return;
  
  9   } 
  
 10 
  
 11   fs::directory_iterator dirit(dirpath), end; 
  
 12 
  
 13   std::for_each(dirit, end, [](const fs::directory_entry& entry) { 
 14           std::cout <<entry.path().string() << '\n'; 
  
 15         }); 
  
 16 } 
  
 17 
  
 18 int main(int argc, char *argv[1]) { 
  
 19   if (argc > 1) { 
  
 20     traverse(argv[1]); 
  
 21   } 
  
 22 }
  
 [
  347 
 ]",NA
Querying filesystem entries,"Boost Filesystem provides a set of functions to perform useful operations on files and 
 directories. Most of these are functions in the 
 boost::filesystem
  namespace. Using 
 these functions, we can check whether a file exists, its size in bytes, its last modification 
 time, the file type, whether it is empty, and so on. We use this slew of functions to write 
 the 
 printFileProperties
  function we used in the preceding section:
  
 Listing 9.7: Querying file system entries
  
  1 #include <boost/filesystem.hpp>
  
  2 #include <iostream>
  
  3 #include <boost/date_time.hpp>
  
  4 namespace fs = boost::filesystem;
  
  5 namespace pxtm = boost::posix_time;
  
  6
  
  7 void printFileProperties(const fs::directory_entry& entry,
  
  8                          int indent = 0) {
  
  9   const fs::path& path= entry.path();
  
 10   fs::file_status stat = entry.symlink_status();
  
 [
  350 
 ]",NA
Performing operations on files ,"In addition to querying filesystem entries for information, we can also use the Boost 
 Filesystem library to perform operations on files like creating directories and links, 
 copying files and moving them, and so on.",NA
Creating directories ,"It is easy to create directories using the function 
 boost::filesystem::create_ 
 directory
 . You pass it a path and it creates a directory at that path if one does not 
 exist; it does nothing if the directory already exists. If the path exists but is not a 
 directory, 
 create_directory
  throws an exception. There is also a non-throwing 
 version that takes a 
 boost::system::error_code
  reference, which it sets on error. 
 These functions returns 
 true
  if they create the directory and 
 false
  if they do not:
  
 Listing 9.8: Creating directories
  
  1 #include <boost/filesystem.hpp>
  
  2 #include <iostream>
  
  3 #include <cassert> 
  
  4 namespace fs = boost::filesystem;
  
  5
  
  6 int main() {
  
  7   fs::path p1 = ""notpresent/dirtest"";
  
  8   boost::system::error_code ec;
  
  9   if (!is_directory(p1.parent_path()) || exists(p1)) { 
 10     
 assert( !create_directory(p1, ec) ); 
  
 11 
  
 12     if (is_directory(p1)) assert(!ec.value()); 
  
 13     else assert(ec.value()); 
  
 14   } 
  
 15 
  
 16   try { 
  
 17     if (create_directories(p1)) { 
  
 18       assert( !create_directory(p1) ); 
  
 19     } 
  
 20   } catch (std::exception& e) { 
  
 21     std::cout << ""Exception caught: "" << e.what() << '\n'; 
 22   } 
  
 23 }
  
 [
  354 
 ]",NA
Creating symbolic links,"Symbolic links, sometimes called soft links, are entries in the filesystem that act like 
 aliases to other files. They can refer to files as well as directories and are often used 
 to provide alternate, simplified names and paths for files and directories. 
  
 Symbolic links have been around on UNIX systems for quite a while now and have 
 been available in some form on Windows since Windows 2000. We can use the 
 function 
 boost::filesystem::create_symlink
  to create symbolic links. For 
 creating symbolic links to directories, the function 
 boost::filesystem::create_ 
 directory_symlink
  is recommended for better portability.
  
 Listing 9.9: Creating symbolic links
  
  1 #include <boost/filesystem.hpp>
  
  2 namespace fs = boost::filesystem;
  
  3
  
  4 void makeSymLink(const fs::path& target, const fs::path& link) {
  
  5   boost::system::error_code ec;
  
  6 
  
  7   if (is_directory(target)) {
  
  8     create_directory_symlink(target, link);
  
  9   } else {
  
 10     create_symlink(target, link);
  
 11   }
  
 12 }
  
 [
  355 
 ]",NA
Copying files,"Copying files is another common chore that Boost Filesystem helps in. The 
  
 boost::filesystem::copy_file
  function copies regular files from source to 
 destination and fails if the file already exists at the destination. Using an appropriate 
 override, it can be made to overwrite the file at the destination instead. The 
  
 boost::filesystem::copy_symlink
  takes a source symbolic link and creates a 
 second symbolic link at the destination that aliases the same file as the source. 
  
 You cannot pass a directory as the destination to either function. There is also a 
 boost::copy_directory
  function, which does not seem to do what its name 
 suggests. It creates directories and copies attributes of the source directory to the 
 target directory. So, we will roll out our own recursive directory-copying utility 
 function instead:
  
 Listing 9.10: Recursively copying directories
  
  1 void copyDirectory(const fs::path& src, const fs::path& target) {
  
  2   if (!is_directory(src)
  
  3     || (exists(target) && !is_directory(target))
  
  4     || !is_directory(absolute(target).parent_path())
  
  5     || commonPrefix(src, target) == src) {
  
  6     throw std::runtime_error(""Preconditions not satisfied"");
  
  7   }
  
  8
  
  9   boost::system::error_code ec;
  
 10   fs::path effectiveTarget = target;
  
 11   if (exists(target)) {
  
 12     effectiveTarget /= src.filename();
  
 13   }
  
 14   create_directory(effectiveTarget);
  
 [
  356 
 ]",NA
Moving and deleting files,"You can move or rename files and directories using the 
  
 boost::filesystem::rename
  function, which takes the old and new paths as 
 arguments. The two-argument overload throws an exception if it fails, while the 
 three-argument overload sets an error code:
  
 void rename(const path& old_path, const path& new_path);
  
 void rename(const path& old_path, const path& new_path,
  
  error_code& ec);
  
 If 
 new_path
  does not exist, it is created provided its parent directory exists; otherwise, 
 the call to rename fails. If 
 old_path
  is not a directory, then 
 new_path
 , if it exists, 
 cannot be a directory either. If 
 old_path
  is a directory, then 
 new_path
 , if it exists, 
 must be an empty directory or the function fails. When a directory is moved to another 
 empty directory, the contents of the source directory are copied inside the target 
 empty directory, and then the source directory is removed. Renaming symbolic links 
 acts on the links, not on the files they refer to.
  
 You can delete files and empty directories by calling 
 boost::filesystem::remove 
 passing it the path to the filesystem entry. To recursively remove a directory that is 
 not empty, you must call 
 boost::filesystem::remove_all
 .
  
 bool remove(const path& p);
  
 bool remove(const path& p, error_code& ec);
  
 uintmax_t remove_all(const path& p);
  
 uintmax_t remove_all(const path& p, error_code& ec);
  
 The 
 remove
  function returns false if the file named by the path does not exist. This 
 removes symbolic links without impacting the files they alias. The 
 remove_all 
 function returns the total number of entries it removes. On error, the single-argument 
 overloads of 
 remove
  and 
 remove_all
  throw an exception, while the two-argument 
 overloads set the error code reference passed to it without throwing an exception.",NA
Path-aware fstreams,"In addition, the header file 
 boost/filesystem/fstream.hpp
  provides versions of 
 Standard file stream classes that work with 
 boost::filesystem::path
  objects. These 
 are very handy when you are writing code that uses 
 boost::filesystem
  and also 
 needs to read and write files.
  
  
 A C++ Technical Specification based on the Boost Filesystem library 
  
  
 has been recently approved by ISO. This makes way for its inclusion 
  
 in a future revision of the C++ Standard Library.
  
 [
  358 
 ]",NA
Extensible I/O with Boost IOStreams,"The Standard Library IOStreams facility is meant to provide a framework for 
 operations of all kinds on all manner of devices, but it has not proven to be the easiest 
 of frameworks to extend. The Boost IOStreams library supplements this framework 
 with a simpler interface for extending I/O facilities to newer devices, and provides 
 some pretty useful classes that address common needs while reading and writing data.",NA
Architecture of Boost IOStreams,"The Standard Library IOStreams framework provides two basic abstractions, 
 streams
  
 and 
 stream buffers
 . Streams provide a uniform interface to the application for reading 
 or writing a sequence of characters on an underlying device. Stream buffers provide a 
 lower-level abstraction for the actual device, which is leveraged and further abstracted 
 by streams.
  
 The Boost IOStreams framework provides the 
 boost::iostreams::stream
  and 
 boost::iostreams::stream_buffer
  templates, which are generic implementations 
 of the stream and stream buffer abstractions. These two templates implement their 
 functionality in terms of a further set of concepts, which are described as follows:
  
 • 
  
 • 
  
 • 
  
 • 
  
 • 
  
 A 
 source
  is an abstraction for an object from which a sequence of characters 
 can be read.
  
 A 
 sink
  is an abstraction for an object to which a sequence of characters can be 
 written.
  
 A 
 device
  is a source, a sink, or both.
  
 An 
 input filter
  modifies a sequence of characters read from a source, while an 
 output filter
  modifies a sequence of characters before it is written to a sink.
  
 A 
 filter
  is an input filter or an output filter. It is possible to write a filter that can 
 be used either as an input filter or as an output filter; this is known as a 
 dual 
 use filter
 .
  
 To perform I/O on a device, we associate a sequence of zero or more filters plus the 
 device with an instance of 
 boost::iostreams::stream
  or an instance of 
 boost::iostreams::stream_buffer
 . A sequence of filters is called a 
 chain
  and a 
 sequence of filters with a device at the end is said to be a 
 complete chain
 .
  
 [
  359 
 ]",NA
Using devices,"A device provides an interface to read and write characters to an underlying 
  
 medium. It abstracts a real medium like a disk, memory, or network connection. In this 
 book, we will focus on using the number of readily available devices shipped as part of the 
 Boost IOStreams library. Methods of writing our own device classes are beyond the scope 
 of this book, but you should have little difficulty in picking them up from the online 
 documentation once you are familiar with the content we cover in this chapter.",NA
Devices for file I/O,"Boost defines a number of devices for performing I/O on files and the one we look at 
 first is a device that abstracts platform-specific file descriptors. Each platform uses some 
 native handle for open files, different from how standard C++ represents open files 
 using 
 fstream
 s. These could be integer file descriptors on POSIX systems and HANDLEs 
 on Windows, for example. The Boost IOStreams library provides the 
 boost::iostreams::file_descriptor_source
 , 
 boost::iostreams::file_ 
 descriptor_sink
 , and 
 boost::iostreams::file_descriptor
  devices that adapt 
 POSIX file descriptors and Windows file handles into devices for input and output. In the 
 following example, we use a 
 file_descriptor_source
  object to read successive lines 
 from a file on a POSIX system using the stream interface. This is useful if you want to use 
 a stream interface for I/O on a file that is opened using system calls that deal in file 
 descriptors.
  
 Listing 9.11: Using the file_descriptor device
  
  1 #include <boost/iostreams/stream.hpp>
  
  2 #include <boost/iostreams/device/file_descriptor.hpp>
  
  3 #include <iostream>
  
  4 #include <string>
  
  5 #include <cassert>
  
  6 #include <sys/types.h>
  
  7 #include <fcntl.h>
  
  8 namespace io = boost::iostreams;
  
  9
  
 10 int main(int argc, char *argv[]) {
  
 11   if (argc < 2) {
  
 12     return 0;
  
 13   }
  
 14
  
 15   int fdr = open(argv[1], O_RDONLY);
  
 [
  361 
 ]",NA
Devices for reading and writing to memory ,"The Standard Library 
 std::stringstream
  family of classes is commonly used for 
 reading and writing formatted data to memory. If you want to read and write from any 
 given contiguous memory area, like an array or byte buffer, the 
 array
  family of 
 devices (
 array_source
 , 
 array_sink
 , and 
 array
 ) from Boost IOStreams library 
 comes in handy:
  
 Listing 9.12: Using array devices
  
  1 #include <boost/iostreams/device/array.hpp>
  
  2 #include <boost/iostreams/stream.hpp>
  
  3 #include <boost/iostreams/copy.hpp>
  
  4 #include <iostream>
  
  5 #include <vector>
  
  6 namespace io = boost::iostreams;
  
  7
  
  8 int main() {
  
  9   char out_array[256]; 
  
 10   io::array_sink sink(out_array, out_array + sizeof(out_array)); 
 11   io::stream<io::array_sink> out(sink); 
  
 12   out << ""Size of out_array is "" << sizeof(out_array) 
  
 13       << '\n' << std::ends << std::flush; 
  
 14 
  
 15   std::vector<char> vchars(out_array, 
  
 16                           out_array + strlen(out_array)); 
  
 17   io::array_source src(vchars.data(),vchars.size()); 
  
 18   io::stream<io::array_source> in(src);
  
 [
  363 
 ]",NA
Using filters ,"Filters act on the character stream that is written to a sink or read from a source, 
 either transforming it before it is written and read, or simply observing some 
 properties of the stream. The transformation can do a variety of things, like tagging 
 keywords, translating text, performing regular expression substitution, and 
 performing compression or decompression. Observer filters can compute line and 
 word counts or compute a message digest among other things.
  
 [
  365 
 ]",NA
Basic filters ,"In the first example of using filters, we use 
 boost::iostreams::counter
  filter to 
 keep a count of characters and lines in text read from a file:
  
 Listing 9.14: Using the counter filter
  
  1 #include <boost/iostreams/device/file.hpp>
  
  2 #include <boost/iostreams/filtering_stream.hpp>
  
  3 #include <boost/iostreams/filter/counter.hpp>
  
  4 #include <boost/iostreams/copy.hpp>
  
  5 #include <iostream>
  
  6 #include <vector>
  
  7 namespace io = boost::iostreams;
  
  8
  
  9 int main(int argc, char *argv[]) { 
  
 10   if (argc <= 1) { 
  
 11     return 0; 
  
 12   } 
  
 13 
  
 14   io::file_source infile(argv[1]); 
  
 15   io::counter counter; 
  
 16   io::filtering_istream fis; 
  
 17   fis.push(counter); 
  
 18   assert(!fis.is_complete()); 
  
 19   fis.push(infile); 
  
 20   assert(fis.is_complete()); 
  
 21 
  
 22   io::copy(fis, std::cout); 
  
 23 
  
 24   io::counter *ctr = fis.component<io::counter>(0); 
 25   std::cout << ""Chars: "" << ctr->characters() << '\n' 
 26             << ""Lines: "" << ctr->lines() << '\n'; 
 27 
 }
  
 [
  366 
 ]",NA
Filters for compression and decompression,"Boost IOStreams library comes with three different filters for compressing and 
 decompressing data, one each for gzip, zlib, and bzip2 formats. The gzip and zlib formats 
 implement different variants of the 
 DEFLATE algorithm
  for compression, while the 
 bzip2 format uses the more space-efficient 
 Burrows-Wheeler algorithm
 . Since these 
 are external libraries, they must be built and linked to our executables if we use these 
 compression formats. If you have followed the detailed steps outlined in 
 Chapter 1
 , 
 Introducing Boost
 , to build Boost libraries with support for zlib and bzip2, then the zlib 
 and bzip2 shared libraries should have been built along with the Boost Iostreams shared 
 library.
  
 In the following example, we compress a file named on the command line and write it to 
 the disk. We then read it back, decompress it, and write it to the standard output.
  
 Listing 9.16: Using gzip compressor and decompressor
  
  1 #include <boost/iostreams/device/file.hpp>
  
  2 #include <boost/iostreams/filtering_stream.hpp>
  
 [
  368 
 ]",NA
Composing filters,"Filtering streams can apply multiple filters to a character sequence in a pipeline. Using the 
 push
  method on the filtering stream, we form the pipeline starting with the outermost 
 filter, inserting the filters in the desired order, and ending with the device.
  
 This means that for filtering an output stream, you first push the filter that gets applied 
 first and work forward pushing each successive filter, followed at the end by the sink. For 
 example, in order to filter out some lines and compress before writing to a sink, the 
 sequence of pushes would be like the following:
  
 filtering_ostream fos;
  
 fos.push(grep);
  
 fos.push(gzip);
  
 fos.push(sink);
  
 For filtering input streams, you push the filters, starting with the filter that gets applied 
 last and work backward pushing each preceding filter, followed at the end by the source. 
 For example, in order to read a file, decompress it and then perform a line count, the 
 sequence of pushes will look like this:
  
 filtering_istream fis;
  
 fis.push(counter);
  
 fis.push(gunzip);
  
 fis.push(source);
  
 [
  370 
 ]",NA
Pipelining,"It turns out that a little operator overloading can make this much more expressive. We 
 can write the preceding chains using the pipe operator (
 operator|
 ) in the following 
 alternative notation:
  
 filtering_ostream fos; 
  
 fos.push(grep | gzip | sink);
  
 filtering_istream fis; 
  
 fis.push(counter | gunzip | source);
  
 The preceding snippet is clearly more expressive with fewer lines of code. From left to 
 right, the filters are strung together in the order you push them into the stream, with the 
 device at the end. Not all filters can be combined in this way, but many readily available 
 ones from the Boost IOStreams library can; more definitively, filters must conform to 
 the 
 Pipable concept
  to be combined this way. Here is a complete example of a program 
 that reads the text in a file, removes blank lines, and then compresses it using bzip2:
  
 Listing 9.17: Piping filters
  
  1 #include <boost/iostreams/device/file.hpp>
  
  2 #include <boost/iostreams/filtering_stream.hpp>
  
  3 #include <boost/iostreams/stream.hpp>
  
  4 #include <boost/iostreams/filter/bzip2.hpp>
  
  5 #include <boost/iostreams/filter/grep.hpp>
  
  6 #include <boost/iostreams/copy.hpp>
  
  7 #include <boost/regex.hpp>
  
  8 #include <iostream>
  
  9 namespace io = boost::iostreams; 
  
 10 
  
 11 int main(int argc, char *argv[]) { 
  
 12   if (argc <= 1) { return 0; } 
  
 13 
  
 14   io::file_source infile(argv[1]); 
  
 15   io::bzip2_compressor bzip2; 
  
 16   io::grep_filter grep(boost::regex(""^\\s*$""), 
  
 17         boost::regex_constants::match_default, 
  
 18         io::grep::invert); 
  
 19   io::filtering_istream fis; 
  
 20   fis.push(bzip2 | grep | infile); 
  
 21   io::file_sink outfile(argv[1] + 
 std::string("".bz2"")); 22   io::stream<io::file_sink> 
 os(outfile); 
  
 23 
  
 24   io::copy(fis, os); 
  
 25 }
  
 [
  371 
 ]",NA
Branching data streams with tee,"While using filter chains with multiple filters, it is sometimes useful, 
  
 especially for debugging, to capture the data flowing between two filters. The 
 boost::iostreams:: tee_filter
  is an output filter akin to the Unix 
 tee
  command 
 that sits interposed between two filters and extracts a copy of the data stream flowing 
 between the two filters. Essentially, when you want to capture data at different 
 intermediate stages of processing, you can use a 
 tee_filter
 :
  
 filter1
  
 filter1
  
 Tee filter2
  
 filter3
  
 filter3
  
 output
  
 input
  
 You can also multiplex two sink devices to create a 
 tee device
 , such that writing some 
 content to the tee device writes it to both the underlying devices. The 
  
 boost::iostream::tee_device
  class template combines two sinks to create such a 
 tee device. By nesting tee devices or pipelining tee filters, we can generate several 
 parallel streams that can be processed differently. The 
 boost::iostreams::tee 
 function template can generate tee filters and tee streams. It has two overloads—a 
 single-argument overload that takes a sink and generates a 
 tee_filter
 , and a two-
 argument overload that takes two sinks and returns a 
 tee_device
 . The following 
 example shows how to compress a file to three different compression formats (gzip, zlib, 
 and bzip2) using very little code:
  
 Listing 9.18: Branching output streams with tees
  
  1 #include <boost/iostreams/device/file.hpp>
  
  2 #include <boost/iostreams/filtering_stream.hpp>
  
  3 #include <boost/iostreams/stream.hpp>
  
  4 #include <boost/iostreams/filter/gzip.hpp>
  
  5 #include <boost/iostreams/filter/bzip2.hpp>
  
  6 #include <boost/iostreams/filter/zlib.hpp>
  
  7 #include <boost/iostreams/copy.hpp>
  
  8 #include <boost/iostreams/tee.hpp>
  
  9 namespace io = boost::iostreams;
  
 10
  
 [
  372 
 ]",NA
Self-test questions ,"For multiple-choice questions, choose all options that apply:
  
 1. What is unique to the 
 canonical
  and 
 equivalent
  functions for 
  
 manipulating paths?
  
 a. The arguments cannot name real paths.
  
 b. Both are namespace-level functions. 
  
 c. The arguments must name real paths.
  
 2. What is the problem with the following code snippet assuming the path is 
  
 of 
 type 
 boost::filesystem::path
 ?
  
 if (is_regular_file(path)) { /* … */ } 
  
 else if (is_directory(path)) { /* … */ 
 } 
  
 else if (is_symlink(path)) { /* … */ }
  
 a. It must have static 
 value
  field.
  
 b. It must have an embedded type called 
 type
 . 
  
 c. It must have static 
 type
  field.
  
 d. It must have an embedded type called 
 result
 .
  
 3. Given this code snippet: 
  
 boost::filesystem::path p1(""/opt/boost/include/boost/thread.hpp""); 
 size_t n = std::distance(p1.begin(), p1.end());
  
 What is the value of n?
  
 a. 5, the total number of components in the path.
  
 b. 6, the total number of components in the path.
  
 c. 10, the sum of the number of slashes and components. d. 
 4, the total number of directory components.
  
 [
  374 
 ]",NA
Summary,"In this chapter, we covered the Boost Filesystem library for reading file metadata and 
 state of files and directories, and performing operations on them. We also covered 
 the high-level Boost IOStreams framework for performing type-safe I/O with rich 
 semantics.
  
 Working with files and performing I/O are basic system programming tasks that 
 almost any useful piece of software needs to perform and the Boost libraries we 
 covered in this chapter ease those tasks through a set of portable interfaces. In the 
 next chapter, we will turn our attention to another systems programming topic—
 concurrency and multithreading.
  
 [
  375 
 ]",NA
Concurrency with Boost,"Threads
  represent concurrent streams of execution within a process. They are a low-
 level abstraction for 
 concurrency
  and are exposed by the system programming 
 libraries or system call interfaces of operating systems, for example, POSIX threads, 
 Win32 Threads. On multiprocessor or multicore systems, operating systems can 
 schedule two threads from the same process to run in parallel on two different cores, 
 thus achieving true 
 parallelism
 .
  
 Threads are a popular mechanism to abstract concurrent tasks that can potentially run in 
 parallel with other such tasks. Done right, threads can simplify program structure and 
 improve performance. However, concurrency and parallelism 
  
 introduce complexities and nondeterministic behavior unseen in single-threaded 
 programs, and doing it right can often be the biggest challenge when it comes to threads. 
 A wide variance in the native multithreading libraries or interfaces across operating 
 systems makes the tasks of writing portable concurrent software using threads even 
 more difficult. The Boost Thread library eases this problem by providing a portable 
 interface to create threads and higher level abstractions for concurrent tasks. The 
 Boost 
 Coroutine
  library provides a mechanism to create cooperative 
 coroutines
  or functions 
 which can be exited and resumed, retaining states of automatic objects between such 
 calls. Coroutines can express event-driven logic in a simpler way, and avoid the overhead 
 of threads in some cases.
  
 This chapter is a hands-on introduction to using the Boost Thread library and also 
 features a short account of the Boost Coroutine library. It is divided into the 
 following sections:
  
 • 
  
 Creating concurrent tasks with Boost Thread
  
 • 
  
 Concurrency, signaling, and synchronization
  
 • 
  
 Boost Coroutines
  
 [
  377 
 ]",NA
Creating concurrent tasks with Boost ,NA,NA
Thread ,"Consider a program that prints greetings in different languages. There is one list of 
 greetings in Anglo-Saxon languages, such as English, German, Dutch, Danish, and so on. 
 There is a second list of greetings in Romance languages, such as Italian, Spanish, French, 
 Portuguese, and so on. Greetings from both language groups need to be printed, and we 
 do not want to delay printing the greetings from one group because of the other, that is, 
 we want to print greetings from both the groups 
 concurrently
 . 
  
 Here is one way to print both the groups of greetings:
  
 Listing 10.1: Interleaved tasks
  
  1 #include <iostream>
  
  2 #include <string>
  
  3 #include <vector>
  
  4
  
  5 int main()
  
  6 {
  
  7   typedef std::vector<std::string> strvec;
  
  8
  
  9   strvec angloSaxon{""Guten Morgen!"", ""Godmorgen!"", 10                    
 ""Good morning!"", ""goedemorgen""}; 11 
  
 12   strvec romance{""Buenos dias!"", ""Bonjour!"", 
  
 13                  ""Bom dia!"", ""Buongiorno!""}; 
  
 14 
  
 15   size_t max1 = angloSaxon.size(), max2 = romance.size(); 
 16   size_t i = 0, j = 0; 
  
 17 
  
 18   while (i < max1 || j < max2) { 
  
 19     if (i < max1) 
  
 20       std::cout << angloSaxon[i++] << '\n';
  
 [
  378 
 ]",NA
Using Boost Threads,"Every running process has at least one thread of execution. A traditional ""hello world"" 
 program with a 
 main
  function also has a single thread, often called the 
 main thread
 . 
  
 Such programs are called 
 single-threaded
 . Using Boost Threads, we can create programs 
 with multiple threads of execution that run concurrent tasks. We can rewrite the listing 
 10.1 using Boost Threads so that the code for an individual task is cleanly factored out, 
 and the tasks potentially run in parallel when parallel hardware 
  
 is available. Here is how we can do this:
  
 Listing 10.2: Concurrent tasks as threads
  
  1 #include <boost/thread.hpp>
  
  2 #include <string>
  
  3 #include <vector>
  
 [
  379 
 ]",NA
Moving threads and waiting on threads,"An object of 
 std::thread
  is associated with and manages exactly one thread in a 
 process. Consider the following code snippet:
  
  1 void threadFunc() { ... }
  
  2
  
  3 boost::thread makeThread(void (*thrFunc)()) { 
 4   assert(thrFunc);
  
  5   boost::thread thr(thrFunc);
  
  6   // do some work
  
  7   return thr;
  
  8 }
  
  9 
  
 10 int main() { 
  
 11   auto thr1 = makeThread(threadFunc);
  
 [
  382 
 ]",NA
Thread IDs,"At any time, each running thread in a process has a unique identifier. This identifier is 
 represented by the type 
 boost::thread::id
  and can be obtained from a 
  
 boost::thread
  object by calling the 
 get_id
  method. To get the ID of the current 
 thread, we must use 
 boost::this_thread::get_id()
 . A string representation of the 
 ID can be printed to an 
 ostream
  object, using an overloaded insertion operator 
 (
 operator<<
 ).
  
 Thread IDs can be ordered using an 
 operator<
  so they can easily be stored in 
  
 ordered associative containers (
 std::set
  / 
 std::map
 ). Thread IDs can be compared 
 using an 
 operator==
  and can be stored in unordered associative containers too 
 (
 std::unordered_set
  / 
 std::unordered_map
 ). Storing threads in associative 
 containers indexed by their IDs is an effective means of supporting lookups on threads:
  
 Listing 10.3: Using thread IDs
  
  1 #include <boost/thread.hpp>
  
  2 #include <boost/chrono/duration.hpp>
  
  3 #include <vector>
  
  4 #include <map>
  
 [
  384 
 ]",NA
Cores and threads,"Many modern computers have multiple CPU cores on a single die and there might be 
 multiple dice in a processor package. To get the number of physical cores on the 
 computer, you can use the static function 
 boost::thread::physical_concurrency
 .
  
 Modern Intel CPUs support Intel's HyperThreading technology, which maximizes 
 utilization of a single core by using two sets of registers allowing two threads to be 
 multiplexed on the core at any given point and reducing the costs of context switching. 
 On an Intel system with eight cores and supporting HyperThreading, the maximum 
 number of threads that can be scheduled to run in parallel at any given time is then 8x2 
 = 16. The static function 
 boost::thread::hardware_concurrency 
 returns this 
 number for the local machine.
  
 These numbers are useful in deciding the optimal number of threads in your 
 program. However, it is possible for these functions to return 0 if the numbers are 
 not available from the underlying system. You should test these functions 
 thoroughly on each platform where you plan to use them.",NA
Managing shared data,"All threads in a process have access to the same global memory, so the results of 
 computations performed in one thread are relatively easy to share with other threads. 
 Concurrent read-only operations on shared memory do not require any coordination, but 
 any write to shared memory requires synchronization with any read or write. 
  
 Threads that share 
 mutable data
  and other resources need mechanisms to 
 arbitrate 
 access
  to shared data and signal each other about events and state changes. In this 
 section, we explore the mechanisms for coordination between multiple threads.",NA
Creating and coordinating concurrent tasks,"Consider a program that generates the difference between two text files à la the Unix 
 diff
  utility. You need to read two files, and then apply an algorithm to identify the parts 
 that are identical and the parts that have changed. For most text files, reading both the 
 files and then applying a suitable algorithm (based on the Longest Common Subsequence 
 problem) works perfectly well. The algorithm itself is beyond the scope of this book and 
 not germane to the present discussion.
  
 Consider the tasks we need to perform:
  
 • 
  
 R1: Read complete contents of the first file
  
 • 
  
 R2: Read complete contents of the second file
  
 • 
  
 D: Apply the diff algorithm to the contents of the two files
  
 [
  386 
 ]",NA
boost::future and boost::promise ,"The 
 boost::future<>
  template is used to represent the result of a computation that 
 potentially happens in the future. An object of type 
 boost::future<T>
  represents a 
 proxy for an object of type 
 T
  that will potentially be produced in the future. Loosely 
 speaking, 
 boost::future
  enables a calling code to wait or block for an event to 
 happen—the event of producing a value of a certain type. This mechanism can be used 
 to signal events and pass values from one thread to another.
  
 The producer of the value or the source of the event needs a way to communicate with the 
 future object in the calling thread. For this, an object of type 
 boost::promise<T>
 , 
 associated with the future object in the calling thread, is used to signal events and send 
 values. Thus 
 boost::future
  and 
 boost::promise
  objects work in pairs to signal events 
 and pass values across threads. We will now see how we can guarantee that the two file 
 read operations in two threads precede the diff operation using Boost futures and 
 promises:
  
 Listing 10.4b: Returning values from a thread using futures and promises
  
  1 #define BOOST_THREAD_PROVIDES_FUTURE
  
  2 #include <boost/thread.hpp>
  
  3 #include <boost/thread/future.hpp>
  
  4 // other includes
  
  5
  
  6 std::vector<char> diffFiles(const std::string& file1, 
  
  7                             const std::string& file2) {
  
  8   // set up the promise-future pair
  
  9   boost::promise<std::vector<char>> promised_value; 
  
 10   boost::future<std::vector<char>> future_result 
  
 11                                = promised_value.get_future(); 
 12   // spawn a reader thread for file2 
  
 13   boost::thread reader( 
  
 14                     [&promised_value, &file2]() { 
  
 15                       std::cout << ""Reading "" << file2 << 
 '\n'; 16                       auto content = 
 readFromFile(file2); 17                       
 promised_value.set_value(content); 
  
 18                       std::cout << ""Read of "" << file2 
  
 19                                 << "" completed.\n""; 
  
 20                     }); 
  
 21 
  
 22   std::cout << ""Reading "" << file1 << '\n'; 
  
 23   auto content1 = readFromFile(file1); 
  
 24   std::cout << ""Read of "" << file1 << "" completed.\n""; 
  
 25 
  
 26   auto content2 = future_result.get(); // this blocks
  
 [
  388 
 ]",NA
Waiting for future ,"The 
 get
  member function of 
 boost::future<>
  blocks the calling thread until the 
 associated promise is set. It returns the value set in the promise. Sometimes, you might 
 want to block for a short duration and go ahead if the promise is not set. To do this, 
 you have to use the 
 wait_for
  member function and specify the duration to wait using 
 boost::chrono::duration
  (see 
 Chapter 8
 , 
 Date and Time Libraries
 ):
  
 Listing 10.5: Waiting and timing out on a future
  
  1 #define BOOST_THREAD_PROVIDES_FUTURE
  
  2 #include <boost/thread.hpp>
  
  3 #include <boost/thread/future.hpp>
  
  4 #include <boost/chrono.hpp>
  
  5 #include <ctime>
  
  6 #include <cassert>
  
  7 #include <cstdlib>
  
  8 #include <iostream>
  
  9 
  
 10 int main() { 
  
 11   boost::promise<void> promise; 
  
 12   boost::future<void> future = promise.get_future(); 
  
 13 
  
 14   std::cout << ""Main thread id="" 
  
 15                       << boost::this_thread::get_id() << '\n'; 
 16   boost::thread thr([&promise]() { 
  
 17          srand(time(0)); 
  
 18          int secs = 10 + rand() % 10; 
  
 19          std::cout << ""Thread "" << 
 boost::this_thread::get_id() 20                   << "" sleeping 
 for "" 
  
 21                   << secs << "" seconds\n""; 
  
 22          boost::this_thread::sleep_for( 
  
 23               boost::chrono::seconds(secs)); 
  
 24          promise.set_value(); 
  
 25        }); 
  
 26 
  
 27   size_t timeout_count = 0; 
  
 28   size_t secs = 2; 
  
 29 
  
 30   while (future.wait_for(boost::chrono::seconds(secs)) 
  
 31           == boost::future_status::timeout) { 
  
 32     std::cout << ""Main thread timed out\n""; 
  
 33     ++timeout_count; 
  
 34   } 
  
 35   assert(future.is_ready());
  
 [
  390 
 ]",NA
Throwing exceptions across threads,"If the initial function passed to the 
 boost::thread
  constructor allows any exceptions to 
 propagate, then the program is immediately aborted by a call to 
 std::terminate
 . This 
 creates a problem if we need to throw an exception from one thread to indicate a problem 
 to another thread, or propagate an exception we caught in one thread to another. The 
 promise/future mechanism comes in handy for this purpose too. Consider how, in Listing 
 10.4a and 10.4b, you would handle the case when a file does not exist or is not readable:
  
 [
  391 
 ]",NA
shared_future ,"The 
 boost::future
  object can only be waited upon by one thread. It is not copyable 
 but is movable; thus, its ownership can be transferred from one thread to another and 
 one function to another, but never shared. If we want multiple threads to wait on the 
 same condition using the future mechanism, we need to use 
 boost::shared_ future
 . 
 In the following example, we create a publisher thread that waits for a fixed duration 
 before setting a promise with its thread ID. We also create three subscriber threads, 
 which poll a 
 boost::shared_future
  object associated with the promise object at 
 different periodicities until it is ready, and then retrieves the thread ID of the publisher 
 object from the 
 shared_future
 :
  
 Listing 10.7: Using shared_future
  
  1 #include <string>
  
  2 #include <vector>
  
  3 #include <iostream>
  
  4 #define BOOST_THREAD_PROVIDES_FUTURE
  
  5 #include <boost/lexical_cast.hpp>
  
  6 #include <boost/thread.hpp>
  
  7 #include <boost/thread/future.hpp>
  
  8 #include <boost/chrono.hpp>
  
  9 
  
 10 int main() { 
  
 11   boost::promise<std::string> prom; 
  
 12   boost::future<std::string> fut(prom.get_future()); 
  
 13   boost::shared_future<std::string> shfut(std::move(fut)); 14   
 boost::thread publisher([&prom]() { 
  
 15               std::string id = 
  
 16                 boost::lexical_cast<std::string>( 
  
 17                                boost::this_thread::get_id()); 
 18               std::cout << ""Publisher thread "" << id 
  
 19                         << "" starting.\n""; 
  
 20               boost::this_thread::sleep_for( 
  
 21                                   boost::chrono::seconds(15)); 
 22               prom.set_value(id);
  
 [
  393 
 ]",NA
std::future and std::promise,"The C++11 Standard Library provides 
 std::future<>
 , 
 std::shared_future<>
 , 
 and 
 std::promise<>
  templates that are pretty much identical in behavior to their 
 Boost library counterparts. The Boost version's additional member functions are 
 experimental, but leaving those aside, they mirror their Standard Library 
 counterparts. For example, we can rewrite listing 10.5 and 10.7 by replacing the 
 following symbols in the program text:
  
 • 
  
 Replace 
 boost::thread
  with 
 std::thread
  
 • 
  
 Replace 
 boost::future
  with 
 std::future
  
 • 
  
 Replace 
 boost::promise
  with 
 std::promise
  
 • 
  
 Replace 
 boost::shared_promise
  with 
 std::shared_promise
  
 • 
  
 Replace 
 boost::chrono
  with 
 std::chrono
  
 In addition, we would need to replace the included headers 
 boost/thread.hpp
 , 
 boost/thread/future.hpp
 , and 
 boost/chrono.hpp
  with the Standard Library 
 headers 
 thread
 , 
 future
 , and 
 chrono
  respectively.
  
 In listing 10.6, we used the 
 set_exception
  member function of 
 boost::promise 
 to 
 enable passing an exception across thread boundaries. This would require some 
 changes to work with 
 std::promise
 . C++11 introduces 
 std::exception_ptr
 , a 
 special smart pointer type with shared ownership semantics that must wrap exception 
 objects so that they can be passed across functions and threads (see 
 Appendix
 , 
 C++11 
 Language Features Emulation
 ). The 
 set_exception
  member function of 
 std::promise
  takes a parameter of type 
 std::exception_ptr
  instead of a 
 std::exception
 . The following snippet shows how you would change listing 10.6 to 
 use the Standard Library:
  
  1 // include other headers
  
  2 #include <exception>
  
 ... // other code
  
 22   boost::thread reader(
  
 23                        [&promised_value, &file2]() {
  
 24                          try {
  
 25                            auto content = readFromFile(file2);
  
 26                            promised_value.set_value(content);
  
 27                          } catch (std::exception& e) {
  
 28                            promised_value.set_exception(
  
 29                                     std::current_exception());
  
 30                          }
  
 31                        });
  
 [
  395 
 ]",NA
std::packaged_task and std::async,"While threads are powerful constructs, the full generality and control that they provide 
 comes at the cost of simplicity. In a lot of cases, it works best to operate at a higher level 
 of abstraction than creating explicit threads to run tasks. The Standard Library provides 
 the 
 std::async
  function template and 
 std::packaged_task
  class template that 
 provide different levels of abstractions for creating concurrent tasks, freeing the 
 programmer from having to write a lot of boilerplate code in the process. They have 
 counterparts in the Boost library (
 boost::async
  and 
 boost::packaged_ task
 ) that 
 are incompletely implemented and less portable to use as of this writing (Boost version 
 1.57), especially in pre-C++11 environments.",NA
std::packaged_task,"The 
 std::packaged_task<>
  class template is used to create asynchronous tasks. 
 You need to explicitly create a thread that runs the task or calls the task manually 
 using the overloaded 
 operator()
  in 
 packaged_task
 . But you do not need to 
 manually set up promise-future pairs or deal with promises in any way. Here is 
 listing 10.6, rewritten using 
 std::packaged_task
 :
  
 [
  396 
 ]",NA
std::async,"The 
 std::async
  function template creates a task from a function object that can 
 potentially run concurrently in a separate thread. It returns a 
 std::future
  object, 
 which can be used to block on the task or wait for it. It is available through the Standard 
 Library header file 
 future
 . With 
 std::async
 , we no longer need to explicitly create 
 threads. Instead, we pass to 
 std::async
  the function to execute, the arguments to pass, 
 and an optional launch policy. 
 std::async
  runs the function either asynchronously in a 
 different thread or synchronously on the calling thread based on the launch policy 
 specified. Here is a simple rewrite of listing 10.5 using 
 std::async
 :
  
 Listing 10.9: Using std::async to create concurrent tasks
  
  1 #include <iostream>
  
  2 #include <thread>
  
  3 #include <future>
  
  4 #include <chrono>
  
  5 #include <ctime>
  
  6 #include <cstdlib>
  
  7
  
  8 int main()
  
  9 {
  
 10   int duration = 10 + rand() % 10;
  
 11   srand(time(0));
  
 12   std::cout << ""Main thread id=""
  
 13             << std::this_thread::get_id() << '\n';
  
 [
  398 
 ]",NA
Launch policy,"We used the launch policy 
 std::launch::async
  to indicate that we want the task to 
 run on a separate thread. This would launch the task immediately in a separate thread. 
 Using the other standard launch policy 
 std::launch::deferred
  , we can launch the 
 task lazily, when we first call 
 get
  or 
 wait
  (non-timed wait functions) on the associated 
 future object. The task would run synchronously in the thread that calls 
 get
  or 
 wait
 . 
 This also means that the task would never be launched if one used the 
 deferred
  policy 
 and did not call 
 get
  or 
 wait
 .
  
 We could not have used 
 std::launch::deferred
  in the listing 10.10. This is because we 
 wait for the future to be ready (line 28) before calling 
 get
  in the same thread (line 34). 
 The task would never be launched until we called 
 get
 , but the future could never be ready 
 unless the task was launched and returned a value; so we would spin eternally in the 
 while
  loop.
  
 While creating a task using 
 std::async
 , we may also omit the launch policy:
  
 auto future = std::async([]() {...}, arg1, arg2);
  
 In such cases, the behavior is equivalent to the following call:
  
 auto future = std::async(std::launch::async|std::launch::deferred,
  
  []() {...}, arg1, arg2);
  
 It is up to the implementation to choose the behavior conforming to either 
  
 std::launch::async
  or 
 std::launch::deferred
 . Moreover, the implementation 
 would only create a new thread if the runtime libraries needed to support 
  
 multithreading are linked to the program. With the default policy, when 
  
 multithreading is enabled, 
 std::async
  either launches new tasks in new threads or 
 posts them to an internal thread pool. If there are no free threads in the pool or free 
 cores, the tasks would be launched synchronously.",NA
Lock-based thread synchronization methods,"So far, we saw how we can delegate functions to be run on separate threads 
  
 using 
 boost::thread
  and 
 std::thread
 . We saw the use of 
 boost::future
  and 
 boost::promise
  to communicate results and exceptions between threads and to 
 impose order between tasks through blocking calls. Sometimes, you can break down 
 your program into independent tasks that can be run concurrently, producing a value, a 
 side effect, or both, which is then consumed by another part of the program. 
  
 Launching such tasks and waiting on them using futures is an effective strategy. Once 
 the tasks have returned, you can start on the next phase of computations that consume 
 the results of the first phase.
  
 [
  400 
 ]",NA
Data races and atomic operations,"Consider the following code snippet. We create two threads, and each thread 
 increments a shared integer variable a fixed number of times in a loop:
  
 int main() {
  
  int x = 0;
  
  const int max = 1000000;
  
  auto thrFunc = [&x]() {
  
  for (int i = 0; i < max; ++i) {
  
  ++x;
  
  }
  
  };
  
  boost::thread t1(thrFunc);
  
  boost::thread t2(thrFunc);
  
  t1.join();
  
  t2.join();
  
  std::cout << ""Value of x: "" << x << '\n';
  
 }
  
 What value of 
 x
  would be printed at the end of the program? Since each thread 
 increments 
 x
  a million times and there are two threads, one could expect it to be 
 2000000
 . You can verify for yourself that the increment operator is called on 
 x
  no less 
 and no more than 
 N*max
  times, where 
 N=2
  is the number of threads and 
 max
  is a 
 million. Yet I saw 
 2000000
  being printed not for once; each time it was a smaller 
 number. This behavior might vary depending on the OS and hardware, but it is 
 common enough. Clearly, some increments are not taking effect.
  
 [
  401 
 ]",NA
Mutual exclusion and critical sections,"One way to make the 
 ++x
  operation thread-safe is to perform it in a 
 critical section
 . 
  
 A critical section is a section of code that cannot be executed simultaneously by two 
 different threads. Thus, two increments of 
 x
  from different threads can be interleaved. 
 Threads must adhere to this protocol and can use a 
 mutex
  to do so. A mutex is a 
 primitive used for synchronizing concurrent access to shared resources, such as the 
 variable 
 x
 . We use the 
 boost::mutex
  class for this purpose, as shown in the following 
 example:
  
 [
  403 
 ]",NA
boost::lock_guard ,"Acquiring a lock on a mutex and failing to release it is disastrous, as any other thread 
 waiting on the mutex will never make any progress. The bare 
 lock
  / 
 try_lock
  and 
 unlock
  calls on the mutex are not a good idea, and we need some means of locking and 
 unlocking mutexes in an exception-safe way. The 
 boost::lock_guard<> 
 template uses 
 the 
 Resource Acquisition Is Initialization
  (
 RAII
 ) idiom to lock and unlock mutexes in 
 its constructor and destructor:
  
 Listing 10.11: Using boost::lock_guard
  
  1 #include <boost/thread/thread.hpp>
  
  2 #include <boost/thread/mutex.hpp>
  
  3 #include <iostream>
  
  4
  
  5 int main()
  
  6 {
  
  7   int x = 0;
  
  8   static const int max = 1000000;
  
  9   boost::mutex mtx; 
  
 10 
  
 11   auto thrFunc = [&x, &mtx]() { 
  
 12     for (int i = 0; i < max; ++i) { 
  
 13       boost::lock_guard<boost::mutex> lg(mtx); 
 14       ++x; 
  
 16     } 
  
 17   }; 
  
 18 
  
 19   boost::thread t1(thrFunc); 
  
 20   boost::thread t2(thrFunc); 
  
 21 
  
 22   t1.join();
  
 [
  406 
 ]",NA
boost::unique_lock,"The 
 boost::unique_lock<>
  template is a more flexible alternative that still uses 
 RAII to manage mutex-like locks but provides an interface to manually lock and unlock 
 as required. For this additional flexibility, 
 unique_lock
  has to maintain an additional 
 data member to keep track of whether the mutex is owned by the thread or not. We 
 can use 
 unique_lock
  to manage any class conforming to the 
 Lockable 
 concept. A 
 class conforms to the Lockable concept if it conforms to BasicLockable and 
 additionally, defines an accessible 
 try_lock
  member function—just as 
 boost::mutex
  does.
  
 [
  407 
 ]",NA
Deadlocks ,"Mutexes provide for exclusive ownership of shared resources and many 
  
 real-world problems deal with multiple shared resources. Take the case of a multiplayer 
 first-person shooting game. It maintains and updates two lists in real time. There is a set 
 A of shooters who are players with ammunition of some sort, and a second set U of 
 players that are unarmed. When a player exhausts her ammo, she is moved from A to U. 
 When her ammo is replenished, she is moved back from U to A. Thread 1 handles 
 moving elements from A to U and thread 2 handles moving elements from U to A.
  
 When a new player joins the game, she is added to either U or A, depending on 
 whether she has ammo. When a player is killed in the game, she is removed from 
 whichever set (U or A) she was part of. But when ammo is either exhausted or 
 replenished, the player is moved between U and A; so both U and A need to be edited. 
 Consider the following code in which one thread is responsible for moving players 
 from A to U when ammo is exhausted, and another thread is responsible for the 
 movement back (U to A) when ammo is replenished:
  
 Listing 10.12: Deadlock example
  
  1 #include <iostream>
  
  2 #include <cstdlib>
  
  3 #include <ctime>
  
  4 #include <set>
  
  5 #include <boost/thread.hpp>
  
  6
  
  7 struct player {
  
  8   int id;
  
  9   // other fields 
  
 10   bool operator < (const player& that) const { 
  
 11     return id < that.id; 
  
 12   } 
  
 13 }; 
  
 14 
  
 15 std::set<player> armed, unarmed; // A, U 
  
 16 boost::mutex amtx, umtx; 
  
 17 
  
 18 auto a2u = [&](int playerId) { 
  
 19         boost::lock_guard<boost::mutex> lka(amtx); 20         
 auto it = armed.find(player{playerId}); 21         if 
 (it != armed.end()) { 
  
 22           auto plyr = *it; 
  
 23           boost::unique_lock<boost::mutex> lku(umtx); 
 24           unarmed.insert(plyr);
  
 [
  409 
 ]",NA
Synchronizing on conditions,"Mutexes serialize access to shared data by creating critical sections. A critical section is 
 like a room with a lock and a waiting area outside. One thread acquires the lock and 
 occupies the room while others arrive outside, wait for the occupant to vacate the room, 
 and then take its place in some defined order. Sometimes, threads need to wait on a 
 condition becoming true, such as some shared data changing state. Let us look at the 
 producer-consumer problem to see examples of threads waiting 
  
 on conditions.",NA
Condition variables and producer-consumer problem,"The Unix command-line utility 
 grep
  searches files for text patterns specified using 
 regular expressions. It can search through a whole list of files. To search for a pattern 
 in a file, its complete contents must be read and searched for the pattern. 
  
 Depending on the number of files to search, one or more threads can be employed to 
 concurrently read contents of files into buffers. The buffers can be stored in some data 
 structure that indexes them by file and offset. Multiple threads can then process these 
 buffers and search them for the pattern.
  
 What we just described is an example of a producer-consumer problem in which a set of 
 threads generates some content and puts them in a data structure, and a second set of 
 threads reads the content off the data structure, and performs computations on it. If the 
 data structure is empty, the consumers must wait until a producer adds some content. If 
 data fills up the data structure, then the producers must wait for consumers to process 
 some data and make room in the data structure before trying to add more content. In 
 other words, consumers wait on certain conditions to fulfill and these are fulfilled as a 
 result of the actions of the producers, and vice versa.
  
 [
  412 
 ]",NA
Condition variable nuances,"We call 
 notify_one
  to signal the 
 canRead
  condition variable and wake up exactly one 
 thread waiting to read (line 39). Instead, we could have called 
 notify_all
  to 
 broadcast
  
 the event and wake up all waiting threads, and it would still have worked. However, we 
 only put one new element in the queue in each call to 
 push
 , so exactly one of the threads 
 woken up would read the new element off the queue. The other threads would check the 
 number of elements in the queue, find it empty, and go back to waiting, resulting in 
 unnecessary context switches.
  
 But if we added a load of elements to the queue, calling 
 notify_all
  might be a better 
 alternative than 
 notify_one
 . Calling 
 notify_one
  would wake up only one waiting 
 thread, which would process the elements serially in a loop (lines 63-65). Calling 
 notify_all
  would wake up all the threads, and they would process the elements 
 concurrently much quicker.
  
 One common conundrum is whether to call 
 notify_one
 /
 notify_all
  while holding the 
 mutex, as we have done in our examples earlier, or after releasing it. Both options work 
 equally well, but there might be some difference in the performance. 
  
 If you signal a condition variable while holding the mutex, the woken up threads would 
 immediately block, waiting for the mutex until you release it. So there are two additional 
 context switches per thread and these can have an impact on the performance. 
 Therefore, if you unlock the mutex first before signaling the condition variable, you 
 could see some performance benefits. Therefore, signaling 
 after 
 unlocking is the often 
 preferred approach.",NA
The Readers-Writers problem,"Take the case of an online catalog of a library. The library maintains a look-up table of 
 books. For simplicity, let us imagine that the books can only be looked up by titles, and 
 titles are unique. Multiple threads representing various clients perform look-ups on the 
 library concurrently. From time to time, the librarian adds new books to the catalog and 
 rarely, takes a book off the catalog. A new book can be added only if a book with the 
 same title is not already present, or if an older 
  
 edition of the title is present.
  
 In the following snippet, we define a type representing a book entry and the public 
 interface of the 
 LibraryCatalog
  class that represents the library catalog:
  
 [
  417 
 ]",NA
Upgradable locks,"There is one glaring problem in the implementation of 
 add_book
  and 
 remove_book 
 methods in listing 10.14b. Both methods modify the catalog conditionally, based on the 
 outcome of a look-up that is run first. Yet an exclusive lock is acquired unconditionally at 
 the start of both operations. One could conceivably call 
 remove_book
  with a nonexistent 
 title or 
 add_book
  with an edition of a book that is already in the catalog, in a loop, and 
 seriously hamper the concurrency of the system doing nothing.
  
 If we acquired a shared lock to perform the look up, we would have to release it before 
 acquiring an exclusive lock for modifying the catalog. In this case, the results of the 
 look up would no longer be reliable, as some other thread could have modified the 
 catalog between the time the shared lock is released and the exclusive lock acquired.
  
 This problem can be addressed by using 
 boost::upgrade_lock
  and a set of 
 associated primitives. This is shown in the following rewrite of 
 add_book
 :
  
  1 bool LibraryCatalog::add_book(const book_t& book) {
  
  2   boost::upgrade_lock<boost::shared_mutex> upglock(mtx);
  
  3   auto it = catalog.find(book.title);
  
  4
  
  5   if (it == catalog.end()) {
  
  6     boost::upgrade_to_unique_lock<boost::shared_mutex> 
  
  7                                             ulock(upglock);
  
  8     catalog[book.title] = book;
  
  9     return true;
  
 10   } else if (it->second.edition > book.edition) {
  
 11     boost::upgrade_to_unique_lock<boost::shared_mutex> 
  
 12                                             ulock(upglock);
  
 [
  421 
 ]",NA
Performance of shared_mutex,"boost::shared_mutex
  is slower than 
 boost::mutex
  but acquiring additional read 
 locks on an already read-locked mutex is much faster. It is ideally suited for frequent 
 concurrent reads with infrequent need for exclusive write access. Any time you deal 
 with frequent writes, just use 
 boost::mutex
  to provide exclusive write access.
  
 Most solutions to the MRSW problem either prefer readers over writers or the other way 
 round. In 
 read-preferring solutions
 , when a shared lock is in effect, new reader threads 
 can acquire a shared lock even with a writer waiting to acquire an exclusive lock. This 
 leads to write-starvation as the writer only ever gets an exclusive lock at a point when no 
 readers are around. In 
 write-preferring solutions
 , if there is a writer thread waiting on 
 an exclusive lock, then new readers are queued even if existing readers hold a shared lock. 
 This impacts the concurrency of reads. Boost 1.57 (current release) provides a 
 shared/exclusive lock implementation that is completely fair and does not have either a 
 reader- or a writer-bias.
  
 [
  422 
 ]",NA
Standard Library primitives,"The C++11 Standard Library introduces 
 std::mutex
  and a whole host of RAII wrappers 
 for locks, including 
 std::lock_guard
 , 
 std::unique_lock
 , and 
  
 std::lock
 , available in the header 
 mutex
 . C++11 Standard Library also introduces 
 std::condition_variable
  available in the header 
 condition_variable
 . The C++14 
 Standard Library introduces 
 std::shared_timed_mutex
 , which corresponds to 
 boost::shared_mutex
  and 
 std::shared_lock
 , both available in the header 
 mutex
 . 
  
 They correspond to their Boost counterparts of the same names, and have very 
 similar interfaces. There is no upgrade lock facility in the Standard Library as of 
 C++14, nor any equivalent of the convenient 
 boost::thread_group
 .",NA
Boost Coroutine,"Coroutines are functions that can 
 yield
  or relinquish control to another coroutine, and 
 then given control back, resuming from the point at which they earlier yielded. The state 
 of automatic variables is maintained between a yield and the resumption. Coroutines 
 can be used for complex control flow patterns with surprisingly simple and clean code. 
 The Boost Coroutine library provides two types of coroutines:
  
 • 
  
 • 
  
 Asymmetric coroutines
 : Asymmetric coroutines distinguish between a caller 
 and a callee coroutine. With asymmetric coroutines, a callee can only yield back 
 to the caller. They are often used for unidirectional data transfer from either the 
 callee to caller, or the other way.
  
 Symmetric coroutines
 : Such coroutines can 
 yield
  to other coroutines, 
 irrespective of who the caller was. They can be used to generate complex 
 cooperative chains of coroutines.
  
 When a coroutine yields control, it is said to be suspended—its registers are saved and 
 it relinquishes control to another function. On resumption, the registers are restored 
 and execution continues beyond the point of yield. The Boost Coroutine library utilizes 
 the Boost Context library for this purpose.
  
 A distinction is made between 
 stackful coroutines
  versus 
 stackless coroutines
 . A stackful 
 coroutine can be suspended from within a function called by the coroutine, that is, from a 
 nested stackframe. With stackless coroutines, only the top level routine may suspend 
 itself. In this chapter, we only look at asymmetric stackful coroutines.
  
 [
  423 
 ]",NA
Asymmetric coroutines ,"The core template used to define asymmetric coroutines is called 
  
 boost::coroutines::asymmetric_coroutine<>
 . It takes a single type parameter that 
 represents the type of value transferred from one coroutine to the other. It can be 
 void
  if 
 no value needs to be transferred.
  
 Coroutines that call other coroutines or yield to them must have a way to refer to other 
 coroutines. The nested type 
 asymmetric_coroutine<T>::push_type 
 represents a 
 coroutine that provides data of type 
 T
 , and the nested type 
 asymmetric_ 
 coroutine<T>::pull_type
  represents a coroutine that consumes the data of type 
 T
 . 
 Both the types are callable types, with an overloaded 
 operator()
 . Using these types, we 
 shall now write a program that uses coroutines to read data from a vector of elements:
  
 Listing 10.15: Using asymmetric coroutines
  
  1 #include <iostream>
  
  2 #include <boost/coroutine/all.hpp>
  
  3 #include <boost/bind.hpp>
  
  4 #include <vector>
  
  5 #include <string>
  
  6
  
  7 template <typename T>
  
  8 using pull_type = typename
  
  9   boost::coroutines::asymmetric_coroutine<T>::pull_type; 
 10 
  
 11 template <typename T> 
  
 12 using push_type = typename 
  
 13   boost::coroutines::asymmetric_coroutine<T>::push_type; 
 14 
  
 15 template <typename T> 
  
 16 void getNextElem(push_type<T>& sink, 
  
 17                  const std::vector<T>& vec) 
  
 18 { 
  
 19   for (const auto& elem: vec) { 
  
 20     sink(elem); 
  
 21   } 
  
 22 } 
  
 23 
  
 24 int main() 
  
 25 { 
  
 26   std::vector<std::string> vec{""hello"", ""hi"", ""hola"", 27                               
 ""servus""}; 
  
 28   pull_type<std::string> greet_func(
  
 [
  424 
 ]",NA
Self-test questions,"For multiple choice questions, choose all options that apply:
  
 1. What happens if you do not call 
 join
  or 
 detach
  on a 
 boost::thread 
  
 object and a 
 std::thread
  object?
  
 a. 
 join
  is called on underlying thread of 
 boost::thread
 .
  
 b. 
 std::terminate
  is called for 
 std::thread
 , terminating the program.
  
 c. 
 detach
  is called on underlying thread of 
 boost::thread
 .
  
 d. 
 detach
  is called on underlying thread of 
 std::thread
 .
  
 2. What happens if an exception is allowed to propagate past the initial 
  
 function with which a 
 boost::thread
  object is created?
  
 a. The program is terminated via 
 std::terminate
 .
  
 b. It is undefined behavior.
  
 c. The call to 
 get
  on the 
 future
  object throws an exception in the 
  
  calling thread.
  
 d. The thread is terminated but the exception is not propagated.
  
 3. Should you call 
 notify_one
  or 
 notify_all
  on a 
 condition_variable 
  
 object without holding the associated mutex?
  
 a. No, the call will block.
  
 b. Yes, but it may result in priority inversion in some cases.
  
 c. No, some waiting threads may miss the signal.
  
 d. Yes, it may even be faster.
  
 [
  426 
 ]",NA
Summary,"In this chapter, we looked at how to write concurrent logic in terms of threads and 
 tasks using the Boost Thread library and the C++11 Standard Library. We learned how 
 to use the futures and promises paradigm to define ordering of operations across 
 concurrent tasks, and some abstractions around futures and promises in the Standard 
 Library. We also studied various lock-based thread synchronization primitives and 
 applied them to some common multithreading problems.
  
 Multithreading is a difficult and complex topic, and this chapter merely introduces the 
 portable APIs available in Boost to write concurrent programs. The Boost Thread library 
 and the concurrent programming interfaces in the C++ Standard Library are an evolving 
 set, and we did not cover several features: the C++ memory model and atomics, Boost 
 Lockfree, thread cancellation, experimental continuations with 
 boost::future
 s, and 
 several more topics. Architectural concerns in designing concurrent systems and 
 concurrent data structures are other relevant topics that are outside the scope of this 
 book. Hopefully, the concepts and methods presented in this chapter will help you 
 explore further in these directions.
  
 [
  427 
 ]",NA
References,"• 
  
 • 
  
 • 
  
 C++ Concurrency in Action
 , 
 Anthony Williams
 , 
 Manning Publications 
  
 Lockfree data structures: 
 http://www.boost.org/libs/lockfree 
  
 A proposal to add coroutines to the C++ standard library (Revision 1)
 , 
 Oliver 
 Kowalke
  and 
 Nat Goodspeed
 : 
 http://www.open-
 std.org/jtc1/sc22/wg21/
  
 docs/papers/2014/n3985.pdf
  
 • 
  
 Lock-Free Programming, Herb Sutter: 
 https://youtu.be/c1gO9aB9nbs
  
 • 
  
 atomic<> Weapons (video), Herb Sutter:
  
 °
  
 https://channel9.msdn.com/Shows/Going+Deep/Cpp-and-
  
 Beyond-2012-Herb-Sutter-atomic-Weapons-1-of-2
  
 °
  
 https://channel9.msdn.com/Shows/Going+Deep/Cpp-and-
  
 Beyond-2012-Herb-Sutter-atomic-Weapons-2-of-2
  
 [
  428 
 ]",NA
Network Programming ,NA,NA
Using Boost Asio,"In today's networked world, Internet servers handling thousands of requests per second 
 have a tough mandate to fulfill—of maintaining responsiveness and not slowing down 
 even with increasing volumes of requests. Building reliable processes that efficiently 
 handle network I/O and scale with the number of connections is challenging because it 
 often requires the application programmer to understand the underlying protocol stack 
 and exploit it in ingenious ways. What adds to the challenge is the variance in the 
 programming interfaces and models for network programming across platforms, and 
 the inherent difficulties of using low-level APIs.
  
 Boost Asio (pronounced ay-see-oh) is a portable library for performing efficient network 
 I/O using a consistent programming model. The emphasis is on performing asynchronous 
 I/O (hence the name Asio), where the program initiates I/O 
  
 operations and gets on with its other jobs, without blocking for the OS to return with the 
 results of the operation. When the operation is complete in the underlying OS, the 
 program is notified by the Asio library and takes an appropriate action. The problems 
 Asio helps solve and the consistent, portable interfaces it uses to do so, make Asio 
 compellingly useful. But the asynchronous nature of interactions also makes it more 
 complex and less straightforward to reason about. This is the reason we will study Asio in 
 two parts: to first understand its interaction model and then use it to perform network 
 I/O:
  
 • 
  
 Task execution with Asio
  
 • 
  
 Network programming using Asio
  
 [
  429 
 ]",NA
Task execution with Asio ,"At its core, Boost Asio provides a task execution framework that you can use to 
 perform operations of any kind. You create your tasks as function objects and post 
 them to a task queue maintained by Boost Asio. You enlist one or more threads to pick 
 these tasks (function objects) and invoke them. The threads keep picking up tasks, one 
 after the other till the task queues are empty at which point the threads do not block 
 but exit.",NA
"IO Service, queues, and handlers ","At the heart of Asio is the type 
 boost::asio::io_service
 . A program uses the 
 io_service
  interface to perform network I/O and manage tasks. Any program that 
 wants to use the Asio library creates at least one instance of 
 io_service
  and 
 sometimes more than one. In this section, we will explore the task management 
 capabilities of 
 io_service
 , and defer the discussion of network I/O to the latter half 
 of the chapter.
  
 Here is the IO Service in action using the obligatory ""hello world"" example:
  
 Listing 11.1: Asio Hello World
  
  1 #include <boost/asio.hpp>
  
  2 #include <iostream>
  
  3 namespace asio = boost::asio;
  
  4
  
  5 int main() {
  
  6   asio::io_service service;
  
  7
  
  8   service.post(
  
  9     [] { 
  
 10       std::cout << ""Hello, world!"" << 
 '\n'; 11     }); 
  
 12 
  
 13   std::cout << ""Greetings: \n""; 
  
 14   service.run(); 
  
 15 }
  
 [
  430 
 ]",NA
"Handler states – run_one, poll, and poll_one","While the 
 run
  function blocks until there are no more handlers in the queue, there are 
 other member functions of 
 io_service
  that let you process handlers with greater 
 flexibility. But before we look at this function, we need to distinguish between pending 
 and ready handlers.
  
 The handlers we posted to the 
 io_service
  were all ready to run immediately and were 
 invoked as soon as their turn came on the queue. In general, handlers are associated 
 with background tasks that run in the underlying OS, for example, network I/O tasks. 
 Such handlers are meant to be invoked only once the associated task is completed, 
 which is why in such contexts, they are called 
 completion handlers
 . These handlers are 
 said to be 
 pending
  until the associated task is awaiting completion, and once the 
 associated task completes, they are said to be 
 ready
 .
  
 The 
 poll
  member function, unlike 
 run
 , dispatches all the ready handlers but does not 
 wait for any pending handler to become ready. Thus, it returns immediately if there 
 are no ready handlers, even if there are pending handlers. The 
 poll_one 
 member 
 function dispatches exactly one ready handler if there be one, but does not block 
 waiting for pending handlers to get ready.
  
 The 
 run_one
  member function blocks on a nonempty queue waiting for a handler to 
 become ready. It returns when called on an empty queue, and otherwise, as soon as it 
 finds and dispatches a ready handler.",NA
post versus dispatch,"A call to the 
 post
  member function adds a handler to the task queue and returns 
 immediately. A later call to 
 run
  is responsible for dispatching the handler. There is 
 another member function called 
 dispatch
  that can be used to request the 
 io_ 
 service
  to invoke a handler immediately if possible. If 
 dispatch
  is invoked in a thread 
 that has already called one of 
 run
 , 
 poll
 , 
 run_one
 , or 
 poll_one
 , then the handler will be 
 invoked immediately. If no such thread is available, 
 dispatch
  adds the handler to the 
 queue and returns just like 
 post
  would. In the following example, we invoke 
 dispatch
  
 from the 
 main
  function and from within another handler:
  
 Listing 11.2: post versus dispatch
  
  1 #include <boost/asio.hpp>
  
  2 #include <iostream>
  
  3 namespace asio = boost::asio;
  
  4
  
  5 int main() {
  
 [
  432 
 ]",NA
Concurrent execution via thread pools ,"The 
 io_service
  object is thread-safe and multiple threads can call 
 run
  on it 
  
 concurrently. If there are multiple handlers in the queue, they can be processed 
 concurrently by such threads. In effect, the set of threads that call 
 run
  on a given 
 io_service
  form a 
 thread pool
 . Successive handlers can be processed by different 
 threads in the pool. Which thread dispatches a given handler is indeterminate, so the 
 handler code should not make any such assumptions. In the following example, we post a 
 bunch of handlers to the 
 io_service
  and then start four threads, which all call 
 run
  on it:
  
 Listing 11.3: Simple thread pools
  
  1 #include <boost/asio.hpp>
  
  2 #include <boost/thread.hpp>
  
  3 #include <boost/date_time.hpp>
  
  4 #include <iostream>
  
  5 namespace asio = boost::asio;
  
  6
  
  7 #define PRINT_ARGS(msg) do {\
  
  8   boost::lock_guard<boost::mutex> lg(mtx); \
  
  9   std::cout << '[' << boost::this_thread::get_id() \ 
  
 10             << ""] "" << msg << std::endl; \ 
  
 11 } while (0) 
  
 12 
  
 13 int main() { 
  
 14   asio::io_service service; 
  
 15   boost::mutex mtx; 
  
 16 
  
 17   for (int i = 0; i < 20; ++i) { 
  
 18     service.post([i, &mtx]() { 
  
 19                          PRINT_ARGS(""Handler["" << i << ""]""); 
 20                          boost::this_thread::sleep(
  
 [
  434 
 ]",NA
io_service::work ,"Sometimes, it is useful to keep the thread pool started, even when there are no handlers 
 to dispatch. Neither 
 run
  nor 
 run_one
  blocks on an empty queue. So in order for them to 
 block waiting for a task, we have to indicate, in some way, that there is outstanding 
 work to be performed. We do this by creating an instance of 
 io_ service::work
 , as 
 shown in the following example:
  
 Listing 11.4: Using io_service::work to keep threads engaged
  
  1 #include <boost/asio.hpp>
  
  2 #include <memory>
  
  3 #include <boost/thread.hpp>
  
  4 #include <iostream>
  
  5 namespace asio = boost::asio;
  
  6
  
  7 typedef std::unique_ptr<asio::io_service::work> work_ptr; 
 8
  
  9 #define PRINT_ARGS(msg) do {\ … 
  
 ...
  
 14 
  
 15 int main() { 
  
 16   asio::io_service service; 
  
 17   // keep the workers occupied 
  
 18   work_ptr work(new asio::io_service::work(service)); 
  
 19   boost::mutex mtx; 
  
 20 
  
 21   // set up the worker threads in a thread group 
  
 22   boost::thread_group workers; 
  
 23   for (int i = 0; i < 3; ++i) { 
  
 24     workers.create_thread([&service, &mtx]() { 
  
 25                          PRINT_ARGS(""Starting worker thread 
 ""); 26                          service.run(); 
  
 27                          PRINT_ARGS(""Worker thread done""); 28                        
 }); 
  
 29   }
  
 [
  436 
 ]",NA
Serialized and ordered execution via strands,"Thread pools allow handlers to be run concurrently. This means that handlers that 
 access shared resources need to synchronize access to these resources. We already saw 
 examples of this in listings 11.3 and 11.4, when we synchronized access to 
 std::cout
 , 
 which is a global object. As an alternative to writing synchronization code in handlers, 
 which can make the handler code more complex, we can use 
 strands
 .
  
  
 Think of a strand as a subsequence of the task queue with the constraint 
  
  
 that no two handlers from the same strand ever run concurrently.
  
 [
  437 
 ]",NA
Network I/O using Asio,"We want to use Asio to build scalable network services that perform I/O over the 
 network. Such services receive requests from clients running on remote machines and 
 send them information over the network. The data transfer between processes across 
 machine boundaries, happening over the wire, is done using certain protocols of network 
 communication. The most ubiquitous of these protocols is IP or the 
 Internet Protocol
  
 and a 
 suite of protocols
  layered above it. Boost Asio supports TCP, UDP, and ICMP, the 
 three popular protocols in the IP protocol suite. We do not cover ICMP in this book.",NA
UDP and TCP,"User Datagram Protocol
  or UDP is used to transmit 
 datagrams
  or message units from 
 one host to another over an IP network. UDP is a very basic protocol built over IP and is 
 stateless in the sense that no context is maintained across multiple network I/O 
 operations. The reliability of data transfer using UDP depends on the reliability of the 
 underlying network, and UDP transfers have the following caveats:
  
 • 
  
 • 
  
 • 
  
 • 
  
 A UDP datagram may not be delivered at all 
  
 A given datagram may be delivered more than once 
  
 Two datagrams may not be delivered to the destination in the order in 
 which they were dispatched from the source 
  
 UDP will detect any data corruption in the datagrams and drop such 
 messages without any means of recovery
  
 For these reasons, UDP is considered to be an unreliable protocol.
  
 If an application requires stronger guarantees from the protocol, we choose 
  
 Transmission Control Protocol 
 or TCP. TCP deals in terms of byte streams rather than 
 messages. It uses a handshake mechanism between two endpoints of the network 
 communication to establish a durable 
 connection
  between the two points and 
 maintains state during the life of the connection. All communications between the two 
 endpoints happen over such a connection. At the cost of a somewhat higher latency than 
 UDP, TCP guarantees the following:
  
 • 
  
 • 
  
 On a given connection, the receiving application receives the stream of bytes 
 sent by the sender in the order they were sent
  
 Any data lost or corrupted on the wire can be retransmitted, greatly 
 improving the reliability of deliveries
  
 [
  441 
 ]",NA
IP addresses,"IP addresses are numeric identifiers used to uniquely identify interfaces connected to an 
 IP network. The older IPv4 protocol uses 32-bit IP addresses in an address space of 4 
 billion (2
 32
 ) addresses. The emergent IPv6 protocol uses 128-bit IP addresses in an 
 address space of 3.4 × 10
 38
  (2
 128
 ) unique addresses, which is practically 
  
 inexhaustible. You can represent IP addresses of both types using the class 
  
 boost::asio::ip::address
 , while version-specific addresses can be represented using 
 boost::asio::ip::address_v4
  and 
 boost::asio::ip::address_v6
 .",NA
IPv4 addresses,"The familiar IPv4 addresses, such as 212.54.84.93, are 32-bit unsigned integers 
 expressed in the 
 dotted-quad notation
 ; four 8-bit unsigned integers or 
 octets 
  
 representing the four bytes in the address, the most significant on the left to the least 
 significant on the right, separated by dots (period signs). Each octet can range from 0 
 through 255. IP addresses are normally interpreted in network byte order, that is, Big-
 endian.",NA
Subnets,"Larger computer networks are often divided into logical parts called 
 subnets
 . 
  
 A subnet consists of a set of nodes that can communicate with each other using 
 broadcast messages. A subnet has an associated pool of IP addresses that have a 
 common prefix, usually, called the 
 routing prefix
  or 
 network address
 . The remaining 
 part of the IP address field is called the 
 host part
 .
  
 Given an IP address 
 and
  the length of the prefix, we can compute the prefix using the 
 netmask
 . The netmask of a subnet is a 4-byte bitmask, whose bitwise-AND with an IP 
 address in the subnet yields the routing prefix. For a subnet with a routing prefix of length 
 N, the netmask has the most significant N bits set and the remaining 32-N bits unset. The 
 netmask is often expressed in a dotted-quad notation. For example, if the address 
 172.31.198.12 has a routing prefix that is 16 bits long, then its netmask would be 
 255.255.0.0 and the routing prefix would be 172.31.0.0.
  
 [
  442 
 ]",NA
Special addresses,"Some IPv4 addresses have special meanings. For example, an IP address with all bits set 
 in the host part is known as the 
 broadcast address
  for the subnet and is used to 
 broadcast messages to all hosts in the subnet. For example, the broadcast address in the 
 network 172.31.0.0/16 is 172.31.255.255.
  
 Applications listening for incoming requests use the 
 unspecified address
  0.0.0.0 
 (
 INADDR_ANY
 ) to listen on all available network interfaces, without the need to know 
 addresses plumbed on the system.
  
 The 
 loopback address
  127.0.0.1 is commonly associated with a virtual network interface 
 that is not associated with any hardware and does not require the host to be connected to 
 a network. Data sent over the loopback interface immediately shows up as received data 
 on the sender host itself. Often used for testing networked applications within a box, you 
 can configure additional loopback interfaces and associate loopback addresses from the 
 range 127.0.0.0 through 127.255.255.255.",NA
Handling IPv4 addresses with Boost,"Let us now look at a code example of constructing IPv4 addresses and glean useful 
 information from them, using the type 
 boost::asio::ip::address_v4
 :
  
 Listing 11.6: Handling IPv4 addresses
  
  1 #include <boost/asio.hpp>
  
  2 #include <iostream>
  
 [
  443 
 ]",NA
IPv6 addresses,"In its most general form, an IPv6 address is represented as a sequence of eight 
  
 2-byte unsigned hexadecimal integers, separated by colons. Digits 
 a
  through 
 f
  in the 
 hexadecimal integers are written in lowercase by convention and leading zeros in each 
 16-bit number are omitted. Here is an example of an IPv6 address in this notation:
  
 2001:0c2f:003a:01e0:0000:0000:0000:002a
  
 One sequence of two or more zero terms can be collapsed completely. Thus, the 
 preceding address can be written as 2001:c2f:3a:1e0::2a. All leading zeros have been 
 removed and the contiguous zero terms between bytes 16 and 63 have been 
 collapsed, leaving the colon pair (::). If there be multiple zero-term sequences, the 
 longest one is collapsed, and if there is a tie, the one that is leftmost is collapsed. 
  
 Thus, we can abbreviate this 2001:0000:0000:01e0:0000:0000:001a:002a to this 
 2001::1e0:0:0:1a:2a. Note that the leftmost sequence of two zero-terms is collapsed, 
 while the other between bits 32 and 63 are not collapsed.
  
 [
  445 
 ]",NA
"Address classes, scopes, and subnets","There are three classes of IPv6 addresses:
  
 • 
  
 • 
  
 • 
  
 Unicast addresses
 : These addresses identify a single network interface
  
 Multicast addresses
 : These addresses identify a group of network interfaces 
 and are used to send data to all the interfaces in the group
  
 Anycast addresses
 : These addresses identify a group of network interfaces, but 
 data sent to an 
 anycast
  address is delivered to one or more interfaces that are 
 topologically closest to the sender and not to all the interfaces in the group
  
 In unicast and anycast addresses, the least significant 64-bits of the address represent the 
 host ID. In general, the higher order 64-bits represent the network prefix.
  
 Each IPv6 address also has a 
 scope
 , which identifies the segment of the network in 
 which it is valid:
  
 • 
  
 • 
  
 • 
  
 Node-local
  addresses, including loopback addresses are used for 
 communication within the node.
  
 Global
  addresses are routable addresses reachable across networks.
  
 Link-local
  addresses are automatically assigned to each and every IPv6-enabled 
 interface and are accessible only within a network, that is, routers do not route 
 traffic headed for link-local addresses. Link-local addresses are assigned to 
 interfaces even when they have routable addresses. Link-local addresses have a 
 prefix of fe80::/64.",NA
Special addresses,"The IPv6 
 loopback address
  analogous to 127.0.0.1 in IPv4 is ::1. The 
 unspecified 
 address
  (all zeros) in IPv6 is written as :: (
 in6addr_any
 ). There are no broadcast 
 addresses in IPv6, and multicast addresses are used to define groups of recipient 
 interfaces, a topic that is outside the scope of this book.
  
 [
  446 
 ]",NA
Handling IPv6 addresses with Boost ,"In the following example, we construct IPv6 addresses and query properties of these 
 addresses using the 
 boost::asio::ip::address_v6
  class:
  
 Listing 11.7: Handling IPv6 addresses
  
  1 #include <boost/asio.hpp>
  
  2 #include <iostream>
  
  3 #include <vector>
  
  4 namespace asio = boost::asio;
  
  5 namespace sys = boost::system;
  
  6 using namespace asio::ip;
  
  7
  
  8 void printAddr6Properties(const address_v6& addr) {
  
  9   if (addr.is_v4_mapped()) { std::cout << ""is v4-mapped, ""; } 
 10   else { 
  
 11     if (addr.is_link_local()) { std::cout << ""is link local"";} 
 12   } 
  
 13 } 
  
 14 
  
 15 void printAddrProperties(const address& addr) { ... } 
  
 16 
  
 17 int main() { 
  
 18   sys::error_code ec; 
  
 19   std::vector<address> addresses; 
  
 20   std::vector<const char*> addr_strings{""::1"", ""::"", 
  
 21     ""fe80::20"", ""::ffff:223.18.221.9"", ""2001::1e0:0:0:1a:2a""}; 
 22 
  
 23   for (const auto& v6str: addr_strings) { 
  
 24     address addr = address_v6::from_string(v6str, ec); 
  
 25     if (!ec) { addresses.push_back(addr); } 
  
 26   } 
  
 27 
  
 28   for (const auto& addr : addresses) { 
  
 29     printAddrProperties(addr); 
  
 30   } 
  
 31 }
  
 This example augments listing 11.6 with IPv6-specific checks. The function 
  
 printAddrProperties
  (line 15) is the same as that from listing 11.6, so it is not 
 repeated in full. The 
 printAddr6Properties
  function (line 8) checks whether the 
 address is an IPv4-mapped IPv6 address (line 9) and whether it is a link-local address 
 (line 11). Other relevant checks are already performed through version-agnostic 
 members of 
 address
  in 
 printAddrProperties
  (see listing 11.6).
  
 [
  447 
 ]",NA
"Endpoints, sockets, and name resolution","Applications 
 bind
  to IP addresses when providing network services, and multiple 
 applications initiate outbound communication with other applications, starting from an 
 IP address. Multiple applications can bind to the same IP address using different 
 ports
 . 
 A port is an unsigned 16-bit integer which, along with the IP address and protocol (TCP, 
 UDP, etc.), uniquely identifies a communication 
 endpoint
 . Data communication happens 
 between two such endpoints. Boost Asio provides distinct endpoint types for UDP and 
 TCP, namely, 
 boost::asio::ip::udp::endpoint
  and 
 boost::asio::ip::tcp::endpoint
 .",NA
Ports,"Many standard and widely used network services use fixed, well-known ports. 
  
 Ports 0 through 1023 are assigned to well-known system services, including the likes of 
 FTP, SSH, telnet, SMTP, DNS, HTTP, and HTTPS. Widely used applications may register 
 standard ports between 1024 and 49151 with the 
 Internet Assigned Numbers 
 Authority
  (
 IANA
 ). Ports above 49151 can be used by any application, without the need 
 for registration. The mapping of well-known ports to services is often maintained on a 
 disk file, such as 
 /etc/services
  on POSIX systems and 
 %SYSTEMROOT%\system32\drivers\etc\services
  on Windows.",NA
Sockets,"A 
 socket
  represents an endpoint in use for network communication. It represents one 
 end of a communication channel and provides the interface for performing all data 
 communication. Boost Asio provides distinct socket types for UDP and TCP, namely, 
 boost::asio::ip::udp::socket
  and 
 boost::asio::ip::tcp::socket
 . 
  
 Sockets are always associated with a corresponding local endpoint object. The native 
 network programming interfaces on all modern operating systems use some derivative of 
 the Berkeley Sockets API, which is a C API for performing network communications. The 
 Boost Asio library provides type-safe abstractions built around this core API.
  
 [
  448 
 ]",NA
Hostnames and domain names,"Identifying hosts in a network by names rather than numeric addresses is often more 
 convenient. The Domain Name System (DNS) provides a hierarchical naming system in 
 which hosts in a network are each identified by a hostname qualified with a unique 
 name identifying the network, known as the 
 fully-qualified domain name 
 or simply 
 domain name
 . For example, the imaginary domain name 
 elan.taliesyn. org
  could 
 be mapped to the IP address 140.82.168.29. Here, 
 elan
  would identify the specific host 
 and 
 taliesyn.org
  would identify the domain that the host is part of. It is quite possible 
 for different groups of machines in a single network to report to different domains and 
 even for a given machine to be part of multiple domains.",NA
Name resolution,"A hierarchy of DNS servers across the world, and within private networks, maintain 
 name-to-address mappings. Applications ask a configured DNS server to resolve a fully-
 qualified domain name to an address. The DNS server either resolves the request to an 
 IP address or forwards it to another DNS server higher up in the hierarchy if there is 
 one. The resolution fails if none of the DNS servers, all the way up to the root of the 
 hierarchy, has an answer. A specialized program or a library that initiates such name 
 resolution requests is called a 
 resolver
 . Boost Asio provides protocol-specific resolvers: 
 boost::asio::ip::tcp::resolver
  and 
 boost::asio::ip::udp::resolver
  for 
 performing such name resolutions. We query for services on hostnames and obtain one 
 or more endpoints for that service. The following example shows how to do this, given a 
 hostname, and optionally, a service name or port:
  
 Listing 11.8: Looking up IP addresses of hosts
  
  1 #include <boost/asio.hpp>
  
  2 #include <iostream>
  
  3 namespace asio = boost::asio;
  
 [
  449 
 ]",NA
Buffers ,"Data is sent or received over the network as a byte stream. A contiguous byte stream 
 can be represented using a pair of values: the starting address of the sequence and the 
 number of bytes in the sequence. Boost Asio provides two abstractions for such 
 sequences, 
 boost::asio::const_buffer
  and 
 boost::asio::mutable_buffer
 . The 
 const_buffer
  type represents a read-only sequence that is typically used as a data 
 source when sending data over the network. The 
 mutable_buffer
  represents a read-
 write sequence that is used when you need to add or update data in your buffer, for 
 example, when you receive data from a remote host:
  
 Listing 11.10: Using const_buffer and mutable_buffer
  
  1 #include <boost/asio.hpp>
  
  2 #include <iostream>
  
  3 #include <cassert>
  
  4 namespace asio = boost::asio;
  
  5
  
  6 int main() {
  
  7   char buf[10];
  
  8   asio::mutable_buffer mbuf(buf, sizeof(buf));
  
  9   asio::const_buffer cbuf(buf, 5); 
  
 10 
  
 11   std::cout << buffer_size(mbuf) << '\n'; 
  
 12   std::cout << buffer_size(cbuf) << '\n'; 
  
 13 
  
 14   char *mptr = asio::buffer_cast<char*>(mbuf); 
  
 15   const char *cptr = asio::buffer_cast<const char*>(cbuf); 
 16   assert(mptr == cptr && cptr == buf); 
  
 17 
  
 18   size_t offset = 5; 
  
 19   asio::mutable_buffer mbuf2 = mbuf + offset; 
  
 20   assert(asio::buffer_cast<char*>(mbuf2) 
  
 21         - asio::buffer_cast<char*>(mbuf) == offset); 
  
 22   assert(buffer_size(mbuf2) == buffer_size(mbuf) - 
 offset); 23 }
  
 In this example, we show how a char array is wrapped in a 
 mutable_buffer
  and a 
 const_buffer
  (lines 8-9). While constructing a buffer, you specify the starting 
 address of the memory region and the length of the region in number of bytes. A 
 const 
 char
  array can only be wrapped in a 
 const_buffer
 , not in a 
 mutable_ buffer
 . 
 These buffer wrappers 
 do not
  allocate storage, manage any heap-allocated memory, or 
 perform any data copying.
  
 [
  452 
 ]",NA
Buffer sequences for vectored I/O,"Sometimes, it is convenient to send data from a series of buffers or split the received 
 data across a series of buffers. Calling network I/O functions once per sequence would 
 be inefficient, because these calls ultimately translate to system calls and there is an 
 overhead in making each such call. An alternative is to use network I/O functions that 
 can process a 
 sequence of buffers
  passed to it as an argument. This is often called 
 vectored I/O
  or 
 gather-scatter I/O
 . All of Boost Asio's I/O functions deal in buffer 
 sequences, and so they must be passed buffer sequences rather than single buffers. A 
 valid buffer sequence for use with Asio I/O functions satisfies the following conditions:
  
 • 
  
 • 
  
 • 
  
 Has a member function 
 begin
  that returns a bidirectional iterator, which 
 points to a 
 mutable_buffer
  or 
 const_buffer
  
 Has a member function 
 end
  that returns an iterator pointing to the end of the 
 sequence
  
 Is copyable
  
 For a buffer sequence to be useful, it must either be a sequence of 
 const_buffer
 s or a 
 sequence of 
 mutable_buffer
 s. Formally, these requirements are summarized in the 
 ConstBufferSequence
  and 
 MutableBufferSequence
  concepts. This is a slightly 
 simplified set of conditions, but is good enough for our purposes. We can make such 
 sequences using Standard Library containers, such as 
 std::vector
 , 
 std::list
 , and so 
 on, as well as Boost containers. However, since we frequently deal with only a single 
 buffer, Boost provides the 
 boost::asio::buffer
  function that makes it easy to adapt a 
 single buffer as a buffer sequence of length one. Here is a short example illustrating 
 these ideas:
  
 [
  453 
 ]",NA
Synchronous and asynchronous ,NA,NA
communications,"In the following sections, we put together our understanding of IP addresses, endpoints, 
 sockets, buffers, and other Asio infrastructure we learned so far to write network client 
 and server programs. Our examples use the 
 client-server model 
 of interaction, in 
 which a 
 server
  program services incoming requests, and a 
 client 
 program initiates such 
 requests. Such clients are referred to as the 
 active endpoints
 , while such servers are 
 referred to as 
 passive endpoints
 .
  
 Clients and servers may communicate 
 synchronously
 , blocking on each network I/O 
 operation until the request has been handled by the underlying OS, and only then 
 proceeding to the next step. Alternatively, they can use 
 asynchronous I/O
 , initiating 
 network I/O without waiting for them to complete, and being notified later upon their 
 completion. With asynchronous I/O, unlike the synchronous case, programs do not wait 
 idly if there are I/O operations to perform. Thus, asynchronous I/O scales better with 
 larger numbers of peers and higher volumes of data. We will look at both synchronous 
 and asynchronous models of communication. While the programming model for 
 asynchronous interactions is event-driven and more complex, the use of Boost Asio 
 coroutines can keep it very manageable. Before we write UDP and TCP servers, we will 
 take a look at the Asio deadline timer to understand how we write synchronous and 
 asynchronous logic using Asio.",NA
Asio deadline timer,"Asio provides the 
 basic_deadline_timer
  template, using which you can wait for 
 a specific duration to elapse or for an absolute time point. The specialization 
 deadline_timer
  is defined as:
  
 typedef basic_deadline_timer<boost::posix_time::ptime> 
  
  deadline_timer;
  
 It uses 
 boost::posix_time::ptime
  and 
 boost::posix_time::time_duration
  as the 
 time point and duration type respectively. The following example illustrates how an 
 application can use 
 deadline_timer
  to wait for a duration to elapse:
  
 Listing 11.12: Waiting synchronously
  
  1 #include <boost/asio.hpp>
  
  2 #include <boost/date_time.hpp>
  
  3 #include <iostream>
  
  4
  
  5 int main() {
  
 [
  455 
 ]",NA
Asynchronous logic using Asio coroutines ,"The 
 async_wait
  member function of 
 deadline_timer
  initiates an asynchronous 
 operation. Such a function returns before the operation it initiates is completed. It 
 registers a completion handler, and the completion of the asynchronous event is 
 notified to the program through a call to this handler. If we have to run such 
 asynchronous operations in a sequence, the control flow becomes complex. For 
 example, let us suppose we want to wait for 5 seconds, print 
 Hello
 , then wait for 10 
 more seconds, and finally, print 
 world
 . Using synchronous 
 wait
 , it is as easy as shown 
 in the following snippet:
  
 boost::asio::deadline_timer timer; 
  
 timer.expires_from_now(boost::posix_time::seconds(5)); 
 timer.wait(); 
  
 std::cout << ""Hello, ""; 
  
 timer.expires_from_now(boost::posix_time::seconds(10)); 
 timer.wait(); 
  
 std::cout << ""world!\n"";
  
 In many real-life scenarios, especially with network I/O, blocking on synchronous 
 operations is just not an option. In such cases, the code becomes considerably more 
 complex. Using 
 async_wait
  as a model asynchronous operation, the following 
 example illustrates the complexity of asynchronous code:
  
 Listing 11.14: Asynchronous operations
  
  1 #include <boost/asio.hpp>
  
  2 #include <boost/bind.hpp>
  
  3 #include <boost/date_time.hpp>
  
  4 #include <iostream>
  
  5
  
  6 void print_world(const boost::system::error_code& ec) {
  7   
 std::cout << ""world!\n"";
  
  8 }
  
  9 
  
 10 void print_hello(boost::asio::deadline_timer& timer, 11                  
 const boost::system::error_code& ec) { 
 12   std::cout << 
 ""Hello, "" << std::flush; 
  
 13 
  
 14   timer.expires_from_now(boost::posix_time::seconds(10)); 
 15   timer.async_wait(print_world); 
  
 16 } 
  
 17 
  
 18 int main() 
  
 19 { 
  
 20   boost::asio::io_service service;
  
 [
  458 
 ]",NA
UDP,"The UDP I/O model is relatively simple and the distinction between client and server is 
 blurred. For network I/O using UDP, we create a UDP socket, and use the 
 send_to
  and 
 receive_from
  functions to send datagrams to specific endpoints.",NA
Synchronous UDP client and server,"In this section, we write a UDP client (listing 11.16) and a synchronous UDP server 
 (listing 11.17). The UDP client tries to send some data to a UDP server on a given 
 endpoint. The UDP server blocks waiting to receive data from one or more UDP clients. 
 After sending data, the UDP client blocks waiting to receive a response from the server. 
 The server, after receiving the data, sends some response back before proceeding to 
 handle more incoming messages.
  
 Listing 11.16: Synchronous UDP client
  
  1 #include <boost/asio.hpp>
  
  2 #include <iostream>
  
  3 #include <exception>
  
  4 namespace asio = boost::asio;
  
  5
  
  6 int main(int argc, char *argv[]) {
  
  7   if (argc < 3) {
  
  8     std::cerr << ""Usage: "" << argv[0] << "" host port\n"";
  
  9     return 1;
  
 10   }
  
 11
  
 12   asio::io_service service;
  
 13   try {
  
 14     asio::ip::udp::resolver::query query(asio::ip::udp::v4(),
  
 15                                        argv[1], argv[2]);
  
 [
  461 
 ]",NA
Asynchronous UDP server,"An asynchronous version of the UDP server can significantly improve the 
  
 responsiveness of the server. A traditional asynchronous model can entail a more 
 complex programming model, but coroutines can significantly improve the situation.",NA
Asynchronous UDP server using completion handler ,NA,NA
chains,"For asynchronous communication, we use the 
 async_receive_from
  and 
 async_ 
 send_to
  member functions of 
 socket
 . These functions do not wait for the I/O request to 
 be handled by the operating system but return immediately. They are passed a function 
 object, which is to be called when the underlying operation is completed. This function 
 object is queued in the task queue of the 
 io_service
  and is dispatched when the actual 
 operation on the operating system returns:
  
 template <typename MutableBufSeq, typename ReadHandler>
  
 deduced async_receive_from(
  
  const MutableBufSeq& buffers,
  
 [
  464 
 ]",NA
Asynchronous UDP server using coroutines ,"Handler chaining fragments the logic across a set of handlers and sharing state across 
 handlers becomes particularly complex. It is the price for better performance, but it is a 
 price we can avoid, as we saw earlier using Asio coroutines to handle asynchronous 
 waits on 
 boost::asio::deadline_timer
  in listing 11.15. We will now use Asio 
 coroutines to write an asynchronous UDP server:
  
 Listing 11.19: Asynchronous UDP server using Asio coroutines
  
  1 #include <boost/asio.hpp>
  
  2 #include <boost/asio/spawn.hpp>
  
  3 #include <boost/bind.hpp>
  
  4 #include <boost/shared_ptr.hpp>
  
  5 #include <boost/make_shared.hpp>
  
  6 #include <iostream>
  
  7 namespace asio = boost::asio;
  
  8 namespace sys = boost::system;
  
  9 
  
 10 const size_t MAXBUF = 256; 
  
 11 typedef boost::shared_ptr<asio::ip::udp::socket> 
  
 12                                   shared_udp_socket; 
  
 13 
  
 14 void udp_send_to(boost::asio::yield_context yield, 
  
 15                  shared_udp_socket socket, 
  
 16                  asio::ip::udp::endpoint peer) 
  
 17 { 
  
 18     const char *msg = ""hello from server""; 
  
 19     socket->async_send_to(asio::buffer(msg, std::strlen(msg)), 
 20                          peer, yield); 
  
 21 } 
  
 22
  
 [
  467 
 ]",NA
Performance and concurrency,"We claimed that the asynchronous mode of communication improves responsiveness of 
 the server. Let us understand exactly what factors contribute to this improvement. In the 
 synchronous model of listing 11.17, a call to 
 receive_from
  could not be issued unless the 
 send_to
  function returned. In the asynchronous code of listing 11.18, 
 waitForReceive
  
 is called as soon as a message is received and consumed (lines 23-25), and it does not 
 wait for the 
 async_send_to
  to complete. Likewise, in listing 11.19 which illustrates the 
 use of coroutines in asynchronous models, coroutines help suspend a function waiting for 
 an asynchronous I/O operation to complete, and to continue processing other tasks in the 
 queue meanwhile. This is the principal source of improvement in the responsiveness of 
 the asynchronous servers.
  
 It is worth noting that in listing 11.18, all I/O happens on a single thread. This means 
 that at any given point in time, our program handles only one incoming UDP message. 
 This allows us to reuse the 
 buffer
  and 
 remote_peer
  member variables, without 
 worrying about synchronization. We must still ensure that we print the received buffer 
 (lines 22-23) before calling 
 waitForReceive
  again (line 24). If we inverted that order, 
 the buffer could potentially be overwritten by a new incoming message before it could 
 be printed.
  
 Consider what would have happened if we called 
 waitForReceive
  inside the 
 receive handler rather than the send handler like this:
  
 18     socket.async_receive_from(asio::buffer(buffer, MAXBUF),
  
 19           remote_peer,
  
 20           [this] (const sys::error_code& ec,
  
 21                   size_t sz) {
  
 ...            ...
  
 26             socket.async_send_to(
  
 27                 asio::buffer(msg, strlen(msg)),
  
 28                 remote_peer,
  
 29                 [this](const sys::error_code& ec,
  
 30                        size_t sz) {
  
 31                   waitForReceive();
  
 32                 });
  
 33           });
  
 In this case, the receive would be started only after the send completed; so even with 
 asynchronous calls it would be no better than the synchronous example in listing 11.17.
  
 [
  470 
 ]",NA
TCP,"In terms of network I/O, the programming model for UDP is about as simple as it 
 gets—you either send a message, or receive a message, or do both. TCP is a fairly 
 complex beast in comparison and its interaction model has a few additional details to 
 understand.
  
 In addition to reliability guarantees, TCP implements several nifty algorithms to ensure 
 that an overeager sender does not swamp a relatively slow receiver with lots of data 
 (
 flow control
 ), and all senders get a fair share of the network bandwidth (
 congestion 
 control
 ). There is a fair amount of computation that happens at the TCP layer for all of 
 this, and TCP needs to maintain some state information to perform these computations. 
 For this TCP uses 
 connections
  between endpoints.",NA
Establishing a TCP connection,"A 
 TCP connection
  consists of a pair of TCP sockets, potentially on different hosts 
 connected by an IP network and some associated state data. Relevant connection state 
 information is maintained at each end of the connection. A 
 TCP server
  typically starts 
 listening for incoming connections
  and is said to constitute the 
 passive end
  of the 
 connection. A 
 TCP client
  initiates a request to connect to a TCP server and is said to be 
 the 
 active end
  of the connection. A well-defined mechanism known as the 
 TCP 3-way 
 handshake 
 is used for establishing TCP connections. Similar mechanisms exist for 
 coordinated connection termination. Connections can also be unilaterally reset or 
 terminated, like in case of applications or hosts going down for various reasons or in case 
 of an irrecoverable error of some sort.",NA
Client- and server-side calls,"For a TCP connection to be set up, a server process must be listening on an endpoint, 
 and a client process must actively initiate a connection to that endpoint. The server 
 performs the following steps:
  
 1. Create a TCP listener socket.
  
 2. Create a local endpoint for listening to incoming connections and bind the 
  
 TCP listener socket to this endpoint.
  
 3. Start listening for incoming connections on the listener.
  
 4. Accept any incoming connections, and open a server-side endpoint (different 
  
 from the listener endpoint) to serve that connection.
  
 5. Perform communication on that connection.
  
 6. Handle the termination of the connection.
  
 7. Continue to listen for other incoming connections.
  
 [
  474 
 ]",NA
Synchronous TCP client and server ,"We will now write a TCP client which connects to a TCP server on a specified host and 
 port, sends some text to the server, and then receives some messages back from the 
 server:
  
 Listing 11.20: Synchronous TCP client
  
  1 #include <boost/asio.hpp>
  
  2 #include <iostream>
  
  3 namespace asio = boost::asio;
  
  4
  
  5 int main(int argc, char* argv[]) {
  
  6   if (argc < 3) {
  
  7     std::cerr << ""Usage: "" << argv[0] << "" host port\n""; 8     
 exit(1);
  
  9   } 
  
 10 
  
 11   const char *host = argv[1], *port = argv[2]; 
  
 12 
  
 13   asio::io_service service; 
  
 14   asio::ip::tcp::resolver resolver(service); 
  
 15   try { 
  
 16     asio::ip::tcp::resolver::query query(asio::ip::tcp::v4(), 
 17                                        host, port); 
  
 18     asio::ip::tcp::resolver::iterator end, 
  
 19                        iter = resolver.resolve(query); 
  
 20 
  
 21     asio::ip::tcp::endpoint server(iter->endpoint()); 
  
 22     std::cout << ""Connecting to "" << server << '\n'; 
  
 23     asio::ip::tcp::socket socket(service, 
  
 24                                  asio::ip::tcp::v4()); 
  
 25     socket.connect(server); 
  
 26     std::string message = ""Hello from client""; 
  
 27     asio::write(socket, asio::buffer(message.c_str(), 
  
 28                                    message.size()));
  
 [
  475 
 ]",NA
Concurrency and performance,"The TCP server handles each connection independently. But creating a new thread for 
 each new connection scales badly, and the server's resources could be overrun if a large 
 number of connections hit it over a very short interval. One way to handle this is to limit 
 the number of threads. Earlier, we modified the UDP server example from listing 11.18 
 to use a thread pool and limit the total number of threads. We can do the same with our 
 TCP server from listing 11.21. Here is an outline for how this can be done:
  
 12 asio::io_service service; 
  
 13 boost::unique_ptr<asio::io_service::work> workptr( 
  
 14                                    new dummyWork(service)); 
 15 auto threadFunc = [&service] { service.run(); }; 
  
 16 
  
 17 boost::thread_group workers; 
  
 18 for (int i = 0; i < max_threads; ++i) { //max_threads 
  
 19   workers.create_thread(threadFunc); 
  
 20 } 
  
 21 
  
 22 asio::ip::tcp::endpoint ep(asio::ip::tcp::v4(), port); 23 
 asio::ip::tcp::acceptor acceptor(service, ep); 
  
 24 while (true) { 
  
 25   socket_ptr socket(new asio::ip::tcp::socket(service)); 26   
 acceptor.accept(*socket); 
  
 27 
  
 28   service.post([socket] { /* do I/O on the connection */ }); 
 29 } 
  
 30 
  
 31 workers.join_all(); 
  
 32 workptr.reset(); // we don't reach here
  
 First, we create a pool of a fixed number of threads (lines 15-20), and make sure they 
 do not exit by posting a dummy work to the 
 io_service
 's task queue 
  
 (lines 13-14). Instead of creating a thread for each new connection, we post a handler 
 for the connection to the task queue of the 
 io_service
  (line 28). This handler can be 
 exactly the same as the initial function of the per-connection thread in listing 11.21. 
  
 The threads in the pool then dispatch the handlers on their own schedule. The 
 number of threads represented by 
 max_threads
  can be tweaked easily based on 
 the number of processors in the system.
  
 While using the thread pool limits the number of threads, it does little to improve the 
 responsiveness of the server. In the event of a large influx of new connections, handlers of 
 the newer connections would form a big backlog in the queue, and these clients would be 
 kept waiting while the server services earlier connections. We have already addressed 
 similar concerns in our UDP server by using asynchronous I/O. In the next section, we will 
 use the same strategy to scale our TCP servers better.
  
 [
  479 
 ]",NA
Asynchronous TCP server ,"The synchronous TCP server is inefficient mainly because the read and write operations 
 on the sockets block for a finite amount of time, waiting for the operations to complete. 
 During this time, even with thread pools around, the thread serving the connection just 
 waits idly for an I/O operation to go through, before it can proceed to handle the next 
 available connection.
  
 We can eliminate these idle waits using asynchronous I/O. Just as we saw with the 
 asynchronous UDP server, we could either use chains of handlers or coroutines to write 
 the asynchronous TCP server. While handler chains make the code complex, and 
 therefore error-prone, coroutines make it far more readable and intuitive. We will first 
 write an asynchronous TCP server using coroutines, and then use the more traditional 
 handler-chaining, just to put the difference between the two approaches in perspective. 
 You can skip the handler-chaining implementations on first reading.",NA
Asynchronous TCP server using coroutines ,"The following is the complete code for a TCP server employing asynchronous I/O via 
 coroutines:
  
 Listing 11.22: Asynchronous TCP server using coroutines
  
  1 #include <boost/asio.hpp>
  
  2 #include <boost/asio/spawn.hpp>
  
  3 #include <boost/thread.hpp>
  
  4 #include <boost/shared_ptr.hpp>
  
  5 #include <boost/make_shared.hpp>
  
  6 #include <boost/bind.hpp>
  
  7 #include <boost/array.hpp>
  
  8 #include <iostream>
  
  9 #include <cstring> 
  
 10 
  
 11 namespace asio = boost::asio; 
  
 12 typedef boost::shared_ptr<asio::ip::tcp::socket> 
 socketptr; 13 
  
 14 void handle_connection(asio::yield_context yield, 
  
 15                        socketptr socket) 
  
 16 { 
  
 17   asio::io_service& service = socket->get_io_service(); 18   
 char msg[BUFSIZ]; 
  
 19   msg[0] = '\0'; 
  
 20   boost::system::error_code ec; 
  
 21   const char *resp = ""Hello from server""; 
  
 22
  
 [
  480 
 ]",NA
Asynchronous TCP server without coroutines,"We now look at how to write an asynchronous TCP server without coroutines. This 
 involves a more complex handshake between handlers, and hence, we want to split the 
 code into appropriate classes. We define two classes in two separate header files. The 
 class 
 TCPAsyncServer
  (listing 11.23) represents the server instance that listens for 
 incoming connections. It goes in the 
 asyncsvr.hpp
  header file. The class 
 TCPAsyncConnection
  (listing 11.25) represents the processing context of a single 
 connection. It goes in the 
 asynconn.hpp
  header file.
  
 [
  482 
 ]",NA
Lifetime of TCPAsyncConnection,"Each instance of 
 TCPAsyncConnection
  needs to survive as long as the client remains 
 connected to the server. This makes it difficult to bind the scope of this object to any 
 function in the server. This is the reason we create the 
 TCPAsyncConnection 
 object 
 wrapped in a 
 shared_ptr
 , and then capture it in handler lambdas. The 
 TCPAsyncConnection
  member functions for performing I/O on the connection, 
 waitForReceive
  and 
 startSend
 , are both asynchronous. So they push a handler into 
 the 
 io_service
 's task queue before returning. These handlers capture the 
 shared_ptr
  
 wrapped instance of 
 TCPAsyncConnection
  to keep the instance alive across calls.
  
 [
  487 
 ]",NA
Performance and concurrency,"Notice that both implementations of TCP asynchronous server, with and without 
 coroutines, are single-threaded. However, there are no thread-safety issues in either 
 implementation, so we could have as well employed a thread pool, each of whose 
 threads would call 
 run
  on the 
 io_service
 .",NA
Inversion of control flow,"The most significant difficulty with programming asynchronous systems is the 
 inversion of control flow. To write the code for a synchronous server, we know we 
 have to call the operations in the following sequence:
  
 1. Call 
 accept
  on the acceptor.
  
 2. Call 
 read
  on the socket.
  
 3. Call 
 write
  on the socket.
  
 We know that 
 accept
  returns only when the connection has been established, so it is 
 safe to call 
 read
 . Also, 
 read
  returns only after it has read the number of bytes asked for, 
 or encountered an end-of-file. So it is safe for a 
 write
  call to follow. This made writing 
 code incredibly easy compared to the asynchronous model, but introduced waits that 
 affected our ability to handle other waiting connections, while our requests were being 
 serviced.
  
 [
  488 
 ]",NA
Self-test questions,"For multiple choice questions, choose all options that apply:
  
 1. What is the difference between 
 io_service::dispatch
  and 
 io_ 
  
 service::post
 ?
  
 a. 
 dispatch
  returns immediately while 
 post
  runs the handler before returning
  
 b. 
 post
  returns immediately while 
 dispatch
  may run the handler on the 
 current thread if it can, or it behaves like post
  
 c. 
 post
  is thread-safe while 
 dispatch
  is not
  
 d. 
 post
  returns immediately while 
 dispatch
  runs the handler
  
 2. What happens if a handler throws an exception when it is dispatched?
  
 a. It is undefined behavior
  
 b. It terminates the program with a call to 
 std::terminate
  
 c. The call to run, on the 
 io_service
  that dispatched the handler, will throw
  
 d. The 
 io_service
  is stopped
  
 [
  489 
 ]",NA
Summary,"Asio is a well-designed library that can be used to write fast, nimble network servers 
 that utilize the most optimal mechanisms for asynchronous I/O available on a system. It 
 is an evolving library and is the basis for a Technical Specification that proposes to add a 
 networking library to a future revision of the C++ Standard.
  
 In this chapter, we learned how to use the Boost Asio library as a task queue manager 
 and leverage Asio's TCP and UDP interfaces to write programs that communicate over 
 the network. Using Boost Asio, we were able to highlight some of the general concerns of 
 network programming, the challenges to scaling for a large number of concurrent 
 connections, and the advantages and complexity of asynchronous I/O. In particular, we 
 saw how using stackful coroutines makes writing asynchronous servers a breeze, 
 compared to the older model of chaining handlers. While we did not cover stackless 
 coroutines, the ICMP protocol, and serial port communications among other things, the 
 topics covered in this chapter should provide you with a solid foundation for 
 understanding these areas.",NA
References,"• 
  
 Thinking Asynchronously in C++
  (blog), 
 Christopher Kohlhoff
 : 
 http://blog.
  
 think-async.com/
  
 • 
  
 Networking Library Proposal
 , 
 Christopher Kohlhoff
 : 
 http://www.open-
 std.org/ 
  
 jtc1/sc22/wg21/docs/papers/2014/n4332.html
  
 [
  491 
 ]",NA
C++11 Language Features ,NA,NA
Emulation,"In this section, we will review some concepts from C++ programming that will be 
 conceptually important in understanding several topics covered in this book. Many of 
 these concepts have been introduced relatively recently as part of C++11. We will look 
 at: RAII, copy- and move-semantics, 
 auto
 , range-based for-loops, and C++11 exception 
 handling enhancements. We will look at how these features can 
  
 be emulated under a pre-C++11 compiler using parts of the Boost libraries.",NA
RAII,"C++ programs frequently deal with system resources like memory, file and socket 
 handles, shared memory segments, mutexes, and so on. There are well-defined 
 primitives, some from the C Standard Library and many more from the native systems 
 programming interfaces, which are used to request and relinquish these resources. 
 Failing to guarantee the release of acquired resources can cause grave problems to an 
 application's performance and correctness.
  
 The destructor of a C++ object 
 on the stack
  is automatically invoked during stack 
 unwinding. The unwinding happens when a scope is exited due to control reaching the 
 end of the scope, or by executing 
 return
 , 
 goto
 , 
 break
 , or 
 continue
 . A scope is also 
 exited as a result of an exception being thrown. In either case, the destructor is 
 guaranteed to be called. This guarantee is limited to C++ objects on the stack. It does not 
 apply to C++ objects on the heap because they are not associated with a lexical scope. 
 Furthermore, it does not apply to the aforementioned resources like memory and file 
 descriptors, which are objects of Plain Old Data types (POD-types) and therefore do not 
 have a destructor.
  
 [
  493 
 ]",NA
Copy semantics,"An object keeps state information in its data members, which can themselves be of POD-
 types or class types. If you do not define a copy constructor for your class, then the 
 compiler implicitly defines one for you. This implicitly-defined copy constructor copies 
 each member in turn, invoking the copy constructor of members of class type and 
 performing a bitwise copy of POD-type members. The same is true of the assignment 
 operator. The compiler generates one if you do not define your own, and it performs 
 member-wise assignment, invoking the assignment operators of member objects of class-
 type, and performing bitwise copies of POD-type members.
  
 [
  495 
 ]",NA
The nothrow swap,"Thanks to Rule of Zero, you should rarely need to bother about the Rule of Three. But 
 when you do have to use the Rule of Three, there are a few nitty-gritties to take care 
 of. Let us first understand how you would define a copy operation for the 
 String
  
 class in listing A.1:
  
 Listing A.1a: Copy constructor
  
  1 String::String(const String &str) : buffer_(0), len_(0)
  
  2 {
  
  3   buffer_ = dupstr(str.buffer_, len_);
  
  4 }
  
 The implementation of copy constructor is no different than that of the constructor in 
 listing A.1. The assignment operator requires more care. Consider how 
 String 
 objects are assigned to in the following example:
  
  1 String band1(""Deep Purple"");
  
  2 String band2(""Rainbow"");
  
  3 band1 = band2;
  
 On line 3, we assign 
 band2
  to 
 band1
 . As part of this, 
 band1
 's old state should be 
 deallocated and then overwritten with a copy of 
 band2
 's internal state. The problem is 
 that copying 
 band2
 's internal state might fail, and so 
 band1
 's old state should not be 
 destroyed until 
 band2
 's state has been copied successfully. Here is a succinct way to 
 achieve this:
  
 Listing A.1b: Assignment operator
  
  1 String& String::operator=(const String& rhs)
  
  2 {
  
  3   String tmp(rhs);   // copy the rhs in a temp variable
  
  4   swap(tmp);         // swap tmp's state with this' state.
  
  5   return *this;      // tmp goes out of scope, releases this'
  
  6                      // old state
  
  7 }
  
 We create 
 tmp
  as a copy of 
 rhs
  (line 3) and if this copying fails, it should throw an 
 exception and the assignment operation would fail. The internal state of the assignee, 
 this
 , should not change. The call to 
 swap
  (line 4) executes only if the copying succeeded 
 (line 3). The call to 
 swap
  exchanges the internal states of 
 this
  and the 
 tmp 
 object. As a 
 result, 
 this
  now contains the copy of 
 rhs
  and 
 tmp
  contains the older state of 
 this
 . At the 
 end of this function, 
 tmp
  goes out of scope and releases the old state of 
 this
 .
  
 [
  498 
 ]",NA
Move semantics and rvalue references,"Copy semantics are for creating clones of objects. It is useful sometimes, but not always 
 needed or even meaningful. Consider the following class that encapsulates a TCP client 
 socket. A TCP socket is an integer that represents one endpoint of a TCP connection and 
 through which data can be sent or received to the other endpoint. 
  
 The TCP socket class can have the following interface:
  
 class TCPSocket
  
 {
  
 public:
  
  TCPSocket(const std::string& host, const std::string& port);
  
  ~TCPSocket();
  
  bool is_open();
  
  vector<char> read(size_t to_read);
  
  size_t write(vector<char> payload);
  
 private:
  
 [
  499 
 ]",NA
rvalue references,"In order to support move semantics better, we must first answer the question: which 
 objects can be moved from? Consider the 
 TCPSocket
  example again. In the function 
 connectToService
 , the expression 
 TCPSocket(get_service_host(), 
 get_service_port())
  is an 
 unnamed temporary
  object of 
 TCPSocket
  whose sole 
 purpose is to be transferred to the caller's context. There is no way for anyone to 
 refer to this object beyond the statement where it gets created. It makes perfect 
 sense to move the contents out of such an object. But in the following snippet:
  
 TCPSocket socket = connectToService();
  
 performIO(socket);
  
 It would be dangerous to move out the contents of 
 socket
  object because in the 
 calling context, the object is still bound to the name 
 socket
  and can be used in 
 further operations. The expression 
 socket
  is called an 
 lvalue expression
 —one that 
 has an identity and whose address can be taken by prefixing the &-operator to the 
 expression. Non-lvalue expressions are referred to as 
 rvalue expressions
 . These are 
 unnamed expressions whose address cannot be computed using the &-operator on 
 the expression. An expression, such as 
 TCPSocket(get_service_host(), 
 get_service_port())
  is an rvalue expression.
  
 [
  501 
 ]",NA
rvalue-reference overloads,"We can create overloads of a function based on whether they take lvalue expressions or 
 rvalue expressions. In particular, we can overload the copy constructor to take rvalue 
 expressions. For the 
 TCPSocket
  class, we can write the following:
  
 TCPSocket(const TCPSocket&) = delete;
  
 TCPSocket(TCPSocket&& rvref) : socket_fd_(-1)
  
 {
  
  std::swap(socket_fd_, rvref.socket_fd_);
  
 }
  
 While the lvalue overload is the deleted copy constructor, rvalue overload is called the 
 move constructor because this is implemented to usurp or ""steal"" the contents of the 
 rvalue expression passed to it. It moves the contents of the source to the target, leaving 
 the source (
 rvref
 ) in some unspecified state that is safe to destruct. In this case, this 
 amounts to setting the 
 socket_fd_
  member of the 
 rvref
  to -1.
  
 With this definition of the move constructor, 
 TCPSocket
  becomes movable but not 
 copyable. The 
 connectToService
  implementation would work correctly:
  
 TCPSocket connectToService()
  
 {
  
  return TCPSocket(get_service_host(),get_service_port());
  
 }
  
 This would move the temporary object back to the caller. But the following call to 
 performIO
  would be ill-formed because 
 socket
  is an lvalue expression and 
 TCPSocket
  
 only defines move semantics for which an rvalue expression was necessary:
  
 TCPSocket socket = connectToService();
  
 performIO(socket);
  
 This is a good thing because you cannot move contents out of an object like 
 socket 
 that you could potentially use later. An rvalue-expression of a movable type can be 
 passed by value and thus the following will be well-formed:
  
 performIO(connectToService());
  
 Note that the expression 
 connectToService()
 is an rvalue expression because it is 
 not bound to a name and its address cannot be taken.
  
 [
  503 
 ]",NA
Move assignment ,"Just as we can construct an object by stealing the contents of another object, we can also 
 move the contents of one object to another after both have been constructed. To do this, 
 we can define a 
 move assignment operator
 , an rvalue-overload of the copy assignment 
 operator:
  
  1 // move assignment
  
  2 String& String::operator=(String&& rhs) noexcept 
 3 {
  
  4   swap(rhs);
  
  5   return *this;
  
  6 }
  
 Alternatively, we can define a 
 universal assignment operator
  that works for both 
 lvalue and rvalue expressions:
  
  1 // move assignment
  
  2 String& String::operator=(String rhs)
  
  3 {
  
  4   swap(rhs);
  
  5   return *this;
  
  6 }
  
 Note that the universal assignment operator cannot coexist with either the lvalue or the 
 rvalue overload, else there would be ambiguity in overload resolution.
  
 [
  504 
 ]",NA
xvalues,"When you call a function with an rvalue expression, the compiler resolves function 
 calls to an rvalue-overload of the function if one is available. But if you call the function 
 with a named variable, it gets resolved to an lvalue overload if one is available or the 
 program is ill-formed. Now you might have a named variable that you can move from 
 because you have no use for it later:
  
 void performIO(TCPSocket socket);
  
 TCPSocket socket = connectToService();
  
 // do stuff on socket
  
 performIO(socket);  // ill-formed because socket is lvalue
  
 The preceding example will fail to compile because 
 performIO
  takes its sole 
 parameter by value and 
 socket
  is of a move-only type but it is not an rvalue 
 expression. By using 
 std::move
 , you can cast an lvalue expression to an rvalue 
 expression, and pass it to a function that expects an rvalue expression. The 
 std::move
  function template is defined in the standard header 
 utility
 .
  
 #include <utility> // for std::moves
  
 performIO(std::move(socket));
  
 The call to 
 std::move(socket)
  gives us an rvalue reference to 
 socket
 ; it does not 
 cause any data to be moved out of 
 socket
 . When we pass this expression of rvalue-
 reference type to the function 
 performIO
 , which takes its parameter by value, a new 
 TCPSocket
  object is created in the 
 performIO
  function, corresponding to its by-value 
 parameter. It is 
 move initialized
  from 
 socket
 , that is, its move constructor steals the 
 contents of 
 socket
 . Following the call to 
 performIO
 , the variable 
 socket 
 loses its 
 contents and therefore should not be used in further operations. If the move constructor 
 of 
 TCPSocket
  is correctly implemented, then 
 socket
  should still be safe to destruct.
  
 The expression 
 std::move(socket)
  shares the identity of 
 socket
 , but it would 
 potentially
  be moved from within the function it is passed to. Such expressions are 
 called 
 xvalues
 , the 
 x
  standing for 
 expired
 .
  
  
 xvalues
  have a well-defined identity like lvalues, but can be moved from 
  
  
 like rvalues. 
 xvalues
  bind to rvalue reference parameters of a function.
  
 If 
 performIO
  did not take its parameter by value but as an rvalue-reference then one 
 thing would change:
  
 void performIO(TCPSocket&& socket);
  
 performIO(std::move(socket));
  
 [
  505 
 ]",NA
Move emulation using Boost.Move ,"In this section, we look at how, with relative ease, you can actually retrofit much of the 
 move semantics for your own legacy classes using the Boost.Move library. First, 
 consider the interface of the 
 String
  class in C++ 11 syntax:
  
  1 class String
  
  2 {
  
  3 public:
  
  4   // Constructor
  
  5   String(const char *str = 0);
  
  6
  
  7   // Destructor
  
  8   ~String();
  
  9 
  
 10   // Copy constructor 
  
 11   String(const String& that); 
  
 12 
  
 13   // Copy assignment operator 
  
 14   String& operator=(const String& rhs); 
  
 15 
  
 16   // Move constructor
  
 [
  507 
 ]",NA
C++11 auto and Boost.Auto ,"Consider how you declare an iterator to a vector of strings:
  
 std::vector<std::string> names; 
  
 std::vector<std::string>::iterator iter = 
 vec.begin();
  
 The declared type of 
 iter
  is big and unwieldy and it is a pain to write it explicitly every 
 time. Given that the compiler knows the type of the initializing expression on the right-
 hand side, that is, 
 vec.begin()
 , this is also superfluous. Starting with C++11, you can use 
 the 
 auto
  keyword to ask the compiler to deduce the type of a declared variable using the 
 type of the expression it is initialized with. Thus, the preceding tedium is replaced by the 
 following:
  
  
 std::vector<std::string> names; 
  
  
 auto iter = vec.begin(); 
  
 Consider the following statement:
  
 auto var = expr;
  
 The deduced type of 
 var
  is the same as the deduced type 
 T
 , when the following 
 function template is called with the argument 
 expr
 :
  
 template <typename T> 
  
 void foo(T);
  
 foo(expr);
  
 [
  511 
 ]",NA
Type deduction rules ,"There are a few rules to keep in mind. First, if the initializing expression is a 
 reference, the reference is stripped in the deduced type:
  
 int x = 5; 
  
 int& y = x; 
  
 auto z = y;  // deduced type of z is int, not 
 int&
  
 If you want to declare an lvalue-reference, you must explicitly adorn the 
 auto 
 keyword with an ampersand (&), as shown here:
  
 int x = 5; 
  
 auto& y = x;     // deduced type of y is int&
  
 If the initializing expression is not copyable, you must make the assignee a reference in 
 this way.
  
 The second rule is that 
 const
  and 
 volatile
  qualifiers of the initializing expression are 
 stripped in the deduced type, unless the variable declared with 
 auto
  is explicitly 
 declared as a reference:
  
 int constx = 5; 
  
 auto y = x;     // deduced type of y is int 
  
 auto& z = x;    // deduced type of z is constint
  
 Again, if you want to add a 
 const
  or 
 volatile
  qualifier, you must do so explicitly, as 
 shown:
  
 intconst x = 5; 
  
 auto const y = x;    // deduced type of y is constint",NA
Common uses ,"The 
 auto
  keyword is very convenient to use in a lot of situations. It lets you get away 
 from having to type long template IDs, in particular when the initializing expression is a 
 function call. Here are a couple of examples to illustrate the advantages:
  
 auto strptr = boost::make_shared<std::string>(""Hello""); 
 // type of strptr is boost::shared_ptr<std::string>
  
 auto coords(boost::make_tuple(1.0, 2.0, 3.0)); 
  
 // type of coords is boost::tuple<double, double, double>
  
 [
  512 
 ]",NA
Boost.Auto,"If you are on a pre-C++11 compiler, you can emulate this effect using the 
 BOOST_ AUTO
  
 and 
 BOOST_AUTO_TPL
  macros. Thus, you can write the last snippet as follows:
  
 #include <boost/typeof/typeof.hpp>
  
 BOOST_AUTO(strptr, boost::make_shared<std::string>(""Hello""));
  
 // type of strptr is boost::shared_ptr<std::string>
  
 BOOST_AUTO(coords, boost::make_tuple(1.0, 2.0, 3.0));
  
 // type of coords is boost::tuple<double, double, double>
  
 Note the header file 
 boost/typeof/typeof.hpp
  that needs to be included to use 
 the macro.
  
 If you want to declare a reference type, you can adorn the variable with a leading 
 ampersand (&). Likewise, to qualify your variable with 
 const
  or 
 volatile
 , you 
 should add the 
 const
  or 
 volatile
  qualifier before the variable name. Here is an 
 example:
  
 BOOST_AUTO(const& strptr, boost::make_shared<std::string>(""Hello""));
  
 // type of strptr is boost::shared_ptr<std::string>",NA
Range-based for-loops,"Range-based for-loops are another syntactic convenience introduced in C++11. Range-
 based for-loops allow you to iterate through a sequence of values like arrays, containers, 
 iterator ranges, and so on, without having to explicitly specify boundary conditions. It 
 makes iterating less error-prone by obviating the need to specify boundary conditions.
  
 The general syntax for range-based for-loop is:
  
 for (range-declaration : sequence-expression) {
  
  statements;
  
 }
  
 [
  513 
 ]",NA
Boost.Foreach,"You can use the 
 BOOST_FOREACH
  macro to emulate the basic uses of C++11's 
 range-based for-loops:
  
 #include <boost/foreach.hpp>
  
 [
  514 
 ]",NA
C++11 exception-handling improvements,"C++11 introduced the ability to capture and store an exception that can be passed 
 around and rethrown later. This is particularly useful for propagating exceptions 
 across threads.",NA
Storing and rethrowing exceptions,"To store an exception, the type 
 std::exception_ptr
  is used. 
 std::exception_ptr 
 is a smart pointer type with shared ownership semantics, not unlike 
 std::shared_ 
 ptr
  (see 
 Chapter 3
 , 
 Memory Management and Exception Safety
 ). An instance of 
  
 std::exception_ptr
  is copyable and movable and can be passed to other functions 
 potentially across threads. A default-constructed 
 std::exception_ptr
  is a null object 
 that does not point to any exception. Copying a 
 std::exception_ptr
  object creates 
 two instances that manage the same underlying exception object. The underlying 
 exception object continues to exist as long as the last 
 exception_ptr 
 instance 
 containing it exists.
  
 The function 
 std::current_exception
 , when called inside a catch-block, returns the 
 active exception for which the catch-block was executed, wrapped in an instance of 
 std::exception_ptr
 . When called outside a catch-block, it returns a null 
 std::exception_ptr
  instance.
  
 The function 
 std::rethrow_exception
  is passed an instance of 
 std::exception_ 
 ptr
  (which must not be null) and throws the exception contained in the 
  
 std::exception_ptr
  instance.
  
 [
  515 
 ]",NA
Storing and rethrowing exception using Boost,"In pre-C++11 environments, you can use the 
 boost::exception_ptr
  type to store 
 exceptions and 
 boost::rethrow_exception
  to throw the exception stored in 
 boost::exception_ptr
 . There is also the 
 boost::current_exception
  function 
 which works akin to 
 std::current_exception
 . But without underlying language 
 support, it requires help from the programmer to function.
  
 In order for 
 boost::current_exception
  to return the currently active exception 
 wrapped in 
 boost::exception_ptr
 , we must modify the exception before throwing it to 
 make it amenable to be handled using this mechanism. To do this, we call 
 boost::enable_current_exception
  on the exception to be thrown. The following 
 snippet illustrates this:
  
 Listing A.4: Using boost::exception_ptr
  
  1 #include <boost/exception_ptr.hpp>
  
  2 #include <iostream>
  
  3
  
  4 void do_work()
  
  5 {
  
  6   throw boost::enable_current_exception(
  
  7             std::runtime_error(""Exception in do_work""));
  
  8 }
  
  9
  
 10 void do_more_work()
  
 11 {
  
 12   boost::exception_ptr eptr;
  
 13 
  
 14   try {
  
 15     do_work();
  
 [
  517 
 ]",NA
Self-test questions ,"1. The Rule of Three states that if you define your own destructor for a class, 
  
  
 you should also define:
  
 a. Your own copy constructor
  
 b. Your own assignment operator
  
 c. Both a and b
  
 d. Either a or b
  
 2. Assuming the class 
 String
  has both copy and move constructors, which of 
  
 the following does not invoke a move constructor:
  
 a. 
 String s1(getName());
  
 b. 
 String s2(s1);
  
 c. 
 String s2(std::move(s1));
  
 d. 
 String s3(""Hello"");
  
 3. The purpose of 
 std::move
  function is to:
  
 a. Move contents of its argument out
  
 b. Create an lvalue reference from an rvalue reference
  
 c. Create an xvalue from an lvalue expression
  
 d. Swap contents of its argument with another object
  
 [
  518 
 ]",NA
References,"• 
  
 • 
  
 • 
  
 Effective Modern C++: 42 Specific Ways to Improve Your Use of C++11 
 and C++14
 , 
 Scott Meyers
 , 
 O'Reilly Media
  
 A Tour of C++
 , 
 Bjarne Stroustrup
 , 
 Addison Wesley Professional
  
 The C++ Programming Language (4/e)
 , 
 Bjarne Stroustrup
 , 
 Addison 
 Wesley Professional
  
 [
  519 
 ]",NA
Index ,NA,NA
A B,"ABI (application binary interface)  6 
  
 Abstract Syntax Tree (AST)  287 
  
 active endpoints  455 
  
 actors  290 
  
 anchors  152, 154 
  
 Argument Dependent Lookup 
  
   
 (ADL)  64, 198 
  
 arity  253 
  
 Asio deadline timer  455-457 
  
 assignment operator 
  
  
 about  497 
  
  
 implementing  498 
  
 asymmetric coroutines 
  
  
 about  424 
  
  
 using  425 
  
 asynchronous communication  455 
  
 asynchronous TCP server 
  
  
 about  480 
  
  
 concurrency  488 
  
  
 coroutines, used  480-482 
  
  
 inversion of control flow  488 
  
  
 lifetime of TCPAsyncConnection  487 
  
 performance  488 
  
  
 without coroutines  482-487 
  
 asynchronous UDP server 
  
  
 about  464-467 
  
  
 completion handler chains, used  464, 465 
  
 coroutines, used  467-469 
  
 atomic operation  403 
  
 atoms  152
  
 BasicLockable concept  407 
  
 bimaps 
  
  
 for many-to-many relations  242 
  
  
 projections  246, 247 
  
  
 tagged access  245, 246 
  
  
 using  245 
  
 binary  253 
  
 blocking calls  463 
  
 Boost 
  
  
 about  2 
  
  
 evolution  1 
  
  
 history  1 
  
  
 URL  2 
  
 boost::intrusive_ptr  109 
  
 boost::scoped_array  90, 91 
  
 boost::scoped_ptr  81-83 
  
 boost::shared_ptr  96, 98 
  
 boost::weak_ptr  102-105 
  
 Boost.Any 
  
  
 about  47 
  
  
 used, for storing heterogeneous values 
  
  
 of data  47 
  
  
 using  48-50 
  
 Boost.Assign 
  
  
 containers, initializing with 
  
   
 lists of values  206-209 
  
  
 list of values, assigning to 
  
   
 containers  203-206 
  
  
 object initialization  203 
  
  
 pointer containers, initializing  209-212 
  
 used, for assignment  203 
  
  
 values, assigning  209-212
  
 [
  521 
 ]",NA
C,"C++  75 
  
 C++11 
  
  
 exception-handling improvements  515 
 C++11 auto 
  
  
 about  511 
  
  
 common uses  512 
  
  
 type deduction rules  512
  
 [
  523 
 ]",NA
D E,"data race  401-403 
  
 date and time calculations, with 
  
   
 Boost Date Time 
  
  
 about  311 
  
  
 Posix time  316 
  
 dates, from Gregorian calendar 
  
  
 about  312 
  
  
 date durations, handling  314 
  
  
 date objects, creating  312, 313 
  
  
 date periods  314-316 
  
 Date_Time library 
  
  
 about  312 
  
  
 boost::gregorian::date  312 
  
  
 boost::gregorian::date_duration  312 
  
  
 boost::posix_time::ptime  316 
  
  
 boost::posix_time::time_duration  316 
  
  
 boost::posix_time::time_period  316 
  
 deadlock  409-412 
  
 DEFLATE algorithm  368 
  
 delegates  262 
  
 dequeue  413 
  
 device 
  
  
 about  359 
  
  
 for file I/O  361-363 
  
  
 for reading and writing to memory  363-365 
  
 using  361 
  
 diagnostic macros 
  
  
 using, from Predef library  70-72 
  
 disjunctions  155 
  
 domain name  449 
  
 Domain Specific Embedded 
  
   
 Languages (DSELs) 
  
  
 about  284, 290 
  
  
 Boost Phoenix  290 
  
  
 Boost Spirit Parser Framework  296 
  
  
 expression templates  285-290 
  
  
 lazy evaluation  285 
  
 dual use filter  359 
  
 dynamic memory allocation  76, 77 
  
 dynamic scoping  261 
  
 dynamically-allocated objects 
  
  
 containers  190
  
 eager evaluation  285 
  
 Embedded Domain Specific Language 
  
  
 (EDSL)  290 
  
 enable_shared_from_this 
  
  
 defining  106-108 
  
 endpoint  448 
  
 endpoint iterator  450 
  
 enqueue  413 
  
 exception-handling improvements, C++11 
  
 exceptions, re-throwing  515-517 
  
  
 exceptions, re-throwing with Boost  517 
  
 exceptions, storing  515-517 
  
  
 exceptions, storing with Boost  517 
  
 exception safety 
  
  
 about  76, 77 
  
  
 and RAII  78, 79 
  
 Expat library 
  
  
 URL  11 
  
 expression templates  285-290 
  
 Extended Backus-Naur Form (EBNF)  296 
 extensible I/O, with Boost IOStreams 
  
  
 about  359 
  
  
 devices, using  361 
  
  
 filters, using  365 
  
 extension  343",NA
F,"filename  342 
  
 files and directories, managing with 
  
   
 Boost Filesystem 
  
  
 about  336 
  
  
 directories, traversing  347-350 
  
  
 filesystem entries, querying  350-353 
  
  
 operations, performing on files  354 
  
  
 paths, breaking into components  342-347 
  
 paths, constructing  340, 341 
  
  
 paths, manipulating  336 
  
  
 paths, printing  336-338 
  
 filtering stream buffers  366 
  
 filtering streams  366
  
 [
  525 
 ]",NA
G,"gather-scatter I/O  453 
  
 generic algorithms  167 
  
 generic containers  167 
  
 generic format  337 
  
 generic programming  167 
  
 GNU Compiler Collection (GCC)  3 
 grep_filter 
  
  
 using  367, 368 
  
 guarantees 
  
  
 basic guarantee  78 
  
 gzip compressor and 
 decompressor 
  
 using  368",NA
H,"handler  431 
  
 hash table  172 
  
 heterogeneous values, of data 
  
  
 about  34 
  
  
 storing  35 
  
  
 storing, Boost.Any used  47-50 
  
  
 storing, Boost.Conversion used  50 
  
 storing, Boost.Variant used  35 
  
 higher order programming  249 
  
 higher order programming, with Boost 
  
 about  250, 251 
  
  
 function objects  251-254 
  
 hostnames  449",NA
I,"ICU library 
  
  
 URL  11 
  
 img_rotate function  77 
  
 initializer list  182, 203 
  
 inorder traversal  218 
  
 input filter  359 
  
 input iterator  347 
  
 insert method  176 
  
 Internet Assigned Numbers 
   
 Authority (IANA)  448 
 Internet Protocol  441 
  
 intrusive_ptr 
  
  
 using  110-113 
  
 I/O objects  449 
  
 I/O service object  449 
  
 IP addresses 
  
  
 about  442 
  
  
 IPv4 addresses  442 
  
  
 IPv6 addresses  445 
  
 IPv4 addresses 
  
  
 about  442 
  
  
 handling, with Boost  443, 445 
  
 special addresses  443 
  
  
 subnets  442 
  
 IPv6 addresses 
  
  
 about  445 
  
  
 address classes  446 
  
  
 anycast addresses  446
  
 [
  526 
 ]",NA
K,"key  227 
  
 Kleene star  
 153",NA
L,"lambda expressions  255 
  
 lambdas 
  
  
 about  255 
  
  
 capture clauses, specifying  256 
  
 lambda captures  256-258 
  
  
 lambda introducers  256 
  
  
 using  256 
  
 lazy evaluation  285, 287 
  
 lexical_cast function template 
  
 using  51, 52 
  
 libboost-all-dev package 
  
  
 /usr/include  9 
  
  
 /usr/lib/arch-linux-gnu  9 
  
 library name components 
  
  
 ABI  6 
  
  
 about  5 
  
  
 extensions  6 
  
  
 prefix  5 
  
  
 threading model  6 
  
  
 toolset identifier  5 
  
  
 version  6 
  
 library name layouts 
  
  
 about  6
  
  
 system layout  7 
  
  
 tagged layout  7 
  
  
 versioned layout  6 
  
 library naming conventions  5 
  
 Linux 
  
  
 Boost binary distribution, installing  9 
  
  
 Boost libraries, building on  11, 12 
  
  
 Boost libraries, linking against  16 
  
 Linux toolchain  4 
  
 Lockable concept  407 
  
 lock-based thread synchronization methods 
  
 about  400 
  
  
 atomic operation  403 
  
  
 critical sections  403 
  
  
 data races  401, 402 
  
  
 mutual exclusion  403 
  
  
 Readers-Writers problem  417 
  
  
 Standard Library primitives  423 
  
  
 synchronizing, on conditions  412 
  
 lookups 
  
  
 multimaps, used  228, 229 
  
 loopback address  443 
  
 lvalue expression  501 
  
 lvalue references  502",NA
M,"make_shared 
  
  
 defining  106-108 
  
 metafunction  34 
  
 metafunction forwarding  279 
  
 move assignment operator 
  
  
 defining  504 
  
 move-construct  169 
  
 move emulation 
  
  
 Boost.Move library, using  507-510 
 multi-criteria lookups 
  
  
 containers  228, 229 
  
 multi-index containers 
  
  
 defining  230, 231 
  
 Multiple Readers Single Writer 
  
  
 (MRSW) model  419 
  
 MutableBufferSequence  453 
  
 mutex 
  
  
 about  403 
  
  
 using  403-405
  
 [
  527 
 ]",NA
N,"Named Return Value Optimization 
  
   
 (NRVO)  506 
  
 native format  337 
  
 netmask  442 
  
 network I/O, using Asio 
  
  
 about  441 
  
  
 Asio deadline timer  455-457 
  
  
 asynchronous communication  455 
  
  
 asynchronous logic, using Asio 
  
   
  coroutines  458-461 
  
  
 buffers  452 
  
  
 domain names  449 
  
  
 endpoints  448 
  
  
 hostnames  449 
  
  
 IP addresses  442 
  
  
 name resolution  449-451 
  
  
 ports  448 
  
  
 sockets  448, 449 
  
  
 synchronous communication  455 
  
  
 TCP  441, 474 
  
  
 UDP  441, 461 
  
 non-capturing sub-expressions  155 
  
 nonmemory resources 
  
  
 managing, smart pointers used  114, 115 
 nonstandard containers 
  
  
 about  172 
  
  
 flat associative containers  172-175 
  
  
 slist  175, 176 
  
  
 slist, splicing operation  177-180 
  
  
 stable_vector  181-184 
  
  
 static_vector  184-186 
  
 normalized absolute path  341 
  
 nullary  253 
  
 Null Object Pattern 
  
  
 URL  202",NA
O,"operations, performing on files 
 about  354 
  
 directories, creating  354, 355
  
  
 files, copying  356, 357 
  
  
 files, deleting  358 
  
  
 files, moving  358 
  
  
 path-aware fstreams  358 
  
  
 symbolic links, creating  355, 356 
 output filter  359",NA
P,"parallelism  377 
  
 parent path  342 
  
 parser expressions  299, 300 
  
 parser operators  297-300 
  
 parsing directives  301 
  
 parsing timestamps  305-307 
  
 partial function application  262-266 
 partial specializations  269 
  
 passive endpoints  455 
  
 Pimpl Idiom  86 
  
 Pipable concept  371 
  
 Plain Old Data (POD) types  34 
  
 pointer containers 
  
  
 null pointers  202, 203 
  
  
 ownership semantics  197-201 
  
 pointers 
  
  
 versus Boost.Optional  30 
  
 poll member function  432 
  
 poll_one member function  432 
  
 ports  448 
  
 Posix time 
  
  
 about  316 
  
  
 resolution  318, 319 
  
  
 time iterator  321, 322 
  
  
 time periods  320, 321 
  
  
 time points and durations, 
  
   
 constructing  316-318 
  
 predefined parsers  297 
  
 Predef library 
  
  
 about  70 
  
  
 diagnostic macros, using  70-72 
  
 predicates  252 
  
 preprocessor macros 
  
  
 using  69-72 
  
 primary template  268 
  
 producer-consumer problem  412, 
 413 program performance 
  
  
 auto_cpu_timer  332
  
 [
  528 
 ]",NA
Q,"Qi parsing API  297, 298 
  
 quantifiers  153",NA
R,"RAII 
  
  
 about  78, 79, 406, 493, 494 
  
  
 implementing  494, 495 
  
 range  122 
  
 range adaptors  133 
  
 range-based for-loops 
  
  
 about  513 
  
  
 Boost.Foreach  514 
  
 range declaration  514 
  
 range lookups 
  
  
 using  235, 236 
  
 Readers-Writers problem  417-421 
  
 read-preferring solutions  422 
  
 recursive variants 
  
  
 defining  41, 42 
  
  
 JSON content, representing  43, 44 
  
  
 visiting  45-47 
  
 regular expressions 
  
  
 Boost.Regex, using  152 
  
  
 parsing, with Boost.Regex  155, 156 
  
 syntax  152 
  
 regular expressions syntax 
  
  
 anchors  154 
  
  
 atoms  152 
  
  
 character class  154 
  
  
 disjunctions  155 
  
  
 quantifiers  153 
  
  
 sub-expressions  154, 155 
  
 relative path  342 
  
 replace and erase algorithms 
  
  
 for text processing  136 
  
 Representation type parameter  323 
 resolver  449 
  
 Resource Acquisition Is 
  
   
 Initialization. 
 See
   RAII 
  
 Return Value Optimization (RVO)  506 
 root directory  342, 343
  
 root name  338, 343 
  
 root path  343 
  
 Rule of Three  497 
  
 Rule of Zero  497 
  
 run function  432 
  
 run_one member function  432 
  
 Runtime Type Identification (RTTI)  47 
 rvalue expressions  501 
  
 rvalue references 
  
  
 about  501, 502 
  
  
 move assignment  504 
  
  
 overloads  503 
  
  
 xvalues  505, 506",NA
S,"scoped_ptr 
  
  
 about  84 
  
  
 exception-safe scopes, creating  84 
  
  
 object ownership across functions, 
  
   
 transferring  85 
  
  
 uses  84 
  
  
 using, as class member  85-90 
  
 semantic actions  301-303 
  
 sequence expression  514 
  
 shallow copy  497 
  
 shared_array  113 
  
 shared data, managing 
  
  
 about  386 
  
  
 concurrent tasks, coordinating  386, 387 
  
 concurrent tasks, creating  386, 387 
  
  
 lock-based thread synchronization 
  
   
 methods  400 
  
 shared_mutex 
  
  
 about  422 
  
  
 performance  422 
  
 shared ownership semantics 
  
  
 about  96 
  
  
 boost::intrusive_ptr  109, 110 
  
  
 boost::shared_ptr  96, 97 
  
  
 shared_array  113 
  
  
 std::shared_ptr  97, 98 
  
 shared_ptr 
  
  
 dynamically-allocated objects, storing in 
   
 Standard Library containers  100-102 
  
 used, as class member  99, 100 
  
  
 uses  99
  
 [
  529 
 ]",NA
T,"tagged layout  7 
  
 task execution, with Asio 
  
  
 about  430 
  
  
 concurrent execution, via 
  
   
 thread pools  434, 435 
  
  
 handlers  431 
  
  
 handler states  432 
  
  
 IO Service  430 
  
  
 io_service::work  436, 437 
  
  
 post, versus dispatch  432, 433 
  
  
 queues  431 
  
  
 serialized and ordered execution, 
  
   
 via strands  437-440 
  
 TCP 
  
  
 about  441, 474 
  
  
 asynchronous TCP server  480 
  
  
 concurrency  479 
  
  
 performance  479 
  
  
 synchronous TCP client  475, 476 
  
  
 synchronous TCP server  477, 478 
  
  
 TCP connection, establishing  474 
  
 TCP 3-way handshake  474 
  
 TCP client  474 
  
 TCP connection 
  
  
 client- and server-side calls  474 
  
 TCP server  474 
  
 TCP socket  499 
  
 Technical Report 1 (TR1)  106 
  
 tee device  372 
  
 template identifier  268 
  
 template metaprogramming  249 
  
 text processing 
  
  
 with Boost String Algorithms 
  
   
 library  120-124 
  
  
 with case-conversion algorithms  133, 134 
  
 with replace and erase algorithms  136 
  
 with split and join algorithms  137, 138 
  
 with trimming algorithms  133-135
  
 [
  530 
 ]",NA
U,"UDP 
  
  
 about  441, 461 
  
  
 asynchronous UDP server  464 
  
  
 asynchronous UDP server, using 
  
   
 completion handler chains  464-467 
  
 asynchronous UDP server, using 
  
   
 coroutines  467-469 
  
  
 caveats  441 
  
  
 concurrency  470-473 
  
  
 performance  470-473 
  
  
 synchronous UDP client  461-463 
  
  
 synchronous UDP server  464 
  
 unique ownership semantics 
  
  
 about  81
  
  
 boost::scoped_array  90, 91 
  
  
 boost::scoped_ptr  81-83 
  
  
 std::unique_ptr  92 
  
 unique_ptr 
  
  
 arrays, wrapping  94, 95 
  
  
 make_unique, in C++14  95 
  
  
 used, for ownership transfer  92, 93 
 universal assignment operator 
  
  
 defining  504 
  
 Unix time  353 
  
 unspecified address  443 
  
 unstable container  182 
  
 upgradable locks  421 
  
 User Datagram Protocol. 
 See
   UDP",NA
V,"vectored I/O 
  
  
 about  453 
  
  
 buffer sequences for  453 
  
 versioned layout  6",NA
W,"wildcard  152 
  
 Windows 
  
  
 Boost binary distribution, installing  8 
  
 Boost libraries, building on  13, 14 
  
 Boost libraries, linking against  17-19 
 Windows toolchain  4 
  
 write-preferring solutions  422",NA
X,xvalues  505,NA
Z,"Zlib library 
  
 URL  10
  
 [
  531 
 ]",NA
Thank you for buying ,NA,NA
Learning Boost C++ Libraries,NA,NA
About Packt Publishing,"Packt, pronounced 'packed', published its first book, 
 Mastering phpMyAdmin for Effective MySQL 
 Management
 , in April 2004, and subsequently continued to specialize in publishing highly 
 focused books on specific technologies and solutions.
  
 Our books and publications share the experiences of your fellow IT professionals in adapting and 
 customizing today's systems, applications, and frameworks. Our solution-based books give you the 
 knowledge and power to customize the software and technologies you're using to get the job done. 
 Packt books are more specific and less general than the IT books you have seen in the past. Our 
 unique business model allows us to bring you more focused information, giving you more of what 
 you need to know, and less of what you don't.
  
 Packt is a modern yet unique publishing company that focuses on producing quality, 
 cutting-edge books for communities of developers, administrators, and newbies alike. For 
 more information, please visit our website at 
 www.packtpub.com
 .",NA
Writing for Packt,"We welcome all inquiries from people who are interested in authoring. Book proposals should be 
 sent to 
 author@packtpub.com
 . If your book idea is still at an early stage and you would like to 
 discuss it first before writing a formal book proposal, then please contact us; one of our 
 commissioning editors will get in touch with you. 
  
 We're not just looking for published authors; if you have strong technical skills but no writing 
 experience, our experienced editors can help you develop a writing career, or simply get some 
 additional reward for your expertise.",NA
Boost C++ Application ,NA,NA
Development Cookbook,"ISBN:  978-1-84951-488-0            Paperback: 348 pages
  
 Over 80 practical, task-based recipes to create 
 applications using Boost libraries
  
 1. 
  
 2. 
  
 Explores how to write a program once and then 
 use it on Linux, Windows, MacOS, and Android 
 operating systems.
  
 Take advantage of the real power of Boost and 
 C++ to get a good grounding in using it in any 
 project.",NA
Boost.Asio C++ Network ,NA,NA
Programming,"ISBN: 978-1-78216-326-8            Paperback: 156 pages
  
 Enhance your skills with practical examples for 
 C++ network programming
  
 1. 
  
 2. 
  
 3. 
  
 4. 
  
 Augment your C++ network programming 
 using Boost.Asio.
  
 Discover how Boost.Asio handles synchronous 
 and asynchronous programming models.
  
 Practical examples of client/server applications.
  
 Learn how to deal with threading when writing 
 network applications.
  
  
 Please check 
 www.PacktPub.com
  for information on our titles",NA
C++ Multithreading Cookbook,"ISBN: 978-1-78328-979-0             Paperback: 422 pages
  
 Over 60 recipes to help you create ultra-fast 
 multithreaded applications using C++ with 
 rules, guidelines, and best practices
  
 1. 
  
 2. 
  
 3. 
  
 4. 
  
 Create multithreaded applications using 
 the power of C++.
  
 Upgrade your applications with parallel 
 execution in easy-to-understand steps.
  
 Stay up to date with new Windows 8 
 concurrent tasks.
  
 Avoid classical synchronization problems.",NA
Getting Started with C++ ,NA,NA
Audio Programming for ,NA,NA
Game Development,"ISBN: 978-1-84969-909-9            Paperback: 116 pages
  
 A hands-on guide to audio programming in 
  
 game development with the FMOD audio library 
 and toolkit
  
 1. 
  
 2. 
  
 3. 
  
 Add audio to your game using FMOD and 
 wrap it in your own code.
  
 Understand the core concepts of audio 
 programming and work with audio at 
 different levels of abstraction.
  
 Work with a technology that is widely 
 considered to be the industry standard 
 in audio middleware.
  
  
 Please check 
 www.PacktPub.com
  for information on our titles",NA
