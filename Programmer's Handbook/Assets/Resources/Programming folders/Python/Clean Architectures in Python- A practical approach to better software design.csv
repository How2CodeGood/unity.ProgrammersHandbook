Larger Text,Smaller Text,Symbol
Clean Architectures in Python,NA,NA
A practical approach to better software design,NA,NA
Leonardo Giordani,"This book is for sale at
  http://leanpub.com/clean-architectures-in-python
  
 This version was published on 2020-04-13
  
  
 This is a
  Leanpub
  book. Leanpub empowers authors and publishers with the Lean 
 Publishing process.
  Lean Publishing
  is the act of publishing an in-progress ebook using 
 lightweight tools and many iterations to get reader feedback, pivot until you have the right 
 book and build traction once you do.
  
 © 2018 - 2020 Leonardo Giordani",NA
Tweet This Book!,"Please help Leonardo Giordani by spreading the word about this book on
  Twitter
 !
  
 The suggested hashtag for this book is
  #pycabook
 .
  
 Find out what other people are saying about the book by clicking on this link to search 
 for this hashtag on Twitter: 
  
 #pycabook",NA
Contents,"Introduction
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
 1 
  
 What is a software architecture? 
  
 . 
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
 2 
  
 Why is it called “clean” architecture? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
 3 
  
  
  
  
  
 4 Why Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 Acknowledgments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
 4
  
 About the book
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
 6 
  
 A brief history of this book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 6 
  
 How this book is structured . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 7 
  
 Typographic conventions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 7 
  
 Why this book comes for free . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 7 
  
 Submitting issues or patches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 8 
  
 About the author . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 8
  
 Setup a Python Project
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 9 
  
 Virtual environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
  
 9 
  
 Python projects with Cookiecutter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
 10",NA
Part 1 - Tools,. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .,NA
 12,"Chapter 1 - Introduction to TDD
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
 13",NA
Part 2 - The clean ,NA,NA
architecture,. . . . . . . . . . . . . . . . . . . . . . .,NA
 78,"Chapter 1 - Components of a clean architecture
  . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
 79 
  
 Layers and data flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 79 
  
 Main layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 79 
  
 APIs and shades of grey . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 81
  
 Chapter 2 - A basic example
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 82 
  
 Project overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 82 
  
 Project setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 83 
  
 Domain models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 83 
  
 Serializers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
  
  
 87",NA
Part 3 - Appendices,. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .,NA
167,"Changelog
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  168",NA
Introduction,"Learn about the Force, Luke.
  
 • Star Wars (1977)
  
 This book is about a software design methodology. A methodology is a set of guidelines that 
 help you reach your goal effectively, thus saving time, implementing far-sighted solutions, 
 and avoiding the need to reinvent the wheel time and again.
  
 As other professionals around the world face problems and try to solve them, some of 
 them, having discovered a good way to solve a problem, decide to share their experience, 
 usually in the form of a “best practices” post on a blog, or talk at a conference. We also 
 speak of
  patterns
 ¹
 , which are formalised best practices, and
  anti-patterns
 , when it comes to 
 advice about what not to do and why it is better to avoid a certain solution.
  
 Often, when best practices encompass a wide scope, they are designated a
  methodology
 . 
 The definition of a methodology is to convey a method, more than a specific solution to a 
 problem. The very nature of methodologies means they are not connected to any specific 
 case, in favour of a wider and more generic approach to the subject matter. This also means 
 that applying methodologies without thinking shows that one didn’t grasp the nature of a 
 methodology, which is to help to find a solution and not to provide it.
  
 This is why the main advice I have to give is: be reasonable; try to understand why a 
 methodology leads to a solution and adopt it if it fits your need. I’m saying this at the very 
 beginning of this book because this is how I’d like you to approach this work of mine.
  
 The clean architecture, for example, pushes abstraction to its limits. One of the main 
 concepts is that you should isolate parts of your system as much as possible, so you can 
 replace them without affecting the rest. This requires a lot of abstraction layers, which 
 might affect the performances of the system, and which definitely require a greater initial 
 development effort. You might consider these shortcomings unacceptable, or perhaps be 
 forced to sacrifice cleanliness in favour of execution speed, as you cannot afford to waste 
 resources.
  
 In these cases, break the rules. You are always free to keep the parts you consider useful 
 and discard the rest, but if you have understood the reason behind the methodology, you 
 will also know why you do something different. My advice is to keep track of such reasons, 
 either in design documents
  
 ¹
 from the seminal book “Design Patterns: Elements of Reusable Object-Oriented Software” by Gamma, Vlissides, Johnson, and Helm.",NA
What is a software architecture?,"Every production system, be it a software package, a mechanical device, or a simple 
 procedure, is made of components and connections between them. The purpose of the 
 connections is to use the output of some components as inputs of other components, in 
 order to perform a certain action or set of actions.
  
 In a process, the architecture specifies which components are part of an implementation 
 and how they are interconnected.
  
 A simple example is the process of writing a document. The process, in this case, is the 
 conversion of a set of ideas and sentences into a written text, and it can have multiple 
 implementations. A very simple one is when someone writes with a pen on a sheet of 
 paper, but it might become more complex if we add someone who is writing what another 
 person dictates, multiple proof readers who can send back the text with corrections, and a 
 designer who curates the visual rendering of the text. In both cases the process is the same, 
 and the nature of inputs (ideas, sentences) and outputs (a document or a book) doesn’t 
 change. The different architecture, however, can greatly affect the quality of the output, or 
 the speed with which it is produced.
  
 An architecture can have multiple granularities, which are the “zoom level” we use to look 
 at the components and their connections. The first level is the one that describes the whole 
 process as a black box with inputs and outputs. At this level we are not even concerned 
 with components, we don’t know what’s inside the system and how it works. We only know 
 what it does.
  
 As you zoom in, you start discovering the details of the architecture, that is, which 
 components are in the aforementioned black box and how they are connected. These 
 components are in turn black boxes, and you don’t want to know specifically how they 
 work, but you want to know what their input and outputs are, where the inputs come from, 
 and how the outputs are used by other components.
  
 This process is virtually unlimited, so there is never one single architecture that describes a 
 complete system, but rather a set of architectures, each one covering the granularity we are 
 interested in.
  
 Let me give you a very simple example that has nothing to do with software. Let’s consider 
 a shop as a system and let’s discuss its architecture.",NA
Why is it called “clean” architecture?,"The architecture explained in this book has many names, but the one that is mainly in use 
 nowadays is “clean architecture”. This is the name used by Robert Martin in
  his seminal 
 post²
  where he clearly states this structure is not a novelty, but has been promoted by 
 many software designers over the years. I believe the adjective “clean” describes one of the 
 fundamental aspects of both the software structure and the development approach of this 
 architecture. It is clean, that is, it is easy to understand what happens.
  
 ²
 http://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html",NA
Why Python?,"I have been working with Python for 20 years, along with other languages, but I came to 
 love its simplicity and power and so I ended up using it on many projects. When I was first 
 introduced to the clean architecture I was working on a Python application that was meant 
 to glue together the steps of a processing chain for satellite imagery, so my journey with the 
 concepts I will explain started with this language.
  
 I will therefore speak of Python in this book, but the main concepts are valid for any other 
 language, especially object-oriented ones. I will not introduce Python here, so a minimal 
 knowledge of the language syntax is needed to understand the examples and the projects I 
 will discuss.
  
 The clean architecture concepts are independent from the language, but the 
 implementation obviously leverages what a specific language allows you to do, so this book 
 is about the clean architecture and an implementation of it that I devised using Python. I 
 really look forward to seeing more books about the clean architecture that explore other 
 implementations in Python and in other languages.",NA
Acknowledgments,"• Eleanor de Veras, who proofread the introduction.
  
 • Roberto Ciatti, who introduced me to clean architectures.
  
 • Max H. Gerlach, Paul Schwendenman, Eric Smith, Grant Moore, Hans Chen, Ramces 
 Chirino 
  
 who fixed typos and bad grammar submitting issues and pull requests.
  
 • Faust Gertz and Michael O’Neill for spotting a bug in the code of the
  calc
  example. Fixing 
 that 
  
 and adding the test to the book is the best example of TDD I could give to the 
 readers.
  
 • Łukasz Dziedzic, who developed the free “Lato” font (
 Latofonts³
 ), used for the cover.",NA
About the book,"We’ll put the band back together, do a few gigs, we get some bread. Bang! Five thousand 
 bucks.
  
 • The Blues Brothers (1980)",NA
A brief history of this book,"In 2015 I was introduced to the clean architecture by Roberto Ciatti. I started working with 
 him following a strict Test-Driven Development (TDD) approach and learning or better 
 understanding many things I consider pillars of my programming knowledge now.
  
 Unfortunately the project was cancelled, but the clean architecture concepts stuck with me, 
 so I revisited them for a simple open source project I started working on at the time
  ⁵
 . 
 Meanwhile I read“Object Oriented Software Engineering: A Use-Case Driven Approach” by 
 Ivar Jacobson
 ⁶
 .
  
 In 2013 I started writing a personal blog,
  The Digital Cat⁷
 , and after having published many 
 Python-related posts I began working on a post to show other programmers the beauty of 
 the clean architecture concepts: “Clean Architectures in Python: a step by step example”, 
 published in 2016, which was well received by the Python community. For a couple of 
 years I considered expanding the post, but I couldn’t find the time to do it, and in the 
 meanwhile I realised that many things I had written needed to be corrected, clarified, or 
 simply updated.
  
 I also saw that other posts of mine could clarify parts of the methodology used in 
 developing a project based on the clean architecture, such as the introduction to TDD. So I 
 thought that a book could be the best way to present the whole picture effectively, and here 
 we are.
  
 This book is the product of many hours’ thinking, experimenting, studying, and making 
 mistakes. I couldn’t have written it without the help of many people, some of whose names 
 I don’t know, who provided free documentation, free software, free help.
  
 Errors: be aware there will be many. I’m not a native English speaker and a friend kindly 
 proofread the opening, less technical chapters, trying to mitigate the worst errors. In the 
 future I may consider having it reviewed by a professional. For now I can only apologise in 
 advance for my mistakes and hope you will nevertheless enjoy the book and be able to use 
 it effectively.",NA
How this book is structured,"This book is divided into two parts.
  
 The first part is about
  Test-driven Development (TDD)
 , a programming technique that 
 will help you develop more reliable and easily modifiable software. I will first guide you 
 through a
  very simple example
  in chapter 1, demonstrating how to use TDD to approach a 
 project, and how to properly create tests from requirements. In chapter 2 I will then 
 discuss
  unit testing
  from a more theoretical point of view, categorising functions and their 
 tests. Chapter 3 will introduce
  mocks
 , a powerful tool that helps to test complex scenarios.
  
 The second part introduces
  the clean architecture
 . The first chapter discusses briefly the
  
 compo-nents
  and the ideas behind this software structure, while chapter 2 runs through
  a 
 concrete example 
 of clean architecture for a very simple web service. Chapter 3 discusses
  
 error management
  and improvements to the Python code developed in the previous 
 chapter. Finally, chapter 4 shows how to plug
  different database systems
  to the web 
 service created previously.",NA
Typographic conventions,"This book uses Python, so the majority of the code samples will be in this language, either
  
 inline 
 or in a specific code block
  
 def
  example
 ():
  
 print
 (
 ""This is a code block""
 )
  
 Code blocks don’t include line numbers, as the part of code that are being discussed are 
 usually repeated in the text. This also makes it possible to copy the code from the PDF 
 directly.
  
  
  
 This aside provides the link to the repository tag that contains the code that was 
 presented
  
 This is a recap of a rule that was explained and exemplified",NA
Why this book comes for free,NA,NA
Submitting issues or patches,"This book is not a collaborative effort. It is the product of my work, and it expresses my 
 personal view on some topics, and also follows my way of teaching. Both can definitely be 
 improved, and they might also be wrong, so I am open to suggestions, and I will gladly 
 receive any report about mistakes or any request for clarifications. Feel free to use the 
 GitHub Issues of the
  book repository⁸
 or of the projects presented in the book. I will answer 
 or fix issues as soon as possible, and if needed I will publish a new version of the book with 
 the correction. Thanks!",NA
About the author,"My name is Leonardo Giordani, I was born in 1977 with Star Wars, bash, Apple ][, BSD, Dire 
 Straits, The Silmarillion. I’m interested in operating systems and computer languages, 
 photography, fantasy and science fiction, video and board games, guitar playing, and (too) 
 many other things.
  
 I studied and used several programming languages, from the Z80 and x86 Assembly to 
 Python and Scala. I love mathematics and cryptography. I’m mainly interested in open 
 source software, and I like both the theoretical and practical aspects of computer science.
  
 For 13 years I was a C/Python programmer and devops for a satellite imagery company. 
 and I am currently infrastructure engineer at
  WeGotPOP⁹
 , a UK company based in London 
 and New York that creates innovative software for film productions.
  
 In 2013 I started publishing some technical thoughts on my blog,
  The Digital Cat¹⁰
 .
  
 ⁸
 https://github.com/pycabook/pycabook/is
 sues",NA
Setup a Python Project,"Snakes. Why did it have to be snakes?
  
 • Raiders of the Lost Ark (1981)",NA
Virtual environments,"One of the first things you have to learn as a Python programmer is how to create, manage, 
 and use your virtual environments. A virtual environment is just a directory (with many 
 subdirectories) that mirrors a Python installation like the one that you can find in your 
 operating system. This is a good way to isolate a specific version of Python and the 
 packages that are not part of the standard library.
  
 This is handy for many reasons. First of all, the Python version installed system-wide (your 
 Linux distribution, your version of Mac OS, Windows, or other operating system) shouldn’t 
 be tampered with. That Python installation and its modules are managed by the maintainer 
 of the operating system, and in general it’s not a good idea to make changes there unless 
 you are certain of what you are doing. Having a single personal installation of Python, 
 however, is usually not enough, as different projects may have different requirements. For 
 example, the newest version of a package might break the API compatibility and unless we 
 are ready to move the whole project to the new API, we want to keep the version of that 
 package fixed and avoid any update. At the same time another project may require the 
 bleeding edge or even a fork of that package: for example when you have to patch a security 
 issue, or if you need a new feature and can’t wait for the usual release cycle that can take 
 weeks.
  
 Ultimately, the idea is that it is cheaper and simpler (at least in 2018) to copy the whole 
 Python installation and to customise it than to try to manage a single installation that 
 satisfies all the requirements. It’s the same advantage we have when using virtual 
 machines, but on a smaller scale.
  
 The starting point to become familiar with virtual environments is the
  official 
 documentation¹¹
 , but if you experience issues with a specific version of your operating 
 system you will find plenty of resources on Internet that may clarify the matter.
  
 In general, my advice is to have a different virtual environment for each Python project. You 
 may prefer to keep them inside or outside the project’s directory. In the latter case the 
 name of the",NA
Python projects with Cookiecutter,"Creating a Python project from scratch is not easy. There are many things to configure and I 
 would only suggest manually writing all the files if you strongly need to understand how 
 the Python distribution code works. If you want to focus on your project, instead, it’s better 
 to use a template.
  
 Cookiecutter¹⁷
  is a simple but very powerful Python software created by Audrey Roy 
 Greenfeld. It creates directories and files with a template, and can create very complex set-
 ups, asking you a mere handful of questions. There are already templates for Python 
 (obviously), C, Scala, LaTeX, Go, and other languages, and creating your own template is 
 very simple.
  
 The
  official Python template¹⁸
  is maintained by the same author of Cookiecutter. Other 
 Python templates with different set-ups or that rely on different tools are available, and 
 some of them are linked in the Cookiecutter README file.
  
 I maintain
  a Python project template¹⁹
  that I will use throughout the book. You are not 
 required to use it, actually I encourage you to fork it and change what you don’t like as soon 
 as you get comfortable with the structure and the role that the various files have.
  
 These templates work perfectly for open source projects. If you are creating a closed source 
 project you will not need some of the files (like the license or the instructions for 
 programmers who want to collaborate), but you can always delete them once you have 
 applied the template. If you need to do this more than once, you can fork the template and 
 change it to suit your needs.
  
 ¹²
 https://virtualenvwrapper.readthedocs.io/en/latest/
  
 ¹³
 https://git-scm.com/docs/gitignore
  
 ¹⁴
 https://docs.pytest.org/en/latest/reference.html#confval-
 norecursedirs
 ¹⁵
 https://pipenv.readthedocs.io/en/latest/
  
 ¹⁶
 https://packaging.python.org/guides/tool-recommendations/",NA
Part 1 - Tools,NA,NA
Chapter 1 - Introduction to TDD,"Why worry? Each one of us is wearing an unlicensed nuclear accelerator on his back.
  
 • Ghostbusters (1984)",NA
Introduction,"“Test-Driven Development” (TDD) is fortunately one of the names that I can spot most 
 frequently when people talk about methodologies. Unfortunately, many programmers still 
 do not follow it, fearing that it will impose a further burden on the already difficult life of 
 the developer.
  
 In this chapter I will try to outline the basic concept of TDD and to show you how your job 
 as a programmer can greatly benefit from it. I will develop a very simple project to show 
 how to practically write software following this methodology.
  
 TDD is a methodology, something that can help you to create better code. But it is not going 
 to solve all your problems. As with all methodologies you have to pay attention not to 
 commit blindly to it. Try to understand the reasons why certain practices are suggested by 
 the methodology and you will also understand when and why you can or have to be 
 flexible.
  
 Keep also in mind that testing is a broader concept that doesn’t end with TDD. This latter 
 focuses a lot on unit testing, which is a specific type of test that helps you to develop the API 
 of your library/package. There are other types of tests, like integration or functional ones, 
 that are not specifically part of the TDD methodology, strictly speaking, even though the 
 TDD approach can be extended to any testing activity.",NA
A real-life example,"Let’s start with a simple example taken from a programmer’s everyday life.
  
 The programmer is in the office with other colleagues, trying to nail down an issue in some 
 part of the software. Suddenly the boss storms into the office, and addresses the 
 programmer:
  
 Boss
 : I just met with the rest of the board. Our clients are not happy, we didn’t fix enough 
 bugs in the last two months.",NA
A simple TDD project,"The project we are going to develop is available at https://github.com/pycabook/calc
  
 This project is purposefully extremely simple. You don’t need to be an experienced Python 
 programmer to follow this chapter, but you need to know the basics of the language. The 
 goal of this chapter is not that of making you write the best Python code, but that of 
 allowing you learn the TDD work flow, so don’t be too worried if your code is not perfect.
  
 Methodologies are like sports: you cannot learn them just by reading their description on a 
 book. You have to practice them. Thus, you should avoid as much as possible to just follow 
 this chapter reading the code passively. Instead, you should try to write the code and to try 
 new solutions to the problems that I discuss. This is very important, as it actually makes 
 you use TDD. This way, at the end of the chapter you will have a personal experience of 
 what TDD is like.",NA
Setup the project,"Following the instructions that you can find in the first chapter, create a virtual 
 environment for the project, install Cookiecutter, and then create a project using the 
 recommended template. I named the project
  calc
 , but you are free to give it another name. 
 After you created the project, enter the directory and install the requirements with
  pip install 
 -r requirements/dev.txt
 ²²
 . You should be able to run
  
 ²²
 this project template defines 3 different requirements files,
  prod.txt
 ,
  test.txt
 , and
  dev.txt
 , in hierarchical order.
  test.txt
  includes 
 prod.txt
 , and
  dev.txt
  includes
  test.txt
 . The reason is that when you test you want to be able to run the system with its production",NA
Requirements,"The goal of the project is to write a class
  Calc
  that performs calculations: addition, 
 subtraction, multiplication, and division. Addition and multiplication shall accept multiple 
 arguments. Division shall return a float value, and division by zero shall return the string
  
 ""inf""
 . Multiplication by zero must raise a
  ValueError
  exception. The class will also provide a 
 function to compute the average of an iterable like a list. This function gets two optional 
 upper and lower thresholds and should remove from the computation the values that fall 
 outside these boundaries.
  
 As you can see the requirements are pretty simple, and a couple of them are definitely not 
 “good”requirements, like the behaviour of division and multiplication. I added those 
 requirements for the sake of example, to show how to deal with exceptions when 
 developing in TDD.",NA
Step 1 - Adding two numbers,NA,NA
Step 2 - Adding three numbers,"The requirements state that “Addition and multiplication shall accept multiple arguments”. 
 This means that we should be able to execute not only
  add(4, 5)
  like we did, but also
  add(4, 5,",NA
Step 3 - Adding multiple numbers,"The requirements are not yet satisfied, however, as they mention “multiple” numbers and 
 not just three. How can we test that we can add a generic amount of numbers? We might 
 add a
  test_add_-four_numbers
 , a
  test_add_five_numbers
 , and so on, but this will cover specific cases 
 and will never cover all of them. Sad to say, it is impossible to test that generic condition, 
 or, at least in this case, so complex that it is not worth trying to do it.
  
 What you shall do in TDD is to test boundary cases. In general you should always try to find 
 the so-called “corner cases” of your algorithm and write tests that show that the code 
 covers them. For example, if you are testing some code that accepts inputs from 1 to 100, 
 you need a test that runs it with a generic number like 42
 ²⁵
 , but you definitely want to have 
 a specific test that runs the algorithm with the number 1 and one that runs with the 
 number 100. You also want to have tests that show the algorithm doesn’t work with 0 and 
 101 arguments, but we will talk later about testing error conditions.
  
 In our example there is no real limitation to the number of arguments that you pass to your 
 function. Before Python 3.7 there was a limit of 256 arguments, which has been removed in 
 that version of the language, but these are limitations enforced by an external system
 ²⁶
 , 
 and they are not real boundaries of your algorithm.
  
 ²⁴
 https://github.com/pycabook/calc/tree/step-2-adding-three-
 numbers
  
 ²⁵
 which is far from being generic, but don’t panic!
  
 ²⁶
 the definition of “external system” obviously depends on what you are testing. If you are implementing a programming 
 language you want to have tests that show how many arguments you can pass to a function, or that check the amount of memory",NA
Step 4 - Subtraction,"From the requirements we know that we have to implement a function to subtract 
 numbers, but this doesn’t mention multiple arguments (as it would be complex to define 
 what subtracting 3 of more numbers actually means). The tests that implements this 
 requirements is
  
 def
  test_subtract_two_numbers
 ():
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 sub(
 10
 ,
  3
 )
  
 assert
  res
  == 7
  
 which doesn’t pass with the following error
  
 ²⁸
 https://github.com/pycabook/calc/tree/step-3-adding-multiple-numbers
  
 ²⁹
 yes, you can test it running a function and measuring the execution time. This however, depends too much on external conditions, 
 so typically performance testing is done in a completely different way.",NA
Step 5 - Multiplication,"It’s time to move to multiplication, which has many similarities to addition. The 
 requirements state that we have to provide a function to multiply numbers and that this 
 function shall allow us to multiply multiple arguments. In TDD you should try to tackle 
 problems one by one, possibly dividing a bigger requirement in multiple smaller ones.
  
 In this case the first test can be the multiplication of two numbers, as it was for addition.
  
 def
  test_mul_two_numbers
 (): 
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 mul(
 6
 ,
  4
 )
  
 assert
  res
  == 24
  
 And the test suite fails as expected with the following error",NA
Step 6 - Refactoring,"Previously, I introduced the concept of refactoring, which means changing the code without 
 altering the results. How can you be sure you are not altering the behaviour of your code? 
 Well, this is what the tests are for. If the new code keeps passing the test suite you can be 
 sure that you didn’t remove any feature
 ³⁵
 .
  
 This means that if you have no tests you shouldn’t refactor. But, after all, if you have no 
 tests you shouldn’t have any code, either, so refactoring shouldn’t be a problem you have. If 
 you have some code without tests (I know you have it, I do), you should seriously consider 
 writing tests for it, at least before changing it. More on this in a later section.
  
 For the time being, let’s see if we can work on the code of the
  Calc
  class without altering the 
 results. I do not really like the definition of the
  mul2
  function inside the
  mul
  one. It is 
 obviously perfectly fine and valid, but for the sake of example I will pretend we have to get 
 rid of it.
  
 Python provides support for anonymous functions with the
  lambda
  operator, so I might 
 replace the 
 mul
  code with
  
 from
  functools
  import
  reduce
  
 class
  Calc
 :
  
 [
 ...
 ]
  
 def
  mul
 (
 self
 ,
  *
 args):
  
 return
  reduce
 (
 lambda
  x, y: x
 *
 y, args)
  
  
 Git tag:
  step-6-refactoring³⁶
  
 where I define an anonymous function that accepts two inputs
  x, y
  and returns their 
 multiplication 
 x*y
 . Running the test suite I can see that all the test pass, so my refactoring is 
 correct.
  
  
 TDD rule number 6 
  
 Never refactor without 
 tests.
  
 ³⁵
 In theory, refactoring shouldn’t add any new behaviour to the code, as it should be an idempotent transformation. There is no 
 real practical way to check this, and we will not bother with it now. You should be concerned with this if you are discussing security, 
 as your code shouldn’t add any entry point you don’t want to be there. In this case you will need tests that check not the presence of 
 some feature, but the absence of them.",NA
Step 7 - Division ,"The requirements state that there shall be a division function, and that it has to return a 
 float value. This is a simple condition to test, as it is sufficient to divide two numbers that do 
 not give an integer result 
  
 def
  test_div_two_numbers_float
 ():
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 div(
 13
 ,
  2
 )
  
 assert
  res
  == 6.5
  
 The test suite fails with the usual error that signals a missing method. The implementation 
 of this function is very simple as the
  /
  operator in Python performs a float division 
  
 class
  Calc
 :
  
 [
 ...
 ]
  
 def
  div
 (
 self
 , a, b):
  
 return
  a
  /
  b
  
  
 Git tag:
  step-7-float-division³⁷
  
 If you run the test suite again all the test should pass. There is a second requirement about 
 this operation, however, that states that division by zero shall return the string
  ""inf""
 . Now, 
 this is obviously a requirement that I introduced for the sake of giving some interesting and 
 simple problem to solve with TDD, as an API that returns either floats or strings is not 
 really the best idea.
  
 The test that comes from the requirement is 
 simple 
 def
  test_div_by_zero_returns_inf
 ():
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 div(
 5
 ,
  0
 )
  
 assert
  res
  ==
  ""inf""",NA
Step 8 - Testing exceptions,"A further requirement is that multiplication by zero must raise a
  ValueError
  exception. This 
 means that we need a way to test if our code raises an exception, which is the opposite of 
 what we did until now. In the previous tests, the condition to pass was that there was no 
 exception in the code, while in this test the condition will be that an exception has been 
 raised.
  
 Pytest provides a
  raises
  context manager that runs the code contained in it and passes only if 
 the given exception is produced by that code.
  
 import
  pytest
  
 [
 ...
 ]
  
 def
  test_mul_by_zero_raises_exception
 ():
  
 c
  =
  Calc()
  
 with
  pytest
 .
 raises(
 ValueError
 ):
  
 c
 .
 mul(
 3
 ,
  0
 )
  
 In this case, thus, pytest runs the line
  c.mul(3, 0)
 . If it doesn’t raise the
  ValueError
  exception the 
 test will fail. Indeed, if you run the test suite now, you will get the following failure
  
 ________________________ test_mul_by_zero_raises_exception ________________________
  
 def test_mul_by_zero_raises_exception():
  
 c = Calc()
  
 with pytest.raises(ValueError):
  
 > 
  
 c.mul(3, 0)
  
 E 
  
 Failed: DID NOT RAISE <class 'ValueError'>
  
 tests/test_calc.py:70: Failed
  
 which explicitly signals that the code didn’t raise the expected exception.
  
 The code that makes the test pass needs to test if one of the inputs of the
  mul
  functions is 0. 
 This can be done with the help of the built-in
  all
  Python function, which accepts an iterable 
 and returns 
 True
  only if all the values contained in it are
  True
 . Since in Python the value
  0
  is 
 not true, we may write
  
 ³⁸
 https://github.com/pycabook/calc/tree/step-7-division-by-zero",NA
Step 9 - A more complex set of requirements,"Until now the requirements were pretty simple, so it’s time to try to tackle a more complex 
 problem. The remaining requirements say that the class has to provide a function to 
 compute the average of an iterable, and that this function shall accept two optional upper 
 and lower thresholds to remove outliers.
  
 Let’s break these two requirements into a set of simpler ones
  
 1. The function accepts an iterable and computes the average, i.e.
  avg([2, 5, 12, 98]) == 29.25 
 2. 
 The function accepts an optional upper threshold. It must remove all the values that are 
 greater than the threshold before computing the average, i.e.
  avg([2, 5, 12, 98], ut=90) == 
 avg([2,
  
  
 5, 12]) 
  
 3. The function accepts an optional lower threshold. It must remove all the values that 
 are less 
  
 then the threshold before computing the average, i.e.
  avg([2, 5, 12, 98], lt=10) == 
 avg([12,
  
  
 98]) 
  
 4. The upper threshold is not included in the comparison, i.e.
  avg([2, 5, 12, 98], ut=98) ==
  
  
 avg([2, 5, 12, 98]) 
  
 5. The lower threshold is not included in the comparison, i.e.
  avg([2, 5, 12, 98], lt=5) ==
  
 avg([5, 12, 98]) 
  
 6. The function works with an empty list, returning
  0
 , i.e.
  avg([]) == 0 
  
 7. The function works if the list is empty after outlier removal, i.e.
  avg([12, 98], lt=15, ut=90)
  
  
 == 0 
  
 8. The function outlier removal works if the list is empty, i.e.
  avg([], lt=15, ut=90) == 0
  
 As you can see a simple requirement can produce multiple tests. Some of these are clearly 
 expressed by the requirement (numbers 1, 2, 3), some of these are choices that we make 
 (numbers 4, 5, 6) and can be discussed, some are boundary cases that we have to discover 
 thinking about the problem (numbers 6, 7, 8).
  
 There is a fourth category of tests, which are the ones that come from bugs that you 
 discover. We will discuss about those later in this chapter.",NA
Step 9.1 - Average of an iterable,"Let’s start adding a test for requirement number 1
  
 def
  test_avg_correct_average
 (): 
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 avg([
 2
 ,
  5
 ,
  12
 ,
  98
 ])
  
 assert
  res
  == 29.25
  
 We feed the
  avg
  function a list of generic numbers, which average we calculated with an 
 external tool. The first run of the test suite fails with the usual complaint about a missing 
 function
  
 ____________________________ test_avg_correct_average _____________________________
  
 def test_avg_correct_average(): 
  
  
 c = Calc()
  
 > 
  
 res = c.avg([2, 5, 12, 98]) 
  
 E 
  
 AttributeError: 'Calc' object has no attribute 'avg'
  
 tests/test_calc.py:76: AttributeError
  
 And we can make the test pass with a simple use of
  sum
  and
  len
 , as both built-in functions 
 work on iterables
  
 class
  Calc
 : 
  
 [
 ...
 ]
  
 def
  avg
 (
 self
 , it): 
  
  
 return
  sum
 (it)
 /
 len
 (it)
  
  
 Git tag:
  step-9-1-average-of-an-iterable⁴⁰",NA
Step 9.2 - Upper threshold,"The second requirement mentions an upper threshold, but we are free with regards to the 
 API, i.e. the requirement doesn’t specify how the threshold is supposed to be specified or",NA
Step 9.3 - Lower threshold,"The lower threshold is the mirror of the upper threshold, so it doesn’t require many 
 explanations. The test is
  
 def
  test_avg_removes_lower_outliers
 ():
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 avg([
 2
 ,
  5
 ,
  12
 ,
  98
 ], lt
 =10
 )
  
 assert
  res
  ==
  pytest
 .
 approx(
 55
 )
  
 and the code of the
  avg
  function now becomes
  
 def
  avg
 (
 self
 , it, lt
 =
 None
 , ut
 =
 None
 ):
  
 if
  not
  lt:
  
 lt
  =
  min
 (it)
  
 if
  not
  ut:
  
 ut
  =
  max
 (it)
  
 _it
  =
  [x
  for
  x
  in
  it
  if
  x
  >=
  lt
  and
  x
  <=
  ut]
  
 return
  sum
 (_it)
 /
 len
 (_it)
  
  
 Git tag:
  step-9-3-lower-threshold⁴²",NA
Step 9.4 and 9.5 - Boundary inclusion,"As you can see from the code of the
  avg
  function, the upper and lower threshold are 
 included in the comparison, so we might consider the requirements as already satisfied. 
 TDD, however, pushes you to write a test for each requirement (as we saw it’s not unusual 
 to actually have multiple tests per requirements), and this is what we are going to do.
  
 The reason behind this is that you might get the expected behaviour for free, like in this 
 case, because some other code that you wrote to pass a different test provides that feature 
 as a side effect. You don’t know, however what will happen to that code in the future, so if 
 you don’t have tests that show that all your requirements are satisfied you might lose 
 features without knowing it.
  
 The test for the fourth requirement is",NA
Step 9.6 - Empty list ,"Requirement number 6 is something that wasn’t clearly specified in the project description 
 so we decided to return 0 as the average of an empty list. You are free to change the 
 requirement and decide to raise an exception, for example.
  
 The test that implements this requirement is
  
 ⁴³
 https://github.com/pycabook/calc/tree/step-9-4-upper-threshold-is-included
  
 ⁴⁴
 https://github.com/pycabook/calc/tree/step-9-5-lower-threshold-is-included",NA
Step 9.7 - Empty list after applying the thresholds ,"The next requirement deals with the case in which the outlier removal process empties the 
 list. The test is the following
  
 def
  test_avg_manages_empty_list_after_outlier_removal
 ():
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 avg([
 12
 ,
  98
 ], lt
 =15
 , ut
 =90
 )
  
 assert
  res
  == 0
  
 and the test suite fails with a
  ZeroDivisionError
 , because the length of the iterable is now 0.
  
 ________________ test_avg_manages_empty_list_after_outlier_removal ________________
  
 def test_avg_manages_empty_list_after_outlier_removal():
  
 c = Calc()
  
 > 
  
 res = c.avg([12, 98], lt=15, ut=90)
  
 tests/test_calc.py:124:
  
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
  
 self = <calc.calc.Calc object at 0x7f6f687a0a58>, it = [12, 98], lt = 15, ut = 90
  
 def avg(self, it, lt=None, ut=None):
  
 if not len(it):",NA
Step 9.8 - Empty list before applying the thresholds,"The last requirement checks another boundary case, which happens when the list is empty 
 and we specify one of or both the thresholds. This test will check that the outlier removal 
 code doesn’t assume the list contains elements.
  
 def
  test_avg_manages_empty_list_before_outlier_removal
 ():
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 avg([], lt
 =15
 , ut
 =90
 )
  
 assert
  res
  == 0
  
 This test doesn’t fail. So, according to the TDD methodology, we should justify the reason 
 why it doesn’t fail, and decide if we want to keep it. The reason why it doesn’t fail is 
 because the two list comprehensions used to filter the elements work perfectly with empty 
 lists. As for the test, it comes directly from a corner case, and it checks a behaviour which is 
 not already covered by other tests. This makes me decide to keep the test.
  
  
 Git tag:
  step-9-8-empty-list-before-thresholds⁴⁷",NA
Step 9.9 - Zero as lower/upper threshold,"This is perhaps the most important step of the whole chapter, for two reasons. First of all, 
 the test added in this step was added by two readers
 ⁴⁸
 , and this is shows a real TDD 
 workflow. After you published you package (or your book, in this case) someone notices a 
 wrong behaviour in some use case. This might be a big flaw or a tiny corner case, but in any 
 case they can come up with a test that exposes the bug, and maybe even with a patch to the 
 code, but the most important part is the test.
  
 Whoever discovers the bug has a clear way to show it, and you, as an 
 author/maintainter/developer can add that test to your suite and work on the code until 
 that passes. The rest of the test suite will block any change in the code that disrupts an 
 already tested behaviour. As I stressed multiple times in this part of the book, we could do 
 the same without TDD, but if we need to change a substantial amount of code there is 
 nothing like a test suite that can guarantee we are not re-introducing bugs.
  
 Second, this step shows an important part of the TDD workflow: checking corner cases. In 
 general you should pay a lot of attention to the boundaries of a domain, and test the 
 behaviour of the code in those cases.
  
 This test shows that the code doesn’t manage zero-valued lower thresholds correctly
  
 def
  test_avg_manages_zero_value_lower_outlier
 ():
  
 c
  =
  Calc()
  
 res
  =
  c
 .
 avg([
 -1
 ,
  0
 ,
  1
 ], lt
 =0
 )
  
 assert
  res
  == 0.5
  
 The reason is that the
  avg
  function contains a check like
  if lt:
 , which fails when
  lt
  is 0, as that 
 is a false value. The check should be
  if lt is not None:
 , so that part of the
  avg
  function becomes
  
 if
  lt
  is not
  None
 :
  
 _it
  =
  [x
  for
  x
  in
  _it
  if
  x
  >=
  lt]
  
 It is immediately clear that the upper threshold has the same issue, so the two tests I added 
 are",NA
Recap of the TDD rules ,"Through this very simple example we learned 6 important rules of the TDD methodology. 
 Let us review them, now that we have some experience that can make the words",NA
How many assertions?,"I am frequently asked “How many assertions do you put in a test?”, and I consider this 
 question important enough to discuss it in a dedicated section. To answer this question I 
 want to briefly go back to the nature of TDD and the role of the test suite that we run.
  
 The whole point of automated tests is to run through a set of checkpoints that can quickly 
 reveal that there is a problem in a specific area. Mind the words “quickly” and “specific”. 
 When I run the test suite and an error occurs I’d like to be able to understand as fast as 
 possible where the problem lies. This doesn’t (always) mean that the problem will have a 
 quick resolution, but at least I can be immediately aware of which part of the system is 
 misbehaving.
  
 On the other side, we don’t want to have too many test for the same condition, on the 
 contrary we want to avoid testing the same condition more than once as tests have to be 
 maintained. A test suite that is too fine-grained might result in too many tests failing 
 because of the same problem in the code, which might be daunting and not very 
 informative.
  
 My advice is to group together assertions that can be done after the same setup, if they test 
 the same process. For example, you might consider the two functions
  add
  and
  sub
  that we 
 tested in this chapter. They require the same setup, which is to instantiate the
  Calc
  class (a 
 setup that they share with many other tests), but they are actually testing two different 
 processes. A good sign of this is that you should rename the test to
  test_add_or_sub
 , and a 
 failure in this test would require a further investigation in the test output to check which 
 method of the class is failing.
  
 If you had to test that a method returns positive even numbers, instead, you might consider 
 running the method and then writing two assertions, one that checks that the number is 
 positive, and one that checks it is even. This makes sense, as a failure in one of the two 
 means a failure of the whole process.
  
 As a quick rule of thumb, then, consider if the test is a logical
  AND
  between conditions or a 
 logical 
 OR
 . In the former case go for multiple assertions, in the latter create multiple test 
 functions.",NA
How to manage bugs or missing features,NA,NA
Chapter 2 - On unit testing,"Describe in single words, only the good things that come into your mind about your mother.
  
 • Blade Runner (1982)",NA
Introduction,"What I introduced in the previous chapter is commonly called “unit testing”, since it focuses 
 on testing a single and very small unit of code. As simple as it may seem, the TDD process 
 has some caveats that are worth being discussed. In this chapter I discuss some aspects of 
 TDD and unit testing that I consider extremely important.",NA
Tests should be fast,"You should run your tests many times, potentially you should run them every time you save 
 your code. Your tests are the watchdogs of your code, the dashboard warning lights that 
 signal a correct status or some malfunction. This means that your testing suite should be
  
 fast
 . If you have to wait minutes for each execution to finish, chances are that you will end 
 up running your tests only after some long coding session, which means that you are not 
 using them as guides.
  
 It’s true however that some tests may be intrinsically slow, or that the test suite might be so 
 big that running it would take an amount of time which makes continuous testing 
 uncomfortable. In this case you should identify a subset of tests that run quickly and that 
 can show you if something is not working properly, the so-called “smoke tests”, and leave 
 the rest of the suite for longer executions that you run less frequently. Typically, the library 
 part of your project has tests that run very quickly, as testing functions does not require 
 specific set-ups, while the user interface tests (be it a CLI or a GUI) are usually slower.",NA
Tests should be idempotent,"Idempotency
  in mathematics and computer science identifies processes that can be run 
 multiple times without changing the status of the system. Since this latter doesn’t change, 
 the tests can be",NA
Tests should be isolated,"In computer science
  isolation
  means that a component shall not change its behaviour 
 depending on something that happens externally. In particular it shouldn’t be affected by 
 the execution of other components in the system (spatial isolation) and by the previous 
 execution of the component itself (temporal isolation). Each test should run as much as 
 possible in an isolated universe.
  
 While this is easy to achieve for small components, like we did with the
  Calc
  class, it might 
 be almost impossible to do in more complex cases. Whatever routine you will write that 
 deals with time, for example, be it the current date or a time interval, you are faced with 
 something that flows incessantly and that cannot be stopped or slowed down. This is also 
 true in other cases, for example if you are testing a routine that accesses an external service 
 like a website. If the website is not reachable the test will fail, but this failure comes from an 
 external source, not from the code under test.
  
 Mocks are again a good tool to enforce isolation in tests that need to communicate with 
 external actors in the system.",NA
External systems,"It is important to understand that the above definitions (idempotency, isolation) depend on 
 the scope of the test. You should consider
  external
  whatever part of the system is not 
 directly involved in the test, even though you need to use it to run the test itself. You should 
 also try to reduce the scope of the test as much as possible.
  
 Let me give you an example. Consider a web application and imagine a test that checks that 
 a user can log in. The login process involves many layers: the user inputs, the username and 
 the password in a GUI and submits the form, the GUI communicates with the core of the 
 application that finds the user in the DB and checks the password hash against the one",NA
Focus on messages,"I will never recommend enough Sandi Metz’s talk
  “The Magic Tricks of Testing”⁵¹
  where 
 she considers the different messages that a software component has to deal with. She 
 comes up with 3 different origins for messages (incoming, sent to self, and outgoing) and 2 
 types (query and command). The very interesting conclusion she reaches is that you should 
 only test half of them, and I believe this is one of the most useful results you can learn as a 
 software developer. In this section I will shamelessly start from Sandi Metz’s 
 categorisations and give a personal view of the matter. I absolutely recommend to watch 
 the original talk as it is both short and very effective.
  
 Testing is all about the behaviour of a component when it is used, i.e. when it is connected 
 to other components that interact with it. This interaction is well represented by the word 
 “message”, which has hereafter the simple meaning of “data exchanged between two 
 actors”.
  
 We can then classify the interactions happening in our system, and thus to our components, 
 by flow
 ⁵²
  and by type.",NA
Message flow,"The flow is defined as the tuple
  (source, origin)
 , that is where the message comes from and 
 what its destination is. There are three different combinations that we are interested in:
  
 (outside, self)
 , 
 (self, self)
 , and
  (self, outside)
 , where
  self
  is the object we are testing, and
  outside
  is a 
 generic object that lives in the system. There is a fourth combination,
  (outside, outside)
  that is 
 not relevant for the testing, since it doesn’t involve the object under analysis.
  
 So
  (outside, self)
  contains all the messages that other parts of the system send to our 
 component. These messages correspond to the public API of the component, that is the set",NA
Message type,"Messages can be further divided according to the interaction the source requires to have 
 with the target:
  queries
  and
  commands
 . Queries are messages that do not change the status 
 of the component, they just extract information. The
  Calc
  class that we developed in the 
 previous section is a typical example of object that exposes query methods. Adding two 
 numbers doesn’t change the status of the object, and you will receive the same answer 
 every time you call the
  add
  method.
  
 Commands, instead, are the complete opposite. They do not extract any information, but 
 they change the status of the object. A method of an object that increases an internal 
 counter or a method that adds values to an array are perfect examples of commands.
  
 It’s perfectly normal to combine a query and a command in a single message, as long as you 
 are aware that your message is changing the status of the component. Remember that 
 changing the status is something that can have concrete secondary effect.",NA
The testing grid,"Combining 3 flows and 2 message types we get 6 different message cases that involve the 
 component under testing. For each one of this cases we have to decide how to test the 
 interaction represented by that flow and message type.",NA
Incoming queries,"An incoming query is a message that an external actor sends to get a value from your 
 component. Testing this behaviour is straightforward, as you just need to write a test that 
 sends the message and makes an assertion on the returned value. A concrete example of 
 this is what we did to test the
  add 
 method of
  Calc
 .",NA
Incoming commands,"An incoming command comes from an external actor that wants to change the status of the 
 system. There should be a way for an external actor to check the status, which translates 
 into the need of having either a companion incoming query message that allows to extract 
 the status (or at least the part of the status affected by the command), or the knowledge 
 that the change is going to affect the behaviour of another query. A simple example might 
 be a method that sets the precision (number of digits) of the division in the
  Calc
  object. 
 Setting that value changes the result of a query, which can be used to test the effect of the 
 incoming command.",NA
Private queries,"A private query is a message that the component sends to self to get a value without 
 affecting its own state, and it is basically nothing more than an explicit use of some internal 
 logic. This happens often in object-oriented languages because you extracted some 
 common logic from one or more methods of an object and created a private method to 
 avoid duplication.
  
 Since private queries use the internal logic you shouldn’t test them. This might be 
 surprising, as private methods are code, and code should be tested, but remember that 
 other methods are calling them, so the effects of that code are not invisible, they are tested 
 by the tests of the public entry points, although indirectly. The only effect you would 
 achieve by testing private methods is to lock the tests to the internal implementation of the 
 component, which by definition shouldn’t be used by anyone outside of the component 
 itself. This in turn, makes refactoring painful, because you have to keep redundant tests in 
 sync with the changes that you do, instead of using them as a guide for the code changes 
 like TDD wants you to do.
  
 As Sandi Metz says, however, this is not an inflexible rule. Whenever you see that testing an 
 internal method makes the structure more robust feel free to do it. Be aware that you are 
 locking the implementation, so do it only where it makes a real difference businesswise.",NA
Private commands,"Private commands shouldn’t be treated differently than private queries. They change the 
 status of the component, but this is again part of the internal logic of the component itself, 
 so you shouldn’t test private commands either. As stated for private queries, feel free to do 
 it if this makes a real difference.",NA
Outgoing queries and commands,NA,NA
Conclusions,"Since the discovery of TDD few things changed the way I write code more than these 
 considerations on what I am supposed to test. Out of 6 different types of tests we 
 discovered that 2 shouldn’t be tested, 2 of them require a very simple technique based on 
 assertions, and the last 2 are the only ones that requires an advanced technique (mocks). 
 This should cheer you up, as for once a good methodology doesn’t add new rules and 
 further worries, but removes one third of them, forbidding you to implement them!",NA
Chapter 3 - Mocks,"We’re gonna get bloody on this one, Rog.
  
 • Lethal Weapon (1987)",NA
Basic concepts,"As we saw in the previous chapter the relationship between the component that we are 
 testing and other components of the system can be complex. Sometimes idempotency and 
 isolation are not easy to achieve, and testing outgoing commands requires to check the 
 parameters sent to the external component, which is not trivial.
  
 The main difficulty comes from the fact that your code is actually using the external system. 
 When you run it in production the external system will provide the data that your code 
 needs and the whole process can work as intended. During testing, however, you don’t 
 want to be bound to the external system, for the reasons explained in the previous chapter, 
 but at the same time you need it to make your code work.
  
 So, you face a complex issue. On the one hand your code is connected to the external system 
 (be it hardcoded or chosen programmatically), but on the other hand you want it to run 
 without the external system being active (or even present).
  
 This problem can be solved with the use of mocks. A mock, in the testing jargon, is an object 
 that simulates the behaviour of another (more complex) object. Wherever your code 
 connects to an external system, during testing you can replace the latter with a mock, 
 pretending the external system is there and properly checking that your component 
 behaves like intended.",NA
First steps,"Let us try and work with a mock in Python and see what it can do. First of all fire up a 
 Python shell and import the library
  
 >>>
  from
  unittest
  import
  mock
  
 The main object that the library provides is
  Mock
  and you can instantiate it without any 
 argument",NA
Simple return values,"The simplest thing a mock can do for you is to return a given value every time you call one 
 of its methods. This is configured setting the
  return_value
  attribute of a mock object",NA
Complex return values,"The
  side_effect
  parameter of mock objects is a very powerful tool. It accepts three different 
 flavours of objects: callables, iterables, and exceptions, and changes its behaviour 
 accordingly.
  
 If you pass an exception the mock will raise it
  
 >>>
  m
 .
 some_attribute
 .
 side_effect
  =
  ValueError
 (
 'A custom value error'
 ) 
 >>>
  
 m
 .
 some_attribute() 
  
 Traceback (most recent call last): 
  
  
 File
  ""<stdin>""
 , line
  1
 ,
  in
  <
 module
 > 
  
  
 File
  ""/usr/lib/python3.6/unittest/mock.py""
 , line
  939
 ,
  in
  __call__ 
  
 return
  
 _mock_self
 .
 _mock_call(
 *
 args,
  **
 kwargs) 
  
  
 File
  ""/usr/lib/python3.6/unittest/mock.py""
 , line
  995
 ,
  in
  _mock_call 
  
 raise
  effect 
  
 ValueError
 : A custom value error",NA
Asserting calls,"As I explained in the previous chapter outgoing commands shall be tested checking the 
 correctness of the message argument. This can be easily done with mocks, as these objects 
 record every call that they receive and the arguments passed to it.
  
 Let’s see a practical example
  
 from
  unittest
  import
  mock 
  
 import
  myobj
  
 def
  test_connect
 (): 
  
 external_obj
  =
  mock
 .
 Mock() 
  
 myobj
 .
 MyObj(external_obj) 
  
 external_obj
 .
 connect
 .
 assert_called_with()
  
 Here, the
  myobj.MyObj
  class needs to connect to an external object, for example a remote 
 repository or a database. The only thing we need to know for testing purposes is if the class 
 called the
  connect 
 method of the external object without any parameter.
  
 So the first thing we do in this test is to instantiate the mock object. This is a fake version of 
 the external object, and its only purpose is to accept calls from the
  MyObj
  object under test 
 and possibly return sensible values. Then we instantiate the
  MyObj
  class passing the 
 external object. We expect the class to call the
  connect
  method so we express this 
 expectation calling 
 external_obj.connect.assert_called_with()
 .",NA
A simple example,"To learn how to use mocks in a practical case, let’s work together on a new module in the
  
 calc 
 package. The target is to write a class that downloads a JSON file with data on 
 meteorites and computes some statistics on the dataset using the
  Calc
  class. The file is 
 provided by NASA at
  this URL⁵³
 .
  
 The class contains a
  get_data
  method that queries the remote server and returns the data, 
 and a method
  average_mass
  that uses the
  Calc.avg
  method to compute the average mass of the 
 meteorites and return it. In a real world case, like for example in a scientific application, I 
 would probably split the class in two. One class manages the data, updating it whenever it 
 is necessary, and another one manages the statistics. For the sake of simplicity, however, I 
 will keep the two functionalities together in this example.
  
 Let’s see a quick example of what is supposed to happen inside our code. An excerpt of the 
 file provided from the server is
  
 [ 
  
 { 
  
  
  
 ""fall""
 :
  ""Fell""
 , 
  
  
  
 ""geolocation""
 : { 
  
  
  
  
 ""type""
 :
  ""Point""
 , 
  
  
  
  
 ""coordinates""
 : [
 6.08333
 ,
  50.775
 ] 
  
  
 }, 
  
  
  
 ""id""
 :
 ""1""
 , 
  
  
  
 ""mass""
 :
 ""21""
 , 
  
  
  
 ""name""
 :
 ""Aachen""
 , 
  
  
  
 ""nametype""
 :
 ""Valid""
 , 
  
  
  
 ""recclass""
 :
 ""L5""
 , 
  
  
  
 ""reclat""
 :
 ""50.775000""
 , 
  
  
  
 ""reclong""
 :
 ""6.083330""
 , 
  
  
  
 ""year""
 :
 ""1880-01-01T00:00:00.000""",NA
Patching,"Mocks are very simple to introduce in your tests whenever your objects accept classes or 
 instances from outside. In that case, as shown in the previous sections, you just have to 
 instantiate the
  Mock 
 class and pass the resulting object to your system. However, when the 
 external classes instantiated by your library are hardcoded this simple trick does not work. 
 In this case you have no chance to pass a fake object instead of the real one.
  
 This is exactly the case addressed by patching. Patching, in a testing framework, means to 
 replace a globally reachable object with a mock, thus achieving the goal of having the code 
 run unmodified, while part of it has been hot swapped, that is, replaced at run time.",NA
A warm-up example,"Let us start with a very simple example. Patching can be complex to grasp at the beginning 
 so it is better to start learning it with trivial use cases.
  
 Create a new project following the instructions given previously in the book, calling this 
 project 
 fileinfo
 . The purpose of this library is to develop a simple class that returns 
 information about a given file. The class shall be instantiated with the file path, which can 
 be relative.
  
 The starting point is the class with the
  __init__
  method. If you want you can develop the class 
 using TDD, but for the sake of brevity I will not show here all the steps that I followed. This 
 is the set of tests I have in
  tests/test_fileinfo.py
  
 ⁵⁴
 https://github.com/pycabook/calc/tree/meteoritestats-class-added",NA
The patching decorator,"The
  patch
  function we imported from the
  unittest.mock
  module is very powerful, as it can 
 temporarily replace an external object. If the replacement has to or can be active for the 
 whole test, there is a cleaner way to inject your mocks, which is to use
  patch
  as a function 
 decorator.
  
 This means that you can decorate the test function, passing as argument the same 
 argument you would pass if
  patch
  was used in a
  with
  statement. This requires however a 
 small change in the test function prototype, as it has to receive an additional argument, 
 which will become the mock.",NA
Multiple patches,"You can patch more that one object in the same test. For example, consider the case where 
 the 
 get_info
  method calls
  os.path.getsize
  in addition to
  os.path.abspath
 , because it needs it to 
 return the size of the file. You have at this point two different outgoing queries, and you 
 have to replace both with mocks to make your class work during the test.
  
 This can be easily done with an additional
  patch
  decorator
  
 @patch
 (
 'os.path.getsize'
 ) 
  
 @patch
 (
 'os.path.abspath'
 ) 
  
 def
  test_get_info
 (abspath_mock, getsize_mock): filename
  =
  
 'somefile.ext' 
  
 original_path
  =
  '../{}'
 .
 format(filename)
  
 test_abspath
  =
  'some/abs/path' 
  
 abspath_mock
 .
 return_value
  =
  test_abspath
  
 test_size
  = 1234 
  
 getsize_mock
 .
 return_value
  =
  test_size
  
 ⁵⁷
 https://github.com/pycabook/fileinfo/tree/patch-with-function-decorator",NA
Checking call parameters,"When you patch, your internal algorithm is not run, as the patched method just return the 
 values they have been instructed to return. This is connected to what we said about testing 
 external systems, so everything is good, but while we don’t want to test the internals of the
  
 os.path
  module, we want to be sure that we are passing the correct values to the external 
 methods.
  
 This is why mocks provide methods like
  assert_called_with
  (and other similar methods), 
 through which we can check the values passed to a patched method when it is called. Let’s 
 add the checks to the test",NA
Patching immutable objects,"The most widespread version of Python is CPython, which is written, as the name suggests, 
 in C. Part of the standard library is also written in C, while the rest is written in Python 
 itself.
  
 The objects (classes, modules, functions, etc.) that are implemented in C are shared 
 between interpreters
 ⁶⁰
 , and this requires those objects to be immutable, so that you cannot 
 alter them at runtime from a single interpreter.
  
 An example of this immutability can be given easily using a Python console",NA
Mocks and proper TDD,"Following a strict TDD methodology means writing a test before writing the code that 
 passes that test. This can be done because we use the object under test as a black box, 
 interacting with it through its API, and thus not knowing anything of its internal structure.
  
 When we mock systems we break this assumption. In particular we need to open the black 
 box every time we need to patch an hardcoded external system. Let’s say, for example, that 
 the object under test creates a temporary directory to perform some data processing. This 
 is a detail of the implementation and we are not supposed to know it while testing the 
 object, but since we need to mock the file creation to avoid interaction with the external 
 system (storage) we need to become aware of what happens internally.
  
 ⁶²
 https://github.com/pycabook/fileinfo/tree/correct-patching",NA
A warning,"Mocks are a good way to approach parts of the system that are not under test but that are 
 still part of the code that we are running. This is particularly true for parts of the code that 
 we wrote, which internal structure is ultimately known. When the external system is 
 complex and completely detached from our code, mocking starts to become complicated 
 and the risk is that we spend more time faking parts of the system than actually writing 
 code.
  
 In this cases we definitely crossed the barrier between unit testing and integration testing. 
 You may see mocks as the bridge between the two, as they allow you to keep unit-testing 
 parts that are naturally connected (“integrated”) with external systems, but there is a point 
 where you need to recognise that you need to change approach.
  
 This threshold is not fixed, and I can’t give you a rule to recognise it, but I can give you 
 some advice. First of all keep an eye on how many things you need to mock to make a test 
 run, as an increasing number of mocks in a single test is definitely a sign of something 
 wrong in the testing approach. My rule of thumb is that when I have to create more than 3 
 mocks, an alarm goes off in my mind and I start questioning what I am doing.
  
 The second advice is to always consider the complexity of the mocks. You may find yourself 
 patching a class but then having to create monsters like
  cls_mock().func1().func2().func3.assert_-
 called_with(x=42)
  which is a sign that the part of the system that you are mocking is deep into 
 some code that you cannot really access, because you don’t know it’s internal mechanisms. 
 This is the case with ORMs, for example, and I will discuss it later in the book.
  
 The third advice is to consider mocks as “hooks” that you throw at the external system, and 
 that break its hull to reach its internal structure. These hooks are obviously against the 
 assumption that we can interact with a system knowing only its external behaviour, or its 
 API. As such, you should keep in mind that each mock you create is a step back from this 
 perfect assumption, thus “breaking the spell” of the decoupled interaction. Doing this you 
 will quickly become annoyed when you have to create too many mocks, and this will 
 contribute in keeping you aware of what you are doing (or overdoing).",NA
Recap,"Mocks are a very powerful tool that allows us to test code that contains outgoing messages. 
 In particular they allow us to test the arguments of outgoing commands. Patching is a good 
 way to overcome the fact that some external components are hardcoded in our code and 
 are thus unreachable through the arguments passed to the classes or the methods under 
 analysis.
  
 Mocks are also the most complex part of testing, so don’t be surprised if you are still a bit 
 confused by them. Review the chapter once, maybe, but then try to go on, as in later 
 chapters we will use mocks in very simple and practical examples, which may shed light 
 upon the whole matter.",NA
Part 2 - The clean architecture,NA,NA
Chapter 1 - Components of a ,NA,NA
clean architecture,"Wait a minute. Wait a minute Doc, uh, are you telling me you built a time machine… out 
 of a DeLorean?
  
 • Back to the Future (1985)",NA
Layers and data flow,"A clean architecture is a layered architecture, which means that the various elements of 
 your system are categorised and have a specific place where to be, according to the 
 category you assigned them. A clean architecture is also a spherical architecture, with inner 
 (lower) layers completely encompassed by outer (higher) ones, and the former ones being 
 oblivious of the existence of the latter ones.
  
 The deeper a layer is in the architecture, the more abstract the content is. The inner layers 
 contain representations of business concepts, while the outer layers contain specific details 
 about the real-life implementation. The communication between elements that live in the 
 same layer is unrestricted, but when you want to communicate with elements that have 
 been assigned to other layers you have to follow one simple rule. This rule is the most 
 important thing in a clean architecture, possibly being the core expression of the clean 
 architecture itself.
  
 Talk inwards with simple structures, talk outwards through interfaces.
  
 Your elements should talk inwards, that is pass data to more abstract elements, using basic 
 structures provided by the language (thus globally known) or structures known to those 
 elements. Remember that an inner layer doesn’t know anything about outer ones, so it 
 cannot understand structures defined there.
  
 Your elements should talk outwards using interfaces, that is using only the expected API of 
 a component, without referring to a specific implementation. When an outer layer is 
 created, elements living there will plug themselves into those interfaces and provide a 
 practical implementation.",NA
Main layers,NA,NA
Entities,"This layer of the clean architecture contains a representation of the domain models, that is 
 everything your project needs to interact with and is sufficiently complex to require a 
 specific representation. For example, strings in Python are complex and very powerful 
 objects. They provide many methods out of the box, so in general, it is useless to create a 
 domain model for them. If your project is a tool to analyse medieval manuscripts, however, 
 you might need to isolate sentences and at this point maybe you need a specific domain 
 model.
  
 Since we work in Python, this layer will contain classes, with methods that simplify the 
 interaction with them. It is very important, however, to understand that the models in this 
 layer are different from the usual models of frameworks like Django. These models are not 
 connected with a storage system, so they cannot be directly saved or queried using 
 methods of their classes, they don’t contain methods to dump themselves to JSON strings, 
 they are not connected with any presentation layer. They are so-called lightweight models.
  
 This is the inmost layer. Entities have mutual knowledge since they live in the same layer, 
 so the architecture allows them to interact directly. This means that one of your Python 
 classes can use another one directly, instantiating it and calling its methods. Entities don’t 
 know anything that lives in outer layers, however. For example, entities don’t know details 
 about the external interfaces, and they only work with interfaces.",NA
Use cases,"This layer contains the use cases implemented by the system. Use cases are the processes 
 that happen in your application, where you use your domain models to work on real data. 
 Examples can be a user logging in, a search with specific filters being performed, or a bank 
 transaction happening when the user wants to buy the content of the cart.
  
 A use case should be as small a possible. It is very important to isolate small actions in use 
 cases, as this makes the whole system easier to test, understand and maintain.
  
 Use cases know the entities, so they can instantiate them directly and use them. They can 
 also call each other, and it is common to create complex use cases that put together simpler 
 ones.",NA
External systems,"This part of the architecture is made by external systems that implement the interfaces 
 defined in the previous layer. Examples of these systems can be a specific framework that 
 exposes an HTTP API, or a specific database.",NA
APIs and shades of grey,"The word API is of uttermost importance in a clean architecture. Every layer may be 
 accessed by elements living in inner layers by an API, that is a fixed
 ⁶³
  collection of entry 
 points (methods or objects).
  
 The separation between layers and the content of each layer are not always fixed and 
 immutable. A well-designed system shall also cope with practical world issues such as 
 performances, for example, or other specific needs. When designing an architecture it is 
 very important to know “what is where and why”, and this is even more important when 
 you “bend” the rules. Many issues do not have a black-or-white answer, and many decisions 
 are “shades of grey”, that is it is up to you to justify why you put something in a given place.
  
 Keep in mind, however, that you should not break the
  structure
  of the clean architecture, 
 and be particularly very strict about the data flow. If you break the data flow, you are 
 basically invalidating the whole structure. You should try as hard as possible not to 
 introduce solutions that are based on a break in the data flow, but realistically speaking, if 
 this saves money, do it.
  
 If you do it, there should be a giant warning in your code and your documentation 
 explaining why you did it. If you access an outer layer breaking the interface paradigm 
 usually it is because of some performance issues, as the layered structure can add some 
 overhead to the communications between elements. You should clearly tell other 
 programmers that this happened, because if someone wants to replace the external layer 
 with something different, they should know that there is direct access which is 
 implementation-specific.
  
 For the sake of example, let’s say that a use case is accessing the storage layer through an 
 interface, but this turns out to be too slow. You decide then to access directly the API of the 
 specific database you are using, but this breaks the data flow, as now an internal layer (use 
 cases) is accessing an outer one (external interfaces). If someone in the future wants to 
 replace the specific database you are using with a different one, they have to be aware of 
 this, as the new database probably won’t provide the same API entry point with the same 
 data.
  
 If you end up breaking the data flow consistently maybe you should consider removing one 
 layer of abstraction, merging the two layers that you are linking.
  
 ⁶³
 here “fixed” means “the same among every implementation”. An API may obviously change in time.",NA
Chapter 2 - A basic example,"Joshua/WOPR: Wouldn’t you prefer a good game of 
 chess? David: Later. Let’s play Global Thermonuclear 
 War.
  
 • Wargames (1983)",NA
Project overview,"The goal of the “Rent-o-Matic” project (fans of “Day of the Tentacle” may get the reference) 
 is to create a simple search engine on top of a dataset of objects which are described by 
 some quantities. The search engine allows setting some filters to narrow the search.
  
 The objects in the dataset are houses for rent described by the following quantities:
  
 • An unique identifier
  
 • A size in square meters
  
 • A renting price in 
 Euro/day
  
 • Latitude and longitude
  
 The description of the house is purposely minimal so that the whole project can easily fit in 
 a chapter. The concepts that I will show are however easily extendable to more complex 
 cases.
  
 As pushed by the clean architecture model, we are interested in separating the different 
 layers of the system.
  
 I will follow the TDD methodology, but I will not show all the single steps to avoid this 
 chapter becoming too long.
  
 Remember that there are multiple ways to implement the clean architecture concepts, and 
 the code you can come up with strongly depends on what your language of choice allows 
 you to do. The following is an example of clean architecture in Python, and the 
 implementation of the models, use cases and other components that I will show is just one 
 of the possible solutions.
  
 The full project is available on
  GitHub⁶⁴
 .
  
 ⁶⁴
 https://github.com/pycabook/rentomatic",NA
Project setup,"Follow the instructions I gave in the first chapter and create a virtual environment for the 
 project, install Cookiecutter, and then create a project using the recommended template. 
 For this first project use the name
  rentomatic
  as I did, so you can use the same code that I will 
 show without having to change the name of the imported modules. You also want to use 
 pytest, so answer yes to that question.
  
 After you created the project install the requirements with
  
 $ pip install -r requirements/dev.txt
  
 Try to run
  py.test -svv
  to check that everything is working correctly, and then remove the 
 files 
 tests/test_rentomatic.py
  and
  rentomatic/rentomatic.py
 .
  
 In this chapter, I will not explicitly state that I run the test suite, as I consider it part of the 
 standard workflow. Every time we write a test you should run the suite and check that you 
 get an error (or more), and the code that I give as a solution should make the test suite 
 pass. You are free to try to implement your own code before copying my solution, 
 obviously.",NA
Domain models,"Let us start with a simple definition of the
  Room
  model. As said before, the clean 
 architecture models are very lightweight, or at least they are lighter than their counterparts 
 in common web frameworks.
  
 Following the TDD methodology, the first thing that I write are the tests. Create the
  
 tests/domain/test_-room.py
  and put this code inside it
  
 import
  uuid
  
 from
  rentomatic.domain
  import
  room
  as
  r
  
 def
  test_room_model_init
 ():
  
 code
  =
  uuid
 .
 uuid4()
  
 room
  =
  r
 .
 Room(code, size
 =200
 , price
 =10
 ,
  
 longitude
 =-0.09998975
 ,
  
 latitude
 =51.75436293
 )
  
 assert
  room
 .
 code
  ==
  code
  
 assert
  room
 .
 size
  == 200
  
 assert
  room
 .
 price
  == 10
  
 assert
  room
 .
 longitude
  == -0.09998975",NA
Serializers,"Outer layers can use the
  Room
  model, but if you want to return the model as a result of an 
 API call you need a serializer.
  
 The typical serialization format is JSON, as this is a broadly accepted standard for web-
 based APIs. The serializer is not part of the model but is an external specialized class that 
 receives the model instance and produces a representation of its structure and values.
  
 To test the JSON serialization of our
  Room
  class put the following code into the file
  
 tests/serializers/test_-room_json_serializer.py
 :
  
 import
  json 
  
 import
  uuid
  
 from
  rentomatic.serializers
  import
  room_json_serializer
  as
  ser 
 from
  
 rentomatic.domain
  import
  room
  as
  r
  
 def
  test_serialize_domain_room
 (): 
  
 code
  =
  uuid
 .
 uuid4()
  
 room
  =
  r
 .
 Room( 
  
  
 code
 =
 code, 
  
  
 size
 =200
 , 
  
  
 price
 =10
 , 
  
  
 longitude
 =-0.09998975
 , 
  
  
 latitude
 =51.75436293 
  
 )
  
 expected_json
  =
  """""" 
  
  
 {{ 
  
  
  
 ""code"": ""{}"", 
  
  
  
 ""size"": 200, 
  
  
  
 ""price"": 10, 
  
  
  
 ""longitude"": -0.09998975, 
  
  
  
 ""latitude"": 51.75436293 
  
  
 }} 
  
 """"""
 .
 format(code)
  
 json_room
  =
  json
 .
 dumps(room,
  cls
 =
 ser
 .
 RoomJsonEncoder)",NA
Use cases,"It’s time to implement the actual business logic that runs inside our application. Use cases 
 are the places where this happens, and they might or might not be directly linked to the 
 external API of the system.
  
 ⁶⁹
 https://github.com/pycabook/rentomatic/tree/chapter-2-serializers",NA
The storage system,"During the development of the use case, we assumed it would receive an object that 
 contains the data and exposes a
  list
  function. This object is generally speaking nicknamed 
 “repository”, being the source of information for the use case. It has nothing to do with the 
 Git repository, though, so be careful not to mix the two nomenclatures.
  
 The storage lives in the third layer of the clean architecture, the external systems. The 
 elements in this layer are accessed by internal elements through an interface, which in 
 Python just translates in exposing a given set of methods (in this case only
  list
 ). It is worth 
 noting that the level of abstraction provided by a repository in a clean architecture is 
 higher than that provided by an ORM in a framework or by a tool like SQLAlchemy. The 
 repository provides only the endpoints that the application needs, with an interface which 
 is tailored to the specific business problems the application implements.
  
 To clarify the matter in terms of concrete technologies, SQLAlchemy is a wonderful tool to 
 abstract the access to an SQL database, so the internal implementation of the repository 
 could use it to access a PostgreSQL database, for example. But the external API of the layer 
 is not that provided by SQLAlchemy. The API is a reduced set of functions that the use cases 
 call to get the data, and the internal implementation can use a wide range of solutions to 
 achieve the same goal, from raw SQL queries to a complex system of remote calls through a 
 RabbitMQ network.
  
 A very important feature of the repository is that it can return domain models, and this is in 
 line with what framework ORMs usually do. The elements in the third layer have access to 
 all the elements defined in the internal layers, which means that domain models and use 
 cases can be called and used directly from the repository.
  
 For the sake of this simple example, we will not deploy and use a real database system. 
 Given what we said, we are free to implement the repository with the system that better 
 suits our needs, and in this case I want to keep everything simple. We will thus create a 
 very simple in-memory storage system loaded with some predefined data.
  
 The first thing to do is to write some tests that document the public API of the repository. 
 The file containing the tests is
  tests/repository/test_memrepo.py
 .
  
 ⁷¹
 https://github.com/pycabook/rentomatic/tree/chapter-2-use-cases",NA
A command-line interface,"So far we created the domain models, the serializers, the use cases and the repository, but 
 we are still missing a system that glues everything together. This system has to get the call 
 parameters from the user, initialise a use case with a repository, run the use case that 
 fetches the domain models from the repository, and return them to the user.
  
 Let’s see now how the architecture that we just created can interact with an external 
 system like a CLI. The power of a clean architecture is that the external systems are 
 pluggable, which means that we can defer the decision about the detail of the system we 
 want to use. In this case, we want to give the user an interface to query the system and to 
 get a list of the rooms contained in the storage system, and the simplest choice is a 
 command-line tool.
  
 Later we will create a REST endpoint and we will expose it through a Web server, and it will 
 be clear why the architecture that we created is so powerful.",NA
HTTP API,"In this section, I will go through the creation of an HTTP endpoint for the room list use case. 
 An HTTP endpoint is a URL exposed by a Web server that runs a specific logic and returns 
 values, often formatted as JSON, which is a widely used format for this type of API.
  
 The semantics of URLs, their structure and the requests they can accept, comes from the 
 REST recommendations. REST is however not part of the clean architecture, which means 
 that you can choose to model your URLs according to whatever scheme you might prefer.
  
 To expose the HTTP endpoint we need a web server written in Python, and in this case, I 
 chose Flask. Flask is a lightweight web server with a modular structure that provides just 
 the parts that the user needs. In particular, we will not use any database/ORM, since we 
 already implemented our own repository layer. The clean architecture works perfectly 
 with other frameworks, like Django, web2py, Pylons, and so on.
  
 Let us start updating the requirements files. The
  requirements/prod.txt
  file shall contain Flask, 
 as this package contains a script that runs a local webserver that we can use to expose the 
 endpoint
  
 Flask
  
 The
  requirements/test.txt
  file will contain the pytest extension to work with Flask (more on 
 this later)",NA
Conclusions,"I hope you can now appreciate the power of the layered architecture that we created. We 
 definitely wrote a lot of code to “just” print out a list of models, but the code we wrote is a 
 skeleton that can easily be extended and modified. It is also fully tested, which is a part of 
 the implementation that many software projects struggle with.
  
 The use case I presented is purposely very simple. It doesn’t require any input and it cannot 
 return error conditions, so the code we wrote completely ignored input validation and 
 error management. These topics are however extremely important, so we need to discuss 
 how a clean architecture can deal with them.",NA
Chapter 3 - Error management,"You sent them out there and you didn’t even warn them! Why didn’t you warn them, Burke?
  
 • Aliens (1986)",NA
Introduction,"In every software project, a great part of the code is dedicated to error management, and 
 this code has to be rock solid. Error management is a complex topic, and there is always a 
 corner case that we left out, or a condition that we supposed could never fail, while it does.
  
 In a clean architecture, the main process is the creation of use cases and their execution. 
 This is, therefore, the main source of errors, and the use cases layer is where we have to 
 implement the error management. Errors can obviously come from the domain models 
 layer, but since those models are created by the use cases the errors that are not managed 
 by the models themselves automatically become errors of the use cases.
  
 To start working on possible errors and understand how to manage them, I will expand the 
 RoomListUseCase
  to support filters that can be used to select a subset of the
  Room
  objects in 
 storage.
  
 The
  filters
  argument could be, for example, a dictionary that contains attributes of the
  Room
  
 model and the thresholds to apply to them. Once we accept such a rich structure, we open 
 our use case to all sorts of errors: attributes that do not exist in the
  Room
  model, thresholds 
 of the wrong type, filters that make the storage layer crash, and so on. All these 
 considerations have to be taken into account by the use case.
  
 In particular, we can divide the error management code into two different areas. The first 
 one represents and manages requests, that is, the input data that reaches our use case. The 
 second one covers the way we return results from the use case through responses, the 
 output data. These two concepts shouldn’t be confused with HTTP requests and responses, 
 even though there are similarities. We are considering here the way data can be passed to 
 and received from use cases, and how to manage errors. This has nothing to do with the 
 possible use of this architecture to expose an HTTP API.
  
 Request and response objects are an important part of a clean architecture, as they 
 transport call parameters, inputs and results from outside the application into the use cases 
 layer.",NA
Basic requests and responses,"We can implement structured requests before we expand the use case to accept filters. We 
 just need a
  RoomListRequestObject
  that can be initialised without parameters, so let us create 
 the file 
 tests/request_objects/test_room_list_request_objects.py
  and put there a test for this object.
  
 from
  rentomatic.request_objects
  import
  room_list_request_object
  as
  req
  
 def
  test_build_room_list_request_object_without_parameters
 ():
  
 request
  =
  req
 .
 RoomListRequestObject()
  
 assert
  bool
 (request)
  is
  True
  
 def
  test_build_room_list_request_object_from_empty_dict
 ():
  
 request
  =
  req
 .
 RoomListRequestObject
 .
 from_dict({})
  
 assert
  bool
 (request)
  is
  True
  
 While at the moment this request object is basically empty, it will come in handy as soon as 
 we start having parameters for the list use case. The code of the
  RoomListRequestObject
  is the 
 following and goes into the
  rentomatic/request_objects/room_list_request_object.py
  file
  
 class
  RoomListRequestObject
 :
  
 @classmethod
  
 def
  from_dict
 (
 cls
 , adict):
  
 return
  cls
 ()
  
 def
  __bool__
 (
 self
 ):
  
 return
  True",NA
Requests and responses in a use case,"Let’s implement the request and response objects that we developed into the use case. The 
 new version of
  tests/use_cases/test_room_list_use_case.py
  is the following
  
 ⁸⁶
 https://github.com/pycabook/rentomatic/tree/chapter-3-basic-requests-and-responses-step-2",NA
Request validation,NA,NA
Responses and failures,"There is a wide range of errors that can happen while the use case code is executed. 
 Validation errors, as we just discussed in the previous section, but also business logic 
 errors or errors that come from the repository layer or other external systems that the use 
 case interfaces with. Whatever the error, the use case shall always return an object with a 
 known structure (the response), so we need a new object that provides good support for 
 different types of failures.
  
 As happened for the requests there is no unique way to provide such an object, and the 
 following code is just one of the possible solutions.
  
 The new version of the
  tests/response_objects/test_response_objects.py
  file is the following
  
 import
  pytest
  
 from
  rentomatic.response_objects
  import
  response_objects
  as
  res
  
 from
  rentomatic.request_objects
  import
  room_list_request_object
  as
  req
  
 @pytest.fixture
  
 def
  response_value
 ():
  
 return
  {
 'key'
 : [
 'value1'
 ,
  'value2'
 ]}
  
 @pytest.fixture
  
 def
  response_type
 ():
  
 return
  'ResponseError'
  
 @pytest.fixture
  
 def
  response_message
 ():
  
 return
  'This is a response error'",NA
Error management in a use case,"Our implementation of requests and responses is finally complete, so we can now 
 implement the last version of our use case. The
  RoomListUseCase
  class is still missing a proper 
 validation of the incoming request.
  
 Let’s change the
  test_room_list_without_parameters
  test in the
  tests/use_cases/test_room_-
 list_use_case.py
  file, adding
  filters=None
  to
  assert_called_with
 , to match the new API
  
 def
  test_room_list_without_parameters
 (domain_rooms): repo
  =
  
 mock
 .
 Mock() 
  
 repo
 .
 list
 .
 return_value
  =
  domain_rooms
  
 room_list_use_case
  =
  uc
 .
 RoomListUseCase(repo) request
  
 =
  req
 .
 RoomListRequestObject()
  
 response
  =
  room_list_use_case
 .
 execute(request)
  
 assert
  bool
 (response)
  is
  True 
  
 repo
 .
 list
 .
 assert_called_with(filters
 =
 None
 ) 
  
 assert
  response
 .
 value
  ==
  domain_rooms",NA
Integrating external systems,"I want to point out a big problem represented by mocks. As we are testing objects using 
 mocks for external systems, like the repository, no tests fail at the moment, but trying to 
 run the Flask development server would certainly return an error. As a matter of fact, 
 neither the repository nor the HTTP server is in sync with the new API, but this cannot be 
 shown by unit tests if they are properly written. This is the reason why we need integration 
 tests, since the real components are running only at that point, and this can raise issues 
 that were masked by mocks.
  
 For this simple project, my integration test is represented by the Flask development server, 
 which at this point crashes with this exception
  
 TypeError
 : execute() missing
  1
  required positional argument:
  'request_object'
  
 Actually, after the introduction of requests and responses, we didn’t change the REST 
 endpoint, which is one of the connections between the external world and the use case. 
 Given that the API of the use case changed, we surely need to change the endpoint code, 
 which calls the use case.",NA
The HTTP server,"As we can see from the above exception the
  execute
  method is called with the wrong 
 parameters in the REST endpoint. The new version of
  tests/rest/test_get_rooms_list.py
  is
  
 import
  json
  
 from
  unittest
  import
  mock
  
 from
  rentomatic.domain.room
  import
  Room
  
 from
  rentomatic.response_objects
  import
  response_objects
  as
  res
  
 room_dict
  =
  {
  
 'code'
 :
  '3251a5bd-86be-428d-8ae9-6e51a8048c33'
 ,
  
 'size'
 :
  200
 ,
  
 'price'
 :
  10
 ,
  
 'longitude'
 :
  -0.09998975
 ,
  
 'latitude'
 :
  51.75436293
  
 }
  
 room
  =
  Room
 .
 from_dict(room_dict)",NA
The repository,"If we run the Flask development webserver now and try to access the
  /rooms
  endpoint, we 
 will get a nice response that says
  
 {
 ""type""
 :
  ""SystemError""
 ,
  ""message""
 :
  ""TypeError: list() got an unexpected keyword argu\ ment 'filters'""
 }
  
 and if you look at the HTTP response
 ⁹²
  you can see an HTTP 500 error, which is exactly the 
 mapping of our
  SystemError
  use case error, which in turn signals a Python exception, which 
 is in the
  message 
 part of the error.
  
 This error comes from the repository, which has not been migrated to the new API. We 
 need then to change the
  list
  method of the
  MemRepo
  class to accept the
  filters
  parameter and 
 to act accordingly.
  
 The new version of the
  tests/repository/test_memrepo.py
  file is
  
 import
  pytest
  
 from
  rentomatic.domain
  import
  room
  as
  r 
  
 from
  rentomatic.repository
  import
  memrepo
  
 @pytest.fixture 
  
 def
  room_dicts
 (): 
  
 return
  [ 
  
  
  
 { 
  
  
  
  
 'code'
 :
  'f853578c-fc0f-4e65-81b8-566c5dffa35a'
 , 
   
  
 'size'
 :
  215
 , 
  
  
  
  
 'price'
 :
  39
 , 
  
  
  
  
 'longitude'
 :
  -0.09998975
 , 
  
  
  
  
 'latitude'
 :
  51.75436293
 , 
  
  
  
 }, 
  
  
  
 { 
  
  
  
  
 'code'
 :
  'fe2c3195-aeff-487a-a08f-e0bdc0ec6e9a'
 , 
  
  
  
 'size'
 :
  405
 , 
  
  
  
  
 'price'
 :
  66
 , 
  
  
  
  
 'longitude'
 :
  0.18228006
 , 
  
  
  
  
 'latitude'
 :
  51.74640997
 , 
  
  
  
 },",NA
Conclusions,"We now have a very robust system to manage input validation and error conditions, and it 
 is generic enough to be used with any possible use case. Obviously, we are free to add new 
 types of errors to increase the granularity with which we manage failures, but the present 
 version already covers everything that can happen inside a use case.
  
 In the next chapter, we will have a look at repositories based on real database engines, 
 showing how to test external systems with integration tests, and how the clean 
 architecture allows us to simply switch between very different backends for services.
  
 ⁹³
 https://github.com/pycabook/rentomatic/tree/chapter-3-the-repository",NA
Chapter 4 - Database repositories,"Ooooh, I’m very sorry Hans. I didn’t get that memo. Maybe you should’ve put it on the 
 bulletin board.
  
 • Die Hard (1988)
  
 The basic in-memory repository I implemented for the project is enough to show the 
 concept of the repository layer abstraction, and any other type of repository will follow the 
 same idea. In the spirit of providing a simple but realistic solution, however, I believe it is 
 worth reimplementing the repository layer with a proper database.
  
 This gives me the chance to show you one of the big advantages of a clean architecture, 
 namely the simplicity with which you can replace existing components with others, 
 possibly based on a completely different technology.",NA
Introduction,"The clean architecture we devised in the previous chapters defines a use case that receives 
 a repository instance as an argument and uses its
  list
  method to retrieve the contained 
 entries. This allows the use case to form a very loose coupling with the repository, being 
 connected only through the API exposed by the object and not to the real implementation. 
 In other words, the use cases are polymorphic with respect to the
  list
  method.
  
 This is very important and it is the core of the clean architecture design. Being connected 
 through an API, the use case and the repository can be replaced by different 
 implementations at any time, given that the new implementation provides the requested 
 interface.
  
 It is worth noting, for example, that the initialisation of the object is not part of the API that 
 the use cases are using since the repository is initialised in the main script and not in each 
 use case. The 
 __init__
  method, thus, doesn’t need to be the same among the repository 
 implementation, which gives us a great deal of flexibility, as different storages may need 
 different initialisation values.
  
 The simple repository we implemented in one of the previous chapters was",NA
A repository based on PostgreSQL,"Let’s start with a repository based on a popular SQL database,
  PostgreSQL⁹⁴
 . It can be 
 accessed from Python in many ways, but the best one is probably through the
  
 SQLAlchemy⁹⁵
  interface. SQLAlchemy is an ORM, a package that maps objects (as in object-
 oriented) to a relational database, and can normally be found in web frameworks like 
 Django or in standalone packages like the one we are considering.
  
 The important thing about ORMs is that they are very good examples of something you 
 shouldn’t try to mock. Properly mocking the SQLAlchemy structures that are used when 
 querying the DB results in very complex code that is difficult to write and almost 
 impossible to maintain, as every single change in the queries results in a series of mocks 
 that have to be written again.
 ⁹⁶
  
 We need therefore to set up an integration test. The idea is to create the DB, set up the 
 connection with SQLAlchemy, test the condition we need to check, and destroy the 
 database. Since the action of creating and destroying the DB can be expensive in terms of 
 time, we might want to do it just at the beginning and at the end of the whole test suite, but 
 even with this change, the tests will be slow. This is why we will also need to use labels to 
 avoid running them every time we run the suite. Let’s face this complex task one step at a 
 time.",NA
Label integration tests,"The first thing we need to do is to label integration tests, exclude them by default and 
 create a way to run them. Since pytest supports labels, called
  marks
 , we can use this feature 
 to add a global mark to a whole module. Create the
  tests/repository/postgres/test_postgresrepo.py
  
 file and put in it this code
  
 import
  pytest
  
 pytestmark
  =
  pytest
 .
 mark
 .
 integration
  
 def
  test_dummy
 ():
  
 pass
  
 The
  pytestmark
  module attribute labels every test in the module with the
  integration
  tag. To 
 verify that this works I added a
  test_dummy
  test function which always passes. You can now 
 run
  py.test-svv -m integration
  to ask pytest to run only the tests marked with that label. The
  -m
  
 option supports a rich syntax that you can learn by reading the
  documentation⁹⁷
 .
  
 ⁹⁴
 https://www.postgresql.org
  
 ⁹⁵
 https://www.sqlalchemy.org",NA
Create the SQLalchemy classes,"Creating and populating the test database with initial data will be part of the test suite, but 
 we need to define somewhere the tables that will be contained in the database. This is 
 where SQLAlchemy’s ORM comes into play, as we will define those tables in terms of 
 Python objects.
  
 Add the packages
  SQLAlchemy
  to the
  prod.txt
  requirements file and update the installed 
 packages with",NA
Spin up and tear down the database container,"When we run the integration tests the Postgres database engine must be already running in 
 the background, and it must be already configured, for example, with a pristine database 
 ready to be used. Moreover, when all the tests have been executed the database should be 
 removed and the database engine stopped.
  
 This is a perfect job for Docker, which can run complex systems in isolation with minimal 
 configuration. We might orchestrate the creation and destruction of the database with 
 bash, but this would mean wrapping the test suite in another script which is not my 
 favourite choice.
  
 The structure that I show you here makes use of docker-compose through the
  pytest-docker
 ,
  
 pyyaml
 , and
  sqlalchemy-utils
  packages. The idea is simple: given the configuration of the 
 database (name, user, password), we create a temporary file containing the docker-
 compose configuration that spins up a Postgres database. Once the Docker container is 
 running, we connect to the database engine with SQLAlchemy to create the database we 
 will use for the tests and we populate it. When all the tests have been executed we tear 
 down the Docker image and we leave the system in a clean status.
  
 Due to the complexity of the problem and a limitation of the
  pytest-docker
  package, the 
 resulting setup is a bit convoluted. The
  pytest-docker
  plugin requires you to create a
  
 docker_compose_file 
 fixture that should return the path of a file with the docker-compose 
 configuration (YAML syntax). The plugin provides two fixtures,
  docker_ip
  and
  docker_services
 : 
 the first one is simply the IP of the Docker host (which can be different from localhost in 
 case of remote execution) while the second is the actual routine that runs the containers 
 through docker-compose and stops them after the test session. My setup to run this plugin 
 is complex, but it allows me to keep all the database information in a single place.",NA
Database fixtures ,"With the
  pg_engine
  fixture we can define higher-level functions such as
  pg_session_empty
  that 
 gives us access to the pristine database,
  pg_data
 , which defines some values for the test 
 queries, and 
 pg_session
  that creates the rows of the
  Room
  table using the previous two 
 fixtures. All these fixtures will be defined in
  tests/repository/postgres/conftest.py
  
 from
  rentomatic.repository.postgres_objects
  import
  Base, Room
  
 [
 ...
 ]
  
 @pytest.fixture
 (scope
 =
 'session'
 )
  
 def
  pg_session_empty
 (pg_engine):
  
 Base
 .
 metadata
 .
 create_all(pg_engine)
  
 Base
 .
 metadata
 .
 bind
  =
  pg_engine
  
 DBSession
  =
  sqlalchemy
 .
 orm
 .
 sessionmaker(bind
 =
 pg_engine)
  
 session
  =
  DBSession()
  
 yield
  session
  
 session
 .
 close()
  
 @pytest.fixture
 (scope
 =
 'function'
 )
  
 def
  pg_data
 ():
  
 return
  [
  
 {
  
 'code'
 :
  'f853578c-fc0f-4e65-81b8-566c5dffa35a'
 ,
  
 'size'
 :
  215
 ,",NA
Integration tests,"At this point we can create the real tests in the
  tests/repository/postgres/test_postgresrepo.py 
 file, 
 replacing the
  test_dummy
  one. The first function is
  test_repository_list_without_parameters
 , which 
 runs the
  list
  method without any argument. The test receives the
  docker_setup
  fixture that 
 allows us to initialise the
  PostgresRepo
  class, the
  pg_data
  fixture with the test data that we put 
 in the database, and the
  pg_session
  fixture that creates the actual test database in the 
 background. The actual test code compares the codes of the rooms returned by the
  list
  
 method and the test data of the
  pg_data
  fixture.
  
 The file is basically a copy of
  tests/repository/postgres/test_memrepo.py
 , which is not surpris-ing. 
 Usually, you want to test the very same conditions, whatever the storage system. Towards 
 the end of the chapter we will see, however, that while these files are initially the same, 
 they can evolve differently as we find bugs or corner cases that come from the specific 
 implementation (in-memory storage, PostgreSQL, and so on).",NA
Running the web server,"Now that the whole test suite passes we can run the Flask web server using a PostgreSQL 
 container. This is not yet a production scenario, but I will not cover that part of the setup, 
 as it belongs to a different area of expertise. It will be sufficient to point out that the Flask 
 development web server cannot sustain big loads, and that a database run in a container 
 will lose all the data when the container is stopped. A production infrastructure will 
 probably run a WSGI server like uWSGI or Gunicorn (
 here¹⁰³
  you can find a curated list of 
 WSGI servers) and a proper database like an AWS RDS instance.",NA
A repository based on MongoDB,"Thanks to the flexibility of clean architecture, providing support for multiple storage 
 systems is a breeze. In this section, I will implement the
  MongoRepo
  class that provides an 
 interface towards MongoDB, a well-known NoSQL database. We will follow the same 
 testing strategy we used for PostgreSQL, with a Docker container that runs the database 
 and docker-compose that orchestrates the spin up and tear down of the whole system.
  
 You will quickly understand the benefits of the complex test structure that I created in the 
 previous section. That structure allows me to reuse some of the fixtures now that I want to 
 implement tests for a new storage system.
  
 Let’s start defining the
  tests/repository/mongodb/conftest.py
  file, which contains the following 
 code
  
 import
  pymongo 
  
 import
  pytest
  
 def
  mg_is_responsive
 (ip, docker_setup): 
  
 try
 : 
  
  
  
 client
  =
  pymongo
 .
 MongoClient( 
  
  
  
  
 host
 =
 docker_setup[
 'mongo'
 ][
 'host'
 ], 
  
  
  
  
 username
 =
 docker_setup[
 'mongo'
 ][
 'user'
 ], 
   
  
 password
 =
 docker_setup[
 'mongo'
 ][
 'password'
 ], 
  
  
  
 authSource
 =
 'admin' 
  
  
  
 ) 
  
  
  
 client
 .
 admin
 .
 command(
 'ismaster'
 ) 
  
  
  
 return
  True 
  
 except
  pymongo
 .
 errors
 .
 ServerSelectionTimeoutError: 
  
  
 return
  False
  
 @pytest.fixture
 (scope
 =
 'session'
 ) 
  
 def
  mg_client
 (docker_ip, docker_services, docker_setup): 
  
 docker_services
 .
 wait_until_responsive( 
  
  
  
 timeout
 =30.0
 , pause
 =0.1
 , 
  
  
  
 check
 =
 lambda
 : mg_is_responsive(docker_ip, docker_setup) )",NA
Conclusions,"This chapter concludes the overview of the clean architecture example. Starting from 
 scratch, we created domain models, serializers, use cases, an in-memory storage system, a 
 command-line interface and an HTTP endpoint. We then improved the whole system with a 
 very generic request/response management code, that provides robust support for errors. 
 Last, we implemented two new storage systems, using both a relational and a NoSQL 
 database.
  
 This is by no means a little achievement. Our architecture covers a very small use case, but 
 is robust and fully tested. Whatever error we might find in the way we dealt with data, 
 databases, requests, and so on, can be isolated and tamed much faster than in a system 
 which doesn’t have tests. Moreover, the decoupling philosophy not only allows us to 
 provide support for multiple storage systems, but also to quickly implement new access 
 protocols, or new serialisations for our objects.",NA
Part 3 - Appendices,NA,NA
Changelog,"What’s the last thing you do remember? Hmm?
  
 • Alien (1979)
  
 I will track here changes between releases of the book, following
  Semantic Versioning¹¹²
 . A 
 change in the
  major
  number means an incompatible change, that is a big rewrite of the 
 book, also known as 2nd edition, 3rd edition, and so on. I don’t know if this will ever 
 happen, but the version number comes for free. A change in the
  minor
  number means that 
 something important was added to the content, like a new section or chapter. A change in 
 the
  patch
  number signals minor fixes like typos in the text or the code, rewording of 
 sentences, and so on.
  
 Current version
 : 1.0.12
  
 Version 1.0.12 (2020-04-13)
  
 • GitHub user
  Vlad Blazhko¹¹³
  found a bug in the
  fileinfo
  project and added a fix and a test 
 condition. As a result, I expanded the chapter on mocks with a small section describing 
 what he did. Many thanks Vlad!
  
 Version 1.0.11 (2020-02-15)
  
 • GitHub user
  lrfuentesw¹¹⁴
  spotted an error in the memory repository. Price filters with 
 a string 
  
 value were not working because they were not converted into integers. 
 Thank you!
  
 Version 1.0.10 (2019-09-23)
  
 • GitHub user
  Ramces Chirino¹¹⁵
  submitted a mega PR with mant grammatical 
 corrections. 
  
 Thanks!
  
 Version 1.0.9 (2019-04-12)
  
 ¹¹²
 https://semver.org/
  
 ¹¹³
 https://github.com/pisarik
  
 ¹¹⁴
 https://github.com/lrfuente
 sw
  
 ¹¹⁵
 https://github.com/chirinos
 ky",NA
