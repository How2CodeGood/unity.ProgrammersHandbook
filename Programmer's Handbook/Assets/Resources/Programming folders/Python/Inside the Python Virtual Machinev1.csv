Larger Text,Smaller Text,Symbol
Inside The Python Virtual Machine,NA,NA
Obi Ike-Nwosu,"This book is for sale at
  http://leanpub.com/insidethepythonvirtualmachine
  
 This version was published on 2019-03-02
  
  
 This is a
  Leanpub
  book. Leanpub empowers authors and publishers with the Lean 
 Publishing process.
  Lean Publishing
  is the act of publishing an in-progress ebook using 
 lightweight tools and many iterations to get reader feedback, pivot until you have the right 
 book and build traction once you do.
  
 © 2015 - 2019 Obi Ike-Nwosu",NA
Also By,NA,NA
 Obi Ike-Nwosu ,Intermediate Python,NA
Contents,"1.
  
 Introduction
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 1
  
 2.
  
 The View From 30,000ft
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 3
  
 3.
  
 Compiling Python Source Code
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 9
  
 4.
  
 3.1
  
 From Source To Parse Tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 9
  
 3.2
  
 Python tokens . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 11
  
 3.3
  
 From Parse Tree To Abstract Syntax Tree . . . . . . . . . . . . . . . . . . . . . . . . .
  
 15
  
 3.4
  
 Building The Symbol Table . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 16
  
 3.5
  
 From AST To Code Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 24
  
 Python Objects
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 37
  
 5.
  
 4.1
  
 PyObject . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 37
  
 4.2
  
 Under the cover of Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 38
  
 4.3
  
 Type Object Case Studies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 41
  
 4.4
  
 Minting type instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 44
  
 4.5
  
 Objects and their attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 48
  
 4.6
  
 Method Resolution Order (MRO) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 59
  
 Code Objects
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 62
  
 6.
  
 5.1
  
 Exploring code objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 62
  
 5.2
  
 Code Objects within other code 
 objects
  
 . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 68
  
 5.3
  
 Code Objects in the VM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 70
  
 Frames Objects
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 72
  
 7.
  
 6.1
  
 Allocating Frame Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 74
  
 Interpreter and Thread States
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 76
  
 8.
  
 7.1
  
 The Interpreter state . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 76
  
 7.2
  
 The Thread 
 state
  
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 78
  
 Intermezzo: The
  abstract.c
  Module
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 84
  
 9.
  
 The evaluation loop,
  ceval.c
  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 88
  
 9.1
  
 Putting names in place . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 88
  
 9.2
  
 The parts of the machine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
  
 90",NA
1. Introduction,"The Python Programming language has been around for quite a while. Development work 
 was started on the first version by Guido Van Rossum in 1989 and it has since grown to 
 become one of the more popular languages that has been used in applications ranging from 
 graphical interfaces to 
 financial¹
  and
  data analysis²
  applications.
  
 This write-up aims to go behind the scene of the Python interpreter and provide a 
 conceptual overview of how a python program is executed. This material targets
  CPython
  
 which as of this writing is the most popular implementation of Python and is considered 
 the standard.
  
  
 Python and CPython are used interchangeably in this text but any mention of Python 
 refers to CPython which is the version of python implemented in C. Other 
 implementations include PyPy which is python implemented in a restricted subset of 
 Python, Jython which
  
 is python implemented on the Java Virtual Machine etc.
  
 I like to think of the execution of a python program as split into two or three main phases 
 as listed below depending on how the interpreter is invoked. These are covered in different 
 measures within this write-up:
  
 1. Initialization : This involves the set up of the various data structures needed by the 
 python process. This will probably only counts when a program is being executed non-
 interactively through the interpreter shell.
  
 2. Compiling : This involves activities such as parsing source code to build syntax trees, 
 creation 
  
 of abstract syntax trees, building of symbol tables and generation of code 
 objects.
  
 3. Interpreting : This involves the actual execution of generated code objects within some 
 context.
  
 The process of generating parse trees and abstract syntax trees from source code is 
 language agnostic so the same methods that apply to other languages also apply to Python; 
 as a result, not much is on this subject is covered here. On the other hand, the process of 
 building symbol tables and code objects from the
  Abstract Syntax tree
  is the more 
 interesting part of the compilation phase which is handled in a more or less python specific 
 way and attention is paid to it. The interpreting of compiled code objects and all the data 
 structures that are used in the process is also covered. Topics that will be touched upon 
 include but are not limited to the process of building symbol tables and generating code 
 objects, python objects, frame objects, code objects, function objects, python opcodes, the 
 interpreter loop, generators and user defined classes.",NA
"2. The View From 30,000ft","This chapter provides a high level expose on how the interpreter goes about executing a 
 python program. In subsequent chapters, we zoom in on the various pieces of puzzle and 
 provide a more detailed description of such pieces. Regardless of the complexity of a 
 python program, this process is the same. The excellent explanation of this process 
 provided by Yaniv Aknin in his
  Python Internal series¹
  provides some of the basis and 
 motivation for this discussion.
  
 Given a python module,
  test.py
 , this module can be executed at the command line by passing 
 it as an argument to the python interpreter program as such
  $python test.py
 . This is just one 
 of the ways of the invoking the python executable - we could start the interactive 
 interpreter, execute a string as code etc but these other methods of execution are not of 
 interest to us. When the module is passed as an argument to the executable on the 
 command line, figure 2.1 best captures the flow of various activities that are involved in the 
 actual execution of the supplied module.
  
  
 Figure 2.1: Flow during execution of source code
  
 The python executable is a
  C
  program just like any other
  C
  program such as the linux kernel 
 or a simple
  hello world
  program in
  C
  so pretty much the same process happens when the 
 python executable is invoked. Take a moment to grasp this, the python executable is just 
 another program that runs your own
  program
 . The same argument can be made for the 
 relationship between
  C
  and 
 assembly
  or
  llvm
 . The standard process initialization which 
 depends on the platform the executable is running on starts once the python executable is 
 invoked with module name as argument,
  
 ¹
 https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/",NA
3. Compiling Python Source Code,"Although python is not popularly regarded as a compiled language, it actually is one. 
 During compilation, some python source code is transformed into bytecode that is 
 executable by the virtual machine. This compilation process in python is however a 
 straightforward process that does not involve
  lots
  of complicated steps. The compilation 
 process of a python program involves the following steps in the given order.
  
 1. Parsing the python source code into a parse tree.
  
 2. Transforming the parse tree into an abstract syntax tree 
 (AST). 3. Generation of the symbol table.
  
 4. Generation of the code object from the AST. This step involves:
  
 1. Transforming the AST into a flow control graph.
  
 2. Emitting a code object from the control flow graph.
  
 Parsing source code into a parse tree and transforming that parse tree into an AST is a 
 standard process and python does not introduce any complicated nuances so the focus of 
 this chapter is on the transformation of an AST into a control flow graph and the emission 
 of code object from the control flow graph. For anyone interested in parse tree and AST 
 generation, the
  dragon book¹
 provides a much more indepth
  tour de force
  of both topics.",NA
3.1 From Source To Parse Tree,"The python parser is an
  LL(1)²
  parser that is based on the description of such parsers as 
 laid out the Dragon book. The
  Grammar/Grammar
  module contains the Extended Backus-Naur 
 Form
  (EBNF) 
 grammar specification for the Python language. A cross section of this 
 specification is shown in listing 3.0.
  
 ¹
 https://www.amazon.co.uk/Compilers-Principles-Techniques-Alfred-
 Aho/dp/0201100886
 ²
 https://en.wikipedia.org/wiki/LL_parser",NA
3.2 Python tokens,"Python source code is made up of tokens. For example, the
  return
  word is a keyword token, 
 the literal -
  2
  is a numeric literal token and so on. The first task while parsing python source 
 is to tokenize the source that is break it into its component tokens. Python has a number of 
 tokens such as the following.
  
 1. identifiers : These are names that defined by a programmer. They include function 
 names, variable names, class names etc. These must conform to the rules of identifiers 
 as specified in the python documentation.
  
 2. operators: these are special symboles such as
  +
 ,
  *
  that operate on data values and 
 produce 
  
 results.
  
 3. delimiters: this group of symbols serve to group expressions, provide punctuations 
 and 
  
 assignment. Examples in this category include
  (, )
 ,
  {,}
 ,
  =
 ,
  *=
  etc.
  
 4. literals: these are symbols that provide a constant value for some type. We have the 
 string and byte literals such as
  ""Fred""
 ,
  b""Fred""
  and numeric literals which include integer 
 literals such as
  2
 , floating point literal such as
  1e100
  and imaginary literals such as
  10j
 .
  
 5. comments: these are string literals that start with the hash symbol. Comment tokens 
 always 
  
 end at the end of the physical line.
  
 6. NEWLINE: this is a special token that denotes the end of a logical line.
  
 7. INDENT and DEDENT: These token are used to represent indentation levels which 
 group 
  
 compound statements.
  
 A group of tokens delineated by the
  NEWLINE
  token make up a logical line hence we could 
 say that a python program is made up of a sequence of
  logical lines
  with each logical line 
 delineated by the
  NEWLINE
  token. These logical lines maps to python statements. Each of 
 these logical lines are made up of a number of physical lines that are each terminated by an 
 end-of-line sequence. In python, most times logical lines map to physical line so we have 
 logical line delimited by end-of-line characters. Compound statements can span multiple 
 physical lines such as shown in figure 3.0. Logical lines can be joined together implicitly 
 when expression are in parentheses, square brackets or curly braces or explicitly by the 
 use of the backslash character. Indentation also plays a central role in grouping python 
 statements. One of lines in the python grammar is thus
  suite: simple_stmt | NEWLINE INDENT 
 stmt+ DEDENT
  so one of the major task of the python tokenizer is to generate indent and 
 dedent tokens that go into the parse tree. The tokenizer uses a stack to keep track of 
 indents and uses the algorithm in listing 3.1 to generate INDENT and DEDENT tokens.",NA
3.3 From Parse Tree To Abstract Syntax Tree,"The next stage of the compilation process is the transformation of a python parse trees to 
 an
  Abstract Syntax Tree
  (AST). The abstract syntax tree is a representation of the code that 
 is independent of the niceties of python’s syntax. For example, a parse tree contains the 
 colon node as shown in figure 3.0 because it is a syntax construct but the AST will not 
 contain such syntax construct as shown in listing 3.4.
  
 Listing 3.4: Using the
  ast
  module to manipulate the AST of python source code
  
 1
  
  
 2
  
  
 3
  
  
 4
  
  
 5
  
  
 6
  
  
 7
  
  
 8
  
 >>>
  import
  ast 
  
 >>>
  import
  pprint 
  
 >>>
  node
  =
  ast
 .
 parse(code_str, mode
 =
 ""exec""
 ) 
  
 >>>
  ast
 .
 dump(node) 
  
 (
 ""Module(body=[FunctionDef(name='hello_world', args=arguments(args=[], "" 'vararg=None, 
 kwonlyargs=[], kw_defaults=[], kwarg=None, defaults=[]), ' 
 ""body=[Return(value=Str(s='hello world'))], decorator_list=[], "" 
  
 'returns=None)])'
 )
  
 The definitions of the AST nodes for the various Python are found in the file
  
 Parser/Python.asdl 
 file. Most definitions in the AST correspond to a particular source 
 construct such as an
  if
  statement or an attribute lookup. The
  ast
  module bundled with the 
 python interpreter provides us with the ability to manipulate a python AST. Tools such as
  
 codegen
 ⁴
  can take an
  AST
  representation in python and output the corresponding python 
 source code. In the CPython implementation, the
  AST 
 nodes are represented by
  C
  structures 
 as defined in the
  Include/Python-ast.h
 . These structures are actually generated by python 
 code; the
  Parser/asdl_c.py
  module generates this file from the
  AST 
 asdl definition. For example 
 a cross-section of the definition of a
  statement
  node is shown in listing 3.5.
  
 Listing 3.5: A cross-section of an AST statement node data structure
  
 1
  
  
 2
  
  
 3
  
  
 4
  
  
 5
  
  
 6
  
  
 struct
  _stmt { 
  
  
 enum
  _stmt_kind kind; 
  
  
 union
  { 
  
  
  
 struct
  { 
  
  
  
  
 identifier name; 
  
  
  
  
 arguments_ty args; 
  
  
  
  
 asdl_seq
  *
 body; 
  
  
  
  
 asdl_seq
  *
 decorator_list; 
  
  
  
  
 expr_ty returns;
  
  
 ⁴
 https://pypi.python.org/pypi/codegen/1.0",NA
3.4 Building The Symbol Table,"With the
  AST
  generated, the next step of the process is the generation of a symbol table. The 
 symbol
  
 table just like the name suggest is a collection of the names within a code block and the 
 context
  
 in whic such names are used. The process of building the symbol table involves the analysis 
 of the
  
 names contained within a code block and the assignment of the correct scoping to such 
 names.",NA
Names and Binding,"In python, objects are referenced by
  names
 .
  names
  are analogous to
  but not exactly
  variables in
  
 C++ 
 and
  Java
 .
  
 >>>
  x
  = 5
  
 In the above, example,
  x
  is a name that references the object,
  5
 . The process of
  assigning
  a 
 reference to
  5
  to
  x
  is called
  binding
 . A binding causes a name to be associated with an object 
 in the innermost scope of the currently executing program. Bindings may occur during a 
 number of instances such as during variable assignment or function or method call when the 
 supplied parameter is bound to the argument. It is important to note that names are just 
 symbols and they have no
  type
  associated with them;
  names are just references to objects 
 that actually have types
 .
  
 Code Blocks
  
 Code blocks are central to python program and understanding them for what they are is 
 paramount to understanding the internals of the python virtual machine. A code block is a 
 piece of program code that is executed as a single unit in python. Modules, functions and 
 classes are all examples of code blocks. Commands typed in interactively at the REPL, script 
 commands run with the
  -c
  option are also code blocks. A code block has a number of name-
 spaces associated with it. For example, a module code block has access to the
  global
  name-
 space while a function code block has access to the
  local
  as well as the
  global
  name-spaces.
  
 Namespaces
  
 A
  namespace
  as the name implies is a context in which a given set of names is bound to 
 objects. Namespaces are implemented as dictionary mappings in python. The
  builtin
  
 namespace is an example of a name-space that contains all the built-in functions and this can 
 be accessed by entering 
 __builtins__.__dict__
  at the terminal (the result is of a considerable 
 amount). The interpreter has access to multiple namespaces including
  the global name-
 space
 ,
  the builtin namespace
  and
  the local namespace
 . These namespaces are created at 
 different times and have different lifetimes. For example, a new
  local
  namespace is created 
 at the invocation of a function and forgotten when the function exits or returns. The
  global
  
 namespace is created at the start of the execution of a module and all names defined in this 
 namespace are available module wide while the
  built-in
  namespace comes into existence 
 when the interpreter is invoked and contains all the builtin names. These three name-spaces 
 are the main namespaces available to the interpreter.
  
 Scopes
  
 A scope is an area of a program in which a set of name bindings (namespaces) is visible and 
 directly accessible without using any dot notation. At runtime, the following scopes may be 
 available.
  
 1. Inner most scope with local names 
  
 2. The scope of enclosing functions if any (this is applicable for nested 
 functions) 3. The current module’s
  globals
  scope 
  
 4. The scope containing the builtin namespace.",NA
Symbol table data structures,"Two data structures that are central to the generation of a symbol table are:
  
 1. The symbol table data structure.
  
 2. The symbol table entry data structure.
  
 The symbol table data structure is shown in listing 3.7. One can think of this as a table that 
 is composed of entries that hold information on the names used in different code blocks of 
 a given module.
  
 Listing 3.7: The symtable data structure
  
 1 
  
 2 
  
 3 
  
 4 
  
 5 
  
 6 
  
 7 
  
 8 
  
 9 
  
 1
 0 
  
 struct
  symtable {
  
 PyObject
  *
 st_filename;
  
 /* name of file being compiled */
  
 struct
  _symtable_entry
  *
 st_cur;
  /* current symbol table entry */ 
 struct
  
 _symtable_entry
  *
 st_top;
  /* symbol table entry for module */
  
 PyObject
  *
 st_blocks;
  
 /* dict: map AST node addresses
  
 *
  
 to symbol table entries */
  
 PyObject
  *
 st_stack;
  
 /*list: stack of namespace info */
  
 PyObject
  *
 st_global;
  
 /*borrowed ref to
  
 st_top->ste_symbols*/
  
 int
  st_nblocks;
  
 /* number of blocks used. kept for
  
 consistency with the corresponding 
  
 compiler structure */
  
 PyObject
  *
 st_private;
  
 /* name of current class or NULL */
  
 PyFutureFeatures
  *
 st_future;
  
 /* module's future features that",NA
3.5 From AST To Code Objects,"With the symbol table generated, the next step for the compiler is to generate code objects 
 from the
  AST
  incorporating information contained in the symbol table; the functions that 
 handle this step are implemented in the
  Python/compile.c
  module. This process of generating 
 code objects is also a multi-step process. In the first step, the
  AST
  is converted into basic 
 blocks of python byte code instructions. The algorithm for this is similar to that used in 
 generating symbol tables - functions named
  compiler_visit_xx
  where
  xx
  is the node type are 
 used to recursively visit each node type emitting basic blocks of python bytecode 
 instructions during the visit process. The basic blocks and paths between them implicitly 
 represent a graph - the control flow graph. This graph shows the code paths that can be 
 taken during the execution of a program. In the second step, the generated control flow 
 graph is flattened using a post-order depth first search transversal. After the graph is 
 flattened, the jump offsets are then calculated and used as instruction argument for byte 
 code
  jump 
 instructions. The code object is emitted from the this set of instructions. To get a 
 good understanding of this process, consider the the
  fizzbuzz
  function in listing 3.11.",NA
Assembling basic blocks,"Once the CFG is generated, the basic blocks now contain bytecode instructions that 
 represent the 
 AST
  but the blocks are not ordered linearly and in the case of jump 
 statements, the instructions still have basic blocks as jump targets rather than relative or 
 absolute offsets into the instruction stream. The
  assemble
  function handles the linearization 
 of the CFG and creation of code object from the CFG.
  
 First, the assemble function adds instructions for a
  return None
  statement to any block that 
 ends without a
  RETURN
  statement - now you know why you can define methods without 
 adding a
  RETURN 
 statement. This is followed by a
  post-order
  depth first traversal of the 
 implicit
  CFG
  graph in order to flatten out the blocks - the post order traversal visits the 
 children of a node before visiting the node itself.",NA
Graph Traversal,"In a post-order depth-first traversal of a graph, we recursively visit the left child 
 node of the graph followed by the right child node of the graph then the node itself. 
 In our graph in figure 3.5, when the graph is flattened using a post-order traversal, 
 the order of the nodes is 
 H -> D -> I -> J -> E -> B -> K -> L -> F -> G -> C -> A
 . This is in 
 contrast to an pre-order traversal that produces
  A -> B -> D -> H -> E -> I -> J -> C -> F -> K -> 
 L-> G
  or a in-order traversal that produces
  H -> D -> B -> I -> E -> J -> A -> K -> L
  
 -> F -> C -> G
  
 The CFG of the
  fizzbuzz
  function given in listing 3.3 is a relatively simple graph - the result of 
 the 
 post-order
  traversal for the
  fizzbuzz
  is
  block 5 -> block 4 -> block 3 -> block 2 -> block 1
 . Once this 
 graph has been linearized (i.e flattened), the offsets for instructions jumps can then be 
 calculated by calling the
  assemble_jump_offsets
  function on the flattened graph.
  
 Assembling the jump offsets takes place in two phases. In the first phase, the offset of every 
 instruction into the instruction array is calculated as shown in the snippet from listing 3.16. 
 This is a simple loop that works from the end of the flattened array building up the offset 
 from 0.",NA
4. Python Objects,"In this chapter, we look at python objects and their implementation in the CPython virtual 
 machine. A fundamental understanding of how the python objects are organized is 
 important to groking the internals of the python virtual machine. Most of the source that is 
 discussed here is available from the the
  Include/
  and
  Objects/
  directories. Unsurprisingly, the 
 implementation of the object system in python is quite complex and we try to avoid getting 
 bogged down in the gory details of the
  C 
 implementation. To kick this off, we start by 
 looking at the
  PyObject
  structure - the workhorse of the python object system.",NA
4.1 PyObject,"A cursory inspection of the CPython source code will show the ubiquity of the
  PyObject
  
 structure. Infact, as we will see later on in this treatise, when the interpreter loop is 
 working on values on the evaluation stack, all of such values are regarded as
  PyObject
 s
 . For 
 want of a better term, we refer to this as the
  super class
  of all python objects. Values are 
 actually never declared as
  PyObject
 s but a pointer to any object can be cast to a
  PyObject
 . In 
 layman’s term, any object can be treated as a 
 PyObject
  structure because the initial segment 
 of all objects is actually a
  PyObject
  structure.",NA
A word on,C,NA
 structs.,"When we say
  values are never declared as
  PyObject
 s but a pointer to any object can be 
 cast to a
  PyObject
  we are referring to an implementation detail dependent on the C 
 programming langugage and how it interprets data at memory locations. C structs 
 which are used to represent python objects are just groups of bytes which we can 
 interpret in any manner which choose to. For example, a struct,
  test
 , maybe 
 composed of 5
  short
  values each 2 bytes in size and summing up to 10 bytes. In C, 
 given a reference to ten bytes we can interpret those ten bytes as
  test
  struct 
 composed of 5 short values regardless of whether the 10 bytes were actually defined 
 as a
  test
  struct - however the output when you try to access the fields of the
  struct
  
 maybe gibberish. This means that given
  n
  bytes of data that represent a python 
 object where
  n
  is greater than the size of a PyObject, we can interpret the first n bytes 
 as a PyObject.
  
 The
  PyObject
  structure is shown in listing 4.0 and is composed of a number of fields that 
 must be filled in order for a value to be treated as an object.",NA
A word on reference counting.,"CPython uses reference counting for memory management. This is a simple method 
 in which whenever a new reference to an object is created such as the case of binding 
 a name to an object as in listing 4.1, the reference count of the object goes up. The 
 converse is true -whenever a reference to an object goes away (for example using a
  
 del
  on name deletes the reference), the reference count is decremented. When the 
 reference count of an object gets to zero, it can be deallocated by the VM. In the VM 
 world, the
  Py_INCREF
  and
  Py_DECREF
  are used to increase and decrease reference count 
 of objects and they show up in a lot of code snippets that we discuss.
  
 Types in the VM are implemented using the
  _typeobject
  data structure defined in the
  
 Objects/Object.h 
 module. This is a C
  struct
  with fields for mostly functions or collection of 
 functions that are filled in by each type. We look at this data structure next.",NA
4.2 Under the cover of Types,"The
  _typeobject
  structure defined in
  Include/Object.h
  serves as the base structure of
  all
  python 
 types. The data structure defines a large number of fields that are mostly pointers to C 
 functions that",NA
4.3 Type Object Case Studies,NA,NA
The,tuple,NA
 type,"We look at the
  tuple
  type to get a feel for how the fields of a type object are populated. We 
 choose this because it is relatively easy to grok given the small size of the implementation - 
 roughly a thousand plus lines of
  C
  including documentation strings. The implementation for 
 the
  tuple
  type is shown in listing 4.3.
  
 Listing 4.3: Tuple type definition
  
 1
  
 PyTypeObject PyTuple_Type
  =
  {
  
 /* tp_dealloc */
  
 2
  
 PyVarObject_HEAD_INIT(
 &
 PyType_Type,
  0
 )
  
 3
  
 ""tuple""
 ,
  
 4
  
 sizeof
 (PyTupleObject)
  -
  sizeof
 (PyObject
  *
 ),
  
 5
  
 sizeof
 (PyObject
  *
 ),
  
 6
  
 (destructor)tupledealloc,
  
 7
  
 0
 ,
  
 /* tp_print */
  
 8
  
 0
 ,
  
 /* tp_getattr */
  
 9
  
 0
 ,
  
 /* tp_setattr */
  
 10
  
 0
 ,
  
 /* tp_reserved */
  
 11
  
 (reprfunc)tuplerepr,
  
 /* tp_repr */
  
  
 ²
 https://docs.python.org/3.6/library/stdtypes.html#sequence-types-list-tuple-range",NA
The,type,NA
 type,"The other type we would like to look at is the
  type
  type. This the
  metatype
  for all builtin 
 types and the vanilla user-defined type (a user can define a new metatype) - notice how 
 this type is used in initializing the
  tuple
  object in
  PyVarObject_HEAD_INIT
 . When discussing 
 types it is important to distinguish between objects that have
  type
  as their type and objects 
 that have a user defined type as their type. This comes very much to the fore when dealing 
 with attribute referencing in objects.
  
 This type defines methods that are used when working with types and the fields are similar 
 to those from the previous section. When creating new types as we will see in subsequent 
 sections, it is this type that is used.",NA
The,object,NA
 type,"Another important type is the
  object
  type which is very similar to the
  type
  type. The object 
 type is the root type for all user defined types and provides some default values that are 
 used to fill in the",NA
4.4 Minting type instances,"With an assumed firm understanding of the rudiments of types, we can progress onto one 
 of the most fundamental functions of types which is the ability to create an instance of a 
 type. To fully understand the process of creating new type instances, it is important to 
 remember that just as we differentiate between builtin types and user defined types
  ⁴
 , the 
 internal structure of both will most likely differ too. The
  tp_new
  field is the cookie cutter for 
 new type instances in python. The 
 documentation⁵
  for the
  tp_new
  slot as reproduced below 
 gives a brilliant description of the function that should fill this slot.
  
 An optional pointer to an instance creation function. If this function is NULL for a 
 particular type, that type cannot be called to create new instances; presumably 
 there is some other way to create instances, like a factory function. The function 
 signature is
  
 PyObject *tp_new(PyTypeObject *subtype, PyObject *args, PyObject *kwds)
  
 The subtype argument is the type of the object being created; the
  args
  and
  kwds 
 arguments represent positional and keyword arguments of the call to the type. 
 Note that subtype doesn’t have to equal the type whose tp_new function is called; 
 it may be a subtype of that type (but not an unrelated type). The
  tp_new
  function 
 should call 
 subtype->tp_alloc(subtype, nitems)
  to allocate space for the object, and then 
 do only as much further initialization as is absolutely necessary. Initialization that 
 can safely be ignored or repeated should be placed in the
  tp_init
  handler. A good 
 rule of thumb is that for immutable types, all initialization should take place in
  
 tp_new
 , while for mutable types, most initialization should be deferred to
  tp_init
 .
  
 This field is inherited by subtypes, except it is not inherited by static types whose
  
 tp_base 
 is
  NULL
  or &PyBaseObject_Type.
  
 We will use the
  tuple
  type from the previous section as an example of a builtin type. The
  
 tp_new
  field of the tuple type references the -
  tuple_new
  method shown in listing 4.4 which 
 handles the creation of new tuple objects. To create a new tuple object, this function is 
 dereferenced and invoked.",NA
4.5 Objects and their attributes,"Types and their attributes
  (variables and methods)
  are central to object oriented 
 programming. Conventionally, types and instances store their attributes using a
  dict
  data 
 structure - this is not the full story in the case of instances when
  __slots__
  are defined . The
  
 dict
  data structure can be found in one of two places depending on the type of the object as 
 was mentioned in the previous section.
  
 1. For objects that have a type of
  Type
 , the
  tp_dict
  slot of type structure is a pointer to a
  dict 
  
 that contains values, variables and methods for that type. In the more conventional 
 sense we 
  
 say the
  tp_dict
  field of the type object data structure is a pointer to the
  type
  or
  
 class dict
 . 2. For objects that have a type other than type
  (i.e instances of user defined types)
 , 
 that
  dict
  data 
  
 structure when present is located just after the
  PyObject
  structure that 
 represents the object.
  
 The
  tp_dictoffset
  value of the type of the object gives the offset from the start of an object 
 to this instance
  dict
  contains the instance attributes.
  
 Doing a simple diction access to obtain attributes seems straightforward but this is hardly 
 the end of the story. Infact, searching for attributes is way more involved than just checking
  
 tp_dict
  value for instance of 
  
 Type
  or the
  dict
  at
  tp_dictoffset
  for instances of user defined types. To get a full understanding, 
 we have to discuss the
  descriptor protocol
  - a protocol that is at the heart of attribute 
 referencing in python.
  
 The
  Descriptor HowTo Guide⁶
  is an excellent introduction to descriptors but a cursory 
 description of descriptors is provided here. Simply put, a
  descriptor
  is an
  object
  that 
 implements the
  __get__
 ,",NA
Examples of Attribute Referencing with Descriptors inside the VM,"Descriptors play a very major role in attribute referencing in Python. Consider the
  type
  data 
 structure discussed earlier on in this chapter. The
  tp_descr_get
  and
  tp_descr_set
  fields in a type 
 data structure can be filled in by any type instance that wishes to be treated as a descriptor. 
 A function object is a very good place to show how this works.
  
 Given the type definition,
  Account
  from listing 4.11, consider what happens when we 
 reference the method,
  name_balance_str
 , from the class as such -
  Account.name_balance_str
  and 
 when we reference the same method from an instance as shown in listing 4.14.
  
 Listing 4.14: Illustrating bound and unbound functions
  
 >> a = Account() 
  
 >> a.name_balance_str 
  
 <
 bound
  method Account
 .
 name_balance_str of
  <
 __main__
 .
 Account object at 
 0x102a0ae10
 >>
  
 >> Account.name_balance_str 
  
 <
 function
  Account
 .
 name_balance_str at 0x102a2b840
 >",NA
4.6 Method Resolution Order (MRO),"We have mentioned
  mro
  when discussing attribute referencing but without discussing 
 much about it so in this section we go into a bit more detail on
  mro
 . In python, types can 
 belong to a multiple inheritance hierarchy so there is need for an order in which methods 
 are searched when a type inherits from multiple classes; this order which is referred to as 
 |
 Method Resolution Order (MRO)
  is also actually used when searching for other non-method 
 attributes as we saw in the algorithm for attribute reference resolution. The article,
  Python 
 2.3 Method Resolution order⁷
 , is an excellent and easy to read documentation of the 
 method resolution algorithm used in python; a summary of the main points are reproduced 
 here.
  
 Python uses the
  C3⁸
  algorithm for building the
  method resolution order
  (also referred to as 
 linearization
  here) when a type inherits from multiple base types. Some notations used in 
 explaining this algorithm are shown in listing 4.25.
  
 C1 C2 ... CN denotes the list of classes 
  
 [C1, C2, C3 .., CN]
  
 The head of the list is its first element: head = C1
  
 The tail is the rest of the list: tail = C2 ... CN.
  
 C + (C1 C2 ... CN) = C C1 C2 ... CN denotes the sum of the lists [C] +
  
 [C1, C2, ... ,CN].
  
 Consider a type
  C
  in a multiple inheritance hierarchy, with
  C
  inheriting from the base types
  
 B1, B2, ... , BN
 , the linearization of
  C
  is the sum of
  C
  plus the merge of the linearizations of the 
 parents and the list of the parents -
  L[C(B1 ... BN)] = C + merge(L[B1] ... L[BN], B1 ... BN)
 . The 
 linearization of the
  object
  type which has no parents is trivial -
  L[object] = object
 . The
  merge 
 operation is calculated according to the following
  algorithm⁹
 :
  
 take the head of the first list, i.e L[B1][0]; if this head is not in the tail of any of the 
 other lists, then add it to the linearization of C and remove it from the lists in the 
 merge, otherwise look at the head of the next list and take it, if it is a good head. 
 Then repeat the operation until all the class are removed or it is impossible to 
 find good heads. In this case, it is impossible to construct the merge, Python 2.3 
 will refuse to create the class C and will raise an exception.
  
 Some type hierarchies cannot be linearized using this algorithm and in such cases the VM 
 throws an error and does not create such hierarchies.
  
 ⁷
 https://www.python.org/download/releases/2.3/mro/
  
 ⁸
 http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.19.3910&rep=rep1&t
 ype=pdf
 ⁹
 https://www.python.org/download/releases/2.3/mro/",NA
5. Code Objects,"In this part of the write-up, we explore code objects. Code objects are central to the 
 operation of the python virtual machine. Code objects encapsulate the bytecode of the 
 python virtual machine; we may call the bytecode the assembly language for the python 
 virtual machine.
  
 Code objects as the name suggests represent compiled executable python code. We have 
 seen code objects before when we discussed the compilation of python source. Code 
 objects are produced whenever a block of python code is compiled. As described in the 
 brilliant
  python documentation¹
  
 A Python program is constructed from code blocks. A block is a piece of Python 
 program text that is executed as a unit. The following are blocks: a module, a 
 function body, and a class definition. Each command typed interactively is a 
 block. A script file (a file given as standard input to the interpreter or specified as 
 a command line argument to the interpreter) is a code block. A script command 
 (a command specified on the interpreter command line with the ‘-c’ option) is a 
 code block. The string argument passed to the built-in functions
  eval()
  and
  exec()
  is 
 a code block.
  
 The code object contains runnable bytecode instructions that when run alter the state of 
 the python virtual machine. Given a function, we can access the code object for the function 
 body using the 
 __code__
  attribute of the function as in the following snippet.
  
 Listing 5.1: Function code objects
  
 def return_author_name():
  
 return ""obi Ike-Nwosu""
  
 >>> return_author_name.__code__
  
 <
 code
  object return_author_name at 0x102279270
 ,
  file
  ""<
 stdin
 >"", line 1>
  
 For other code blocks, one can obtain the code objects for that code block by compiling 
 such code. The
  compile²
  function provides a facility for this in the python interpreter. The 
 code objects come with a number of fields that are used by the interpreter loop when 
 executing and we look at some of these fields in the following sections.",NA
5.1 Exploring code objects,"A good place to start with code objects is be to compile a simple function and inspect the 
 code object generated by that function. We use the simple
  fizzbuzz
  function as a guinea pig 
 as shown in listing 5.2.",NA
The bytecode -,co_code,NA
 in more detail.,"The actual virtual machine instructions for a code object, the bytecode, are contained in the
  
 co_code 
 field of a code object as previously mentioned. The byte code from the
  fizzbuzz
  
 function for example is the string of bytes shown in listing 5.7.",NA
5.2 Code Objects within other code objects,"Another code block code object that is worth looking at is that of a module being compiled. 
 Assuming we were compiling a module with the
  fizzbuzz
  function as content, what would the 
 output, look like? To find out, we use the
  compile
  function in python to compile a module 
 with the content shown in listing 5.9.",NA
5.3 Code Objects in the VM,NA,NA
6. Frames Objects,"Code objects contain the executable byte code but lack the contextual information required 
 for the execution of such code. Take the set of bytecode instructions in listing 6.0 for 
 example,
  LOAD_COST 
 takes an index as argument but the code object has no array or data 
 structure that contains data to load the value at the index from.
  
 Listing 6.0: A set of bytecode instructions
  
 0 LOAD_CONST
  
 0 (<
 code
  object f at 0x102a028a0
 ,
  file
  ""
 fizzbuzz
 .
 py
 "",\
  
 line 1
 >) 
  
  
 2 LOAD_CONST 
  
 1 ('f') 
  
  
 4 MAKE_FUNCTION 
  
 0 
  
  
 6 STORE_NAME 
  
 0 (f) 
  
  
 8 LOAD_CONST 
  
  
 2 (None) 10 RETURN_VALUE
  
 Another data structure that provides such contextual information is required for the 
 execution of code objects and this is where frame objects come in. One can think of the 
 frame object as a container in which the code object is executed - it knows about the code 
 object and has references to data and values that are required during the execution of some 
 code object. As usual, python does indeed provide us with some facilities to inspect frame 
 objects using the
  sys._getframe()
  function as shown in the listing 6.1 snippet.
  
 Listing 6.1: Accessing frame objects
  
 >>>
  import
  sys 
  
 >>>
  f
  =
  sys
 .
 _getframe() 
  
 >>>
  f 
  
 <
 frame
  object
  at
  0x10073ed48> 
  
 Traceback (most recent call last): 
  
 File
  ""<stdin>""
 , line
  1
 ,
  in
  <
 module
 > 
  
 NameError
 : name
  'f_'
  is not
  defined 
  
 >>>
  dir
 (f) 
  
 [
 '__class__'
 ,
  '__delattr__'
 ,
  '__dir__'
 ,
  '__doc__'
 ,
  '__eq__'
 ,
  '__format__'
 , 
 '__ge__'
 ,
  '__getattribute__'
 ,
  '__gt__'
 ,
  
 '__hash__'
 ,
  '__init__'
 ,
  '__le__'
 , 
 '__lt__'
 ,
  '__ne__'
 ,
  '__new__'
 ,
 '__reduce__'
 ,
  '__reduce_ex__'
 ,
  '__repr__'
 , 
 '__setattr__'
 ,
  '__sizeof__'
 ,
  '__str__'
 ,
  '__subclasshook__'
 ,
  'clear'
 , 
 'f_back'
 ,
  'f_builtins'
 ,
  'f_code'
 ,
  
 'f_globals'
 ,
  'f_lasti'
 ,
  'f_lineno'
 , 
 'f_locals'
 ,
  'f_trace'
 ]",NA
6.1 Allocating Frame Objects,"Frame objects are ubiquitous during python code evaluation - every code block that is 
 executed needs a frame object that provides some context. New frame objects are created 
 by a invoking the 
 PyFrame_New
  function in the
  Objects/frameobject.c
  module. This function is 
 invoked so many times - whenever a code object is executed, that two main optimizations",NA
7. Interpreter and Thread States,"As disucussed in opening chapters, one of the steps during the bootstrapping of the python 
 interpreter is the initialisation of the interpreter state and thread state data structures. In 
 this chapter, we look at these data structures in detail and explain the importance of these 
 data structures.",NA
7.1 The Interpreter state,"The
  Py_Initialize
  function from the
  pylifecycle.c
  module is one of the bootstrap functions 
 invoked during the intialisation of the python interpreter. The function handles the set-up 
 of the python runtime as well as the initialisation of the interpreter state and thread state 
 data structures among other things.
  
 The interpreter state is a very simple data structure that captures the global state that is 
 shared by a set of cooperating threads of execution in a python process. A cross section of 
 this data structure definition is provided in listing 7.0 to provide some insight into this very 
 important data structure.
  
 Listing 7.0: Cross-section of the interpreter state data structure
  
 typedef struct
  _is {
  
 struct
  _is
  *
 next; 
  
 struct
  _ts
  *
 tstate_head;
  
 PyObject
  *
 modules; 
  
 PyObject
  *
 modules_by_index; 
  
 PyObject
  *
 sysdict; 
  
 PyObject
  *
 builtins; 
  
 PyObject
  *
 importlib;
  
 PyObject
  *
 codec_search_path; 
  
 PyObject
  *
 codec_search_cache; 
  
 PyObject
  *
 codec_error_registry; 
  
 int
  codecs_initialized; 
  
 int
  fscodec_initialized;
  
 ...",NA
7.2 The Thread state,"Jumping straight into the exploring the
  Thread state
  data structure which is shown in 
 listing 7.1, one can see that the thread state data structure is a more involved data structure 
 than the interpreter state data structure.
  
 Listing 7.2: Cross-section of the thread state data structure
  
 typedef struct
  _ts { 
  
 struct
  _ts
  *
 prev; 
  
 struct
  _ts
  *
 next; 
  
 PyInterpreterState
  *
 interp;
  
 struct
  _frame
  *
 frame; 
  
 int
  recursion_depth; 
  
 char
  overflowed; 
  
 char
  recursion_critical; 
  
 int
  tracing; 
  
 int
  use_tracing;
  
 Py_tracefunc c_profilefunc; 
  
 Py_tracefunc c_tracefunc; 
  
 PyObject
  *
 c_profileobj; 
  
 PyObject
  *
 c_traceobj;
  
 PyObject
  *
 curexc_type; 
  
 PyObject
  *
 curexc_value; 
  
 PyObject
  *
 curexc_traceback;
  
 PyObject
  *
 exc_type; 
  
 PyObject
  *
 exc_value; 
  
 PyObject
  *
 exc_traceback;
  
 ...
  
 } PyThreadState;
  
 The
  next
  and
  previous
  fields of a thread state data structure reference threads states created 
 prior to and just after the given thread state. These fields form a doubly linked list of thread 
 states that share a single interpreter state. The
  interp
  field references the interpreter state",NA
Global Interpreter Lock -,GIL,NA
The Need for a GIL,"Before we begin any discussion on the
  GIL
 , it is worthwhile to ask why we need a global lock 
 that will probably adversely affects our threads? There are a myriad of reasons why the
  GIL
  
 is relevant. First of all however, it is important to understand that the
  GIL
  is an 
 implementation detail of CPython and not an actual language detail - Jython which is python 
 implemented on the Java virtual machine has no notion of a
  GIL
 . The primary reason the
  GIL
  
 exist is for ease of implemenation of the CPython virtual machine. It is way easier to 
 implement a single global lock than to implement fine grained locks and the core developers 
 have opted for this. There have however been projects to implement fine grained locks 
 within the python virtual machine but these have slowed down single threaded programs 
 atimes. A global lock also provides much needed synchronization when performing certain 
 tasks. Take the reference counting mechanism that is used by CPython for memory 
 management, without the concept of a
  GIL
 , you may have two thread interleave their 
 increment and decrement of reference count leading to serious issues with memory 
 handling. Another reason for this lock is that some
  C 
 libraries that CPython calls into are 
 inherently not thread safe so some kind of synchronization is required when using them.
  
 At the interpreter startup, a single main thread of execution is created and there is no 
 contention for the
  GIL
  as there is no other thread around so the main thread does not 
 bother to acquire the lock. When another thread is spawned using the python threading 
 module, the
  GIL
  comes into play. The snippet in listing 7.3 is from the
  Modules/_threadmodule.c
  
 and provides an idea of how this process proceeds as a new thread is created.
  
 Listing 7.3: Cross-section of code for creating new thread
  
 boot
 ->
 interp
  =
  PyThreadState_GET()
 ->
 interp; 
  
 boot
 ->
 func
  =
  func; 
  
 boot
 ->
 args
  =
  args; 
  
 boot
 ->
 keyw
  =
  keyw; 
  
 boot
 ->
 tstate
  =
  _PyThreadState_Prealloc(boot
 ->
 interp); 
  
 if
  (boot
 ->
 tstate
  ==
  NULL
 ) { 
  
  
 PyMem_DEL(boot); 
  
  
 return
  PyErr_NoMemory
 (); 
  
 } 
  
 Py_INCREF(func); 
  
 Py_INCREF(args); 
  
 Py_XINCREF(keyw);",NA
GIL and Performance,"The
  GIL
  is the primary reason why increasing the number of threads working on a CPU 
 bound program in a single process core setting in in python most times does not speed up 
 such a program. Infact at times, adding a thread will adversely affect the performance of a 
 program when compared to that of a single threaded program; this is because there is a cost 
 associated with all the switches and waits.",NA
8. Intermezzo: The,NA,NA
 abstract.c,NA,NA
 Module,"We have thus far mentioned multiple times that the python virtual machine generically 
 treat values for evaluation as
  PyObject
 s. This leaves the obvious question -
  How are 
 operations safely carried out on such generic objects ?
 . For example, when evaluating the 
 bytecode instruction
  BINARY_ADD
 , two
  PyObject
  values are popped from the evaluation stack 
 and used as argument to an addition operation but how does the virtual machine know if 
 the values actually implement a protocol of which the add operation is part of ?
  
 To understand how alot of the operations on
  PyObject
 s work, we only have to look at the 
 Objects/Abstract.c
  module. This module defines a number of functions that work on objects 
 that implement a given object protocol. This means that for example, if one was adding two 
 objects then the add function in this module would expect that both objects implement the
  
 __add__
  method of the
  tp_numbers
  slots. The best way to explain this is to illustrate with an 
 example.
  
 Consider the case of the
  BINARY_ADD
  opcode, when it is applied to the addition of two 
 numbers, the 
 PyNumber_Add
  function of the
  Objects/Abstract.c
  module is invoked. The 
 definition of this function is provided in listing 8.1.
  
 Listing 8.1: Generic add function from abstract.c module
  
 1 
  
 2 
  
 3 
  
 4 
  
 5 
  
 6 
  
 7 
  
 8 
  
 9 
  
 1
 0 
  
 1
 1 
  
 1
 2
  
 PyObject
  *
  PyNumber_Add
 (PyObject
  *
 v, PyObject
  *
 w){ 
  
  
 PyObject
  *
 result
  =
  binary_op1(v, w, NB_SLOT(nb_add)); 
  
 if
  (result
  ==
  
 Py_NotImplemented) { 
  
  
  
 PySequenceMethods
  *
 m
  =
  v
 ->
 ob_type
 ->
 tp_as_sequence; 
  
  
 Py_DECREF(result); 
  
  
  
 if
  (m
  &&
  m
 ->
 sq_concat) { 
  
  
  
  
 return
  (
 *
 m
 ->
 sq_concat)(v, w); 
  
  
  
 } 
  
  
  
 result
  =
  binop_type_error(v, w,
  ""+""
 ); 
  
  
 } 
  
  
 return
  result; 
  
 }
  
 Our interest at this point is in line 2 of the
  PyNumber_Add
  function from listing 8.1 - the call to 
 the
  binary_op1
  function. The
  binary_op1
  function is another generic function that takes among 
 its parameters, two values that are numbers or subclass of numbers and applies a binary 
 function to those two values; the
  NB_SLOT
  macro returns the offset of a given method into 
 the
  PyNumberMethods 
 structure; recall that this structure is a collection of methods that work 
 on numbers. The definition of this generic
  binary_op1
  function is included in listing 8.2 and 
 an in-depth explanation of this function immediately follows.",NA
"9. The evaluation loop,",NA,NA
 ceval.c,"We have finally arrived at the gut of the virtual machine - it is here that the virtual machine 
 iterates over python bytecode instructions of a code object and executes such instructions. 
 This is achieved using an actual
  for
  loop that iterates over an opcode switching on each type 
 in order to run the desired execution code. The
  Python/ceval.c
  module, about 5411 lines long, 
 implements most of the functionality required - at the heart of this function is the
  
 PyEval_EvalFrameEx
  function, an approximately 3000 line long function that contains the 
 actual evaluation loop. It is this
  PyEval_-EvalFrameEx
  function that is the main thrust of our 
 focus in the chapter.
  
 The
  Python/ceval.c
  module provides platform specific optimizations such as
  threaded gotos
  as 
 well as python virtual machine optimizations such as opcode prediction. In this write-up, 
 we are more concerned with the virtual machine processes and optimizations so we 
 conveniently disregard any platform specific optimizations or process introduced here so 
 long as it does not take away from our explanation of the evaluation loop. We go into more 
 detail than usual here so as to provide a solid explanation for how the heart of the virtual 
 machine is structured and works. It is important to note that the opcodes and their 
 implementations are constantly in flux so this description here may be inaccurate at a later 
 time.
  
 Before any execution of bytecode can take place, a number of housekeeping operations 
 such as creating and initializing frames, setting up variables and initializing the virtual 
 machine variables such as instruction pointers have to be carried out. We get our feet wet 
 with these 
  
 operations first explaining the setup processes that have to take place before the evaluation 
 begins.",NA
9.1 Putting names in place,"As mentioned above, the heart of the virtual machine is the
  PyEval_EvalFrameEx
  function that 
 actually executes the python bytecode but before this bytecode can be executed, a lot of 
 setup - error checking, frame creation and initialization etc - has to take place in order to 
 prepare the evaluation context. This is where the
  _PyEval_EvalCodeWithName
  function also 
 within the
  Python/ceval.c 
 module comes in. For illustration purposes, we assume that we are 
 working with a module that has the content shown in listing 9.0.",NA
9.2 The parts of the machine,"With all the names in place,
  PyEval_EvalFrameEx
  is invoked with a frame object as one of its 
 arguments. A cursory look at this function shows that the function is composed of quite a 
 few C macros and variables. The
  macros
  are an integral part of the execution loop - they 
 provide a means to abstract away repetitive code without incurring the cost of a function 
 call and as such we describe a few of them. In this section, we assume that the virtual 
 machine is not running with
  C 
 optimizations such as
  computed gotos
  enabled so we 
 conveniently ignore macros related to such optimizations.",NA
Bytecode instruction,"We have discussed the format of bytecode instructions in the chapter on code objects but it 
 is very relevant to our discussion here so we repeat our description of the format of 
 bytecode instructions here.
  
 Assuming we are working with python 3.6 bytecodes, all bytecodes are 16 bit long. The 
 Python VM uses a little endian byte encoding on the machine which I am currently typing 
 out this book thus the 16 bits of code are structured as shown in the following image with 
 the opcode taking up 1 byte and the argument to the opcode taking up the second byte.",NA
9.3 The Evaluation loop,"We have finally come to the heart of the virtual machine -the loop where the opcode are 
 actually evaluated. The actual loop implementation is pretty anti-climatic as there is really 
 nothing special here, just a
  never ending
  for
  loop and a massive
  switch
  statement that is used 
 to match opcodes. To get a concrete understanding of this statement, we look at the 
 execution of the simple hello world function in listing 9.6.
  
 Listing 9.6: Simple hello world python function
  
 def
  hello_world
 ():
  
 print
 (
 ""hello world""
 )
  
 A disassembly of the function from listing 9.7 is shown in listing 9.6 and we show how this 
 set of bytecode loops through the evaluation switch.",NA
9.4 A sampling of opcodes,"The python virtual machine has about 157 opcodes so we randomly pick a few opcodes and 
 de-construct to get more of a feel for how these opcodes function. Some examples of these 
 opcodes include:
  
 1.
  MAKE_FUNCTION
 : As the name suggest the opcode creates a function object from values 
 on the 
  
 the evaluation stack. Consider a module containing the functions shown in 
 listing 9.11.
  
  Listing 9.11: Function definitions in a module
  
 def
  test_non_local
 (arg,
  *
 args, defarg
 =
 ""test""
 , local_arg
  = 2 
  
 print
 (arg) 
  
 print
 (defarg) 
  
 print
 (args) 
  
 print
 (defkwd) 
  
 print
 (kwd)
  
 def
  hello_world
 (): 
  
  
 print
 (
 ""Hello world!""
 )
  
 defkwd
 =2
 ,
  **
 kwd):
  
 A disassembly of the code object formt he compilation of the module gives the set of 
 bytecode instructions shown in listing 9.12",NA
10. The Block Stack,"One of the data structures that does not get as much coverage as it should is the block stack 
 -the other stack within a frame object. Most discussions of the Python VM just mention the 
 block stack passingly but then focus on the evaluation stack. However, the block stack is 
 pretty important- there are probably other ways to implement exception handling but as 
 we will see while we progress through this chapter, using a stack, the block stack, makes it 
 incredibly simple to implement exception handling. The block stack and exception handling 
 are so intertwined that one will not fully understand the need for the block stack without 
 actually taking exception handling into consideration. The block stack is also used for loops 
 but it is difficult to see a reason for block stacks with loops until one looks at how loop 
 constructs like
  break
  interact with exception handlers so lets get straight down to the 
 details. The block stack makes the implementation of such interactions a straightforward 
 affair.
  
 The block stack is a stack data structure field within a frame object. Just like the evaluation 
 stack of the frame, values are pushed to and popped from the block stack during the 
 execution of a frame’s code. However the block stack is used only for handling loops and 
 exceptions. The best way to explain the block stack is with an example so we illustrate with 
 a simple
  try...finally
  construct within a loop as shown in the snippet in listing 10.0.
  
 Listing 10.0: Simple python function with exception handling
  
 def
  test
 ():
  
 for
  i
  in
  range
 (
 4
 ):
  
 try
 :
  
 break
  
 finally
 :
  
 print
 (
 ""Exiting loop""
 )
  
 When the function from listing 10.0 is disassembled, the result is shown in listing 10.1.
  
 Listing 10.1: Disassembly of function in listing 10.0
  
 2
  
 0
  SETUP_LOOP
  
 34
  (to
  36
 )
  
 2
  LOAD_GLOBAL
  
 0
  (
 range
 )
  
 4
  LOAD_CONST
  
 1
  (
 4
 )
  
 6
  CALL_FUNCTION
  
 1
  
 8
  GET_ITER
  
 >>
  
 10
  FOR_ITER
  
 22
  (to
  34
 )
  
 12
  STORE_FAST
  
 0
  (i)",NA
10.1 A Short Note on Exception Handling,"With this basic understanding of the block stack, it is not difficult to fathom how exceptions 
 and exception handling are implemented. Take the snippet in listing 10.3 that tries to add a 
 number to a string.
  
 Listing 10.3: Simple python function with exception handling
  
 def
  test1
 ():
  
 try
 :
  
 2 +
  's'
  
 except
  Exception
 :
  
 print
 (
 ""Caught exception""
 )
  
 The opcodes generated for the simple function in listing 10.3 are shown in listion 10.4.",NA
11. From Class code to bytecode,"We have covered a lot of ground discussing the nuts and bolts of how the python virtual 
 machine or interpreter (whichever you want to call it) executes your code but for an object 
 oriented language like Python, we have actually left out one of the most important parts - 
 the nuts and bolts of how a user defined class gets compiled down to bytecode and 
 executed.
  
 From our discussion on Python objects, we have a rough idea of how new classes
  may
  be 
 created but that intuition may not totally capture the whole process from the
  class ...
  
 definition of a user to actual bytecode that creates new class objects so this chapter aims to 
 bridge that gap and provide an exposition on how this process occurs.
  
 As usual we start with a very simple user defined class module as shown in listing lisitng 
 11.0.
  
 Listing 11.0: A simple class definition
  
 class
  Person
 :
  
 def
  __init__
 (
 self
 , name, age): 
  
 self
 .
 name
  =
  name 
  
 self
 .
 age
  =
  age
  
 When a module containing the above class definition is disassembled with the
  dis
  module, 
 the stream of bytecode shown in listing 11.1 is output.
  
 Listing 11.1: A simple class definition
  
  
  
 0
  LOAD_BUILD_CLASS 
  
  
  
 2
  LOAD_CONST 
  
 0
  (
 <
 code
  object
  Person at
  0x102298b70
 ,
  file
  ""str
 \ 
 ing""
 , line
  2>
 ) 
  
  
  
 4
  LOAD_CONST 
  
 1
  (
 'Person'
 ) 
  
  
  
 6
  MAKE_FUNCTION 
  
 0 
  
  
  
 8
  LOAD_CONST 
  
 1
  (
 'Person'
 ) 
  
  
 10
  CALL_FUNCTION 
  
 2 
  
  
 12
  STORE_NAME 
  
 0
  (Person) 
  
  
 14
  LOAD_CONST 
  
 2
  (
 None
 ) 
  
  
 16
  RETURN_VALUE
  
 We are interested in bytes 0 to bytes 12 as these are the actual opcodes that create the new 
 class object and store it so that it can be referenced by its name (
 Person
  in our example).",NA
12. Generators: Behind the scenes.,"Generators are one of the really beautiful concepts in python. A generator function is a 
 function that contain a
  yield
  statement and when a generator function is invoked it returns a 
 generator. A very simple use of generators in python is as an iterator that produces values 
 for an iteration on demand. Listing 12.0 is a very simple example of a generator function 
 that returns a generator that produces values from
  0
  up to
  n
 .
  
 Listing 12.0: A simple generator
  
 def
  firstn
 (n):
  
 num
  = 0
  
 while
  num
  <
  n:
  
 v
  =
  yield
  num
  
 print
 (v)
  
 num
  += 1
  
 firstn
  is a generator fucntion so calling the
  firstn
  function with a value does not return a 
 simple value like a conventional function would do but rather it returns a generator object 
 which captures the
  continuation
  of the computation. We can then use the
  next
  function to 
 get successive values from the returned generator object or the
  send
  method of the 
 generator object to send values into the generator object.
  
 In this chapter, we are not interested in the semantics of the generators objects or how the 
 generators are or should be used. Our interest lies with the nuts and bolts of how 
 generators are implemented under the covers in CPython. We are interested in how it is 
 possible to suspend a computation and then subsequently resume such computation. We 
 look at the data structures and ideas behind this concept and surprisingly they are not too 
 complicated. First, we look at the C implementation of a generator object.",NA
12.1 The Generator object,"The
  generator
  object definition is shown in listing 12.1 and going through this definition 
 provides some intuition into how generator execution can be suspended or resumed. We 
 can see that a generator object contains a
  frame
  object (recall execution frames from the 
 chapter on frames) and a code object, two objects that are essential to execution of python 
 bytecode.",NA
Creating generators,"When a generator function is called, the generator function does not run to completion and 
 return a value rather a generator object is returned. This is possible because of the
  
 CO_GENERATOR
  flag that is set during the compilation of a generator function and this flags",NA
12.2 Running a generator,"We can run a generator object by passing it as argument to the
  next
  builtin function. This 
 will cause the generator to execute till it hits a
  yield
  expression then it suspends execution. 
 The questions of importance to us here is how the generators are able to capture execution 
 state and update those at will.
  
 Looking back at the generator object definition from listing 12.1, we see that generators 
 have a field that references a frame object and this is filled in when the generator is created 
 as shown in listing 12.2. The frame object as we recall has all the state that is required to 
 execute a code object so by having a reference to that execution frame, the generator object 
 can capture all the state required for its execution.
  
 Now that we know how a generator object captures execution state, we move to the 
 question of how the execution of a suspended generator obect is resumed and this is not 
 too hard to figure out given the information that we have already. When the
  next
  builtin 
 function is called with a generator as an argument, the
  next
  function dereferences the
  
 tp_iternext
  field of the generator type and invokes whatever function that field references. In 
 the case of a generator object, that field references a function,
  gen_iternext
 , that simply 
 invoke another function,
  gen_send_ex
 , that does the actual work of resuming the execution of 
 the generator object. Recall that before the generator object was created, all the intial setup 
 was already carried out by the
  _PyEval_EvalCodeWithName 
 function - frame object was 
 intialised and variables initialised correctly, so the execution of the generator object 
 involves calling the
  PyEval_EvalFrameEx
  with the frame object contained within the generator 
 object as the frame argument. The execution of the code object contained within the frame 
 then proceeds as explained the chapter on the evaluation loop.
  
 To get a more indepth look at a generator function, we look at the generator function from 
 listing 12.0. The disassembly of the generator function from listing 12.0 results in the set of 
 bytecode shown in listing 12.3.",NA
