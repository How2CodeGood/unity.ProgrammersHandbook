Larger Text,Smaller Text,Symbol
Python Network,NA,NA
Programming,NA,NA
Conquer all your networking challenges with the powerful,NA,NA
Python language,NA,NA
Abhishek Ratan,NA,NA
Eric Chou,NA,NA
Pradeeban Kathiravelu,NA,NA
Dr. M. O. Faruque Sarker,BIRMINGHAM - MUMBAI,NA
Python Network Programming,"Copyright 
 ©
  2019 Packt Publishing
 All rights reserved. No part of this book may be reproduced, stored in a retrieval
 system, or transmitted in any form or by any means, without the prior written
 permission of the publisher, except in the case of brief quotations embedded in critical
 articles or reviews.
 Every effort has been made in the preparation of this book to ensure the accuracy of
 the information presented. However, the information contained in this book is sold
 without warranty, either express or implied. Neither the authors, nor Packt
 Publishing or its dealers and distributors, will be held liable for any damages caused
 or alleged to have been caused directly or indirectly by this book.
 Packt Publishing has endeavored to provide trademark information about all of the
 companies and products mentioned in this book by the appropriate use of capitals.
 However, Packt Publishing cannot guarantee the accuracy of this information.
 First published: January 2019
 Production reference: 1300119
 Published by Packt Publishing Ltd.
 Livery Place
 35 Livery Street
 Birmingham
 B3 2PB, UK.
 ISBN 978-1-78883-546-6
 www.packtpub.com",NA
Why subscribe?,"Spend less time learning and more time coding with practical eBooks and
 Videos from over 4,000 industry professionals
 Improve your learning with Skill Plans built especially for you
 Get a free eBook or video every month
 Mapt is fully searchable
 Copy and paste, print, and bookmark content",NA
Packt.com,"Did you know that Packt offers eBook versions of every book published, with PDF
 and ePub files available? You can upgrade to the eBook version at 
 www.packt.com
  and
 as a print book customer, you are entitled to a discount on the eBook copy. Get in
 touch with us at 
 customercare@packtpub.com
  for more details.
 At 
 www.packt.com
 , you can also read a collection of free technical articles, sign up for
 a range of free newsletters, and receive exclusive discounts and offers on Packt books
 and eBooks.",NA
Contributors,NA,NA
About the authors,"Abhishek Ratan
  has around 15 years of technical experience in networking,
 automation, and various ITIL processes, and has worked in various roles in different
 organizations. As a network engineer, security engineer, automation engineer, TAC
 engineer, tech lead, and content writer, he has gained a wealth of experience during
 the 15 years of his career. Abhishek also has a deep interest in strategy game playing,
 and if he is not working on technical stuff, he is busy spending time on his strategy
 games.
 He is currently working as a Sr. Automation Engineer at ServiceNow, learning, and
 expanding his automation skills in the ServiceNow platform. His earlier experience
 includes working for companies such as Microsoft, Symantec, and Navisite,which has
 given him exposure to various environments.
 Eric Chou
  is a seasoned technologist with an industry experience of over 18 years. He
 has worked on and helped managed some of the largest networks in the industry
 while working at Amazon AWS, Microsoft Azure, and other companies. Eric is
 passionate about network automation, Python, and helping companies build better
 security postures. Eric is the author of several books and online classes on networking
 with Python and network security. He is the proud inventor of two patents in IP
 telephony. Eric shares his deep interest in technology through his books, classes, and
 his blog, and contributes to some of the popular Python open source projects.",NA
Packt is searching for authors like you,"If you're interested in becoming an author for Packt, please visit
 authors.packtpub.com
  and apply today. We have worked with thousands of
 developers and tech professionals, just like you, to help them share their insight with
 the global tech community. You can make a general application, apply for a specific
 hot topic that we are recruiting an author for, or submit your own idea.",NA
Table of Contents,"Preface
 1
 Chapter 1: Fundamental Concepts
 8
 Network automation
 8
 DevOps
 9
 Software-defined networking
 10
 OpenFlow
 11
 Program concepts
 12
 Variables
 13
 Data types
 13
 Decision makers
 15
 Loops
 17
 Arrays
 18
 Functions
 19
 Best practices
 20
 Readability of a program
 20
 Support information
 22
 Indentation
 23
 Sample best practice example
 23
 Language choices (Python/PowerShell)
 25
 Writing your first program
 26
 PowerShell IDE
 27
 Python IDE
 30
 Representational State Transfer (REST) framework
 31
 Summary
 36
 Chapter 2: Python for Network Engineers
 37
 Python interpreter and data types
 37
 Conditions and loops
 42
 Nested and multiple conditions
 44
 Loops
 46
 For next loop
 46
 While loop
 48
 Writing Python scripts
 49
 Functions
 51
 Passing arguments from the command line
 57
 Python modules and packages
 58
 Multithreading for parallel processing
 59
 Using Netmiko for SSH and network device interaction
 62
 Network automation use case
 67",NA
Preface,"Python Network Programming reviews the core elements of Python and the TCP/IP
 protocol suite. It highlights major aspects of Python network programming such as
 writing simple networking clients, creating and deploying SDN and NFV systems,
 and extending your network with Mininet. You
 ’
 ll also learn how to automate legacy
 and the latest network devices. As you progress through the chapters, you
 ’
 ll use
 Python for DevOps and open source tools to test, secure, and analyze your network.
 This Learning Path will guide you in configuring the Linux Foundation networking
 ecosystem and deploying automated networks in the cloud. You will gain experience
 in retrieving network information with flow-based monitoring, a polling mechanism,
 and data visualization. Toward the end, you'll develop client-side applications, such
 as web API clients, email clients, SSH, and FTP, using socket programming and
 multithreaded or event-driven architectures.
 By the end of this Learning Path, you will have learned how to analyze a network's
 security vulnerabilities using advanced network packet capture and analysis
 techniques.
 This Learning Path includes content from the following Packt products:
 Practical Network Automation by Abhishek Ratan
 Mastering Python Networking by Eric Chou
 Python Network Programming Cookbook, Second Edition by Pradeeban
 Kathiravelu, Dr. M. O. Faruque Sarker",NA
Who this book is for,"If you are a Python developer or a system administrator who wants to start network
 programming, this Learning Path gets you a step closer to your goal. IT professionals
 and DevOps engineers who are new to managing network devices or those with
 minimal experience looking to expand their knowledge and skills in Python will also
 find this Learning Path useful. Although prior knowledge of networking is not
 required, some experience in Python programming will be helpful for a better
 understanding of the concepts in the Learning Path.",NA
What this book covers,"Chapter 1
 , 
 Fundamental Concepts
 , introduces how to get started with automation.
 Chapter 2
 , 
 Python for Network Engineers
 , introduces to Python as a scripting language,
 and samples to explain usage of Python in accessing network devices and data
 parsing from the device outputs.
 Chapter 3
 , 
 Continuous Integration for Network Engineers
 , gives an overview of
 integration principles for network engineers to manage rapid growth with high
 availability and rapid disaster recovery.
 Chapter 4
 , 
 SDN Concepts in Network Automation
 , talks about moving your enterprise
 Java applications to virtualized x86 platforms to better utilize resources with easier
 life cycle and scalability management.
 Chapter 5
 , 
 Low-Level Network Device Interactions
 , uses practical examples to illustrate
 how to use Python to execute commands on a network device. It will also discuss the
 challenges of having a CLI-only interface in automation. The chapter will use the
 Pexpect and Paramiko libraries for the examples.
 Chapter 6
 , 
 APIs and Intent-Driven Networking
 , discusses the newer network devices
 that support 
 Application Programming Interfaces
  (
 APIs
 ) and other high-level
 interaction methods. It also illustrates tools that allow abstraction of low-level tasks
 while focusing on the intent of the network engineers. A discussion about and
 examples of Cisco NX-API, Juniper PyEZ, and Arista Pyeapi will be used in the
 chapter.
 Chapter 7
 , 
 The Python Automation Framework 
 –
  Ansible Basics
 , discusses the basics of
 Ansible, an open source, Python-based automation framework. Ansible moves one
 step further from APIs and focuses on declarative task intent. In this chapter, we will
 cover the advantages of using Ansible, its high-level architecture, and see some
 practical examples of Ansible with Cisco, Juniper, and Arista devices.
 Chapter 8
 , 
 The Python Automation Framework 
 –
  Beyond Basics
 , builds on the knowledge
 in the previous chapter and covers the more advanced Ansible topics. We will cover
 conditionals, loops, templates, variables, Ansible Vault, and roles. It will also cover
 the basics of writing custom modules.",NA
To get the most out of this book,"To get the most out of this book, some basic hands-on network operation knowledge
 and Python is recommended. Most of the chapters can be read in any order, with the
 exceptions of chapters 7 and 8, which should be read in sequence. Besides the basic
 software and hardware tools introduced at the beginning of the book, new tools
 relevant to each of the chapters will be introduced.",NA
Download the example code files,"You can download the example code files for this book from your account at
 www.packt.com
 . If you purchased this book elsewhere, you can visit
 www.packt.com/support
  and register to have the files emailed directly to you.
 You can download the code files by following these steps:
 Log in or register at 
 www.packt.com
 .
 1.
 Select the 
 SUPPORT
  tab.
 2.
 Click on 
 Code Downloads & Errata
 .
 3.
 Enter the name of the book in the 
 Search
  box and follow the onscreen
 4.
 instructions.
 Once the file is downloaded, please make sure that you unzip or extract the folder
 using the latest version of:
 WinRAR/7-Zip for Windows
 Zipeg/iZip/UnRarX for Mac
 7-Zip/PeaZip for Linux
 The code bundle for the book is also hosted on GitHub at 
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 PacktPublishing/
 ​
 Python-
 ​
 Network-
 ​
 Programming
 . In case there's an update to the
 code, it will be updated on the existing GitHub repository.",NA
Download the color images,"We also provide a PDF file that has color images of the screenshots/diagrams used in
 this book. You can download it here: 
 https:/
 ​
 /
 ​
 www.
 ​
 packtpub.
 ​
 com/
 ​
 sites/
 ​
 default/
 files/
 ​
 downloads/
 ​
 9781788835466_
 ​
 ColorImages.
 ​
 pdf
 .",NA
Conventions used,"There are a number of text conventions used throughout this book.
 CodeInText
 : Indicates code words in text, database table names, folder names,
 filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles.
 Here is an example: ""The 
 input()
  method is used to get an input from the user.""
 A block of code is set as follows:
 #PowerShell sample code:
 $countries=""India"",""UK"",""USA"",""France""
 foreach ($country in $countries)
 {
 write-host ($country+"" is good"")
 }
 Any command-line input or output is written as follows:
 easy_install <name of module>
 Bold
 : Indicates a new term, an important word, or words that you see onscreen. For
 example, words in menus or dialog boxes appear in the text like this. Here is an
 example: ""If you need something different, click on the 
 DOWNLOADS
  link in the
 header for all possible downloads: ""
 Warnings or important notes appear like this.
 Tips and tricks appear like this.",NA
Get in touch,"Feedback from our readers is always welcome.
 General feedback
 : If you have questions about any aspect of this book, mention the
 book title in the subject of your message and email us at
 customercare@packtpub.com
 .
 Errata
 : Although we have taken every care to ensure the accuracy of our content,
 mistakes do happen. If you have found a mistake in this book, we would be grateful if
 you would report this to us. Please visit 
 www.packt.com/submit-errata
 , selecting
 your book, clicking on the Errata Submission Form link, and entering the details.
 Piracy
 : If you come across any illegal copies of our works in any form on the Internet,
 we would be grateful if you would provide us with the location address or website
 name. Please contact us at 
 copyright@packt.com
  with a link to the material.
 If you are interested in becoming an author
 : If there is a topic that you have
 expertise in and you are interested in either writing or contributing to a book, please
 visit 
 authors.packtpub.com
 .",NA
Reviews,"Please leave a review. Once you have read and used this book, why not leave a
 review on the site that you purchased it from? Potential readers can then see and use
 your unbiased opinion to make purchase decisions, we at Packt can understand what
 you think about our products, and our authors can see your feedback on their book.
 Thank you!
 For more information about Packt, please visit 
 packt.com
 .",NA
1,NA,NA
Fundamental Concepts,"This chapter introduces the concept of network automation and familiarizes you with
 the keywords that are part of the automation framework. Before we dive into the
 details of network automation, it is important to understand why we need network
 automation and what we can achieve if we embrace the automation concepts and
 framework. This chapter also provides an insight into the traditional model of
 engineer and support operations, and shows how network automation can help
 bridge that gap for better efficiency and reliability.
 Some of the topics covered in this chapter are as follows:
 What is network automation?
 DevOps
 Software-defined networking
 Basics of OpenFlow
 Basic programming concepts
 Programming language choices for automation
 Introduction to REST framework",NA
Network automation,"Automation, as the word suggests, is a framework of automating a particular task by
 understanding, interpreting, and creating logic. This includes enhancing the current
 capabilities of the tasks that are done manually and reducing the error rate of those
 tasks while focusing on scaling the task with reduced effort.
 As an example, imagine we need to upgrade the IOS image of a Cisco router. This can
 involve multiple tasks, such as loading the image on the router, validating the
 checksum of the image, offloading traffic (if it's a production router), modifying the
 boot variable, and finally, reloading the router with the new image.",NA
DevOps,"Historically, there have been two specific teams in every networking department. One
 of the teams is the engineering team, which is responsible for conceiving new ideas to
 improve the network and designing, deploying, and optimizing the current
 infrastructure. This team is primarily responsible for performing tasks such as
 configuration and cabling from scratch.",NA
Software-defined networking,"As you may be aware, there have been multiple proprietary networking devices, such
 as firewalls, switches, and routers, that were made by different network vendors.
 However, owing to the proprietary information from each different vendor, multiple
 network devices might not exist in a single network infrastructure environment. Even
 if they exist together, network engineers have to focus their effort on ensuring that
 each vendor device can exist in a network path without any hiccups. There might be
 times when one routing protocol might not be compatible with all the network
 devices in a multi-vendor environment, and a lot of time is wasted ensuring either the
 removal of that protocol, or the removal of the vendor which that does not support
 that protocol. This can waste effort and time, which could be better spent improving
 the infrastructure.",NA
OpenFlow,"OpenFlow is a communication protocol that is used for communication between
 different vendor's equipment for the packet flow. This standard is maintained by a
 group called 
 Open Network Foundation
  (
 ONF
 ). OpenFlow, as the name suggests, is
 used to control the flow of packets in a network layer through a mix of 
 Access
 Control Lists
  (
 ACLs
 ) and routing protocols.
 OpenFlow primarily has two components
 —
 controllers and switches. Controllers are
 used to take decisions in terms of creating a path for the packet to flow across the
 different connected devices, and switches (or network equipment) are dynamically
 configured from the controller based upon the path that a packet needs to take.",NA
Program concepts,"Now, as we start working upon our practical approach to automation, we need to
 understand the basics of what a program is and how to write one.
 Simply explained, a program is a set of instructions that is passed to the system to
 perform a specific task. This set of instructions is based upon real-life challenges and
 tasks that need to be accomplished in an automated method. Small sets of programs
 can be combined to create an application that can be installed, deployed, and
 configured for individual or organizational requirements. Some of the key concepts
 and programming techniques that we will discuss from this point onward will be
 PowerShell and Python. These are the two most popular scripting languages that are
 used to create quick, effective, and result-oriented automation.
 These are some of the key concepts that I would like to introduce while creating a
 program:
 Variables
 Data types
 Decision makers
 Loops
 Arrays",NA
Variables,"These are predefined, human-readable, and understandable words or letters that are
 used to store some values. At the very basis of writing a program we need a variable
 in which we will store the data or information, and based upon the variables, we can
 further enhance the programming logic. As we can see in the first line, an important
 part of creating a variable is that it should be human-readable and understandable.
 Let us take an example: Suppose I want to store a number 
 2
  in a variable. We can
 choose any name for a variable and define it:
 Option 1: x=2
 Option 2: number=2
 The correct answer will be 
 Option 2
 , as we know by the variable name (
 number
 )
 that this variable contains a specific number. As we can see in the preceding example,
 if we keep on using random ways of defining variables as we would when creating a
 big program, the complexity would be increased substantially because of the unclear
 meanings of the variables.
 Different programming languages have different ways to define a variable, but the
 underlying concept of ensuring a variable is human-readable should be the top-most
 priority of the programmer or program author.",NA
Data types,"As the name suggests, these are the classifications of the values that we pass on to the
 variable. A variable can be defined to store a specific type of value that can be
 declared based upon the data type.
 There are multiple data types, but for our initial discussion there are primarily four
 data types that need to be understood:
 String
 : This is a catch-all data type. Any value defined as a string is as
 simple as saying the value is plain English with characters, alphabets,
 special characters, and so on. I have referred to it as a catch-all data type
 because nearly all other data types can be converted to string format
 keeping the same values intact during conversion to string.",NA
Decision makers,"These are one of the very critical components of a program and they can define the
 flow of the program. As the name suggests, a decision maker decides a certain action
 based upon a certain condition.
 Simply put, if you wanted to buy an ice cream you would go to an ice-cream shop,
 but for a coffee you would go to a coffee shop. In this case, the condition was whether
 you wanted ice cream or coffee. The action was based upon the result of the
 condition: you went to that specific shop.
 These decision makers, also called 
 conditions
 , are defined in a different manner in
 different scripting languages, but the result of each of the conditions decides the
 future flow of the program.
 Generally, in a condition, two or more values are compared and either a true or a
 false is returned. Depending on the value returned, a specific set of instructions are
 executed.
 Consider the following example:
 Condition:
 if (2 is greater than 3), then
 Proceed to perform Option 1
 else
 Proceed to perform Option 2
 As we see in the preceding example, a condition is evaluated and if 
 2 is greater
 than 3
 , then the flow of program will be performed based upon 
 Option 1
 , and in
 case of a false (which means 2 is not greater than 3), 
 Option 2
  would be chosen.
 If we want a bit more complexity, we can add multiple decision-making statements or
 conditions to granulize the flow of a program.
 Let us take an example:
 if (Car is of red color), then
   if (Car is Automatic), then
     if (Car is a sedan), then
       Option 1 (Purchase the car)
     else (Option 2, ask for a sedan car from dealer)
   else (Option 3, ask for an Automatic car from dealer)
 else (Option 4, ask for a red car from dealer)",NA
Loops,"A loop, as we know in common language, is circling the same path over and over
 again. In other words, if I am asked to fetch five ice creams from the ice cream store,
 and I can carry only one ice cream at a time, I will repeat the process of going to the
 ice cream shop to purchase ice cream five times. Correlating this with programming,
 if the same set of instructions need to be performed multiple times, then we put those
 instructions inside a loop.
 A very basic loop is generally depicted as an iteration of a variable as many times as
 we want the instructions to be carried out.
 Let's take an example:
 Start the loop from one, until the loop has been repeated sixty times,
 adding a value of 1 to the loop:
 Perform action",NA
Arrays,"An array (or list in some scripting languages) is used to store a similar set of multiple
 values inside a single variable. This helps to ensure all data types with similar
 meanings are stored in a single variable, and also we can easily loop through these
 array objects to fetch the values stored in an array.
 Consider the following example:
 countries=[""India"",""China"",""USA"",""UK""]
 for specific country in countries
  Perform action
 As we can see in the variable declaration, now we are declaring a similar data type
 with a similar context or meaning by grouping them together and assigning them into
 a single variable. In our example, it's the country names all assigned to an array
 variable named 
 countries
 . In the next line, we are now iterating using the loop
 method, and for every 
 specific country
  in the list or array of 
 countries
 , we will
 perform the action. In this case, the loop will be executed to perform the action for
 each country, from the country name 
 India
  to the end of the country name 
 UK
 .
 Each value stored in an array is referred to as an element of the array. Additionally,
 an array can be easily sorted, which means irrespective of the order of the elements in
 the array, we can get a sorted list or array by calling some additional programming
 tasks.",NA
Functions,"Functions or methods are a pre-written small set of instructions that result in a
 specific task being performed when they are called. The functions can also be defined
 as a single name for a group of programming instructions written together to achieve
 a common task.
 Taking an example, think of driving as a function. In driving, there are multiple
 things that need to be taken care of, such as understanding traffic signals, running a
 car, and driving the car in traffic and on the road.
 All these tasks are grouped in a function named 
 driving
 . Now, let's say we have two
 people, example 1 and example 2, who want to learn to drive. From a programming
 perspective, once we define a function, we need to call it whenever we want to
 perform the same set of tasks. Hence, we would call 
 driving(example 1)
  and
 then 
 driving (example 2)
 , which would ensure that both people would become a
 driver after going through the set of instructions in the 
 driving
  function.
 Let us look at another example:
 countries=[""India"",""China"",""USA"",""UK""]
 function hellocountry(countryname)
  Return ""hello "" countryname
 for each country in countries:
      hellocountry(each country)
 In the first line, we declare an array with country names as elements. Next, we define
 a function named 
 hellocountry
  that accepts an input of 
 countryname
 . In the
 function itself, we simply return the value of the 
 countryname
  that was passed to the
 function as input, preceding by the work 
 hello
 .",NA
Best practices,"As we have now looked at the basics of some of the key components of a program,
 there is another important aspect of how to write a good program that we will
 consider.
 From a machine's perspective, there is no understanding of how a program is written,
 as long as the instructions given in the program are in the right format or syntax and
 the machine is able to interpret each of the instructions correctly. For an end user,
 again the way the program is written might not be important as long as the end user
 gets the desired result. The person concerned with how a program is written is a
 programmer who is writing their own program, or a programmer or developer who
 needs to interpret another programmer's program.
 There may be multiple reasons why a programmer might need to interpret a program
 that's not been written by them. It may be to support the program while the
 programmer who wrote the program is not available, or to enhance the program by
 adding their own piece of code or programming instructions. Another reason for code
 readability is fixing bugs. Any program or set of instructions may malfunction due to
 incorrect input or incorrect logic, which can result in unexpected behavior or
 unexpected results. This is called a bug, and bugs need to be fixed to ensure the
 program does what it was written for originally.
 Every programmer has their own set of best practices, but some of the key aspects of
 a program are readability, support information, and indentation.",NA
Readability of a program,"This is one of the most important aspects of writing a good program. A program
 needs to be written in such a way that even a layman or a first-time reader of the
 program should be able to interpret the basics of what is happening.",NA
Support information,"This, as the name suggests, is additional information, preferably added as comments,
 containing details about the program and author. As a suggestion, at the minimum a
 program should have the author info (that is, the person who created the program),
 contact details such as phone number and email address, basic usage of the program
 or the purpose of the program, and the version of the program.
 The version is specific such as starting from 1.0 and as and when we enhance the
 program or add new features, we can change it to version 1.1 (for minor changes) or a
 newer version such as version 2.0 (for major changes).
 Consider an example:
 Program start
 Comment: Author: Myself
 Comment: Contact: myemail@emailaddress.com
 Comment: Phone: 12345
 Comment: Version: 1.0
 Comment: Purpose: This program is to demo the comments for support
 info
 Comment: Execution method: Open the Command Prompt and run this
 program by calling this program.
 Comment: Any extra additional info (if needed)
 Program end
 This approach ensures that everyone knows which is the latest version of the script
 and how to execute the program or script. Also, this has info about the contact details
 of the author, so if anything breaks in production, the author can be easily reached to
 rectify or fix the scripts in production.",NA
Indentation,"This is similar to what we do when we write in plain English. Indenting a program is
 mandatory in some scripting languages, but as a best practice it should be followed
 for any program that we write in any programming language. Indentation improves
 the readability of a program because it helps the programmer or someone else
 reading the program to quickly understand the flow of the program.
 Let's see an example where we have a nested condition in which we check if a 
 Car
  is
 Red
  and if it is a 
 Sedan
  and if it is 
 Automatic
 .
 A bad way of writing this would be as follows:
 if (Car is 'Red')
 if (Car is 'Sedan')
 if (Car is 'Automatic')
 do something
 Now, think of adding multiple lines like this to a long program, and you will get
 easily confused by the flow of program as you read through it.
 A better and recommended way to write this is as follows:
 if (Car is 'Red')
     if (Car is 'Sedan')
         if (Car is 'Automatic')
            do something
 This provides a clear flow of the program. Only check the other conditions if the 
 Car
 is 
 Red
 ; otherwise, don't check for the other conditions. This is where we say we are
 nesting the conditions inside each other, which is also called 
 nested conditions
 .
 This also clears a lot of confusion while troubleshooting a complex program. We can
 easily identify the problematic code or instructions by quickly parsing through the
 program and understanding the flow for each segment of the program.",NA
Sample best practice example,"This example summarizes the best practices using all the elements that we have
 learned so far, by creating a basic program.",NA
Language choices (Python/PowerShell),"Moving ahead, armed with the knowledge of how to write a program and an
 understanding best practices, we will now look at some scripting languages that
 suffice for our automation scripts. A basic difference between a scripting language
 and a programming language (such as C and C++) is that a scripting language is not
 compiled but interpreted through the underlying environment in which it is executed
 (in other words, a converter is required to convert the commands written in human-
 readable format to machine format by parsing one line at a time), whereas the
 programming language is primarily compiled and hence can be executed in multiple
 environments without the use of any specific underlying environment or
 requirements.
 What this means is if I write a script in Python, PowerShell, or even Perl, I need to
 install that specific language in order to run the program or script that I have written.
 C or C++ code can be compiled to make an executable file (
 .exe
 ) , and can run
 independently without the installation of any language. Additionally, a scripting
 language is less code-intensive, which means that it can automatically interpret some
 of the code written in a program depending on how it is called.
 Let's consider an example. Here's how we declare a variable in scripting language:
 x=5
 OR
 x=""author""
 OR
 x=3.5
 Whereas in a programming language, the same type of declaration would be made
 like this:
 integer x=5
 String x=""author""
 Float x=3.5
 This states that depending on the value we assign to the variable, the variable type is
 automatically identified in an scripting language, whereas in a programming
 language the declarations are tightly controlled. In this case, if we declare a variable
 as a 
 String
 , this clearly means that we cannot declare any other type of value in that
 variable unless we explicitly change the data type of that variable.",NA
Writing your first program,"Now, because we are starting from fresh, we need to understand how to write our
 first program and execute it. PowerShell comes pre-installed on a Windows machine.
 But we need to install Python by downloading it from the web ( 
 https:/
 ​
 /
 ​
 www.
 python.
 ​
 org
 ) and choosing the right version for your operating system. Once
 downloaded, it can installed just like any other application that is installed on a
 Windows machine.
 On a Linux machine, the same holds true, but because of the .NET requirement,
 PowerShell will not be supported on Linux or Unix environments. Hence, if we are
 using a Unix or Linux environment, Python or Perl remain our preferences for
 scripting.",NA
PowerShell IDE,"This can be invoked by clicking on the 
 Start
  button and searching for 
 Windows
 PowerShell ISE
 . Once invoked, the initial screen will look like this:
 As we can see in the preceding screenshot, a PowerShell script is saved with a 
 .ps1
 extension. Once we write something in the IDE (or ISE, as it is called with
 PowerShell), it needs to be saved as 
 somefilename.ps1
  and then executed to see the
 result.",NA
Python IDE,"Similar to PowerShell, once Python is installed, it has its own IDE. It can be invoked
 by typing or calling IDLE (Python) from the 
 Start
  menu:
 The Python IDE, called IDLE, looks similar to the preceding screenshot when it is
 opened. The heading bar depicts the version of Python (which is 3.6.1 in this case)
 and the three greater than signs (
 >>>
 ) show the command line, which is ready to
 accept Python commands and execute them. To write a program, we click on 
 File
  |
 New File
 , which opens up a notepad in which we can write the program.
 Lets see a similar 
 hello world
  program in Python:",NA
Representational State Transfer (REST),NA,NA
framework,"One of the most important aspects of network automation is to understand and
 leverage tools that are currently available for specific tasks. For example, this could be
 Splunk for data mining, SolarWinds for network monitoring, syslog servers, or even
 any custom applications to perform various tasks.",NA
Summary,"In this chapter, we covered the basics of various terminology that we will use while
 performing network automation. This chapter also introduced the readers to some
 basic aspects of programming to help build the logic of a program.
 This chapter also explained why to write a good program and how to write one,
 along with some reference points for scripting languages. There was also a brief
 discussion about the current scripting languages, their basic usage, and writing a very
 basic program in two of the most popular scripting languages (Python and
 PowerShell).
 Finally, we summed it all up by introducing the REST framework, which included a
 discussion about APIs, how to call them, and an explanation of XML and JSON as
 inter-platform data exchange languages.
 The next chapter will go deeper into how to write scripts using Python, with relevant
 examples in PowerShell to ensure the reader becomes familiar with both Python and
 PowerShell. There will be tips and best practices as well.",NA
2,NA,NA
Python for Network Engineers,"As we are now familiar with how to write a program using the concepts used in
 programming languages, as well as best practices, now let's dig deep into writing an
 actual Python program or script. Keeping the primary focus on how to write a
 program in Python, we will also see how to write the same program in PowerShell,
 since there might be times where we would need to use PowerShell to achieve the
 results that we are looking for. We will cover various aspects of creating a program
 with some explanations of each of the statements and provide some tips and tricks to
 get through those tricky situations.
 In this chapter, we will cover the following topics:
 Python interpreter and data types
 Writing Python scripts using conditional loops
 Functions
 Installing new modules/libraries
 Passing arguments from command line for scripts
 Using Netmiko to interact with network devices
 Multithreading",NA
Python interpreter and data types,"An interpreter, as the name suggests, is used to interpret instructions so that they are
 understandable by others. In our case, it is used to convert our Python language to a
 machine-understandable format that governs the flow of instructions that we gave to
 the machine.",NA
Conditions and loops,"Conditions are checked using a left and right value comparison. The evaluation
 returns either true or false, and a specific action is performed depending on the result.
 There are certain condition operators that are used to evaluate the left and right value
 comparisons:
 Operators
 Meaning
 ==
 If both values are equal
 !=
 If both values are NOT equal",NA
Nested and multiple conditions,"Sometimes we need to check multiple conditions in a single 
 if
  condition.
 Let's see an example of this:
 Here, we are checking the range of the marks. The flow of the program is as follows:
 Assign a value of 
 85
  to the 
 marks
  variable. If 
 marks
  is less than or equal to 
 45
 , print
 Grade C
 , else if 
 marks
  is greater than 
 45
  and less than equal to 
 75
 , print 
 Grade B
 ,
 else if 
 marks
  is greater than 
 75
 , print 
 Grade A
 , else if none of the preceding
 conditions match, then print 
 Unable to determine
 .
 The PowerShell sample code for the preceding Python task is as follows:
 #PowerShell sample code:
 $marks=85
 if ($marks -le 45)
 {
     write-host ""Grade C""
 }
 elseif (($marks -gt 45) -and ($marks -le 75))",NA
Loops,"A loop is used to repeat a set of instructions until a specific condition is fulfilled.
 There are two common ways of creating a loop in Python, which are discussed as
 follows:",NA
For next loop,"This type of loop checks for a condition and repeats the instructions inside the loop
 until the condition is met:
 for <incremental variable> in final value:
   statements
 Here's an example of printing numbers from 1 to 10 in a for loop:
 As we can see, we use a built-in 
 range(starting value, max value)
  function,
 which specifies the loop to repeat from the starting value until the incremental value
 reaches the maximum value. In this case, the variable 
 x
  is incremented by 1 and in
 each loop, the value is printed out. This is repeated until the value of 
 x
  reaches 
 10
 ,
 where the 
 for
  loop terminates.",NA
While loop,"While
  loop is different from 
 for
  loop, as no new variable is needed in this loop, and
 any current variable can be used to perform the tasks inside the 
 while
  loop. An
 example is as follows:
 while True:
      perform instructions
      if condition():
        break
 This is similar to 
 for
 , but in this case the actions are performed first, and then the
 condition is checked. In the preceding example, the value of 
 x
  is printed first, and we
 repeat the same set of instructions until the value of 
 x
  reaches 
 10
  or greater. Once the
 if
  condition is met, we break out of the loop. If we do not specify a 
 break
  condition,
 we will go into an infinite loop with a increment of 1 for each 
 x
  value.",NA
Writing Python scripts,"We are now familiar with the basic concepts of Python. Now we will write an actual
 program or script in Python.
 Ask for the input of a country name, and check whether the last character of the
 country is a vowel:
 countryname=input(""Enter country name:"")
 countryname=countryname.lower()
 lastcharacter=countryname.strip()[-1]
 if 'a' in lastcharacter:
     print (""Vowel found"")
 elif 'e' in lastcharacter:
     print (""Vowel found"")
 elif 'i' in lastcharacter:
     print (""Vowel found"")
 elif 'o' in lastcharacter:
     print (""Vowel found"")
 elif 'u' in lastcharacter:
     print (""Vowel found"")
 else:
     print (""No vowel found"")
 Output of the preceding code is as follows:",NA
Functions,"For any recurring set of instructions, we can define a function. In other words, a
 function is a closed set of instructions to perform a specific logic or task. Depending
 upon the input provided, a function has the ability to return the results or parse the
 input with specific instructions to get results without any return values.
 A function is defined by the 
 def
  keyword, which specifies that we need to define a
 function and provide a set of instructions related to that function.
 In this task we will print the greater of two input numbers:
 def checkgreaternumber(number1,number2):
     if number1 > number2:
       print (""Greater number is "",number1)
     else:
      print (""Greater number is"",number2)
 checkgreaternumber(2,4)
 checkgreaternumber(3,1)",NA
Passing arguments from the command line,"Sometimes it is necessary to pass arguments to the script from the command line. This
 is generally needed when we need to perform some quick actions in our script, rather
 than the script asking us for the inputs.
 Consider the following lines of code where we pass two numbers as arguments to
 scripts, and print the sum of them:
 import sys
 print (""Total output is "")
 print (int(sys.argv[1])+int(sys.argv[2]))
 When we run this script, say it's saved as 
 checkargs.py
 , and execute it as follows:
 python checkargs.py 5 6
 The output returned is as follows:
 Total output is
 11
 The key here is the import of the 
 sys
  module, which is a predefined module in
 Python to handle any system-related tasks of Python. The values that we pass as
 arguments are stored in 
 sys.argv[1]
  onwards, since 
 sys.argv[0]
  is the name of
 actual script being run. In this case, 
 sys.argv[0]
  will be 
 checkargs.py
 ,
 sys.argv[1]
  will be 
 5
 , and 
 sys.argv[2]
  will be 
 6
 .
 The PowerShell code for the preceding task is as follows:
 #PowerShell sample code
 $myvalue=$args[0]
 write-host (""Argument passed to PowerShell is ""+$myvalue)
 The arguments passed in a Python script are in string format, so we
 need to explicitly convert them to the right type for the expected
 output. In the preceding script, if we had not converted it to the
 integer type by using the 
 int()
  function, then the output would
 have been 
 56
  instead of 
 int(5)
  + 
 int(6)
  = 
 11
 .",NA
Python modules and packages,"Because Python is the most popular open source coding language, there are many
 developers who contribute their expertise by creating specific modules and sharing
 them for others to use. These modules are a specific set of functions or instructions
 that are used to perform specialized tasks and can be called easily in our programs.
 The modules can be easily called using the 
 import
  command inside the scripts.
 Python has many built-in modules that are directly called using 
 import
 , but for
 specialized modules, an external installation is needed. Luckily, Python provides a
 very easy way to download and install these modules.
 As an example, let's install a module named 
 Netmiko
  that can help us work on
 logging into network devices more efficiently. Python provides a well-documented
 reference for each of the modules, and for our module, the documentation can be
 found at 
 https:/
 ​
 /
 ​
 pypi.
 ​
 python.
 ​
 org/
 ​
 pypi/
 ​
 netmiko.
 ​
  
 For installation, all we have to
 do is go into the folder from the command line where 
 python.exe
  is installed or is
 present. There is a sub folder in that location called 
 scripts
 .
 Inside that folder, we have two options that can be used for installing modules,
 easy_install.exe
  or 
 pip.exe
 .
 Installing the library for Python, can be done in two ways:
 The syntax of 
 easy_install
  is as follows:
 easy_install <name of module>
 For example:
 easy_install netmiko
 The syntax of 
 pip install
  is as follows:
 pip install <name of module>
 For example:
 pip install netmiko
 Once we install the required module, we need to restart Python by
 closing all open sessions and invoking IDLE again so the modules
 can be loaded. More information on modules can be gathered
 from 
 https:/
 ​
 /
 ​
 docs.
 ​
 python.
 ​
 org/
 ​
 2/
 ​
 tutorial/
 ​
 modules.
 ​
 html.",NA
Multithreading for parallel processing,"As we are now focusing on writing our scripts efficiently, a major aspect of this is
 how efficiently, quickly, and correctly we fetch the information. When we use the 
 for
 loop, we parse through each item one by one, which is fine if we get results quickly.
 Now, if each item in a 
 for
  loop is a router from which we need to get the output of
 show version, and if each router takes around 10 seconds to log in, gather the output,
 and log out, and we have around 30 routers that we need to get this information
 from, we would need 10*30 = 300 seconds for the program to complete the execution.
 If we are looking for more advanced or complex calculations on each output, which
 might take up to a minute, then it will take 30 minutes for just 30 routers.
 This starts becoming very inefficient when our complexity and scalability grows. To
 help with this, we need to add parallelism to our programs. What this simply means
 is, we log in simultaneously on all 30 routers, and perform the same task to fetch the
 output at the same time. Effectively, this means that we now get the output on all  30
 routers in 10 seconds, because we have 30 parallel threads being called.
 A thread is nothing but another instance of the same function being called, and
 calling it 30 times means we are invoking 30 threads at the same time to perform the
 same tasks.
 Here's an example:
 import datetime
 from threading import Thread
 def checksequential():
     for x in range(1,10):
         print (datetime.datetime.now().time())
 def checkparallel():
     print (str(datetime.datetime.now().time())+""\n"")
 checksequential()
 print (""\nNow printing parallel threads\n"")
 threads = []
 for x in range(1,10):
     t = Thread(target=checkparallel)
     t.start()
     threads.append(t)
 for t in threads:
     t.join()",NA
Using Netmiko for SSH and network,NA,NA
device interaction,"Netmiko (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 ktbyers/
 ​
 netmiko
 ) is a library in Python that is used
 extensively an interaction with network devices. This is a multi-vendor library with
 support for Cisco IOS, NXOS, firewalls, and many other devices. The underlying
 library of this is Paramiko, which is again used extensively for SSH into various
 devices.
 Netmiko extends the Paramiko ability of SSH to add enhancements, such as going
 into configuration mode in network routers, sending commands, receiving output
 based upon the commands, adding enhancements to wait for certain commands to
 finish executing, and also taking care of yes/no prompts during command execution.
 Here's an example of a simple script to log in to the router and show the version:
 from netmiko import ConnectHandler
 device = ConnectHandler(device_type='cisco_ios', ip='192.168.255.249',
 username='cisco', password='cisco')
 output = device.send_command(""show version"")
 print (output)
 device.disconnect()",NA
Network automation use case,"As we have now interacted with multiple sections of Python and device interaction,
 let's create a use case to incorporate what we have learned so far. The use case is as
 follows
 :
 Log into the router and fetch some information:
 task1()
 : Show the version, show the IP in brief, show the clock, and show
 1.
 the configured usernames on the router.
 task2()
 : Create another username on the 
 test
  router with the password
 2.
 test
  and check whether we can log in successfully with the newly created
 username.
 task3()
 : Log in with the newly created username 
 test
 , and delete all the
 3.
 other usernames from the 
 running-config
 . Once this is done, return all
 the current usernames configured on the router to confirm whether only
 the 
 test
  username is configured on the router.
 Let's build a script to tackle these tasks one by one:
 from netmiko import ConnectHandler
 device = ConnectHandler(device_type='cisco_ios', ip='192.168.255.249',
 username='cisco', password='cisco')
 def task1():
     output = device.send_command(""show version"")
     print (output)
     output= device.send_command(""show ip int brief"")
     print (output)
     output= device.send_command(""show clock"")
     print (output)
     output= device.send_command(""show running-config | in username"")
     output=output.splitlines()
     for item in output:
         if (""username"" in item):",NA
Summary,"In this chapter, we learned some advanced techniques for writing scripts by using
 functions, conditions, and loops; we covered multi-threading our scripts for faster
 and parallel execution, we got familiar with using Netmiko to interact with network
 devices, and looked at a real-world example of achieving a certain set of tasks using a
 single script.",NA
3,NA,NA
Continuous Integration for,NA,NA
Network Engineers,"In this chapter, we will see some of the tools that help us in working on planning our
 automation projects, and some examples to interact with some increasingly complex
 scenarios related to various devices or network technologies.
 Some of the aspects that we will be working on are:
 Interaction with Splunk
 BGP and routing table
 Wireless client to AP to switchport
 Phone to switchport
 WLAN and IPAM
 Useful best practices and use cases",NA
Interaction with Splunk,"Splunk
  is one of the most widely used data mining tools. With its data mining and
 digging capabilities, engineers can take actions based upon decisions. While it is
 useful in various aspects, here we will see an example of Splunk being used as a
 Syslog server, with our test router sending a message (as syslog) to this server, and
 how from automation we can query results from Splunk for these syslogs and take
 actions.
 This is an important part of automation, since based upon certain events (alerts and
 syslogs), engineers need to perform automated tasks, like self healing, or even
 triggering emails or using third-party tools to create tickets for various teams to work
 on.
 Here we will see the basic implementation and configuration of Splunk as a Syslog
 server:
  
 After downloading and installing Splunk , it can be accessed from the
 1.
 URL 
 http://localhost:8000/en-US/account/login?return_to=%2
 Fen-US%2F
  as we can see in the following screenshot:",NA
Automation examples on various,NA,NA
technology domains,"With the familiarity and understanding of automation with the interaction of devices,
 APIs, controllers, let's see some examples of how to interact with other network
 domain devices and tackle some complex scenarios using automation frameworks.
 Some of these examples will be a small project in themselves, but
 will help you understand additional ways of performing automation
 tasks in depth.",NA
BGP and routing table,"Let's take an example in which we need to configure BGP, validate if a session is up,
 and report the details for the same. In our example, we would take two routers (as a
 prerequisite, both routers are able to ping each other) as follows:
 As we see 
 R2
  and 
 testrouter
  are able to ping each other using an IP address of the
 FastEthernet0/0
  interface of each other.",NA
Configuring Cisco switchport for access point,"When working with a multi-device environment, along with routers and switches we
 need to interact with other network gear(s) like wireless devices. This example will
 show how to configure a switch with specific ports to be connected to 
 Access Point
 (
 AP
 ) as trunk. 
 In our test case, assuming the VLANs configured on AP are 
 vlan 100
  and 
 vlan 200
 for users, and the native VLAN is 
 vlan 10
 , and the code is as follows:
 from netmiko import ConnectHandler
 import time
 def apvlanpush(routerip,switchport):
     uname=""cisco""
     passwd=""cisco""
     device = ConnectHandler(device_type='cisco_ios', ip=routerip,
 username=uname, password=passwd)
     cmds=""interface ""+switchport
     cmds=cmds+""\nswitchport mode trunk\nswitchport trunk encapsulation
 dot1q\n""
     cmds=cmds+ ""switchport trunk native vlan 10\nswitchport trunk
 allowed vlan add 10,100,200\nno shut\n""
     xcheck=device.send_config_set(cmds)
     print (xcheck)",NA
Configuring Cisco switchport for IP Phone,"Similar to the earlier scenario, where we want a switchport as a trunk port for AP, we
 can configure the switchport to work with IP Phones. An additional task for
 configuring a port to be used as IP Phone is that another end machine or data
 machine can be connected to the IP Phone for data transfer. In other words, a single
 switchport of a Cisco router can act as both a voice and data port when used with IP
 Phone.",NA
Wireless LAN (WLAN),"There are many vendors that have backend APIs that can be controlled or called
 using Python to perform certain wireless tasks. A commonly used vendor in wireless
 is 
 Netgear
 . Python has a library 
 pynetgear
  that helps us achieve some of the
 automation to control our locally connected devices. 
 Let's see an example of fetching the current network devices connected to the local
 wireless Netgear router in our network:
 >>> from pynetgear import Netgear, Device
 >>> netgear = Netgear(""myrouterpassword"",
 ""192.168.100.1"",""admin"",""80"")
 >>> for i in netgear.get_attached_devices():
   print (i)
 The 
 Netgear
  method accepts four arguments in the following order
 (
 routerpassword
 , 
 routerip
 , 
 routerusername
 , and 
 routerport
 ). As we see in the
 current example, the router is reachable using 
 http://192.168.100.1
  with the
 username 
 admin
  and password as 
 myrouterpassword
 . Hence, we call the method
 with these parameters.
 The output is shown as follows:
 >>> netgear.get_attached_devices()
 [Device(signal=3, ip='192.168.100.4', name='ANDROID-12345',
 mac='xx:xx:xx:xx:xx:xx', type='wireless', link_rate=72),
 Device(signal=None, ip='192.168.100.55', name='ANDROID-678910',
 mac='yy:yy:yy:yy:yy:yy', type='wireless', link_rate=72),
 Device(signal=None, ip='192.168.100.10', name='mylaptop',
 mac='zz:zz:zz:zz:zz:zz', type='wireless', link_rate=520)]
 As we see, the method 
 get_attached_devices()
  returned a list of all the IPs, their
 MAC addresses (hidden in this example), signal (or wireless band being used), and
 the link rate for the connection in Mbps.
 We can use similar type of methods to manipulate bandwidth, block any user, or
 perform other tasks that are exposed by the APIs of the specific hardware
 manufacturer.",NA
Access of IP Address Management (IPAM),"Another requirement in networking is to use the IPAM database for IPAM. It is
 provided by different vendors, and as an example here, we would refer to
 SolarWind's IPAM. SolarWinds is again an industry standard tool for monitoring and
 performing various functionalities on a network, and it has a good set of APIs to
 interact with using its ORION SDK toolkit.
 In Python, we can install the library 
 orionsdk
  to achieve interaction with
 SolarWinds. Let's see an example in which we fetch the next available IP address from
 the IPAM module in SolarWinds:
 from orionsdk import SwisClient
 npm_server = 'mysolarwindsserver'
 username = ""test""
 password = ""test""
 verify = False
 if not verify:
     from requests.packages.urllib3.exceptions import
 InsecureRequestWarning
     requests.packages.urllib3.disable_warnings(InsecureRequestWarning)
 swis = SwisClient(npm_server, username, password)
 print(""My IPAM test:"")
 results=swis.query(""SELECT TOP 1 Status, DisplayName FROM IPAM.IPNode
 WHERE Status=2"")
 print (results)
 ### for a formatted printing
 for row in results['results']:
  print(""Avaliable: {DisplayName}"".format(**row))
 The output is as follows:",NA
Example and use case,"Here, we will see a detailed example that is common to most network engineers, and
 how to automate it using Python. Also, we will create it as a web based tool, enabling
 it to run from any environment or machine, using only a browser.",NA
Create a web-based pre and post check tool,NA,NA
for validations,"In the following example, we will see how we can perform a pre and post check on
 any network maintenance that we do. This is generally required by every network
 engineer while performing activities on production devices to ensure that once the
 maintenance activity is complete, an engineer has not missed out anything that could
 cause an issue later on. It is also required to validate if our changes and maintenance
 have been completed successfully, or if we need to perform additional fixes and
 rollbacks in case of validations that have failed.",NA
Step 1 ,NA,NA
–,NA,NA
 Create the main HTML file,"We will design a web-based form to select certain show commands that we will call
 for performing checks. These commands, when executed, will act as a precheck; once
 our maintenance activity is complete, we will act again as a postcheck.
 Any difference between the same command outputs in precheck or postcheck
 scenarios will be highlighted and the engineer will be in a good position to make
 decisions on calling the maintenance a success or failure, based on the outputs.
 The HTML code (
 prepostcheck.html
 ) is as follows:
 <!DOCTYPE html>
 <html xmlns=""http://www.w3.org/1999/xhtml"">
 <head>
          <script>
              function checkme() {
         var a=document.forms[""search""][""cmds""].value;
         var b=document.forms[""search""][""searchbox""].value;
         var c=document.forms[""search""][""prepost""].value;
         var d=document.forms[""search""][""changeid""].value;
         if (a==null || a=="""")
         {
           alert(""Please Fill All Fields"");
           return false;
         }
         if (b==null || b=="""")
         {
           alert(""Please Fill All Fields"");
           return false;
         }
         if (c==null || c=="""")
         {
           alert(""Please Fill All Fields"");
           return false;
         }
         if (d==null || d=="""")
         {
           alert(""Please Fill All Fields"");
           return false;
         }
 document.getElementById(""mypoint"").style.display = ""inline"";
              }",NA
Step 2 ,NA,NA
–,NA,NA
 Create the backend Python code,"Now, let's see the back end Python code (
 checks.py
 )
  
 that will accept these inputs
 from HTML form and perform its task. The code is as follows:
 #!/usr/bin/env python
 import cgi
 import paramiko",NA
Step 3 ,NA,NA
–,NA,NA
 Create web server based files for the tool,"Now with the both pre and post check files created, let's create a web framework to
 perform web-based pre/post check for the files. We need to create a web page in
 which our current log files are visible as pre and post files, and we can select the
 precheck
  file and its relevant 
 postcheck
  file for comparison. As we know that we
 cannot use HTML or browser languages to fetch information about any files from the
 server,  we need to use some backed web language to perform this function for us.
 We take advantage of ASP and VB.NET to create the web page to display the already
 created log files for selection and comparison.
 The backend code for 
 selectfiles.aspx
  is as follows (this is to display the files
 from the log directory on a browser):
 <%@ Page Language=""VB"" AutoEventWireup=""false""
 CodeFile=""selectfiles.aspx.vb"" Inherits=""selectfiles"" %>
 <!DOCTYPE html>
 <html xmlns=""http://www.w3.org/1999/xhtml"">
 <head runat=""server"">
     <title></title>
 </head>
 <body>
     <form id=""form1"" method=""post"" action=""comparefiles.aspx"" >
     <div>
     <%response.write(xmystring.tostring())%>
     </div>
          <input type=""submit"" value=""Submit"">
     </form>
   <br><br><br>
 </body>
 </html>",NA
Step 4 ,NA,NA
–,NA,NA
 Create server based files for pre and post,NA,NA
files comparison,"The final step is to create a web page that retrieves the text from these files and also
 provides frontend (or a web-based tool) for easy comparison. For our purpose, we use
 a JScript library called 
 diffview
  
 . 
 To call this dependency, we need to download
  
 diffview.js
 , 
 difflib.js
 , and 
 diffview.css
  which available here: 
 https:/
 ​
 /
 github.
 ​
 com/
 ​
 cemerick/
 ​
 jsdifflib, 
 and copy the files into our web server folder.
 Once done, in the similar way as accessing the files, we would again create a 
 .aspx
 page to get the content of the selected files and display it for comparison.
 The following is the code of the main page 
 comparefiles.aspx
 :
 <%@ Page Language=""VB"" AutoEventWireup=""false""
 CodeFile=""comparefiles.aspx.vb"" Inherits=""comparefiles"" %>
 <!DOCTYPE html>
 <html xmlns=""http://www.w3.org/1999/xhtml"">
 <head>
   <meta charset=""utf-8""/>
   <meta http-equiv=""X-UA-Compatible"" content=""IE=Edge,chrome=1""/>
   <link rel=""stylesheet"" type=""text/css"" href=""diffview.css""/>
   <script type=""text/javascript"" src=""diffview.js""></script>
   <script type=""text/javascript"" src=""difflib.js""></script>
 <style type=""text/css"">
 body {
   font-size: 12px;
   font-family: Sans-Serif;
 }
 h2 {
   margin: 0.5em 0 0.1em;
   text-align: center;
 }
 .top {
   text-align: center;
 }
 .textInput {
   display: block;
   width: 49%;
   float: left;
 }
 textarea {
   width:100%;
   height:300px;
 }",NA
Summary,"In this chapter, we saw various concepts related to the usage of automation in daily
 network scenarios. We got familiar with examples of performing various tasks related
 to additional devices such as wireless AP and IP Phones. Additionally, we also got
 introduced to IPAM of SolarWinds and how to work on the API using Python.
 We also saw a real-world example of creating a pre and post validation tool to help
 engineers make quick maintenance validation decisions, and also ported to the web
 so that the tool can be used from anywhere, instead of running from individual
 machines with Python installed as a prerequisite.
 Finally, in our concluding chapter, we will look at some additional aspects of SDN to
 understand better usage and how and where to automate, with respect to SDN
 scenarios.",NA
4,NA,NA
SDN Concepts in Network,NA,NA
Automation,"As we have seen on our journey so far, there are numerous scenarios where we can
 automate a network, from daily or routine tasks, to managing infrastructure from a
 single controller-based architecture.  Building upon those concepts, we will now gain
 some additional insights for working in 
 software-defined networks
  (
 SDNs
 ) and look
 at some examples of working with cloud platforms.
 Some of the key components we are going to cover are:
 Cloud platform automation
 Network automation tools
 Controller-based network fabric
 Programmable network devices",NA
Managing cloud platforms,"We can use network automation techniques through Python to work on various cloud
 providers. From working on cloud instances, to spinning up new VMs, controlling
 full access like ACLs, and creating specific network layer tasks like VPNs, and
 network configurations of each instance, we can automate just about anything using
 available connectors or APIs in Python. Let's see some basic configuration and
 connections on the most popular cloud platform, 
 Amazon Web Services
  (
 AWS
 )
 using Python.",NA
Programmable network devices,"Looking back at historic implementations, we had a fixed set of hardware or
 networks geared for catering services to the end users. End users also had a limited
 set of connection options to access a limited set of networks or connected
 resources. As the number of users increased, a simple solution was to add additional
 hardware or network gear. However, with the surge of different end user devices,
 such as mobile phones, and high data demand and up time requirements for end
 users, managing the increasing amount of hardware and additional connections
 becomes a complex task.
 A simple device failure or cable failure might impact the entire set of connected
 hardware or network gears, which would create a widespread downtime for end
 users, resulting in a loss of man hours both in terms of productivity and trust. Think
 of a large 
 internet service provider
  (
 ISP
 ) with recurring outages, with each outage
 affecting a large set of both enterprise and home users. If a new ISP were to enter the
 market with reliability as its unique selling point, people would not think twice
 before jumping to the new provider. Effectively, this could result in a loss of business
 and ultimately, a closure situation for the earlier provider because of the decreasing
 reliability and trust among its current set of users.
 To handle this type of situation, one solution that has emerged is the usability of the
 same set of devices or network hardware to perform different functions using the
 same hardware platform. This has been made possible through a combination
 of SDN
  
 and 
 programmable networks
  (
 PNs
 ).
 SDN takes care of control plane configurations for data to automatically reroute to a
 path that is the best available for a specific source to the destination. For example, let's
 say we need to reach destination D from source A. The best path to reach D is A -> C
 -> D.
 Now, in the case of legacy traffic flow, unless C is down or practically shut, the traffic
 will not flow from A -> B -> D (unless special complex configurations are done on
 each network gear/device). In an SDN environment, using OpenFlow as the
 underlying protocol, the controller will detect any issues in the path of A -> C -> D,
 and based upon certain issues (like packet drop or congestion in the path), would
 make an intelligent decision to ensure there is a new path for the data to flow from A
 -> B -> D.",NA
Controller-based network fabric,"As we come out of the legacy hardware era in which each physical path was
 connected and designed to take traffic from one point to another, and where a packet
 had limited availability to reach from one device to another, SDN is ensuring that we
 have a network fabric for our data to reach between different sources and
 destinations.",NA
Network automation tools,"As we have seen throughout the previous chapters, we have multiple choices
 regarding automating a network. From a basic configuration for any device using
 Netmiko to deploying and creating configurations across various devices in a
 network using Ansible,
  
 there are many options for engineers to automate networks
 based upon various needs.
 Python is extensively used in creating automation scenarios, owing to its open
 community support for various vendors and protocols. Nearly every major player in
 the industry has support for Python programming, tweaking their own tools or any
 supporting technology that they have. Another major aspect of network automation
 are the custom-based solutions that could be made for organization requirements.
 The self-service API model is a good start to ensuring that some of the tasks that are
 done manually can be converted to APIs, which can then be leveraged into any
 language based upon the automation needs.
 Let's see an example that can be used as a basic guide to understand the advantage of
 self or custom-created automation tools. The output of 
 show ip bgp summary
  
  in
 Cisco is the same as 
 show bgp summary
  in Juniper. Now, as an engineer who needs
 to validate the BGP on both the vendors, I need to understand both the commands
 and interpret the output.",NA
Summary,"In this chapter, we learned about the basic functionality of SDN controllers,
 programmable fabric, and some network automation tools. We have also seen how to
 work with cloud platforms and, with reference to a live example of managing AWS
 Cloud from Python, understood how we can control cloud operations using
 automation.
 We gained a deep understanding about the role of controllers, and with some
 examples of Cisco controllers, went into details on how a controller can be
 programmed or called in programs/scripts to perform certain tasks. We also saw the
 basics of some popular network automation tools, such as SolarWinds, and created an
 in-house web-based automation tool for monitoring our network, called PingMatrix
 or PingMesh.",NA
5,NA,NA
Low-Level Network Device,NA,NA
Interactions,"In this chapter, we will start to dive deeper into the management of network devices
 using Python. In particular, we will examine the different ways in which we can use
 Python to programmatically communicate with legacy network routers and switches.
 What do I mean by legacy network routers and switches? While it is hard to imagine
 any networking device coming out today without an 
 Application Program Interface
 (
 API
 ) for programmatic communication, it is a known fact that many of the network
 devices deployed in previous years did not contain API interfaces. The intended
 method of management for those devices was through 
 Command Line Interfaces
 (
 CLIs
 ) using terminal programs, which were originally developed with a human
 engineer in mind. The management relied on the engineer's interpretation of the data
 returned from the device for appropriate action. As the number of network devices
 and the complexity of the network grew, it became increasingly difficult to manually
 manage them one by one. 
 Python has two great libraries that can help with these tasks, Pexpect and Paramiko,
 as well as other libraries derived from them. This chapter will cover Pexpect first,
 then move on with examples from Paramiko. Once you understand the basics of
 Paramiko, it is easy to branch out to expanded libraries such as Netmiko. It is also
 worth mentioning that Ansible (covered in 
 Chapters 7
 , 
 The Python Automation
 Framework 
 –
  Ansible Basics
 , and 
 Chapter 8
 , 
 The Python Automation Framework 
 –
  Beyond
 Basics
 ) relies heavily on Paramiko for its network modules. In this chapter, we will
 take a look at the following topics:
 The challenges of the CLI
 Constructing a virtual lab
 The Python Pexpect library",NA
The challenges of the CLI Data center networking changes (source:  ),"At the Interop expo in Las Vegas in 2014, 
 BigSwitch Networks'
  CEO Douglas Murray
 displayed the following slide to illustrate what had changed in 
 Data Center
 Networking
  (
 DCN
 ) in the 20 years between 1993 to 2013:
 https:/
 ​
 /
 ​
 www.
 ​
 bigswitch.
 ​
 com/
 ​
 sites/
 ​
 default/
 ​
 files/
 presentations/
 ​
 murraydouglasstartuphotseatpanel.
 ​
 pdf
 His point was apparent: not much had changed in those 20 years in the way we
 manage network devices. While he might have been negatively biased toward the
 incumbent vendors when displaying this slide, his point is well taken. In his opinion,
 the only thing that had changed about managing routers and switches in 20 years was
 the protocol changing from the less secure Telnet to the more secure SSH.",NA
Constructing a virtual lab,"Before we dive into the packages, let's examine the options of putting together a lab
 for the benefit of learning. As the old saying goes, 
 practice makes perfect
 : we need an
 isolated sandbox to safely make mistakes, try out new ways of doing things, and
 repeat some of the steps to reinforce concepts that were not clear in the first try. It is
 easy enough to install Python and the necessary packages for the management host,
 but what about those routers and switches that we want to simulate?",NA
Cisco VIRL,"I remember when I first started to study for my 
 Cisco Certified Internetwork Expert
 (
 CCIE
 ) lab exam, I purchased some used Cisco equipment from eBay to study with.
 Even at a discount, each router and switch cost hundreds of US dollars, so to save
 money, I purchased some really outdated Cisco routers from the 1980s (search for
 Cisco AGS routers in your favorite search engine for a good chuckle), which
 significantly lacked features and horsepower, even for lab standards. As much as it
 made for an interesting conversation with family members when I turned them on
 (they were really loud), putting the physical devices together was not fun. They were
 heavy and clunky, it was a pain to connect all the cables, and to introduce link failure,
 I would literally unplug a cable.
 Fast-forward a few years. 
 Dynamip
  was created and I fell in love with how easy it
 was to create different network scenarios. This was especially important when I tried
 to learn a new concept. All you need is the IOS images from Cisco, a few carefully
 constructed topology files, and you can easily construct a virtual network that you
 can test your knowledge on. I had a whole folder of network topologies, pre-saved
 configurations, and different version of images, as called for by the scenario. The
 addition of a GNS3 frontend gives the whole setup a beautiful GUI facelift. With
 GNS3, you can just click and drop your links and devices; you can even just print out
 the network topology for your manager right out of the GNS3 design panel. The only
 thing that was lacking was the tool not being officially blessed by the vendor and the
 perceived lack of credibility because of it. 
 In 2015, the Cisco community decided to fulfill this need by releasing the Cisco VIRL.
 If you have a server that meets the requirements and you are willing to pay for the
 required annual license, this is my preferred method of developing and trying out
 much of the Python code, both for this book and my own production use.",NA
VIRL tips,"The VIRL website (
 http:/
 ​
 /
 ​
 virl.
 ​
 cisco.
 ​
 com/
 ​
 ) offers lots of guidance,
 preparation, and documentation. I also find that the VIRL user community generally
 offers quick and accurate help. I will not repeat information already offered in those
 two places; however, here are some of the setups I use for the lab in this book:
 VIRL uses two virtual Ethernet interfaces for connections. The first
 1.
 interface is set up as NAT for the host machine's internet connection, and
 the second is used for local management interface connectivity (VMnet2 in
 the following example). I use a separate virtual machine with a similar
 network setup in order to run my Python code, with the first primary
 Ethernet used for internet connectivity and the second Ethernet connection
 to Vmnet2 for lab device management network:",NA
Cisco DevNet and dCloud,"Cisco provides two other excellent, and, at the time of writing, free, methods for
 practicing network automation with various Cisco gears. Both of the tools require
 a 
 Cisco Connection Online (CCO)
  login. They are both really good, especially for the
 price point (they are free!). It is hard for me to imagine that these online tools will 
 remain free for long; it is my belief that, at some point, these tools will need to charge
 money for their usage or be rolled into a bigger initiative that requires a fee.
 However, we can take advantage of them while they are available at no charge.
 The first tool is the Cisco DevNet (
 https:/
 ​
 /
 ​
 developer.
 ​
 cisco.
 ​
 com/
 ​
 ) sandbox, which
 includes guided learning tracks, complete documentation, and sandbox remote labs,
 among other benefits. Some of the labs are always on, while others you need to
 reserve. The lab availability will depend on usage. It is a great alternative if you do
 not already have a lab at your own disposal. In my experience with DevNet, some of
 the documentation and links were outdated, but they can be easily retrieved for the
 most updated version. In a rapidly changing field such as software development, this
 is somewhat expected. DevNet is certainly a tool that you should take full advantage
 of, regardless of whether you have a locally run VIRL host or not:",NA
GNS3,"There are a few other virtual labs that I use for this book and other purposes. The
 GNS3
  tool is one of them:
 As mentioned previously in this chapter, 
 GNS3
  is what a lot of us used to study for
 certification tests and to practice for labs. The tool has really grown up from the early
 days of the simple frontend for Dynamips into a viable commercial product. Cisco-
 made tools, such as VIRL, DevNet, and dCloud, only contain Cisco technologies.
 Even though they provide ways for virtual lab devices to communicate with the
 outside world, they are not as easy as just having multi-vendor virtualized appliances
 living directly in the simulation environment. 
 GNS3
  is vendor-neutral and can
 include a multi-vendor virtualized platform directly in the lab. This is typically done
 either by making a clone of the image (such as Arista vEOS) or by directly launching
 the network device image via other hypervisors (such as Juniper Olive emulation).
 Some might argue that GNS3 does not have the breadth and depth of the Cisco VIRL
 project, but since they can run different variation Cisco technologies, I often use it
 when I need to incorporate other vendor technologies into the lab. 
 Another multi-vendor network emulation environment that has gotten a lot of great 
 reviews is the 
 Emulated Virtual Environment Next Generation (EVE-NG)
 , 
 http:/
 ​
 /
 www.
 ​
 eve-
 ​
 ng.
 ​
 net/
 ​
 . I personally do not have much experience with the tool, but many
 of my colleagues and friends in the industry use it for their network labs.",NA
Python Pexpect library,"Pexpect is a pure Python module for spawning child applications, controlling them,
 and responding to expected patterns in their output. Pexpect works like Don Libes'
 Expect. Pexpct allows your script to spawn a child application and control it as if a
 human were typing commands. Pexpect, Read the Docs: 
 https:/
 ​
 /
 ​
 pexpect.
 readthedocs.
 ​
 io/
 ​
 en/
 ​
 stable/
 ​
 index.
 ​
 html
 Let's take a look at the Python Pexpect library. Similar to the original Tcl Expect
 module by Don Libe, Pexpect launches or spawns another process and watches over
 it in order to control the interaction. The Expect tool was originally developed to
 automate interactive processes such as FTP, Telnet, and rlogin, and was later
 expanded to include network automation. Unlike the original Expect, Pexpect is
 entirely written in Python, which does not require TCL or C extensions to be
 compiled. This allows us to use the familiar Python syntax and its rich standard
 library in our code.",NA
Pexpect installation,"Since this is the first package we will install, we will install both the 
 pip
  tool with
 the 
 pexpect
  package. The process is pretty straightforward:
 sudo apt-get install python-pip #Python2
 sudo apt-get install python3-pip
 sudo pip3 install pexpect
 sudo pip install pexpect #Python2",NA
Pexpect overview Lab topology,"For our first lab, we will construct a simple network with two IOSv devices connected
 back to back: 
 The devices will each have a loopback address in the 
 192.16.0.x/24
  range and the
 management IP will be in the 
 172.16.1.x/24
  range. The VIRL topology file is
 included in the accommodated book downloadable files. You can import the topology
 to your own VIRL software. If you do not have VIRL, you can also view the necessary
 information by opening the topology file with a text editor. The file is simply an XML
 file with each node's information under the 
 node
  element:",NA
Our first Pexpect program,"Our first program, 
 chapter5_1.py
 , extends what we did in the last section with
 some additional code:
      #!/usr/bin/python3
      import pexpect
      devices = {'iosv-1': {'prompt': 'iosv-1#', 'ip': '172.16.1.20'},
 'iosv-2': {'prompt': 'iosv-2#', 'ip': '172.16.1.21'}}
      username = 'cisco'
      password = 'cisco'
      for device in devices.keys():
          device_prompt = devices[device]['prompt']
          child = pexpect.spawn('telnet ' + devices[device]['ip'])",NA
More Pexpect features,"In this section, we will look at more Pexpect features that might come in handy when
 certain situations arise.
 If you have a slow or fast link to your remote device, the default 
 expect()
  method
 timeout is 30 seconds, which can be increased or decreased via the 
 timeout
 argument:
 >>> child.expect('Username', timeout=5)",NA
Pexpect and SSH,"If you try to use the previous Telnet example and plug it into an SSH session instead,
 you might find yourself pretty frustrated with the experience. You always have to 
 include the username in the session, answering the 
 ssh
  new key question, and much
 more mundane tasks. There are many ways to make SSH sessions work, but luckily,
 Pexpect has a subclass called 
 pxssh
 , which specializes in setting up SSH connections.
 The class adds methods for login, log out, and various tricky things to handle
 the different situations in the 
 ssh
  login process. The procedures are mostly the same,
 with the exception of 
 login()
  and 
 logout()
 :
 >>> from pexpect import pxssh
 >>> child = pxssh.pxssh()
 >>> child.login('172.16.1.20', 'cisco', 'cisco',
 auto_prompt_reset=False)
 True
 >>> child.sendline('show version | i V')
 19
 >>> child.expect('iosv-1#')
 0
 >>> child.before
 b'show version | i VrnCisco IOS Software, IOSv Software (VIOS-
 ADVENTERPRISEK9-M), Version 15.6(2)T, RELEASE SOFTWARE
 (fc2)rnProcessor board ID 9MM4BI7B0DSWK40KV1IIRrn'
 >>> child.logout()
 >>>
 Notice the 
 auto_prompt_reset=False
  argument in the 
 login()
  method. By
 default, 
 pxssh
  uses the Shell prompt to synchronize the output. But since it uses the
 PS1 option for most of bash or CSH, they will error out on Cisco or other network
 devices.",NA
Putting things together for Pexpect,"As the final step, let's put everything you have learned so far about Pexpect into a
 script. Putting code into a script makes it easier to use in a production environment,
 as well as easier to share with your colleagues. We will write our second script,
 chapter5_2.py
 .",NA
The Python Paramiko library,"Paramiko is a Python implementation of the SSHv2 protocol. Just like the 
 pxssh
 subclass of Pexpect, Paramiko simplifies the SSHv2 interaction between the host and
 the remote device. Unlike 
 pxssh
 , Paramiko focuses only on SSHv2 with no Telnet
 support. It also provides both client and server operations.
 Paramiko is the low-level SSH client behind the high-level automation framework
 Ansible for its network modules. We will cover Ansible in later chapters. Let's take a
 look at the Paramiko library.",NA
Installation of Paramiko,"Installing Paramiko is pretty straightforward with Python 
 pip
 . However, there is a
 hard dependency on the cryptography library. The library provides low-level, C-
 based encryption algorithms for the SSH protocol.
 The installation instruction for Windows, Mac, and other flavors of
 Linux can be found at 
 https:/
 ​
 /
 ​
 cryptography.
 ​
 io/
 ​
 en/
 ​
 latest/
 installation/
 ​
 .",NA
Paramiko overview,"Let's look at a quick Paramiko example using the Python 3 interactive shell:
 >>> import paramiko, time
 >>> connection = paramiko.SSHClient()
 >>> connection.set_missing_host_key_policy(paramiko.AutoAddPolicy())
 >>> connection.connect('172.16.1.20', username='cisco',
 password='cisco', look_for_keys=False, allow_agent=False)
 >>> new_connection = connection.invoke_shell()
 >>> output = new_connection.recv(5000)
 >>> print(output)
 b""rn******************************************************************
 ********rn* IOSv is strictly limited to use for evaluation,
 demonstration and IOS *rn* education. IOSv is provided as-is and is",NA
Our first Paramiko program,"Our first program will use the same general structure as the Pexpect program we
 have put together. We will loop over a list of devices and commands while using
 Paramiko instead of Pexpect. This will give us a good compare and contrast of the
 differences between Paramiko and Pexpect.",NA
More Paramiko features,"We will look at Paramiko a bit later in the book, when we discuss Ansible, as
 Paramiko is the underlying transport for many of the network modules. In this
 section, we will take a look at some of the other features of Paramiko.",NA
Paramiko for servers,"Paramiko can be used to manage servers through SSHv2 as well. Let's look at an
 example of how we can use Paramiko to manage servers. We will use key-based
 authentication for the SSHv2 session.
 In this example, I used another Ubuntu virtual machine on the same
 hypervisor as the destination server. You can also use a server on
 the VIRL simulator or an instance in one of the public cloud
 providers, such as Amazon AWS EC2.
 We will generate a public-private key pair for our Paramiko host:
 ssh-keygen -t rsa
 This command, by default, will generate a public key named 
 id_rsa.pub
 , as the
 public key under the user home directory 
 ~/.ssh
  along with a private key named
 id_rsa
 . Treat the private key with the same attention as you would private
 passwords that you do not want to share with anybody else. You can think of the
 public key as a business card that identifies who you are. Using the private and public
 keys, the message will be encrypted by your private key locally and decrypted by
 the remote host using the public key. We should copy the public key to the remote
 host. In production, we can do this via out-of-band using a USB drive; in our lab, we
 can simply copy the public key to the remote host's 
 ~/.ssh/authorized_keys
  file.
 Open up a Terminal window for the remote server, so you can paste in the public key.
 Copy the content of 
 ~/.ssh/id_rsa
  on your management host with Paramiko:
 <Management Host with Pramiko>$ cat ~/.ssh/id_rsa.pub
 ssh-rsa <your public key> echou@pythonicNeteng
 Then, paste it to the remote host under the 
 user
  directory; in this case, I am using
 echou
  for both sides:
 <Remote Host>$ vim ~/.ssh/authorized_keys
 ssh-rsa <your public key> echou@pythonicNeteng
 You are now ready to use Paramiko to manage the remote host. Notice in this
 example that we will use the private key for authentication as well as the
 exec_command()
  method for sending commands:
 Python 3.5.2 (default, Nov 17 2016, 17:05:23)
 [GCC 5.4.0 20160609] on linux
 Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
 >>> import paramiko",NA
Putting things together for Paramiko,"We are almost at the end of the chapter. In this last section, let's make the Paramiko
 program more reusable. There is one downside of our existing script: we need to open
 up the script every time we want to add or delete a host, or whenever we need to
 change the commands we want to execute on the remote host. This is due to the fact
 that both the host and command information are statically entered inside of the script.
 Hardcoding the host and command has a higher chance of making mistakes. Besides,
 if you were to pass on the script to colleagues, they might not feel comfortable
 working in Python, Paramiko, or Linux.
 By making both the host and command files be read in as parameters for the script,
 we can eliminate some of these concerns. Users (and a future you) can simply modify
 these text files when you need to make host or command changes.",NA
Looking ahead,"We have taken a pretty huge leap forward in this chapter as far as automating our
 network using Python is concerned. However, the method we have used feels like
 somewhat of a workaround for automation. We attempted to trick the remote devices
 into thinking they were interacting with a human on the other end.",NA
Downsides of Pexpect and Paramiko,NA,NA
compared to other tools,"The biggest downside of our method so far is that the remote devices do not return
 structured data. They return data that is ideal to be fitted on a terminal to be
 interpreted by a human, not by a computer program. The human eye can easily
 interpret a space, while a computer only sees a return character. 
 We will take a look at a better way in the upcoming chapter. As a prelude to 
 Chapter
 6
 , 
 APIs and Intent-Driven Networking
 , let's discuss the idea of idempotency.",NA
Idempotent network device interaction,"The term 
 idempotency
  has different meanings, depending on its context. But in this
 book's context, the term means that when a client makes the same call to a remote
 device, the result should always be the same. I believe we can all agree that this is
 necessary. Imagine a scenario where each time you execute the same script, you get a
 different result back. I find that scenario very scary. How can you trust your script if
 that is the case? It would render our automation effort useless because we need to be
 prepared to handle different returns.",NA
Bad automation speeds bad things up,"Bad automation allows you to poke yourself in the eye a lot faster, it is as simple as
 that. Computers are much faster at executing tasks than us human engineers. If we
 had the same set of operating procedures executed by a human versus a script, the
 script would finish faster than humans, sometimes without the benefit of having a
 solid feedback loop between procedures. The internet is full of horror stories of when
 someone pressed the 
 Enter
  key and immediately regretted it.
 We need to make sure the chances of bad automation scripts screwing things up are
 as small as possible. We all make mistakes; carefully test your script before any
 production work and small blast radius are two keys to making sure you can catch
 your mistake before it comes back and bites you.",NA
Summary,"In this chapter, we covered low-level ways to communicate directly with network
 devices. Without a way to programmatically communicate and make changes to
 network devices, there is no automation. We looked at two libraries in Python that
 allow us to manage devices that were meant to be managed by the CLI. Although
 useful, it is easy to see how the process can be somewhat fragile. This is mostly due to
 the fact that the network gears in question were meant to be managed by human
 beings and not computers.
 In 
 Chapter 6
 , 
 APIs and Intent-Driven Networking
 , we will look at network devices
 supporting API and intent-driven networking.",NA
6,NA,NA
APIs and Intent-Driven,NA,NA
Networking,"In 
 Chapter 5
 , 
 Low-Level Network Device Interactions
 , we looked at ways to interact with
 the network devices using Pexpect and Paramiko. Both of these tools use a persistent
 session that simulates a user typing in commands as if they are sitting in front of a
 Terminal. This works fine up to a point. It is easy enough to send commands over for
 execution on the device and capture the output. However, when the output becomes
 more than a few lines of characters, it becomes difficult for a computer program to
 interpret the output. The returned output from Pexpect and Paramiko is a series of
 characters meant to be read by a human being. The structure of the output consists of
 lines and spaces that are human-friendly but difficult to be understood by computer
 programs. 
 In order for our computer programs to automate many of the tasks we want to
 perform, we need to interpret the returned results and make follow-up actions based
 on the returned results. When we cannot accurately and predictably interpret the
 returned results, we cannot execute the next command with confidence. 
 Luckily, this problem was solved by the internet community. Imagine the difference
 between a computer and a human being when they are both reading a web page. The
 human sees words, pictures, and spaces interpreted by the browser; the computer
 sees raw HTML code, Unicode characters, and binary files. What happens when a
 website needs to become a web service for another computer? The same web
 resources need to accommodate both human clients and other computer programs.
 Doesn't this problem sound familiar to the one that we presented before? The answer
 is the 
 Application Program Interface
  (
 API
 ). It is important to note that an API is a
 concept and not a particular technology or framework, according to Wikipedia.",NA
Infrastructure as code,"In a perfect world, network engineers and architects who design and manage
 networks should focus on what they want the network to achieve instead of the
 device-level interactions. In my first job as an intern for a local ISP, wide-eyed and
 excited, my first assignment was to install a router on a customer's site to turn up
 their fractional frame relay link (remember those?). How would I do that? I asked. I
 was handed a standard operating procedure for turning up frame relay links. I went
 to the customer site, blindly typed in the commands, and looked at the green lights
 flashing, then happily packed my bag and patted myself on the back for a job well
 done. As exciting as that first assignment was, I did not fully understand what I was
 doing. I was simply following instructions without thinking about the implication of
 the commands I was typing in. How would I troubleshoot something if the light was
 red instead of green? I think I would have called back to the office and cried for help
 (tears optional).",NA
Intent-Driven Networking,"Since the publication of the first edition of this book, the term 
 Intent-Based
 Networking
  has seen an uptick in use after major network vendors chose to use it to
 describe their next-generation devices. In my opinion, 
 Intent-Driven Networking
  is
 the idea of defining a state that the network should be in and having software code to 
 enforce that state. As an example, if my goal is to block port 80 from being externally
 accessible, that is how I should declare it as the intention of the network. The
 underlying software will be responsible for knowing the syntax of configuring and
 applying the necessary access-list on the border router to achieve that goal. Of course,
 Intent-Driven Networking is an idea with no clear answer on the exact
 implementation. But the idea is simple and clear, I would hereby argue that we
 should focus as much on the intent of the network and abstract ourselves from the
 device-level interaction. 
 In using an API, it is my opinion that it gets us closer to a state of intent-driven
 networking. In short, because we abstract the layer of a specific command executed
 on our destination device, we focus on our intent instead of the specific commands.
 For example, going back to our 
 block port 80
  access-list example, we might use
 access-list and access-group on a Cisco and filter-list on a Juniper. However, in using
 an API, our program can start asking the executor for their intent while masking what
 kind of physical device it is they are talking to. We can even use a higher-level
 declarative framework, such as Ansible, which we will cover in 
 Chapter 7
 , 
 The Python
 Automation Framework 
 –
  Ansible Basics
 . But for now, let's focus on network APIs.",NA
Screen scraping versus API structured output,"Imagine a common scenario where we need to log into the network device and make
 sure all the interfaces on the devices are in an up/up state (both the status and the
 protocol are showing as 
 up
 ). For the human network engineers getting into a Cisco
 NX-OS device, it is simple enough to issue the 
 show IP interface brief
 command in the Terminal to easily tell from the output which interface is up:
     nx-osv-2# show ip int brief
     IP Interface Status for VRF ""default""(1)
     Interface IP Address Interface Status
     Lo0 192.168.0.2 protocol-up/link-up/admin-up
     Eth2/1 10.0.0.6 protocol-up/link-up/admin-up
     nx-osv-2#
 The line break, white spaces, and the first line of the column title are easily
 distinguished from the human eye. In fact, they are there to help us line up, say, the
 IP addresses of each interface from line one to line two and three. If we were to put
 ourselves in the computer's position, all these spaces and line breaks only takes us
 away from the really important output, which is: which interfaces are in the up/up
 state? To illustrate this point, we can look at the Paramiko output for the same
 operation:
     >>> new_connection.send('sh ip int briefn')
     16
     >>> output = new_connection.recv(5000)
     >>> print(output)
     b'sh ip int briefrrnIP Interface Status for VRF
     ""default""(1)rnInterface IP Address Interface
     StatusrnLo0 192.168.0.2 protocol-up/link-up/admin-up
     rnEth2/1 10.0.0.6 protocol-up/link-up/admin-up rnrnx-
     osv-2# '
     >>>",NA
Data modeling for infrastructure as code Data modeling process ,"According to Wikipedia (
 https:/
 ​
 /
 ​
 en.
 ​
 wikipedia.
 ​
 org/
 ​
 wiki/
 ​
 Data_
 ​
 model
 ), the 
 definition for a data model is as follows:
 A data model is an abstract model that organizes elements of data and standardizes
 how they relate to one another and to properties of the real-world entities. For
 instance, a data model may specify that the data element representing a car be
 composed of a number of other elements which, in turn, represent the color and size
 of the car and define its owner.
 The data modeling process can be illustrated in the following diagram:",NA
The Cisco API and ACI,"Cisco Systems, the 800-pound gorilla in the networking space, have not missed out on
 the trend of network automation. In their push for network automation, they have
 made various in-house developments, product enhancements, partnerships, as well
 as many external acquisitions. However, with product lines spanning routers,
 switches, firewalls, servers (unified computing), wireless, the collaboration software
 and hardware, and analytic software, to name a few, it is hard to know where to start.
 Since this book focuses on Python and networking, we will scope this section to the
 main networking products. In particular, we will cover the following:
 Nexus product automation with NX-API
 Cisco NETCONF and YANG examples
 The Cisco application-centric infrastructure for the data center
 The Cisco application-centric infrastructure for the enterprise",NA
Cisco NX-API,"Nexus is Cisco's primary product line of data center switches. The NX-API (
 http:/
 ​
 /
 www.
 ​
 cisco.
 ​
 com/
 ​
 c/
 ​
 en/
 ​
 us/
 ​
 td/
 ​
 docs/
 ​
 switches/
 ​
 datacenter/
 ​
 nexus9000/
 ​
 sw/
 ​
 6-
 ​
 x/
 programmability/
 ​
 guide/
 ​
 b_
 ​
 Cisco_
 ​
 Nexus_
 ​
 9000_
 ​
 Series_NX-
 OS_Programmability_Guide/b_Cisco_Nexus_9000_Series_NX-
 OS_Programmability_Guide_chapter_011.html
 ) allows the engineer to interact with
 the switch outside of the device via a variety of transports including SSH, HTTP, and
 HTTPS.",NA
Lab software installation and device preparation,"Here are the Ubuntu packages that we will install. You may already have some of the
 packages such 
 pip
  and 
 git
 :
 $ sudo apt-get install -y python3-dev libxml2-dev libxslt1-dev libffi-
 dev libssl-dev zlib1g-dev python3-pip git python3-requests",NA
NX-API examples,"NX-API sandbox is a great way to play around with various commands, data formats,
 and even copy the Python script directly from the web page. In the last step, we
 turned it on for learning purposes. It should be turned off in production. Let's launch
 a web browser and take a look at the various message formats, requests, and
 responses based on the CLI commands that we are already familiar with:",NA
The Cisco and YANG models,"Earlier in this chapter, we looked at the possibility of expressing the network by using
 the data modeling language YANG. Let's look into it a little bit more with examples.
 First off, we should know that the YANG model only defines the type of data sent
 over the NETCONF protocol without dictating what the data should be. Secondly, it
 is worth pointing out that NETCONF exists as a standalone protocol, as we saw in the
 NX-API section. YANG, being relatively new, has a spotty supportability across
 vendors and product lines. For example, if we run the same capability exchange script
 that we have used before for a Cisco 1000v running IOS-XE, this is what we will see:
     urn:cisco:params:xml:ns:yang:cisco-virtual-service?module=cisco-
     virtual-service&revision=2015-04-09
     http://tail-f.com/ns/mibs/SNMP-NOTIFICATION-MIB/200210140000Z?
     module=SNMP-NOTIFICATION-MIB&revision=2002-10-14
     urn:ietf:params:xml:ns:yang:iana-crypt-hash?module=iana-crypt-
     hash&revision=2014-04-04&features=crypt-hash-sha-512,crypt-hash-
     sha-256,crypt-hash-md5
     urn:ietf:params:xml:ns:yang:smiv2:TUNNEL-MIB?module=TUNNEL-
     MIB&revision=2005-05-16
     urn:ietf:params:xml:ns:yang:smiv2:CISCO-IP-URPF-MIB?module=CISCO-
     IP-URPF-MIB&revision=2011-12-29
     urn:ietf:params:xml:ns:yang:smiv2:ENTITY-STATE-MIB?module=ENTITY-
     STATE-MIB&revision=2005-11-22
     urn:ietf:params:xml:ns:yang:smiv2:IANAifType-",NA
The Cisco ACI,"The Cisco 
 Application Centric Infrastructure
  (
 ACI
 ) is meant to provide a centralized
 approach to all of the network components. In the data center context, it means that
 the centralized controller is aware of and manages the spine, leaf, and top of rack
 switches, as well as all the network service functions. This can be done through GUI,
 CLI, or API. Some might argue that the ACI is Cisco's answer to the broader
 controller-based software-defined networking.
 One of the somewhat confusing points for ACI is the difference between ACI and
 APIC-EM. In short, ACI focuses on data center operations while APIC-EM focuses on
 enterprise modules. Both offer a centralized view and control of the network
 components, but each has its own focus and share of tool sets. For example, it is rare
 to see any major data center deploy a customer-facing wireless infrastructure, but a
 wireless network is a crucial part of enterprises today. Another example would be the
 different approaches to network security. While security is important in any network,
 in the data center environment, lots of security policies are pushed to the edge node
 on the server for scalability. In enterprise security, policies are somewhat shared
 between the network devices and servers.
 Unlike NETCONF RPC, ACI API follows the REST model to use the HTTP verb (
 GET
 ,
 POST
 , 
 DELETE
 ) to specify the operation that's intended.",NA
The Python API for Juniper networks,"Juniper networks have always been a favorite among the service provider crowd. If
 we take a step back and look at the service provider vertical, it would make sense that
 automating network equipment is on the top of their list of requirements. Before the
 dawn of cloud-scale data centers, service providers were the ones with the most
 network equipment. A typical enterprise network might have a few redundant
 internet connections at the corporate headquarter with a few hub-and-spoke remote
 sites connected back to the HQ using the service provider's private MPLS network. To
 a service provider, they are the ones who need to build, provision, manage, and
 troubleshoot the connections and the underlying networks. They make their money
 by selling the bandwidth along with value-added managed services. It would make
 sense for the service providers to invest in automation to use the least amount of
 engineering hours to keep the network humming along. In their use case, network
 automation is the key to their competitive advantage.",NA
Juniper and NETCONF NETCONF model ,"The 
 Network Configuration Protocol
  (
 NETCONF
 ) is an IETF standard, which was
 first published in 2006 as 
 RFC 4741
  and later revised in 
 RFC 6241
 . Juniper networks
 contributed heavily to both of the RFC standards. In fact, Juniper was the sole author
 for RFC 4741. It makes sense that Juniper devices fully support NETCONF, and it
 serves as the underlying layer for most of its automation tools and frameworks. Some
 of the main characteristics of NETCONF include the following:
 It uses 
 Extensible Markup Language
  (
 XML
 ) for data encoding.
 1.
 It uses 
 Remote Procedure Calls
  (
 RPC
 ), therefore in the case of HTTP(s) as
 2.
 the transport, the URL endpoint is identical while the operation intended is
 specified in the body of the request.
 It is conceptually based on layers from top to bottom. The layers include
 3.
 the content, operations, messages, and transport:",NA
Device preparation,"In order to start using NETCONF, let's create a separate user as well as turn on the
 required services:
     set system login user netconf uid 2001
     set system login user netconf class super-user
     set system login user netconf authentication encrypted-password
      ""$1$0EkA.XVf$cm80A0GC2dgSWJIYWv7Pt1""
     set system services ssh
     set system services telnet
     set system services netconf ssh port 830
 For the Juniper device lab, I am using an older, unsupported
 platform called 
 Juniper Olive
 . It is solely used for lab purposes. You
 can use your favorite search engine to find out some interesting facts
 and history about Juniper Olive.
 On the Juniper device, you can always take a look at the configuration either in a flat
 file or in XML format. The 
 flat
  file comes in handy when you need to specify a one-
 liner command to make configuration changes:
     netconf@foo> show configuration | display set
     set version 12.1R1.9
     set system host-name foo
     set system domain-name bar
     <omitted>
 The XML format comes in handy at times when you need to see the XML structure of
 the configuration:
     netconf@foo> show configuration | display xml
     <rpc-reply
 xmlns:junos=""http://xml.juniper.net/junos/12.1R1/junos"">
      <configuration junos:commit-seconds=""1485561328"" junos:commit-
     localtime=""2017-01-27 23:55:28 UTC"" junos:commit-user=""netconf"">
      <version>12.1R1.9</version>
      <system>
      <host-name>foo</host-name>
     <domain-name>bar</domain-name>",NA
Juniper NETCONF examples,"We will use a pretty straightforward example to execute 
 show version
 . We will
 name this file 
 junos_netconf_1.py
 :
   #!/usr/bin/env python3
   from ncclient import manager
   conn = manager.connect(
       host='192.168.24.252',
       port='830',
       username='netconf',
       password='juniper!',
       timeout=10,
       device_params={'name':'junos'},
       hostkey_verify=False)
   result = conn.command('show version', format='text')
   print(result)
   conn.close_session()
 All the fields in the script should be pretty self-explanatory, with the exception of
 device_params
 . Starting with ncclient 0.4.1, the device handler was added to specify
 different vendors or platforms. For example, the name can be juniper, CSR, Nexus, or
 Huawei. We also added 
 hostkey_verify=False
  because we are using a self-signed
 certificate from the Juniper device.
 The returned output is 
 rpc-reply
  encoded in XML with an 
 output
  element:
     <rpc-reply message-id=""urn:uuid:7d9280eb-1384-45fe-be48-
     b7cd14ccf2b7"">
     <output>
     
 Hostname: foo
     Model: olive
     JUNOS Base OS boot [12.1R1.9]
     JUNOS Base OS Software Suite [12.1R1.9]
     <omitted>",NA
Juniper PyEZ for developers,"PyEZ
  is a high-level Python implementation that integrates better with your existing
 Python code. By utilizing the Python API, you can perform common operation and
 configuration tasks without the extensive knowledge of the Junos CLI.
 Juniper maintains a comprehensive Junos PyEZ developer guide at
 https:/
 ​
 /
 ​
 www.
 ​
 juniper.
 ​
 net/
 ​
 techpubs/
 ​
 en_
 ​
 US/
 ​
 junos-
 ​
 pyez1.
 ​
 0/
 information-
 ​
 products/
 ​
 pathway-
 ​
 pages/
 ​
 junos-
 ​
 pyez-
 ​
 developer-
 guide.
 ​
 html#configuration
  on their technical library. If you are
 interested in using PyEZ, I would highly recommend at least a
 glance through the various topics in the guide.",NA
Installation and preparation,"The installation instructions for each of the operating systems can be found on the
 Installing Junos PyEZ
  (
 https:/
 ​
 /
 ​
 www.
 ​
 juniper.
 ​
 net/
 ​
 techpubs/
 ​
 en_
 ​
 US/
 ​
 junos-
 ​
 pyez1.
 ​
 0/
 topics/
 ​
 task/
 ​
 installation/
 ​
 junos-
 ​
 pyez-
 ​
 server-
 ​
 installing.
 ​
 html
 ) page. We will
 show the installation instructions for Ubuntu 16.04.
 The following are some dependency packages, many of which should already be on
 the host from running previous examples:
 $ sudo apt-get install -y python3-pip python3-dev libxml2-dev
 libxslt1-dev libssl-dev libffi-dev
 PyEZ
  packages can be installed via pip. Here, I have installed for both Python 3 and
 Python 2:
 $ sudo pip3 install junos-eznc
 $ sudo pip install junos-eznc
 On the Juniper device, NETCONF needs to be configured as the underlying XML API
 for PyEZ:
 set system services netconf ssh port 830",NA
PyEZ examples,"In the previous interactive prompt, we already saw that when the device connects,
 the object automatically retrieves a few facts about the device. In our first example,
 junos_pyez_1.py
 , we were connecting to the device and executing an RPC call for
 show interface em1
 :
       #!/usr/bin/env python3
       from jnpr.junos import Device
       import xml.etree.ElementTree as ET
       import pprint
       dev = Device(host='192.168.24.252', user='juniper',
 passwd='juniper!')",NA
The Arista Python API,"Arista Networks
  have always been focused on large-scale data center networks. In its
 corporate profile page (
 https:/
 ​
 /
 ​
 www.
 ​
 arista.
 ​
 com/
 ​
 en/
 ​
 company/
 ​
 company-
 ​
 overview
 ), it
 is stated as follows:
 ""Arista Networks was founded to pioneer and deliver software-driven cloud
 networking solutions for large data center storage and computing environments.""
 Notice that the statement specifically called out 
 large data centers
 , which we already
 know are exploded with servers, databases, and, yes, network equipment. It makes
 sense that automation has always been one of Arista's leading features. In fact, they
 have a Linux underpin behind their operating system, allowing many added benefits
 such as Linux commands and a built-in Python interpreter.
 Like other vendors, you can interact with Arista devices directly via eAPI, or you can
 choose to leverage their 
 Python
  library. We will see examples of both. We will also
 look at Arista's integration with the Ansible framework in later chapters.",NA
Arista eAPI management,"Arista's eAPI was first introduced in EOS 4.12 a few years ago. It transports a list of
 show or configuration commands over HTTP or HTTPS and responds back in JSON.
 An important distinction is that it is a 
 Remote Procedure Call
  (
 RPC
 ) and 
 JSON-RPC
 ,
 instead of a pure RESTFul API that's served over HTTP or HTTPS. For our intents
 and purposes, the difference is that we make the request to the same URL endpoint
 using the same HTTP method (
 POST
 ). Instead of using HTTP verbs (
 GET
 , 
 POST
 , 
 PUT
 ,
 DELETE
 ) to express our action, we simply state our intended action in the body of the
 request. In the case of eAPI, we will specify a 
 method
  key with a 
 runCmds
  value for
 our intention.",NA
The eAPI preparation,"The eAPI agent on the Arista device is disabled by default, so we will need to enable
 it on the device before we can use it:
 arista1(config)#management api http-commands
 arista1(config-mgmt-api-http-cmds)#no shut
 arista1(config-mgmt-api-http-cmds)#protocol https port 443
 arista1(config-mgmt-api-http-cmds)#no protocol http
 arista1(config-mgmt-api-http-cmds)#vrf management
 As you can see, we have turned off the HTTP server and are using HTTPS as the sole
 transport instead. Starting from a few EOS versions ago, the management interfaces,
 by default, reside in a VRF called 
 management.
  In my topology, I am accessing the
 device via the management interface; therefore, I have specified the VRF for eAPI
 management. You can check that API management state via the ""show management
 api http-commands"" command:
 arista1#sh management api http-commands
 Enabled: Yes
 HTTPS server: running, set to use port 443
 HTTP server: shutdown, set to use port 80
 Local HTTP server: shutdown, no authentication, set to use port 8080
 Unix Socket server: shutdown, no authentication
 VRF: management
 Hits: 64
 Last hit: 33 seconds ago
 Bytes in: 8250
 Bytes out: 29862
 Requests: 23
 Commands: 42
 Duration: 7.086 seconds
 SSL Profile: none
 QoS DSCP: 0
  User Requests Bytes in Bytes out Last hit
 ----------- -------------- -------------- --------------- ------------
 --
  admin 23 8250 29862 33 seconds ago
 URLs
 -----------------------------------------
 Management1 : https://192.168.199.158:443
 arista1#",NA
eAPI examples,"We can then write a simple program called 
 eapi_1.py
  to look at the response text:
       #!/usr/bin/python2
       from __future__ import print_function
       from jsonrpclib import Server
       import ssl
       ssl._create_default_https_context =
 ssl._create_unverified_context
       switch =
 Server(""https://admin:arista@192.168.199.158/command-api"")
       response = switch.runCmds( 1, [ ""show version"" ] )
       print('Serial Number: ' + response[0]['serialNumber'])
 Note that, since this is Python 2, in the script, I used the 
 from
 __future__ import print_function
  to make future migration
 easier. The 
 ssl
 -related lines are for Python version > 2.7.9. For more
 information, please see 
 https:/
 ​
 /
 ​
 www.
 ​
 python.
 ​
 org/
 ​
 dev/
 ​
 peps/
 ​
 pep-
 0476/
 ​
 .
 This is the response I received from the previous 
 runCms()
  method:
     [{u'memTotal': 3978148, u'internalVersion': u'4.16.6M-
     3205780.4166M', u'serialNumber': u'<omitted>',
 u'systemMacAddress':
     u'<omitted>', u'bootupTimestamp': 1465964219.71, u'memFree':
     277832, u'version': u'4.16.6M', u'modelName': u'DCS-7050QX-32-F',
     u'isIntlVersion': False, u'internalBuildId': u'373dbd3c-60a7-4736-
    8d9e-bf5e7d207689', u'hardwareRevision': u'00.00', u'architecture':
    u'i386'}]
 As you can see, the result is a list containing one dictionary item. If we need to grab
 the serial number, we can simply reference the item number and the key:
      print('Serial Number: ' + response[0]['serialNumber'])",NA
The Arista Pyeapi library,"The Python client Pyeapi (
 http:/
 ​
 /
 ​
 pyeapi.
 ​
 readthedocs.
 ​
 io/
 ​
 en/
 ​
 master/
 ​
 index.
 ​
 html
 )
 library is a native Python library wrapper around eAPI. It provides a set of bindings
 to configure Arista EOS nodes. Why do we need Pyeapi when we already have eAPI?
 Picking between Pyeapi versus eAPI is mostly a judgment call if you are in a Python
 environment. 
 However, if you are in a non-Python environment, eAPI is probably the way to go.
 From our examples, you can see that the only requirement of eAPI is a JSON-RPC
 capable client. Thus, it is compatible with most programming languages. When I first
 started out in the field, Perl was the dominant language for scripting and network
 automation. There are still many enterprises that rely on Perl scripts as their primary
 automation tool. If you're in a situation where the company has already invested a
 ton of resources and the code base is in another language than Python, eAPI with
 JSON-RPC would be a good bet.
 However, for those of us who prefer to code in Python, a native 
 Python
  library
 means a more natural feeling in writing our code. It certainly makes extending a
 Python program to support the EOS node easier. It also makes keeping up with the
 latest changes in Python easier. For example, we can use Python 3 with Pyeapi!",NA
Pyeapi installation,"Installation is straightforward with pip:
 $ sudo pip install pyeapi
 $ sudo pip3 install pyeapi
 Note that pip will also install the netaddr library as it is part of the
 stated requirements 
 (http:/
 ​
 /
 ​
 pyeapi.
 ​
 readthedocs.
 ​
 io/
 ​
 en/
 ​
 master/
 requirements.
 ​
 html) for Pyeapi.
 By default, the Pyeapi client will look for an INI style hidden (with a period in front)
 file called 
 eapi.conf
  in your home directory. You can override this behavior by
 specifying the 
 eapi.conf
  file path, but it is generally a good idea to separate your
 connection credential and lock it down from the script itself. You can check out the
 Arista Pyeapi documentation (
 http:/
 ​
 /
 ​
 pyeapi.
 ​
 readthedocs.
 ​
 io/
 ​
 en/
 ​
 master/
 configfile.
 ​
 html#configfile
 ) for the fields contained in the file. Here is the file I am
 using in the lab:
 cat ~/.eapi.conf
 [connection:Arista1]
 host: 192.168.199.158
 username: admin
 password: arista
 transport: https
 The first line, 
 [connection:Arista1]
 , contains the name that we will use in our
 Pyeapi connection; the rest of the fields should be pretty self-explanatory. You can
 lock down the file to be read-only for the user using this file:
 $ chmod 400 ~/.eapi.conf
 $ ls -l ~/.eapi.conf
 -r-------- 1 echou echou 94 Jan 27 18:15 /home/echou/.eapi.conf",NA
Pyeapi examples,"Now, we are ready to take a look around the usage. Let's start by connecting to the
 EOS node by creating an object in the interactive Python shell:
 Python 3.5.2 (default, Nov 17 2016, 17:05:23)
 [GCC 5.4.0 20160609] on linux
 Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
 >>> import pyeapi
 >>> arista1 = pyeapi.connect_to('Arista1')
 We can execute show commands to the node and receive the output:
 >>> import pprint
 >>> pprint.pprint(arista1.enable('show hostname'))
 [{'command': 'show hostname',
  'encoding': 'json',
  'result': {'fqdn': 'arista1', 'hostname': 'arista1'}}]
 The configuration field can be either a single command or a list of commands using
 the 
 config()
  method:
 >>> arista1.config('hostname arista1-new')
 [{}]
 >>> pprint.pprint(arista1.enable('show hostname'))
 [{'command': 'show hostname',
  'encoding': 'json',
  'result': {'fqdn': 'arista1-new', 'hostname': 'arista1-new'}}]
 >>> arista1.config(['interface ethernet 1/3', 'description my_link'])
 [{}, {}]
 Note that command abbreviation (
 show run
  versus 
 show running-config
 ) and
 some extensions will not work:
 >>> pprint.pprint(arista1.enable('show run'))
 Traceback (most recent call last):
 ...
  File ""/usr/local/lib/python3.5/dist-packages/pyeapi/eapilib.py"", line
 396, in send
  raise CommandError(code, msg, command_error=err, output=out)
 pyeapi.eapilib.CommandError: Error [1002]: CLI command 2 of 2 'show
 run' failed: invalid command [incomplete token (at token 1: 'run')]
 >>>
 >>> pprint.pprint(arista1.enable('show running-config interface
 ethernet 1/3'))
 Traceback (most recent call last):
 ...
 pyeapi.eapilib.CommandError: Error [1002]: CLI command 2 of 2 'show",NA
Vendor-neutral libraries,"There are several excellent efforts of vendor-neutral libraries such as Netmiko
 (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 ktbyers/
 ​
 netmiko
 ) and NAPALM (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 napalm-
 ​
 automation/
 ​
 napalm
 ). Because these libraries do not come natively from the
 device vendor, they are sometimes a step slower to support the latest platform or
 features. However, because the libraries are vendor-neutral, if you do not like vendor
 lock-in for your tools, then these libraries are a good choice. Another benefit of using
 these libraries is the fact that they are normally open source, so you can contribute
 back upstream for new features and bug fixes.",NA
Summary,"In this chapter, we looked at various ways to communicate and manage network
 devices from Cisco, Juniper, and Arista. We looked at both direct communication
 with the likes of NETCONF and REST, as well as using vendor-provided libraries
 such as PyEZ and Pyeapi. These are different layers of abstractions, meant to provide
 a way to programmatically manage your network devices without human
 intervention.
 In 
 Chapter 7
 , 
 The Python Automation Framework 
 –
  Ansible Basics
 , we will take a look at
 a higher level of vendor-neutral abstraction framework called 
 Ansible
 . Ansible is an
 open source, general purpose automation tool written in Python. It can be used to
 automate servers, network devices, load balancers, and much more. Of course, for our
 purpose, we will focus on using this automation framework for network devices.",NA
7,NA,NA
The Python Automation,NA,NA
Framework – Ansible Basics,"The previous two chapters incrementally introduced different ways to interact with
 network devices. In 
 Chapter 5
 , 
 Low-Level Network Device Interactions
 , we discussed
 Pexpect and Paramiko libraries that manage an interactive session to control the
 interactions. In 
 Chapter 6
 , 
 APIs and Intent-Driven Networking
 , we started to think of
 our network in terms of API and intent. We looked at various APIs that contain
 a well-defined command structure and provide a structured way of getting feedback
 from the device. As we moved from 
 Chapter 5
 , 
 Low-Level Network Device Interactions
 ,
 to 
 Chapter 6
 , 
 APIs and Intent-Driven Networking
 , we began to think about our intent
 for the network and gradually expressed our network in terms of code. 
 Let's expand upon the idea of translating our intention into network requirements. If
 you have worked on network designs, chances are the most challenging part of the
 process is not the different pieces of network equipment, but rather qualifying and
 translating business requirements into the actual network design. Your network
 design needs to solve business problems. For example, you might be working within
 a larger infrastructure team that needs to accommodate a thriving online e-commerce
 site that experiences slow site response times during peak hours.",NA
A more declarative framework,"You woke up one morning in a cold sweat from a nightmare you had about a
 potential network security breach. You realized that your network contains valuable
 digital assets that should be protected. You have been doing your job as a network
 administrator, so it is pretty secure, but you want to put more security measures
 around your network devices just to be sure.",NA
A quick Ansible example,"As with other automation tools, Ansible started out by managing servers before
 expanding its ability to manage networking equipment. For the most part, the
 modules and what Ansible refers to as the playbook are similar between server
 modules and network modules with subtle differences. In this chapter, we will look at
 a server task example first and draw comparisons later on with network modules.",NA
The control node installation,"First, let's clarify the terminology we will use in the context of Ansible. We will refer
 to the virtual machine with Ansible installed as the control machine, and the
 machines being managed as the target machines or managed nodes. Ansible can be
 installed on most of the Unix systems, with the only dependency of Python 2.6 or 2.7.
 Currently, the Windows operating system is not officially supported as the control
 machine. Windows hosts can still be managed by Ansible, as they are just not
 supported as the control machine.
 As Windows 10 starts to adopt the Windows Subsystem for Linux,
 Ansible might soon be ready to run on Windows as well. For more
 information, please check the Ansible documentation for Windows
 (
 https:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 2.
 ​
 4/
 ​
 intro_
 ​
 windows.
 ​
 html
 ). 
 On the managed node requirements, you may notice some documentation
 mentioning that Python 2.4 or later is a requirement. This is true for managing target
 nodes with operating systems such as Linux, but obviously not all network
 equipment supports Python. We will see how this requirement is bypassed for
 networking modules by local execution on the control node.
 For Windows, Ansible modules are implemented in PowerShell.
 Windows modules in the core and extra repository live in a
 Windows/subdirectory if you would like to take a look. 
 We will be installing Ansible on our Ubuntu virtual machine. For instructions on
 installation on other operating systems, check out the installation documentation
 (
 http:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 intro_
 ​
 installation.
 ​
 html
 ). In the following
 code block, you will see the steps for installing the software packages:
 $ sudo apt-get install software-properties-common
 $ sudo apt-add-repository ppa:ansible/ansible
 $ sudo apt-get update
 $ sudo apt-get install ansible
 We can also use 
 pip
  to install Ansible: 
 pip install ansible
 . My
 personal preference is to use the operating system's package
 management system, such as Apt on Ubuntu. 
 We can now do a quick verification as follows:
 $ ansible --version",NA
Running different versions of Ansible from,NA,NA
source,"You can run Ansible from a source code checkout (we will look at Git as a version
 control mechanism in 
 Chapter 10
 , 
 Working with Git
 ): 
 $ git clone https://github.com/ansible/ansible.git --recursive
 $ cd ansible/
 $ source ./hacking/env-setup
 ...
 Setting up Ansible to run out of checkout...
 $ ansible --version
 ansible 2.7.0.dev0 (devel cde3a03b32) last updated 2018/07/11 08:39:39
 (GMT -700)
   config file = /etc/ansible/ansible.cfg
 ...
 To run different versions, we can simply use 
 git checkout
  for the different branch
 or tag and perform the environment setup again:
 $ git branch -a
 $ git tag --list
 $ git checkout v2.5.6
 ...
 HEAD is now at 0c985fe... New release v2.5.6
 $ source ./hacking/env-setup
 $ ansible --version
 ansible 2.5.6 (detached HEAD 0c985fee8a) last updated 2018/07/11
 08:48:20 (GMT -700)
   config file = /etc/ansible/ansible.cfg",NA
Lab setup Lab topology ,"In this chapter and in 
 Chapter 8
 , 
 The Python Automation Framework 
 –
  Beyond Basics
 ,
 our lab will have an Ubuntu 16.04 control node machine with Ansible installed. This
 control machine will have reachability for the management network for our VIRL
 devices, which consist of IOSv and NX-OSv devices. We will also have a separate
 Ubuntu VM for our playbook example when the target machine is a host:",NA
Your first Ansible playbook,"Our first playbook will be used between the control node and a remote Ubuntu host.
 We will take the following steps:
 Make sure the control node can use key-based authorization.
 1.
 Create an inventory file.
 2.
 Create a playbook.
 3.
 Execute and test it.
 4.",NA
The public key authorization,"The first thing to do is copy your SSH public key from your control machine to the
 target machine. A full public key infrastructure tutorial is outside the scope of this
 book, but here is a quick walkthrough on the control node:
 $ ssh-keygen -t rsa <<<< generates public-private key pair on the host
 machine if you have not done so already
 $ cat ~/.ssh/id_rsa.pub <<<< copy the content of the output and paste
 it to the ~/.ssh/authorized_keys file on the target host
 You can read more about PKI at 
 https:/
 ​
 /
 ​
 en.
 ​
 wikipedia.
 ​
 org/
 ​
 wiki/
 Public_
 ​
 key_
 ​
 infrastructure
 .
 Because we are using key-based authentication, we can turn off password-based
 authentication on the remote node and be more secure. You will now be able to 
 ssh
 from the control node to the remote node using the private key without being
 prompted for a password.
 Can you automate the initial public key copying? It is possible, but
 is highly dependent on your use case, regulation, and environment.
 It is comparable to the initial console setup for network gears to
 establish initial IP reachability. Do you automate this? Why or why
 not?",NA
The inventory file,"We do not need Ansible if we have no remote target to manage, right? Everything
 starts with the fact that we need to perform some task on a remote host. In Ansible,
 the way we specify the potential remote target is with an inventory file. We can have
 this inventory file as the 
 /etc/ansible/hosts
  file or use the 
 -i
  option to specify
 the file during playbook runtime. Personally, I prefer to have this file in the same
 directory where my playbook is and use the 
 -i
  option.
 Technically, this file can be named anything you like as long as it is
 in a valid format. However, the convention is to name this file
 hosts
 . You can potentially save yourself and your colleagues some
 headaches in the future by following this convention.
 The inventory file is a simple, plaintext INI-style (
 https:/
 ​
 /
 ​
 en.
 ​
 wikipedia.
 ​
 org/
 ​
 wiki/
 INI_
 ​
 file
 ) file that states your target. By default, the target can either be a DNS FQDN
 or an IP address:
 $ cat hosts
 192.168.199.170
 We can now use the command-line option to test Ansible and the 
 hosts
  file:
 $ ansible -i hosts 192.168.199.170 -
 m ping
 192.168.199.170 | SUCCESS => {
  ""changed"": false,
  ""ping"": ""pong""
 }
 By default, Ansible assumes that the same user executing the
 playbook exists on the remote host. For example, I am executing the
 playbook as 
 echou
  locally; the same user also exists on my remote
 host. If you want to execute as a different user, you can use the 
 -u
 option when executing, that is, 
 -u REMOTE_USER
 .
 The previous line in the example reads in the host file as the inventory file and
 executes the 
 ping
  module on the host called 
 192.168.199.170
 . Ping (
 http:/
 ​
 /
 ​
 docs.
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 ping_
 ​
 module.
 ​
 html
 ) is a trivial test module that connects to the
 remote host, verifies a usable Python installation, and returns the output 
 pong
  upon
 success.",NA
Our first playbook,"Playbooks are Ansible's blueprint to describe what you would like to do to the hosts
 using modules. This is where we will be spending the majority of our time as
 operators when working with Ansible. If you are building a tree house, the playbook
 will be your manual, the modules will be your tools, while the inventory will be the
 components that you will be working on when using the tools.
 The playbook is designed to be human readable, and is in YAML format. We will
 look at the common syntax used in the Ansible architecture section. For now, our
 focus is to run an example playbook to get the look and feel of Ansible.
 Originally, YAML was said to mean Yet Another Markup Language,
 but now, 
 http:/
 ​
 /
 ​
 yaml.
 ​
 org/
 ​
  has repurposed the acronym to be
 YAML ain't markup language.
 Let's look at this simple 6-line playbook, 
 df_playbook.yml
 :
 ---
 - hosts: 192.168.199.170
   tasks:
     - name: check disk usage
       shell: df > df_temp.txt",NA
The advantages of Ansible,"There are many infrastructure automation frameworks besides Ansible
 —
 namely
 Chef, Puppet, and SaltStack. Each framework offers its own unique features and
 models; there is no one right framework that fits all the organizations. In this section,
 I would like to list some of the advantages of Ansible over other frameworks and why
 I think this is a good tool for network automation.
 I am listing the advantages of Ansible without comparing them to other frameworks.
 Other frameworks might adopt some of the same philosophy or certain aspects of
 Ansible, but rarely do they contain all of the features that I will be mentioning. I
 believe it is the combination of all the following features and philosophy that makes
 Ansible ideal for network automation.",NA
Agentless,"Unlike some of its peers, Ansible does not require a strict master-client model. No
 software or agent needs to be installed on the client that communicates back to the
 server. Outside of the Python interpreter, which many platforms have by default,
 there is no additional software needed.",NA
Idempotent,"According to Wikipedia, idempotence is the property of certain operations in
 mathematics and computer science that can be applied multiple times without
 changing the result beyond the initial application (
 https:/
 ​
 /
 ​
 en.
 ​
 wikipedia.
 ​
 org/
 ​
 wiki/
 Idempotence
 ). In more common terms, it means that running the same procedure 
 over and over again does not change the system after the first time. Ansible aims to be
 idempotent, which is good for network operations that require a certain order of
 operations.
 The advantage of idempotence is best compared to the Pexpect and Paramiko scripts
 that we have written. Remember that these scripts were written to push out
 commands as if an engineer was sitting at the terminal. If you were to execute the
 script 10 times, the script will make changes 10 times. If we write the same task via
 the Ansible playbook, the existing device configuration will be checked first, and the
 playbook will only execute if the changes do not exist. If we execute the playbook 10
 times, the change will only be applied during the first run, with the next 9 runs
 suppressing the configuration change.",NA
Simple and extensible,"Ansible is written in Python and uses YAML for the playbook language, both of
 which are considered relatively easy to learn. Remember the Cisco IOS syntax? This is
 a domain-specific language that is only applicable when you are managing Cisco IOS
 devices or other similarly structured equipment; it is not a general purpose language
 beyond its limited scope. Luckily, unlike some other automation tools, there is no
 extra domain-specific language or DSL to learn for Ansible because YAML and
 Python are both widely used as general purpose languages.
 As you can see from the previous example, even if you have not seen YAML before, it
 is easy to accurately guess what the playbook is trying to do. Ansible also uses Jinja2
 as a template engine, which is a common tool used by Python web frameworks such
 as Django and Flask, so the knowledge is transferable.
 I cannot stress enough the extensibility of Ansible. As illustrated by the preceding
 example, Ansible starts out with automating server (primarily Linux) workloads in
 mind. It then branches out to manage Windows machines with PowerShell. As more
 and more people in the industry started to adapt Ansible, the network became a topic
 that started to get more attention. The right people and team were hired at Ansible,
 network professionals started to get involved, and customers started to demand
 vendors for support. Starting with Ansible 2.0, network automation has become a
 first-class citizen alongside server management. The ecosystem is alive and well, with
 continuous improvement in each of the releases.
 Just like the Python community, the Ansible community is friendly, and the attitude
 is inclusive of new members and ideas. I have first-hand experience of being a noob
 and trying to make sense of contribution procedures and wishing to write modules to
 be merged upstream. I can testify to the fact that I felt welcomed and respected for
 my opinions at all times.
 The simplicity and extensibility really speak well for future proofing. The technology
 world is evolving fast, and we are constantly trying to adapt to it. Wouldn't it be great
 to learn a technology once and continue to use it, regardless of the latest trend?
 Obviously, nobody has a crystal ball to accurately predict the future, but Ansible's
 track record speaks well for future technology adaptation.",NA
Network vendor support,"Let's face it, we don't live in a vacuum. There is a running joke in the industry that the
 OSI layer should include a layer 8 (money) and 9 (politics). Every day, we need to
 work with network equipment made by various vendors. 
 Take API integration as an example. We saw the difference between the Pexpect and
 API approach in previous chapters. API clearly has an upper hand in terms of
 network automation. However, the API interface does not come cheap. Each vendor
 needs to invest time, money, and engineering resources to make the integration
 happen. The willingness for the vendor to support a technology matters greatly in our
 world. Luckily, all the major vendors support Ansible, as clearly indicated by the ever
 increasingly available network modules (
 http:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 list_
 of_
 ​
 network_
 ​
 modules.
 ​
 html
 ).
 Why do vendors support Ansible more than other automation tools? Being agentless
 certainly helps, since having SSH as the only dependency greatly lowers the bar of
 entry. Engineers who have been on the vendor side know that the feature request
 process is usually months long and many hurdles have to be jumped through. Any
 time a new feature is added, it means more time spent on regression testing,
 compatibility checking, integration reviews, and many more. Lowering the bar of
 entry is usually the first step in getting vendor support.
 The fact that Ansible is based on Python, a language liked by many networking
 professionals, is another great propeller for vendor support. For vendors such as
 Juniper and Arista who already made investments in PyEZ and Pyeapi, they can
 easily leverage the existing Python modules and quickly integrate their features into
 Ansible. As you will see in 
 Chapter 8
 , 
 The Python Automation Framework 
 –
  Beyond
 Basics
 , we can use our existing Python knowledge to easily write our own modules.
 Ansible already had a large number of community-driven modules before it focused
 on networking. The contribution process is somewhat baked and established, or as
 baked as an open source project can be. The core Ansible team is familiar with
 working with the community for submission and contribution.",NA
The Ansible architecture Ansible playbook,"The Ansible architecture consists of playbooks, plays, and tasks. Take a look
 at 
 df_playbook.yml
  that we used previously:
 The whole file is called a playbook, which contains one or more plays. Each play can
 consist of one or more tasks. In our simple example, we only have one play, which
 contains a single task. In this section, we will take a look at the following:
 YAML
 : This format is extensively used in Ansible to express playbooks and
 variables.
 Inventory
 : The inventory is where you can specify and group hosts in your
 infrastructure. You can also optionally specify host and group variables in
 the inventory file.",NA
YAML,"YAML is the syntax used for Ansible playbooks and some other files. The official
 YAML documentation contains the full specifications of the syntax. Here is a compact
 version as it pertains to the most common usage for Ansible:
 A YAML file starts with three dashes (
 ---
 )
 Whitespace indentation is used to denote structures when they are lined
 up, just like Python
 Comments begin with the hash (
 #
 ) sign
 List members are denoted by a leading hyphen (
 -
 ), with one member per
 line
 Lists can also be denoted via square brackets (
 []
 ), with elements separated
 by a comma (
 ,
 )
 Dictionaries are denoted by key: value pairs, with a colon for separation
 Dictionaries can be denoted by curly braces, with elements separated by
 a comma (
 ,
 )
 Strings can be unquoted, but can also be enclosed in double or single
 quotes",NA
Inventories,"By default, Ansible looks at the 
 /etc/ansible/hosts
  file for hosts specified in your
 playbook. As mentioned previously, I find it more expressive to specify the host file
 via the 
 -i
  option. This is what we have been doing up to this point. To expand on our
 previous example, we can write our inventory host file as follows:
 [ubuntu]
 192.168.199.170
 [nexus]
 192.168.199.148
 192.168.199.149
 [nexus:vars]
 username=cisco
 password=cisco
 [nexus_by_name]
 switch1 ansible_host=192.168.199.148
 switch2 ansible_host=192.168.199.149",NA
Variables,"We discussed variables a bit in the previous section. Because our managed nodes are
 not exactly alike, we need to accommodate the differences via variables. Variable
 names should be letters, numbers, and underscores, and should always start with a
 letter. Variables are commonly defined in three locations:
 The playbook
 The inventory file
 Separate files to be included in files and roles
 Let's look at an example of defining variables in a playbook, 
 cisco_1.yml
 :
 ---
 - name: Configure SNMP Contact
 hosts: ""nexus""
 gather_facts: false
 connection: local
 vars:
 cli:
 host: ""{{ inventory_hostname }}""
 username: cisco
 password: cisco
 transport: cli
 tasks:
 - name: configure snmp contact
 nxos_snmp_contact:
 contact: TEST_1
 state: present
 provider: ""{{ cli }}""
 register: output
 - name: show output
 debug:
 var: output
 You can see the 
 cli
  variable declared under the 
 vars
  section, which is being used in
 the task of 
 nxos_snmp_contact
 .",NA
Templates with Jinja2,"In the previous section, we used variables with the Jinja2 syntax of 
 {{ variable }}
 .
 While you can do a lot of complex things in Jinja2, luckily, we only need some of the
 basic things to get started.
 Jinja2 (
 http:/
 ​
 /
 ​
 jinja.
 ​
 pocoo.
 ​
 org/
 ​
 ) is a full-featured, powerful
 template engine that originated in the Python community. It is
 widely used in Python web frameworks such as Django and Flask.
 For now, it is enough to just keep in mind that Ansible utilizes Jinja2 as the template
 engine. We will revisit the topics of Jinja2 filters, tests, and lookups as the situations
 call for them. You can find more information on the Ansible Jinja2 template here:
 http:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 playbooks_
 ​
 templating.
 ​
 html
 .",NA
Ansible networking modules,"Ansible was originally made for managing nodes with full operating systems such as
 Linux and Windows before it was extended to support network equipment. You may
 have already noticed the subtle differences in playbooks that we have used so far for
 network devices, such as the lines of 
 gather_facts: false
  and 
 connection:
 local
 ; we will take a closer look at the differences in the following sections.",NA
Local connections and facts,"Ansible modules are Python code that's executed on the remote host by default.
 Because of the fact that most network equipment does not expose Python directly, or
 they simply do not contain Python, we are almost always executing the playbook
 locally. This means that the playbook is interpreted locally first and commands or
 configurations are pushed out later on as needed.",NA
Provider arguments,"As we have seen from 
 Chapter 5
 , 
 Low-Level Network Device Interactions,
  and 
 Chapter
 6
 , 
 APIs and Intent-Driven Networking
 , network equipment can be connected via both
 SSH or API, depending on the platform and software release. All core networking
 modules implement a 
 provider
  argument, which is a collection of arguments used
 to define how to connect to the network device. Some modules only support 
 cli
 while some support other values, for example, Arista EAPI and Cisco NXAPI. This is
 where Ansible's ""let the vendor shine"" philosophy is demonstrated. The module will
 have documentation on which transport method they support.
 Starting with Ansible 2.5, the recommended way to specify the transport method is
 by using the 
 connection
  variable. You will start to see the provider parameter being
 gradually phased out from future Ansible releases. Using the 
 ios_command
  module
 as an example, 
 https:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 latest/
 ​
 modules/
 ​
 ios_
 ​
 command_
 module.
 ​
 html#ios-
 ​
 command-
 ​
 module
 , the provider parameter still works, but is being
 labeled as deprecated. We will see an example of this later in this chapter. 
 Some of the basic arguments supported by the 
 provider
  transport are as follows:
 host
 : This defines the remote host
 port
 : This defines the port to connect to
 username
 : This is the username to be authenticated",NA
The Ansible Cisco example,"Cisco's support in Ansible is categorized by the operating systems IOS, IOS-XR, and
 NX-OS. We have already seen a number of NX-OS examples, so in this section let's try
 to manage IOS-based devices.
 Our host file will consist of two hosts, 
 R1
  and 
 R2
 :
 [ios_devices]
 R1 ansible_host=192.168.24.250
 R2 ansible_host=192.168.24.251
 [ios_devices:vars]
 username=cisco
 password=cisco
 Our playbook, 
 cisco_5.yml
 , will use the 
 ios_command
  module to execute arbitrary
 show commands
 :
     ---
     - name: IOS Show Commands
       hosts: ""ios_devices""
       gather_facts: false
       connection: local",NA
Ansible 2.5 connection example,"We have briefly talked about the addition of network connection changes in Ansible
 playbooks, starting with version 2.5. Along with the changes, Ansible also released a
 network best practices document, 
 https:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 latest/
 network/
 ​
 user_
 ​
 guide/
 ​
 network_
 ​
 best_
 ​
 practices_
 ​
 2.
 ​
 5.
 ​
 html
 . Let's build an example
 based on the best practices guide. For our topology, we will reuse the topology in
 Chapter 5
 , 
 Low-Level Network Device Interactions
 , with two IOSv devices. Since there
 are multiple files involved in this example, the files are grouped into a subdirectory
 named 
 ansible_2-5_example
 . 
 Our inventory file is reduced to the group and the name of the hosts: 
 $ cat hosts
 [ios-devices]
 iosv-1
 iosv-2
 We have created a 
 host_vars
  directory with two files. Each corresponds to the name
 specified in the inventory file: 
 $ ls -a host_vars/
 . .. iosv-1 iosv-2
 The variable file for the hosts contains what was previously included in the CLI
 variable. The additional variable of 
 ansible_connection
  specifies 
 network_cli
  as
 the transport:
 $ cat host_vars/iosv-1
 ---
 ansible_host: 172.16.1.20
 ansible_user: cisco
 ansible_ssh_pass: cisco
 ansible_connection: network_cli
 ansible_network_os: ios
 ansbile_become: yes
 ansible_become_method: enable
 ansible_become_pass: cisco
 $ cat host_vars/iosv-2
 ---
 ansible_host: 172.16.1.21
 ansible_user: cisco
 ansible_ssh_pass: cisco
 ansible_connection: network_cli
 ansible_network_os: ios",NA
The Ansible Juniper example,"The Ansible Juniper module requires the Juniper PyEZ package and NETCONF. If
 you have been following the API example in 
 Chapter 6
 , 
 APIs and Intent-Driven
 Networking
 , you are good to go. If not, refer back to that section for installation
 instructions as well as some test script to make sure PyEZ works. The Python package
 called 
 jxmlease
  is also required:
 $ sudo pip install jxmlease
 In the host file, we will specify the device and connection variables:
 [junos_devices]
 J1 ansible_host=192.168.24.252
 [junos_devices:vars]
 username=juniper
 password=juniper!
 In our Juniper playbook, we will use the 
 junos_facts
  module to gather basic facts
 for the device. This module is equivalent to the setup module and will come in handy
 if we need to take action depending on the returned value. Note the different value of
 transport and port in the example here:
     ---
     - name: Get Juniper Device Facts
       hosts: ""junos_devices""
       gather_facts: false",NA
The Ansible Arista example,"The final playbook example we will look at will be the Arista command module. At
 this point, we are quite familiar with our playbook syntax and structure. The Arista
 device can be configured to use transport using 
 cli
  or 
 eapi
 , so, in this example, we
 will use 
 cli
 .
 This is the host file:
 [eos_devices]
 A1 ansible_host=192.168.199.158
 The playbook is also similar to what we have seen previously:
     ---
  - name: EOS Show Commands
  hosts: ""eos_devices""
  gather_facts: false
  connection: local
  vars:
  cli:
  host: ""{{ ansible_host }}""
  username: ""arista""
  password: ""arista""
  authorize: true
  transport: cli
  tasks:",NA
Summary,"In this chapter, we took a grand tour of the open source automation framework
 Ansible. Unlike Pexpect-based and API-driven network automation scripts, Ansible
 provides a higher layer of abstraction called the playbook to automate our network
 devices.
 Ansible was originally constructed to manage servers and was later extended to
 network devices; therefore we took a look at a server example. Then, we compared
 and contrasted the differences when it came to network management playbooks.
 Later, we looked at the example playbooks for Cisco IOS, Juniper JUNOS, and Arista
 EOS devices. We also looked at the best practices recommended by Ansible if you are
 using Ansible version 2.5 and later. 
 In 
 Chapter 8
 , 
 The Python Automation Framework 
 –
  Beyond Basics
 , we will leverage the
 knowledge we gained in this chapter and start to look at some of the more advanced
 features of Ansible.",NA
8,NA,NA
The Python Automation,NA,NA
Framework – Beyond Basics,"In this chapter, we will further build on the knowledge we have gained from the
 previous chapters and dive deeper into the more advanced topics of Ansible. Many
 books have been written about Ansible, and there is more to Ansible than we can
 cover in two chapters. The goal here is to introduce the majority of the features and
 functions of Ansible that I believe you will need as a network engineer and shorten
 the learning curve as much as possible.
 It is important to point out that if you were not clear on some of the points made in
 Chapter 7
 , 
 The Python Automation Framework 
 –
  Ansible Basics
 , now is a good time to go
 back and review them as they are a prerequisite for this chapter.
 In this chapter, we will look into the following topics:
 Ansible conditionals
 Ansible loops
 Templates
 Group and host variables
 The Ansible Vault
 Ansible roles
 Writing your own module
 We have a lot of ground to cover, so let's get started!",NA
Ansible conditionals,"Ansible conditionals are similar to conditional statements in programming
 languages. In Ansible, it uses conditional keywords to only run a task when the
 condition is met. In many cases, the execution of a play or task may depend on the
 value of a fact, variable, or the previous task result. For example, if you have a play to
 upgrading router images, you want to include a step to make sure the new router
 image is on the device before you move on to the next play of rebooting the router.
 In this section, we will discuss the 
 when
  clause, which is supported for all modules, as
 well as unique conditional states that are supported in Ansible networking command
 modules. Some of the conditions are as follows:
 Equal to (
 eq
 )
 Not equal to (
 neq
 )
 Greater than (
 gt
 )
 Greater than or equal to (
 ge
 )
 Less than (
 lt
 )
 Less than or equal to (
 le
 )
 Contains",NA
The when clause,"The 
 when
  clause is useful when you need to check the output of a variable or a play
 execution result and act accordingly. We saw a quick example of the 
 when
  clause in
 Chapter 7
 , 
 The Python Automation Framework 
 –
  Ansible Basic
 s, when we looked at the
 Ansible 2.5 best practices structure. If you recall, the task only ran when the network
 operating system of the device was the Cisco IOS. Let's look at another example of its
 use in 
 chapter8_1.yml
 :
     ---
     - name: IOS Command Output
       hosts: ""iosv-devices""
       gather_facts: false
       connection: local
       vars:
         cli:
           host: ""{{ ansible_host }}""
           username: ""{{ username }}""
           password: ""{{ password }}""
           transport: cli",NA
Ansible network facts,"Prior to 2.5, Ansible networking shipped with a number of network-specific fact
 modules. The network fact modules exist, but the naming and usage was different
 between vendors. Starting with version 2.5, Ansible started to standardize its network
 fact module usage. The Ansible network fact modules gather information from the
 system and store the results in facts prefixed with 
 ansible_net_
 . The data collected
 by these modules is documented in the 
 return values
  in the module documentation.
 This is a pretty big milestone for Ansible networking modules, as it does a lot of the
 heavy lifting for you to abstract the fact-gathering process by default.
 Let's use the same structure we saw in 
 Chapter 7
 , 
 The Python Automation Framework 
 –
 Ansible Basics
 , Ansible 2.5 best practices, but expand upon it to see how
 the 
 ios_facts
  module was used to gather facts. As a review, our inventory file
 contains two iOS hosts with the host variables residing in the 
 host_vars
  directory: 
 $ cat hosts
 [ios-devices]
 iosv-1
 iosv-2
 $ cat host_vars/iosv-1
 ---
 ansible_host: 172.16.1.20
 ansible_user: cisco
 ansible_ssh_pass: cisco
 ansible_connection: network_cli
 ansible_network_os: ios
 ansbile_become: yes
 ansible_become_method: enable
 ansible_become_pass: cisco
 Our playbook will have three tasks. The first task will use the 
 ios_facts
  module to
 gather facts for both of our network devices. The second task will display certain facts
 gathered and stored for each of the two devices. You will see that the facts we
 displayed were the default 
 ansible_net
  facts, as opposed to a registered variable
 from the first task. The third task will display all the facts we collected for the 
 iosv-1
 host:
 $ cat my_playbook.yml
 ---
 - name: Chapter 5 Ansible 2.5 network facts
   connection: network_cli
   gather_facts: false
   hosts: all",NA
Network module conditional,"Let's take a look at another network device conditional example by using the
 comparison keyword we saw at the beginning of this chapter. We can take advantage
 of the fact that both IOSv and Arista EOS provide the outputs in JSON format for the
 show
  commands. For example, we can check the status of the interface:
     arista1#sh interfaces ethernet 1/3 | json
     {
      ""interfaces"": {
      ""Ethernet1/3"": {
      ""interfaceStatistics"": {",NA
Ansible loops,"Ansible provides a number of loops in the playbook, such as standard loops, looping
 over files, subelements, do-until, and many more. In this section, we will look at two
 of the most commonly used loop forms: standard loops and looping over hash values.",NA
Standard loops,"Standard loops in playbooks are often used to easily perform similar tasks multiple
 times. The syntax for standard loops is very easy: the 
 {{ item }}
  variable is the
 placeholder looping over the 
 with_items
  list. For example, take a look at the
 following section in the 
 chapter8_4.yml
  playbook:
       tasks:
         - name: echo loop items
           command: echo {{ item }}
           with_items: ['r1', 'r2', 'r3', 'r4', 'r5']
 It will loop over the five list items with the same 
 echo
  command:
 TASK [echo loop items]
 *********************************************************
 changed: [192.168.199.185] => (item=r1)
 changed: [192.168.199.185] => (item=r2)
 changed: [192.168.199.185] => (item=r3)
 changed: [192.168.199.185] => (item=r4)
 changed: [192.168.199.185] => (item=r5)",NA
Looping over dictionaries,"Looping over a simple list is nice. However, we often have an entity with more than
 one attribute associated with it. If you think about the 
 vlan
  example in the last
 section, each 
 vlan
  would have several unique attributes to it, such as the 
 vlan
 description, the gateway IP address, and possibly others. Oftentimes, we can use a
 dictionary to represent the entity to incorporate multiple attributes to it.",NA
Templates,"For as long as I can remember, working as a network engineer, I have always used a
 kind of network template. In my experience, many of the network devices have
 sections of the network configuration that are identical, especially if these devices
 serve the same role in the network.
 Most of the time, when we need to provision a new device, we use the same
 configuration in the form of a template, replace the necessary fields, and copy the file
 over to the new device. With Ansible, you can automate all of the work by using the
 template module (
 http:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 template_
 ​
 module.
 ​
 html
 ).",NA
The Jinja2 template,"Let's also modify the playbook accordingly. In 
 chapter8_8.yml
 , we will make the
 following changes:
 Change the source file to 
 nxos.j2
 1.
 Change the destination file to be a variable
 2.
 Provide the variable values as a dictionary that we will substitute in the
 3.
 template:
     ---
     - name: Template Looping
       hosts: localhost
       vars:
         nexus_devices: {
           ""nx-osv-1"": {""hostname"": ""nx-osv-1"", ""username"": ""cisco"",
     ""password"": ""cisco""}
         }
       tasks:
         - name: create router configuration files
           template:
             src=./nxos.j2
             dest=./{{ item.key }}.conf
           with_dict: ""{{ nexus_devices }}""
 After running the playbook, you will find the destination file called 
 nx-osv-1.conf
 with the values filled in and ready to be used:
 $ cat nx-osv-1.conf",NA
Jinja2 loops,"We can also loop through a list as well as a dictionary in Jinja2. We will use both as
 loops in 
 nxos.j2
 :
     {% for vlan_num in item.value.vlans %}
     vlan {{ vlan_num }}
     {% endfor %}
     {% for vlan_interface in item.value.vlan_interfaces %}
     interface {{ vlan_interface.int_num }}
       ip address {{ vlan_interface.ip }}/24
     {% endfor %}
 Provide the additional list and dictionary variables in the 
 chapter8_8.yml
 playbook:
    vars:
      nexus_devices: {
        ""nx-osv-1"": {
        ""hostname"": ""nx-osv-1"",
        ""username"": ""cisco"",
        ""password"": ""cisco"",
        ""vlans"": [100, 200, 300],
        ""vlan_interfaces"": [
           {""int_num"": ""100"", ""ip"": ""192.168.10.1""},
           {""int_num"": ""200"", ""ip"": ""192.168.20.1""},
           {""int_num"": ""300"", ""ip"": ""192.168.30.1""}
         ]
        }
      }
 Run the playbook, and you will see the configuration for both 
 vlan
  and
 vlan_interfaces
  filled in on the router config.",NA
The Jinja2 conditional,"Jinja2 also supports an 
 if
  conditional check. Let's add this field in for turning on the
 netflow feature for certain devices. We will add the following to the 
 nxos.j2
 template:
     {% if item.value.netflow_enable %}
     feature netflow
     {% endif %}
 We will list out the difference in the playbook:
     vars:
       nexus_devices: {
       <skip>
              ""netflow_enable"": True
       <skip>
      }
 The last step we will undertake is to make 
 nxos.j2
  more scalable by placing the
 vlan
  interface section inside of a 
 true-false
  conditional check. In the real world,
 more often than not, we will have multiple devices with knowledge of the 
 vlan
 information, but only one device as the gateway for client hosts:
     {% if item.value.l3_vlan_interfaces %}
     {% for vlan_interface in item.value.vlan_interfaces %}
     interface {{ vlan_interface.int_num }}
      ip address {{ vlan_interface.ip }}/24
     {% endfor %}
     {% endif %}
 We will also add a second device, called 
 nx-osv-2
 , in the playbook:
      vars:
        nexus_devices: {
        <skip>
          ""nx-osv-2"": {
            ""hostname"": ""nx-osv-2"",
            ""username"": ""cisco"",
            ""password"": ""cisco"",
            ""vlans"": [100, 200, 300],
            ""l3_vlan_interfaces"": False,
            ""netflow_enable"": False
          }
         <skip>
      }",NA
Group and host variables,"Note that, in the previous playbook, 
 chapter8_8.yml
 , we have repeated ourselves
 in the username and password variables for the two devices under the
 nexus_devices
  variable:
     vars:
       nexus_devices: {
         ""nx-osv-1"": {
           ""hostname"": ""nx-osv-1"",
           ""username"": ""cisco"",
           ""password"": ""cisco"",",NA
Group variables,"By default, Ansible will look for group variables in the same directory as the
 playbook called 
 group_vars
  for variables that can be applied to the group. By
 default, it will look for the filename that matches the group name in the inventory file.
 For example, if we have a group called 
 [nexus-devices]
  in the inventory file, we
 can have a file under 
 group_vars
  named 
 nexus-devices
  to house all the variables
 that can be applied to the group.
 We can also use a special file named 
 all
  to include variables applied to all the
 groups.
 We will utilize this feature for our username and password variables. First, we will
 create the 
 group_vars
  directory:
 $ mkdir group_vars
 Then, we can create a YAML file called 
 all
  to include the username and password:
 $ cat group_vars/all
 ---
 username: cisco
 password: cisco",NA
Host variables,"We can further separate out the host variables in the same format as the group
 variables. This was how we were able to apply the variables in the Ansible 2.5
 playbook examples in 
 Chapter 7
 , 
 The Python Automation Framework 
 –
  Ansible
 Basics
 , and earlier in this chapter: 
 $ mkdir host_vars
 In our case, we execute the commands on the localhost, and so the file under
 host_vars
  should be named accordingly, such as 
 host_vars/localhost
 . In our
 host_vars/localhost
  file, we can also keep the variables declared in 
 group_vars
 :
 $ cat host_vars/localhost
 ---
 ""nexus_devices"":
   ""nx-osv-1"":
     ""hostname"": ""nx-osv-1""
     ""username"": ""{{ username }}""
     ""password"": ""{{ password }}""
     ""vlans"": [100, 200, 300]
     ""l3_vlan_interfaces"": True
     ""vlan_interfaces"": [
         {""int_num"": ""100"", ""ip"": ""192.168.10.1""},
         {""int_num"": ""200"", ""ip"": ""192.168.20.1""},
         {""int_num"": ""300"", ""ip"": ""192.168.30.1""}
      ]
     ""netflow_enable"": True",NA
The Ansible Vault,"As you can see from the previous section, in most cases, the Ansible variable provides
 sensitive information such as a username and password. It would be a good idea to
 put some security measures around the variables so that we can safeguard against
 them. The Ansible Vault (
 https:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 2.
 ​
 5/
 ​
 user_
 ​
 guide/
 vault.
 ​
 html
 ) provides encryption for files so they appear in plaintext.",NA
The Ansible include and roles,"The best way to handle complex tasks is to break them down into smaller pieces. Of
 course, this approach is common in both Python and network engineering. In Python,
 we break complicated code into functions, classes, modules, and packages. In
 networking, we also break large networks into sections such as racks, rows, clusters,
 and datacenters. In Ansible, we can use 
 roles
  and 
 includes
  to segment and
 organize a large playbook into multiple files. Breaking up a large Ansible playbook
 simplifies the structure as each of the files focuses on fewer tasks. It also allows the
 sections of the playbook to be reused.",NA
The Ansible include statement,"As the playbook grows in size, it will eventually become obvious that many of the
 tasks and plays can be shared across different playbooks. The Ansible 
 include
 statement is similar to many Linux configuration files that just tell the machine to
 extend the file the same way as if the file was directly written in. We can use an
 include
  statement for both playbooks and tasks. Here, we will look at a simple
 example of extending our task.
 Let's assume that we want to show outputs for two different playbooks. We can make
 a separate YAML file called 
 show_output.yml
  as an additional task:
     ---
     - name: show output
         debug:
           var: output
 Then, we can reuse this task in multiple playbooks, such as in 
 chapter8_11_1.yml
 ,
 which looks largely identical to the last playbook with the exception of registering the
 output and the include statement at the end:
     ---
     - name: Ansible Group and Host Varibles
       hosts: localhost
       tasks:
         - name: create router configuration files
           template:
             src=./nxos.j2
             dest=./{{ item.key }}.conf
           with_dict: ""{{ nexus_devices }}""",NA
Ansible roles,"Ansible roles separate the logical function with a physical host to fit your network
 better. For example, you can construct roles such as spines, leafs, core, as well as
 Cisco, Juniper, and Arista. The same physical host can belong to multiple roles; for
 example, a device can belong to both Juniper and the core. This flexibility allows us to
 perform operations, such as upgrade all Juniper devices, without worrying about the
 device's location in the layer of the network.
 Ansible roles can automatically load certain variables, tasks, and handlers based on a
 known file infrastructure. The key is that this is a known file structure that we
 automatically include. In fact, you can think of roles as pre-made 
 include
  statements
 by Ansible.
 The Ansible playbook role documentation (
 http:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 playbooks_
 ​
 roles.
 ​
 html#roles
 ) describes a list of role directories that we can
 configure. We do not need to use all of them. In our example, we will only modify the
 tasks and the vars
  folders. However, it is good to know all of the available
 options in the Ansible role directory structure.",NA
Writing your own custom module,"By now, you may get the feeling that network management in Ansible is largely
 dependent on finding the right module for your task. There is certainly a lot of truth
 in that logic. Modules provide a way to abstract the interaction between the managed
 host and the control machine; they allow us to focus on the logic of our operations.
 Up to this point, we have seen the major vendors providing a wide range of modules
 for Cisco, Juniper, and Arista.",NA
The first custom module,"Writing a custom module does not need to be complicated; in fact, it doesn't even
 need to be in Python. But since we are already familiar with Python, we will use
 Python for our custom modules. We are assuming that the module is what we will be
 using ourselves and our team without submitting back to Ansible, therefore we will
 ignore some of the documentation and formatting for the time being. 
 If you are interested in developing modules that can be submitted
 upstream to Ansible, please consult the developing modules guide
 from Ansible (
 https:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 latest/
 ​
 dev_
 guide/
 ​
 developing_
 ​
 modules.
 ​
 html
 ). 
 By default, if we create a folder named 
 library
  in the same directory as the
 playbook, Ansible will include the directory in the module search path. Therefore, we
 can put our custom module in the directory and we will be able to use it in our
 playbook. The requirement for the custom module is very simple: all the module
 needs is to return a JSON output to the playbook.
 Recall that in 
 Chapter 6
 , 
 APIs and Intent-Driven Networking
 , we used the following
 NXAPI Python script to communicate to the NX-OS device:
     import requests
     import json
     url='http://172.16.1.142/ins'
     switchuser='cisco'
     switchpassword='cisco'",NA
The second custom module,"Building upon the last module, let's utilize the common module boilerplate from
 Ansible that's stated in the module development documentation (
 http:/
 ​
 /
 ​
 docs.
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 dev_
 ​
 guide/
 ​
 developing_
 ​
 modules_
 ​
 general.
 ​
 html
 ). We will
 modify the last custom module and create 
 custom_module_2.py
  to ingest inputs
 from the playbook.
 First, we will import the boilerplate code from 
 ansible.module_utils.basic
 :
     from ansible.module_utils.basic import AnsibleModule
     if __name__ == '__main__':
         main()",NA
Summary,"In this chapter, we covered a lot of ground. Building from our previous knowledge of
 Ansible, we expanded into more advanced topics such as conditionals, loops, and
 templates. We looked at how to make our playbook more scalable with host variables,
 group variables, include statements, and roles. We also looked at how to secure our
 playbook with the Ansible Vault. Finally, we used Python to make our own custom
 modules.
 Ansible is a very flexible Python framework that can be used for network automation.
 It provides another abstraction layer separated from the likes of the Pexpect and API-
 based scripts. It is declarative in nature in that it is more expressive in terms of
 matching our intent. Depending on your needs and network environment, it might be
 the ideal framework that you can use to save time and energy.",NA
9,NA,NA
AWS Cloud Networking,"Cloud computing is one of the major trends in computing today. Public cloud
 providers have transformed the high-tech industry and what it means to launch a
 service from scratch. We no longer need to build our own infrastructure; we can pay
 the public cloud providers to rent a portion of their resources for our infrastructure
 needs. Nowadays, walking around any technology conferences or meetups, we will
 be hard-pressed to find a person who has not learned about, used, or built services
 based in the cloud. Cloud computing is here, and we better get used to working with
 it.
 There are several service models of cloud computing, roughly divided into 
 Software-
 as-a-Service
  (
 SaaS
 ) (
 https://en.wikipedia.org/wiki/Software_as_a_service
 ),
 Platform-as-a-Service
  (
 PaaS
 ) (
 https:/
 ​
 /
 ​
 en.
 ​
 wikipedia.
 ​
 org/
 ​
 wiki/
 ​
 Cloud_
 computing#Platform_
 ​
 as_
 ​
 a_
 ​
 service_
 ​
 (PaaS)
 ), and 
 Infrastructure-as-a-Service
  (
 IaaS
 )
 (
 https:/
 ​
 /
 ​
 en.
 ​
 wikipedia.
 ​
 org/
 ​
 wiki/
 ​
 Infrastructure_
 ​
 as_
 ​
 a_
 ​
 service
 ). Each service
 model offers a different level of abstraction from the user's perspective. For us,
 networking is part of the Infrastructure-as-a-Service offering and the focus of this
 chapter.
 Amazon Web Services
  (
 AWS
 —
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 ) is the first company to 
 offer IaaS public cloud services and the clear leader in the space by market share in
 2018. If we define the term 
 Software Defined Networking
  (
 SDN
 ) as a group of
 software services working together to create network constructs 
 –
  IP addresses, access
 lists, Network Address Translation, routers 
 –
  we can make the argument that AWS is
 the world's largest implementation of SDN. They utilize their massive scale of the
 global network, data centers, and hosts to offer an amazing array of networking
 services.",NA
AWS setup,"If you do not already have an AWS account and wish to follow along with these
 examples, please log on to 
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
  and sign up. The process is
 pretty straightforward and simple; you will need a credit card and some form of
 verification. AWS offers a number of services in a free tier (
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 free/
 ​
 ), where you can use some of the most popular services for free up to a certain
 level.",NA
AWS CLI and Python SDK AWS IAM,"We can also manage the AWS services via the command-line interface. The AWS CLI
 is a Python package that can be installed via PIP (
 https:/
 ​
 /
 ​
 docs.
 ​
 aws.
 ​
 amazon.
 ​
 com/
 cli/
 ​
 latest/
 ​
 userguide/
 ​
 installing.
 ​
 html
 ). Let's install it on our Ubuntu host: 
 $ sudo pip3 install awscli
 $ aws --version
 aws-cli/1.15.59 Python/3.5.2 Linux/4.15.0-30-generic botocore/1.10.58
 Once the AWS CLI is installed, for easier and more secure access, we will create a
 user and configure AWS CLI with the user credentials. Let's go back to the AWS
 console and select 
 IAM
  for user and access management:",NA
AWS network overview AWS regions ,"When we discuss AWS services, we need to start at the top with regions and
 availability zones. They have big implications for all of our services. At the time of
 writing this book, AWS listed 18 Regions, 55 
 Availability Zones
  (
 AZ
 ), and one local
 region around the world. In the words of AWS Global Infrastructure, (
 https:/
 ​
 /
 ​
 aws.
 amazon.
 ​
 com/
 ​
 about-
 ​
 aws/
 ​
 global-
 ​
 infrastructure/
 ​
 ): 
 ""The AWS Cloud infrastructure is built around Regions and Availability Zones
 (AZs). AWS Regions provide multiple, physically separated and isolated
 Availability Zones which are connected with low latency, high throughput, and
 highly redundant networking.""
 Some of the services AWS offer are global, but most of the services are region-based.
 What this means for us is that we should build our infrastructure in a region that is
 closest to our intended users. This will reduce the latency of the service to our
 customer. If our users are in the United States east coast, we should pick 
 us-east-1
 (N. Virginia) or 
 us-east-2
  (Ohio) as our region if the service is regional-based:",NA
Virtual private cloud,"Amazon Virtual Private Cloud (Amazon VPC)
  enables customers to launch AWS
 resources into a virtual network dedicated to the customer's account. It is truly a
 customizable network that allows you to define your own IP address range, add and
 delete subnets, create routes, add VPN gateways, associate security policies, connect
 EC2 instances to your own datacenter, and much more. In the early days when VPC
 was not available, all EC2 instances in the AZ were on a single, flat network that was
 shared among all customers. How comfortable would the customer be with putting
 their information in the cloud? Not very, I'd imagine. Between the launch of EC2 in
 2007 until the launch of VPC in 2009, VPC functions was one of the most requested
 features of AWS. 
 The packets leaving your EC2 host in a VPC are intercepted by the
 Hypervisor. The Hypervisor will check them with a mapping
 service which understands our VPC construct. The packets leaving
 your EC2 hosts are encapsulated with the AWS real servers' source
 and destination addresses. The encapsulation and mapping service
 allows for the flexibility of VPC, but also some of the limitations
 (multicast, sniffing) of VPC. This is, after all, a virtual network.",NA
Route tables and route targets,"Routing is one of the most important topics in network engineering. It is worth
 looking at it more closely. We already saw that we had an implicit router and the
 main routing table when we created the VPC. From the last example, we created an
 internet gateway, a custom routing table with a default route pointing to the internet
 gateway, and associated the custom routing table with a subnet.
 The concept of the route target is where VPC is a bit different than traditional
 networking. In summary: 
 Each VPC has an implicit router
 Each VPC has the main routing table with the local route populated
 You can create custom-routing tables
 Each subnet can follow a custom-routing table or the default main routing
 table
 The route table route target can be an internet gateway, NAT gateway, VPC
 peers, and so on
 We can use Boto3 to look at the custom route tables and association with the subnets: 
 $ cat Chapter9_2_query_route_tables.py
 #!/usr/bin/env python3
 import json, boto3
 region = 'us-east-1'
 vpc_name = 'mastering_python_networking_demo'
 ec2 = boto3.resource('ec2', region_name=region)
 client = boto3.client('ec2')
 response = client.describe_route_tables()
 print(json.dumps(response['RouteTables'][0], sort_keys=True,
 indent=4))",NA
Automation with CloudFormation VPC for US-West-1,"AWS CloudFomation (
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 cloudformation/
 ​
 ), is one way in
 which we can use a text file to describe and launch the resource that we need. We can
 use CloudFormation to provision another VPC in the 
 us-west-1
  region: 
 The CloudFormation template can be in YAML or JSON; we will use YAML for our 
 first template for provisioning:
 $ cat Chapter9_3_cloud_formation.yml
 AWSTemplateFormatVersion: '2010-09-09'
 Description: Create VPC in us-west-1
 Resources:
   myVPC:
     Type: AWS::EC2::VPC
     Properties:",NA
Security groups and the network ACL VPC security,"AWS 
 Security Groups
  and the 
 Access Control
  list can be found under the 
 Security
 section of your VPC:",NA
Elastic IP,"Elastic IP
  (
 EIP
 ) is a way to use a public IPv4 address that's reachable from the
 internet. It can be dynamically assigned to an EC2 instance, network interface, or
 other resources. A few characteristics of Elastic IP are as follows: 
 The Elastic IP is associated with the account and is region-specific. For
 example, the EIP in 
 us-east-1
  can only be associated with resources in
 us-east-1
 .
 You can disassociate an Elastic IP from a resource, and re-associate it with a
 different resource. This flexibility can sometimes be used to ensure high
 availability. For example, you can migrate from a smaller EC2 instance to a
 larger EC2 instance by reassigning the same IP address from the small EC2
 instance to the larger one.
 There is a small hourly charge associated with Elastic IP.",NA
NAT Gateway,"To allow the hosts in our EC2 public subnet to be accessed from the internet, we can
 allocate an Elastic IP and associate it with the network interface of the EC2 host.
 However, at the time of writing this book, there is a limit of five Elastic IPs per EC2-
 VPC (
 https:/
 ​
 /
 ​
 docs.
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 AmazonVPC/
 ​
 latest/
 ​
 UserGuide/
 ​
 VPC_
 ​
 Appendix_
 Limits.
 ​
 html#vpc-
 ​
 limits-
 ​
 eips
 ). Sometimes, it would be nice to allow the host in a
 private subnet outbound access when needed without creating a permanent one-to-
 one mapping between the Elastic IP and the EC2 host.",NA
Direct Connect and VPN,"Up to this point, our VPC is a self-contained network that resides in the AWS
 network. It is flexible and functional, but to access the resources inside of the VPC, we
 will need to access them with their internet-facing services such as SSH and HTTPS. 
 In this section, we will look at the two ways AWS allow us to connect to the VPC
 from our private network: IPSec VPN Gateway and Direct Connect.",NA
VPN Gateway,"The first way to connect our on-premise network to VPC is with traditional IPSec
 VPN connections. We will need a publicly accessible device that can establish VPN
 connections to AWS's VPN device. The customer gateway needs to support route-
 based IPSec VPNs where the VPN connection is treated as a connection that a routing
 protocol can run over the virtual link. Currently, AWS recommends using BGP to
 exchange routes.",NA
Direct Connect,"The IPSec VPN connection we saw is an easy way to provide connectivity for on-
 premise equipment to the AWS cloud resources. However, it suffers the same faults
 that IPSec over the internet always does: it is unreliable, and we have very little
 control over it. There is very little performance monitoring and no 
 Service-Level
 Agreement
  (
 SLA
 ) until the connection reaches a part of the internet that we can
 control.",NA
Network scaling services,"In this section, we will take a look at some of the network services AWS offers. Many
 of the services do not have a direct network implication, such as DNS and content 
 distribution network. They are relevant in our discussion due to their close
 relationship with the network and application's performance.",NA
Elastic Load Balancing Elastic Load Balancer Comparison (Source:  ),"Elastic Load Balancing
  (
 ELB
 ) allows incoming traffic from the internet to be
 automatically distributed across multiple EC2 instances. Just like load balancers in the
 physical world, this allows us to have better redundancy and fault tolerance while
 reducing the per-server load. ELB comes in two flavors: application and network load
 balancing. 
 The application load balancer handles web traffic via HTTP and HTTPS; the network
 load balancer operates on a TCP level. If your application runs on HTTP or HTTPS, it
 is generally a good idea to go with the application load balancer. Otherwise, using the
 network load balancer is a good bet. 
 A detailed comparison of the application and network load balancer can be found
 at 
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 elasticloadbalancing/
 ​
 details/
 ​
 :
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 elasticloadbalancing/
 ​
 details/
 ​",NA
Route53 DNS service,"We all know what domain name services are; Route53 is AWS's DNS service. Route53
 is a full-service domain registrar where you can purchase and manage domains
 directly from AWS. Regarding network services, DNS allows a way to load balance
 between geographic regions by service domain names in a round-robin fashion
 between regions. 
 We need the following items before we can use DNS for load balancing: 
 An Elastic Load Balancer in each of the intended load balance regions.
 A registered domain name. We do not need Route53 as the domain
 registrar.
 Route53 is the DNS service for the domain.
 We can then use the Route 53 latency-based routing policy with health-check in an
 active-active environment between the two Elastic Load Balancers.",NA
CloudFront CDN services,"CloudFront is Amazon's 
 Content Delivery Network
  (
 CDN
 ) that reduces the latency
 for content delivery by physically serving the content closer to the customer. The
 content can be static web page content, videos, applications, APIs, or most recently,
 Lambda functions. CloudFront edge locations include the existing AWS regions, but
 are also in many other locations around the globe. The high-level operation of
 CloudFront is as follows: 
 Users access your website for one or more objects
 DNS routes the request to the Amazon CloudFront edge location closest to
 the user's request
 The CloudFront edge location will either service the content via the cache
 or request the object from the origin
 AWS CloudFront and CDN services in general are typically handled by application
 developers or DevOps engineers. However, it is always good to be aware of their
 operations.",NA
Other AWS network services,"There are lots of other AWS Network Services that we do not have the space to cover.
 Some of the more important ones are listed in this section:
 AWS Transit VPC
  (
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 blogs/
 ​
 aws/
 ​
 aws-
 ​
 solution-
 transit-
 ​
 vpc/
 ​
 ): This is a way to connect multiple virtual private clouds to a
 common VPC that serves as a transit center. This is a relatively new service,
 but it can minimize the connection that you need to set up and manage.
 This can also serve as a tool when you need to share resources between
 separate AWS accounts.
 Amazon GuardDuty
  (
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 guardduty/
 ​
 ): This is a 
 managed threat detection service that continuously monitors for malicious
 or unauthorized behavior to help protect our AWS workloads. It monitors
 API calls or potentially unauthorized deployments.
 AWS WAF 
 (
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 waf/
 ​
 ): This is a web application 
 firewall that helps protect web applications from common exploits. We can
 define customized web security rules to allow or block web traffic.
 AWS Shield
  (
 https:/
 ​
 /
 ​
 aws.
 ​
 amazon.
 ​
 com/
 ​
 shield/
 ​
 ): This is a managed
 Distributed Denial of Service
  (
 DDoS
 ) protection service that safeguards
 applications running on AWS. The protection service is free for all
 customers at the basic level; the advanced version of AWS Shield is a fee-
 based service.",NA
Summary,"In this chapter, we looked at AWS Cloud Networking services. We went over the
 AWS network definitions of Region, Availability Zone, Edge Locations, and Transit
 Center. By understanding the overall AWS network, this gives us a good idea of some
 of the limitations and contains for the other AWS network services. Throughout this
 chapter, we used the AWS CLI, the Python Boto3 library, as well as CloudFormation
 to automate some of the tasks. 
 We covered the AWS virtual private cloud in depth with the configuration of the
 route table and route targets. The example on security groups and network ACL
 controls the security for our VPC. We also looked at Elastic IP and NAT Gateways
 regarding allowing external access.",NA
10,NA,NA
Working with Git,"We have worked on various aspects of network automation with Python, Ansible,
 and many other tools. If you have been following along with the examples, in the first
 nine chapters of the book, we have used over 150 files containing over 5,300 lines of
 code. That's pretty good for network engineers who may have been working
 primarily with the command-line interface! With our new set of scripts and tools, we
 are now ready to go out and conquer our network tasks, right? Well, not so fast, my
 fellow network ninjas. 
 The first task we face with the code files is how to keep them in a location where they
 can be retrieved and used by us and others. Ideally, this location would be the only
 place where the latest version of the file is kept. After the initial release, we might add
 features and fix bugs in the future, so we would like a way to track these changes and
 keep the latest ones available for download. If the new changes do not work, we
 would like to rollback the changes and reflect the differences in the history of the file.
 This would give us a good idea of the evolution of the code files. 
 The second question is the collaboration process between our team members. If we
 work with other network engineers, we will need to work collectively on the files. The
 files can be the Python scripts, Ansible Playbook, Jinja2 templates, INI-style
 configuration files, and many others. The point is any kind of text-based files should
 be tracked with multiple input that everybody in the team should be able to see. 
 The third question is accountability. Once we have a system that allows for multiple
 inputs and changes, we need to mark these changes with an appropriate track record
 to reflect the owner of the change. The track record should also include a brief reason
 for the change so the person reviewing the history can get an understanding of why
 the change was made.",NA
Introduction to Git,"Git was created by Linus Torvalds, the creator of the Linux kernel, in April 2005. With
 his dry wit, he has affectionately called the tool the information manager from hell. In
 an interview with the Linux Foundation, Linus mentioned that he felt source-control
 management was just about the least interesting thing in the computing world
 (
 https:/
 ​
 /
 ​
 www.
 ​
 linuxfoundation.
 ​
 org/
 ​
 blog/
 ​
 10-
 ​
 years-
 ​
 of-
 ​
 git-
 ​
 an-
 ​
 interview-
 ​
 with-
 git-
 ​
 creator-
 ​
 linus-
 ​
 torvalds/
 ​
 ). Nevertheless, he created the tool after a
 disagreement between the Linux kernel developer community and BitKeeper, the
 proprietary system they were using at the time. 
 What does the name Git stand for? In British English slang, a Git is
 an insult denoting an unpleasant, annoying, childish person. With
 his dry humor, Linus said he is an egotistical bastard and that he
 named all of his projects after himself. First Linux, now Git.
 However, some suggested that the name is short for 
 Global
 Information Tracker
  (
 GIT
 ). You can be the judge.",NA
Benefits of Git,"The success of hosting large and distributed open source projects, such as the Linux
 kernel and Python, speaks to the advantages of Git. This is especially significant given
 that Git is a relatively new source-control tool and people do not tend to switch to a
 new tool unless it offers significant advantages over the old tool. Let's look at some of
 the benefits of Git:
 Distributed development
 : Git supports parallel, independent, and
 simultaneous development in private repositories offline. Compare this to
 some other version-control systems that require constant synchronization
 with a central repository; this allows significantly greater flexibility for the
 developers.
 Scale to handle thousands of developers
 : The number of developers
 working on different parts of some of the open source projects is in the
 thousands. Git supports the integration of their work reliably.
 Performance
 : Linus was determined to make sure Git was fast and
 efficient. To save space and transfer time for the sheer volume of updates
 for the Linux kernel code alone, compression and a delta check would be
 needed to make Git fast and efficient.
 Accountability and immutability
 : Git enforces a change log on every
 commit that changes a file so that there is a trail for all the changes and the
 reason behind them. The data objects in Git cannot be modified after they
 were created and placed in the database, making them immutable. This
 further enforces accountability.
 Atomic transactions
 : The integrity of the repository is ensured as the
 different, but related, change is performed either all together or not at all.
 This will ensure the repository is not left in a partially-changed or
 corrupted state.",NA
Git terminology,"Here are some Git terminologies we should be familiar with: 
 Ref
 : The name that begins with 
 refs
  that point to an object.
 Repository
 : A database that contains all of a project's information, files,
 metadata, and history. It contains a collection of 
 ref
  for all the collections
 of objects.
 Branch
 : An active line of development. The most recent commit is the 
 tip
 or the 
 HEAD
  of that branch. A repository can have multiple branches, but
 your 
 working tree
  or 
 working directory
  can only be associated with
 one branch. This is sometimes referred to as the current or 
 checked
 out
  branch.
 Checkout
 : The action of updating all or part of the working tree to a
 particular point.
 Commit
 : A point in time in Git history, or it can mean to store a new
 snapshot into the repository.
 Merge
 : The action to bring the content of another branch into the current
 branch. For example, I am merging the 
 development
  branch with the
 master
  branch.
 Fetch
 : The action of getting the content from a remote repository.
 Pull
 : Fetching and merging a repository.
 Tag
 : A mark in a point in time in a repository that is significant. In 
 Chapter
 7
 , 
 The Python Automation Framework 
 –
  Ansible Basics
 , we saw the tag used to
 specify the release points, 
 v2.5.0a1
 .
 This is not a complete list; please refer to the Git glossary, 
 https:/
 ​
 /
 ​
 git-
 ​
 scm.
 ​
 com/
 docs/
 ​
 gitglossary
 , for more terms and their definitions.",NA
Git and GitHub,"Git and GitHub are not the same thing. Sometimes, for engineers who are new to
 version-control systems, this is confusing. Git is a revision-control system while
 GitHub, 
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 , is a centralized hosting service for Git repositories. 
 Because Git is a decentralized system, GitHub stores a copy of our project's
 repository, just like any other developer. Often, we just designate the GitHub
 repository as the project's central repository and all other developers push and pull
 their changes to and from that repository. 
 GitHub takes this idea of being the centralized repository in a distributed system
 further by using the 
 fork
  and 
 pull requests
  mechanisms. For projects hosted on
 GitHub, encourage developers to 
 fork
  the repository, or make a copy of the
 repository, and work on that copy as their centralized repository. After making
 changes, they can send a 
 pull request
  to the main project, and the project
 maintainers can review the changes and 
 commit
  the changes if they see fit. GitHub
 also adds the web interface to the repositories besides command line; this makes Git
 more user-friendly.",NA
Setting up Git,"So far, we have been using Git to just download files from GitHub. In this section, we
 will go a bit further by setting up Git variables so we can start committing our files. I
 am going to use the same Ubuntu 16.04 host in the example. The installation process
 is well-documented; if you are using a different version of Linux or other operating
 systems, a quick search should land you at the right set of instructions. 
 If you have not done so already, install Git via the 
 apt
  package-management tool: 
 $ sudo apt-get update
 $ sudo apt-get install -y git
 $ git --version
 git version 2.7.4",NA
Gitignore,"From time to time, there are files you do not want Git to check into GitHub or other
 repositories. The easiest way to do this is to create 
 .gitignore
  in the
 repository
  folder; Git will use it to determine which files a directory should ignore
 before you make a commit. This file should be committed into the repository to share
 the ignore rules with other users.",NA
Git usage examples,"Most of the time, when we work with Git, we will use the command line: 
 $ git --help
 usage: git [--version] [--help] [-C <path>] [-c name=value]
            [--exec-path[=<path>]] [--html-path] [--man-path] [--info-
 path]
            [-p | --paginate | --no-pager] [--no-replace-objects] [--
 bare]
            [--git-dir=<path>] [--work-tree=<path>] [--
 namespace=<name>]
            <command> [<args>]
 We will create a 
 repository
  and create a file inside the repository: 
 $ mkdir TestRepo
 $ cd TestRepo/
 $ git init
 Initialized empty Git repository in
 /home/echou/Master_Python_Networking_second_edition/Chapter10/TestRepo
 /.git/
 $ echo ""this is my test file"" > myFile.txt
 When the repository was initialized with Git, a new hidden folder of 
 .git
  was added
 to the directory. It contains all the Git-related files: 
 $ ls -a
 . .. .git myFile.txt
 $ ls .git/
 branches config description HEAD hooks info objects refs",NA
GitHub example GitHub private repository,"In this example, we will use GitHub as the centralized location to synchronize our
 local repository and share with other users. 
 We will create a repository on GitHub. By default, GitHub has a free public
 repository; in my case, I pay a small monthly fee to host private repositories. At the
 time of creation, you can choose to create the license and the 
 .gitignore
  file:",NA
Collaborating with pull requests,"As mentioned, Git supports collaboration between developers for a single project. We
 will take a look at how it is done when the code is hosted on GitHub.",NA
Git with Python,"There are some Python packages that we can use with Git and GitHub. In this section,
 we will take a look at the GitPython and PyGithub libraries.",NA
GitPython,"We can use the GitPython package, 
 https:/
 ​
 /
 ​
 gitpython.
 ​
 readthedocs.
 ​
 io/
 ​
 en/
 ​
 stable/
 index.
 ​
 html
 , to work with our Git repository. We will install the package and use the
 Python shell to construct a 
 Repo
  object. From there, we can list all the commits in the
 repository: 
 $ sudo pip3 install gitpython
 $ python3
 >>> from git import Repo",NA
PyGitHub,"Let's look at using the PyGitHub package, 
 http:/
 ​
 /
 ​
 pygithub.
 ​
 readthedocs.
 ​
 io/
 ​
 en/
 latest/
 ​
 , to interact with GitHub repositories. The package is a wrapper around
 GitHub APIv3, 
 https:/
 ​
 /
 ​
 developer.
 ​
 github.
 ​
 com/
 ​
 v3/
 ​
 : 
 $ sudo pip install pygithub
 $ sudo pip3 install pygithub",NA
Automating configuration backup,"In this example, we will use PyGithub to back up a directory containing our router
 configurations. We have seen how we can retrieve the information from our devices
 with Python or Ansible; we can now check them into GitHub. 
 We have a subdirectory, named 
 config
 , with our router configs in text format: 
 $ ls configs/
 iosv-1 iosv-2
 $ cat configs/iosv-1
 Building configuration...
 Current configuration : 4573 bytes
 !
 ! Last configuration change at 02:50:05 UTC Sat Jun 2 2018 by cisco
 !
 version 15.6
 service timestamps debug datetime msec
 ...",NA
Collaborating with Git,"Git is an awesome collaboration technology, and GitHub is an incredibly effective
 way to develop projects together. GitHub provides a place for anyone in the world
 with internet access to share their thoughts and code for free. We know how to use
 Git and some of the basic collaboration steps using GitHub, but how do we join and
 contribute to a project? Sure, we would like to give back to these open source projects
 that have given us so much, but how do we get started? 
 In this section, we'll look at some of the things to know about software-development
 collaboration using Git and GitHub:
 Start small
 : One of the most important things to understand is the role we
 can play within a team. We might be awesome at network engineering but
 a mediocre Python developer. There are plenty of things we can do that
 don't involve being a highly-skilled developer. Don't be afraid to start
 small, documentation and testing are two good ways to get your foot in the
 door as a contributor. 
 Learn the ecosystem
 : With any project, large or small, there is a set of
 conventions and a culture that has been established. We are all drawn to
 Python for its easy-to-read syntax and beginner-friendly culture; they also
 have a development guide that is centered around that ideology (
 https:/
 ​
 /
 devguide.
 ​
 python.
 ​
 org/
 ​
 ). The Ansible project, on the other hand, also has an
 extensive community guide (
 https:/
 ​
 /
 ​
 docs.
 ​
 ansible.
 ​
 com/
 ​
 ansible/
 ​
 latest/
 community/
 ​
 index.
 ​
 html
 ). It includes the code of conduct, the pull request
 process, how to report bugs, and the release process. Read these guides and
 learn the ecosystem for the project of interest. 
 Make a branch
 : I have made the mistake of forking a project and making a
 pull request for the main branch. The main branch should be left alone for
 the core contributors to make changes to. We should create a separate
 branch for our contribution and allow the branch to be merged at a later
 date.",NA
Summary,"In this chapter, we looked at the version-control system known as Git and its close
 sibling, GitHub. Git was developed by Linus Torvolds in 2005 to help develop the
 Linux kernel and later adopted by other open source projects as the source-control
 system. Git is a fast, distributed, and scalable system. GitHub provides a centralized
 location to host Git repositories on the internet that allow anybody with an internet
 connection to collaborate.
 We looked at how to use Git in the command line, its various operations, and how
 they are applied in GitHub. We also studied two of the popular Python libraries for
 working with Git: GitPython and PyGitHub. We ended the chapter with a
 configuration backup example and notes about project collaboration.",NA
11,NA,NA
"Sockets, IPv4, and Simple",NA,NA
Client/Server Programming,"In this chapter, we will cover the following recipes:
 Printing your machine's name and IPv4 address
 Retrieving a remote machine's IP address
 Converting an IPv4 address to different formats
 Finding a service name, given the port and protocol
 Converting integers to and from host to network byte order
 Setting and getting the default socket timeout
 Handling socket errors gracefully
 Modifying a socket's send/receive buffer size
 Changing a socket to the blocking/non-blocking mode
 Reusing socket addresses
 Printing the current time from the internet time server
 Writing an SNTP client
 Writing a simple TCP echo client/server application
 Writing a simple UDP echo client/server application",NA
Introduction,"This chapter introduces Python's core networking library through some simple
 recipes. Python's socket module has both class-based and instances-based utilities.
 The difference between a class-based and instance-based method is that the former
 doesn't need an instance of a socket object. This is a very intuitive approach. For
 example, in order to print your machine's IP address, you don't need a socket object.
 Instead, you can just call the socket's class-based methods. On the other hand, if you
 need to send some data to a server application, it is more intuitive that you create a
 socket object to perform that explicit operation. The recipes presented in this chapter
 can be categorized into three groups as follows:
 In the first few recipes, the class-based utilities have been used in order to
 extract some useful information about host, network, and any target
 service.
 After that, some more recipes have been presented using the instance-
 based utilities. Some common socket tasks, including manipulating the
 socket timeout, buffer size, and blocking mode has been demonstrated.
 Finally, both class-based and instance-based utilities have been used to
 construct some clients, which perform some practical tasks, for example,
 synchronizing the machine time with an internet server or writing a generic
 client/server script.
 You can use these demonstrated approaches to write your own client/server
 application.",NA
Printing your machine's name and IPv4,NA,NA
address,"Sometimes, you need to quickly discover some information about your machine, for
 example, the hostname, IP address, number of network interfaces, and so on. This is
 very easy to achieve using Python scripts.",NA
Getting ready,"You need to install Python on your machine before you start coding. Python comes
 preinstalled in most of the Linux distributions. For Microsoft Windows operating
 systems, you can download binaries from the Python website: 
 http:/
 ​
 /
 ​
 www.
 ​
 python.
 org/
 ​
 download/
 ​
 .
 Currently, Python 3.x is released in addition to Python 2.x. Many of the current Linux
 distributions and macOS versions are still shipping Python 2 by default. However,
 some ship both of them.
 Download the relevant installer for your operating system and the relevant version
 based on whether your operating system is 32 bit or 64 bit.
 You may consult the documentation of your operating system to check and review
 your Python setup. After installing Python on your machine, you can try opening the
 Python interpreter from the command line by typing python. This will show the
 interpreter prompt, 
 >>>
 , which should be similar to the following output:
 ~$ python
 Python 2.7.12 (default, Nov 19 2016, 06:48:10)
 [GCC 5.4.0 20160609] on linux2
 Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
 >>>",NA
How to do it...,"In the latter versions of Ubuntu since Ubuntu 14.04, Python 3 can be executed by
 typing python3:
 ~$ python3
 Python 3.5.2 (default, Nov 17 2016, 17:05:23)
 [GCC 5.4.0 20160609] on linux
 Type ""help"", ""copyright"", ""credits"" or
 ""license"" for more information.
 >>>",NA
How it works...,"The import socket statement imports one of Python's core networking libraries. Then,
 we use the two utility functions, 
 gethostname()
  and 
 gethostbyname(host_name)
 .
 You can type 
 help(socket.gethostname)
  to see the online help information from
 within the command line. Alternatively, you can type the following address in your
 web browser at 
 http://docs.python.org/3/library/socket.html
 . You can refer to
 the following code:
     gethostname(...)
         gethostname() -> string
         Return the current host name.
     gethostbyname(...)
         gethostbyname(host) -> address
         Return the IP address (a string of the form
         '255.255.255.255') for a host.
 The first function takes no parameter and returns the current or localhost name. The
 second function takes a single 
 hostname
  parameter and returns its IP address.",NA
Retrieving a remote machine's IP address,"Sometimes, you need to translate a machine's hostname into its corresponding IP
 address, for example, a quick domain name lookup. This recipe introduces a simple
 function to do that.",NA
How to do it...,"If you need to know the IP address of a remote machine, you can use a built-in library
 function, 
 gethostbyname()
 . In this case, you need to pass the remote hostname as
 its parameter.",NA
How it works...,"This recipe wraps the 
 gethostbyname()
  method inside a user-defined function
 called 
 get_remote_machine_info()
 . In this recipe, we introduced the notion of
 exception handling. As you can see, we wrapped the main function call inside a 
 try-
 except
  block. This means that, if some error occurs during the execution of this
 function, this error will be dealt with by this 
 try-except
  block.
 For example, let's change the 
 remote_host
  value and replace 
 https:/
 ​
 /
 ​
 www.
 ​
 python.
 org/
 ​
  with something non-existent, for example, 
 www.pytgo.org
 :
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.
     import socket
     def get_remote_machine_info():
         remote_host = 'www.pytgo.org'",NA
Converting an IPv4 address to different,NA,NA
formats,"When you would like to deal with low-level network functions, sometimes, the usual
 string notation of IP addresses are not very useful. They need to be converted to the
 packed 32-bit binary formats.",NA
How to do it...,"The Python 
 socket
  library has utilities to deal with the various IP address formats.
 Here, we will use two of them: 
 inet_aton()
  and 
 inet_ntoa()
 .
 Let us create the 
 convert_ip4_address()
  function, where 
 inet_aton()
  and
 inet_ntoa()
  will be used for the IP address conversion. We will use two sample IP
 addresses, 
 127.0.0.1
  and 
 192.168.0.1
 .
 Listing 1.3 shows 
 ip4_address_conversion
  as follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.
     import socket
     from binascii import hexlify",NA
How it works...,"In this recipe, the two IP addresses have been converted from a string to a 32-bit
 packed format using a 
 for-in
  statement. Additionally, the Python 
 hexlify
  function
 is called from the 
 binascii
  module. This helps to represent the binary data in a
 hexadecimal format.",NA
"Finding a service name, given the port",NA,NA
and protocol,"If you would like to discover network services, it may be helpful to determine what
 network services run on which ports using either the TCP or UDP protocol.",NA
Getting ready,"If you know the port number of a network service, you can find the service name
 using the 
 getservbyport()
  socket class function from the socket library. You can
 optionally give the protocol name when calling this function.",NA
How to do it...,"Let us define a 
 find_service_name()
  function, where the 
 getservbyport()
 socket class function will be called with a few ports, for example, 
 80, 25
 . We can use
 Python's 
 for-in
  loop construct.
 Listing 1.4 shows 
 finding_service_name
  as follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import socket
 def find_service_name():
     protocolname = 'tcp'
     for port in [80, 25]:
         print (""Port: %s => service name: %s"" %(port,
 socket.getservbyport(port, protocolname)))
     print (""Port: %s => service name: %s"" %(53,
 socket.getservbyport(53, 'udp')))
 if __name__ == '__main__':
     find_service_name()
 If you run this script, you will see the following output:
 $ python 11_4_finding_service_name.py
 Port: 80 => service name: http
 Port: 25 => service name: smtp
 Port: 53 => service name: domain
 This indicates that 
 http
 , 
 smtp
 , and 
 domain
  services are running on the ports 
 80
 , 
 25
 ,
 and 
 53
  respectively.",NA
How it works...,"In this recipe, the 
 for-in
  statement is used to iterate over a sequence of variables. So
 for each iteration, we use one IP address to convert them in their packed and
 unpacked format.",NA
Converting integers to and from host to,NA,NA
network byte order,"If you ever need to write a low-level network application, it may be necessary to
 handle the low-level data transmission over the wire between two machines. This
 operation requires some sort of conversion of data from the native host operating
 system to the network format and vice versa. This is because each one has its own
 specific representation of data.",NA
How to do it...,"Python's 
 socket
  library has utilities for converting from a network byte order to host
 byte order and vice versa. You may want to become familiar with them, for example,
 ntohl()
 /
 htonl()
 .
 Let us define the 
 convert_integer()
  function, where the 
 ntohl()
 /
 htonl()
  socket
 class functions are used to convert IP address formats.
 Listing 1.5 shows 
 integer_conversion
  as follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import socket
 def convert_integer():
     data = 1234
     # 32-bit
     print (""Original: %s => Long  host byte order: %s, Network byte
 order: %s"" %(data, socket.ntohl(data), socket.htonl(data)))
     # 16-bit
     print (""Original: %s => Short  host byte order: %s, Network byte
 order: %s"" %(data, socket.ntohs(data), socket.htons(data)))
 if __name__ == '__main__':
     convert_integer()",NA
How it works...,"Here, we take an integer and show how to convert it between network and host byte
 orders. The 
 ntohl()
  socket class function converts from the network byte order to
 host byte order in a long format. Here, 
 n
  represents network and 
 h
  represents host; 
 l
 represents long and 
 s
  represents short, that is, 16-bit.",NA
Setting and getting the default socket,NA,NA
timeout,"Sometimes, you need to manipulate the default values of certain properties of a
 socket
  library, for example, the socket timeout.",NA
How to do it...,"You can make an instance of a 
 socket
  object and call a 
 gettimeout()
  method to get
 the default timeout value and the 
 settimeout()
  method to set a specific timeout
 value. This is very useful in developing custom server applications.
 We first create a 
 socket
  object inside a 
 test_socket_timeout()
  function. Then,
 we can use the 
 getter
 /
 setter
  instance methods to manipulate timeout values.
 Listing 1.6 shows 
 socket_timeout
  as follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import socket
 def test_socket_timeout():",NA
How it works...,"In this code snippet, we have first created a 
 socket
  object by passing the socket
 family and socket type as the first and second arguments of the socket constructor.
 Then, you can get the socket timeout value by calling 
 gettimeout()
  and alter the
 value by calling the 
 settimeout()
  method. The timeout value passed to the
 settimeout()
  method can be in seconds (non-negative float) or 
 None
 . This method
 is used for manipulating the blocking-socket operations. Setting a timeout of 
 None
 disables timeouts on socket operations.",NA
Handling socket errors gracefully,"In any networking application, it is very common that one end is trying to connect,
 but the other party is not responding due to networking media failure or any other
 reason. The Python 
 socket
  library has an elegant method of handing these errors via
 the 
 socket.error
  exceptions. In this recipe, a few examples are presented.",NA
How to do it...,"Let us create a few try-except code blocks and put one potential error type in each
 block. In order to get a user input, the 
 argparse
  module can be used. This module is
 more powerful than simply parsing command-line arguments using 
 sys.argv
 . In the
 try-except blocks, put typical socket operations, for example, create a 
 socket
  object,
 connect to a server, send data, and wait for a reply.
 The following recipe illustrates the concepts in a few lines of code.
 Listing 1.7 shows 
 socket_errors
  as follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import sys
 import socket
 import argparse
 def main():
     # setup argument parsing
     parser = argparse.ArgumentParser(description='Socket Error
 Examples')
     parser.add_argument('--host', action=""store"", dest=""host"",
 required=False)
     parser.add_argument('--port', action=""store"", dest=""port"",
 type=int,
 required=False)
     parser.add_argument('--file', action=""store"", dest=""file"",
 required=False)
     given_args = parser.parse_args()
     host = given_args.host
     port = given_args.port
     filename = given_args.file
     # First try-except block -- create socket
     try:
         s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
     except socket.error as e:
         print (""Error creating socket: %s"" % e)
         sys.exit(1)
     # Second try-except block -- connect to given host/port
     try:
         s.connect((host, port))
     except socket.gaierror as e:
         print (""Address-related error connecting to",NA
How it works...,"In Python, passing command-line arguments to a script and parsing them in the
 script can be done using the 
 argparse
  module. This is available in Python 2.7. For
 earlier versions of Python, this module is available separately in 
 Python Package
 Index
  (
 PyPI
 ). You can install this via 
 easy_install
  or 
 pip
 .
 In this recipe, three arguments are set up
 —
 a hostname, port number, and filename.
 The usage of this script is as follows:
 $ python 11_7_socket_errors.py --host=<HOST>
   --port=<PORT> --file=<FILE>
 In the preceding recipe, msg.encode('utf-8')
 encodes the message into UTF-8, and
 buf.decode('utf-8') decodes the received UTF-8
 format.",NA
Modifying a socket's send/receive buffer,NA,NA
sizes,"The default socket buffer size may not be suitable in many circumstances. In such
 circumstances, you can change the default socket buffer size to a more suitable value.",NA
How to do it...,"Let us manipulate the default socket buffer size using a socket object's 
 setsockopt()
 method.
 First, define two constants: 
 SEND_BUF_SIZE
 /
 RECV_BUF_SIZE
  and then wrap a socket
 instance's call to the 
 setsockopt()
  method in a function. It is also a good idea to
 check the value of the buffer size before modifying it. Note that we need to set up the
 send and receive buffer size separately.
 Listing 1.8 shows how to modify socket send/receive buffer sizes as follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import socket
 SEND_BUF_SIZE = 4096
 RECV_BUF_SIZE = 4096
 def modify_buff_size():
     sock = socket.socket( socket.AF_INET, socket.SOCK_STREAM )
     # Get the size of the socket's send buffer
     bufsize = sock.getsockopt(socket.SOL_SOCKET, socket.SO_SNDBUF)
     print (""Buffer size [Before]:%d"" %bufsize)
     sock.setsockopt(socket.SOL_TCP,
                      socket.TCP_NODELAY, 1)",NA
How it works...,"You can call the 
 getsockopt()
  and 
 setsockopt()
  methods on a socket object to
 retrieve and modify the socket object's properties respectively. The 
 setsockopt()
 method takes three arguments: 
 level
 , 
 optname
 , and 
 value
 . Here, 
 optname
  takes the
 option name and 
 value
  is the corresponding value of that option. For the first
 argument, the needed symbolic constants can be found in the socket module
 (
 SO_*etc.
 ).",NA
Changing a socket to the blocking/non-,NA,NA
blocking mode,"By default, TCP sockets are placed in a blocking mode. This means the control is not
 returned to your program until some specific operation is complete. If you call the
 connect()
  API, the connection blocks your program until the operation is complete.
 On many occasions, you don't want to keep your program waiting forever, either for
 a response from the server or for any error to stop the operation. For example, when
 you write a web browser client that connects to a web server, you should consider a
 stop functionality that can cancel the connection process in the middle of this
 operation. This can be achieved by placing the socket in the non-blocking mode.",NA
How to do it...,"Let us see what options are available under Python. In Python, a socket can be placed
 in the blocking or non-blocking mode. In the non-blocking mode, if any call to API,
 for example, 
 send()
  or 
 recv()
 , encounters any problem, an error will be raised.
 However, in the blocking mode, this will not stop the operation. We can create a
 normal TCP socket and experiment with both the blocking and non-blocking
 operations.
 To manipulate the socket's blocking nature, we should create a socket object first.
 We can then call 
 setblocking(1)
  to set up blocking or 
 setblocking(0)
  to unset
 blocking. Finally, we bind the socket to a specific port and listen for incoming
 connections.
 Listing 1.9 shows how the socket changes to blocking or non-blocking mode as
 follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import socket
 def test_socket_modes():
     s = socket.socket(socket.AF_INET,
                        socket.SOCK_STREAM)
     s.setblocking(1)
     s.settimeout(0.5)
     s.bind((""127.0.0.1"", 0))",NA
How it works...,"In this recipe, we enable blocking on a socket by setting the value 
 1
  in the
 setblocking()
  method. Similarly, you can unset the value 
 0
  in this method to make
 it non-blocking.
 This feature will be reused in some later recipes, where its real purpose will be
 elaborated.",NA
Reusing socket addresses,"You want to run a socket server always on a specific port even after it is closed
 intentionally or unexpectedly. This is useful in some cases where your client program
 always connects to that specific server port. So, you don't need to change the server
 port.",NA
How to do it...,"If you run a Python socket server on a specific port and try to rerun it after closing it
 once, you won't be able to use the same port. It will usually throw an error like the
 following command:
 Traceback (most recent call last):
    
 File ""11_10_reuse_socket_address.py"",
    line 40, in <module>
     
     reuse_socket_addr()
    
 File ""11_10_reuse_socket_address.py"",
    line 25, in reuse_socket_addr
     
     srv.bind( ('', local_port) )
    
 File ""<string>"", line 1, in bind
     
 socket.error: [Errno 98] Address
     already in use
 The remedy to this problem is to enable the socket reuse option, 
 SO_REUSEADDR
 .
 After creating a 
 socket
  object, we can query the state of address reuse, say an old
 state. Then, we call the 
 setsockopt()
  method to alter the value of its address reuse
 state. Then, we follow the usual steps of binding to an address and listening for
 incoming client connections.
 In the preceding example, when you close the Python script with 
 Ctrl
  + 
 C,
  you notice
 an exception:
 ^CTraceback (most recent call last):File ""11_9_socket_modes.py"", line
 20, in <module>
 test_socket_modes()
 File ""11_9_socket_modes.py"", line 17, in test_socket_modes
 s.listen(1)
 KeyboardInterrupt
 This indicates that there was a keyboard interrupt in the execution.
 In this example, we catch the 
 KeyboardInterrupt
  exception so that if you issue 
 Ctrl
 + 
 C
 , then the Python script gets terminated without showing any exception message.
 Listing 1.10 shows how to reuse socket addresses as follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import socket
 import sys",NA
How it works...,"You may run this script from one console window and try to connect to this server
 from another console window by typing 
 telnet localhost 8282
 .
 You will see an output printed in the program window as your telnet connects to it:
 Connected by 127.0.0.1:46584
 Here the host and port will defer based on the telnet instance that you are sending
 this request from.
 After you close the server program, you can rerun it again on the same port.
 However, if you comment out the line that sets the 
 SO_REUSEADDR
 , the server will not
 run for the second time.",NA
Printing the current time from the internet,NA,NA
time server,"Many programs rely on the accurate machine time, such as the 
 make
  command in
 UNIX. Your machine time may be different and need synchronizing with another
 time server in your network.",NA
Getting ready,"In order to synchronize your machine time with one of the internet time servers, you
 can write a Python client for that. For this, 
 ntplib
  will be used. Here, the
 client/server conversation will be done using 
 Network Time Protocol
  (
 NTP
 ). If
 ntplib
  is not installed on your machine, you can get it from 
 PyPI
  with the following
 command using 
 pip
  or 
 easy_install
 :
 $ pip install ntplib
 If 
 pip
  is not installed on your computer, first install it before executing the preceding
 command. In Debian-based Linux distributions such as Ubuntu, this can be installed
 by:
 $ sudo apt install python-pip
 Note that you will need to install 
 pip
  for Python 3 separately if you are running it
 along side Python 2, as typically Python 2 is set as the default version:
 $ sudo apt-get install python3-pip
 Similarly, 
 ntplib
  needs to be installed for 
 python3-pip
  (also called 
 pip3
 )
 separately:
 $ pip3 install ntplib
 It is a good idea to upgrade 
 pip
  to the latest version if you are running an outdated
 version, by issuing the following command:
 $ pip install --upgrade pip
 or:
 $ pip3 install --upgrade pip
 If Python 2 and Python 3 are installed alongside in your computer then use 
 pip3
 .
 I am using the 
 pip
  version 9.0.1, for both Python 2 and Python 3. This is the latest
 version at the time of writing.",NA
How to do it...,"We create an instance of 
 NTPClient
  and then we call the 
 request()
  method on it by
 passing the NTP server address.
 Listing 1.11 shows how to print the current time from the internet time server as
 follows:
     #!/usr/bin/env python
     # This program is optimized for Python 2.7.12
       and Python 3.5.2.
     # It may run on any other version with/without
       modifications.
     import ntplib
     from time import ctime
     def print_time():
         ntp_client = ntplib.NTPClient()
         response = ntp_client.request('pool.ntp.org')
         print (ctime(response.tx_time))
     if __name__ == '__main__':
         print_time()
 In my machine, this recipe shows the following output:
 $ python 11_11_print_machine_time.py
 Fri Jun  2 16:01:35 2017",NA
How it works...,"Here, an NTP client has been created and an NTP request has been sent to one of the
 internet NTP servers, 
 pool.ntp.org
 . The 
 ctime()
  function is used for printing the
 response.",NA
Writing an SNTP client,"Unlike the previous recipe, sometimes, you don't need to get the precise time from
 the NTP server. You can use a simpler version of NTP called simple network time
 protocol.",NA
How to do it...,"Let us create a plain SNTP client without using any third-party library.
 Let us first define two constants: 
 NTP_SERVER
  and 
 TIME1970. NTP_SERVER
  is the
 server address to which our client will connect, and 
 TIME1970
  is the reference time
 on January 1, 1970 (also called 
 Epoch
 ). You may find the value of the Epoch time or
 convert to the Epoch time at 
 http://www.epochconverter.com/
 . The actual client
 creates a UDP socket (
 SOCK_DGRAM
 ) to connect to the server following the UDP
 protocol. The client then needs to send the SNTP protocol data (
 '\x1b' + 47 *
 '\0'
 ) in a packet. Our UDP client sends and receives data using the 
 sendto()
  and
 recvfrom()
  methods.
 When the server returns the time information in a packed array, the client needs a
 specialized 
 struct
  module to unpack the data. The only interesting data is located in
 the 11th element of the array. Finally, we need to subtract the reference value,
 TIME1970
 , from the unpacked value to get the actual current time.
 Listing 1.12 shows how to write an SNTP client as follows:
     #!/usr/bin/env python
     # This program is optimized for Python 2.7.12
       and Python 3.5.2.
     # It may run on any other version with/without
       modifications.
     import socket
     import struct
     import sys
     import time
     NTP_SERVER = ""0.uk.pool.ntp.org""
     TIME1970 = 2208988800
     def sntp_client():
         client = socket.socket( socket.AF_INET,
                             socket.SOCK_DGRAM )
         data = '\x1b' + 47 * '\0'
         client.sendto( data.encode('utf-8'),
                          ( NTP_SERVER, 123 ))
         data, address = client.recvfrom( 1024 )
         if data:
             print ('Response received
                               from:', address)
         t = struct.unpack( '!12I', data )[10]
         t -= TIME1970
         print ('\tTime=%s' % time.ctime(t))
     if __name__ == '__main__':
         sntp_client()",NA
How it works...,"This SNTP client creates a socket connection and sends the protocol data. After
 receiving the response from the NTP server (in this case, 
 0.uk.pool.ntp.org
 ), it
 unpacks the data with 
 struct
 . Finally, it subtracts the reference time, which is
 January 1, 1970, and prints the time using the 
 ctime()
  built-in method in the Python
 time module.",NA
Writing a simple TCP echo client/server,NA,NA
application,"After testing with basic socket APIs in Python, let us create a TCP socket server and
 client now. Here, you will have the chance to utilize your basic knowledge gained in
 the previous recipes.",NA
How to do it...,"In this example, a server will echo whatever it receives from the client. We will use
 the Python 
 argparse
  module to specify the TCP port from a command line. Both the
 server and client script will take this argument.
 First, we create the server. We start by creating a TCP socket object. Then, we set the
 reuse address so that we can run the server as many times as we need. We bind the
 socket to the given port on our local machine. In the listening stage, we make sure we
 listen to multiple clients in a queue using the backlog argument to the 
 listen()
 method. Finally, we wait for the client to be connected and send some data to the
 server. When the data is received, the server echoes back the data to the client.",NA
How it works...,"In order to see the client/server interactions, launch the following server script in one
 console:
 $ python 11_13a_echo_server.py --port=9900
 Starting up echo server  on localhost port 9900
 Waiting to receive message from client
 Now, run the client from another Terminal as follows:
 $ python 11_13b_echo_client.py --port=9900
 Connecting to localhost port 9900
 Sending Test message. This will be echoed
 Received: Test message. Th
 Received: is will be echoe
 Received: d
 Closing connection to the server
 Upon receiving the message from the client, the server will also print something
 similar to the following message:
 Data: Test message. This will be echoed
 sent Test message. This will be echoed
 bytes back to ('127.0.0.1', 42961)
 Waiting to receive message from client",NA
Writing a simple UDP echo client/server,NA,NA
application,"As we have developed a simple TCP server and client in the previous recipe, we will
 now look at how to develop the same with UDP.",NA
How to do it...,"This recipe is similar to the previous one, except this one is with UDP. The method
 recvfrom()
  reads the messages from the socket and returns the data and the client
 address.
 Listing 1.14a shows how to write a simple UDP echo client/server application as
 follows:
 #!/usr/bin/env python
 # This program is optimized for Python 2.7.12
    and Python 3.5.2.
 # It may run on any other version with/without
   modifications.
 import socket
 import sys
 import argparse
 host = 'localhost'
 data_payload = 2048
 def echo_server(port):
     """""" A simple echo server """"""
     # Create a UDP socket
     sock = socket.socket(socket.AF_INET,
                          socket.SOCK_DGRAM)
     # Bind the socket to the port
     server_address = (host, port)
     print (""Starting up echo server
             on %s port %s"" % server_address)
     sock.bind(server_address)
     while True:
         print (""Waiting to receive message
                  from client"")",NA
How it works...,"In order to see the client/server interactions, launch the following server script in one
 console:
 $ python 11_14a_echo_server_udp.py --port=9900
 Starting up echo server on localhost port 9900
 Waiting to receive message from client
 Now, run the client from another terminal as follows:
 $ python 11_14b_echo_client_udp.py --port=9900
 Connecting to localhost port 9900
 Sending Test message. This will be echoed
 received Test message. This will be echoed
 Closing connection to the server
 Upon receiving the message from the client, the server will also print something
 similar to the following message:
 received 33 bytes from ('127.0.0.1', 43542)
 Data: Test message. This will be echoed
 sent 33 bytes back to ('127.0.0.1', 43542)
 Waiting to receive message from client",NA
12,NA,NA
Multiplexing Socket I/O for,NA,NA
Better Performance,"In this chapter, we will cover the following recipes:
 Using ForkingMixIn in your socket server applications
 Using ThreadingMixIn in your socket server applications
 Writing a chat server using select.select
 Multiplexing a web server using select.epoll
 Multiplexing an echo server using Diesel concurrent library",NA
Introduction,"This chapter focuses on improving the socket server performance using a few useful
 techniques. Unlike the previous chapter, here we consider multiple clients that will be
 connected to the server and the communication can be asynchronous. The server does
 not need to process the request from clients in a blocking manner; this can be done
 independently of each other. If one client takes more time to receive or process data,
 the server does not need to wait for that. It can talk to other clients using separate
 threads or processes.",NA
Using ForkingMixIn in your socket server,NA,NA
applications,"You have decided to write an asynchronous Python socket server application. The
 server will not block in processing a client request. So the server needs a mechanism
 to deal with each client independently.
 Python 
 SocketServer
  class comes with two utility classes: 
 ForkingMixIn
  and
 ThreadingMixIn
 . The 
 ForkingMixIn
  class will spawn a new process for each client
 request. This class is discussed in this section. The 
 ThreadingMixIn
  class will be
 discussed in the next section. For more information, you can refer to the relevant
 Python 2 documentation at 
 http://docs.python.org/2/library/socketserver.html
 and Python 3 documentation at
 https://docs.python.org/3/library/socketserver.html
 .",NA
How to do it...,"Let us rewrite our echo server, previously described in 
 Chapter 11
 , 
 Sockets, IPv4, and
 Simple Client/Server Programming
 . We can utilize the subclasses of the 
 SocketServer
 class family. It has ready-made TCP, UDP, and other protocol servers. We can create a
 ForkingServer
  class inherited from 
 TCPServer
  and 
 ForkingMixIn
 . The former
 parent will enable our 
 ForkingServer
  class to do all the necessary server operations
 that we did manually before, such as creating a socket, binding to an address, and
 listening for incoming connections. Our server also needs to inherit from
 ForkingMixIn
  to handle clients asynchronously.",NA
How it works...,"An instance of 
 ForkingServer
  is launched in the main thread, which has been
 daemonized to run in the background. Now, the two clients have started interacting
 with the server.
 If you run the script, it will show the following output:
 $ python 12_1_forking_mixin_socket_server.py
 Server loop running PID: 26479
 PID 26479 Sending echo message to the server :
  ""Hello echo server!""
 Sent: 18 characters, so far...
 Server sending response [current_process_id: data] = [26481: Hello
 echo server!]
 PID 26479 received: b': Hello echo server!'
 First client running
 PID 26479 Sending echo message to the server : ""Hello echo server!""
 Sent: 18 characters, so far...
 Server sending response [current_process_id: data] = [26482: Hello",NA
Using ThreadingMixIn in your socket,NA,NA
server applications,"Perhaps you prefer writing a multi-threaded application over a process-based one
 due to any particular reason, for example, sharing the states of that application across
 threads, avoiding the complexity of inter-process communication, or something else.
 In such a situation, if you want to write an asynchronous network server using
 SocketServer
  library, you will need 
 ThreadingMixIn
 .",NA
Getting ready,"By making a few minor changes to our previous recipe, you can get a working
 version of socket server using 
 ThreadingMixIn
 .",NA
How to do it...,"As seen in the previous socket server based on 
 ForkingMixIn
 , 
 ThreadingMixIn
 socket server will follow the same coding pattern of an echo server except for a few
 things. First, our 
 ThreadedTCPServer
  will inherit from 
 TCPServer
  and
 TheadingMixIn
 . This multi-threaded version will launch a new thread when a client
 connects to it. Some more details can be found at
 http://docs.python.org/2/library/socketserver.html
 .
 The request handler class of our socket server, 
 ForkingServerRequestHandler
 ,
 sends the echo back to the client from a new thread. You can check the thread
 information here. For the sake of simplicity, we put the client code in a function
 instead of a class. The client code creates the client socket and sends the message to
 the server.",NA
How it works...,"This recipe first creates a server thread and launches it in the background. Then it
 launches three test clients to send messages to the server. In response, the server
 echoes back the message to the clients. In the 
 handle()
  method of the server's
 request handler, you can see that we retrieve the current thread information and print
 it. This should be different in each client connection.
 In this client/server conversation, the 
 sendall()
  method has been used to guarantee
 the sending of all data without any loss:
 $ python 12_2_threading_mixin_socket_server.py
 Server loop running on thread: Thread-1
 Client received: b""Thread-2: b'Hello from client 1'""
 Client received: b""Thread-3: b'Hello from client 2'""
 Client received: b""Thread-4: b'Hello from client 3'""",NA
Writing a chat server using select.select,"Launching a separate thread or process per client may not be viable in any larger
 network server application where several hundred or thousand clients are
 concurrently connected to the server. Due to the limited available memory and host
 CPU power, we need a better technique to deal with a large number of clients.
 Fortunately, Python provides the 
 select
  module to overcome this problem.",NA
How to do it...,"We need to write an efficient chat server that can handle several hundred or a large
 number of client connections. We will use the 
 select()
  method from the 
 select
 module that will enable our chat server and client to do any task without blocking a
 send or receive a call all the time.
 Let us design this recipe such that a single script can launch both client and server
 with an additional 
 --name
  argument. Only if 
 --name=server
  is passed from the
 command line, the script will launch the chat server. Any other value passed to the 
 --
 name
  argument, for example, 
 client1
 , 
 client2
 , will launch a chat client. Let's
 specify our chat server port number from the command line using the 
 --port
 argument. For a larger application, it may be preferable to write separate modules for
 the server and client.
 Listing 2.3 shows an example of chat application using 
 select.select
  as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 2
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import select
 import socket
 import sys
 import signal
 import pickle
 import struct
 import argparse
 SERVER_HOST = 'localhost'
 CHAT_SERVER_NAME = 'server'
 # Some utilities
 def send(channel, *args):",NA
How it works...,"At the top of our module, we defined two utility functions: 
 send()
  and 
 receive()
 .
 The chat server and client use these utility functions, which were demonstrated
 earlier. The details of the chat server and client methods were also discussed earlier.",NA
Multiplexing a web server using,NA,NA
select.epoll,"Python's 
 select
  module has a few platform-specific, networking event management
 functions. On a Linux machine, 
 epoll
  is available. This will utilize the operating
 system kernel that will poll network events and let our script know whenever
 something happens. This sounds more efficient than the previously mentioned
 select.select
  approach.",NA
How to do it...,"Let's write a simple web server that can return a single line of text to any connected
 web browser.
 The core idea is during the initialization of this web server, we should make a call to
 select.epoll()
  and register our server's file descriptor for event notifications. In
 the web server's executive code, the socket event is monitored as follows:
 Listing 2.4 Simple web server using select.epoll
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 2
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import socket
 import select
 import argparse
 SERVER_HOST = 'localhost'
 EOL1 = b'\n\n'
 EOL2 = b'\n\r\n'
 SERVER_RESPONSE  = b""""""HTTP/1.1 200 OK\r\nDate: Mon, 1 Apr 2013
 01:01:01 GMT\r\nContent-Type: text/plain\r\nContent-Length: 25\r\n\r\n
 Hello from Epoll Server!""""""
 class EpollServer(object):
     """""" A socket server using Epoll""""""
     def __init__(self, host=SERVER_HOST, port=0):
         self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
         self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR,
 1)
         self.sock.bind((host, port))
         self.sock.listen(1)
         self.sock.setblocking(0)
         self.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY,
 1)
         print (""Started Epoll Server"")
         self.epoll = select.epoll()
         self.epoll.register(self.sock.fileno(), select.EPOLLIN)
     def run(self):
         """"""Executes epoll server operation""""""
         try:
             connections = {}; requests = {}; responses = {}",NA
How it works...,"In our 
 EpollServer
  web server's constructor, a socket server is created and bound to
 a localhost at a given port. The server's socket is set to the non-blocking mode
 (
 setblocking(0)
 ). The 
 TCP_NODELAY
  option is also set so that our server can
 exchange data without buffering (as in the case of an SSH connection). Next, the
 select.epoll()
  instance is created and the socket's file descriptor is passed to that
 instance to help monitoring.
 In the 
 run()
  method of the web server, it starts receiving the socket events. These
 events are denoted as follows:
 EPOLLIN
 : This socket reads events
 EPOLLOUT
 : This socket writes events",NA
Multiplexing an echo server using Diesel,NA,NA
concurrent library,"Sometimes you need to write a large custom networking application that wants to
 avoid repeated server initialization code that creates a socket, binds to an address,
 listens, and handles basic errors. There are numerous Python networking libraries out
 there to help you remove boiler-plate code. Here, we can examine such a library
 called Diesel.",NA
Getting ready,"Diesel uses a non-blocking technique with co-routines to write networking severs
 efficiently. As stated on the website, Diesel's core is a tight event loop that uses 
 epoll
 to deliver nearly flat performance out to 10,000 connections and beyond. Here, we
 introduce Diesel with a simple echo server. You also need Diesel library 3.0 or any
 later version. You can do that with 
 pip
  command:
  $ pip install diesel
 If you encounter some issues in installing, make sure you have the dependencies
 installed. The following command should fix most of these errors:
 $ sudo apt-get install build-essential libssl-dev libffi-dev python-
 dev
 You may need to run as a super-user depending on your operating systems
 configurations, since 
 diesel
  installs some critical dependencies such as the
 cryptography
  module that requires admin privileges to install.
 Diesel has some dependency issues in Python 3. Installing and getting it to work is
 easier with Python 2.",NA
How to do it...,"In the Python Diesel framework, applications are initialized with an instance of the
 Application()
  class and an event handler is registered with this instance. Let's see
 how simple it is to write an echo server.
 Listing 2.5 shows the code on the echo server example using Diesel as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 2
 # This program is optimized for Python 2.7.12.
 # It will work with Python 3.5.2 once the depedencies for diesel are
 sorted out.
 # It may run on any other version with/without modifications.
 # You also need diesel library 3.0 or a later version.
 # Make sure to install the dependencies beforehand.
 import diesel
 import argparse
 class EchoServer(object):
     """""" An echo server using diesel""""""
     def handler(self, remote_addr):
         """"""Runs the echo server""""""
         host, port = remote_addr[0], remote_addr[1]
         print (""Echo client connected from: %s:%d"" %(host, port))
         while True:
             try:
                 message = diesel.until_eol()
                 your_message = ': '.join(['You said', message])
                 diesel.send(your_message)
             except Exception as e:
                 print (""Exception:"",e)
 def main(server_port):",NA
How it works...,"Our script has taken a command-line argument for 
 --port
  and passed this to the
 main()
  function where our Diesel application has been initialized and run.
 Diesel has a notion of service where an application can be built with many services.
 EchoServer
  has a 
 handler()
  method. This enables the server to deal with
 individual client connections. The 
 Service()
  method takes the 
 handler
  method
 and a port number to run that service.
 Inside the 
 handler()
  method, we determine the behavior of the server. In this case,
 the server is simply returning the message text.
 If we compare this code with 
 Chapter 11
 , 
 Sockets, IPv4, and Simple Client/Server
 Programming
 , in the 
 Writing a simple echo client/server application
  recipe (
 listing 1.13a
 ), it
 is very clear that we do not need to write any boiler-plate code and hence it's very
 easy to concentrate on high-level application logic.",NA
13,NA,NA
"IPv6, Unix Domain Sockets,",NA,NA
and Network Interfaces,"In this chapter, we will cover the following topics:
 Forwarding a local port to a remote host
 Pinging hosts on the network with ICMP
 Waiting for a remote network service
 Enumerating interfaces on your machine
 Finding the IP address for a specific interface on your machine
 Finding whether an interface is up on your machine
 Detecting inactive machines on your network
 Performing a basic IPC using connected sockets (socketpair)
 Performing IPC using Unix domain sockets
 Finding out if your Python supports IPv6 sockets
 Extracting an IPv6 prefix from an IPv6 address
 Writing an IPv6 echo client/server",NA
Introduction,"This chapter extends the use of Python's 
 socket
  library with a few third-party
 libraries. It also discusses some advanced techniques, for example, the asynchronous
 ayncore
  module from the Python standard library. This chapter also touches upon
 various protocols, ranging from an ICMP ping to an IPv6 client/server.",NA
Forwarding a local port to a remote host,"Sometimes, you may need to create a local port forwarder that will redirect all traffic
 from a local port to a particular remote host. This might be useful to enable proxy
 users to browse a certain site while preventing them from browsing some others.",NA
How to do it...,"Let us create a local port forwarding script that will redirect all traffic received at port
 8800
  to the Google home page (
 http:/
 ​
 /
 ​
 www.
 ​
 google.
 ​
 com
 ). We can pass the local and
 remote host as well as port number to this script. For the sake of simplicity, let's only
 specify the local port number as we are aware that the web server runs on port 
 80
 .
 Listing 3.1 shows a port forwarding example, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 LOCAL_SERVER_HOST = 'localhost'
 REMOTE_SERVER_HOST = 'www.google.com'
 BUFSIZE = 4096
 import asyncore
 import socket
 class PortForwarder(asyncore.dispatcher):
     def __init__(self, ip, port, remoteip,remoteport,backlog=5):
         asyncore.dispatcher.__init__(self)
         self.remoteip=remoteip
         self.remoteport=remoteport
         self.create_socket(socket.AF_INET,socket.SOCK_STREAM)",NA
How it works...,"We created a port forwarding class, 
 PortForwarder
  subclassed, from
 asyncore.dispatcher
 , which wraps around the 
 socket
  object. It provides a few
 additional helpful functions when certain events occur, for example, when the
 connection is successful or a client is connected to a server socket. You have the
 choice of overriding the set of methods defined in this class. In our case, we only
 override the 
 handle_accept()
  method.
 Two other classes have been derived from 
 asyncore.dispatcher
 . The 
 Receiver
 class handles the incoming client requests and the 
 Sender
  class takes this 
 Receiver
 instance and processes the sent data to the clients. As you can see, these two classes
 override the 
 handle_read()
 , 
 handle_write()
 , and 
 writeable()
  methods to
 facilitate the bi-directional communication between the remote host and local client.",NA
Pinging hosts on the network with ICMP,"An ICMP ping is the most common type of network scanning you have ever
 encountered. It is very easy to open a command-line prompt or Terminal and type
 ping www.google.com
 . How difficult is that from inside a Python program? This
 recipe shows you an example of a Python ping.",NA
Getting ready,You need the superuser or administrator privilege to run this recipe on your machine.,NA
How to do it...,"You can lazily write a Python script that calls the system ping command-line tool, as
 follows:
 import subprocess
 import shlex
 command_line = ""ping -c 1 www.google.com""
 args = shlex.split(command_line)
 try:
       subprocess.check_call(args,stdout=subprocess.PIPE,\
 stderr=subprocess.PIPE)
     print (""Google web server is up!"")
 except subprocess.CalledProcessError:
     print (""Failed to get ping."")
 However, in many circumstances, the system's ping executable may not be available
 or may be inaccessible. In this case, we need a pure Python script to do that ping.
 Note that this script needs to be run as a superuser or administrator.
 Listing 3.2 shows the ICMP ping, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 3",NA
How it works...,"A 
 Pinger
  class has been constructed to define a few useful methods. The class
 initializes with a few user-defined or default inputs, which are as follows:
 target_host
 : This is the target host to ping
 count
 : This is how many times to do the ping
 timeout
 : This is the value that determines when to end an unfinished ping
 operation",NA
Waiting for a remote network service,"Sometimes, during the recovery of a network service, it might be useful to run a script
 to check when the server is online again.",NA
How to do it...,"We can write a client that will wait for a particular network service forever or for a
 timeout. In this example, by default, we would like to check when a web server is up
 in localhost. If you specified some other remote host or port, that information will be
 used instead.
 Listing 3.3 shows waiting for a remote network service, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 import socket
 import errno
 from time import time as now
 DEFAULT_TIMEOUT = 120
 DEFAULT_SERVER_HOST = 'localhost'
 DEFAULT_SERVER_PORT = 80
 class NetServiceChecker(object):
     """""" Wait for a network service to come online""""""
     def __init__(self, host, port, timeout=DEFAULT_TIMEOUT):
         self.host = host
         self.port = port
         self.timeout = timeout",NA
How it works...,"The preceding script uses the 
 argparse
  module to take the user input and process
 the hostname, port, and timeout, which is how long our script will wait for the 
 desired network service. It launches an instance of the 
 NetServiceChecker
  class
 and calls the 
 check()
  method. This method calculates the final end time of waiting
 and uses the socket's 
 settimeout()
  method to control each round's end time, that is
 next_timeout
 . It then uses the socket's 
 connect()
  method to test if the desired
 network service is available until the socket timeout occurs. This method also catches
 the socket timeout error and checks the socket timeout against the timeout values
 given by the user.",NA
Enumerating interfaces on your machine,"If you need to list the network interfaces present on your machine, it is not very
 complicated in Python. There are a couple of third-party libraries out there that can
 do this job in a few lines. However, let's see how this is done using a pure socket call.",NA
Getting ready,"You need to run this recipe on a Linux box. To get the list of available interfaces, you
 can execute the following command:
 $ /sbin/ifconfig",NA
How to do it...,"Listing 3.4 shows how to list the networking interfaces, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import sys
 import socket
 import fcntl
 import struct
 import array
 SIOCGIFCONF = 0x8912 #from C library sockios.h
 STUCT_SIZE_32 = 32
 STUCT_SIZE_64 = 40
 PLATFORM_32_MAX_NUMBER =  2**32
 DEFAULT_INTERFACES = 8
 def list_interfaces():
     interfaces = []
     max_interfaces = DEFAULT_INTERFACES
     is_64bits = sys.maxsize > PLATFORM_32_MAX_NUMBER
     struct_size = STUCT_SIZE_64 if is_64bits else STUCT_SIZE_32
     sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
     while True:
         bytes = max_interfaces * struct_size
         interface_names = array.array('B', b'\0' * bytes)",NA
How it works...,"This recipe code uses a low-level socket feature to find out the interfaces present on
 the system. The single 
 list_interfaces()
  method creates a socket object and finds
 the network interface information from manipulating this object. It does so by making
 a call to the 
 fnctl
  module's 
 ioctl()
  method. The 
 fnctl
  module interfaces with
 some Unix routines, for example, 
 fnctl()
 . This interface performs an I/O control
 operation on the underlying file descriptor socket, which is obtained by calling the
 fileno()
  method of the 
 socket
  object.",NA
Finding the IP address for a specific,NA,NA
interface on your machine,"Finding the IP address of a particular network interface may be needed from your
 Python network application.",NA
Getting ready,"This recipe is prepared exclusively for a Linux box. There are some Python modules
 specially designed to bring similar functionalities on Windows and macOS platforms.
 For example, see 
 http://sourceforge.net/projects/pywin32/
  for Windows-specific
 implementation.",NA
How to do it...,"You can use the 
 fnctl
  module to query the IP address on your machine.
 Listing 3.5 shows us how to find the IP address for a specific interface on your
 machine, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.",NA
How it works...,"This recipe is similar to the previous one. The preceding script takes a command-line
 argument: the name of the network interface whose IP address is to be known. The
 get_ip_address()
  function creates a 
 socket
  object and calls the 
 fnctl.ioctl()
 function to query on that object about IP information. Note that the
 socket.inet_ntoa()
  function converts the binary data to a human-readable string
 in a dotted format as we are familiar with it.",NA
Finding whether an interface is up on,NA,NA
your machine,"If you have multiple network interfaces on your machine, before doing any work on a
 particular interface, you would like to know the status of that network interface, for
 example, if the interface is actually up. This makes sure that you route your command
 to active interfaces.",NA
Getting ready,"This recipe is written for a Linux machine. So, this script will not run on a Windows
 or macOS host. In this recipe, we use 
 Nmap
 , a famous network scanning tool. You
 can find more about Nmap from its website 
 http://nmap.org/
 .
 Install Nmap in your computer. For Debian-based systems, the command is:
 $ sudo apt-get install nmap",NA
How to do it...,"We can create a 
 socket
  object and get the IP address of that interface. Then, we can
 use any of the scanning techniques to probe the interface status.
 Listing 3.6 shows the detect network interface status, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 import socket
 import struct
 import fcntl
 import nmap
 SAMPLE_PORTS = '21-23'
 def get_interface_status(ifname):
     sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
     ip_address = socket.inet_ntoa(fcntl.ioctl(
         sock.fileno(),
         0x8915, #SIOCGIFADDR, C socket library sockios.h
         struct.pack(b'256s', bytes(ifname[:15], 'utf-8'))
     )[20:24])
     nm = nmap.PortScanner()
     nm.scan(ip_address, SAMPLE_PORTS)
     return nm[ip_address].state()
 if  __name__ == '__main__':
     parser = argparse.ArgumentParser(description='Python
                                        networking utils')
     parser.add_argument('--ifname', action=""store"", dest=""ifname"",
                           required=True)
     given_args = parser.parse_args()
     ifname = given_args.ifname
     print (""Interface [%s] is: %s"" %(ifname,
 get_interface_status(ifname)))",NA
How it works...,"The recipe takes the interface's name from the command line and passes it to the
 get_interface_status()
  function. This function finds the IP address of that
 interface by manipulating a UDP 
 socket
  object.
 This recipe needs the Nmap third-party module. We can install that PyPI using the
 pip install
  command. The Nmap scanning instance, 
 nm
 , has been created by
 calling 
 PortScanner()
 . An initial scan to a local IP address gives us the status of the
 associated network interface.",NA
Detecting inactive machines on your,NA,NA
network,"If you have been given a list of IP addresses of a few machines on your network and
 you are asked to write a script to find out which hosts are inactive periodically, you
 would want to create a network scanner type program without installing anything on
 the target host computers.",NA
Getting ready,"This recipe requires installing the 
 Scapy
  library (> 2.2), which can be obtained at
 http://www.secdev.org/projects/scapy/files/scapy-latest.zip
 .
 At the time of writing, the default 
 Scapy
  release works with Python 2, and does not
 support Python 3. You may download the 
 Scapy
  for Python 3 from 
 https:/
 ​
 /
 ​
 pypi.
 python.
 ​
 org/
 ​
 pypi/
 ​
 scapy-
 ​
 python3/
 ​
 0.
 ​
 20
 .",NA
How to do it...,"We can use 
 Scapy
 , a mature network-analyzing, third-party library, to launch an
 ICMP scan. Since we would like to do it periodically, we need Python's 
 sched
 module to schedule the scanning tasks.
 Listing 3.7 shows us how to detect inactive machines, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 # Requires scapy-2.2.0 or higher for Python 2.7.
 # Visit: http://www.secdev.org/projects/scapy/files/scapy-latest.zip
 # As of now, requires a separate bundle for Python 3.x.
 # Download it from: https://pypi.python.org/pypi/scapy-python3/0.20
 import argparse
 import time
 import sched
 from scapy.all import sr, srp, IP, UDP, ICMP, TCP, ARP, Ether
 RUN_FREQUENCY = 10
 scheduler = sched.scheduler(time.time, time.sleep)
 def detect_inactive_hosts(scan_hosts):
     """"""
     Scans the network to find scan_hosts are live or dead
     scan_hosts can be like 10.0.2.2-4 to cover range.
     See Scapy docs for specifying targets.
     """"""
     global scheduler
     scheduler.enter(RUN_FREQUENCY, 1, detect_inactive_hosts,
                     (scan_hosts, ))
     inactive_hosts = []
     try:
         ans, unans = sr(IP(dst=scan_hosts)/ICMP(), retry=0, timeout=1)
         ans.summary(lambda r : r.sprintf(""%IP.src% is alive""))
         for inactive in unans:
             print (""%s is inactive"" %inactive.dst)
             inactive_hosts.append(inactive.dst)
         print (""Total %d hosts are inactive"" %(len(inactive_hosts)))
     except KeyboardInterrupt:
         exit(0)",NA
How it works...,"The preceding script first takes a list of network hosts, 
 scan_hosts
 , from the
 command line. It then creates a schedule to launch the 
 detect_inactive_hosts()
 function after a one-second delay. The target function takes the 
 scan_hosts
 argument and calls 
 Scapy
  library's 
 sr()
  function.",NA
Performing a basic IPC using connected,NA,NA
sockets (socketpair),"Sometimes, two scripts need to communicate some information between themselves
 via two processes. In Unix/Linux, there's a concept of connected socket, of
 socketpair
 . We can experiment with this here.",NA
Getting ready,"This recipe is designed for a Unix/Linux host. Windows/macOS is not suitable for
 running this one.",NA
How to do it...,"We use a 
 test_socketpair()
  function to wrap a few lines that test the socket's
 socketpair()
  function.",NA
How it works...,"The 
 socket.socketpair()
  function simply returns two connected 
 socket
  objects.
 In our case, we can say that one is a parent and another is a child. We fork another
 process via a 
 os.fork()
  call. This returns the process ID of the parent. In each
 process, the other process' socket is closed first and then a message is exchanged via a
 sendall()
  method call on the process's socket. The try-except block prints any error
 in case of any kind of exception.",NA
Performing IPC using Unix domain,NA,NA
sockets,"Unix domain sockets
  (
 UDS
 ) are sometimes used as a convenient way to
 communicate between two processes. As in Unix, everything is conceptually a file. If
 you need an example of such an IPC action, this can be useful.",NA
How to do it...,"We launch a UDS server that binds to a filesystem path, and a UDS client uses the
 same path to communicate with the server.
 Listing 3.9a shows a Unix domain socket server, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.",NA
How it works...,"A common path is defined for a UDS client/server to interact. Both the client and
 server use the same path to connect and listen to.
 In a server code, we remove the path if it exists from the previous run of this script. It
 then creates a Unix 
 datagram
  socket and binds it to the specified path. It then listens
 for incoming connections. In the data processing loop, it uses the 
 recv()
  method to
 get data from the client and prints that information on screen.
 The client-side code simply opens a Unix 
 datagram
  socket and connects to the shared
 server address. It sends a message to the server using 
 sendall()
 . It then waits for
 the message to be echoed back to itself and prints that message.",NA
Finding out if your Python supports IPv6,NA,NA
sockets,"IP version 6 or IPv6 is increasingly adopted by the industry to build newer
 applications. In case you would like to write an IPv6 application, the first thing you'd
 like to know is if your machine supports IPv6. This can be done from the Linux/Unix
 command line, as follows:
 $ cat /proc/net/if_inet6
 00000000000000000000000000000001 01 80 10 80       lo
 fe80000000000000642a57c2e51932a2 03 40 20 80     wlo1
 From your Python script, you can also check if the IPv6 support is present on your
 machine, and Python is installed with that support.",NA
Getting ready,"For this recipe, use 
 pip
  to install a Python third-party library, 
 netifaces
 , as follows:
 $ pip install netifaces",NA
How to do it...,"We can use a third-party library, 
 netifaces
 , to find out if there is IPv6 support on
 your machine. We can call the 
 interfaces()
  function from this library to list all
 interfaces present in the system.
 Listing 3.10 shows the Python IPv6 support checker, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 # This program depends on Python module netifaces => 0.8
 import socket
 import argparse
 import netifaces as ni
 def inspect_ipv6_support():
     """""" Find the ipv6 address""""""
     print (""IPV6 support built into Python: %s"" %socket.has_ipv6)
     ipv6_addr = {}
     for interface in ni.interfaces():
         all_addresses = ni.ifaddresses(interface)
         print (""Interface %s:"" %interface)
         for family,addrs in all_addresses.items():
             fam_name = ni.address_families[family]
             print ('  Address family: %s' % fam_name)
             for addr in addrs:
                 if fam_name == 'AF_INET6':
                     ipv6_addr[interface] = addr['addr']
                 print ('    Address  : %s' % addr['addr'])
                 nmask = addr.get('netmask', None)
                 if nmask:
                     print ('    Netmask  : %s' % nmask)
                 bcast = addr.get('broadcast', None)
                 if bcast:
                     print ('    Broadcast: %s' % bcast)
     if ipv6_addr:
         print (""Found IPv6 address: %s"" %ipv6_addr)
     else:
         print (""No IPv6 interface found!"")
 if __name__ == '__main__':
     inspect_ipv6_support()",NA
How it works...,"The IPv6 support checker function, 
 inspect_ipv6_support()
 , first checks if
 Python is built with IPv6 using 
 socket.has_ipv6
 . Next, we call the 
 interfaces()
 function from the 
 netifaces
  module. This gives us the list of all interfaces. If we call
 the 
 ifaddresses()
  method by passing a network interface to it, we can get all the IP
 addresses of this interface. We then extract various IP-related information, such as
 protocol family, address, netmask, and broadcast address. Then, the address of a 
 network interface has been added to the 
 IPv6_address
  dictionary if its protocol
 family matches 
 AF_INET6
 .",NA
Extracting an IPv6 prefix from an IPv6,NA,NA
address,"In your IPv6 application, you need to dig out the IPv6 address for getting the prefix
 information. Note that the upper 64-bits of an IPv6 address are represented from a
 global routing prefix plus a subnet ID, as defined in RFC 3513. A general prefix (for
 example, 
 /48
 ) holds a short prefix based on which a number of longer, more specific
 prefixes (for example, 
 /64
 ) can be defined. A Python script can be very helpful in
 generating the prefix information.",NA
How to do it...,"We can use the 
 netifaces
  and 
 netaddr
  third-party libraries to find out the IPv6
 prefix information for a given IPv6 address.
 Make sure to have 
 netifaces
  and 
 netaddr
  installed in your system:
 $ pip install netaddr
 The program is as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 # This program depends on Python modules netifaces and netaddr.
 import socket
 import netifaces as ni
 import netaddr as na
 def extract_ipv6_info():
     """""" Extracts IPv6 information""""""
     print (""IPv6 support built into Python: %s"" %socket.has_ipv6)
     for interface in ni.interfaces():
         all_addresses = ni.ifaddresses(interface)
         print (""Interface %s:"" %interface)
         for family,addrs in all_addresses.items():
             fam_name = ni.address_families[family]
             for addr in addrs:
                 if fam_name == 'AF_INET6':
                     addr = addr['addr']
                     has_eth_string = addr.split(""%eth"")",NA
How it works...,"Python's 
 netifaces
  module gives us the network interface IPv6 address. It uses the
 interfaces()
  and 
 ifaddresses()
  functions for doing this. The 
 netaddr
  module
 is particularly helpful to manipulate a network address. It has a 
 IPNetwork()
  class
 that provides us with an address, IPv4 or IPv6, and computes the prefix, network,
 and broadcast addresses. Here, we find this information class instance's 
 version
 ,
 prefixlen
 , and 
 network
  and 
 broadcast
  attributes.",NA
Writing an IPv6 echo client/server,"You need to write an IPv6 compliant server or client and wonder what could be the
 differences between an IPv6 compliant server or client and its IPv4 counterpart.",NA
How to do it...,"We use the same approach as writing an echo client/server using IPv6. The only major
 difference is how the socket is created using IPv6 information.
 Listing 12a shows an IPv6 echo server, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 import socket
 import sys
 HOST = 'localhost'
 def echo_server(port, host=HOST):
     """"""Echo server using IPv6 """"""
     for result in socket.getaddrinfo(host, port, socket.AF_UNSPEC,
 socket.SOCK_STREAM, 0, socket.AI_PASSIVE):
         af, socktype, proto, canonname, sa = result
         try:
             sock = socket.socket(af, socktype, proto)
         except socket.error as err:
             print (""Error: %s"" %err)
         try:",NA
How it works...,"The IPv6 echo server first determines its IPv6 information by calling
 socket.getaddrinfo()
 . Notice that we passed the 
 AF_UNSPEC
  protocol for creating
 a TCP socket. The resulting information is a tuple of five values. We use three of
 them, address family, socket type, and protocol, to create a server socket. Then, this
 socket is bound with the socket address from the previous tuple. It then listens to the
 incoming connections and accepts them. After a connection is made, it receives data
 from the client and echoes it back.
 On the client-side code, we create an IPv6-compliant client socket instance and send
 the data using the 
 send()
  method of that instance. When the data is echoed back, the
 recv()
  method is used to get it back.",NA
14,NA,NA
Programming with HTTP for,NA,NA
the Internet,"In this chapter, we will cover the following topics:
 Downloading data from an HTTP server
 Serving HTTP requests from your machine
 Extracting cookie information after visiting a website
 Submitting web forms
 Sending web requests through a proxy server
 Checking whether a web page exists with the HEAD request
 Spoofing Mozilla Firefox in your client code
 Saving bandwidth in web requests with the HTTP compression
 Writing an HTTP fail-over client with resume and partial downloading
 Writing a simple HTTPS server code with Python and OpenSSL
 Building asynchronous network applications with Twisted
 Building asynchronous network applications with Tornado
 Building concurrent applications with Tornado Future",NA
Introduction,"This chapter explains Python HTTP networking library functions with a few third-
 party libraries. For example, the 
 requests
  library deals with the HTTP requests in a
 nicer and cleaner way. The 
 OpenSSL
  library is used in one of the recipes to create an
 SSL-enabled web server.
 Many common HTTP protocol features have been illustrated in a few recipes, for
 example, the web form submission with 
 POST
 , manipulating header information, use
 of compression, and so on.",NA
Downloading data from an HTTP server,"You would like to write a simple HTTP client to fetch some data from any web server
 using the native HTTP protocol. This can be the very first steps towards creating your
 own HTTP browser.",NA
How to do it...,"Let us access 
 https:/
 ​
 /
 ​
 www.
 ​
 python.
 ​
 org/
 ​
  with our 
 Pythonic minimal browser
 .
 You may need to install 
 urllib
  module for the relevant Python versions:
 $ sudo pip2 install urllib
 Listing 4.1 explains the following code for a simple HTTP client:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 import argparse
 import urllib.request
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #import urllib2
 REMOTE_SERVER_HOST = 'http://www.cnn.com'",NA
How it works...,"This recipe defines an 
 urllib.request
  module that fetches data from the remote
 host. 
 urllib.request.urlopen()
  opens the given web page and fetches it. Since it
 comes with Python 3, it does not support Python 2. However, you may install and use
 urllib
  for Python 2 as we elaborated before.",NA
Serving HTTP requests from your,NA,NA
machine,"You would like to create your own web server. Your web server should handle client
 requests and send a simple hello message.",NA
How to do it...,"Python ships with a very simple web server that can be launched from the command
 line as follows:
 $ python -m SimpleHTTPServer 8080
 This will launch an HTTP web server on port 
 8080
 . You can access this web server
 from your browser by typing 
 http://localhost:8080
 . This will show the contents
 of the current directory from where you run the preceding command. If there is any
 web server index file, for example, 
 index.html
 , inside that directory, your browser
 will show the contents of 
 index.html
 . However, if you like to have full control over
 your web server, you need to launch your customized HTTP server.
 Listing 4.2 gives the following code for the custom HTTP web server:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 import argparse
 import sys
 from http.server import BaseHTTPRequestHandler, HTTPServer
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
 DEFAULT_HOST = '127.0.0.1'
 DEFAULT_PORT = 8800
 class RequestHandler(BaseHTTPRequestHandler):
     """""" Custom request handler""""""",NA
How it works...,"In this recipe, we created the 
 CustomHTTPServer
  class inherited from the
 HTTPServer
  class. In the constructor method, the 
 CustomHTTPServer
  class sets up
 the server address and port received as a user input. In the constructor, our web
 server's 
 RequestHandler
  class has been set up. Every time a client is connected, the
 server handles the request according to this class.
 The 
 RequestHandler
  defines the action to handle the client's 
 GET
  request. It sends an
 HTTP 
 header
  (code 
 200
 ) with a success message Hello from server! using the
 write()
  method.",NA
Extracting cookie information after,NA,NA
visiting a website,"Many websites use cookies to store their various information on to your local disk.
 You would like to see this cookie information and perhaps log in to that website
 automatically using cookies.",NA
How to do it... Log in to BitBucket,"Let us try to pretend to log in to a popular code-sharing website, 
 https:/
 ​
 /
 ​
 bitbucket.
 org/
 ​
 . We would like to submit the login information on the login page, 
 https:/
 ​
 /
 bitbucket.
 ​
 org/
 ​
 account/
 ​
 signin/
 ​
 ?
 ​
 next=
 ​
 /
 ​
 . The following screenshot shows the login
 page:
 So, we note down the form element IDs and decide which fake values should be
 submitted. We access this page the first time, and the next time, we access the home
 page to observe what cookies have been set up.
 Listing 4.3 explains extracting cookie information as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version",NA
How it works...,"We have used Python's 
 cookielib
  and set up a 
 CookieJar
  and 
 cj
 . The login data
 has been encoded using 
 urllib.urlencode
 . 
 urllib2
  has a 
 build_opener()
 method, which takes the predefined 
 CookieJar
  with an instance of
 HTTPCookieProcessor()
  and returns a URL 
 opener
 . We call this 
 opener
  twice:
 once for the login page and once for the home page of the website. It seems that only
 one cookie, 
 bb_session
 , was set with the 
 set-cookie
  directive present in the page
 header. More information about 
 cookielib
  can be found on the official Python
 documentation site at 
 http:/
 ​
 /
 ​
 docs.
 ​
 python.
 ​
 org/
 ​
 2/
 ​
 library/
 ​
 cookielib.
 ​
 html
 .
 Cookielib
  has been replaced by 
 http.cookiejar
  in Python 3. You may find more
 information on this at 
 https:/
 ​
 /
 ​
 docs.
 ​
 python.
 ​
 org/
 ​
 3/
 ​
 library/
 ​
 http.
 ​
 cookiejar.
 ​
 html
 .",NA
Submitting web forms,"During web browsing, we submit web forms many times in a day. Now, you would
 like do that using the Python code.",NA
Getting ready,"This recipe uses a third-party Python module called 
 requests
 . You can install the
 compatible version of this module by following the instructions from 
 http:/
 ​
 /
 ​
 docs.
 python-
 ​
 requests.
 ​
 org/
 ​
 en/
 ​
 latest/
 ​
 user/
 ​
 install/
 ​
 . For example, you can use 
 pip
  to
 install requests from the command line as follows:
 $ pip install requests",NA
How to do it...,"Let us submit some fake data to register with 
 https:/
 ​
 /
 ​
 twitter.
 ​
 com/
 ​
 . Each form
 submission has two methods: 
 GET
  and 
 POST
 . The less sensitive data, for example,
 search queries, are usually submitted by 
 GET
  and the more sensitive data is sent via
 the 
 POST
  method. Let us try submitting data with both of them.
 Listing 4.4 explains the submit web forms, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 import requests
 import urllib
 # Uncomment the below line for Python 2.7.x.
 #import urllib2
 ID_USERNAME = 'signup-user-name'
 ID_EMAIL = 'signup-user-email'
 ID_PASSWORD = 'signup-user-password'
 USERNAME = 'username'
 EMAIL = 'you@email.com'
 PASSWORD = 'yourpassword'
 SIGNUP_URL = 'https://twitter.com/account/create'
 def submit_form():
     """"""Submit a form""""""
     payload = {ID_USERNAME : USERNAME,
                ID_EMAIL    :  EMAIL,
                ID_PASSWORD : PASSWORD,}
     # make a get request
     resp = requests.get(SIGNUP_URL)
     print (""Response to GET request: %s"" %resp.content)
     # send POST request
     resp = requests.post(SIGNUP_URL, payload)
     print (""Headers from a POST request response: %s"" %resp.headers)
 if __name__ == '__main__':
     submit_form()",NA
How it works...,"This recipe uses a third-party module, 
 requests
 . It has convenient wrapper
 methods, 
 get()
  and 
 post()
 , which do the URL encoding of data and submit forms
 properly.
 In this recipe, we created a data payload with a 
 USERNAME
 , 
 PASSWORD
 , and 
 EMAIL
  for
 creating the Twitter account. When we first submit the form with the 
 GET
  method, the
 Twitter website returns an error saying that the page only supports 
 POST
 . After we
 submit the data with 
 POST
 , the page processes it. We can confirm this from the header
 data.",NA
Sending web requests through a proxy,NA,NA
server,"You would like to browse web pages through a proxy. If you have configured your
 browser with a proxy server and that works, you can try this recipe. Otherwise, you
 can use any of the public proxy servers available on the internet.",NA
Getting ready,"You need to have access to a proxy server. You can find a free proxy server by
 searching on Google or on any other search engine. Here, for the sake of
 demonstration, we have used 
 165.24.10.8
 .",NA
How to do it...,"Let us send our HTTP request through a public domain proxy server.
 Listing 4.5 explains proxying web requests across a proxy server as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 import urllib.request, urllib.parse, urllib.error
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #import urllib
 URL = 'https://www.github.com'
 PROXY_ADDRESS = ""165.24.10.8:8080"" # By Googling free proxy server
 if __name__ == '__main__':
     proxy = urllib.request.ProxyHandler({""http"" : PROXY_ADDRESS})
     opener = urllib.request.build_opener(proxy)
     urllib.request.install_opener(opener)
     resp = urllib.request.urlopen(URL)
     # Comment out the above 4 lines and uncomment the below
        for Python 2.7.x.
     #resp = urllib.urlopen(URL, proxies = {""http"" : PROXY_ADDRESS})
     print (""Proxy server returns response headers: %s "" %resp.headers)
 If you run this script, it will show the following output:
 $ python 14_5_proxy_web_request.py
 Proxy server returns response headers: Server: GitHub.com
 Date: Thu, 22 Jun 2017 14:26:52 GMT
 Content-Type: text/html; charset=utf-8
 Transfer-Encoding: chunked",NA
How it works...,"This is a short recipe where we access the social code-sharing site, 
 https:/
 ​
 /
 ​
 www.
 github.
 ​
 com
 , with a public proxy server found on Google search. The proxy address
 argument has been passed to the 
 urlopen()
  method of 
 urllib
 . We print the HTTP
 header
  of the response to show that the proxy settings work here.",NA
Checking whether a web page exists with,NA,NA
the HEAD request,"You would like to check the existence of a web page without downloading the HTML
 content. This means that we need to send a get 
 HEAD
  request with a browser client.
 According to Wikipedia, the 
 HEAD
  request asks for the response identical to the one
 that would correspond to a 
 GET
  request, but without the response body. This is useful
 for retrieving meta-information written in response headers, without having to
 transport the entire content.",NA
How to do it...,"We would like to send a 
 HEAD
  request to 
 http:/
 ​
 /
 ​
 www.
 ​
 python.
 ​
 org
 . This will not
 download the content of the home page, rather it checks whether the server returns
 one of the valid responses, for example, 
 OK
 , 
 FOUND
 , 
 MOVED PERMANENTLY
 , and so on.
 Listing 4.6 explains checking a web page with the 
 HEAD
  request as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 import argparse
 import http.client
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #import httplib
 import urllib.parse
 # Comment out the above line and uncomment the below for Python 2.7.x.",NA
How it works...,"We used the 
 HTTPConnection()
  method of 
 httplib
 , which can make a 
 HEAD
 request to a server. We can specify the path if necessary. Here, the
 HTTPConnection()
  method checks the home page or path of 
 http:/
 ​
 /
 ​
 www.
 ​
 python.
 org
 . However, if the URL is not correct, it can't find the return response inside the
 accepted list of return codes.",NA
Spoofing Mozilla Firefox in your client,NA,NA
code,"From your Python code, you would like to pretend to the web server that you are
 browsing from Mozilla Firefox.",NA
How to do it...,"You can send the custom 
 user-agent
  values in the HTTP request 
 header
 .
 Listing 4.7 explains spoofing Mozilla Firefox in your client code as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 import urllib.request, urllib.error, urllib.parse
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #import urllib2
 BROWSER = 'Mozilla/5.0 (Windows NT 5.1; rv:20.0) Gecko/20100101
 Firefox/20.0'
 URL = 'http://www.python.org'
 def spoof_firefox():
     opener = urllib.request.build_opener()
     # Comment out the above line and uncomment the below for Python
 2.7.x.
     #opener = urllib2.build_opener()
     opener.addheaders = [('User-agent', BROWSER)]
     result = opener.open(URL)
     print (""Response headers:"")
     for header in  result.headers:
     # Comment out the above line and uncomment the below for Python
 2.7.x.
     #for header in  result.headers.headers:
         print (""%s: %s"" %(header, result.headers.get(header)))
         # Comment out the above line and uncomment the below for
            Python 2.7.x.
         #print (header)
 if __name__ == '__main__':
     spoof_firefox()",NA
How it works...,"We used the 
 build_opener()
  method of 
 urllib2
  to create our custom browser
 whose 
 user-agent
  string has been set up as 
 Mozilla/5.0 (Windows NT 5.1;
 rv:20.0) Gecko/20100101 Firefox/20.0)
 .",NA
Saving bandwidth in web requests with,NA,NA
the HTTP compression,"You would like to give your web server users better performance in downloading
 web pages. By compressing HTTP data, you can speed up the serving of web
 contents.",NA
How to do it...,"Let us create a web server that serves contents after compressing it to the 
 gzip
 format.
 Listing 4.8 explains the HTTP compression as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 import argparse
 import string
 import os
 import sys
 import gzip
 import io
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #import cStringIO
 from http.server import BaseHTTPRequestHandler, HTTPServer
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #from BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer
 DEFAULT_HOST = '127.0.0.1'
 DEFAULT_PORT = 8800
 HTML_CONTENT = b""""""<html><body><h1>Compressed Hello
 World!</h1></body></html>""""""
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #HTML_CONTENT = b""""""<html><body><h1>Compressed Hello
 World!</h1></body></html>""""""
 class RequestHandler(BaseHTTPRequestHandler):
     """""" Custom request handler""""""
     def do_GET(self):
         """""" Handler for the GET requests """"""
         self.send_response(200)
         self.send_header('Content-type','text/html')
         self.send_header('Content-Encoding','gzip')
         zbuf = self.compress_buffer(HTML_CONTENT)
         sys.stdout.write(""Content-Encoding: gzip\r\n"")
         self.send_header('Content-Length',len(zbuf))
         self.end_headers()",NA
How it works...,"We created a web server by instantiating the 
 HTTPServer
  class from the
 BaseHTTPServer
  module. We attached a custom request handler to this server
 instance, which compresses every client response using a 
 compress_buffer()
 method. A predefined HTML content has been supplied to the clients.",NA
Writing an HTTP fail-over client with,NA,NA
resume and partial downloading,"You would like to create a fail-over client that will resume downloading a file if it
 fails for any reason in the first instance.",NA
How to do it...,"Let us download the Python 2.7 code from 
 http:/
 ​
 /
 ​
 www.
 ​
 python.
 ​
 org
 . A
 resume_download()
  file will resume any unfinished download of that file.
 Listing 4.9 explains resume downloading as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 import urllib.request, urllib.parse, urllib.error
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #import urllib
 import os
 TARGET_URL = 'http://python.org/ftp/python/2.7.4/'
 TARGET_FILE = 'Python-2.7.4.tgz'
 class CustomURLOpener(urllib.request.FancyURLopener):
 # Comment out the above line and uncomment the below for Python 2.7.x.
 #class CustomURLOpener(urllib.FancyURLopener):
     """"""Override FancyURLopener to skip error 206 (when a
        partial file is being sent)
     """"""
     def http_error_206(self, url, fp, errcode, errmsg, headers,
 data=None):
         pass
 def resume_download():
    file_exists = False
    CustomURLClass = CustomURLOpener()
    if os.path.exists(TARGET_FILE):
          out_file = open(TARGET_FILE,""ab"")
          file_exists = os.path.getsize(TARGET_FILE)
          #If the file exists, then only download the unfinished part
          CustomURLClass.addheader(""range"",""bytes=%s-"" % (file_exists))
    else:
          out_file = open(TARGET_FILE,""wb"")
    web_page = CustomURLClass.open(TARGET_URL + TARGET_FILE)
    #Check if last download was OK
    if int(web_page.headers['Content-Length']) == file_exists:",NA
How it works...,"In this recipe, we created a 
 CustomURLOpener
  class inheriting from the
 FancyURLopener
  method of 
 urllib
 , but 
 http_error_206()
  is overridden where
 partial content is downloaded. So, our method checks the existence of the target file
 and if it is not present, it tries to download with the custom URL opener class.",NA
Writing a simple HTTPS server code with,NA,NA
Python and OpenSSL,"You need a secure web server code written in Python. You already have your SSL
 keys and certificate files ready with you.",NA
Getting ready,"You need to install the third-party Python module, 
 pyOpenSSL
 . This can be grabbed
 from PyPI (
 https:/
 ​
 /
 ​
 pypi.
 ​
 python.
 ​
 org/
 ​
 pypi/
 ​
 pyOpenSSL
 ). Both on Windows and
 Linux hosts, you may need to install some additional packages, which are
 documented at 
 http:/
 ​
 /
 ​
 pythonhosted.
 ​
 org/
 ​
 /
 ​
 pyOpenSSL/
 ​
 .",NA
How to do it...,"After placing a certificate file on the current working folder, we can create a web
 server that makes use of this certificate to serve encrypted content to the clients.
 Listing 4.10 explains the code for a secure HTTP server as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 4
 # This program requires Python 3.5.2 or any later version
 # It may run on any other version with/without modifications.
 #
 # Follow the comments inline to make it run on Python 2.7.x.
 # Requires pyOpenSSL and SSL packages installed
 import socket, os
 from OpenSSL import SSL
 from socketserver import BaseServer
 from http.server import HTTPServer
 from http.server import SimpleHTTPRequestHandler
 # Comment out the above 3 lines and uncomment the below 3 lines for
 Python 2.7.x.
 #from SocketServer import BaseServer
 #from BaseHTTPServer import HTTPServer
 #from SimpleHTTPServer import SimpleHTTPRequestHandler
 class SecureHTTPServer(HTTPServer):",NA
How it works...,"If you notice the previous recipes that create the web server, there is not much
 difference in terms of the basic procedure. The main difference is in applying the SSL
 Context()
  method with the 
 SSLv23_METHOD
  argument. We have created the SSL
 socket with the 
 pyOpenSSL
  third-party module's 
 Connection()
  class. This class
 takes this context object along with the address family and socket type.
 The server's certificate file is kept in the current directory, and this has been applied
 with the context object. Finally, the server has been activated with the
 server_activate()
  method.",NA
Building asynchronous network,NA,NA
applications with Twisted,"Twisted is an event-driven network engine written in Python. Twisted can be used to
 develop asynchronous and publish/subscribe based Python applications.",NA
Getting ready,"You need to install the third-party Python module, 
 twisted
 . This can be grabbed
 from PyPI (
 https:/
 ​
 /
 ​
 pypi.
 ​
 org/
 ​
 project/
 ​
 Twisted/
 ​
 ). Both on Windows and Linux
 hosts, you may need to install some additional packages. The installation procedure is
 documented at 
 https:/
 ​
 /
 ​
 twistedmatrix.
 ​
 com/
 ​
 trac/
 ​
 .
 Follow the following guidelines to install Twisted in your Debian/Ubuntu based
 Linux distributions.
 Twisted suggests against installing anything into global site-package. It recommends
 using 
 virtualenv
  to set up isolated publish/subscribe modules. 
 virtualenv
  is a
 product aimed to create isolated execution environments for Python. While we can
 indeed make Twisted work by directly installing the bundles using 
 pip
 , we respect
 the suggestion of Twisted, and follow their installation guidelines for this recipe.
 Read more on this at 
 https:/
 ​
 /
 ​
 hynek.
 ​
 me/
 ​
 articles/
 ​
 virtualenv-
 ​
 lives/
 ​
 .
 You may install 
 virtualenv
  by the following, in Ubuntu:
 $ sudo apt install virtualenv",NA
How to do it...,"We will build a publish-subscribe paradigm based server-client system in this recipe.
 In this simple application, all the clients are subscribed to all the messages sent by the
 other clients. This can be configured further to alter the client or server behavior.
 Listing 4.11 explains the code for a publish/subscribe server as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse",NA
How it works...,"Twisted is developed as an asynchronous service development bundle, developed for
 Python 2. Currently it has also been ported to Python 3.
 The system has a server that listens to the messages published to it. The server
 functions as a broker in the publish/subscribe paradigm. Any of the clients that send
 messages to the server (in this example, a telnet client), functions as the publisher. All
 the other instances function as the subscriber. As all the instances in this example
 listen to each other, each of them function as both publisher and subscriber.
 You may use various options and commands of the 
 twisted
  module to achieve
 various tasks such as SSH and FTP servers effectively.",NA
Building asynchronous network,NA,NA
applications with Tornado,"Developed in Python, Tornado is a highly-scalable framework to build asynchronous
 network applications. In this recipe, we will build a simple asynchronous application
 using Tornado.",NA
Getting ready,"Tornado is a web framework that can be considered an alternative to Twisted. In
 order to execute this recipe, first you need to install Tornado in your computer, which
 can be done by the following command in Linux environments:
 $ sudo pip install tornado",NA
How to do it...,"We will build an asynchronous application to illustrate the functionality of Tornado.
 In this example, 
 AsyncHttpClient
  of Tornado has been used.",NA
How it works...,"Tornado is a framework to build asynchronous network applications. It is developed
 for Python 2 and Python 3. In the preceding example, 
 http_client
  is an object of the
 AsyncHTTPClient
  class of Tornado. As it is developed in a non-blocking manner,
 the execution does not wait until the application to finish fetching the website. It
 returns even before the method returns the output.
 On the other hand, if it was developed as a synchronous blocking manner using the
 HTTPClient
  class of Tornado, the application will wait for the method to complete
 before proceeding further.",NA
Building concurrent applications with,NA,NA
Tornado Future,"Tornado 
 Future
  construct allows us to develop non-blocking and asynchronous calls
 in a more efficient way. In this recipe, we will develop a simple asynchronous
 application based on Tornado Future constructs.
 To learn more about the concurrent and asynchronous applications
 in Tornado with Future, please visit: 
 http:/
 ​
 /
 ​
 www.
 ​
 tornadoweb.
 ​
 org/
 en/
 ​
 stable/
 ​
 concurrent.
 ​
 html
 .",NA
Getting ready,"Tornado is a web framework. In order to execute this recipe, first you need to install
 Tornado in your computer, which can be done by using the following command in
 Linux environments:
 $ sudo pip install tornado",NA
How to do it...,"We will build a concurrent application to illustrate the functionality of Tornado. In
 this example, the 
 tornado.concurrent
  module of Tornado has been used.
 Listing 4.13 explains the code for a simple concurrent application using Tornado:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 3
 # This program is optimized for Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 import time
 import datetime
 import tornado.httpserver
 import tornado.ioloop
 import tornado.options
 import tornado.web
 from tornado import gen",NA
How it works...,"The 
 concurrent.futures
  package is a concurrent programming pattern offered by
 Python. It consists of the 
 future
  class, which is useful in building concurrent
 applications in a concise manner.
 In the preceding example, 
 req1
  and 
 req2
  represent sample concurrent methods. In
 place of a workload, we have included small code fraction that waits for a time
 interval and returns the current time. Either a callback is given to retrieve the
 execution outcome in a non-blocking manner, or the Future will wait for the function
 to complete if yield is used (as illustrated by this recipe).
 By leveraging the methods and constructs of 
 concurrent.future
  efficiently, we can
 build concurrent and non-blocking applications.",NA
15,NA,NA
"Email Protocols, FTP, and",NA,NA
CGI Programming,"In this chapter, we will cover the following recipes:
 Listing the files in a remote FTP server
 Uploading a local file to a remote FTP server
 Emailing your current working directory as a compressed ZIP file
 Downloading your Google email with POP3
 Checking your remote email with IMAP
 Sending an email with an attachment via the Gmail SMTP server
 Writing a guest book for your (Python-based) web server with CGI
 Finding the mail server from an email address
 Writing a simple SMTP server
 Writing a secure SMTP client using TLS
 Writing a simple POP3 client",NA
Introduction,"This chapter explores the FTP, email, and CGI communications protocol with a
 Python recipe. Using Python, you can easily code simple FTP actions such as a file
 download and upload.",NA
Listing the files in a remote FTP server,"You would like to list the files available on the official Linux kernel's FTP site,
 ftp.kernel.org
 . You can select any other FTP site to try this recipe.",NA
Getting ready,"If you work on a production/enterprise FTP site with a user account, you need a
 username and password. However, in this instance, you don't need a username (and
 password) with the anonymous FTP server at the University of Edinburgh as you can
 log in anonymously.",NA
How to do it...,"We can use the 
 ftplib
  library to fetch files from our selected FTP site. A detailed
 documentation of this library can be found at
 https://docs.python.org/3/library/ftplib.html
  for Python 3 and at
 http://docs.python.org/2/library/ftplib.html
  for Python 2.
 ftplib
  is a built-in Python module, and you do not need to install it separately. Let
 us see how we can fetch some files with 
 ftplib
 .
 Listing 5.1 gives a simple FTP connection test as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 FTP_SERVER_URL = 'ftp.ed.ac.uk'
 import ftplib
 from ftplib import FTP",NA
How it works...,"This recipe uses 
 ftplib
  to create an FTP client session with 
 ftp.kernel.org
 . The
 test_ftp_connection()
  function takes the FTP 
 path
 , 
 username
 , and 
 email
 address for connecting to the FTP server.
 An FTP client session can be created by calling the 
 FTP()
  function of 
 ftplib
  with the
 preceding connection's credentials. This returns a client handle, which then can be
 used to run the usual FTP commands, such as the command to change the working
 directory or 
 cwd()
 . The 
 dir()
  method returns the directory listing.
 It is a good idea to quit the FTP session by calling 
 ftp.quit()
 .",NA
Common error,"If you encounter the following error when you run the program, check whether you
 still can access the 
 FTP_SERVER_URL
 , by pinging to it:
 Traceback (most recent call last):
   
 File ""15_1_list_files_on_ftp_server.py"", line 25, in <module>
     
 email='nobody@nourl.com',
   
 File ""15_1_list_files_on_ftp_server.py"", line 13, in
 test_ftp_connection
     
 ftp = ftplib.FTP(path, username, email)
  
 File ""/usr/lib/python3.5/ftplib.py"", line 118, in __init__
     
 self.connect(host)
   
 File ""/usr/lib/python3.5/ftplib.py"", line 153, in connect
     
 source_address=self.source_address)
   
 File ""/usr/lib/python3.5/socket.py"", line 693, in create_connection
    
 for res in getaddrinfo(host, port, 0, SOCK_STREAM):",NA
Uploading a local file to a remote FTP,NA,NA
server,You would like to upload a file to an FTP server.,NA
Getting ready,"Let us set up a local FTP server. In Unix/Linux, you can install 
 VSFTPD
  (
 Very Secure
 File Transfer Protocol Daemon
 ) FTP Server using the following command:
 $ sudo apt-get install vsftpd
 On a Windows machine, you can install the FileZilla FTP server, which can be
 downloaded from 
 https:/
 ​
 /
 ​
 filezilla-
 ​
 project.
 ​
 org/
 ​
 download.
 ​
 php?
 ​
 type=
 ​
 server
 .
 FileZilla can also be installed in Linux. For example, in Debian-based Linux
 distributions such as Ubuntu:
 $ sudo apt-get install filezilla
 You should create an FTP user account following the FTP server package's user
 manual.
 You would also like to upload a file to an FTP server. You can specify the server
 address, login credentials, and filename as the input argument of your script. You
 should create a local file called 
 readme.txt
  with any text in it.",NA
How to do it...,"Using the following script, let's set up a local FTP server. Once you have installed the
 FTP Server such as VSFTPD or FileZilla, you can upload a file to the logged-in user's
 home
  directory. You can specify the server address, login credentials, and filename as
 the input argument of your script.
 Listing 5.2 gives the FTP upload example as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import os",NA
How it works...,"In this recipe, we assume that a local FTP server is running. Alternatively, you can
 connect to a remote FTP server. The 
 ftp_upload()
  method uses the 
 FTP()
  function
 of Python's 
 ftplib
  to create an FTP connection object. With the 
 login()
  method, it
 logs in to the server.
 After a successful login, the 
 ftp
  object sends the STOR command with either the
 storlines()
  or 
 storbinary()
  method. The first method is used for sending ASCII
 text files such as HTML or text files. The latter method is used for binary data such as
 zipped archive.
 It's a good idea to wrap these FTP methods with try-catch error-handling blocks,
 which is not shown here for the sake of brevity.",NA
Emailing your current working directory,NA,NA
as a compressed ZIP file,"It might be interesting to send the current working directory contents as a
 compressed ZIP archive. You can use this recipe to quickly share your files with your
 friends.",NA
Getting ready,"If you don't have any mail server installed on your machine, you need to install a
 local mail server such as 
 Postfix
 . On a Debian/Ubuntu system, this can be installed
 with default settings using 
 apt-get
 , as shown in the following command:
 $ sudo apt-get install postfix",NA
How to do it...,"Let us first compress the current directory and then create an email message. We can
 send the email message via an external SMTP host, or we can use a local email server
 to do this. Like other recipes, let us get the sender and recipient information from
 parsing the command-line inputs.",NA
How it works...,"We have used Python's 
 zipfile
 , 
 smtplib
 , and an 
 email
  module to achieve our
 objective of emailing a folder as a zipped archive. This is done using the
 email_dir_zipped()
  method. This method takes two arguments: the sender and
 recipient's email addresses to create the email message.
 In order to create a ZIP archive, we create a temporary file with the 
 tempfile
 module's 
 TemporaryFile()
  class. We supply a 
 filename
 , 
 prefix
 , 
 mail
 , and
 suffix
 , 
 .zip
 . Then, we initialize the ZIP archive object with the 
 ZipFile()
  class by
 passing the temporary file as its argument. Later, we add files of the current directory
 with the ZIP object's 
 write()
  method call.
 To send an email, we create a multipart MIME message with the 
 MIMEmultipart()
 class from the 
 email.mime.multipart
  module. Like our usual email message, the
 subject, recipient, and sender information is added in the 
 email
  header.
 We create the email attachment with the 
 MIMEBase()
  method. Here, we first specify
 the application/ZIP header and call 
 set_payload()
  on this message object. Then, in
 order to encode the message correctly, the 
 encode_base64()
  method from encoder's
 module is used. It is also helpful to use the 
 add_header()
  method to construct the
 attachment header. Now, our attachment is ready to be included in the main email
 message with an 
 attach()
  method call.
 Sending an email requires you to call the 
 SMTP()
  class instance of 
 smtplib
 . There is a
 sendmail()
  method that will utilize the routine provided by the OS to actually send
 the email message correctly. Its details are hidden under the hood. However, you can
 see a detailed interaction by enabling the debug option as shown in this recipe.",NA
See also,"Further information about the Python libraries can be found at:
 http://docs.python.org/3/library/smtplib.html
  for Python 3 and
 http://docs.python.org/2/library/smtplib.html
  for Python 2.",NA
Downloading your Google email with,NA,NA
POP3,"You would like to download your Google (or virtually any other email provider's)
 email via the POP3 protocol.",NA
Getting ready,"To run this recipe, you should have an email account with Google or any other
 service provider.",NA
How to do it...,"Here, we attempt to download the first email message from a user's Google email
 account. The username is supplied from a command line, but the password is kept
 secret and not passed from the command line. This is rather entered while the script
 is running and kept hidden from display.
 Listing 5.4 shows how to download our Google email via POP3 as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 import getpass
 import poplib
 GOOGLE_POP3_SERVER = 'pop.googlemail.com'
 def download_email(username):
     mailbox = poplib.POP3_SSL(GOOGLE_POP3_SERVER, '995')
     mailbox.user(username)",NA
How it works...,"This recipe downloads a user's first Google message via POP3. The
 download_email()
  method creates a mailbox object with Python, the 
 POP3_SSL()
 class of 
 poplib
 . We passed the Google POP3 server and port address to the class
 constructor. The mailbox object then sets up a user account with the 
 user()
  method
 call. The password is collected from the user securely using the 
 getpass
  module's
 getpass()
  method and then passed to the 
 mailbox
  object. The mailbox's 
 list()
 method gives us the email messages as a Python list.
 This script first displays the number of email messages stored in the mailbox and
 retrieves the first message with the 
 retr()
  method call. Finally, it's safe to call the
 quit()
  method on the mailbox to clean up the connection.",NA
Checking your remote email with IMAP,"Instead of using POP3, you can also use IMAP to retrieve the email message from
 your Google account. In this case, the message won't be deleted after retrieval.",NA
Getting ready,"To run this recipe, you should have an email account with Google or any other
 service provider.",NA
How to do it...,"Let us connect to your Google email account and read the first email message. If you
 don't delete it, the first email message would be the welcome message from Google.
 Listing 5.5 shows us how to check Google email with IMAP as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 import getpass
 import imaplib
 GOOGLE_IMAP_SERVER = 'imap.googlemail.com'
 def check_email(username):
     mailbox = imaplib.IMAP4_SSL(GOOGLE_IMAP_SERVER, '993')
     password = getpass.getpass(prompt=""Enter your Google password: "")
     mailbox.login(username, password)
     mailbox.select('Inbox')
     typ, data = mailbox.search(None, 'ALL')
     for num in data[0].split():
         typ, data = mailbox.fetch(num, '(RFC822)')
         print ('Message %s\n%s\n' % (num, data[0][1]))
         break
     mailbox.close()
     mailbox.logout()
 if __name__ == '__main__':
     parser = argparse.ArgumentParser(description='Email Download
 Example')",NA
How it works...,"The preceding script takes a Google username from the command line and calls the
 check_email()
  function. This function creates an IMAP mailbox with the
 IMAP4_SSL()
  class of 
 imaplib
 , which is initialized with Google's IMAP server and
 default port.
 Then, this function logs in to the mailbox with a password, which is captured by the
 getpass()
  method of the 
 getpass
  module. The 
 inbox
  folder is selected by calling
 the 
 select()
  method on the mailbox object.
 The 
 mailbox
  object has many useful methods. Two of them are 
 search()
  and
 fetch()
  that are used to get the first email message. Finally, it's safer to call the
 close()
  and 
 logout()
  method on the 
 mailbox
  object to end the IMAP connection.",NA
Sending an email with an attachment via,NA,NA
Gmail SMTP server,"You would like to send an email message from your Google email account to another
 account. You also need to attach a file with this message.",NA
Getting ready,"To run this recipe, you should have an email account with Google or any other
 service provider.",NA
How to do it...,"We can create an email message and attach Python's 
 python-logo.gif
  file with the
 email message. Then, this message is sent from a Google account to a different
 account.
 Listing 4.6 shows us how to send an email from your Google account:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 import os
 import getpass
 import re
 import sys
 import smtplib
 from email.mime.image import MIMEImage
 from email.mime.multipart import MIMEMultipart
 from email.mime.text import MIMEText
 SMTP_SERVER = 'smtp.gmail.com'
 SMTP_PORT = 587
 def send_email(sender, recipient):
     """""" Send email message """"""
     msg = MIMEMultipart()
     msg['Subject'] = 'Python Emaill Test'
     msg['To'] = recipient
     msg['From'] = sender
     subject = 'Python email Test'",NA
How it works...,"In this recipe, an email message is created in the 
 send_email()
  function. This
 function is supplied with a Google account from where the email message will be
 sent. The message header object, 
 msg
 , is created by calling the 
 MIMEMultipart()
 class and then subject, recipient, and sender information is added on it.
 Python's regular 
 expression-handling
  module is used to filter the 
 .gif
  image on
 the current path. The image attachment object, 
 img
 , is then created with the
 MIMEImage()
  method from the 
 email.mime.image
  module. A correct image header
 is added to this object and finally, the image is attached with the 
 msg
  object created
 earlier. We can attach multiple image files within a 
 for
  loop as shown in this recipe.
 We can also attach a plain text attachment in a similar way.
 To send the email message, we create an SMTP session. We call some testing method
 on this session object, such as 
 ehlo()
  or 
 starttls()
 . Then, log in to the Google
 SMTP server with a username and password and a 
 sendmail()
  method is called to
 send the email.",NA
Writing a guestbook for your (Python-,NA,NA
based) web server with CGI,"Common Gateway Interface
  (
 CGI
 ) is a standard in web programming by which
 custom scripts can be used to produce web server output. You would like to catch the
 HTML form input from a user's browser, redirect it to another page, and
 acknowledge a user action.",NA
Getting ready,"To run this recipe, you first need to run a web server that supports CGI scripts.",NA
How to do it...,"We placed our Python CGI script inside a 
 cgi-bin/
  subdirectory and then visited
 the HTML page that contains the feedback form. Upon submitting this form, our web
 server will send the form data to the CGI script, and we'll see the output produced by
 this script.",NA
How it works...,"We have used a basic HTTP server setup that can handle CGI requests. Python 3
 provides these interfaces in the 
 http.server
  module. Python 2 had the modules
 BaseHTTPServer
  and 
 CGIHTTPserver
  to offer the same, which were merged in
 Python into 
 http.server
 .
 The handler is configured to use the 
 /cgi-bin
  path to launch the CGI scripts. No
 other path can be used to run the CGI scripts.
 The HTML feedback form located on 
 15_7_send_feedback.html
  shows a very
 basic HTML form containing the following code:
 <html>
    <body>
          <form action=""/cgi-bin/15_7_get_feedback.py"" method=""post"">
                 Name: <input type=""text"" name=""Name"">  <br />
                 Comment: <input type=""text"" name=""Comment"" />
                 <input type=""submit"" value=""Submit"" />
          </form>
    </body>
 </html>
 Note that the form method is POST and action is set to the 
 /cgi-
 bin/15_7_get_feedback.py
  file. The contents of this file are as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 #!/usr/bin/python
 # Import modules for CGI handling
 import cgi
 import cgitb
 # Create instance of FieldStorage
 form = cgi.FieldStorage()
 # Get data from fields
 name = form.getvalue('Name')
 comment  = form.getvalue('Comment')
 print (""Content-type:text/html\r\n\r\n"")
 print (""<html>"")",NA
Finding the mail server from an email,NA,NA
address,"Websites often need to verify an email that is entered by a user for validity. We can
 verify an email in a few lines of code in Python. First step is to confirm that the email
 is of the accepted format, to ensure that no random input is accepted as an email.
 Next is to see whether the email address indeed exists. Due to restrictions in the major
 email service providers such as Gmail and Hotmail, this code may not work
 completely. Nevertheless, it gives an overall idea on a given email address.",NA
Getting ready,"To run this recipe, you first need to have a from email address that you will use to test
 the other email addresses (marked as 
 toaddress
 ).",NA
How to do it...,"Listing 5.8 shows us the code that finds the domain name from the given email
 address and verifies it:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import re
 import smtplib
 import dns.resolver
 import argparse
 def mail_checker(fromAddress, toAddress):
     regex = '^[a-z0-9][a-z0-9._%+-]{0,63}@[a-z0-9-]+
             (\.[a-z0-9-]+)*(\.[a-z]{2,})$'
     addressToVerify = str(toAddress)
     match = re.match(regex, addressToVerify)
     if match == None:
        print('Bad Syntax in the address to verify.
               Re-enter the correct value')
        raise ValueError('Bad Syntax')
     splitAddress = addressToVerify.split('@')
     domain = str(splitAddress[1])
     records = dns.resolver.query(domain, 'MX')
     mxRecord = records[0].exchange
     mxRecord = str(mxRecord)
     server = smtplib.SMTP()
     server.set_debuglevel(1)
     try:
         server.connect(mxRecord)
     except Exception as e:
         print (""Mail Check Failed Due to Error: %s"" %str(e))
         return
     server.helo(server.local_hostname)
     server.mail(fromAddress)
     code, message = server.rcpt(str(addressToVerify))",NA
How it works...,"We have used a few Python libraries in getting this work. 
 Regular Expressions
 (
 RegEx
 ) in confirming that the emails belong to the correct format are done by using
 the 
 re
  library. The library 
 smtplib
  is an SMTP protocol client for Python programs,
 to execute methods such as sending a message to an SMTP server. You may read
 more about SMTP at 
 https://docs.python.org/3/library/smtplib.html
 .",NA
Writing a simple SMTP server,"In this recipe, we will learn how to build an SMTP server and a client, as a simple
 mail server and a client. We will use Python's 
 smtpd
  library for this recipe. You may
 read more about smtpd at 
 https://docs.python.org/3/library/smtpd.html
 .",NA
Getting ready,"First, we will write an SMTP server that listens on a particular host and a particular
 port. Then we will write an SMTP client that connects to the same host and port, with
 the 
 fromaddress
 , 
 toaddress
 , 
 subject
 , and message passed as the other
 arguments.",NA
How to do it...,"The server receives the messages from the clients and logs them to the console.
 Listing 5.9a gives the code for the SMTP server as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.",NA
How it works...,"The 
 email.utils
  module offers the utility methods for the email server, such as
 formatting the to and from addresses. The 
 smtplib
  module lets us create a mail
 server, while 
 smtpd
  lets us create an email client daemon. The 
 asyncore
  module
 offers a basic infrastructure to write asynchronous clients and servers.",NA
Writing a secure SMTP client using TLS,"Now we will look into how to connect to the mail servers such as Gmail and Yahoo
 through a simple SMTP client secured with TLS.",NA
Getting ready,"This program requires accessing a mail account in a less secured way. Many modern
 email servers may block your login account. For example, you may have to make sure
 that 
 access for less secure apps has been turned on
 .",NA
How to do it...,"You need to offer a valid email address and password to send an email through this
 recipe. We pass the email server, SMTP 
 port
 , 
 fromaddress
 , 
 toaddress
 , email
 subject
 , and email 
 body
  as the arguments, and receive the password to your email
 (from) address using the 
 getpass
  library (so that your email password is not
 displayed in plain text).
 Listing 5.10 gives the simple email client as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import smtplib
 from email.mime.multipart import MIMEMultipart
 from email.mime.text import MIMEText
 import argparse
 import getpass
 def mail_client(host, port, fromAddress, password, toAddress, subject,",NA
How it works...,"If you have not enabled less secure apps to access your email account, it may produce
 an error message similar to the following:
 $ python 15_10_secure_mail_client.py
 Enter your Password:
 Traceback (most recent call last):
   
 File ""15_10_secure_mail_client.py"", line 50, in <module>
     
 mail_client(given_args.host, given_args.port,
 given_args.fromAddress, password, given_args.toAddress,
 given_args.subject, given_args.body)
   
 File ""15_10_secure_mail_client.py"", line 31, in mail_client
     
 mailserver.login(fromAddress, password)
   
 File ""/usr/lib/python3.5/smtplib.py"", line 729, in login
     
 raise last_exception
   
 File ""/usr/lib/python3.5/smtplib.py"", line 720, in login
     
 initial_response_ok=initial_response_ok)
   
 File ""/usr/lib/python3.5/smtplib.py"", line 641, in auth
     
 raise SMTPAuthenticationError(code, resp)
 smtplib.SMTPAuthenticationError: (534, b'5.7.14
 <https://accounts.google.com/signin/continue?sarp=1&scc=1&plt=AKgnsbv9
 \n5.7.14 d-4CxD9A0qK3z36XteHYOlFaK2-
 idda9-3CG5ckc1xi_E1OgaK2aftyHvZvti9jX6fC1kd\n5.7.14
 fbTWvC5gKXK_A94zOBm8YQ_myr0uzInTP-
 Tf2pTdAZcz3owptTesXllHyXD2SCRHEXRJtk\n5.7.14 nr-
 x8QQneko1ZBJCvsbtEmo5EXgETNbESSXmbX7acCZQGukSJJ-5akizNPUrxb6NVMsJwh\n5
 .7.14 L-f5XsY1lBjmIlX9GVyQEZQSB-Iis> Please log in via your web
 browser and\n5.7.14 then try again.\n5.7.14  Learn more at\n5.7.14
 https://support.google.com/mail/answer/78754 o36sm9782398edc.39 -
 gsmtp')
 In addition, your email program would have sent you a warning on this login
 attempt, advising you on potential compromise of your account, or if the login
 attempt was indeed you, suggesting you to enable less secure apps.
 If the credentials are not correct, it will return a different error:
 smtplib.SMTPAuthenticationError: (535, b'5.7.8 Username and Password
 not accepted. Learn more at\n5.7.8
 https://support.google.com/mail/?p=BadCredentials b4sm9037328eda.34 -
 gsmtp')",NA
Writing an email client with POP3,"Now we will look into how to connect to the mail servers with POP3 to fetch an email
 from the email account.",NA
Getting ready,"This program requires accessing a mail account in a less secured way. Many modern
 email servers may block your login account. For example, you may have to make sure
 that 
 access for less secure apps has been turned on
 .",NA
How to do it...,"You need to offer a valid email address and password to send an email through this
 recipe. We pass the email server, POP3 
 port
 , 
 user
  and 
 password
  as the arguments,
 and receive the password to your email account using the 
 getpass
  library (so that
 your email password is not displayed in plain text).
 Listing 5.11 gives the simple POP3 email client as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 5
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import getpass
 import poplib
 import argparse
 def mail_client(host, port, user, password):
     Mailbox = poplib.POP3_SSL(host, port)
     Mailbox.user(user)
     Mailbox.pass_(password)
     numMessages = len(Mailbox.list()[1])
     print (Mailbox.retr(1)[1])
     Mailbox.quit()
 if __name__ == '__main__':
     parser = argparse.ArgumentParser(description='Mail Server
 Example')
     parser.add_argument('--host', action=""store"",
     dest=""host"", type=str, required=True)",NA
How it works...,"If you have not enabled less secure apps to access your email account, it may produce
 an error message.
 Once you have enabled access through less secure apps, this recipe can log in as a
 POP3 client to your email account, retrieve an email from the account, and post it in
 the console.",NA
16,NA,NA
Programming Across,NA,NA
Machine Boundaries,"In this chapter, we will cover the following recipes:
 Executing a remote shell command using telnet
 Copying a file to a remote machine by SFTP
 Printing a remote machine's CPU information
 Installing a Python package remotely
 Running a MySQL command remotely
 Transferring files to a remote machine over SSH
 Configuring Apache remotely to host a website",NA
Introduction,"This chapter promotes some interesting Python libraries. The recipes are presented
 aiming at the system administrators and advanced Python programmers who like to
 write code that connects to remote systems and executes commands. The chapter
 begins with lightweight recipes with a built-in Python library, 
 telnetlib
 . It then
 brings 
 Paramiko
 , a well-known remote access library. Finally, the powerful remote
 system administration library, 
 fabric
 , is presented. The 
 fabric
  library is loved by
 developers who regularly script for automatic deployments, for example, deploying
 web applications or building custom application binaries.",NA
Executing a remote shell command using,NA,NA
telnet,"If you need to connect an old network switch or router via telnet, you can do so from
 a Python script instead of using a bash script or an interactive shell. This recipe will
 create a simple telnet session. It will show you how to execute shell commands to the
 remote host.",NA
Getting ready,"You need to install the telnet server on your machine and ensure that it's up and
 running. You can use a package manager that is specific to your operating system to
 install the telnet server package. For example, on Debian/Ubuntu, you can use 
 apt-
 get
  or 
 aptitude
  to install the 
 telnetd
  package, as shown in the following
 command:
 $ sudo apt-get install telnetd
 $ telnet localhost",NA
How to do it...,"Let us define a function that will take a user's login credentials from the Command
 Prompt and connect to a telnet server.
 Upon successful connection, it will send the Unix 
 'ls'
  command. Then, it will
 display the output of the command, for example, listing the contents of a directory.
 Listing 6.1 shows the code for a telnet session that executes a Unix command
 remotely as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 6
 # This program is optimized for Python 3.5.2.
 # It may run on any other version with/without modifications.
 # To make it run on Python 2.7.x, needs some changes due to API
 differences.
 # Follow the comments inline to make the program work with Python 2.
 import getpass
 import sys",NA
How it works...,"This recipe relies on Python's built-in 
 telnetlib
  networking library to create a telnet
 session. The 
 run_telnet_session()
  function takes the username and password
 from the Command Prompt. The 
 getpass
  module's 
 getpass()
  function is used to
 get the password as this function won't let you see what is typed on the screen.
 In order to create a telnet session, you need to instantiate a 
 Telnet()
  class, which
 takes a hostname parameter to initialize. In this case, 
 localhost
  is used as the
 hostname. You can use the 
 argparse
  module to pass a hostname to this script.
 The telnet session's remote output can be captured with the 
 read_until()
  method.
 In the first case, the login prompt is detected using this method. Then, the username
 with a new line feed is sent to the remote machine by the 
 write()
  method (in this
 case, the same machine accessed as if it's remote). Similarly, the password was
 supplied to the remote host.
 Then, the 
 ls
  command is sent to be executed. Finally, to disconnect from the remote
 host, the 
 exit
  command is sent, and all session data received from the remote host is
 printed on screen using the 
 read_all()
  method.",NA
Copying a file to a remote machine by,NA,NA
SFTP,"If you want to upload or copy a file from your local machine to a remote machine
 securely, you can do so via 
 Secure File Transfer Protocol
  (
 SFTP
 ).",NA
Getting ready,"This recipe uses a powerful third-party networking library, 
 Paramiko
 , to show you
 an example of file copying by SFTP, as shown in the following command. You can
 grab the latest code of 
 Paramiko
  from GitHub
 (
 https://github.com/paramiko/paramiko
 ) or PyPI:
 $ pip install paramiko
 Make sure to have the SSH server and client installed on the target
 host and local host accordingly. In this example, since we are having
 localhost also as the target, install SSH locally:
 $ sudo apt-get install ssh",NA
How to do it...,"This recipe takes a few command-line inputs: the remote hostname, server port,
 source filename, and destination filename. For the sake of simplicity, we can use
 default or hard-coded values for these input parameters.
 In order to connect to the remote host, we need the username and password, which
 can be obtained from the user from the command line.
 Listing 6.2 explains how to copy a file remotely by SFTP, as shown in the following
 code:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 6
 # This program is optimized for Python 3.5.2.
 # It may run on any other version with/without modifications.
 # To make it run on Python 2.7.x, needs some changes due to API
 differences.
 # Follow the comments inline to make the program work with Python 2.
 import argparse
 import paramiko
 import getpass
 SOURCE = '16_2_copy_remote_file_over_sftp.py'
 DESTINATION ='/tmp/16_2_copy_remote_file_over_sftp.py '
 def copy_file(hostname, port, username, password, src, dst):
     client = paramiko.SSHClient()
     client.load_system_host_keys()
     print ("" Connecting to %s \n with username=%s...
               \n"" %(hostname,username))
     t = paramiko.Transport(hostname, port)
     t.connect(username=username,password=password)
     sftp = paramiko.SFTPClient.from_transport(t)
     print (""Copying file: %s to path: %s"" %(src, dst))
     sftp.put(src, dst)
     sftp.close()
     t.close()
 if __name__ == '__main__':
     parser = argparse.ArgumentParser(description='Remote file copy')
     parser.add_argument('--host', action=""store"",",NA
How it works...,"This recipe can take the various inputs for connecting to a remote machine and
 copying a file over SFTP.
 This recipe passes the command-line input to the 
 copy_file()
  function. It then
 creates an SSH client calling the 
 SSHClient
  class of 
 paramiko
 . The client needs to
 load the system host keys. It then connects to the remote system, thus creating an
 instance of the 
 transport
  class. The actual SFTP connection object, 
 sftp
 , is created
 by calling the 
 SFTPClient.from_transport()
  function of 
 paramiko
 . This takes
 the 
 transport
  instance as an input.
 After the SFTP connection is ready, the local file is copied over this connection to the
 remote host using the 
 put()
  method.
 Finally, it is a good idea to clean up the SFTP connection and underlying objects by
 calling the 
 close()
  method separately on each object.",NA
Printing a remote machine's CPU,NA,NA
information,"Sometimes, we need to run a simple command on a remote machine over SSH. For
 example, we need to query the remote machine's CPU or RAM information. This can
 be done from a Python script as shown in this recipe.",NA
Getting ready,"You need to install the third-party package, 
 Paramiko
 , as shown in the following
 command, from the source available from GitHub's repository at
 https://github.com/paramiko/paramiko
 :
 $ pip install paramiko",NA
How to do it...,"We can use the 
 paramiko
  module to create a remote session to a Unix machine. Then,
 from this session, we can read the remote machine's 
 /proc/cpuinfo
  file to extract
 the CPU information.
 Listing 6.3 gives the code for printing a remote machine's CPU information, as
 follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 6
 # This program is optimized for Python 3.5.2.
 # It may run on any other version with/without modifications.
 # To make it run on Python 2.7.x, needs some changes due to API
 differences.
 # Follow the comments inline to make the program work with Python 2.
 import argparse
 import getpass
 import paramiko
 RECV_BYTES = 4096
 COMMAND = 'cat /proc/cpuinfo'
 def print_remote_cpu_info(hostname, port, username, password):
     client = paramiko.Transport((hostname, port))",NA
How it works...,"First, we collect the connection parameters such as 
 hostname
 , 
 port
 , 
 username
 , and
 password
 . These parameters are then passed to the 
 print_remote_cpu_info()
 function.
 This function creates an SSH client session by calling the 
 transport
  class of
 paramiko
 . The connection is made thereafter using the supplied username and
 password. We can create a raw communication session using 
 open_channel()
  on
 the SSH client. In order to execute a command on the remote host, 
 exec_command()
 can be used.
 After sending the command to the remote host, the response from the remote host can
 be caught by blocking the 
 recv_ready()
  event of the session object. We can create
 two lists, 
 stdout_data
  and 
 stderr_data
 , and use them to store the remote output
 and error messages.
 When the command exits in the remote machine, it can be detected using the
 exit_status_ready()
  method, and the remote session data can be concatenated
 using the 
 join()
  string method.
 Finally, the session and client connection can be closed using the 
 close()
  method on
 each object.",NA
Installing a Python package remotely,"While dealing with the remote host in the previous recipes, you may have noticed
 that we need to do a lot of stuff related to the connection setup. For efficient
 execution, it is desirable that they become abstract and only the relevant high-level
 part is exposed to the programmers. It is cumbersome and slow to always explicitly
 set up connections to execute commands remotely.
 Fabric (
 http://fabfile.org/
 ), a third-party Python module, solves this problem. It
 only exposes as many APIs as can be used to efficiently interact with remote
 machines.",NA
Getting ready,"We need Fabric to be installed first. You can install Fabric using the Python packing
 tools, 
 pip
  or 
 easy_install
 , as shown in the following command. Fabric relies on
 the 
 paramiko
  module, which will be installed automatically:
 $ pip install fabric
 Currently the default Fabric does not seem to support Python 3. You may install
 fabric3
  to fix this:
 $ sudo pip install fabric3
 Here, we will connect the remote host using the SSH protocol. So, it's necessary to run
 the SSH server on the remote end. If you like to test with your local machine
 (pretending to access as a remote machine), you may install the 
 openssh
  server
 package locally. On a Debian/Ubuntu machine, this can be done with the package
 manager, 
 apt-get
 , as shown in the following command:
 $ sudo apt-get install openssh-server",NA
How to do it...,"Here's the code for installing a Python package using Fabric.
 Listing 6.4 gives the code for installing a Python package remotely as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 6
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 from getpass import getpass
 from fabric.api import settings, run, env, prompt
 def remote_server():
     env.hosts = ['127.0.0.1']
     env.user = prompt('Enter user name: ')
     env.password = getpass('Enter password: ')
 def install_package():
     run(""pip install yolk"")",NA
How it works...,"This recipe demonstrates how a system administration task can be done remotely
 using a Python script. There are two functions present in this script. The
 remote_server()
  function sets up the Fabric 
 env
  environment variables, for
 example, the hostname, user, password, and so on.
 The other function, 
 install_package()
 , calls the 
 run()
  function. This takes the
 commands that you usually type in the command line. In this case, the command is
 pip install yolk
 . This installs the Python package, 
 yolk
 , with 
 pip
 . As compared
 to the previously described recipes, this method of running a remote command using
 Fabric is easier and more efficient.",NA
Running a MySQL command remotely,"If you ever need to administer a MySQL server remotely, this recipe is for you. It will
 show you how to send database commands to a remote MySQL server from a Python
 script. If you need to set up a web application that relies on a backend database, this
 recipe can be used as a part of your web application setup process.",NA
Getting ready,"This recipe also needs Fabric to be installed first. You can install Fabric using the
 Python packing tools, 
 pip
  or 
 easy_install
 , as shown in the following command.
 Fabric relies on the 
 paramiko
  module, which will be installed automatically:
 $ pip install fabric
 Here, we will connect the remote host using the SSH protocol. So, it's necessary to run
 the SSH server on the remote end. You also need to run a MySQL server on the
 remote host. On a Debian/Ubuntu machine, this can be done with the package
 manager, 
 apt-get
 , as shown in the following command:
 $ sudo apt-get install openssh-server mysql-server",NA
How to do it...,"We defined the Fabric environment settings and a few functions for administering
 MySQL remotely. In these functions, instead of calling the 
 mysql
  executable directly,
 we send the SQL commands to 
 mysql
  via 
 echo
 . This ensures that arguments are
 passed properly to the 
 mysql
  executable.
 Listing 6.5 gives the code for running MySQL commands remotely, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 6
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 from getpass import getpass
 from fabric.api import run, env, prompt, cd
 def remote_server():
     env.hosts = ['127.0.0.1']
     env.user = prompt('Enter your system username: ')
     env.password = getpass('Enter your system user password: ')
     env.mysqlhost = 'localhost'
     env.mysqluser = prompt('Enter your db username: ')
     env.mysqlpassword = getpass('Enter your db user password: ')
     env.db_name = ''
 def show_dbs():
     """""" Wraps mysql show databases cmd""""""
     q = ""show databases""
     run(""echo '%s' | mysql -u%s -p%s"" %(q, env.mysqluser,
           env.mysqlpassword))
 def run_sql(db_name, query):
     """""" Generic function to run sql""""""
     with cd('/tmp'):
         run(""echo '%s' | mysql -u%s -p%s -D %s"" %(query,
              env.mysqluser, env.mysqlpassword, db_name))
 def create_db():
     """"""Create a MySQL DB for App version""""""
     if not env.db_name:
         db_name = prompt(""Enter the DB name:"")
     else:
         db_name = env.db_name
     run('echo ""CREATE DATABASE %s default character set
          utf8 collate utf8_unicode_ci;""|mysql
          --batch --user=%s --password=%s --host=%s'\",NA
How it works...,"This script defines a few functions that are used with Fabric. The first function,
 remote_server()
 , sets the environment variables. The local loopback IP
 (
 127.0.0.1
 ) is put to the list of hosts. The local system user and MySQL login
 credentials are set and collected via 
 getpass()
 .
 The other function utilizes the Fabric 
 run()
  function to send MySQL commands to
 the remote MySQL server by echoing the command to the 
 mysql
  executable.
 The 
 run_sql()
  function is a generic function that can be used as a wrapper in other
 functions. For example, the 
 empty_db()
  function calls it to execute the SQL
 commands. This can keep your code a bit more organized and cleaner.",NA
Transferring files to a remote machine,NA,NA
over SSH,"While automating a remote system administration task using Fabric, if you want to
 transfer files between your local machine and the remote machine with SSH, you can
 use the Fabric's built-in 
 get()
  and 
 put()
  functions. This recipe shows you how we
 can create custom functions to transfer files smartly by checking the disk space before
 and after the transfer.",NA
Getting ready,"This recipe also needs Fabric to be installed first. You can install Fabric using Python
 packing tools, 
 pip
  or 
 easy_install
 , as shown in the following command:
 $ pip install fabric
 Here, we will connect the remote host using the SSH protocol. So, it's necessary to
 install and run the SSH server on the remote host.",NA
How to do it...,"Let us first set up the Fabric environment variables and then create two functions, one
 for downloading files and the other for uploading files.
 Listing 6.6 gives the code for transferring files to a remote machine over SSH as
 follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 6
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 from getpass import getpass
 from fabric.api import local, run, env, get, put, prompt, open_shell
 def remote_server():
     env.hosts = ['127.0.0.1']
     env.password = getpass('Enter your system password: ')
     env.home_folder = '/tmp'
 def login():
     open_shell(command=""cd %s"" %env.home_folder)
 def download_file():
     print (""Checking local disk space..."")
     local(""df -h"")
     remote_path = prompt(""Enter the remote file path:"")
     local_path = prompt(""Enter the local file path:"")
     get(remote_path=remote_path, local_path=local_path)
     local(""ls %s"" %local_path)
 def upload_file():
     print (""Checking remote disk space..."")
     run(""df -h"")
     local_path = prompt(""Enter the local file path:"")
     remote_path = prompt(""Enter the remote file path:"")
     put(remote_path=remote_path, local_path=local_path)
     run(""ls %s"" %remote_path)",NA
How it works...,"In this recipe, we used a few of Fabric's built-in functions to transfer files between
 local and remote machines. The 
 local()
  function does an action on the local
 machine, whereas the remote actions are carried out by the 
 run()
  function.
 This is useful to check the available disk space on the target machine before
 uploading a file and vice versa.
 This is achieved by using the Unix command, 
 df
 . The source and destination file
 paths can be specified via the Command Prompt or can be hard coded in the source
 file in case of an unattended automatic execution.",NA
Configuring Apache remotely to host a,NA,NA
website,"Fabric functions can be run as both regular and super users. If you need to host a
 website in a remote Apache web server, you need the administrative user privileges
 to create configuration files and restart the web server. This recipe introduces the
 Fabric 
 sudo()
  function that runs commands in the remote machine as a superuser.",NA
Getting ready,"This recipe needs Fabric to be installed first on your local machine. You can install
 Fabric using the Python packing tools, 
 pip
  or 
 easy_install
 , as shown in the
 following command:
 $ pip install fabric
 Here, we will connect the remote host using the SSH protocol. So, it's necessary to
 install and run the SSH server on the remote host. It is also assumed that the Apache
 web server is installed and running on the remote server. On a Debian/Ubuntu
 machine, this can be done with the package manager, 
 apt-get
 , as shown in the
 following command:
 $ sudo apt-get install openssh-server apache2",NA
How to do it...,"First, we collect our Apache installation paths and some configuration parameters,
 such as web server user, group, virtual host configuration path, and initialization
 scripts. These parameters can be defined as constants.
 Then, we set up two functions, 
 remote_server()
  and 
 setup_vhost()
 , to execute
 the Apache configuration task using Fabric.
 Listing 6.7 gives the code for configuring Apache remotely to host a website as
 follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 6
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 from getpass import getpass
 from fabric.api import env, put, sudo, prompt
 from fabric.contrib.files import exists
 WWW_DOC_ROOT = ""/data/apache/test/""
 WWW_USER = ""www-data""
 WWW_GROUP = ""www-data""
 APACHE_SITES_PATH = ""/etc/apache2/sites-enabled/""",NA
How it works...,"This recipe sets up the initial Apache configuration parameters as constants and then
 defines two functions. In the 
 remote_server()
  function, the usual Fabric
 environment parameters, for example, hosts, user, password, and so on, are placed.
 The 
 setup_vhost()
  function executes a series of privileged commands. First, it
 checks whether the website's document root path is already created using the
 exists()
  function. If it exists, it removes that path and creates it in the next step.
 Using 
 chown
 , it ensures that the path is owned by the current user.",NA
17,NA,NA
Working with Web Services –,NA,NA
"SOAP, and REST","In this chapter, we will cover the following recipes:
 Querying a local XML-RPC server
 Writing a multithreaded, multicall XML-RPC server
 Running an XML-RPC server with a basic HTTP authentication
 Collecting some photo information from Flickr using REST
 Searching for SOAP methods from an Amazon S3 web service
 Searching Amazon for books through the product search API
 Creating RESTful web applications with Flask",NA
Introduction,"This chapter presents some interesting Python recipes on web services using three
 different approaches, namely, 
 XML Remote Procedure Call
  (
 XML-RPC
 ), 
 Simple
 Object Access Protocol
  (
 SOAP
 ), and 
 Representational State Transfer
  (
 REST
 ). The
 idea behind the web services is to enable an interaction between two software
 components over the web through a carefully designed protocol. The interface is
 machine readable. Various protocols are used to facilitate the web services.",NA
Querying a local XML-RPC server,"If you do a lot of web programming, it's most likely that you will come across this
 task: to get some information from a website that runs an XML-RPC service. Before
 we go into the depth of an XML-RPC service, let's launch an XML-RPC server and
 talk to it first.",NA
Getting ready,"In this recipe, we will use the Python Supervisor program that is widely used to
 launch and manage a bunch of executable programs. Supervisor can be run as a
 background daemon and can monitor child processes and restart if they die suddenly.
 We can install Supervisor by simply running the following command:
 $pip install supervisor
 Supervisor works on Python 2.x version - 2.4 and later. However, it does not work
 under Python 3 at the time of writing. So in order to run this example, you need to
 have Python 2 installed on your computer.",NA
How to do it...,"We need to create a configuration file for Supervisor. A sample configuration is given
 in this recipe. In this example, we define the Unix HTTP server socket and a few other
 parameters. Note the 
 rpcinterface:supervisor
  section where
 rpcinterface_factory
  is defined to communicate with clients.",NA
How it works...,"This recipe relies on running the 
 Supervisor
  daemon (configured with
 rpcinterface
 ) in the background. Supervisor launches another XML-RPC server, as
 follows: 
 17_2_multithreaded_multicall_xmlrpc_server.py
 .",NA
"Writing a multithreaded, multicall XML-",NA,NA
RPC server,"You can make your XML-RPC server accept multiple calls simultaneously. This
 means that multiple function calls can return a single result. In addition to this, if
 your server is multithreaded, then you can execute more code after the server is
 launched in a single thread. The program's main thread will not be blocked in this
 manner.",NA
How to do it...,"We can create a 
 ServerThread
  class inheriting from the threading. Thread class and
 wrap a 
 SimpleXMLRPCServer
  instance in an attribute of this class. This can be set up
 to accept multiple calls.
 Then, we can create two functions: one launches the multithreaded, multicall XML-
 RPC server, and the other creates a client to that server.
 Listing 7.2 gives the code for writing a multithreaded, multicall XML-RPC server, as
 shown:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 7
 # This program is optimized for Python 3.5.2.
 # To make it work with Python 2.7.12:
 #      Follow through the code inline for some changes.
 # It may run on any other version with/without modifications.
 import argparse
 import xmlrpc",NA
How it works...,"In this recipe, we have created a 
 ServerThread
  subclass inheriting from the Python
 threading library's 
 thread
  class. This subclass initializes a server attribute that
 creates an instance of the 
 SimpleXMLRPC
  server. The XML-RPC server address can be
 given through the command-line input. In order to enable the multicall function, we
 called the 
 register_multicall_functions()
  method on the server instance.
 Then, four trivial functions are registered with this XML-RPC server: 
 add()
 ,
 subtract()
 , 
 multiply()
 , and 
 divide()
 .",NA
Running an XML-RPC server with a basic,NA,NA
HTTP authentication,"Sometimes, you may need to implement authentication with an XML-RPC server.
 This recipe presents an example of a basic HTTP authentication with an XML-RPC
 server.",NA
How to do it...,"We can create a subclass of 
 SimpleXMLRPCServer
  and override its request handler
 so that when a request comes, it is verified against given login credentials.
 Listing 7.3a gives the code for running an XML-RPC server with a basic HTTP
 authentication, as shown:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 7
 # This program is optimized for Python 3.5.2.
 # To make it work with Python 2.7.12:
 #      Follow through the code inline for some changes.
 # It may run on any other version with/without modifications.
 import argparse
 import xmlrpc
 # Comment out the above line and uncomment the below line for Python
 2.x.",NA
How it works...,"In the server script, the 
 SecureXMLRPCServer
  subclass is created by inheriting from
 SimpleXMLRPCServer
 . In this subclass initialization code, we created the
 VerifyingRequestHandler
  class that actually intercepts the request and does the
 basic authentication using the 
 authenticate()
  method.
 In the 
 authenticate()
  method, the HTTP request is passed as an argument. This
 method checks the presence of the value of authorization. If its value is set to basic, it
 then decodes the encoded password with the 
 b64decode()
  function from the base64
 standard module. After extracting the username and password, it then checks that
 with the server's given credentials set up initially.
 In the 
 run_server()
  function, a simple 
 echo()
  sub function is defined and
 registered with the 
 SecureXMLRPCServer
  instance.",NA
Collecting some photo information from,NA,NA
Flickr using REST,"Many Internet websites provide a web services interface through their REST APIs.
 Flickr, a famous photo sharing website, has a REST interface. Let's try to gather some
 photo information to build a specialized database or other photo-related applications.
 To run this recipe, you need to install 
 requests
  using pip:
 $ sudo pip install requests",NA
How to do it...,"We need the REST URLs for making the HTTP requests. For simplicity's sake, the
 URLs are hard coded in this recipe. We can use the third-party requests module to
 make the REST requests. It has the convenient 
 GET()
 , 
 POST()
 , 
 PUT()
 , and 
 DELETE()
 methods.
 In order to talk to Flickr web services, you need to register yourself and get a secret
 API key. This API key can be placed in a 
 local_settings.py
  file or supplied
 through the command line.
 Listing 7.4 gives the code for collecting some photo information from Flickr using
 REST, as shown:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 7
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 # Supply Flickr API key via local_settings.py
 import argparse
 import json
 import requests
 try:
     from local_settings import flickr_apikey",NA
How it works...,"This recipe demonstrates how to interact with Flickr using its REST APIs. In this
 example, the 
 collect_photo_info()
  tag takes three parameters: Flickr API key, a
 search tag, and the desired number of search results.
 We construct the first URL to search for photos. Note that in this URL, the value of
 the method parameter is 
 flickr.photos.search
  and the desired result format is
 JSON.
 The results of the first 
 GET()
  call are stored in the resp variable and then converted to
 the JSON format by calling the 
 json()
  method on resp. Now, the JSON data is read
 in a loop looking into the 
 ['photos']['photo']
  iterator. A 
 photo_collection
  list
 is created to return the result after organizing the information. In this list, each
 photo's information is represented by a dictionary. The keys of this dictionary are
 populated by extracting information from the earlier JSON response and another GET
 request to get the information regarding the specific photo.
 Note that to get the comments about a photo, we need to make another 
 GET()
  request
 and gather comment information from the 
 ['comments']['comment']
  elements of
 the returned JSON. Finally, these comments are appended to a list and attached to the
 photo dictionary entry.
 In the main function, we extract the 
 photo_collection
  dictionary and print some
 useful information about each photo.",NA
Searching for SOAP methods from an,NA,NA
Amazon S3 web service,"If you need to interact with a server that implements web services in SOAP, then this
 recipe can help to get a starting point.",NA
Getting ready,"We can use the third-party 
 SOAPpy
  library for this task. This can be installed by
 running the following command:
 $ sudo pip install SOAPpy",NA
How to do it...,"We create a proxy instance and introspect the server methods before we can call
 them.
 In this recipe, let's interact with an Amazon S3 storage service. We have got a test
 URL for the web services API. An API key is necessary to do this simple task.
 Listing 7.5 gives the code for searching for SOAP methods from an Amazon S3 web
 service, as shown:
 #!/usr/bin/env python
 # Python Network Programming Cookbook -- Chapter - 7
 # This program requires Python 2.7 or any later version
 # SOAPpy has discontinued its support for Python 3.
 # You may find more information and other potential libraries at
 https://stackoverflow.com/questions/7817303/what-soap-libraries-exist-
 for-python-3-x
 import SOAPpy
 TEST_URL = 'http://s3.amazonaws.com/ec2-downloads/2009-04-04.ec2.wsdl'
 def list_soap_methods(url):
     proxy = SOAPpy.WSDL.Proxy(url)
     print ('%d methods in WSDL:' % len(proxy.methods) + '\n')
     for key in proxy.methods.keys():
         print (""Key Name: %s"" %key)
         print (""Key Details:"")
         for k,v in proxy.methods[key].__dict__.iteritems():
             print (""%s ==> %s"" %(k,v))
         break
 if __name__ == '__main__':
     list_soap_methods(TEST_URL)
 If you run this script, it will print the total number of available methods that support
 web services definition language
  (
 WSDL
 ) and the details of one arbitrary method, as
 shown:
     
 $ python 17_5_search_amazonaws_with_SOAP.py
     
 /home/faruq/env/lib/python2.7/site-
 packages/wstools/XMLSchema.py:1280: UserWarning: annotation is
     
 ignored
     
   warnings.warn('annotation is ignored')
     
 43 methods in WSDL:",NA
How it works...,"This script defines a method called 
 list_soap_methods()
  that takes a URL and
 constructs a SOAP proxy object by calling the 
 WSDL.Proxy()
  method of 
 SOAPpy
 . The
 available SOAP methods are available under this proxy's method attribute.
 An iteration over the proxy's method keys are done to introspect the method keys. A
 for loop just prints the details of a single SOAP method, that is, the name of the key
 and details about it.",NA
Searching Amazon for books through the,NA,NA
product search API,"If you like to search for products on Amazon and include some of them in your
 website or application, this recipe can help you to do that. We can see how to search
 Amazon for books.",NA
Getting ready,"This recipe depends on the third-party Python 
 bottlenose
  library. You can install
 this library using pip, as shown in the following command:
 $ pip install  bottlenose
 First, you need to place your Amazon account's access key, secret key, and affiliate ID
 into 
 local_settings.py
 . A sample settings file is provided with the book code. You
 can also edit this script and place it here as well.",NA
How to do it...,"We can use the 
 bottlenose
  library that implements the Amazon's product search
 APIs.
 Listing 7.6 gives the code for searching Amazon for books through product search
 APIs, as shown:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 7
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 # Supply the Amazon Access and Secret Keys via local_settings.py
 import argparse
 import bottlenose
 from xml.dom import minidom as xml
 try:
     from local_settings import amazon_account
 except ImportError:
     pass
 ACCESS_KEY = amazon_account['access_key']
 SECRET_KEY = amazon_account['secret_key']
 AFFILIATE_ID = amazon_account['affiliate_id']
 def search_for_books(tag, index):
     """"""Search Amazon for Books """"""
     amazon = bottlenose.Amazon(ACCESS_KEY, SECRET_KEY, AFFILIATE_ID)
     results = amazon.ItemSearch(
                 SearchIndex = index,
                 Sort = ""relevancerank"",",NA
How it works...,"This recipe uses the third-party 
 bottlenose
  library's 
 Amazon()
  class to create an
 object for searching Amazon through the product search API. This is done by the top-
 level 
 search_for_books()
  function. The 
 ItemSearch()
  method of this object is
 invoked with passing values to the 
 SearchIndex
  and 
 Keywords
  keys. It uses the
 relevancerank
  method to sort the search results.
 The search results are processed using the XMLmodule's 
 minidom
  interface, which
 has a useful 
 parseString()
  method. It returns the parsed XML tree-like data
 structure. The 
 getElementsByTagName()
  method on this data structure helps to
 find the item's information. The item attributes are then looked up and placed in a
 dictionary of parsed items. Finally, all the parsed items are appended in a
 all_items()
  list and returned to the user.",NA
Creating RESTful web applications with,NA,NA
Flask,"Creating a simple RESTful web service or a web application with a set of RESTful
 applications with Python has never been easier. Now you can create a simple web
 service and make it run in a matter of minutes in Python.",NA
Getting ready,"This recipe depends on the third-party Python 
 Flask
  library. If it is not already
 available in your local Python installation, you can install this library using pip as
 follows:
 $ pip install  Flask",NA
How to do it...,"We can use the 
 Flask
  library to create simple RESTful web services and web
 applications without having to install any complex web service engines or web
 application containers.
 Listing 7.7 gives the code for a simple web service that gets a number as an input to
 the RESTful service, and outputs the Fibonacci number and Square of the number:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 7
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 from flask import Flask
 app = Flask(__name__)
 @app.route('/<int:num>')
 def index(num=1):
     return ""Your Python Web Service <hr>Fibonacci(""+ str(num) + ""):
      ""+ str(fibonacci(num))+ ""<hr>Square(""+ str(num) + ""):
      ""+ str(square(num))
 def fibonacci(n):
     if n == 0:
         return 0
     elif n == 1:
         return 1
     else:
         return fibonacci(n-1) + fibonacci(n-2)
 def square(n):
     print (""Calculating for the number %s"" %n)
     return n*n",NA
How it works...,"This recipe uses the third-party 
 Flask
  library to create a simple RESTful application
 with the services that we design.
 As we designed, the web service accepts the inputs in the formal:
 http://127.0.0.1:5000/<int>
 The integer value is taken as the input to both our Fibonacci and Square functions.
 The computation is done in the Python backend and the output is printed back in the
 browser
 —
 as the output of the web service.
 The program can be run with debug mode turned off as well, though in our example
 we have left it in the debug mode to get more verbose logs.
 To learn more about Flask, visit their website at: 
 http:/
 ​
 /
 ​
 flask.
 ​
 pocoo.
 ​
 org/
 ​
 . There are
 other alternatives to Flask such as Django
 (
 https://docs.djangoproject.com/en/1.11/
 ) and other frameworks that are built
 on top of Flask such as Eve (
 http://python-eve.org/
 ) that you may also find useful
 to build RESTful web services and web applications using Python.",NA
18,NA,NA
Network Monitoring and,NA,NA
Security,"In this chapter, we will cover the following recipes:
 Sniffing packets on your network
 Saving packets in the pcap format using the pcap dumper
 Adding an extra header in HTTP packets
 Scanning the ports of a remote host
 Customizing the IP address of a packet
 Replaying traffic by reading from a saved pcap file
 Scanning the broadcast of packets",NA
Introduction,"This chapter presents some interesting Python recipes for network security
 monitoring and vulnerability scanning. We begin by sniffing packets on a network
 using the 
 pcap
  library. Then, we start using 
 Scapy
 , which is a 
 Swiss knife
  type of 
 library that can do many similar tasks. Some common tasks in packet analysis are
 presented using 
 Scapy
 , such as saving a packet in the 
 pcap
  format, adding an extra
 header, and modifying the IP address of a packet.
 Some other advanced tasks on network intrusion detection are also included in this
 chapter, for example, replaying traffic from a saved 
 pcap
  file and broadcast scanning.",NA
Sniffing packets on your network,"If you are interested in sniffing packets on your local network, this recipe can be used
 as the starting point. Remember that you may not be able to sniff packets other than
 what is destined to your machine, as decent network switches will only forward
 traffic that is designated for your machine.",NA
Getting ready,"You need to install the 
 pylibpcap
  library (Version 0.6.4 or greater) for this recipe to
 work. In Debian-based Linux systems, you may install it using the following
 command:
 $ sudo apt-get install python-libpcap
 It is also available at SourceForge (
 http://sourceforge.net/projects/pylibpcap/
 ).
 Python 3 may require you to install 
 pypcap
  using 
 pip
  instead:
 $ sudo pip install pypcap
 You also need to install the 
 construct
  library, which can be installed from PyPI via
 pip
  or 
 easy_install
 , as shown in the following command:
 $ easy_install construct
 You may also install 
 construct
  directly from 
 https:/
 ​
 /
 ​
 github.
 com/
 ​
 construct/
 ​
 construct/
 ​
 releases
 .",NA
How to do it...,"We can supply command-line arguments, for example, the network interface name
 and TCP port number, for sniffing.
 Listing 8.1 gives the code for sniffing packets on your network, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 8
 # This program is optimized for Python 2.7.12.
 # It may run on any other version with/without modifications.",NA
How it works...,"This recipe relies on the 
 pcapObject()
  class from the 
 pcap
  library to create an
 instance of sniffer. In the 
 main()
  method, an instance of this class is created, and a
 filter is set using the 
 setfilter()
  method so that only the HTTP packets are
 captured. Finally, the 
 dispatch()
  method starts sniffing and sends the sniffed 
 packet to the 
 print_packet()
  function for postprocessing.
 In the 
 print_packet()
  function, if a packet has data, the payload is extracted using
 the 
 ip_stack.parse()
  method from the 
 construct
  library. This library is useful
 for low-level data processing.",NA
Saving packets in the pcap format using,NA,NA
the pcap dumper,"The 
 pcap
  format, abbreviated from 
 packet capture
 , is a common file format for
 saving network data. More details on the 
 pcap
  format can be found at
 http://wiki.wireshark.org/Development/LibpcapFileFormat
 .
 If you want to save your captured network packets to a file and later reuse them for
 further processing, this recipe can be a working example for you.",NA
How to do it...,"In this recipe, we use the 
 Scapy
  library to sniff packets and write to a file. All utility
 functions and definitions of 
 Scapy
  can be imported using the wild card import, as
 shown in the following command:
 from scapy.all import *
 This is only for demonstration purposes and is not recommended for production
 code.
 The 
 sniff()
  function of 
 Scapy
  takes the name of a 
 callback
  function. Let's write a
 callback
  function that will write the packets onto a file.
 Listing 8.2 gives the code for saving packets in the 
 pcap
  format using the 
 pcap
 dumper, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 8
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import os
 from scapy.all import *
 pkts = []
 count = 0
 pcapnum = 0
 def write_cap(x):
     global pkts
     global count
     global pcapnum
     pkts.append(x)
     count += 1
     if count == 3:
         pcapnum += 1
         pname = ""pcap%d.pcap"" % pcapnum
         wrpcap(pname, pkts)
         pkts = []
         count = 0
 def test_dump_file():
     print (""Testing the dump file..."")
     dump_file = ""./pcap1.pcap""
     if os.path.exists(dump_file):",NA
How it works...,"This recipe uses the 
 sniff()
  and 
 wrpacp()
  utility functions of the 
 Scapy
  library to
 capture all the network packets and dump them onto a file. After capturing a packet
 via 
 sniff()
 , the 
 write_cap()
  function is called on that packet. Some global
 variables are used to work on packets one after another. For example, packets are
 stored in a 
 pkts[]
  list and packet and variable counts are used. When the value of
 the count is 
 3
 , the 
 pkts
  list is dumped onto a file named 
 pcap1.pcap
 , the count 
 variable is reset so that we can continue capturing another three packets and dumped
 onto 
 pcap2.pcap
 , and so on.
 In the 
 test_dump_file()
  function, assume the presence of the first dump file,
 pcap1.dump
 , in the working directory. Now, 
 sniff()
  is used with an offline
 parameter, which captured packets from the file instead of network. Here, the packets
 are decoded one after another using the 
 hexdump()
  function. The contents of the
 packets are then printed on the screen.",NA
Adding an extra header in HTTP packets,"Sometimes, you would like to manipulate an application by supplying a custom
 HTTP header that contains custom information. For example, adding an
 authorization header can be useful to implement the HTTP basic authentication in
 your packet capture code. As with the previous recipe, this recipe requires admin
 privileges to run too.",NA
How to do it...,"Let us sniff the packets using the 
 sniff()
  function of 
 Scapy
  and define a callback
 function, 
 modify_packet_header()
 , which adds an extra header of certain packets.
 Listing 8.3 gives the code for adding an extra header in HTTP packets, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 8
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 from scapy.all import *
 def modify_packet_header(pkt):",NA
How it works...,"First, we set up the packet sniffing using the 
 sniff()
  function of 
 Scapy
 , specifying
 modify_packet_header()
  as the 
 callback
  function for each packet. All TCP
 packets having TCP and a raw layer that are destined to port 
 80
  (HTTP) are
 considered for modification. So, the current packet header is extracted from the
 packet's payload data.
 The extra header is then appended to the existing header dictionary. The packet is
 then printed on screen using the 
 show()
  method, and for avoiding the correctness
 checking failure, the packet checksum data is removed from the packet. Finally, the
 packet is sent over the network.",NA
Scanning the ports of a remote host,"If you are trying to connect to a remote host using a particular port, sometimes you
 get a message saying that 
 Connection is refused
 . The reason for this is that, most
 likely, the server is down on the remote host. In such a situation, you can try to see
 whether the port is open or in the listening state. You can scan multiple ports to
 identify the available services in a machine.",NA
How to do it...,"Using Python's standard 
 socket
  library, we can accomplish this port-scanning task.
 We can take three command-line arguments: target 
 host
 , and 
 start_port
  and
 end_port
  numbers.",NA
How it works...,"This recipe demonstrates how to scan open ports of a machine using Python's
 standard 
 socket
  library. The 
 scan_port()
  function takes three arguments: 
 host
 ,
 start_port
 , and 
 end_port
 . Then, it scans the entire port range in three steps:
 Create a TCP socket using the 
 socket()
  function.
 1.
 If the socket is created successfully, then resolve the IP address of the
 2.
 remote host using the 
 gethostbyname()
  function.
 If the target host's IP address is found, try to connect to the IP using the
 3.
 connect()
  function. If that's successful, then it implies that the port is
 open. Now, close the port with the 
 close()
  function and repeat the first
 step for the next port.",NA
Customizing the IP address of a packet,"If you ever need to create a network packet and customize the source and destination
 IP or ports, this recipe can serve as the starting point.",NA
How to do it...,"We can take all the useful command-line arguments such as network interface name,
 protocol name, source IP, source port, destination IP, destination port, and optional
 TCP flags.",NA
How it works...,"This script defines a 
 send_packet()
  function to construct the IP packet using 
 Scapy
 .
 The source and destination addresses and ports are supplied to it. Depending on the
 protocol, for example, TCP or UDP, it constructs the correct type of packet. If the
 packet is TCP, the 
 flags
  argument is used; if not, an exception is raised.
 In order to construct a TCP packet, 
 Sacpy
  supplies the 
 IP()
 /
 TCP()
  function.
 Similarly, in order to create a UDP packet, the 
 IP()
 /
 UDP()
  function is used.
 Finally, the modified packet is sent using the 
 send()
  function.",NA
Replaying traffic by reading from a saved,NA,NA
pcap file,"While playing with network packets, you may need to replay traffic by reading from
 a previously saved 
 pcap
  file. In that case, you'd like to read the 
 pcap
  file and modify
 the source or destination IP addresses before sending them.",NA
How to do it...,"Let us use 
 Scapy
  to read a previously saved 
 pcap
  file. If you don't have a 
 pcap
  file,
 you can use the 
 Saving packets in the pcap format using pcap dumper
  recipe of this
 chapter to do that.
 Then, parse the arguments from the command line and pass them to a
 send_packet()
  function along with the parsed raw packets. As with the previous
 recipes, this recipe requires admin privileges to run.
 Listing 8.6 gives the code for replaying traffic by reading from a saved 
 pcap
  file, as
 follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 8
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import argparse
 from scapy.all import *
 def send_packet(recvd_pkt, src_ip, dst_ip, count):
     """""" Send modified packets""""""
     pkt_cnt = 0
     p_out = []
     for p in recvd_pkt:
         pkt_cnt += 1
         new_pkt = p.payload
         new_pkt[IP].dst = dst_ip
         new_pkt[IP].src = src_ip
         del new_pkt[IP].chksum
         p_out.append(new_pkt)
         if pkt_cnt % count == 0:",NA
How it works...,"This recipe reads a saved 
 pcap
  file, 
 pcap1.pcap
 , from the disk using the
 PcapReader()
  function of 
 Scapy
  that returns an iterator of packets. The command-
 line arguments are parsed if they are supplied. Otherwise, the default value is used as
 shown in the preceding output.
 The command-line arguments and the packet list are passed to the 
 send_packet()
 function. This function places the new packets in the 
 p_out
  list and keeps track of the
 processed packets. In each packet, the payload is modified, thus changing the source
 and destination IPs. In addition to this, the 
 checksum
  packet is deleted as it was
 based on the original IP address.
 After processing one of the packets, it is sent over the network immediately. After
 that, the remaining packets are sent in one go.
 As with the previous recipes, this recipe requires admin privileges to run.",NA
Scanning the broadcast of packets,"If you encounter the issue of detecting a network broadcast, this recipe is for you. We
 can learn how to find the information from the broadcast packets.",NA
How to do it...,"We can use 
 Scapy
  to sniff the packets arriving to a network interface. After each
 packet is captured, they can be processed by a callback function to get the useful
 information from it.
 Listing 8.7 gives the code for scanning the broadcast of packets, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 8
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.",NA
How it works...,"This recipe sniffs packets in a network using the 
 sniff()
  function of 
 Scapy
 . It has a
 monitor_packet()
  callback function that does the postprocessing of packets.
 Depending on the protocol, for example, IP or TCP, it sorts the packets in a dictionary
 called 
 captured_data
 .
 If an individual IP is not already present in the dictionary, it creates a new entry;
 otherwise, it updates the dictionary with the port number for that specific IP. Finally,
 it prints the IP addresses and ports in each line.",NA
19,NA,NA
Network Modeling,"In this chapter, we will cover the following recipes:
 Simulating networks with ns-3
 Emulating networks with Mininet
 Distributed network emulation with MaxiNet
 Emulating wireless networks with Mininet-WiFi
 Extending Mininet to emulate containers",NA
Introduction,"This chapter explores an early and important aspect of network systems
 development
 —
 network modeling. Specifically, it addresses the simulations and
 emulations of networks with Python-based projects.
 First we will look into network simulations that can model very large systems within
 a single computer. We will discuss ns-3, a network simulator originally written in C++
 with Python bindings, making it easy to simulate networks in Python.
 The chapter goes on to network emulation that indeed models resources one-to-one.
 It discusses Mininet, the most popular network emulator developed in Python. We
 will further discuss the extensions to Mininet, such as MaxiNet and Mininet-WiFi.
 The chapter concludes with how to extend existing simulators and emulators and to
 build a cloud network leveraging these platforms.",NA
Simulating networks with ns-3,"Data centers and cloud networks span across a large number of nodes. Network
 topologies and applications of that scale often can be tested first in simulations to
 ensure that early results are verified quick before an extensive deployment and
 testing in a more realistic emulation or a physical test bench. In this recipe, we will
 learn to simulate network systems with ns-3.",NA
Getting ready,"First download ns-3 from 
 https://www.nsnam.org/ns-3-26/download/
 . We are using
 ns-3.26 in this recipe. Extract the downloaded archive and run from the root directory
 ns-allinone-3.26
 :
 $ ./build.py.
 Since the 
 allinone
  folder contains all the bundles, this build will consume a few
 minutes.
 It shows the following upon the completion of the build:
 'build' finished successfully (14m22.645s)
 Modules built:
 antenna                   aodv                      applications
 bridge                    buildings                 config-store
 core                      csma                      csma-layout
 dsdv                      dsr                       energy
 fd-net-device             flow-monitor              internet
 internet-apps             lr-wpan                   lte
 mesh                      mobility                  mpi
 netanim (no Python)       network                   nix-vector-routing
 olsr                      point-to-point            point-to-point-
 layout
 propagation               sixlowpan                 spectrum
 stats                     tap-bridge                test (no Python)
 topology-read             traffic-control           uan
 virtual-net-device        wave                      wifi
 wimax
 Modules not built (see ns-3 tutorial for explanation):
 brite                     click                     openflow
 visualizer
 Leaving directory `./ns-3.26'",NA
How to do it...,"ns-3 can be used to quickly prototype network protocol implementations and
 applications. Once you have configured ns-3 correctly, you may start running the
 Python examples from the folder 
 ns-
 allinone-3.26/ns-3.26/examples/tutorial
 . More information on this can be
 found from 
 https:/
 ​
 /
 ​
 www.
 ​
 nsnam.
 ​
 org/
 ​
 docs/
 ​
 manual/
 ​
 html/
 ​
 python.
 ​
 html
 .
 Listing 9.1 simulates a network with two nodes with UDP messages between them:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 9
 # This program is optimized for Python 2.7.12 and Python 3.5.2.
 # It may run on any other version with/without modifications.
 import ns.applications
 import ns.core
 import ns.internet
 import ns.network",NA
How it works...,"ns-3 simulates the networks including the nodes and the flows. As there is no real
 emulation of network, complex algorithms and large network systems can be
 simulated by ns-3. In this recipe, we simulated a simple UDP client-server
 architecture to pass messages between them, as an echo client. More complex systems
 can be simulated by following the ns-3 user manuals further.",NA
Emulating networks with Mininet,"Emulating networks offer more accurate and realistic results. Therefore, despite the
 high requirements for resources, emulations are often preferred over simulations in
 networking systems. Mininet is an enterprise-grade open source network emulator
 that is widely used in industries and academia. Mininet API and orchestration
 modules are written in Python, with core emulation performed by compiled C code.
 You may easily write Python code to emulate networks with Mininet, or to extend it
 with more capabilities. Mininet is capable of emulating an entire network one-to-one
 in your laptop. Each node in the network can be represented by a process in Mininet.",NA
Getting ready,"First, install Mininet on your computer. In Debian/Ubuntu based systems, you just
 need to issue the following command to install Mininet:
 $ sudo apt-get install mininet
 Mininet must run as a root, as it should be able to access the programs installed in the
 host as the processes of the emulated nodes. Thus, this recipe needs to be run as root
 too, as it has a Mininet emulation.
 While it is possible to make Mininet work in Python 3.x, by default it works on
 Python 2.7.x. Thus, you may need to install Python 2.7.x or later versions of Python 2,
 if you are using Python 3.x.",NA
How to do it...,"Mininet consists of a few network topologies that are predefined. You may define
 your own topology. In this recipe, we are using tree topology, which is probably the
 most common and the most basic network topology. We ping one emulated host from
 another emulated host.
 Listing 9.2 emulates a simple network with a tree topology:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 9
 # This program is optimized for Python 2.7.12.
 # It may run on any other version with/without modifications.
 import argparse
 from mininet.net import Mininet
 from mininet.topolib import TreeTopo
 # Emulate a network with depth of depth_ and fanout of fanout_
 def emulate(depth_, fanout_):",NA
How it works...,"In this recipe, we pinged (
 depth
 )th host from the 0th host. As (
 depth
  < the number of
 hosts), this works well. Note that subsequent executions will give different outcomes
 as the 
 ping
  statistics. This is because the network is actually emulated with real
 processes, and hence the 
 ping
  actually occurs between the emulated processes.
 You may re-execute the program to see different outcomes to the previous:
 $ sudo python 19_2_mininet_emulation.py --depth=2 --fanout=3
 PING 10.0.0.3 (10.0.0.3) 56(84) bytes of data.
 64 bytes from 10.0.0.3: icmp_seq=1 ttl=64 time=3.33 ms
 --- 10.0.0.3 ping statistics ---
 1 packets transmitted, 1 received, 0% packet loss, time 0ms
 rtt min/avg/max/mdev = 3.332/3.332/3.332/0.000 ms",NA
Distributed network emulation with,NA,NA
MaxiNet,"Mininet requires a large amount of resources to emulate large networks. Hence, it is
 not always feasible to emulate a complex system using Mininet in a single computer
 or server within a given time. MaxiNet attempts to address this by extending Mininet,
 and thus enabling an efficient distributed execution on a cluster. In this recipe, we
 will look into configuring MaxiNet in a cluster and emulating a network in the cluster
 using MaxiNet.",NA
Getting ready,"First, get the MaxiNet installer to all the servers that you would like to install it:
 $ wget https://github.com/MaxiNet/MaxiNet/raw/v1.0/installer.sh
 Make sure you can 
 sudo
  without entering a password for the user. In Ubuntu, this
 can be done by adding the following line to the 
 /etc/sudoers
  file:
 myusername ALL=(ALL) NOPASSWD: ALL
 Here, replace 
 myusername
  with your username.
 Now if you type:
 $ sudo su
 It should not ask for the password.
 You will have to install 
 python-setuptools
 , or upgrade it with 
 pip
 , to make the
 MaxiNet installation work:
 $ sudo apt-get install python-setuptools
 $ pip install --upgrade --user setuptools pip
 Run the script from all the servers as the user that would run MaxiNet later:
 $ sh installer.sh
 Once installed, copy the 
 MaxiNet.cfg
  to 
 /etc/
 :
 $ sudo cp ~/MaxiNet/share/MaxiNet-cfg-sample /etc/MaxiNet.cfg
 Modify it to include the two lines:
 sshuser = yourusername
 usesudo = True
 For example:
 [all]
 ...
 sshuser = ubuntu
 usesudo = True
 Once you have followed through in all your servers, you have MaxiNet ready in all of
 them! Alternatively, you may just download the MaxiNet VMs and host them in your
 servers:",NA
How to do it...,"In this recipe, we will rewrite the same recipe of 9.2 for MaxiNet. As you can notice,
 with minor changes, the code and the API remains compatible with that of Mininet's.
 Listing 9.2 adopts the listing 9.1 for MaxiNet, as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 9
 # This program is optimized for Python 2.7.12.
 # It may run on any other version with/without modifications.
 import sys
 import maxinet
 from mininet.topolib import TreeTopo
 # Emulate a network with depth of depth_ and fanout of fanout_
 def emulate(depth_, fanout_):
     # Start the MaxiNet as a Mininet cluster.
     cluster = maxinet.MininetCluster(""pc1"",""pc2"",""pc3"")
     cluster.start()
     # Emulate the network topology.
     emu = maxinet.Emulation(cluster, TreeTopo(depth_,fanout_))",NA
How it works...,"MaxiNet is Mininet executing in a cluster. It aims to keep the API changes minimal (if
 any), to be able to offer a quick adoption to the existing Mininet users. Make sure that
 all the worker instances in MaxiNet can indeed communicate. As you may have
 noticed, this emulation workload is too little to actually offer any benefits for us to
 distribute it across a cluster. However, when you start emulating larger networks and
 complex systems, the advantages become apparent.",NA
Emulating wireless networks with,NA,NA
Mininet-WiFi,"You may emulate wireless networks and mobile networks through Mininet-WiFi,
 which was developed as an extension to Mininet. While Mininet enables emulation of
 Software-Defined Networks, Mininet-WiFi supports emulation of Software-Defined
 Wireless Networks. Mininet-WiFi emulates mobile terminals efficiently, while also
 providing a visual graphical user interface of emulated wireless networks.",NA
Getting ready,"First install Mininet-WiFi on your computer:
 $ git clone https://github.com/intrig-unicamp/mininet-wifi
 $ cd mininet-wifi
 $ sudo util/install.sh -Wnfvl",NA
How to do it...,"You may emulate 
 mobile ad hoc network
  (
 MANET
 ) and 
 vehicular ad hoc network
 (
 VANET
 ) using Mininet-WiFi, and visualize them in a graphical interface. VANET is
 a subset of MANET, which can be emulated by sub-classing the generic interfaces of
 Mininet-WiFi. In this recipe, we will adopt and extend an example from the Mininet-
 WiFi.
 More examples can be found at 
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 intrig-
 unicamp/
 ​
 mininet-
 ​
 wifi/
 ​
 tree/
 ​
 master/
 ​
 examples
 .
 Listing 9.4 shows the code to emulate a mobile network:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 9
 # This program is optimized for Python 2.7.12.
 # It may run on any other version with/without modifications.
 from mininet.net import Mininet
 from mininet.node import Controller, OVSKernelAP
 from mininet.link import TCLink
 from mininet.cli import CLI",NA
How it works...,"Mininet-WiFi extends Mininet for networks that are mobile in nature. In this recipe,
 we emulated wireless network stations. Following our previous recipe on pinging the
 hosts, you may easily extend this recipe to let the mobile stations communicate
 between themselves. You may further model more complex and larger vehicular
 networks using Mininet-WiFi.",NA
Extending Mininet to emulate containers,"Mininet can leverage the applications installed in the server to attach them as
 processes to the hosts that it emulates. For example, see the following, a 
 vim
  started
 from a host in Mininet:
 $ sudo mn
 *** Creating network
 *** Adding controller
 *** Adding hosts and stations:
 h1 h2
 *** Adding switches and access point(s):
 s1
 *** Adding link(s):
 (h1, s1) (h2, s1)
 *** Configuring hosts
 *** Starting controller(s)
 c0
 *** Starting switches and/or access points
 s1 ...
 *** Starting CLI:
 mininet-wifi> h1 vim
 The preceding command will open a 
 vim
  instance in the Terminal! You may even try
 other applications such as 
 gedit
 , or even 
 mininet
  itself, to run as a process attached
 to the emulated host. However, note that these are real processes from the
 applications that are installed on the server. Not an emulation.
 Containernet extends Mininet to use Docker containers as hosts in Mininet
 emulations, by extending the 
 host
  class of Mininet. Hence, container enables
 emulation of more interesting and complex functionalities, attaching Docker
 containers directly as hosts. This allows the programs installed in a container
 available to the host.",NA
Getting ready,"In this recipe, we use Containernet as an example to show how to extend Mininet for
 more use cases, while using Containernet to show a simple emulation with Docker
 containers as hosts in Mininet. More complex Mininet algorithms can be run on
 Containernet, along with its capabilities to run containers as hosts.
 First, install Containernet in your computer. Since Containernet uses Ansible for this,
 you need to install it before:
 $ sudo apt-get install ansible git aptitude
 $ sudo vim /etc/ansible/hosts
 Add: 
 localhost ansible_connection=local
 Now, to actually install Containernet:
 $ git clone https://github.com/containernet/containernet.git
 $ cd containernet/ansible
 $ sudo ansible-playbook install.yml
 Alternatively, you may use Vagrant to get Containernet up and running faster,
 without actually installing it manually. First make sure to have a hypervisor such as
 Virtualbox installed:
 $ sudo apt-get install virtualbox
 Now, you may execute the following to get Vagrant for Containernet:
 $ cd containernet
 $ vagrant up
 $ vagrant ssh
 You may confirm that you have installed Vagrant correctly by running the following
 from the 
 containernet
  directory:
 $ sudo py.test -v mininet/test/test_containernet.py",NA
How to do it...,"In this recipe, we will attach existing containers to our simple network emulation. To
 avoid creating Docker images on our own, as it is out of scope for this book, we will
 use the example included in the Containernet Vagrant image.
 Docker containers can be initialized in place of hosts and switches as nodes in
 constructing the links. Various parameters and the volumes that define the container
 can be specified.
 Listing 9.5 gives a simple emulation of a network with containers as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 9
 # This program is optimized for Python 2.7.12.
 # It may run on any other version with/without modifications.
 # Adopted from
 https://github.com/containernet/containernet/blob/master/examples/dock
 erhosts.py",NA
How it works...,"Containernet extends Mininet with the container support specifically for Docker. It
 can be installed locally as your Mininet installation, or installed as a Vagrant image.
 While MaxiNet aims to increase the scalability and throughput of Mininet, Mininet-
 WiFi and Containernet aim to offer more features to Mininet. As Mininet offers a
 Python-based API, it can be extended with Python modules. In the core, you may
 extend its kernel with C code.
 Similar to Mininet-WiFi, Containernet too thrives to maintain backward-compatibility
 with Mininet. Thus emulations written in Mininet should work in these projects that
 are started as a fork of Mininet. Moreover, the APIs are maintained to resemble that
 of Mininet with minimal changes, it is easy to adopt to these emulation platforms.
 While these recipes presented the ability to simulate containers in the networks and
 wireless sensor networks, they also serve the purpose to illustrate the potential to
 extend Mininet with more capabilities.",NA
20,NA,NA
"Authentication, Authorization,",NA,NA
and Accounting (AAA),"In this chapter, we will cover the following recipes:
 Finding DNS names of a network
 Finding DNS host information
 Finding DNS resource records
 Making DNS zone transfer
 Querying NTP servers
 Connecting to an LDAP server
 Making LDAP bind
 Reading and writing LDAP
 Authenticating REST APIs with Eve
 Throttling requests with RequestsThrottler",NA
Introduction,"Authentication, authorization, and accounting
  (
 AAA
 ) are the three major pillars of
 access control. Authentication identifies the user, authorization identifies the roles of
 the user, and accounting ensures that the user actions are performed within the usage
 limits (such as throttling). AAA, as they are collectively known, are crucial for
 networks for proper functioning and security. Hence network projects consider AAA
 as a crucial factor in their network architecture
 —
 remarkably the OpenDaylight's
 AAA project is considered to be a core project in the SDN controller ecosystem. In this
 chapter, we will look into the AAA options for networking, and how to configure
 AAA with Python for the networks. We start the chapter with simpler recipes before
 going into more complex ones.",NA
Finding DNS names of a network,"There are a few libraries in Python for managing the 
 Domain Name Servers
  (
 DNS
 ) of
 the internet. Each network administrator needs to effectively manage the DNS
 mappings of their network. In this recipe, we will start by introducing 
 dnspython
 , a
 simple DNS toolkit developed in Python to manage DNS.",NA
Getting ready,"First, install 
 dnspython
  (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 rthalley/
 ​
 dnspython
 ) using the 
 pip
 :
 $ sudo pip install dnspython",NA
How to do it...,"We import 
 dns.name
  of 
 dnspython
  to do a simple exercise to find the DNS names
 from the user inputs of two web URLs, and how these web URLs are related.
 Listing 11.1 evaluates the user input of two web URLs for the DNS names as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 11
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.",NA
How it works...,"The 
 dns.name.from_text()
  retrieves the DNS name from the Terminal user input.
 Then it compares the inputs to check whether they are each other's subdomain or
 superdomain. With 
 labels
  property, we may also retrieve the labels associated with
 each of the site. These simple methods can be useful in tracing the relationship of two
 URLs and automating the detection of subdomains and superdomains from the list of
 URLs.",NA
Finding DNS host information,"It may be useful for us to know the domain name of a given IP address. First given an
 address, we need to know whether it even resolves to a valid address identifiable in
 the internet. We may use the 
 dnspython
  library for these tasks.",NA
Getting ready,"First install 
 dnspython
  (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 rthalley/
 ​
 dnspython
 ) using the 
 pip
 :
 $ sudo pip install dnspython",NA
How to do it...,"We import 
 dns.reversename
  of 
 dnspython
  to do a simple exercise of finding the
 reverse name of an address from the given address. We use 
 dns.resolver
  to find
 the address that an IP address resolves to be.
 Listing 11.2 gives the domain information for a given IP address as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 11
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.
 import argparse
 import dns.reversename",NA
How it works...,"When we input an invalid IP address, the resolving fails with the message, 
 The DNS
 query name does not exist
 . It reports the reverse domain name (
 {reverse-
 IP}.in-addr.arpa
 ) in the message as it could not resolve it to a valid address. If a
 valid address is found by 
 dns.resolver.query()
 , it is returned. 
 Pointer records
 (
 PTR
 ) is used in resolving the IP address to its domain, as it maps a network interface
 (IP) to the host name.",NA
Finding DNS resource records,"You may secure your DNS information with 
 transaction signature
  (
 TSIG
 ). This
 ensures a secured authorized update to DNS record. You may receive the 
 Start of
 Authority
  (
 SOA
 ) information of a host with the DNS lookup utilities 
 host
  and 
 dig
 .
 We first look at 
 host
  utility followed by 
 dig
  before looking into the Python code for
 our current recipe to retrieve the same information:
 $ host cnn.com
 cnn.com has address 151.101.129.67
 cnn.com has address 151.101.193.67
 cnn.com has address 151.101.1.67
 cnn.com has address 151.101.65.67
 cnn.com has IPv6 address 2a04:4e42:600::323
 cnn.com has IPv6 address 2a04:4e42:400::323
 cnn.com has IPv6 address 2a04:4e42:200::323
 cnn.com has IPv6 address 2a04:4e42::323
 cnn.com mail is handled by 10 mxb-000c6b02.gslb.pphosted.com.
 cnn.com mail is handled by 10 mxa-000c6b02.gslb.pphosted.com.
 $ host axn.com
 axn.com has address 198.212.50.74
 axn.com mail is handled by 0 mxa-001d1702.gslb.pphosted.com.
 axn.com mail is handled by 0 mxb-001d1702.gslb.pphosted.com.
 The output indicates that no IPv6 addresses were found for 
 https:/
 ​
 /
 ​
 www.
 ​
 axn.
 ​
 com/
 ​
 .
 $ host -t soa cnn.com
 cnn.com has SOA record ns-47.awsdns-05.com. awsdns-
 hostmaster.amazon.com. 1 7200 900 1209600 86400",NA
Getting ready,"First install the 
 dnspython
  (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 rthalley/
 ​
 dnspython
 ) using the
 following 
 pip
 :
 $ sudo pip install dnspython",NA
How to do it...,"Now we will use 
 dnspython
  to find the same details of a web URL that we earlier
 found using 
 dig
  and 
 host
  commands.
 Listing 11.3 gives a simple, yet verbose code to offer the details of resource records of
 a given URL:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 11
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.
 import argparse
 import dns.zone
 import dns.resolver
 import socket
 def main(address):
     # IPv4 DNS Records
     answer = dns.resolver.query(address, 'A')
     for i in xrange(0, len(answer)):
         print(""Default: "", answer[i])
     # IPv6 DNS Records
     try:
         answer6 = dns.resolver.query(address, 'AAAA')
         for i in xrange(0, len(answer6)):
             print(""Default: "", answer6[i])
     except dns.resolver.NoAnswer as e:
         print(""Exception in resolving the IPv6",NA
How it works...,"The 
 dns.resolver.query(address, <type>)
  resolves the address for the query
 type. The command 
 host
  looks for 
 A
  (IPv4 address), 
 AAAA
  (IPv6 address), and 
 MX
 resource records when the type is not specified. We specify 
 A
 , 
 AAAA
 , 
 MX
 , 
 SOA
 , 
 CNAME
 ,
 NS
 , 
 SIG
 , and 
 KEY
  as the resource record types to resolve the addresses in our recipe.
 The output indicates that some of these records are not set for the sites that we tested.
 The websites that we tested do not contain a 
 SIG
 , 
 KEY
 , or 
 CNAME
  record as we found
 before with the 
 host -t
  command. Since we do not have the authorization or the
 key to actually perform the zone transfer for these sites, this will fail with the message
 Failed to perform zone transfer
 . Also note that 
 http:/
 ​
 /
 ​
 axn.
 ​
 com
  notes that,
 there was no answer for the 
 AAAA
 , thus pointing that no IPv6 DNS record found for
 the website.",NA
Making DNS zone transfer,"We may transfer the DNS zone with the 
 dnspython
  bundle. SOA record consists of
 crucial information for a zone transfer. Our recipe attempts the DNS zone transfer
 and compares the output with that from the 
 dig
  utility. While zone transfer is not
 something that is performed by website users, we used 
 zonetransfer.me
  test
 website to test our recipe and show the zone transfer output. Thanks to 
 https:/
 ​
 /
 digi.
 ​
 ninja/
 ​
 projects/
 ​
 zonetransferme.
 ​
 php
  for setting this site up and running for
 educational purposes. You may read more on zone transfer and the test website
 zonetransfer.me
  from the site.",NA
Getting ready,"First install 
 dnspython
  (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 rthalley/
 ​
 dnspython
 ) using the
 following 
 pip
 :
 $ sudo pip install dnspython",NA
How to do it...,"We will use 
 dnspython
  for the DNS zone transfer.
 Listing 11.4 gives a simple code for a zone transfer as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 11
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.
 import argparse
 import dns.zone
 import dns.resolver
 import socket
 def main(address):
     soa_answer = dns.resolver.query(address, 'SOA')
     master_answer = dns.resolver.query(soa_answer[0].mname, 'A')
     try:
         z = dns.zone.from_xfr(dns.query.",NA
How it works...,"The 
 dns.query.xfr()
  takes two inputs similar to the 
 dig
  utility (
 dig axfr
 @nsztm1.digi.ninja zonetransfer.me
 ). It gets the first input parameter (in the
 case of 
 zonetransfer.me
 , it is 
 nsztm1.digi.ninja
 ), by processing
 master_answer[0].address
 , which is essentially retrieved from the single
 command-line argument (and also the second input parameter), address. We print the
 sorted names after the zone transfer.",NA
Querying NTP servers,"Network Time Protocol
  (
 NTP
 ): 
 http:/
 ​
 /
 ​
 www.
 ​
 ntp.
 ​
 org/
 ​
 ntpfaq/
 ​
 NTP-
 ​
 s-
 ​
 def.
 ​
 htm
  is a 
 protocol that is used to query and synchronize the clocks of the computers connected
 to the internet. In this recipe, we will be using 
 ntplib
  (
 https:/
 ​
 /
 ​
 pypi.
 ​
 python.
 ​
 org/
 pypi/
 ​
 ntplib/
 ​
 ), a Python module that offers an interface to query the NTP servers, to
 learn about the NTP servers, you may use 
 http:/
 ​
 /
 ​
 www.
 ​
 pool.
 ​
 ntp.
 ​
 org/
 ​
 en/
 ​
 use.
 ​
 html
 which finds the closest NTP server for you to synchronize your server clock. It also
 gives guidelines on contributing your computing resources as an NTP server.",NA
Getting ready,"First install 
 ntplib
  in your computer.
 $ sudo apt-get install python-ntplib
 ntplib
  works on Python 2. You may install 
 python3-ntplib
  that works for Python
 3 from 
 https:/
 ​
 /
 ​
 launchpad.
 ​
 net/
 ​
 ubuntu/
 ​
 yakkety/
 ​
 amd64/
 ​
 python3-
 ​
 ntplib/
 ​
 0.
 ​
 3.
 ​
 3-
 ​
 1
 , or
 by following the succeeding commands:
 $ wget
 http://launchpadlibrarian.net/260811286/python3-ntplib_0.3.3-1_all.deb
 $ sudo dpkg -i python3-ntplib_0.3.3-1_all.deb",NA
How to do it...,"Synchronizing your time is crucial accounting task. While it is not ideal to depend on
 the time from the internet for mission-critical systems, the NTP time is sufficiently
 accurate for most of the computing requirements.",NA
How it works...,"We query and print the time from a remote NTP server using
 ctime(response.tx_time)
 . We can pass the address of an NTP server and version
 (1-7) as the arguments to the program. When a generic address such as
 pool.ntp.org
  is used, the closest server is picked based on the requesting server's
 location. Hence, you receive a response with minimal latency.",NA
Connecting to an LDAP server,"Lightweight Directory Access Protocol
  (
 LDAP
 ) is an identity management protocol
 organizing individuals, organizations, resources, and the roles and access of those
 entities, organized locally, in the intranet or in the internet. Many LDAP servers are
 available for download and install and are free and open source, including the
 OpenLDAP and Apache Directory.",NA
Getting ready FreeIPA Log in Screen,"For those who like to try an LDAP instance without actually going through the hassle
 of installing the server, there are a few open and public LDAP servers available
 online. Some of them offer write access, for example, FreeIPA (
 https:/
 ​
 /
 ​
 www.
 ​
 freeipa.
 org/
 ​
 page/
 ​
 Main_
 ​
 Page
 ). FreeIPA is an integrated security information management
 solution that offers an online demo installation for testing purposes at 
 https:/
 ​
 /
 ​
 ipa.
 demo1.
 ​
 freeipa.
 ​
 org/
 ​
 ipa/
 ​
 ui/
 ​
 . We will use it for our recipes. As with any public server
 with write access, FreeIPA server needs to be cleaned up daily. During these hours, it
 goes offline. The FreeIPA web interface is shown as follows:
 You may also use 
 ldap.forumsys.com
 , another public LDAP server with read-only
 access to test our recipes. You may find more LDAP servers accessible online with
 read-only and write accesses, or you may even configure your own LDAP server to
 have full control. In this recipe, we will connect to the LDAP server and receive
 information from it through our Python program.",NA
How to do it...,"We will use the 
 ldap3
  library and import 
 Server
 , 
 Connection
 , and 
 ALL
  modules
 from it. 
 ldap3
  offers an object-oriented access to the directory servers of LDAP.
 Listing 11.6 connects to a remote LDAP server and retrieves the server information
 and schema as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 11
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.
 import argparse
 from ldap3 import Server, Connection, ALL
 def main(address):
     # Create the Server object with the given address.
     # Get ALL information.
     server = Server(address, get_info=ALL)
     #Create a connection object, and bind with auto
      bind set to true.
     conn = Connection(server, auto_bind=True)
     # Print the LDAP Server Information.
     print('******************Server Info**************')
     print(server.info)
     # Print the LDAP Server Detailed Schema.
     print('******************Server Schema**************')
     print(server.schema)
 if __name__ == '__main__':
     parser = argparse.ArgumentParser(description=
                                  'Query LDAP Server')
     parser.add_argument('--address', action=""store"",
     dest=""address"",  default='ipa.demo1.freeipa.org')
     given_args = parser.parse_args()",NA
How it works...,"In the server information, we receive details such as supported controls, extensions,
 and features. Moreover, we also get the schema entry and configuration context. In
 the LDAP server schema, we retrieve information on the various attributes as shown
 as follows:
 'memberUid': Attribute type: 1.3.6.1.1.1.1.12
   Short name: memberUid
   Single value: False
   Equality rule: caseExactIA5Match
   Syntax: 1.3.6.1.4.1.1466.115.121.1.26
 [('1.3.6.1.4.1.1466.115.121.1.26', 'LDAP_SYNTAX', 'IA5 String',
 'RFC4517')]
   Optional in: posixGroup",NA
Making LDAP bind,"We need to authenticate an LDAP user with their password for accessing more
 information relevant for their role. In this recipe, we will attempt to make an LDAP
 bind with the correct password and an invalid one.",NA
Getting ready,"Install 
 ldap3
  Python client, the prerequisite for this recipe:
 $ sudo pip install ldap3",NA
How to do it...,"We will provide the bind 
 dn
  and 
 password
  in addition to the 
 address
  of the LDAP
 server address, as the input arguments.
 Listing 11.7 elaborates how to make an LDAP bind:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 11
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.
 import argparse
 from ldap3 import Server, Connection, ALL, core
 def main(address, dn, password):
     # Create the Server object with the given address.
     server = Server(address, get_info=ALL)
     #Create a connection object, and bind with the
      given DN and password.
     try:
         conn = Connection(server, dn, password, auto_bind=True)
         print('LDAP Bind Successful.')
         print(conn)
     except core.exceptions.LDAPBindError as e:
         # If the LDAP bind failed for reasons such
           as authentication failure.
         print('LDAP Bind Failed: ', e)",NA
How it works...,"The LDAP bind succeeds with the correct credentials. Then you may define your
 search criteria with a relevant filter type and attributes. Once you have performed the
 search, you may iterate and print the resultant entries.",NA
Reading and writing LDAP,"In this recipe, we will read and write from the FreeIPA LDAP demo server.",NA
Getting ready,"Install 
 ldap3
  Python client, the prerequisite for this recipe:
 $ sudo pip install ldap3",NA
How to do it...,"First we will read LDAP with a 
 Reader
  object as shown by Listing 11.8 as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 11
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without
   modifications.
 # Adopted from
 http://ldap3.readthedocs.io/tutorial_abstraction_basic.html
 from ldap3 import Server, Connection, ObjectDef, AttrDef, Reader,
 Writer, ALL
 def main():
     server = Server('ipa.demo1.freeipa.org', get_info=ALL)
     conn = Connection(server,
 'uid=admin,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org',
 'Secret123', auto_bind=True)
     person = ObjectDef('person', conn)
     r = Reader(conn, person, 'ou=ldap3-
                tutorial,dc=demo1,dc=freeipa,dc=org')
     print(r)
     print('************')
     person+='uid'
     print(r)
 if __name__ == '__main__':
     main ()
 This recipe performs an implicit creation of a new attribute definition by the
 following line:
     person+='uid'
 By running this recipe, you may observe the following output:
 $ python 20_8_read_ldap_server.py
 CURSOR : Reader
 CONN   : ldap://ipa.demo1.freeipa.org:389 - cleartext - user:
 uid=admin,cn=users,cn=accounts,dc=demo1,dc=freeipa,dc=org - not lazy -
 bound - open - <local: 192.168.137.95:44860 - remote:
 52.57.162.88:389> - tls not started - listening - SyncStrategy -
 internal decoder",NA
How it works...,"We define the object in the line:
     person = ObjectDef('person', conn)
 Then we define a 
 Reader
  cursor and read it by:
     r = Reader(conn, person, 'ou=ldap3-
     tutorial,dc=demo1,dc=freeipa,dc=org')",NA
Authenticating REST APIs with Eve,"Eve is a REST API server built in Python. We will test how to use Eve REST API
 framework with 
 BasicAuth
 , global authentication. Eve can also be started without 
 any authentication at all, as a simple REST API server. This recipe is a simple
 demonstration of serving the entire web server. However, Eve provides more
 sophisticated and more role-based access control that protects certain APIs with roles
 for the users.
 The server is started with a username and password, and the client passes on the
 base64
  encode of the format 
 username:password
  to the server to get authenticated.",NA
Getting ready,"First install Eve using Python:
 $ sudo pip install eve
 This will install Eve, along with its dependencies, 
 cerberus-0.9.2
 , 
 eve-0.7.4
 ,
 events-0.2.2
 , 
 flask-0.12
 , 
 flask-pymongo-0.5.1
 , 
 pymongo-3.4.0
 ,
 simplejson-3.11.1
 , 
 werkzeug-0.11.15
 .
 In this recipe, we will start a simple server with a username and password as the
 basic authentication.",NA
How to do it...,"First make sure that you have the domain configurations saved as a Python file
 named 
 settings.py
  in the same folder as your program. In this recipe, we have
 included a simple 
 settings.py
  with the following content as a sample:
     
 DOMAIN = {'people': {}}
 If 
 settings.py
  is not found, the program will halt with the following error:
 eve.exceptions.ConfigException: DOMAIN dictionary missing or wrong.",NA
How it works...,"Eve can be initialized with custom authentication. We created our class as a simple
 basic authentication, with a given username and password (which can easily be
 extended to receive the credentials as command-line arguments). The 
 check_auth()
 returns 
 true
  if both the client provided username and password (as a 
 base64
 encoded string) matches the ones that the server is started with.",NA
Throttling requests with,NA,NA
RequestsThrottler,"Networks need to have accounting in addition to authorization and authentication.
 Accounting ensures proper use of the resources, this means that everyone gets to use
 the services in a fair manner. Network throttling enables accounting in the web
 services. This is a simple recipe that offers a throttling service to the web requests.",NA
Getting ready,"We use 
 requests_throttler
  Python module to throttle the web requests. First,
 install the module and configure our recipe using the following script:
 $ sh 20_10_requests_throttling.sh
 #!/bin/bash
 ####################################################
 # Python Network Programming Cookbook, Second Edition --
 Chapter - 11
 ####################################################
 # Download and extract RequestsThrottler
 wget
 https://pypi.python.org/packages/d5/db/fc7558a14efa163cd2d3e4515cdfbbf
 c2dacc1d2c4285b095104c58065c7/RequestsThrottler-0.1.0.tar.gz
 tar -xvf RequestsThrottler-0.1.0.tar.gz
 cd RequestsThrottler-0.1.0
 # Copy our recipe into the folder
 cp ../20_10_requests_throttling.py requests_throttler
 # Configure and Install RequestsThrottling
 python setup.py build
 sudo python setup.py install",NA
How to do it...,"Now, you may execute your recipe by going to the folder,
 RequestsThrottler-0.1.0/requests_throttler
 .
 $ cd RequestsThrottler-0.1.0/requests_throttler
 Make sure to give the full addresses as the command-line argument. For example,
 provide 
 http://cnn.com
 . Not 
 cnn.com
 . Otherwise, you will receive an error
 message similar to the one shown following:
 requests.exceptions.MissingSchema: Invalid URL 'cnn.com': No schema
 supplied. Perhaps you meant http://cnn.com?",NA
How it works...,"The 
 requests_throttler
  Python module supports throttling requests to the web
 servers. There are more throttling implementations based in Python, for example,
 throttle (
 https:/
 ​
 /
 ​
 pypi.
 ​
 python.
 ​
 org/
 ​
 pypi/
 ​
 throttle
 ) is an implementation based on
 token bucket algorithm.
 Throttling can ensure that only a given number of requests are satisfied for a given
 user in a given time interval. Thus, it protects the server from attackers who try to
 flood the server with the requests, as in 
 denial-of-service
  (
 DoS
 ) attacks.",NA
21,NA,NA
Open and Proprietary,NA,NA
Networking Solutions,"In this chapter, we will cover the following recipes:
 Configuring Red PNDA
 Configuring VMware NSX for vSphere 6.3.2
 Configuring Juniper Contrail Server Manager
 Configuring OpenContrail controller
 Configuring OpenContrail cluster
 Interacting with devices running Cisco IOS XR
 Collaborating with Cisco Spark API",NA
Introduction,"We discussed Open SDN projects such as OpenDaylight and ONOS from the Linux
 Foundation and other open source efforts such as Floodlight in the previous chapters.
 In this chapter, we will look more into advanced open and vendor-specific SDN
 programming, and configure various networking projects. Cisco 
 Application Centric
 Infrastructure
  (
 ACI
 ) is an SDN solution from Cisco. Its building blocks include the
 hardware switches of Cisco Nexus 7000 and 9000 Series and Cisco 
 Application Policy
 Infrastructure Controller
  (
 APIC
 ). Juniper Contrail, which was later open sourced as
 OpenContrail
  is another example for a vendor-specific SDN. VMware NSX a
 proprietary SDN solution, also has its open source versions available for public
 download. This chapter will serve as an introduction to a wide range of enterprise
 options available for SDN and networking architecture. While we introduce many
 solutions, we will restrict our detailed discussions to the solutions that are available
 for free.",NA
Configuring Red PNDA,"PNDA is an open source platform for network data analytics. It is horizontally
 scalable and complex to deploy on a single computer. To be able to test smaller scale
 applications in the developer computers, a smaller downsized version of PNDA
 known as Red PNDA (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 pndaproject/
 ​
 red-
 ​
 pnda
 ) is also available.
 In this recipe, we will configure Red PNDA, the minimal version of PNDA in a
 laptop.",NA
Getting ready,"You need to have a minimum of 4GB memory, 2 VCPUs, and 8GB hard disk to install
 Red PNDA. It requires up to an hour to configure and install, this also depends on
 how fast your internet connection is.",NA
How to do it...,"You may configure Red PNDA by following the succeeding commands. First clone
 the project code base:
 $ git clone https://github.com/pndaproject/red-pnda.git
 $ cd red-pnda
 Build it as a super user.
 $ sudo su
 $ bash scripts/install-dependencies.sh wlo1
 In the preceding command, replace 
 wlo1
  with one of your active network interfaces.
 You may find it by using the 
 ifconfig
  command in Linux and 
 ipcofig
  in
 Windows.
 The build requires an internet connection as it downloads the required dependencies.
 You may monitor the status of the build from the logs, as the build logs are verbose.
 Sample configuration logs (as observed in my laptop during the build) are provided
 in the 
 file 21_1_configure_red_pnda_output
  for your reference. After an hour
 or so, the following message will be printed upon a successful installation:
 ....
 Adding platformlibs 0.6.8 to easy-install.pth file
 Installed /usr/local/lib/python3.5/dist-packages/platformlibs-0.6.8-
 py2.7.egg",NA
How it works...,"Red PNDA is a minimalist version of PNDA networking data analytics platform.
 Unlike PNDA, Red PNDA is configured to be run in a single computer and should
 not be used as a production solution due to its limited horizontal scalability.",NA
Configuring VMware NSX for vSphere,NA,NA
6.3.2,"NSX is a network virtualization and security platform offered by VMware in its effort
 towards creating a Software-Defined Data Center. You may download tarballs of NSX
 controller and NSX for vSphere 6.3.2 hypervisor at 
 https:/
 ​
 /
 ​
 my.
 ​
 vmware.
 ​
 com/
 ​
 group/
 vmware/
 ​
 details?
 ​
 downloadGroup=
 ​
 NSXV_
 ​
 632_
 ​
 OSS
 ​
 productId=
 ​
 417
 . With the server
 virtualization offered by vSphere and the network virtualization offered by NSX,
 VMware virtualizes an entire data center. The NSX controller functions as a control
 point for the logical switches and overlay transport tunnels. In this recipe, we will 
 learn to use 
 pynsxv
  (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 vmware/
 ​
 pynsxv
 ), a Python-based library
 and CLI tool, to control NSX for vSphere.",NA
Getting ready,"First install 
 pynsxv
  using 
 pip
 :
 $ sudo pip install pynsxv
 You may confirm that the installation was successful by executing the following
 commands:
 $ pynsxv -h
 usage: pynsxv [-h] [-i INI] [-v] [-d]
 {lswitch,dlr,esg,dhcp,lb,dfw,usage} ...
 PyNSXv Command Line Client for NSX for vSphere
 positional arguments:
 {lswitch,dlr,esg,dhcp,lb,dfw,usage}
 lswitch             Functions for logical switches",NA
How to do it...,"PyNSXv is a Python project to configure and control NSX based Software-Defined
 Data Centers. First configure 
 nsx.ini
  to point to the correct values for the
 parameters:
 [nsxv]
 nsx_manager = <nsx_manager_IP>
 nsx_username = admin
 nsx_password = <nsx_manager_password>
 [vcenter]
 vcenter = <VC_IP_or_Hostname>
 vcenter_user = administrator@domain.local
 vcenter_passwd = <vc_password>
 [defaults]
 transport_zone = <transport_zone_name>
 datacenter_name = <vcenter datacenter name>
 edge_datastore = <datastore name to deploy edges in>
 edge_cluster = <vcenter cluster for edge gateways>
 Then 
 pynsxv
  can offer a global view of the data center network to configure and
 control it as shown by the following output:
 $ pynsxv lswitch list
 +---------------------+----------------+
 | LS name             | LS ID          |
 |---------------------+----------------|
 | edge_ls             | virtualwire-63 |
 | dlr_ls              | virtualwire-64 |
 +---------------------+----------------+",NA
How it works...,"PyNSXv offers a Python-based API and interface to control NSX. You just need to
 offer the NSX Manager and the vCenter IP and credentials as well as names for the
 vCenter data center, edge data store, and edge cluster for the gateways. A complete
 NSX API Guide
  can be found at 
 https:/
 ​
 /
 ​
 pubs.
 ​
 vmware.
 ​
 com/
 ​
 NSX-
 ​
 6/
 ​
 topic/
 ​
 com.
 vmware.
 ​
 ICbase/
 ​
 PDF/
 ​
 nsx_
 ​
 604_
 ​
 api.
 ​
 pdf
  and 
 NSX for vSphere API Guide
  can be found at
 https:/
 ​
 /
 ​
 docs.
 ​
 vmware.
 ​
 com/
 ​
 en/
 ​
 Vmware-
 ​
 NSX-
 ​
 for-
 ​
 vSphere/
 ​
 6.
 ​
 3/
 ​
 nsx_
 ​
 63_
 ​
 api.
 ​
 pdf
 .",NA
Configuring Juniper Contrail Server,NA,NA
Manager,"Juniper Networks (
 http:/
 ​
 /
 ​
 www.
 ​
 juniper.
 ​
 net/
 ​
 us/
 ​
 en/
 ​
 ) offer a set of products aimed at
 network performance and security. It also provides Python-based open source
 projects (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 Juniper
 ) to manage its platform. Contrail offers an
 SDN-enabled management solution and service delivery for wide area networks, thus
 supporting 
 Software-Defined Wide Area Networks
  (
 SD-WANs
 ).
 Contrail Server Manager is a platform to manage the servers in a Contrail cluster. In
 this recipe, first we will set up Juniper Contrail Server Manager (
 https:/
 ​
 /
 ​
 github.
 com/
 ​
 Juniper/
 ​
 contrail-
 ​
 server-
 ​
 manager
 ). You may learn more about configuring
 Contrail Server Manager and other Contrail bundles from 
 http:/
 ​
 /
 ​
 www.
 ​
 juniper.
 ​
 net/
 documentation/
 ​
 en_
 ​
 US/
 ​
 contrail4.
 ​
 0/
 ​
 information-
 ​
 products/
 ​
 pathway-
 ​
 pages/
 getting-
 ​
 started-
 ​
 pwp.
 ​
 pdf
 .
 Juniper is open sourcing many of its networking solutions under OpenContrail
 project. We will look into the open source scripts available to manage and configure
 Contrail. Written in Python 2, these scripts do not support Python 3.",NA
Getting ready,"You may download the relevant software bundle of Juniper Contrail Server Manager
 from 
 http:/
 ​
 /
 ​
 www.
 ​
 juniper.
 ​
 net/
 ​
 support/
 ​
 downloads/
 ​
 ?
 ​
 p=
 ​
 contrail#sw
  and install the
 Contrail Server Manager or Server Manager Lite directly from the command (after
 replacing with the relevant file number):
 $ sudo dpkg -i contrail-server-manager-installer_2.22~juno_all.deb
 More installation instructions can be found at 
 https:/
 ​
 /
 ​
 www.
 ​
 juniper.
 ​
 net/
 documentation/
 ​
 en_
 ​
 US/
 ​
 contrail4.
 ​
 0/
 ​
 topics/
 ​
 concept/
 ​
 install-
 ​
 containers-
 ​
 smlite.
 html
 .",NA
How to do it...,"Let's install Contrail Server Manager in our current directory.
 $ sudo python setup.py install --root install
 This will set up the server manager inside a directory called 
 install
  which is inside
 the current directory.
 Now you will be able to see a bunch of Python scripts of the server manager inside
 the folder 
 install/usr/local/lib/python2.7/dist-packages/src
 :
 $ cd  install/usr/local/lib/python2.7/dist-packages/src
 $ ls
 contrail_defaults.py        __init__.pyc
 server_mgr_db_convert.py
 server_mgr_disk_filesystem_view.pyc  server_mgr_ipmi_monitoring.py
 server_mgr_mon_base_plugin.pyc  server_mgr_utils.py",NA
How it works...,"While Juniper Contrail is a proprietary solution that needs a login to download and
 use the Contrail Server Manager and other products, these open source python scripts
 can be used to manage the Juniper Contrail networking cluster.",NA
Configuring OpenContrail controller,"OpenContrail (
 http:/
 ​
 /
 ​
 www.
 ​
 opencontrail.
 ​
 org/
 ​
 ) is an open source network
 virtualization platform for the cloud from Juniper Networks. In this recipe, we will
 learn to configure OpenContrail controller, also known as the OpenContrail core
 project (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 Juniper/
 ​
 contrail-
 ​
 controller
 ). This project is
 developed in C++ and Python.",NA
Getting ready,"In this recipe we will configure OpenContrail. We will offer complementary
 information to the configuration instructions that can be found in 
 https:/
 ​
 /
 ​
 github.
 com/
 ​
 Juniper/
 ​
 contrail-
 ​
 controller/
 ​
 wiki/
 ​
 OpenContrail-
 ​
 bring-
 ​
 up-
 ​
 and-
 provisioning
 . OpenContrail can be executed in a distributed environment consisting
 of multiple servers for configuration node, analytics node, a control node, and
 compute node. Each node serves their purpose and they all can be virtualized and
 installed inside fewer nodes. However, due to their hardware requirements (memory
 and CPU), it is recommended to run them in individual servers in a cluster, if
 possible.",NA
How to do it...,"You may configure the control node by using the script
 (
 21_4_open_contrail_control_node.sh
 ):
 #!/bin/bash
 ######################################################################
 ########
 # Python Network Programming Cookbook, Second Edition -- Chapter - 12
 # Adopted from
 https://github.com/Juniper/contrail-controller/wiki/Install-and-Config
 ure-OpenContrail-1.06
 ######################################################################
 ########
 # Configue the Ubuntu repositories.
 echo ""deb http://ppa.launchpad.net/opencontrail/ppa/ubuntu precise
 main"" | sudo tee -a /etc/apt/sources.list.d/opencontrail.list
 sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys
 16BD83506839FE77
 sudo apt-get update
 # Install Contrail Control
 sudo apt-get install contrail-control
 You may execute the script to configure a node as the control node as shown here:
 $ sh 21_4_open_contrail_control_node.sh",NA
How it works...,"The control node orchestrates the OpenContrail cluster. You may receive the
 registration of control in discovery using the following command:
 $ curl http://127.0.0.1:5998/services
 The following command shows the control as a generator in the analytics API:
 $ curl http://127.0.0.1:8081/analytics/uves/generators | python -
 mjson.tool",NA
Configuring OpenContrail cluster,"The OpenContrail cluster requires configuration of an analytics node, configuration
 node, and a compute node in addition to the controller node that we configured in the
 previous recipe. In this recipe, we will configure OpenContrail cluster, which is
 composed of many components and sub-projects. Many of the platform tools and
 projects of OpenContrail are built in Python.
 Important!
 The following scripts need to be run in different servers than the
 controller (each on its own), otherwise they will add the same
 repository to the sources list multiple times, which may break your
 Ubuntu update manager. It is highly recommended to test these in
 virtual machines, unless you are confident of breaking and fixing.",NA
How to do it...,"First you need to download and configure the below services for the configuration
 node:
 Apache ZooKeeper, an open source server for a highly reliable distributed
 coordination: 
 https:/
 ​
 /
 ​
 zookeeper.
 ​
 apache.
 ​
 org/
 Apache Cassandra, a distributed open source NoSQL database
 management system: 
 http:/
 ​
 /
 ​
 cassandra.
 ​
 apache.
 ​
 org/
 RabbitMQ message broker: 
 https:/
 ​
 /
 ​
 www.
 ​
 rabbitmq.
 ​
 com/
 network time protocol
  (
 NTP
 ) for time synchronization: 
 http:/
 ​
 /
 ​
 www.
 ​
 ntp.
 org/
 The following script (
 21_5_open_contrail_configuration_node.sh
 ) configures
 a server as the configuration node:
 #!/bin/bash
 ######################################################################
 ########
 # Python Network Programming Cookbook, Second Edition -- Chapter - 12
 # Adopted from
 https://github.com/Juniper/contrail-controller/wiki/Install-and-Config
 ure-OpenContrail-1.06
 ######################################################################
 ########
 # Download and manually install python-support, as it is dropped from
 Ubuntu 16.04.
 wget
 http://launchpadlibrarian.net/109052632/python-support_1.0.15_all.deb
 sudo dpkg -i python-support_1.0.15_all.deb
 # Configuring the package list.
 echo ""deb http://ppa.launchpad.net/opencontrail/ppa/ubuntu precise
 main"" | sudo tee -a /etc/apt/sources.list.d/opencontrail.list
 sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys
 16BD83506839FE77
 echo ""deb http://debian.datastax.com/community stable main"" | sudo tee
 -a /etc/apt/sources.list.d/cassandra.sources.list
 curl -L http://debian.datastax.com/debian/repo_key | sudo apt-key add
 -
 # Run update
 sudo apt-get update
 # Install dependencies",NA
How it works...,"Make sure to set the host names correctly in 
 /etc/hosts
  as you start configuring
 OpenContrail nodes. Once you have configured the configuration node consisting of
 the API server, you may receive the list of tenants or projects by querying using the
 following command:
 $ curl http://127.0.0.1:8082/projects | python -mjson.tool
 You may receive the list of services and clients respectively that are consuming the
 services by the using the following RESTful invocations:
 $ curl http://127.0.0.1:5998/services
 $ curl http://127.0.0.1:5998/clients
 The analytics node provides the analytics API server. List of Contrail's generators can
 be found using the following command:
 $ curl http://127.0.0.1:8081/analytics/generators | python -mjson.tool
 Compute nodes perform the underlying computations of the Contrail cluster.",NA
Interacting with devices running Cisco,NA,NA
IOS XR,"Cisco IOS XR (
 http:/
 ​
 /
 ​
 www.
 ​
 cisco.
 ​
 com/
 ​
 c/
 ​
 en/
 ​
 us/
 ​
 products/
 ​
 ios-
 ​
 nx-
 ​
 os-
 ​
 software/
 ​
 ios-
 xr-
 ​
 software/
 ​
 index.
 ​
 html
 ) is a distributed network operating system for service
 providers. It supports many devices to provide a cloud scale networking. It is known
 as a self-healing distributed networking operating system.
 PyIOSXR
  (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 fooelisa/
 ​
 pyiosxr
 ) is a Python library used to
 manage the devices that are running IOS XR. In this recipe, we will install 
 pyIOSXR
 ,
 mock a network, and coordinate it with a Python program based on 
 pyIOSXR
 .",NA
Getting ready,"First install 
 pyIOSXR
 :
 $ sudo pip install pyIOSXR",NA
How to do it...,"Now you may connect to your device using Python as shown by the following code
 segment:
 from pyIOSXR import IOSXR
 device = IOSXR(hostname='lab001', username='ejasinska',
 password='passwd',
  port=22, timeout=120)
 device.open()
 You may test 
 pyIOSXR
  without an IOS XR device using the mock scripts provided by
 the project.
 Checkout the source code from the source repository:
 $ git clone https://github.com/fooelisa/pyiosxr.git
 $ cd test
 Now you may run 
 test.py
  to test the installation:
 $ python test.py
 ............................................
 --------------------------------------------
 Ran 44 tests in 0.043s
 OK",NA
How it works...,"The 
 test.py
  script gets the mock scripts consisting of 
 xml
  and 
 cfg
  files from the
 mock folder. 
 from pyIOSXR import IOSXR
  imports the relevant bundles for the
 management of IOS XR devices from the project. The mock files are converted by the
 test script to emulate the Cisco IOS XR devices.",NA
Collaborating with Cisco Spark API Cisco Spark Dashboard,"Cisco Spark (
 https:/
 ​
 /
 ​
 www.
 ​
 ciscospark.
 ​
 com/
 ​
 products/
 ​
 overview.
 ​
 html
 ) is a cloud-
 based collaboration platform from Cisco. It supports communication and
 collaboration from multiple devices for meetings, messages, and calls.
 ciscosparkapi
  (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 CiscoDevNet/
 ​
 ciscosparkapi
 ) is an open
 source project that offers a simple and compact Python-based API to Cisco Spark
 where all the operations can easily be performed with simple Python calls. In this
 recipe, we will configure 
 ciscosparkapi
 .
 Cisco Spark is available as a mobile, desktop, and web-based application (
 https:/
 ​
 /
 web.
 ​
 ciscospark.
 ​
 com/
 ​
 signin?
 ​
 mid=
 ​
 22237844097353833060667005765798180584
 ).
 Following is the web interface of Cisco Spark after signing in:",NA
Getting ready,"Install Spark API:
 $ sudo pip install ciscosparkapi",NA
How to do it...,"Execute the below recipe to create a new room and post a photo to it.
 Listing 12.7 gives a simple program that connects to the Cisco Spark cloud, creates a
 room, shares a textual message as well as a photo as follows:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition -- Chapter - 12
 # This program is optimized for Python 3.5.2 and Python 2.7.12.
 # It may run on any other version with/without modifications.
 from ciscosparkapi import CiscoSparkAPI
 api = CiscoSparkAPI()
 # Create a new demo room
 demo_room = api.rooms.create('ciscosparkapi Demonstration')
 print('Successfully Created the Room')
 # Post a message to the new room, and upload an image from a web url.
 api.messages.create(demo_room.id, text=""Welcome to the room!"",
 files=[""https://3.bp.blogspot.com/-wWHD9LVAI7c/WVeyurRmeDI/AAAAAAAADXc
 /CDY17VfYBdAMbI4GS6dGm2Tc4pHBvmpngCLcBGAs/
 s1600/IMG_4469.JPG""])
 print('Successfully Posted the Message and the Image to the Room')
 This program creates a room called 
 ciscosparkapi Desmonstration
  and posts the
 message 
 Welcome to the room!
 .
 Running the recipe produces the following output in the console and in the Cisco
 Spark as shown by the following screenshot:
 $ python 21_7_cisco_spark_api.py
 Successfully Created the Room
 Successfully Posted the Message and the Image to the Room",NA
How it works...,"ciscosparkapi
  wraps the public API of Spark communication platform to offer a
 Python-based interface to control and manage it. With the Spark access token, we
 may create rooms in our channel, delete existing rooms, post to the rooms, add
 colleagues to the room, and perform more activities
 —
 all from the Python program.",NA
22,NA,NA
NFV and Orchestration – A,NA,NA
Larger Ecosystem,"–
 In this chapter, we will cover the following recipes:
 Building VNFs with OPNFV
 Packet processing with DPDK
 Parsing BMP messages with SNAS.io
 Controlling drones with a wireless network
 Creating PNDA clusters",NA
Introduction,"Network softwarization brings software development aspects to networking. We
 discussed how SDN enables a logically centralized control to the data plane in
 previous chapters. In this chapter, we will look into the larger ecosystem of 
 Network
 Function Virtualization
  (
 NFV
 ) and orchestration.
 The Linux Foundation leads many open source networking and orchestration projects
 such as OPNFV, ONAP, PNDA, DPDK, SNAS, ODPi, and FD.io. We will look into
 how to use Python to extend these projects, and leverage them to build and
 orchestrate enterprise network solutions. While many of these are built with multiple
 languages, Python plays an important role in most of these projects as a tool for
 building and testing, if not as the coding language. We will look into how Python is
 used in configuring and installing these projects, while addressing common issues
 faced in configuring these enterprise-grade projects.",NA
Building VNFs with OPNFV,"Open Platform for NFV
  (
 OPNFV
 )
 (
 http://docs.opnfv.org/en/stable-danube/index.html
 ) is an open platform from
 the Linux Foundation to facilitate 
 Network Functions Virtualization
  (
 NFV
 ) across 
 various projects. Various network functions are virtualized and deployed as 
 Virtual
 Network Functions
  (
 VNFs
 ), with the support of NFV platforms such as OPNFV.
 OPNFV consists of many projects and features for 
 Network Function Virtualization
 Infrastructure
  (
 NFVI
 ).
 OPNFV can be installed using various installation tools: Compass, Fuel, TripleO from
 Apex, and Juju. More details on the installation alternatives can be found at
 https://www.opnfv.org/software/downloads/release-archives/danube-2-0
 . In
 this recipe, we will look in to installing OPNFV with Compass in detail. As a large-
 scale cross-layer project with many components, OPNFV is developed in multiple
 languages. Python is used in OPNFV for many scripts including configuration and
 installation actions. As we will learn from this recipe, installing and troubleshooting
 OPNFV requires a Python development environment and extensive experience in
 Python.",NA
Getting ready,"This recipe involves setting up the OPNFV Platform in bare-metal to build VNFs. We
 have slightly modified the 
 quickstart
  provided by OPNFV for it to work in a single
 script. This recipe requires downloading a few GB of image files. If you cannot
 download 20-30 GB in your current data plan, stop executing this recipe. If your disk
 space is running low, this may exhaust your remaining space with the configuration
 of OPNFV as well.",NA
How to do it...,"Install OPNFV in your computer by using the following script:
 $  sh 22_1_quickstart.sh
 Listing 13.1 is a script that invokes other commands to build and install OPNFV as
 follows:
 #!/bin/bash
 ##################################################
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 13
 ##################################################
 sudo apt-get update
 sudo apt-get install -y git
 # To offer the capability for sys-admins to
   restrict program capabilities
 #   with per-program profiles.
 sudo apt-get install -y apparmor
 # Pyyaml is a required package for the
   configuration scripts.
 sudo pip2 install pyyaml",NA
How it works...,"If the computer that you run this recipe does not have enough memory, it will
 produce these following logs during the last few steps:
 + sudo virsh start host4
 error: Failed to start domain host4
 error: internal error: early end of file from monitor,
 possible problem: 2017-07-18T16:29:50.376832Z
 qemu-system-x86_64: cannot set up guest memory
 'pc.ram': Cannot allocate memory",NA
Packet processing with DPDK,"Data Plane Development Kit
  (
 DPDK
 ) is a Linux Foundation project aimed to offer
 libraries and drivers for past packet processing for any processor. DPDK libraries can
 be used to implement 
 tcpdump
 —
 like packet capture algorithms, and send and
 receive packets fast and efficiently with usually less than 80 CPU cycles.
 True to its name, DPDK limits its focus to the data plane, and does not aim to provide
 a stack consisting of network functions. Thus, network middlebox actions such as
 security and firewalls as well as the layer 3 forwarding are not offered by DPDK by
 design. In this recipe, we will configure DPDK for a fast and efficient packet
 processing.
 DPDK is developed in C language though Python applications have been built on top
 of it. In this recipe, we will install DPDK and look into a simple Python application
 built with DPDK.",NA
Getting ready,"You may install DPDK in your computer by using the following script:
 $  sh 22_2_quickstart.sh
 This script will take a few minutes to configure and install DPDK, and produce the
 following lines when it completes its successful installation:
 ..
 Installation in /usr/local/ complete
 DPDK Installation Complete.
 The content of the script is described in detail in the following steps.
 Install 
 pcap
  dependencies, as DPDK depends on 
 pcap
  for the user level packet
 capture:
 $ sudo apt-get install libpcap-dev
 Failure to have pcap in your system will fail the build with the error
 message ""dpdk-stable-17.05.1/drivers/net/pcap/rte_eth_pcap.c:39:18:
 fatal error: pcap.h: No such file or directory""
 Download DPDK's latest stable version from 
 http://dpdk.org/download
 :
 $ wget http://fast.dpdk.org/rel/dpdk-17.05.1.tar.xz
 Extract and configure DPDK:
 $ tar -xvf dpdk-17.05.1.tar.xz
 $ cd dpdk-stable-17.05.1
 $ make config T=x86_64-native-linuxapp-gcc DESTDIR=install
 Configuration done
 Enable 
 pcap
  as the 
 pcap
  headers are required for the capture file format:
 $ sed -ri 's,(PMD_PCAP=).*,\1y,' build/.config
 You have two options to build. Option 1 is to build manually using make (which we
 also have used in our script), and option 2 is to build using the provided 
 dpdk-
 setup.sh
  script:
 Option 1
 :
       
 $ make
       
 ..
       
 == Build app/test-crypto-perf
     
     CC main.o",NA
How to do it...,"After the installation, you may test DPDK with the sample applications following the
 following command:
 $ make -C examples RTE_SDK=$(pwd) RTE_TARGET=build
 O=$(pwd)/build/examples
 usertools
  consists of a few utility bundles written in Python. For example, running
 cpu_layout.py
  produces the following output in my computer:
 $ cd usertools
 $ python cpu_layout.py
 ===============================================
 Core and Socket Information (as reported by '/sys/devices/system/cpu')
 ===============================================
 cores =  [0, 1, 2, 3]
 sockets =  [0]
     
    Socket 0
     
    --------
 Core 0 [0, 1]
 Core 1 [2, 3]
 Core 2 [4, 5]
 Core 3 [6, 7]
 This reports the layout of the quad cores of my laptop. You may receive similar
 output based on your system.
 More networking examples or utility tools can be found inside the folder
 build/examples
 . More products are built extending or leveraging DPDK. Cisco
 TRex is a traffic generator developed in C and Python, on top of DPDK. You may
 configure it locally using the following commands:
 $ wget http://trex-tgn.cisco.com/trex/release/latest
 $ tar -xvf latest
 $ cd v2.27/
 Inside the 
 v2.27
  folder, you will find the Python scripts to execute TRex based on
 DPDK. For example, you may start the master daemon using Python as follows:
 $ sudo python master_daemon.py start
 Master daemon is started
 $ sudo python master_daemon.py show
 Master daemon is running",NA
How it works...,"DPDK is a set of libraries and modules for developing the data plane. It exploits many
 popular tools and projects such as 
 pcap
  to capture the packets. Many of its user tools
 and configuration scripts are written in Python, and a few libraries written in Python
 to extend DPDK. The DPDK example applications found in 
 build/examples
 leverage the core of DPDK to program the data plane.
 The bundled example applications are (as named by DPDK) 
 bond
 , 
 ethtool
 ,
 ip_pipeline
 , 
 kni, l2fwd-jobstats
 , 
 l3fwd-acl
 , 
 link_status_interrupt
 ,
 netmap_compat
 , 
 qos_meter
 , 
 rxtx_callbacks
 , 
 tep_termination
 , 
 vmdq,
 cmdline
 , 
 exception_path
 , 
 ipsec-secgw
 , 
 l2fwd, l2fwd-keepalive
 , 
 l3fwd-
 power
 , 
 load_balancer
 , 
 packet_ordering
 , 
 qos_sched
 , 
 server_node_efd
 ,
 timer, vmdq_dcb
 , 
 distributor
 , 
 helloworld
 , 
 ipv4_multicast
 , 
 l2fwd-crypto
 ,
 l3fwd, l3fwd-vf
 , 
 multi_process
 , 
 performance-thread
 , 
 quota_watermark
 ,
 skeleton
 , 
 vhost
 , and 
 vm_power_manager
 .",NA
Parsing BMP messages with SNAS.io,"Streaming Network Analytics System
  (
 SNAS
 ) or commonly known as SNAS.io is a
 Linux Foundation project that consists of a framework and libraries to track and
 access a large number of routing objects including routers, peers, and prefixes in real
 time. Formerly known as OpenBMP, SNAS implements BMP message bus
 specification. BMP refers to BGP monitoring protocol and by implementing the BMP
 protocol, SNAS communicates with the BMP devices such as routers.
 SNAS has a Python API that lets you develop Python applications on top of SNAS for
 BMP messages. SNAS also consists of an 
 mrt2bmp
  converter developed in Python,
 which reads the routers' 
 MRT
  (
 Multi-threaded Routing Toolkit
 ) files and sends BMP
 messages simultaneously. This SNAS conversion workflow is: 
 Router
  | 
 MRT
  |
 MRT2BMP
  | 
 OpenBMP collector
  | 
 Kafka message bus
  | 
 MySQL consumer
 . You 
 may find more information on these projects at 
 https://github.com/OpenBMP
 .",NA
Getting ready,"First install and configure the Apache Kafka and SNAS library for parsing OpenBMP
 Kafka messages:
 $ sh 22_3_install.sh
 #!/bin/bash
 #########################################################
 # Python Network Programming Cookbook, Second Edition -- Chapter - 13
 #########################################################
 # Install Dependencies
 sudo apt-get install python-dev python-pip libsnappy-dev
 sudo pip install python-snappy kafka-python pyyaml
 # Install SNAS Python API
 git clone https://github.com/OpenBMP/openbmp-python-api-message.git
 cd openbmp-python-api-message
 sudo pip install .
 # Go back to the root directory.
 cd ..
 # Download Apache Kafka
 wget http://apache.belnet.be/kafka/0.11.0.0/kafka_2.11-0.11.0.0.tgz
 tar -xzf kafka_2.11-0.11.0.0.tgz
 Follow the preceding installation script once to download the dependencies, SNAS,
 and Kafka. Use the following script to quick-start Kafka Server:
 $ sh 22_3 quickstart.sh
 #!/bin/bash
 ###############################################
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 13
 ###############################################
 # Start Zookeeper. To view the logs real time,
   in a terminal: ""tail -f zk-server.out"".
 nohup kafka_2.11-0.11.0.0/bin/zookeeper-server-start.sh
 kafka_2.11-0.11.0.0/config/zookeeper.properties >
 zk-server.out &
 # Start Kafka-Server. To view the logs real time, in a
 terminal: ""tail -f kafka-server.out"".
 nohup kafka_2.11-0.11.0.0/bin/kafka-server-start.sh
 kafka_2.11-0.11.0.0/config/server.properties >
 kafka-server.out &",NA
How to do it...,"Once you have installed the SNAS BMP message API and started ZooKeeper server
 and Kafka server as shown previously, you are ready to run a simple listener for the
 BMP messages.
 First, start the Python client of the SNAS message API:
 $ python 22_3_log_consumer.py
 Connecting to kafka... takes a minute to load offsets and topics,
 please wait
 Now consuming/waiting for messages...
 22_3_snas_log_consumer.py is adopted from openbmp-python-api-
 message/examples/log_consumer.py.
 Now, if you run the following from another Terminal and send an empty message
 using the 
 Enter
  key in your keyboard:
 $ kafka_2.11-0.11.0.0/bin/kafka-console-producer.sh --broker-list
 localhost:9092 --topic openbmp.parsed.router
 >
 >
 You will receive the following message:
 $ python 22_3_snas_log_consumer.py --conf=""config.yaml""
 Connecting to kafka... takes a minute to load offsets and topics,
 please wait
 Now consuming/waiting for messages...
 Received Message (2017-07-21 12:17:53.536705) : ROUTER(V: 0.0)
 []",NA
How it works...,"First the nine topics of BMP messages are defined and the SNAS log consumer
 program subscribes to them through the Kafka broker. The BMP parsed messages
 include notifications of 
 router
 , 
 peer
 , 
 collector
 , 
 bmp_stat
 , 
 unicast_prefix
 ,
 l3vpn
 , 
 ls_node
 , 
 ls_link
 , and 
 ls_prefix
 . Once started, the log consumer waits for
 messages on one of these nine topics. When you connect 
 kafka-console-
 producer.sh
 , you may send messages to the broker. However, the messages will not
 reach the log consumer unless they are of one of the nine topics. You may emulate the
 BMP messages by starting the 
 kafka-console-producer.sh
  with one of the topics,
 as we did in the example with 
 --topic openbmp.parsed.router
  flag. The
 received messages for these subscribed topics are pretty printed using
 to_json_pretty()
  in an if-else loop for each of these topics.",NA
Controlling drones with a wireless,NA,NA
network,"Drones are used more ubiquitously these days with controllers capable to control
 them from ground through TCP or UDP messages in a wireless network. 
 Dronecode
 offers a platform to control and program drones, with a simulation environment to
 sandbox the developments. Developed in Python, Dronecode is managed by the
 Linux Foundation. In this recipe, we will run a simplest of drone simulation. More
 interesting recipes can be learned by following their website
 (
 https://www.dronecode.org
 ).",NA
Getting ready,"Dronekit requires Python 2.7 to run. Install the Dronekit and Dronekit 
 Software in
 the Loop
  (
 SITL
 ) Simulator using Python 
 pip
 :
 $ pip install dronekit
 $ pip install dronekit-sitl",NA
How to do it...,"In this recipe, we will simulate a simple drone with 
 dronekit-sitl
 . The simulator
 API is compatible with the Dronekit API that actually controls the drones. Hence, you
 may develop once and run in simulation and production very easily, as with our
 previous recipes on Mininet emulation.
 First, run the 
 dronekit-sitl
  in a Terminal before running
 22_4_dronekit_sitl_simulation.py
 :
 $ dronekit-sitl copter-3.3 --home=-45.12,149.22,544.55,343.55
 os: linux, apm: copter, release: 3.3
 SITL already Downloaded and Extracted.
 Ready to boot.
 Execute: /home/pradeeban/.dronekit/sitl/copter-3.3/apm --
 home=-45.12,149.22,544.55,343.55 --model=quad
 Started model quad at -45.12,149.22,544.55,343.55 at speed 1.0
 bind port 5760 for 0
 Starting sketch 'ArduCopter'
 Serial port 0 on TCP port 5760
 Starting SITL input
 Waiting for connection ....",NA
How it works...,"This recipe initializes a simple drone and prints its status. You may execute it to set its
 parameters and modify its values dynamically. More examples on Dronekit can be
 found at 
 http://python.dronekit.io/examples/
 .",NA
Creating PNDA clusters,"PNDA (
 http://pnda.io/
 ) is a scalable big data analytics platform for networks and
 services from the Linux Foundation. PNDA requires a cluster to run efficiently.
 PNDA offers Python scripts
 (
 https://github.com/pndaproject/pnda-aws-templates
 ) to deploy it over Amazon
 EC2.",NA
Getting ready,"Create an S3 bucket from
 https://s3.console.aws.amazon.com/s3/home?region=eu-west-1
 . We are using 
 EU
 (Ireland)
  as our default region for this recipe. PNDA applications will be hosted in
 this bucket. Replace the 
 pnda-apps
  with the name of your S3 bucket. Since the
 bucket names are shared across all the users in the region, you may not be able to use
 pnda-apps
  as your 
 Bucket name
  as it would already have been used by someone:
   # S3 container to use for PNDA application packages
   PNDA_APPS_CONTAINER: pnda-apps",NA
How to do it...,"Now you may create a PNDA cluster with the commands:
 $ cd cli
 $ python pnda-cli.py create -e <cluster_name> -s <key_name> -f
 standard -o {no-of-tsdb-instances} -n {no-of-hadoop-data-nodes} -k
 {no-of-kafka-brokers} -z {no-of-zookeeper-nodes}
 Replace the names accordingly. For example:
 $ python pnda-cli.py create -e pnda -s key -f standard -o 2 -n 3 -k 2
 -z 3
 Or with just one instance for each:
 $ python pnda-cli.py create -e pnda -s key -f standard -o 1 -n 1 -k 1
 -z 1",NA
How it works...,"In this recipe, 
 pnda-cli.py
  first checks whether the 
 pnda_env.yaml
  file exists, and
 reads the parameters from it. It uses boto's EC2 interface
 (
 http://boto.cloudhackers.com/en/latest/ec2_tut.html
 ) to run many tasks such
 as connecting to the region, initializing the EC2 instances, and configuring them.
 Expect this to take a few minutes, also depending on the connectivity between your
 mirror and the EC2 instance. Thus it might be a good idea to actually create your
 PNDA cluster in a region that is closest to you to minimize the latency.
 In this recipe, we learned how to configure PNDA in AWS. In this process, we also
 learned how useful Python can be for such complex configuration tasks as we used it
 to read the 
 .yaml
  configuration file and configure an AWS cluster based on our
 configurations.",NA
23,NA,NA
Programming the Internet,"In this chapter, we will cover the following recipes:
 Checking a website status
 Benchmarking BGP implementations with bgperf
 BGP with ExaBGP
 Looking glass implementations with Python
 Understanding the internet ecosystem with Python
 Establishing BGP connections with yabgp",NA
Introduction,"Autonomous Systems
  (
 ASes
 ) make the internet. Communications between the ASes
 are handled through implementations of protocols known as 
 Exterior Gateway
 Protocols
  (
 EGP
 ). 
 Border Gateway Protocol
  (
 BGP
 ) is a standardized EGP, designed
 for exchanging routing and reachability information between the ASes. In this
 chapter, we will look into Python libraries for BGP such as 
 exabgp
  and 
 yabgp
 , and
 how to program the internet with Python.",NA
Checking a website status,"A website may be down as its connectivity to the rest of the internet is broken in some
 way. We start this chapter by checking the status of a website. Though this is a very
 simple exercise done with just Python, this can be extended as a health monitor
 application for more complex scenarios on the internet.",NA
Getting ready,"This function tests the connectivity of a website by a given address or a 
 fully
 qualified domain name
  (
 FQDN
 ) and port (default 
 80
  assumed). When a domain
 name is passed as an address, the 
 socket.connect()
  method resolves it.",NA
How to do it...,"Here we will look into a simple recipe that performs this action, as indicated by
 listing 14.1:
 #!/usr/bin/env python
 # Python Network Programming Cookbook, Second Edition
   -- Chapter - 14
 # This program is optimized for Python 2.7.12 and
   Python 3.5.2.
 # It may run on any other version with/without modifications.
 import socket
 from sys import stdout
 from time import sleep
 import argparse
 def is_alive(address, port):
     # Create a socket object to connect with
     s = socket.socket()
     # Now try connecting, passing in a tuple with
       address & port
     try:
         s.connect((address, port))
         return True
     except socket.error:
         return False
     finally:
         s.close()
 def confirm(addres, port):
     while True:
         if is_alive(address, port):
             stdout.write(address + "":"" +
             str(port) + ' is alive\n')
             stdout.flush()
         else:
             stdout.write(address + "":"" +
             str(port) + ' is dead\n')
             stdout.flush()
         sleep(10)",NA
How it works...,"This program checks the website periodically to see if it is up, and prints the log
 accordingly. If the website is down, it will notify the same, in the time intervals.",NA
Benchmarking BGP implementations with,NA,NA
bgperf,"In this recipe, we aim to introduce BGP implementations with Python through a
 simple benchmarking project, as a simple exercise. We will benchmark a few BGP
 implementations with 
 bgpert
 , a Python-based benchmarking tool for BGP
 implementations.",NA
Getting ready,"To install 
 bgperf
 , clone the source code from its source repository:
 $ git clone https://github.com/pradeeban/bgperf.git",NA
How to do it...,"Once you have configured 
 bgperf
 , you will be able to benchmark the BGP
 implementations.
 For example:
 $ sudo python3 bgperf.py bench
 run tester
 tester booting.. (100/100)
 run gobgp
 elapsed: 16sec, cpu: 0.20%, mem: 580.90MB
 elapsed time: 11sec",NA
How it works...,"This recipe looks into the common BGP implementations and benchmarks them
 through the 
 bgperf
  open source project. In the rest of the chapters, we will look at
 some BGP implementations.",NA
BGP with ExaBGP,"ExaBGP (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 Exa-
 ​
 Networks/
 ​
 exabgp
 ) facilitates convenient
 implementation of SDN by converting BGP messages into plain text or JSON formats.",NA
Getting ready,"Install ExaBGP using 
 pip
 :
 $ sudo pip install exabgp
 Generate the environment file by using the following command:
 $ sudo su
 $ mkdir /etc/exabgp
 $ exabgp --fi >/etc/exabgp/exabgp.env",NA
How to do it...,"Now you have installed ExaBGP in your computer. You may explore its command
 using its 
 help
  flag:
 $ exabgp -help",NA
Looking glass implementations with,NA,NA
Python Looking Glass of BIX.bg,"Internet Exchange Points
  (
 IXPs
 ) are the backbones of the internet, as they offer easy
 connectivity between the 
 Autonomous Systems
  (
 ASes
 ) of the internet. The 
 looking
 glass
  (
 lg
 ) implementation is a commonly deployed software in the IXPs. They can be
 used to trace how an IXP can reach any given IP address on the internet. The lg
 implementations are made public such that anyone can use it to trace how to connect
 to a given IP address, thus offering an emulation environment to test the connectivity
 and performance of an IXP for the service providers before committing to use an IXP
 for their own connectivity needs.
 BIX is an IXP based in Bulgaria. You may access the lg of 
 Bulgarian Internet
 Exchange
  (
 BIX
 ) at 
 http:/
 ​
 /
 ​
 lg.
 ​
 bix.
 ​
 bg/
 ​
 . For example, see the output of the query from
 your browser: 
 http:/
 ​
 /
 ​
 lg.
 ​
 bix.
 ​
 bg/
 ​
 ?
 ​
 query=
 ​
 summary
 ​
 addr=
 ​
 216.
 ​
 146.
 ​
 35.
 ​
 35
 ​
 router=
 ​
 rs1.
 bix.
 ​
 bg+%28IPv6%29
  for the IP (IPv6) BGP summary of 
 216.146.35.35
  (
 http:/
 ​
 /
 ​
 dyn.
 com/
 ​
 labs/
 ​
 dyn-
 ​
 internet-
 ​
 guide/
 ​
 ). The output of this query is shown in the following
 screenshot:",NA
Getting ready,"There are more Python-based applications that offer a complete DNS looking glass
 solution. Dyn 
 dns_lg
  (
 https:/
 ​
 /
 ​
 github.
 ​
 com/
 ​
 dyninc/
 ​
 dns_
 ​
 lg
 ) is a DNS looking glass
 solution that depends on 
 ldns
  (
 http:/
 ​
 /
 ​
 www.
 ​
 linuxfromscratch.
 ​
 org/
 ​
 blfs/
 ​
 view/
 ​
 cvs/
 basicnet/
 ​
 ldns.
 ​
 html
 ), a fast and efficient DNS library and 
 ldns-python
  package.
 ldns
  depends on SWIG interface compiler (
 http:/
 ​
 /
 ​
 www.
 ​
 swig.
 ​
 org
 ) to connect its core
 modules developed in C and Python code used. Make sure you have SWIG installed
 on your computer:
 You may install it using the following command in Ubuntu/Debian-based
 1.
 systems:
       $ sudo apt-get install swig
 Download the source of 
 ldns
  using the following command:
 2.
       $ wget -nc http://www.nlnetlabs.nl/downloads/
         ldns/ldns-1.7.0.tar.gz",NA
How to do it...,"As you have installed 
 ldns
 , now you may check out the Dyn's 
 dns_lg
  source code
 from its source code repository:
 git clone git@github.com:dyninc/dns_lg.git
 cd dns_lg/
 Now, you may run the application simply by executing 
 api.py
 . Running it produces
 the following output:
 $ python api.py
 * Running on http://0.0.0.0:8185/
  (Press CTRL+C to quit)
 Now open another console window to run a 
 curl
 :
 curl http://0.0.0.0:8185/cnn.com/
 This will output a line to the preceding 
 api.py
  console:
 127.0.0.1 - - [15/Jul/2017 23:33:40]
 ""GET /cnn.com/ HTTP/1.1"" 200 -",NA
How it works...,"Looking glass offers you an opportunity to see how you can connect to another part
 of the internet through the routers of any given IXP. Similar to the functionality of
 traceroute
 , lg implementations show you the connectivity in the internet scale.
 They are deployed by the IXPs to demonstrate the IXP performance to the potential
 customers.",NA
Understanding the internet ecosystem,NA,NA
with Python,"When network traffic is sent to the internet, it passes through various ASes and IXPs.
 Tools such as 
 traceroute
  and 
 tcptraceroute
  can be used to trace how a particular
 network node in the internet can be accessed from your computer through your
 internet provider. Various tools developed in Python can be used to understand the
 nature of the internet. traIXroute (
 https:/
 ​
 /
 ​
 pypi.
 ​
 python.
 ​
 org/
 ​
 pypi/
 ​
 traixroute
 ) is a
 tool developed on Python 3, which identifies the IXPs on the 
 traceroute
  path.",NA
Getting ready,"You may install traIXroute through 
 pip
 :
 $ sudo pip install traixroute
 To measure the performance and topologies of the internet, you also need to install
 scamper (
 https:/
 ​
 /
 ​
 www.
 ​
 caida.
 ​
 org/
 ​
 tools/
 ​
 measurement/
 ​
 scamper/
 ​
 ), a parallel
 measurement utility for the internet:
 $ sudo scamper-install
 Your traIXroute is now ready to analyze the internet connectivity through the IXPs.
 You may confirm your successful install by running the 
 --help
  command, which
 will produce the output as follows:
 $ traixroute --help
 usage: traixroute [-h] [-dns] [-asn] [-db] [-rule] [-u] [-m] [-o
 OUTPUT] [-v]
     
              {probe,ripe,import} ...
 positional arguments:
   
 {probe,ripe,import}
     
 probe               probe --help
     
 ripe                ripe --help
     
 import              import --help
 optional arguments:
   
 -h, --help                show this help message and exit
   
 -dns, --enable-dns-print
     
                         Enables printing the domain name
  of each IP hop in the
  
 traceroute path.
   
 -asn, --enable-asn-print
     
                         Enables printing the ASN of
  each IP hop in the
  
 traceroute path.
     
   -db, --store-database
     
                         Enables printing the database information.
     
   -rule, --enable-rule-print
     
                         Enables printing the hit IXP detection
 rule(s) in the
  
 traceroute path.
     
   -u, --update          Updates the database with up-to-date
 datasets.
     
   -m, --merge           Exports the database to distinct files,
 the
  
 ixp_prefixes.txt and ixp_membership.txt.
     
   -o OUTPUT, --output OUTPUT
     
                         Specifies the output file name to redirect
 the
  
 traIXroute results.
     
   -v, --version         show program's version number and exit",NA
How to do it...,"Now you may run 
 traixroute
  to see the IXPs in your path. Running 
 traixroute
 for the first time takes a few minutes, as it has to perform a few initialization actions,
 downloading the datasets:
 $ traixroute probe -dest cnn.com -s=""-m 12""
 Dataset files are missing.
 Updating the database...
 Started downloading PDB dataset.
 Started downloading PCH dataset.
 Started downloading RouteViews dataset.
 Routeviews has been updated successfully.
 PDB dataset has been updated successfully.
 PCH dataset has been updated successfully.
 Database has been updated successfully.
 Imported 13 IXP Detection Rules from /configuration/rules.txt.
 Loading from PCH, PDB, Routeviews and additional_info.txt.
 traIXroute using scamper with ""-m 12"" options.
 [15:08:06:001] scamper_privsep_init: could not mkdir /var/empty:
 Permission denied
 Scamper failed. Trying to run with sudo..
 [sudo] password for pradeeban:
 traIXroute to cnn.com (151.101.1.67).
 1)     (62.4.224.1) 15.465 ms
 2)     (91.183.241.176) 18.642 ms
 3)     (91.183.246.112) 12.178 ms
 4)     (62.115.40.97) 20.216 ms
 5)     (213.155.136.216) 20.027 ms
 6)     (80.91.253.163) 12.127 ms
 7)     (*) -
 8)     (*) -
 9)     (*) -
 10)    (*) -
 11)    (*) -
 This did not indicate any IXP in the path between my network and 
 http:/
 ​
 /
 ​
 edition.
 cnn.
 ​
 com/
 ​
 . Let's try once more towards 
 register.bg
 :
 $ sudo traixroute probe -dest register.bg -s=""-m 12""
 Imported 13 IXP Detection Rules from /configuration/rules.txt.
 Loading from Database.
 traIXroute using scamper with ""-m 12"" options.
 traIXroute to register.bg (192.92.129.35).
 1)     (62.4.224.1) 21.699 ms
 2)     (91.183.241.176) 7.769 ms
 3)     (91.183.246.114) 8.056 ms",NA
How it works...,"The 
 -m
  flag indicates the maximum 
 time-to-live
  (
 TTL
 ) between the hops. The 
 *
  in the
 output logs indicates failure to trace a node within the given TTL, as no response was
 received. The 
 -m
  flag dictates the maximum number of hops to be traced. It can be a
 value between 1 and 255, with 1 producing just 1 hop in between, where 255
 produces up to 255 hops towards the end point. However, note that it is unlikely to
 have such a long path in the internet, and if exists, it is even more unlikely to retrieve
 the exact IP addresses through 
 traceroute
  or 
 traixroute
  (you will more likely
 receive 
 *
  for the latter hops).",NA
Establishing BGP connections with,NA,NA
yabgp,"Yabgp is a Python implementation for BGP protocol that supports establishing BGP
 connections from various routers. It can be used for various advanced use cases such
 as future analysis. In this recipe, we will install 
 yabgp
  using 
 virtualenv
  virtual
 environment for Python programs.",NA
Getting ready,"First, get the sources of 
 yabgp
 :
 $ git clone https://github.com/smartbgp/yabgp
 Now to build 
 yabgp
 :
 $ cd yabgp
 Install the requirements following this command, and observe the following logs:
 $ pip install -r requirements.txt
 ..
 Successfully installed Twisted Flask Flask-HTTPAuth netaddr
 zope.interface Werkzeug Jinja2 itsdangerous MarkupSafe
 Cleaning up...
 Now you may confirm the correct installation of 
 yabgpd
  by using the following
 command:
 $ cd bin
 $ python yabgpd -h
 This will output detailed help information on 
 yabgpd
 .",NA
How to do it...,"yabgpd
  is a BGP agent that can orchestrate the BGP routers. You may start the agent
 as a Python application. Make sure to update the correct values for the BGP local and
 remote addresses, and the local and remote BGP autonomous system values. The
 program will print a set of log lines as follows:
 $ python yabgpd --bgp-local_addr=172.31.0.232 --bgp-local_as=23650 \
 --bgp-remote_addr=52.58.130.47 --bgp-remote_as=23650
 2017-07-16 16:19:05,837.837 78465 INFO yabgp.agent [-] Log (Re)opened.
 2017-07-16 16:19:05,837.837 78465 INFO yabgp.agent [-] Configuration:
 2017-07-16 16:19:05,837.837 78465 INFO yabgp.agent [-]
 ******************************************************
 2017-07-16 16:19:05,837.837 78465 INFO yabgp.agent [-] Configuration
 options gathered from:
 2017-07-16 16:19:05,837.837 78465 INFO yabgp.agent [-] command line
 args: ['--bgp-local_addr=172.31.0.232', '--bgp-local_as=23650', '--
 bgp-remote_addr=10.124.1.245', '--bgp-remote_as=23650']
 2017-07-16 16:19:05,837.837 78465 INFO yabgp.agent [-] config files:
 []",NA
How it works...,"yabgpd
  is a BGP agent that can establish BGP connections with various routers. The
 agent receives the BGP messages and is capable of using them for further uses, such
 as future analysis. Running these applications require access to BGP routers to route
 traffic between the autonomous systems. These recipes illustrate the capability of
 Python to build large-scale complex network applications in the internet scale.",NA
Other Books You May Enjoy,"If you enjoyed this book, you may be interested in these other books by Packt:
 Network Analysis using Wireshark 2 Cookbook - Second Edition
 Nagendra Kumar Nainar, Yogesh Ramdoss, Yoram Orzach
 ISBN: 978-1-78646-167-4
 Configure Wireshark 2 for effective network analysis and
 troubleshooting
 Set up various display and capture filters
 Understand networking layers, including IPv4 and IPv6 analysis
 Explore performance issues in TCP/IP
 Get to know about Wi-Fi testing and how to resolve problems
 related to wireless LANs
 Get information about network phenomena, events, and errors
 Locate faults in detecting security failures and breaches in
 networks",NA
Leave a review - let other readers know,NA,NA
what you think,"Please share your thoughts on this book with others by leaving a review on the site
 that you bought it from. If you purchased the book from Amazon, please leave us an
 honest review on this book's Amazon page. This is vital so that other potential
 readers can see and use your unbiased opinion to make purchasing decisions, we can
 understand what our customers think about our products, and our authors can see
 your feedback on the title that they have worked with Packt to create. It will only take
 a few minutes of your time, but is valuable to other potential customers, our authors,
 and Packt. Thank you!",NA
Index,NA,NA
A,"Access Control Lists (ACLs)  
 11
 , 
 316
 Access Point (AP)  
 86
 action plugin
    reference  
 288
 Amazon Elastic Compute Cloud (EC2)
    about  
 303
    reference  
 303
 Amazon GuardDuty
    about  
 324
    reference  
 324
 Amazon Resource Names (ARNs)
    about  
 303
    reference  
 303
 Amazon S3 web service
    SOAP methods, searching  
 567
 , 
 569
 Amazon Virtual Private Cloud (Amazon VPC) 
 303
 Amazon Web Services (AWS)  
 114
    about  
 292
    reference  
 292
 , 
 293
 , 
 295
    setting up  
 293
 , 
 295
 Amazon
    books, searching through product search API 
 569
 , 
 572
 Ansible Galaxy
    about  
 286
    reference  
 286
 Ansible Jinja2 template
    reference  
 245
 Ansible playbook
    about  
 229
 , 
 231
 , 
 232
 , 
 233
    inventory file  
 230
 , 
 231
    public key authorization  
 229
 Ansible Vault
    about  
 278
 , 
 279
 , 
 280
    reference  
 278
 , 
 279
 Ansible, advantages
    about  
 233
    agentless  
 233
 , 
 234
    extensible  
 235
    idempotent  
 234
    network vendor support  
 236
 , 
 237
    simplification  
 235
 Ansible
    about  
 224
 , 
 225
    architecture  
 237
    Arista example  
 255
    Cisco example  
 248
    conditional statements  
 259
    connection example  
 251
    control node installation  
 226
    different versions, executing from source 
 227
 , 
 228
    example  
 225
    include statement  
 281
 , 
 282
    Juniper example  
 253
    loops  
 266
    networking modules  
 245
    reference  
 225
 , 
 226
 , 
 251
    roles  
 281
 , 
 282
 , 
 284
 , 
 285
    setting up  
 228
 Apache 2  
 427
 Apache Cassandra
    URL  
 672
 Apache ZooKeeper
    URL  
 672
 Apache
    configuring, remotely to host website  
 546
 ,
 549
 API structured output
    versus screen scraping  
 183
 , 
 184
 , 
 185
 , 
 186
 Application Centric Infrastructure (ACI)  
 128
 ,",NA
B,"bandwidth
    saving, in web requests with HTTP
 compression  
 472
 , 
 475
 bitbucket
    references  
 460
 BMP messages
    parsing, with SNAS.io  
 694
 , 
 700
 Border Gateway Protocol (BGP)  
 78
 Boto3 VPC API
    reference  
 308
 Boto3
    reference  
 298",NA
C,"Cisco API
    about  
 188
    Cisco NX-API  
 189
    YANG models  
 195
 Cisco Application Centric Infrastructure (ACI)
    about  
 188
 , 
 196
 , 
 197
 , 
 198",NA
D,"Data Center Networking (DCN)  
 147
 data model
    about  
 187
    reference  
 187
 data modeling
    for infrastructure as code  
 187
 , 
 188
 Data Plane Development Kit (DPDK)
    packet, processing  
 690
 , 
 694
    URL  
 691
 data types
    about  
 38
    datetime  
 14
    float  
 14
    integer  
 14",NA
E,"eAPI  
 123
 Elastic IP (EIP)
    about  
 316
    reference  
 317
 Emulated Virtual Environment Next Generation
 (EVE-NG)
    reference  
 157
 Endpoint Groups (EPGs)  
 128
 Endpoints (EPs)  
 128
 Equinix Cloud Exchange
    reference  
 321
 Eve
    used, for authenticating REST APIs  
 650
 Extended Markup Language (XML)  
 32
 Extensible Markup Language (XML)  
 199
 Extensible Operating System (EOS)  
 123",NA
F,"Fabric
    URL  
 536
 files
    transferring, to remote machine over SSH 
 543
 , 
 546
 Flask
    RESTful web applications, creating  
 572
 , 
 576
 Flickr
    photo information, collecting with REST  
 563
 ,
 567
 for next loop  
 46
 FreeIPA
    references  
 640
 functions
    about  
 19
 , 
 51
    passing arguments, from command line  
 57",NA
G,"Git, terminology
    branch  
 329
    checkout  
 329
    commit  
 329
    fetch  
 329
    merge  
 329
    pull  
 329
    ref  
 329
    repository  
 329
    tag  
 329
 Git, with Python
    about  
 348
    GitPython  
 348
    PyGitHub  
 349
 , 
 351
 Git
    about  
 327
    benefits  
 328
    collaboration technology  
 354
    examples  
 333
 , 
 334
 , 
 335
 , 
 337
 , 
 338
 , 
 340",NA
H,"HEAD requests
    web page existence, checking  
 468
 , 
 470
 host variables
    about  
 275
 , 
 277
    reference  
 276
 hosts
    pinging, on network with ICMP  
 420
 , 
 425
 HTTP authentication
    XML-RPC server, executing  
 558
 , 
 562
 HTTP compression
    bandwidth, saving in web requests  
 472
 , 
 475
 HTTP fail-over client
    writing, with partial downloading  
 475
    writing, with resume downloading  
 475
 HTTP packets
    header, adding  
 586
 , 
 588
 HTTP requests
    serving  
 457
 , 
 459
 , 
 463
 HTTP server
    data, downloading  
 453
 , 
 456
 HTTPS server code
    writing, with OpenSSL  
 478
    writing, with Python  
 478
 , 
 480",NA
I,"ICMP
    hosts, pinging on network  
 420
 , 
 425
 idempotence
    reference  
 234
 idempotency  
 178
 , 
 179
 Identify and Access Management (IAM)
    about  
 302
    reference  
 302
 inactive machines
    detecting, on network  
 435
 include statement, Ansible  
 281
 , 
 282
 infrastructure as code
    about  
 181
    data modeling  
 187
 , 
 188
    Intent-Driven Networking  
 182
    screen scraping, versus API structured output 
 183
 , 
 184
 , 
 185
 , 
 186
 Infrastructure-as-a-Service (IaaS)
    reference  
 292
 Integrated Development Environments (IDEs) 
 26
 Intent-Based Networking  
 182
 Intent-Driven Networking  
 182
 interfaces
    enumerating, on machine  
 429
 , 
 430
    IP address, obtaining  
 431
    status, discovering  
 433
 internet service provider (ISP)  
 121
 inventory file
    about  
 230
    reference  
 230
 inventory, Ansible
    about  
 239
 , 
 240
    reference  
 240
 ios_command module
    reference  
 246
 IP Address Management (IPAM)
    accessing  
 94
 IP address",NA
J,"JavaScript Object Notation (JSON)  
 32
 Jinja2 template
    about  
 271
    reference  
 270
 Jinja2
    about  
 245
    conditional statement  
 273
 , 
 274
 , 
 275
    loops  
 272
    reference  
 245
    templates  
 245
 JSON-RPC  
 209
 jsonrpclib
    reference  
 212
 Juniper Contrail Server Manager
    configuring  
 665
 , 
 669
    URL  
 665
 Juniper networks
    Network Configuration Protocol (NETCONF) 
 199
 , 
 200
    PyEZ  
 204
    Python API  
 198
 Juniper Networks
    URL  
 665
 Juniper Olive  
 200
 Juniper vMX
    reference  
 158
 Jupyter Notebook
    URL  
 662",NA
K,"Kafka Manager
    URL  
 662",NA
L,"large data center  
 209
 LDAP bind
    creating  
 645
 Lightweight Directory Access Protocol (LDAP)
    reading  
 647
    server, connecting  
 639
    server, connecting to  
 639
    writing  
 647
 Linux Foundation
    URL  
 684
 local port
    forwarding, to remote host  
 416
 , 
 419
 , 
 420
 local XML-RPC server
    querying  
 552
 , 
 555
 loop
    about  
 17
 , 
 42
 , 
 46
    for next loop  
 46
    while loop  
 48
 loops, Ansible
    about  
 266
    over dictionaries  
 267
 , 
 268
 , 
 269
    reference  
 269
    standard loops  
 266
 , 
 267",NA
M,"Maxinet
    distributed network, emulation  
 606
 , 
 609
    URL  
 604
 Mininet-WiFi
    URL  
 610
    wireless networks, emulating  
 610
 , 
 614
 Mininet
    extending, to emulate containers  
 615
 , 
 621
    networks, emulating  
 603
    URL  
 604
 mobile ad hoc network (MANET)  
 610
 modules, Ansible
    reference  
 230
 Mozilla Firefox",NA
N,"NAPALM
    reference  
 220
 NAT Gateway
    about  
 302
 , 
 317
 , 
 319
    using  
 318
 ncclient library
    about  
 190
    reference  
 190
 neighbor devices  
 127
 nested conditions  
 23
 Netmiko
    reference  
 173
 , 
 220
    reference link  
 62
    used, for SSH  
 62
 network automation
    about  
 8
    tools  
 130
 , 
 132
 , 
 134
 , 
 142
 , 
 143
 , 
 144
    use case  
 67
 Network Configuration Protocol (NETCONF)
    about  
 199
    characteristics  
 199
    device preparation  
 200
 , 
 201
    examples  
 201
 , 
 202
 , 
 203
    reference  
 200
 network device interaction  
 62
 network fabric  
 127
 Network Function Virtualization (NFV)  
 683
 ,
 684
 Network Function Virtualization Infrastructure
 (NFVI)  
 684
 network module conditional  
 264
 , 
 266
 network modules
    reference  
 236
 network scaling services
    about  
 322
    CloudFront CDN services  
 323
    Elastic Load Balancing (ELB)  
 322
    Route53 DNS service  
 323
 Network Time Protocol (NTP)
    references  
 637
 , 
 672
    servers, querying  
 637
 networking modules, Ansible
    about  
 245
    facts  
 245
 , 
 246
    local connections  
 245
 , 
 246
    provider arguments  
 246
 , 
 247
 , 
 248
 networks
    emulating, with Mininet  
 603
    inactive machines, detecting  
 435
    simulating, with ns-3  
 599
 , 
 603
 Nexus API (NX-API)  
 123
 Nmap
    about  
 433
    URL  
 433
 ns-3
    networks, simulating  
 599
 , 
 603
    URL  
 599
 NSX API Guide
    URL  
 664
 NSX for vSphere API Guide
    URL  
 664
 NSX Manager
    URL  
 663
 nxso_snmp_contact module
    reference  
 241",NA
O,"Open Network Foundation (ONF)  
 11
 Open Platform for NFV (OPNFV)
    references  
 684
 , 
 685
    VNFs, building  
 684
 , 
 690
 OpenBMP
    URL  
 694
 OpenContrail cluster
    configuring  
 671
 OpenContrail controller
    configuring  
 669
 OpenContrail core project
    URL  
 669
 OpenContrail
    about  
 657
    URL  
 669
 , 
 670
 OpenFlow  
 11",NA
P,"packages  
 58
 packet capture (pcap) format
    packets, saving with pcap dumper  
 581
 , 
 586
    URL  
 581
 packets
    broadcast, scanning  
 595
 , 
 597
    IP address, customizing  
 590
 , 
 592
    processing, with DPDK  
 690
 , 
 694
    saving, in pcap format with pcap dumper 
 581
 , 
 586
    sniffing, on network  
 578
 , 
 581
 parallel processing
    multithreading  
 59
 Paramiko library
    about  
 169
    drawbacks  
 178
    features  
 174
    for servers  
 175
    implementing  
 176
 , 
 177
    installation  
 169
    overview  
 170
 , 
 171
    program  
 173
    reference  
 169
 , 
 192
 Paramiko
    URL  
 529
 , 
 532
 Pexpect library
    about  
 158
    drawbacks  
 178
    features  
 165
 , 
 168
    implementing  
 167
    installation  
 158
 , 
 159
    overview  
 159
 , 
 160
 , 
 162
 , 
 163
    program  
 164
 , 
 165
    reference  
 158
 , 
 166
    SSH  
 167
 ping module
    reference  
 230
 Platform-as-a-Services (PaaS)
    reference  
 292
 PNDA
    about  
 704
    clusters, creating  
 704
 , 
 709
    references  
 662
    URL  
 704
 Pointer records (PTR)  
 627
 port address translation (PAT)  
 318
 ports
    scanning, of remote host  
 588
 , 
 590
 Power on Auto Provisioning (PoAP)  
 123
 PowerShell IDE  
 27
 PowerShell
    about  
 25
    program  
 26
 program concepts
    about  
 12
    arrays  
 18
    best practice, example  
 23
    best practices  
 20
    data types  
 13
    decision maker  
 15
    functions  
 19
    indentation  
 23
    loop  
 17
    readability  
 20
    support information  
 22
    variables  
 13
 programmable network devices  
 121
 programmable networks (PNs)  
 121
 proxy server
    web requests, sending  
 465
 pyeapi library
    reference link  
 126
 PyEZ
    about  
 204
    examples  
 206
 , 
 207
 , 
 208
    installation  
 204
 , 
 205
 , 
 206
    preparation  
 204
 , 
 205
 , 
 206
    reference  
 204
 PyGitHub
    reference  
 349
 PyIOSXR
    URL  
 677
 pylibcap library
    URL  
 578",NA
R,"Red PNDA
    configuring  
 658
 , 
 661
    URL  
 658
 regular expressions
    reference  
 163
 remote host
    local port, forwarding  
 416
 , 
 419
 , 
 420
    ports, scanning  
 588
 , 
 590
 remote machine
    CPU information, printing  
 532
 , 
 536
    file, copying by SFTP  
 529
 , 
 531
    files, transferring over SSH  
 543
 , 
 546
 remote network service
    waiting for  
 425
 , 
 427
 , 
 428
 Remote Procedure Call (RPC)  
 209
 remote shell command
    executing, with telnet  
 527
 , 
 529
 Representational State Transfer (REST)
 framework  
 31
 Representational State Transfer (REST)
    about  
 551
    used, for collecting photo information  
 563
 ,
 567
 requests module
    about  
 463
    URL  
 463
 Requests
    reference  
 193
 RequestsThrottler
    used, for throttling requests  
 652
 REST APIs
    authenticating, with Eve  
 650
 RESTful web applications
    creating, with Flask  
 572
 , 
 576
 roles, Ansible
    about  
 282
 , 
 284
 , 
 285
    reference  
 282
 , 
 285
 routing table  
 78",NA
S,"S3 bucket
    URL  
 704
 sandbox user guide
    URL  
 666
 Scapy library
    reference  
 435
 screen scraping
    drawbacks  
 184
    versus API structured output  
 183
 , 
 184
 , 
 185
 ,
 186
 SDNVPN
    URL  
 690
 Secure File Transfer Protocol (SFTP)
    file, copying to remote machine  
 529
 , 
 531
 Service-Level Agreement (SLA)  
 320
 Simple Network Management Protocol (SNMP) 
 9
 Simple Object Access Protocol (SOAP)  
 551
 SNAS.io
    BMP messages, parsing  
 694
 , 
 700
 sniffing, packets
    on network  
 578
 , 
 581",NA
T,"technology domain
    automation, example  
 78
    BGP  
 78
    Cisco switchport, configuring for access point 
 86
    Cisco switchport, configuring for IP Phone  
 90
    IP Address Management (IPAM), accessing 
 94
    routing table  
 78
    Wireless LAN (WLAN)  
 93
 telnet
    used, for executing remote shell command 
 527
 , 
 529
 template module
    reference  
 269
 templates
    about  
 269
 , 
 270
 , 
 271
    Jinja2 template  
 271
    with Jinja2  
 245
 throttle
    URL  
 656
 Tornado Future
    URL  
 487
    used, for building concurrent applications  
 487
 Tornado
    used, for building asynchronous network
 applications  
 484
 , 
 486
 traffic
    replaying, from saved pcap file  
 593
 , 
 595
 transaction signature (TSIG)  
 627
 Twisted
    URL  
 480
    used, for building asynchronous network
 applications  
 480
 , 
 484",NA
U,"Unix domain sockets (UDS)
    used, for performing IPC  
 440
 , 
 443
 use case  
 95",NA
V,"variables  
 13
 variables, Ansible
    about  
 241
 , 
 244
 , 
 245
    reference  
 242
 , 
 243
 vehicular ad hoc network (VANET)  
 610
 vendor-neutral libraries  
 220
 VIRL on Packet
    reference  
 151
 virlutils
    reference  
 151
 Virtual Internet Routing Lab (VIRL)
    reference  
 150
 virtual lab
    advantages  
 149
    Cisco DevNet  
 155
 , 
 156
    Cisco VIRL  
 150
 , 
 151
    constructing  
 148
 , 
 149
 , 
 150
    dCloud  
 155
 , 
 156
    disadvantages  
 149
    GNS3  
 157
 , 
 158
 Virtual Network Functions (VNFs)
    about  
 684
    building, with OPNFV  
 684
 , 
 690
 Virtual Private Cloud (VPC)  
 302",NA
W,"web forms
    submitting  
 463
 , 
 465
 web page
    existence, checking with HEAD request  
 468
 ,
 470
 web requests
    bandwidth, saving with HTTP compression 
 472
 , 
 475
    sending, through proxy server  
 465
 web-based post check tool
    creating, for validations  
 95
 , 
 96
 , 
 99
 , 
 106
 , 
 109
 web-based pre check tool
    creating, for validations  
 95
 , 
 96
 , 
 99
 , 
 106
 , 
 109
 when clause  
 259
 , 
 260
 , 
 261
 while loop  
 48
 Wireless LAN (WLAN)  
 93
 wireless networks
    drones, controlling  
 701
 , 
 704
    emulating, with Mininet-WiFi  
 610
 , 
 614",NA
X,"XML Remote Procedure Call (XML-RPC)  
 551
 XML-RPC server
    executing, with basic HTTP authentication 
 558
 , 
 562
    multicall, writing  
 555
 , 
 558
    multithreaded, writing  
 555
 , 
 558",NA
Y,"YAML
    about  
 238
    reference  
 231
 YANG models
    and Cisco API  
 195
    reference  
 196
 Yet Another Next Generation (YANG)  
 188",NA
