Larger Text,Smaller Text,Symbol
Numerical ,NA,NA
Recipes ,NA,NA
in Fortran 77 ,NA,NA
The Art of Scientific Computing ,NA,NA
Second Edition,NA,NA
Volume 1 of ,NA,NA
Fortran Numerical Recipes,NA,NA
William H. Press ,Harvard-Smithsonian Center for Astrophysics,NA
Saul A. Teukolsky ,"Department of Physics, Cornell University",NA
William T. Vetterling ,Polaroid Corporation,NA
Brian P. Flannery ,EXXON Research and Engineering Company,NA
Contents,"Plan of the Two-Volume Edition 
  
 xiii
  
 1
  
 Preface to the Second Edition
  
 xv
  
 Preface to the First Edition
  
 xviii
  
 License Information
  
 xx
  
 Computer Programs by Chapter and Section
  
 xxiv
  
 Preliminaries
  
 1
  
 2
  
 1.0 Introduction 
  
 1.1 Program Organization and Control Structures
  
 1 
  
 5
  
 1.2 Error, Accuracy, and Stability
  
 18
  
 Solution of Linear Algebraic Equations
  
 22
  
 3
  
 2.0 Introduction
  
 22
  
 2.1 Gauss-Jordan Elimination
  
 27
  
 2.2 Gaussian Elimination with Backsubstitution
  
 33
  
 2.3 LU Decomposition and Its Applications
  
 34
  
 2.4 Tridiagonal and Band Diagonal Systems of Equations 
 2.5 Iterative Improvement of a Solution to Linear Equations
  
 42 
  
 47
  
 2.6 Singular Value Decomposition
  
 51
  
 2.7 Sparse Linear Systems
  
 63
  
 2.8 Vandermonde Matrices and Toeplitz Matrices
  
 82
  
 2.9 Cholesky Decomposition 
  
 2.10 QR Decomposition
  
 89 
  
 91
  
 2.11 Is Matrix Inversion an
  N
 3
 Process?
  
 95
  
 Interpolation and Extrapolation
  
 99
  
 3.0 Introduction
  
 99
  
 3.1 Polynomial Interpolation and Extrapolation
  
 102
  
 3.2 Rational Function Interpolation and Extrapolation
  
 104
  
 3.3 Cubic Spline Interpolation
  
 107
  
 3.4 How to Search an Ordered Table 
  
 3.5 Coefficients of the Interpolating Polynomial
  
 110 
  
 113
  
 3.6 Interpolation in Two or More Dimensions
  
 116
  
 v",NA
Plan of the Two-Volume Edition,"Fortran, long the epitome ofstability, is once again a language in flux. 
 Fortran90 is not just the long-awaited updating of traditional Fortran 77 to modern 
 computing practices, but also demonstrates Fortran’s decisive bid to be the 
 language of choice for parallel programming on multiprocessor computers.
  
  
 At the same time, Fortran 90 is completely backwards-compatible with all 
 Fortran 77 code. 
  
 So, users with legacy code, or who choose to use only older 
 language constructs, will still get the benefit of updated and actively maintained 
 compilers.
  
 As we, the authors of
  Numerical Recipes
 , watched the gestation and birth of 
 Fortran 90 by its governing standards committee (an interesting process described 
 by a leading Committee member, Michael Metcalf, in the Foreword to our Volume 
 2), it became clear to us that the right moment for moving Numerical Recipes from 
 Fortran 77 to Fortran 90 was sooner, rather than later.
  
 On the other hand, it was equally clear that Fortran-77-style programming —
 no matter whether with Fortran 77 or Fortran 90 compilers — is, and will continue 
 for a long time to be, the “mother tongue” of a large population of active scientists, 
 engineers, and other users of numerical computation. This is not a user base that we 
 would willingly or knowingly abandon.
  
  
 The solution was immediately clear: 
  
 a two-volume edition of the Fortran 
 Numerical Recipes
  consisting of Volume 1 (this one, a corrected reprinting of the 
 previous one-volume edition), now retitled
  Numerical Recipes in Fortran 77
 , and a 
 completely new Volume 2, titled
  Numerical Recipes in Fortran 90: The Art of 
 Parallel
  Scientific Computing
 . Volume 2 begins with three chapters (21, 22, and 23) 
 that extend the narrative of the first volume to the new subjects of Fortran 90 
 language features, parallel programming methodology, and the implementation of 
 certain useful utility functions in Fortran 90. Then, in exact correspondence with 
 Volume 1’s Chapters 1–20, are new chapters B1–B20, devoted principally to the 
 listing and explanation of new Fortran 90 routines. With a few exceptions, each 
 Fortran 77 routine in Volume 1 has a corresponding new Fortran 90 version in 
 Volume 2. (The exceptions are a few new capabilities, notably in random number 
 generation and in multigrid PDE solvers, that are unique to Volume 2’s Fortran 90.) 
 Otherwise, there is no duplication between the volumes. The detailed explanation of 
 the algorithms in this Volume 1 is intended to apply to, and be essential for, both 
 volumes.
  
 In other words:
  You can use this Volume 1 without having Volume 2, but 
 you can’t use Volume 2 without Volume 1.
  We think that there is much to be 
 gained by having and using
  both
  volumes: Fortran 90’s parallel language 
 constructions are not only useful for present and future multiprocessor machines; 
 they also allow for the elegant and concise formulation of many algorithms on 
 ordinary single-processor computers. We think that essentially
  all
  Fortran 
 programmers will want gradually to migrate into Fortran 90 and into a mode of 
 “thinking parallel.” We have written Volume 2 specifically to help with this 
 important transition.
  
 Volume 2’s discussion of parallel programming is focused on those issues of 
 direct relevance to the Fortran 90 programmer. Some more general aspects of 
 parallel programming, such as communication costs, synchronization of multiple 
 processers,
  
 xiii",NA
Preface to the Second Edition,"Our aim in writing the original edition of
  Numerical Recipes
  was to provide a 
 book that combined general discussion, analytical mathematics, algorithmics, and 
 actual working programs. The success of the first edition puts us now in a difficult, 
 though hardly unenviable, position. We wanted, then and now, to write a book that 
 is informal, fearlessly editorial, unesoteric, and above all useful. There is a danger 
 that, if we are not careful, we might produce a second edition that is weighty, 
 balanced, scholarly, and boring.
  
 It is a mixed blessing that we know more now than we did six years ago. 
 Then, we were making educated guesses, based on existing literature and our own 
 research, about whichnumerical techniqueswere the most important and robust. 
 Now, we have the benefit of direct feedback from a large reader community. 
 Letters to our alter-ego enterprise, Numerical Recipes Software, are in the 
 thousands per year. (Please,
  don’t telephone
  us.) Our post office box has become a 
 magnet for letters pointing out that we have omitted some particular technique, 
 well known to be important in a particular field of science or engineering. We 
 value such letters, and digest them carefully, especially when they point us to 
 specific references in the literature.
  
 The inevitable result of this input is that this Second Edition of
  Numerical 
 Recipes
  is substantially larger than its predecessor, in fact about 50% larger both in 
 words and number of included programs (the latter now numbering well over 
 300).“Don’t let the book grow in size,” is the advice that we received from several 
 wise colleagues. We have tried to follow the intended spirit of that advice, even as 
 we violate the letter of it. We have not lengthened, or increased in difficulty, the 
 book’s principal discussions of mainstream topics. Many new topics are presented 
 at this same accessible level. Some topics, both from the earlier edition and new to 
 this one, are now set in smaller type that labels them as being “advanced.” The 
 reader who ignores such advanced sections completely will not, we think, find any 
 lack of continuity in the shorter volume that results.
  
 Here are some highlights of the new material in this Second Edition:
 •
  a new 
 chapter on integral equations and inverse methods
  
 •
  a detailed treatment of multigrid methods for solving elliptic partial 
 differential equations
  
 •
  routines for band diagonal linear systems
  
 •
  improved routines for linear algebra on sparse matrices
  
 •
  Cholesky and QR decomposition
  
 •
  orthogonal polynomials and Gaussian quadratures for arbitrary weight 
 functions
 •
  methods for calculating numerical derivatives
  
 •
  Pad´e approximants, and rational Chebyshev approximation
  
 •
  Bessel functions, and modified Bessel functions, of fractional order; and 
 several other new special functions
  
 •
  improved random number routines
  
 •
  quasi-random sequences
  
 •
  routines for adaptive and recursive Monte Carlo integration in high-
 dimensional spaces
 •
  globally convergent methods for sets of nonlinear 
 equations",NA
Preface to the First Edition,"We call this book
  Numerical Recipes
  for several reasons. In one sense, this 
 book is indeed a “cookbook” on numerical computation. However there is an 
 important distinction between a cookbook and a restaurant menu. The latter 
 presents choices among complete dishes in each of which the individual flavors are 
 blended and disguised. The former — and this book — reveals the individual 
 ingredients and explains how they are prepared and combined.
  
 Another purpose of the title is to connote an eclectic mixture of presentational 
 techniques. This book is unique, we think, in offering, for each topic considered, a 
 certain amount of general discussion, a certain amount of analytical mathematics, a 
 certain amount of discussion of algorithmics, and (most important) actual imple-
 mentations of these ideas in the form of working computer routines. Our task has 
 been to find the right balance among these ingredients for each topic. You will find 
 that for some topics we have tilted quite far to the analytic side; this where we have 
 felt there to be gaps in the “standard” mathematical training. For other topics, 
 where the mathematical prerequisites are universally held, we have tilted towards 
 more in-depth discussion of the nature of the computational algorithms, or towards 
 practical questions of implementation.
  
 We admit, therefore, to some unevenness in the “level” of this book. About 
 half of it is suitable for an advanced undergraduate course on numerical 
 computation for science or engineering majors. The other half ranges from the level 
 of a graduate course to that of a professional reference. Most cookbooks have, after 
 all, recipes at varying levels of complexity. An attractive feature of this approach, 
 we think, is that the reader can use the book at increasing levels of sophisticationas 
 his/her experience grows. Even inexperienced readers should be able to use our 
 most advanced routines as black boxes. Having done so, we hope that these readers 
 will subsequently go back and learn what secrets are inside.
  
  
 If there is a single dominant theme in this book, it is that practical methods of 
 numerical computation can be simultaneously efficient, clever, and — important— 
 clear. 
  
 The alternative viewpoint, that efficient computational methods must 
 necessarily be so arcane and complex as to be useful only in “black box” form, we 
 firmly reject.
  
 Our purpose in this book is thus to open up a large number of computational 
 black boxes to your scrutiny. We want to teach you to take apart these black boxes 
 and to put them back together again, modifying them to suit your specific needs. 
 We assume that you are mathematically literate, i.e., that you have the normal 
 mathematical preparation associated with an undergraduate degree in a physical 
 science, or engineering, or economics, or a quantitative social science. We assume 
 that you know how to program a computer. We do not assume that you have any 
 prior formal knowledge of numerical analysis or numerical methods.
  
 The scope of
  Numerical Recipes
  is supposed to be “everything up to, but not 
 including, partial differential equations.” We honor this in the breach: First, we
  do
  
 have one introductory chapter on methods for partial differential equations 
 (Chapter 19). Second, we obviouslycannot include
  everything
  else. All the so-
 called“standard” topics of a numerical analysis course have been included in this 
 book:
  
 xviii",NA
License Information,"Read this section if you want to use the programs in this book on a computer. 
 You’ll need to read the followingDisclaimer of Warranty, get the programs onto 
 your computer, and acquire a Numerical Recipes software license. (Without this 
 license, which can be the free “immediate license” under terms described below, 
 the book is intended as a text and reference book, for reading purposes only.)
  
 Disclaimer of Warranty
  
 We make no warranties, express or implied, that the programs contained 
 in this volume are free of error, or are consistent with any particular standard 
 of merchantability, or that they will meet your requirements for any 
 particular application. They should not be relied on for solving a problem 
 whose incorrect solution could result in injury to a person or loss of property. 
 If you do use the programs in such a manner, it is at your own risk. The 
 authors and publisher disclaim all liability for direct or consequential 
 damages resulting from your use of the programs.
  
 How to Get the Code onto Your Computer
  
 Pick one of the following methods:
  
 •
  You can type the programs from this book directly into your computer. In 
 this case, the
  only
  kind of license available to you is the free “immediate 
 license” (see below). You are not authorized to transfer or distribute a 
 machine-readable copy to any other person, nor to have any other person 
 type the programs into a computer on your behalf. We do not want to 
 hear bug reports from you if you choose this option, because experience 
 has shown that
  virtually all
  reported bugs in such cases are typing errors!
  
 •
  You can download the Numerical Recipes programs electronically from the 
 Numerical Recipes On-Line Software Store, located at our Web site 
 (
 http://www.nr.com
 ). They are packaged as a password-protected file, and 
 you’ll need to purchase a license to unpack them. 
  
 You can 
 get a single-screen license and password immediately, on-line, from the On-
 Line Store, with fees ranging from
  $
 50 (PC, Macintosh, educational 
 institutions’ UNIX) to
  $
 140 (general UNIX). Downloading the packaged 
 software from the On-Line Store is also the way to start if you want to 
 acquire a more general (multiscreen, site, or corporate) license.
  
 xx",NA
Computer Programs ,NA,NA
by Chapter and Section,"1.0
  
 flmoon
  
 calculate phases of the moon by date
  
 1.1
  
 julday
  
 Julian Day number from calendar date
  
 1.1
  
 badluk
  
 Friday the 13th when the moon is full
  
 1.1
  
 caldat
  
 calendar date from Julian day number
  
 2.1
  
 gaussj
  
 Gauss-Jordan matrix inversion and linear equation
  
 2.3
  
 ludcmp
  
 solution
  
 linear equation solution,
  LU
  decomposition
  
 2.3
  
 lubksb
  
 linear equation solution, backsubstitution
  
 2.4
  
 tridag
  
 solution of tridiagonal systems
  
 2.4
  
 banmul
  
 multiply vector by band diagonal matrix
  
 2.4
  
 bandec
  
 band diagonal systems, decomposition
  
 2.4
  
 banbks
  
 band diagonal systems, backsubstitution
  
 2.5
  
 mprove
  
 linear equation solution, iterative improvement
  
 2.6
  
 svbksb
  
 singular value backsubstitution
  
 2.6
  
 svdcmp
  
 singular value decomposition of a matrix
  
 2.6
  
 pythag
  
 calculate
  (
 a
 2
 +
  b
 2
 )
 1
 /
 2
 without overflow
  
 2.7
  
 cyclic
  
 solution of cyclic tridiagonal systems
  
 2.7
  
 sprsin
  
 convert matrix to sparse format
  
 2.7
  
 sprsax
  
 product of sparse matrix and vector
  
 2.7
  
 sprstx
  
 product of transpose sparse matrix and vector
  
 2.7
  
 sprstp
  
 transpose of sparse matrix
  
 2.7
  
 sprspm
  
 pattern multiply two sparse matrices
  
 2.7
  
 sprstm
  
 threshold multiply two sparse matrices
  
 2.7
  
 linbcg
  
 biconjugate gradient solution of sparse systems
  
 2.7
  
 snrm
  
 used by
  linbcg
  for vector norm
  
 2.7
  
 atimes
  
 used by
  linbcg
  for sparse multiplication
  
 2.7
  
 asolve
  
 used by
  linbcg
  for preconditioner
  
 2.8
  
 vander
  
 solve Vandermonde systems
  
 2.8
  
 toeplz
  
 solve Toeplitz systems
  
 2.9
  
 choldc
  
 Cholesky decomposition
  
 2.9
  
 cholsl
  
 Cholesky backsubstitution
  
 2.10
  
 qrdcmp
  
 QR decomposition
  
 2.10
  
 qrsolv
  
 QR backsubstitution
  
 2.10
  
 rsolv
  
 right triangular backsubstitution
  
 2.10
  
 qrupdt
  
 update a QR decomposition
  
 2.10
  
 rotate
  
 Jacobi rotation used by
  qrupdt
  
 3.1
  
 polint
  
 polynomial interpolation
  
 3.2
  
 ratint
  
 rational function interpolation
  
 3.3
  
 spline
  
 construct a cubic spline
  
 3.3
  
 splint
  
 cubic spline interpolation
  
 3.4
  
 locate
  
 search an ordered table by bisection
  
 xxiv",NA
Chapter 1. ,NA,NA
Preliminaries,NA,NA
1.0 Introduction,"This book, like its predecessor edition, is supposed to teach you methods of 
 numerical computing that are practical, efficient, and (insofar as possible) elegant. 
 We presume throughout this book that you, the reader, have particular tasks that 
 you want to get done. We view our job as educating you on how to proceed. 
 Occasionally we may try to reroute you briefly onto a particularly beautiful side 
 road; but by and large, we will guide you along main highways that lead to 
 practical destinations.
  
 Throughout this book, you will find us fearlessly editorializing, telling you 
 what you should and shouldn’t do. This prescriptive tone results from a conscious 
 decision on our part, and we hope that you will not find it irritating. We do not 
 claim that our advice is infallible! Rather, we are reacting against a tendency, in the 
 textbook literature of computation, to discuss every possible method that has ever 
 been invented, without ever offering a practical judgment on relative merit. We do, 
 therefore, offer you our practical judgments whenever we can. As you gain 
 experience, you will form your own opinion of how reliable our advice is.
  
 We presume that you are able to read computer programs in
  FORTRAN
 , that 
 being the language of this version of
  Numerical Recipes
  (Second Edition). The 
 book
  Numerical Recipes in C
  (Second Edition) is separately available, if you prefer 
 to program in that language. Earlier editions of
  Numerical Recipes in Pascal
  and 
 Numerical Recipes Routines and Examples in BASIC
  are also available; while not 
 containing the additional material of the Second Edition versions in
  C
  and
  
 FORTRAN
 , these versions are perfectly serviceable if
  Pascal
  or
  BASIC
  is your 
 language of choice.
  
 When we include programs in the text, they look like this:
  
 SUBROUTINE flmoon(n,nph,jd,frac)
  
 INTEGER jd,n,nph
  
 REAL frac,RAD
  
 PARAMETER (RAD=3.14159265/180.)
  
 Our programs begin with an introductory comment summarizing their purpose and explain-
  
 ing their calling sequence. This routine calculates the phases of the moon. Given an integer
  
 n
  and a code
  nph
  for the phase desired (
 nph
  = 0 for new moon, 1 for first quarter, 2 for
  
 full, 3 for last quarter), the routine returns the Julian Day Number
  jd
 , and the fractional
  
 part of a day
  frac
  to be added to it, of the
  n
 th
  such phase since January, 1900. Greenwich
  
 Mean Time is assumed.
  
 INTEGER i
  
 REAL am,as,c,t,t2,xtra
  
 c=n+nph/4. 
  
 This is how we comment an individual line.
  
 t=c/1236.85
  
 t2=t**2
  
 1",NA
1.1 Program Organization and Control ,NA,NA
Structures,"We sometimes like to point out the close analogies between computer 
 programs, on the one hand, and written poetry or written musical scores, on the 
 other. All three present themselves as visual media, symbols on a two-dimensional 
 page or computer screen. Yet, in all three cases, the visual, two-dimensional,
  
 frozen-in-time 
 representation communicates (or is supposed to communicate) 
 something rather",NA
1.1 Program Organization and Control ,NA,NA
Structures,"We sometimes like to point out the close analogies between computer 
 programs, on the one hand, and written poetry or written musical scores, on the 
 other. All three present themselves as visual media, symbols on a two-dimensional 
 page or computer screen. Yet, in all three cases, the visual, two-dimensional,
  
 frozen-in-time 
 representation communicates (or is supposed to communicate) 
 something rather",NA
"1.2 Error, Accuracy, and Stability","Althoughwe assume no prior trainingof the reader in formal numerical 
 analysis, we will need to presume a common understanding of a few key concepts. 
 We will define these briefly in this section.
  
 Computers store numbers not with infinite precision but rather in some ap-
 proximation that can be packed into a fixed number of
  bits
  (binary digits) or
  bytes 
 (groups of 8 bits). Almost all computers allow the programmer a choice among 
 several different such
  representations
  or
  data types
 . Data types can differ in the 
 number of bits utilized (the
  wordlength
 ), but also in the more fundamental respect 
 of whether the stored number is represented in
  fixed-point
  (also called
  integer
 ) or 
 floating-point
  (also called
  real
 ) format.
  
 A number in integer representation is exact. Arithmetic between numbers in 
 integer representation is also exact, with the provisos that (i) the answer is not 
 outside the range of (usually, signed) integers that can be represented, and (ii) that",NA
Chapter 2.,NA,NA
Solution of Linear ,NA,NA
Algebraic Equations,NA,NA
2.0 Introduction,"A set of linear algebraic equations looks like this:
  
 a
 11
 x
 1
  +
  a
 12
 x
 2
  +
  a
 13
 x
 3
  +
  · · ·
  +
  a
 1
 N
 x
 N
  =
  b
 1
  
 a
 21
 x
 1
  +
  a
 22
 x
 2
  +
  a
 23
 x
 3
  +
  · · ·
  +
  a
 2
 N
 x
 N
  =
  b
 2
  
 a
 31
 x
 1
  +
  a
 32
 x
 2
  +
  a
 33
 x
 3
  +
  · · ·
  +
  a
 3
 N
 x
 N
  =
  b
 3 
  
 (
 2.0.1
 )
  
 · · ·· · ·
  
 a
 M
 1
 x
 1
  +
  a
 M
 2
 x
 2
  +
  a
 M
 3
 x
 3
  +
  · · ·
  +
  a
 MN
 x
 N
  =
  b
 M
  
 Here the
  N
  unknowns
  x
 j
 ,
  j
  = 1
 ,
  2
 , . . ., N
  are related by
  M
  equations. 
  
 The 
 coefficients
  a
 ij
  with
  i
  = 1
 ,
  2
 , . . ., M
  and
  j
  = 1
 ,
  2
 , . . ., N
  are known numbers, as are the
  
 right-hand side
  quantities
  b
 i
 ,
  i
  = 1
 ,
  2
 , . . ., M
 .
  
 Nonsingular versus Singular Sets of Equations
  
 If
  N
  =
  M
  then there are as many equations as unknowns, and there is a good 
 chance of solving for a unique solution set of
  x
 j
 ’s. Analytically, there can fail to be 
 a unique solution if one or more of the
  M
  equations is a linear combination of the 
 others, a condition called
  row degeneracy
 , or if all equations contain certain 
 variables only in exactly the same linear combination, called
  column degeneracy
 . 
 (For square matrices, a row degeneracy implies a column degeneracy, and vice 
 versa.) A set of equations that is degenerate is called
  singular
 . We will consider 
 Numerically, at least two additional things can go wrong: singular matrices in some 
 detail in
  §
 2.6.
  
 •
  While not exact linear combinations of each other, some of the equations 
 may be so close to linearly dependent that roundoff errors in the machine 
 render them linearly dependent at some stage in the solution process. In 
 this case your numerical procedure will fail, and it can tell you that it has 
 failed.
  
 22",NA
2.1 Gauss-Jordan Elimination,"For inverting a matrix,
  Gauss-Jordan elimination
  is about as efficient as any 
 other method. For solving sets of linear equations, Gauss-Jordan elimination 
 produces
  both
  the solution of the equations for one or more right-hand side vectors 
 b
 , and also the matrix inverse
  A
 −
 1
 . However, its principal weaknesses are (i) that it 
 requires all the right-hand sides to be stored and manipulated at the same time, and 
 (ii) that when the inverse matrix is
  not
  desired, Gauss-Jordan is three times 
 method’s principal strength is that it is as stable as any other direct method, perhaps 
 slower than the best alternative technique for solving a single linear set (
 §
 2.3). The 
 even a bit more stable when full pivoting is used (see below).
  
 If you come along later with an additional right-hand side vector, you can 
 multiply it by the inverse matrix, of course. This does give an answer, but one that 
 is quite susceptible to roundoff error, not nearly as good as if the new vector had 
 been included with the set of right-hand side vectors in the first instance.
  
  
 For these reasons, Gauss-Jordan elimination should usually not be your method 
  
  
 The 
 of first choice, either for solving linear equations or for matrix inversion.
  
 decomposition methods in
  §
 2.3 are better. Why do we give you Gauss-Jordan at 
 all? Because it is straightforward, understandable, solid as a rock, and an 
 exceptionally good “psychological” backup for those times that something is going 
 wrong and you think it
  might
  be your linear-equation solver.
  
  
 Some people believe that the backup is more than psychological, that Gauss-
 Jordan elimination is an “independent” numerical method. 
  
 This turns out to be 
 mostly myth. Except for the relatively minor differences in pivoting, described 
 below, the actual sequence of operations performed in Gauss-Jordan elimination is 
 very closely related to that performed by the routines in the next two sections.",NA
2.2 Gaussian Elimination with Backsubstitution,"The usefulness of Gaussian elimination with backsubstitution is primarily 
 pedagogical. It stands between full elimination schemes such as Gauss-Jordan, and 
 triangular decomposition schemes such as will be discussed in the next section. 
 Gaussian elimination reduces a matrix not all the way to the identity matrix, but 
 only halfway, to a matrix whose components on the diagonal and above (say) 
 remain nontrivial. Let us now see what advantages accrue.
  
 each stage subtract away rows only
  below
  the then-current pivot element. When
  a
 22 
 Suppose that in doing Gauss-
 Jordan elimination, as described in
  §
 2.1, we at
  
 is the pivot element, for example, we divide the second row by its value (as 
 before), but now use the pivot row to zero only
  a
 32
  and
  a
 42
 , not
  a
 12
  (see equation 
 2.1.1). Suppose, also, that we do only partial pivoting, never interchanging 
 columns, so that the order of the unknowns never needs to be modified.
  
  
 Then, when we have done this for all the pivots, we will be left with a reduced 
 equation that looks like this (in the case of a single right-hand side vector):
  
 0
  
  
 0
  
 0 
  
  
 a
 ′
  
 0
  
 0 
  
 22 
  
 a
 ′
  
 a
 ′
  
 0 
  
 23
  
 33 
  
  
 a
 ′
  
 a
 ′
  
 a
 ′
  
 24
  
 34
  
 44
  ·
  
  
  
   
  
 x
 2
  
 x
 3",NA
2.3 LU Decomposition and Its Applications,"Suppose we are able to write the matrix
  A
  as a product of two matrices,
  
 L
  ·
  U
  =
  A 
  
 (
 2.3.1
 )
  
 where
  L
  is
  lower triangular
  (has elements only on the diagonal and below) and
  U 
 is
  
 upper triangular
  (has elements only on the diagonal and above). For the case of",NA
2.4 Tridiagonal and Band Diagonal Systems ,NA,NA
of Equations,"The special case of a system of linear equations that is
  tridiagonal
 , that is, has 
 nonzero elements only on the diagonal plus or minus one column, is one that 
 occurs frequently. Also common are systems that are
  band diagonal
 , with nonzero 
 elements only along a few diagonal lines adjacent to the main diagonal (above and 
 below).
  
 For tridiagonal sets, the procedures of
  LU
  decomposition, forward- and back-
 substitutioneach take only
  O
 (
 N
 )
  operations, and the whole solution can be encoded 
 very concisely. The resulting routine
  tridag
  is one that we will use in later 
 chapters.
  
 the nonzero components, stored as three vectors. The set of equations to be solved is Naturally, one does not reserve 
 storage for the full
  N × N
  matrix, but only for
  
  
  
 a
 2 
  
   
 b
 1 
 c
 1",NA
2.5 Iterative Improvement of a Solution to ,NA,NA
Linear Equations,"Obviously it is not easy to obtain greater precision for the solution of a linear 
 set than the precision of your computer’s floating-point word. Unfortunately, for 
 large sets of linear equations, it is not always easy to obtain precision equal to, or 
 even comparable to, the computer’s limit. In direct methods of solution, roundoff 
 errors accumulate, and they are magnified to the extent that your matrix is close to 
 singular. You can easily lose two or three significant figures for matrices which 
 (you thought) were
  far
  from singular.
  
 If this happens to you, there is a neat trick to restore the full machine 
 precision, called
  iterative improvement
  of the solution. The theory is very 
 straightforward (see Figure 2.5.1): Suppose that a vector
  x
  is the exact solution of 
 the linear set
  
 A
  ·
  x
  =
  b 
  
 (
 2.5.1
 )
  
 You don’t, however, know
  x
 . You only know some slightly wrong solution
  x
  +
  δ
 x
 , 
 where
  δ
 x
  is the unknownerror. When multipliedby the matrix
  A
 , your 
 slightlywrong solutiongives a product slightlydiscrepant fromthe desired right-
 handside
  b
 , namely
  
 A
  ·
  (
 x
  +
  δ
 x
 ) =
  b
  +
  δ
 b 
  
 (
 2.5.2
 )
  
 Subtracting (2.5.1) from (2.5.2) gives
  
 A
  · δ
 x
  =
  δ
 b 
  
 (
 2.5.3
 )
  
 But (2.5.2) can also be solved, trivially, for
  δ
 b
 . Substituting this into (2.5.3) gives
  
 A
  · δ
 x
  =
  A
  ·
  (
 x
  +
  δ
 x
 )
  −
  b 
  
 (
 2.5.4
 )
  
 In this equation, the whole right-hand side is known, since
  x
  +
  δ
 x
  is the wrong 
 solution that you want to improve. It is essential to calculate the right-hand side in 
 double precision, since there will be a lot of cancellation in the subtraction of
  b
 . 
 Then, we need only solve (2.5.4) for the error
  δ
 x
 , then subtract this from the wrong 
 solution to get an improved solution.
  
 An important extra benefit occurs if we obtained the original solution by
  LU 
 decomposition. In this case we already have the
  LU
  decomposed form of
  A
 , and all 
 we need do to solve (2.5.4) is compute the right-hand side and backsubstitute!
  
 The code to do all this is concise and straightforward:",NA
2.6 Singular Value Decomposition,"There exists a very powerful set of techniques for dealing with sets of equations
  
 or matrices that are either singular or else numerically very close to singular. In many
  
 cases where Gaussian elimination and
  LU
  decomposition fail to give satisfactory
  
 results, this set of techniques, known as
  singular value decomposition
 , or
  SVD
 ,
  
 will diagnose for you precisely what the problem is. 
  
 In some cases, SVD will
  
 not only diagnose the problem, it will also solve it, in the sense of giving you a
  
 useful numerical answer, although, as we shall see, not necessarily “the” answer
  
 that you thought you should get.
  
 SVD is also the method of choice for solving most
 linear least-squares
  problems.
  
 We will outline the relevant theory in this section, but defer detailed discussion of
  
 the use of SVD in this application to Chapter 15, whose subject is the parametric
  
 modeling of data.
  
 SVD methods are based on the followingtheorem of linear algebra, whose proof
  
 is beyond our scope: Any
  M ×N
  matrix
  A
  whose number of rows
  M
  is greater than
  
 or equal to its number of columns
  N
 , can be written as the product of an
  M × N
  
 column-orthogonal matrix
  U
 , an
  N × N
  diagonal matrix
  W
  with positive or zero
  
 elements (the
  singular values
 ), and the transpose of an
  N × N
  orthogonal matrix
  V
 . The various shapes of these 
 matrices will be made clearer by the following tableau:
  
  
 A
  
  
  
  
 =
  
  
  
   
   
 U
    
  
  
  
  
  
  
  
  
   
 ·
       
  
  
  
 w
 1
  
 w
 2
  
 · · ·
  
 · · ·
  
 w
 N
  
  ·
  
  
  
  
 V
 T",NA
2.7 Sparse Linear Systems,"A system of linear equations is called
  sparse
  if only a relatively small number 
 of its matrix elements
  a
 ij
  are nonzero. It is wasteful to use general methods of linear 
 algebra on such problems, because most of the
  O
 (
 N
 3
 )
  arithmetic operations devoted 
 to solving the set of equations or inverting the matrix involve zero operands. 
 Furthermore, you might wish to work problems so large as to tax your available 
 memory space, and it is wasteful to reserve storage for unfruitful zero elements. 
 Note that there are two distinct (and not always compatible) goals for any sparse 
 matrix method: saving time and/or saving space.
  
 diagonal matrix. In the tridiagonal case, e.g., we saw that it was possible to save We have already considered one 
 archetypal sparse form in
  §
 2.4, the band",NA
2.8 Vandermonde Matrices and Toeplitz ,NA,NA
Matrices,"particular type of linear system admits a solution in only of order
  N
  operations, In
  §
 2.4 the case of a tridiagonal 
 matrix was treated specially, because that
  
 rather than of order
  N
 3
 for the general linear problem. When such particular types",NA
2.9 Cholesky Decomposition,"If a square matrix
  A
  happens to be symmetric and positive definite, then it has a special, 
 more efficient, triangular decomposition. 
  
 Symmetric
  means that
  a
 ij
  =
  a
 ji
  for 
 i, j
  = 
 1
 , . . . , N
 , while
  positive definite
  means that
  
 v
  ·
  A
  ·
  v
  >
  0 
  
 for all vectors
  v 
  
 (
 2.9.1
 )
  
 (In Chapter 11 we will see that positive definite has the equivalent interpretation that
  A
  has 
 all positive eigenvalues.) While symmetric, positive definite matrices are rather special, they 
 occur quite frequently in some applications, so their special factorization, called
  Cholesky 
 decomposition
 , is good to know about. When you can use it, Cholesky decomposition is 
 about a factor of two faster than alternative methods for solving linear equations.
  
 Instead of seeking arbitrary lower and upper triangular factors
  L
  and
  U
 , Cholesky 
 decomposition constructs a lower triangular matrix
  L
  whose transpose
  L
 T
 can itself serve as 
 the upper triangular part. In other words we replace equation (2.3.1) by
  
 L
  ·
  L
 T
 =
  A 
  
 (
 2.9.2
 )
  
 This factorization is sometimes referred to as “taking the square root” of the matrix
  A
 . The 
 components of
  L
 T
 are of course related to those of
  L
  by
  
 L
 T ij
 =
  L
 ji 
  
 (
 2.9.3
 )
  
 Writing out equation (2.9.2) in components, one readily obtains the analogs of equations 
 (2.3.12)–(2.3.13),
  
 L
 ii
  =
  
 a
 ii
  −
  
 i−
 1
  
 L
 2 
 ik
  
 1
 /
 2
  
 (
 2.9.4
 )
  
 k
 =1
  
 and
  
 L
 ji
  =
  
 1
  
 a
 ij
  −
  
 i−
 1
  
 L
 ik
 L
 jk
  
 j
  =
  i
  + 1
 , i
  + 2
 , . . . , N
  
 (
 2.9.5
 )
  
 L
 ii
  
 k
 =1",NA
2.10 QR Decomposition,"There is another matrix factorization that is sometimes very useful, the so-called
  QR 
 decomposition
 ,
  
 A
  =
  Q
  ·
  R 
  
 (
 2.10.1
 )
  
 Here
  R
  is upper triangular, while
  Q
  is orthogonal, that is,
  
 Q
 T
 ·
  Q
  =
  1 
  
 (
 2.10.2
 )
  
 where
  Q
 T
 is the transpose matrix of
  Q
 . Although the decomposition exists for a general 
 rectangular matrix, we shall restrict our treatment to the case when all the matrices are 
 square, with dimensions
  N × N
 .",NA
2.11 Is Matrix Inversion an N3 Process?,"We close this chapter with a little entertainment, a bit of algorithmic prestidig-
 itation which probes more deeply into the subject of matrix inversion. We start 
 with a seemingly simple question:",NA
Chapter 3.,NA,NA
Interpolation and ,NA,NA
Extrapolation,NA,NA
3.0 Introduction,"We sometimes know the value of a function
  f
 (
 x
 )
  at a set of points
  x
 1
 , x
 2
 , . . ., x
 N 
 (say, with
 x
 1
  < . . . < x
 N
 ), but we don’t have an analytic expression for
  f
 (
 x
 )
  that lets us 
 calculate its value at an arbitrary point. For example, the
  f
 (
 x
 i
 )
 ’s might result from 
 some physical measurement or from long numerical calculation that cannot be cast 
 into a simple functional form. Often the
  x
 i
 ’s are equally spaced, but not necessarily.
  
 The task now is to estimate
  f
 (
 x
 )
  for arbitrary
  x
  by, in some sense, drawing a 
 smooth curve through (and perhaps beyond) the
  x
 i
 . If the desired
  x
  is in between the 
 largest and smallest of the
  x
 i
 ’s, the problem is called
  interpolation
 ; if
  x
  is outside 
 that range, it is called
  extrapolation
 , which is considerably more hazardous (as 
 many former stock-market analysts can attest).
  
  
 Interpolation and extrapolation schemes must model the function, between or 
 beyond the known points, by some plausible functional form. 
  
 The form should 
 be sufficiently general so as to be able to approximate large classes of functions 
 which might arise in practice. By far most common among the functional forms 
 used are polynomials (
 §
 3.1). Rational functions (quotients of polynomials) also turn 
 out to be extremely useful (
 §
 3.2). Trigonometric functions, sines and cosines, give 
 rise to
  trigonometric interpolation
  and related Fourier methods, which we defer to 
 Chapters 12 and 13.
  
 There is an extensive mathematical literature devoted to theorems about what 
 sort of functions can be well approximated by which interpolating functions. These 
 theorems are, alas, almost completely useless in day-to-day work: If we know 
 enough about our function to apply a theorem of any power, we are usually not in 
 the pitiful state of having to interpolate on a table of its values!
  
 Interpolation is related to, but distinct from,
  function approximation
 . That task 
 consists of finding an approximate (but easily computable) function to use in place 
 of a more complicated one. In the case of interpolation, you are given the function
  f 
 at points
  not of your own choosing
 . For the case of function approximation, you are 
 allowed to compute the function
 f
  at
  any
  desired points for the purpose of developing 
 your approximation. We deal with function approximation in Chapter 5.
  
  
 One can easily find pathological functions that make a mockery of any interpo-
 lation scheme. Consider, for example, the function
  
 f
 (
 x
 ) = 3
 x
 2
 + 1
 π
 4
  ln(
 π − x
 )
 2
  + 1 
  
 (
 3.0.1
 )
  
 99",NA
3.1 Polynomial Interpolation and Extrapolation,"Through any two points there is a unique line. Through any three points, a 
 unique quadratic. Et cetera. The interpolating polynomial of degree
  N −
  1
  through 
 the
  N
  points
  y
 1
  =
  f
 (
 x
 1
 )
 , y
 2
  =
  f
 (
 x
 2
 )
 , . . ., y
 N
  =
  f
 (
 x
 N
 )
  is given explicitly by Lagrange’s 
 classical formula,
  
 P
  (
 x
 ) = 
  
 (
 x − x
 2
 )(
 x − x
 3
 )
 ...
 (
 x − x
 N
 ) 
  
  
 (
 x − x
 1
 )(
 x − x
 3
 )
 ...
 (
 x − x
 N
 ) 
  
 (
 x
 1
  
 − x
 2
 )(
 x
 1
  − x
 3
 )
 ...
 (
 x
 1
  − x
 N
 )
 y
 1
  + (
 x
 2
  − x
 1
 )(
 x
 2
  − x
 3
 )
 ...
 (
 x
 2
  − x
 N
 )
 y
 2
  
 +
  · · ·
  + (
 x
 N
  − x
 1
 )(
 x
 N
  − x
 2
 )
 ...
 (
 x
 N
  − x
 N−
 1
 )
 y
 N 
 (
 x − x
 1
 )(
 x − x
 2
 )
 ...
 (
 x − x
 N−
 1
 )
  
  
 (
 3.1.1
 ) 
 There are
  N
  terms, each a polynomial of degree
  N −
  1
  and each constructed to be 
 zero at all of the
  x
 i
  except one, at which it is constructed to be
  y
 i
 .
  
 It is not terribly wrong to implement the Lagrange formula straightforwardly, 
 but it is not terribly right either. The resulting algorithm gives no error estimate, 
 and it is also somewhat awkward to program. A much better algorithm (for 
 constructing the same, unique, interpolating polynomial) is
  Neville’s algorithm
 , 
 closely related to and sometimes confused with
  Aitken’s algorithm
 , the latter now 
 considered obsolete.
  
  
 Let
  P
 1
  be the value at
  x
  of the unique polynomial of degree zero (i.e., a 
 constant) passing through the point
  (
 x
 1
 , y
 1
 )
 ; so
  P
 1
  =
  y
 1
 . 
  
 Likewise define 
 P
 2
 , P
 3
 , . 
 . ., P
 N
 .
  Now let
  P
 12
  be the value at
  x
  of the unique polynomial of degree one passing 
 through both
  (
 x
 1
 , y
 1
 )
  and
  (
 x
 2
 , y
 2
 )
 . 
  
 Likewise
  P
 23
 , P
 34
 , . . .,",NA
3.2 Rational Function Interpolation and ,NA,NA
Extrapolation,"Some functions are not well approximated by polynomials, but
  are
  well 
 approximated by rational functions, that is quotients of polynomials. 
  
 We de-
 note by
  R
 i
 (
 i
 +1)
 ...
 (
 i
 +
 m
 )
  a rational function passing through the
  m
  + 1
  points",NA
3.3 Cubic Spline Interpolation,"Given a tabulated function
  y
 i
  =
  y
 (
 x
 i
 )
 , i
  = 1
 ...N
 , focus attention on one particular 
 interval, between
  x
 j
  and
  x
 j
 +1
 . Linear interpolation in that interval gives the 
 interpolation formula
  
  
  
  
 y
  =
  Ay
 j
  +
  By
 j
 +1 
  
   
 (
 3.3.1
 ) 
 where 
  
  
 A ≡x
 j
 +1
  − x x
 j
 +1
  − x
 j 
  
 B ≡
  1
  − A
  = 
 x
 j
 +1
  − x
 j 
  
  
  
  
  
  
 x − x
 j 
  
 (
 3.3.2
 )
  
 Equations (3.3.1) and (3.3.2) are a special case of the general Lagrange interpolation 
 formula (3.1.1).
  
 Since it is (piecewise) linear, equation (3.3.1) has zero second derivative in the 
 interior of each interval, and an undefined, or infinite, second derivative at the 
 abscissas
  x
 j
 . The goal of cubic spline interpolationis to get an interpolationformula 
 that is smooth in the first derivative, and continuous in the second derivative, both 
 within an interval and at its boundaries.
  
 Suppose, contrary to fact, that in addition to the tabulated values of
  y
 i
 , we also 
 have tabulated values for the function’s second derivatives,
  y
 ′′
 , that is, a set",NA
3.4 How to Search an Ordered Table,"Suppose that you have decided to use some particular interpolation scheme, 
 such as fourth-order polynomial interpolation, to compute a function
  f
 (
 x
 )
  from a set 
 of tabulated
  x
 i
 ’s and
  f
 i
 ’s. Then you will need a fast way of finding your place in the 
 table of
  x
 i
 ’s, given some particular value
  x
  at which the function evaluation is 
 desired. This problem is not properly one of numerical analysis, but it occurs so 
 often in practice that it would be negligent of us to ignore it.
  
 Formally, the problem is this: Given an array of abscissas
  xx(j)
 ,
  j=
 1, 2,
  . . .,
 n
 , 
 with the elements either monotonically increasing or monotonically decreasing, 
 and given a number
  x
 , find an integer
  j
  such that
  x
  lies between
  xx(j)
  and
  xx(j+1)
 .",NA
3.5 Coefficients of the Interpolating Polynomial,"Occasionally you may wish to knownot the value of the interpolating 
 polynomial that passes through a (small!) number of points, but the coefficients of 
 that poly-nomial. 
  
 A valid use of the coefficients might be, for example, to 
 compute simultaneous interpolated values of the function and of several of its 
 derivatives (see
 §
 5.3), or to convolve a segment of the tabulated function with some 
 other function, where the moments of that other function (i.e., its convolution with 
 powers of
  x
 ) are known analytically.
  
 However, please be certain that the coefficients are what youneed. Generally 
 the coefficients of the interpolating polynomial can be determined much less 
 accurately than its value at a desired abscissa. Therefore it is not a good idea to 
 determine the coefficients only for use in calculating interpolating values. Values 
 thus calculated will not pass exactly through the tabulated points, for example, 
 while values computed by the routines in
  §
 3.1–
 §
 3.3 will pass exactly through such 
 points.",NA
3.6 Interpolation in Two or More Dimensions,"In multidimensional interpolation, we seek an estimate of
  y
 (
 x
 1
 , x
 2
 , . . ., x
 n
 ) 
 from 
 an
  n
 -dimensional grid of tabulated values
  y
  and
  n
  one-dimensional vec-tors giving 
 the tabulated values of each of the independent variables
  x
 1
 , x
 2
 , . . ., x
 n
 . We will not 
 here consider the problem of interpolating on a mesh that is not Cartesian, i.e., has 
 tabulated function values at “random” points in
  n
 -dimensional space rather than at 
 the vertices of a rectangular array. For clarity, we will consider explicitly only the 
 case of two dimensions, the cases of three or more dimensions being analogous in 
 every way.
  
 In two dimensions, we imagine that we are given a matrix of functional values 
 ya(j,k)
 , where
  j
  varies from 1 to
  m
 , and
  k
  varies from 1 to
  n
 . We are also given an 
 array
  x1a
  of length
  m
 , and an array
  x2a
  of length
  n
 . The relation of these input 
 quantities to an underlying function
  y
 (
 x
 1
 , x
 2
 )
  is
  
 ya(j,k) =
  y
 (x1a(j)
 ,
  x2a(k)) 
  
 (
 3.6.1
 )
  
 We want to estimate, by interpolation, the function
  y
  at some untabulated point 
 (
 x
 1
 , 
 x
 2
 )
 .
  
 An important concept is that of the
  grid square
  in which the point
  (
 x
 1
 , x
 2
 ) 
 falls, that is, the four tabulated points that surround the desired interior point. For 
 convenience, we will number these points from 1 to 4, counterclockwise starting 
 from the lower left (see Figure 3.6.1). More precisely, if
  
 x1a(j)
  ≤ x
 1
  ≤
  x1a(j+1) 
 x2a(k)
  ≤ x
 2
  ≤
  x2a(k+1)
  
 (
 3.6.2
 )",NA
Chapter 4. ,NA,NA
Integration of Functions,NA,NA
4.0 Introduction,"Numerical integration, which is also called
  quadrature
 , has a history 
 extending back to the invention of calculus and before. The fact that integrals of 
 elementary functions could not, in general, be computed analytically, while 
 derivatives
  could 
 be, served to give the field a certain panache, and to set it a cut 
 above the arithmetic drudgery of numerical analysis during the whole of the 18th 
 and 19th centuries.
  
 With the invention of automatic computing, quadrature became just one 
 numer-ical task among many, and not a very interesting one at that. Automatic 
 computing, even the most primitivesort involvingdesk calculators and rooms full of 
 “computers”(that were, until the 1950s, people rather than machines), opened to 
 feasibility the much richer field of numerical integration of differential equations. 
 Quadrature is merely the simplest special case: The evaluation of the integral
  
 I
  =
  
  b
  
 f
 (
 x
 )
 dx
  
 (
 4.0.1
 )
  
 a
  
 is precisely equivalent to solving for the value
  I ≡ y
 (
 b
 )
  the differential equation
  
 dy 
  
 dx
 =
  f
 (
 x
 )
  
 (
 4.0.2
 )
  
 with the boundary condition
  
 y
 (
 a
 ) = 0 
  
 (
 4.0.3
 )
  
 Chapter 16 of this book deals with the numerical integration of differential 
 equations. In that chapter, much emphasis is given to the concept of “variable” 
 or“adaptive” choices of stepsize. We will not, therefore, develop that material here. 
 If the function that you propose to integrate is sharply concentrated in one or more 
 peaks, or if its shape is not readily characterized by a single length-scale, then it is 
 likely that you should cast the problem in the form of (4.0.2)–(4.0.3) and use the 
 methods of Chapter 16.
  
 The quadrature methods in this chapter are based, in one way or another, on 
 the obvious device of adding up the value of the integrand at a sequence of 
 abscissas within the range of integration. The game is to obtain the integral as 
 accurately as possible with the smallest number of function evaluations of the 
 integrand. Just as in the case of interpolation (Chapter 3), one has the freedom to 
 choose methods
  
 123",NA
4.1 Classical Formulas for Equally Spaced ,NA,NA
Abscissas,"Where would any book on numerical analysis be without Mr. Simpson and 
 his“rule”? The classical formulas for integrating a function whose value is known 
 at equally spaced steps have a certain elegance about them, and they are redolent 
 with historical association. Through them, the modern numerical analyst 
 communes with the spirits of his or her predecessors back across the centuries, as",NA
4.2 Elementary Algorithms,"Our starting point is equation (4.1.11), the extended trapezoidal rule. There are 
 two facts about the trapezoidal rule which make it the starting point for a variety of 
 algorithms. One fact is rather obvious, while the second is rather “deep.”
  
  
 The obvious fact is that, for a fixed function
  f
 (
 x
 )
  to be integrated between fixed 
 limits
  a
  and
  b
 , one can double the number of intervals in the extended trapezoidal 
 rule without losing the benefit of previous work. The coarsest implementation of the 
 trapezoidal rule is to average the function at its endpoints
  a
  and
  b
 . The first stage of 
 refinement is to add to this average the value of the function at the halfway point. 
 The second stage of refinement is to add the values at the 1/4 and 3/4 points. And so 
 on (see Figure 4.2.1).
  
 Without further ado we can write a routine with this kind of logic to it:",NA
4.3 Romberg Integration,"We can view Romberg’s method as the natural generalization of the routine 
 qsimp
  in the last section to integration schemes that are of higher order than 
 Simpson’s rule. The basic idea is to use the results from
  k
  successive refinements 
 of the extended trapezoidal rule (implemented in
  trapzd
 ) to remove all terms in the 
 error series up to but not including
  O
 (1
 /N
 2
 k
 )
 . The routine
  qsimp
  is the case of
  k
  = 
 2
 . This is one example of a very general idea that goes by the name of 
 Richardson’s deferred approach to the limit
 : Perform some numerical algorithm 
 for various values of a parameter
  h
 , and then extrapolate the result to the continuum 
 limit
  h
  = 0
 .
  
 Equation (4.2.4), which subtracts off the leading error term, is a special case 
 of polynomial extrapolation. In the more general Romberg case, we can use 
 Neville’s algorithm (see
  §
 3.1) to extrapolate the successive refinements to zero 
 stepsize. Neville’s algorithm can in fact be coded very concisely withina Romberg 
 integration routine. For clarity of the program, however, it seems better to do the 
 extrapolation by subroutine call to
  polint
 , already given in
  §
 3.1.
  
 SUBROUTINE qromb(func,a,b,ss)
  
 INTEGER JMAX,JMAXP,K,KM
  
 REAL a,b,func,ss,EPS
  
 EXTERNAL func
  
 C
  
 PARAMETER (EPS=1.e-6, JMAX=20, JMAXP=JMAX+1, K=5, KM=K-1) 
  
 USES polint,trapzd 
  
  
 Returns as
  ss
  the integral of the function
  func
  from
  a
  to
  b
 . Integration is performed by 
  
 Romberg’s method of order 2
 K
 , where, e.g.,
  K
 =2 is Simpson’s rule.
  
 Parameters:
  EPS
  is the fractional accuracy desired, as determined by the extrapolation
  
 error estimate;
  JMAX
  limits the total number of steps;
  K
  is the number of points used in
  
 the extrapolation.
  
 INTEGER j
  
 REAL dss,h(JMAXP),s(JMAXP) 
  
 These store the successive trapezoidal approximations
  
 h(1)=1. 
  
 and their relative stepsizes.
  
 do
  11
  j=1,JMAX
  
 call trapzd(func,a,b,s(j),j)
  
 if (j.ge.K) then
  
 call polint(h(j-KM),s(j-KM),K,0.,ss,dss)
  
 if (abs(dss).le.EPS*abs(ss)) return
  
 endif
  
 s(j+1)=s(j)
  
 h(j+1)=0.25*h(j) 
  
 enddo
  11 
  
 pause ’too many steps in qromb’END
  
 This is a key step: The factor is 0.25 even though the 
 stepsize is decreased by only 0.5. This makes the 
 extrapolation a polynomial in
  h
 2
 as allowed by 
 equation (4.2.1), not just a polynomial in
  h
 .
  
 The routine
  qromb
 , along with its required
  trapzd
  and
  polint
 , is quite 
 powerful for sufficiently smooth (e.g., analytic) integrands, integrated over 
 intervals which contain no singularities, and where the endpoints are also 
 nonsingular.
  qromb
 , in such circumstances, takes many,
  many
  fewer function 
 evaluations than either of the routines in
  §
 4.2. For example, the integral
  
  2
  
 x
 4
 log(
 x
  +
  
 x
 2
 + 1)
 dx
  
 0",NA
4.4 Improper Integrals,"For our present purposes, an integral will be “improper” if it has any of the 
 following problems:
  
  
  
 •
  its integrand goes to a finite limiting value at finite upper and lower limits, 
 but cannot be evaluated
  right on
  one of those limits (e.g.,
  sin
  x/x
  at
  x
  = 0
 )
  
  
 •
  its upper limit is
  ∞
  , or its lower limit is
  −∞
  
  
  
 •
  it has an integrable singularity at either limit (e.g.,
  x
 −
 1
 /
 2
 at
  x
  = 0
 )
  
  
  
 •
  it has an integrable singularity at a known place between its upper and lower 
 limits
  
  
  
 •
  it has an integrable singularity at an unknown place between its upper and 
 lower limits 
  
  
 If an integral is infinite (e.g.,
  ∞
 1 
  
 x
 −
 1
 dx
 ), or does not exist in a limiting sense 
 (e.g., clever algorithmics will return a meaningful answer to an ill-posed problem.
  
   
  ∞−∞
 cos
  xdx
 ), we do not call it improper; we call it impossible. No amount of
  
 In this section we will generalize the techniques of the preceding two sections 
 to cover the first four problems on the above list. A more advanced discussion of 
 quadrature with integrable singularities occurs in Chapter 18, notably
  §
 18.3. The 
 fifth problem, singularity at unknown location, can really only be handled by the 
 use of a variable stepsize differential equation integration routine, as will be given 
 in Chapter 16.
  
 We need a workhorse like the extended trapezoidal rule (equation 4.1.11), but 
 to be evaluated at the endpoints. Equation (4.1.19), the extended midpoint rule, is 
 one which is an
  open
  formula in the sense of
  §
 4.1, i.e., does not require the 
 integrand the best choice. The reason is that (4.1.19) shares with (4.1.11) the 
 “deep” property of having an error series that is entirely even in
  h
 . Indeed there is a 
 formula, not as well known as it ought to be, called the
  Second Euler-Maclaurin 
 summation formula
 ,
  
  x
 N
  
 x
 1
  
 f
 (
 x
 )
 dx
  =
  h
 [
 f
 3
 /
 2
  +
  f
 5
 /
 2
  +
  f
 7
 /
 2
  +
  · · ·
  +
  f
 N−
 3
 /
 2
  +
  f
 N−
 1
 /
 2
 ]
  
 (
 4.4.1
 )",NA
4.5 Gaussian Quadratures and Orthogonal ,NA,NA
Polynomials,"of its functional values at a set of equally spaced points, multiplied by certain aptly In the formulas of
  §
 4.1, the 
 integral of a function was approximated by the sum
  
 chosen weighting coefficients. We saw that as we allowed ourselves more freedom 
 in choosing the coefficients, we could achieve integration formulas of higher and 
 higher order. The idea of
  Gaussian quadratures
  is to give ourselves the freedom to 
 choose not only the weighting coefficients, but also the location of the abscissas at 
 which the function is to be evaluated: They will no longer be equally spaced. Thus, 
 we will have
  twice
  the number of degrees of freedom at our disposal; it will turn 
 out that we can achieve Gaussian quadrature formulas whose order is, essentially, 
 twice that of the Newton-Cotes formula with the same number of function 
 evaluations.
  
 Does this sound too good to be true? Well, in a sense it is. The catch is a 
 familiar one, which cannot be overemphasized: High order is not the same as high 
 accuracy. High order translates to high accuracy only when the integrand is very 
 smooth, in the sense of being “well-approximated by a polynomial.”",NA
4.6 Multidimensional Integrals,"Integrals of functions of several variables, over regions with dimension greater 
 than one, are
  not easy
 . There are two reasons for this. First, the number of function 
 evaluations needed to sample an
  N
 -dimensional space increases as the
  N
 th power of 
 the number needed to do a one-dimensional integral. If you need 30 function 
 evaluations to do a one-dimensional integral crudely, then you will likely need on 
 the order of 30000 evaluations to reach the same crude level for a three-
 dimensional integral. Second, the region of integration in
  N
 -dimensional space is 
 defined by not be convex or simply connected, for example. By contrast, the 
 boundary of a an
  N −
  1
  dimensional boundary which can itself be terribly 
 complicated: It need one-dimensional integral consists of two numbers, its upper 
 and lower limits.
  
  
 The first question to be asked, when faced with a multidimensional integral, is, 
 “can it be reduced analytically to a lower dimensionality?”
  
 For example, 
 so-called
  iterated integrals
  of a function of one variable
  f
 (
 t
 )
  can be reduced to one-
 dimensional integrals by the formula
  
  x
  
  t
 n
  
  t
 3
  t
 2
  
 0 
  
 dt
 n
  
 0 
  
 dt
 n−
 1
  · · ·
  
  
  x 
  
  
  
 0 
  
  
  
  
 dt
 2
  
  
  
  
  
  
 0 
  
  
  
  
  
  
 f
 (
 t
 1
 )
 dt
 1 
  
  
  
  
   
  
 (
 4.6.1
 ) 
  
 1 
  
 = (
 n −
  1)! 
 0 
  
 (
 x − t
 )
 n−
 1
 f
 (
 t
 )
 dt
  
 Alternatively, the function may have some special symmetry in the way it depends 
 on its independent variables. 
  
 If the boundary also has this symmetry, then the 
 dimension can be reduced. In three dimensions, for example, the integration of a 
 spherically symmetric function over a spherical region reduces, in polar coordinates, 
 to a one-dimensional integral.
  
 The next questions to be asked will guide your choice between two entirely 
 different approaches to doing the problem. The questions are: Is the shape of the 
 boundary of the region of integration simple or complicated? Inside the region, is 
 the integrand smooth and simple, or complicated, or locally strongly peaked? Does 
 the problem require high accuracy, or does it require an answer accurate only to a 
 percent, or a few percent?
  
 If your answers are that the boundary is complicated, the integrand is
  not 
 strongly peaked in very small regions, and relatively low accuracy is tolerable, then 
 your problem is a good candidate for
  Monte Carlo integration
 . This method is very 
 straightforward to program, in its cruder forms. One needs only to know a region",NA
Chapter 5. ,NA,NA
Evaluation of Functions,NA,NA
5.0 Introduction,"The purpose of this chapter is to acquaint you with a selection of the 
 techniques that are frequently used in evaluating functions. In Chapter 6, we will 
 apply and illustrate these techniques by giving routines for a variety of specific 
 functions. The purposes of this chapter and the next are thus mostly in harmony, 
 but there is nevertheless some tension between them: Routines that are clearest and 
 most illustrative of the general techniques of this chapter are not always the 
 methods of choice for a particular special function. By comparing this chapter to 
 the next one, you should get some idea of the balance between “general” and 
 “special” methods that occurs in practice.
  
 Insofar as that balance favors general methods, this chapter should give you 
 ideas about how to write your own routine for the evaluation of a function which, 
 while “special” to you, is not so special as to be included in Chapter 6 or the 
 standard program libraries.
  
 CITED REFERENCES AND FURTHER READING:
  
 Fike, C.T. 1968, Computer Evaluation of Mathematical Functions (Englewood Cliffs, NJ: 
 Prentice-
  
 Hall).
  
 Lanczos, C. 1956, Applied Analysis; reprinted 1988 (New York: Dover), Chapter 7.",NA
5.1 Series and Their Convergence,"Everybodyknows that an analytic functioncan be expanded inthe neighborhood 
 of a point
  x
 0
  in a power series,
  
  
 ∞
  
 f
 (
 x
 ) = 
   
 a
 k
 (
 x − x
 0
 )
 k 
  
 (
 5.1.1
 )
  
 k
 =0
  
 Such series are straightforward to evaluate. You don’t, of course, evaluate the
  k
 th 
 power of
  x−x
 0
  ab initio
  for each term; rather you keep the
  k −
 1
 st power and update 
 it with a multiply. Similarly, the form of the coefficients
  a
  is often such as to make 
 use of previous work: Terms like
  k
 !
  or
  (2
 k
 )!
  can be updated in a multiply or two.
  
 159",NA
5.2 Evaluation of Continued Fractions,"Continued fractions are often powerful ways of evaluating functions that occur 
 in scientific applications. A continued fraction looks like this:
  
 f
 (
 x
 ) =
  b
 0
  +
  
 b
 1
  +
  
 b
 2
 +
  
 a
 1
  
 a
 2
  
 (
 5.2.1
 )
  
 b
 3+
  
 a
 3
  
 a
 4
  
 b
 4+
  
 a
 5 
  
 b
 5+
 ···
  
 Printers prefer to write this as
  
 f
 (
 x
 ) =
  b
 0
  +
  
 a
 1
  
 a
 2
  
 a
 3
  
 a
 4
  
  
 a
 5 
  
 b
 5
  +
 · · ·
  
 (
 5.2.2
 )
  
 b
 1
  +
  
 b
 2
  +
  
 b
 3
  +
  
 b
 4
  +
  
 In either (5.2.1) or (5.2.2), the
  a
 ’s and
  b
 ’s can themselves be functions of
  x
 , usually 
 linear or quadratic monomials at worst (i.e., constants times
  x
  or times
  x
 2
 ). For 
 example, the continued fraction representation of the tangent function is
  
  
  
 x 
   
 x
 2 
   
 x
 2 
   
 x
 2 
  
 tan
 x
  = 
    
   
   
   
 (
 5.2.3
 ) 
  
 1
  −
  
 3
  −
  
 5
  −
  
 7
  − · · ·
  
  
 Continued fractions frequently converge much more rapidly than power series 
 expansions, and in a much larger domain in the complex plane (not necessarily 
 including the domain of convergence of the series, however). 
  
 Sometimes the 
 continued fraction converges best where the series does worst, although this is not",NA
5.3 Polynomials and Rational Functions,"of coefficients,
  c(j)
  with
  j= 1
 , . . ., N
 . A polynomial of degree
  N −
  1
  is represented 
 numerically as a stored array We will always take
  c(1)
  to be the constant term in 
 the polynomial,
  c(
 N
 )
  the coefficient of
  x
 N−
 1
 ; but of course other conventions are 
 possible. There are two kinds of manipulations that you can do with a polynomial:
  
 numerical
  manipulations (such as evaluation), where you are given the numerical 
 value of its argument, or
  algebraic
  manipulations, where you want to transform the 
 coefficient array in some way without choosing any particular argument. Let’s start 
 with the numerical.
  
 We assume that you know enough
  never
  to evaluate a polynomial this way:
  
 p=c(1)+c(2)*x+c(3)*x**2+c(4)*x**3+c(5)*x**4
  
 Come the (computer) revolution, all persons found guilty of such criminal 
 behavior will be summarily executed, and their programs won’t be! It is a matter of 
 taste, however, whether to write
  
 p=c(1)+x*(c(2)+x*(c(3)+x*(c(4)+x*c(5))))
  
 or
  
 p=(((c(5)*x+c(4))*x+c(3))*x+c(2))*x+c(1)
  
 If the number of coefficients is a large number
  n
 , one writes
  
 p=c(n)
  
 do
  11
  j=n-1,1,-1
  
 p=p*x+c(j)
  
 enddo
  11
  
  
 Another useful trick is for evaluating a polynomial
  P
  (
 x
 )
  and its derivative 
 dP
  
 (
 x
 )
 /dx
  simultaneously:
  
 p=c(n)
  
 dp=0.
  
 do
  11
  j=n-1,1,-1
  
 dp=dp*x+p
  
 p=p*x+c(j)
  
 enddo
  11
  
 which returns the polynomial as
  p
  and its derivative as
  dp
 .
  
  
 The above trick, which is basically
  synthetic division
 [1,2]
 , generalizes to the 
 evaluation of the polynomial and
  nd-1
  of its derivatives simultaneously:",NA
5.4 Complex Arithmetic,"Since
  FORTRAN
  has the built-in data type
  COMPLEX
 , you can generally let 
 the compiler and intrinsic function library take care of complex arithmetic for you. 
 Generally, but not always. For a program with only a small number of complex 
 operations, you may want to code these yourself, in-line. Or, you may find that 
 your compiler is not up to snuff: It is disconcertingly common to encounter 
 complex operations that produce overflows or underflows when both the complex 
 operands and the complex result are perfectly representable. This occurs, we think, 
 because software companies assign inexperienced programmers to what they 
 believe to be the perfectly trivial task of implementing complex arithmetic.
  
  
 Actually, complex arithmetic is not
  quite
  trivial. 
  
 Addition and subtraction 
 are done in the obvious way, performing the operation separately on the real and 
 imaginary parts of the operands. Multiplication can also be done in the obvious 
 way, with 4 multiplications, one addition, and one subtraction,
  
 (
 a
  +
  ib
 )(
 c
  +
  id
 ) = (
 ac − bd
 ) +
  i
 (
 bc
  +
  ad
 ) 
  
 (
 5.4.1
 )
  
 (the addition before the
  i
  doesn’t count; it just separates the real and imaginary parts 
 notationally). But it is sometimes faster to multiply via
  
 (
 a
  +
  ib
 )(
 c
  +
  id
 ) = (
 ac − bd
 ) +
  i
 [(
 a
  +
  b
 )(
 c
  +
  d
 )
  − ac − bd
 ] 
  
 (
 5.4.2
 )
  
 which has only three multiplications (
 ac
 ,
  bd
 ,
  (
 a
  +
  b
 )(
 c
  +
  d
 )
 ), plus two additions and 
 three subtractions. The total operations count is higher by two, but multiplication is 
 a slow operation on some machines.
  
 While it is true that intermediate results in equations (5.4.1) and (5.4.2) can 
 overflow even when the final result is representable, this happens only when the 
 final answer is on the edge of representability. Not so for the complex modulus, if 
 you or your compiler are misguided enough to compute it as
  
 |a
  +
  ib|
  =
  
 a
 2
 +
  b
 2
  
 (bad!)
  
 (
 5.4.3
 )
  
 whose intermediate result will overflow if either
  a
  or
  b
  is as large as the square root 
 of the largest representable number (e.g.,
  10
 19
 as compared to
  10
 38
 ). The right way 
 to do the calculation is
  
 |a
  +
  ib|
  =
  
  |a| 
 |b|
  
 1 + (
 b/a
 )
 2
  
 |a| ≥ |b| 
  
 |a| < |b|
  
 (
 5.4.4
 )
  
 1 + (
 a/b
 )
 2
  
  
 Complex division should use a similar trick to prevent avoidable overflows, 
 underflow, or loss of precision,
  
 a
  +
  ib 
  
 c
  +
  id
 =
  
  
  
 [
 a
  +
  b
 (
 d/c
 )] +
  i
 [
 b − a
 (
 d/c
 )] 
 c
  
 +
  d
 (
 d/c
 )
  
 |c| ≥ |d|
  
 (
 5.4.5
 )
  
 [
 a
 (
 c/d
 ) +
  b
 ] +
  i
 [
 b
 (
 c/d
 )
  − a
 ] 
 c
 (
 c/d
 ) +
  d
  
 |c| < |d|",NA
5.5 Recurrence Relations and Clenshaw’s ,NA,NA
Recurrence Formula,"Many useful functions satisfy recurrence relations, e.g.,
  
 (
 n
  + 1)
 P
 n
 +1
 (
 x
 ) = (2
 n
  + 1)
 xP
 n
 (
 x
 )
  − nP
 n−
 1
 (
 x
 ) 
 (5.5.1)
  
 J
 n
 +1
 (
 x
 ) = 2
 n x J
 n
 (
 x
 )
  − J
 n−
 1
 (
 x
 ) 
 (5.5.2)
  
 nE
 n
 +1
 (
 x
 ) =
  e
 −x
 − xE
 n
 (
 x
 ) 
  
 (5.5.3)
  
 cos
  nθ
  = 2 cos
  θ
  cos(
 n −
  1)
 θ −
  cos(
 n −
  2)
 θ
  
 (5.5.4)
  
 sin
  nθ
  = 2 cos
  θ
  sin(
 n −
  1)
 θ −
  sin(
 n −
  2)
 θ
 (5.5.5)
  
 where the first three functions are Legendre polynomials, Bessel functions of the 
 first kind, and exponential integrals, respectively. (For notation see
 [1]
 .) These 
 relations",NA
5.6 Quadratic and Cubic Equations,"The roots of simple algebraic equations can be viewed as being functions of 
 the equations’ coefficients. We are taught these functions in elementary algebra. 
 Yet, surprisingly many people don’t know the right way to solve a quadratic 
 equation with two real roots, or to obtain the roots of a cubic equation.
  
 There are two ways to write the solution of the
  quadratic equation
  
 ax
 2
 +
  bx
  +
  c
  = 0 
  
 (
 5.6.1
 )
  
 with real coefficients
  a, b, c
 , namely
  
  
 x
  =
 −b ±√b
 2
 −
  4
 ac 
  
 (
 5.6.2
 ) 
  
   
  
   
 2
 a 
  
 and 
  
  
   
  
    
 2
 c 
  
  
 x
  =
   
  
 −b ±√b
 2
 −
  4
 ac 
  
  
  
   
  
    
 (
 5.6.3
 )
  
 If you use
  either
  (5.6.2)
  or
  (5.6.3) to get the two roots, you are asking for trouble: 
 If either
  a
  or
  c
  (or both) are small, then one of the roots will involve the subtraction 
 of
  b
  from a very nearly equal quantity (the discriminant); you will get that root very 
 inaccurately. The correct way to compute the roots is
  
 q ≡ −
 1 
 b
  +
  sgn
 (
 b
 ) 
 b
 2
 −
  4
 ac 
  
 (
 5.6.4
 )
  
 Then the two roots are
  
 x
 1
  =
 q 
  
 a
  
 and
  
 x
 2
  =
 c 
  
 q
  
 (
 5.6.5
 )
  
 If the coefficients
  a, b, c
 , are complex rather than real, then the above formulas 
 still hold, except that in equation (5.6.4) the sign of the square root should be 
 chosen so as to make
  
 Re
 (
 b
 *
  
 b
 2
 −
  4
 ac
 )
  ≥
  0
  
 (
 5.6.6
 )
  
 where Re denotes the real part and asterisk denotes complex conjugation.
  
 Apropos of quadratic equations, this seems a convenient place to recall that 
 the inverse hyperbolic functions
  sinh
 −
 1
 and
  cosh
 −
 1
 are in fact just logarithms of 
 solutions to such equations,
  
 sinh
 −
 1
 (
 x
 ) = 
  
 ln 
 x
  + 
  
 x
 2
 + 1 
  
 (
 5.6.7
 )
  
 cosh
 −
 1
 (
 x
 ) =
  ±
  ln 
 x
  + 
 x
 2
 −
  1 
  
 (
 5.6.8
 )
  
 Equation (5.6.7) is numerically robust for
  x ≥
  0
 . For negative
  x
 , use the symmetry 
 sinh
 −
 1
 (
 −x
 ) =
  −
  sinh
 −
 1
 (
 x
 )
 . Equation (5.6.8) is of course valid only for
  x ≥
  1
 . Since
  
 FORTRAN
  mysteriously omits the inverse hyperbolic functions from its list of 
 intrinsic functions, equations (5.6.7)–(5.6.8) are sometimes quite essential.",NA
5.7 Numerical Derivatives,"Imagine that you have a procedure which computes a function
  f
 (
 x
 )
 , and now 
 you want to compute its derivative
  f
 ′
 (
 x
 )
 . Easy, right? 
  
 The definition of the 
 derivative, the limit as
  h →
  0
  of
  
 f
 ′
 (
 x
 )
  ≈f
 (
 x
  +
  h
 )
  − f
 (
 x
 ) 
  
 (
 5.7.1
 )
  
 practically suggests the program: Pick a small value
  h
 ; evaluate
  f
 (
 x
  +
  h
 )
 ; you 
 probably have
  f
 (
 x
 )
  already evaluated, but if not, do it too; finally apply equation 
 (5.7.1). 
  
 What more needs to be said?
  
  
 Quite a lot, actually. 
  
 Applied uncritically, the above procedure is almost 
 guaranteed to produce inaccurate results. Applied properly, it can be the right way 
 to compute a derivative only when the function
  f
  is
  fiercely
  expensive to compute, 
 when you already have invested in computing
  f
 (
 x
 )
 , and when, therefore, you want to 
 get the derivative in no more than a single additional function evaluation. In such a 
 situation, the remaining issue is to choose
  h
  properly, an issue we now discuss: 
  
 There are two sources of error in equation (5.7.1), truncation error and 
 roundoff error. The truncation error comes from higher terms in the Taylor series 
 expansion,
  
 f
 (
 x
  +
  h
 ) =
  f
 (
 x
 ) +
  hf
 ′
 (
 x
 ) + 1 2
 h
 2
 f
 ′′
 (
 x
 ) + 1 6
 h
 3
 f
 ′′′
 (
 x
 ) +
  · · ·
  
 (
 5.7.2
 )
  
 whence",NA
5.8 Chebyshev Approximation,"The Chebyshev polynomial of degree
  n
  is denoted
  T
 n
 (
 x
 )
 , and is given by the 
 explicit formula
  
 T
 n
 (
 x
 ) = cos(
 n
  arccos
  x
 ) 
  
 (
 5.8.1
 )
  
 This may look trigonometric at first glance (and there is in fact a close relation 
 between the Chebyshev polynomials and the discrete Fourier transform); however 
 (5.8.1) can be combined with trigonometric identities to yield explicit expressions 
 for
  T
 n
 (
 x
 )
  (see Figure 5.8.1),
  
 T
 0
 (
 x
 ) = 1
  
 T
 1
 (
 x
 ) =
  x
  
 T
 2
 (
 x
 ) = 2
 x
 2
 −
  1
  
 T
 3
 (
 x
 ) = 4
 x
 3
 −
  3
 x 
  
 (
 5.8.2
 )
  
 T
 4
 (
 x
 ) = 8
 x
 4
 −
  8
 x
 2
 + 1
  
 · · ·
  
 T
 n
 +1
 (
 x
 ) = 2
 xT
 n
 (
 x
 )
  − T
 n−
 1
 (
 x
 ) 
 n ≥
  1
 .
  
 (There also exist inverse formulas for the powers of
  x
  in terms of the
  T
 n
 ’s — see 
 equations 5.11.2-5.11.3.)
  
 (1
  − x
 2
 )
 −
 1
 /
 2
 . The Chebyshev polynomials are orthogonal in the interval
  [
 −
 1
 ,
  1]
  over a weight In particular,
  
  1
  
 −
 1 
  
 T
 i
 (
 x
 )
 T
 j
 (
 x
 )
  
  
  
 √
 1
  − x
 2
  dx
  = 
  
  
    
 0
  
 π/
 2
  
 π
  
 i ̸
 =
  j 
  
 i
  =
  j ̸
 = 0 
 i
  =
  j
  = 0 
  
  
 (
 5.8.3
 )
  
 at the points The polynomial
  T
 n
 (
 x
 )
  has
  n
  zeros in the interval
  [
 −
 1
 ,
  1]
 , and they are located
  
 x
  = cos
  
 π
 (
 k −
  1 2
 ) 
  
 k
  = 1
 ,
  2
 , . . ., n 
  
 (
 5.8.4
 ) 
  
  
 n",NA
5.9 Derivatives or Integrals of a ,NA,NA
Chebyshev-approximated Function,"If you have obtained the Chebyshev coefficients that approximate a function 
 in a certain range (e.g., from
  chebft
  in
  §
 5.8), then it is a simple matter to transform 
 them to Chebyshev coefficients corresponding to the derivative or integral of the 
 function. Having done this, you can evaluate the derivative or integral just as if it 
 were a function that you had Chebyshev-fitted
  ab initio
 .
  
  
 The relevant formulas are these: If
  c
 i
 , i
  = 1
 , . . ., m
  are the coefficients that 
 approximate a function
  f
  in equation (5.8.9),
  C
 i
  are the coefficients that approximate 
  
  
 i
 are the coefficients that approximate the derivative 
 the indefinite integral of
  f
 , and
  c
 ′
  
 of
  f
 , then
  
 C
 i
  =
 c
 i−
 1
  − c
 i
 +1 
 (
 i >
  1) 
  
 (
 5.9.1
 ) 
  
 2(
 i −
  1)
  
 c
 ′i−
 1
 =
  c
 ′i
 +1
 + 2(
 i −
  1)
 c
 i 
  
 (
 i
  =
  m −
  1
 , m −
  2
 , . . .,
  2) 
  
 (
 5.9.2
 )
  
 Equation (5.9.1) is augmented by an arbitrary choice of
  C
 1
 , corresponding to 
 an arbitrary constant of integration. Equation (5.9.2), which is a recurrence, is 
 started with the values
  c
 ′m
 =
  c
 ′m
 +1
 = 0
 , corresponding to no information about the
  m
  
 + 1
 st Chebyshev coefficient of the original function
  f
 .
  
 Here are routines for implementing equations (5.9.1) and (5.9.2).
  
 SUBROUTINE chder(a,b,c,cder,n) 
  
 INTEGER n 
  
 REAL a,b,c(n),cder(n) 
  
  
 Given
  a,b,c(1:n)
 , as output from routine
  chebft
  §
 5
 .
 8, and given
  n
 , the desired degree of 
 approximation (length of
  c
  to be used), this routine returns the array
  cder(1:n)
 , the 
  
 Chebyshev coefficients of the derivative of the function whose coefficients are
  c(1:n)
 .
  
 INTEGER j 
  
 REAL con 
  
 cder(n)=0. 
  
 n and n-1 are special cases.
  
 cder(n-1)=2*(n-1)*c(n) 
  
 do
  11
  j=n-2,1,-1 
  
 cder(j)=cder(j+2)+2*j*c(j+1) 
  
 Equation (5.9.2).
  
 enddo
  11 
  
 con=2./(b-a) 
  
 do
  12
  j=1,n 
  
 Normalize to the interval b-a.
  
 cder(j)=cder(j)*con 
  
 enddo
  12 
  
 return 
  
 END
  
 SUBROUTINE chint(a,b,c,cint,n) 
  
 INTEGER n 
  
 REAL a,b,c(n),cint(n) 
  
  
 Given
  a,b,c(1:n)
 , as output from routine
  chebft
  §
 5
 .
 8, and given
  n
 , the desired degree of 
 approximation (length of
  c
  to be used), this routine returns the array
  cint(1:n)
 , the 
  
 Chebyshev 
 coefficients of the integral of the function whose coefficients are
  c
 . The constant 
  
 of integration 
 is set so that the integral vanishes at
  a
 .
  
 INTEGER j 
  
 REAL con,fac,sum",NA
5.10 Polynomial Approximation from ,NA,NA
Chebyshev Coefficients,"You may well ask after reading the preceding two sections, “Must I store and 
 evaluate my Chebyshev approximation as an array of Chebyshev coefficients for a 
 transformed variable
  y
 ? Can’t I convert the
  c
 k
 ’s into actual polynomial coefficients 
 in the original variable
  x
  and have an approximation of the following form?”
  
 m
  
 f
 (
 x
 )
  ≈
  
 g
 k
 x
 k−
 1 
  
 (
 5.10.1
 )
  
  
  
 k
 =1 
  
  
 Yes, you can do this (and we will give you the algorithm to do it), but we 
 caution you against it: Evaluating equation (5.10.1), where the coefficient
  g
 ’s reflect 
 an underlying Chebyshev approximation, usually requires more significant figures 
 than evaluation of the Chebyshev sum directly (as by
  chebev
 ). This is because the 
 Chebyshev polynomials themselves exhibit a rather delicate cancellation: The 
 leading coefficient of
  T
 n
 (
 x
 )
 , for example, is
  2
 n−
 1
 ; other coefficients of
  T
 n
 (
 x
 )
  are 
 Only
  when
  m
  is no larger than 7 or 8 should you contemplate writing a Chebyshev 
 even bigger; yet they all manage to combine into a polynomial that lies between
  ±
 1
 . 
 fit as a direct polynomial, and even in those cases you should be willing to tolerate 
 two or so significant figures less accuracy than the roundoff limit of your machine.
  
 You get the
  g
 ’s in equation (5.10.1) from the
  c
 ’s output from
  chebft
  (suitably 
 truncated at amodest valueof
 m
 )bycallinginsequencethe followingtwoprocedures:
  
 SUBROUTINE chebpc(c,d,n) 
  
 INTEGER n,NMAX 
  
 REAL c(n),d(n) 
  
 PARAMETER (NMAX=50) 
  
 Maximum anticipated value of n.
  
 Chebyshev polynomial coefficients. Given a coefficient array
  c(1:n)
  of length
  n
 , this routine 
 k
 =1
 d
 k
 y
 k−
 1
  =
 n 
 k
 =1
 c
 k
 T
 k−
 1
 (
 y
 )
  −
 c
 1
 /
 2. generates a 
 coefficient array
  d(1:n)
  such that
 n 
 The 
 method is Clenshaw’s recurrence (5.8.11), 
 but now applied algebraically rather than
  
 arithmetically.
  
 INTEGER j,k 
  
 REAL sv,dd(NMAX) 
  
 do
  11
  j=1,n 
  
 d(j)=0.
  
 dd(j)=0.
  
 enddo
  11 
  
 d(1)=c(n) 
  
 do
  13
  j=n-1,2,-1 
  
 do
  12
  k=n-j+1,2,-1 
  
  
  
 sv=d(k) 
  
  
  
 d(k)=2.*d(k-1)-dd(k) 
  
  
  
 dd(k)=sv 
  
 enddo
  12 
  
 sv=d(1) 
  
 d(1)=-dd(1)+c(j) 
  
 dd(1)=sv 
  
 enddo
  13 
  
 do
  14
  j=n,2,-1 
  
 d(j)=d(j-1)-dd(j) 
  
 enddo
  14 
  
 d(1)=-dd(1)+0.5*c(1) 
  
 return 
  
 END",NA
5.11 Economization of Power Series,"One particular application of Chebyshev methods, the
  economization of power series
 , is 
 an occasionally useful technique, with a flavor of getting something for nothing. 
  
  
 Suppose that you are already computing a function by the use of a convergent power 
 series, for example
  
 f
 (
 x
 )
  ≡
  1
  −x 
 3! +
  x
 2 
 5!
 − x
 3 
 7! +
  · · ·
  
 (
 5.11.1
 )
  
 (This function is actually
  sin(
 √x
 )
 /√x
 , but pretend you don’t know that.) You might be 
 doing a problem that requires evaluating the series many times in some particular interval, 
 say 
 [0
 ,
  (2
 π
 )
 2
 ]
 . Everything is fine, except that the series requires a large number of terms 
 before its error (approximated by the first neglected term, say) is tolerable. In our example, 
 with 
 x
  = (2
 π
 )
 2
 , the first term smaller than
  10
 −
 7
 is
  x
 13
 /
 (27!)
 . This then approximates the error 
 of the finite series whose last term is
  x
 12
 /
 (25!)
 .
  
 Notice that because of the large exponent in
  x
 13
 , the error is
  much smaller
  than
  10
 −
 7 
 everywhere in the interval except at the very largest values of
  x
 . This is the feature that 
 allows“economization”: if we are willing to let the error elsewhere in the interval rise to 
 about the same value that the first neglected term has at the extreme end of the interval, then 
 we can replace the 13-term series by one that is significantly shorter.
  
  
 Here are the steps for doing so: 
  
 1. Change variables from
  x
  to
  y
 , as in equation (5.8.10), to map the
  x
  interval into
  
 2. Find the coefficients of the Chebyshev sum (like equation 5.8.8) that exactly equals your
 −
 1
  ≤ y ≤
  1
 .
  
 truncated power series (the one with enough terms for accuracy).",NA
5.12 Pad´e Approximants,"A
  Pad´e approximant
 , so called, is that rational function (of a specified order) whose 
 power series expansion agrees with a given power series to the highest possible order. If the 
 rational function is
  
 M
  
 a
 k
 x
 k
  
 R
 (
 x
 )
  ≡
  
 k
 =0
  
 b
 k
 x
 k
  
 (
 5.12.1
 )
  
 N
  
 1 +
  
 k
 =1
  
 then
  R
 (
 x
 )
  is said to be a Pad´e approximant to the series
  
 if
  
 f
 (
 x
 )
  ≡
  
 ∞
  
 c
 k
 x
 k
  
 (
 5.12.2
 )
  
 k
 =0
  
 (
 5.12.3
 )
  
 R
 (0) =
  f
 (0)",NA
5.13 Rational Chebyshev Approximation,"In
  §
 5.8 and
  §
 5.10 we learned how to find good polynomial approximations to a given 
 function
  f
 (
 x
 )
  in a given interval
  a ≤ x ≤ b
 . Here, we want to generalize the task to find good 
 approximations that are rational functions (see
  §
 5.3). The reason for doing so is that, for 
 some functions and some intervals, the optimal rational function approximation is able to 
 achieve substantially higher accuracy than the optimal polynomial approximation with the 
 same number of coefficients. This must be weighed against the fact that finding a rational 
 function approximation is not as straightforward as finding a polynomial approximation, 
 which, as we saw, could be done elegantly via Chebyshev polynomials.",NA
5.14 Evaluation of Functions by Path ,NA,NA
Integration,"In computer programming, the technique of choice is not necessarily the most 
 efficient, or elegant, or fastest executing one. Instead, it may be the one that is 
 quick to implement, general, and easy to check.
  
 One sometimes needs only a few, or a few thousand, evaluations of a special 
 function, perhaps a complex valued function of a complex variable, that has many 
 different parameters, or asymptotic regimes, or both. Use of the usual tricks (series, 
 continued fractions, rational function approximations, recurrence relations, and so 
 forth) may result in a patchwork program with tests and branches to different 
 formulas. While such a program may be highly efficient in execution, it is often not 
 the shortest way to the answer from a standing start.
  
 A different technique of considerable generality is direct integration of a 
 function’s defining differential equation – an ab initio integration for each desired",NA
Chapter 6. ,NA,NA
Special Functions,NA,NA
6.0 Introduction,"There is nothing particularly special about a
  special function
 , except that some 
 person in authority or textbook writer (not the same thing!) has decided to bestow 
 the moniker. Special functions are sometimes called
  higher transcendental 
 functions
  (higher than what?) or
  functions of mathematical physics
  (but they occur 
 in other fields also) or
  functions that satisfy certain frequently occurring second-
 order differential equations
  (but not all special functions do). One might simply 
 call them“useful functions” and let it go at that; it is surely only a matter of taste 
 which functions we have chosen to include in this chapter.
  
 Good commercially available program libraries, such as NAG or IMSL, 
 contain routines for a number of special functions. These routines are intended for 
 users who will have no idea what goes on inside them. Such state of the art “black 
 boxes” are often very messy things, full of branches to completely different 
 methods depending on the value of the calling arguments. Black boxes have, or 
 should have, careful control of accuracy, to some stated uniform precision in all 
 regimes.
  
 We will not be quite so fastidious in our examples, in part because we want to 
 illustrate techniques from Chapter 5, and in part because we
  want
  you to 
 understand what goes on in the routines presented. Some of our routines have an 
 accuracy parameter that can be made as small as desired, while others (especially 
 those involving polynomial fits) give only a certain accuracy, one that we believe 
 serviceable (typically six significant figures or more). We do
  not
  certify that the 
 routines are perfect black boxes. We do hope that, if you ever encounter trouble in 
 a routine, you will be able to diagnose and correct the problem on the basis of the 
 information that we have given.
  
 In short, the special function routines of this chapter are meant to be used —
 we use them all the time — but we also want you to be prepared to understand their 
 inner workings.
  
 CITED REFERENCES AND FURTHER READING:
  
 Abramowitz, M., and Stegun, I.A. 1964, Handbook of Mathematical Functions, Applied Mathe-
 matics Series, Volume 55 (Washington: National Bureau of Standards; reprinted 1968 by 
 Dover Publications, New York) [full of useful numerical approximations to a great variety 
 of functions].
  
 IMSL Sfun/Library Users Manual (IMSL Inc., 2500 CityWest Boulevard, Houston TX 77042).
  
 NAG Fortran Library (Numerical Algorithms Group, 256 Banbury Road, Oxford OX27DE, U.K.), 
  
 Chapter S.
  
 205",NA
"6.1 Gamma Function, Beta Function, Factorials, ",NA,NA
Binomial Coefficients,"The gamma function is defined by the integral
  
 Γ(
 z
 ) =
  
  ∞
  
 t
 z−
 1
 e
 −t
 dt
  
 (
 6.1.1
 )
  
 0
  
 When the argument
  z
  is an integer, the gamma function is just the familiar factorial 
 function, but offset by one,
  
 n
 ! = Γ(
 n
  + 1) 
  
 (
 6.1.2
 )
  
 The gamma function satisfies the recurrence relation
  
 Γ(
 z
  + 1) =
  z
 Γ(
 z
 ) 
  
 (
 6.1.3
 )
  
 If the function is known for arguments
  z >
  1
  or, more generally, in the half complex 
 plane Re
 (
 z
 )
  >
  1
  it can be obtained for
  z <
  1
  or Re
  (
 z
 )
  <
  1
  by the reflection formula
  
  
  
 π
  
  
 πz
  
 Γ(1
  − z
 ) =Γ(
 z
 ) sin(
 πz
 ) =Γ(1 +
  z
 ) sin(
 πz
 ) 
  
  
  
  
  
 (
 6.1.4
 )
  
 Notice that
  Γ(
 z
 )
  has a pole at
  z
  = 0
 , and at all negative integer values of
  z
 .
  
  
 There are a variety of methods in use for calculating the function
  Γ(
 z
 ) 
 numerically, but none is quite as neat as the approximation derived by Lanczos
 [1]
 . 
 This scheme is entirely specific to the gamma function, seemingly plucked from 
 thin air. 
  
 We will not attempt to derive the approximation, but only state the 
 resulting formula: For certain integer choices of
  γ
  and
  N
 , and for certain coefficients 
 c
 1
 , c
 2
 , . . ., c
 N
 , the gamma function is given by
  
 Γ(
 z
  + 1) = (
 z
  +
  γ
  +
 1 2
 )
 z
 +
  1 2
  e
 −
 (
 z
 +
 γ
 +
  1 2
 )
  
 ×√
 2
 πc
 0
  + 
 z
  + 1 + 
  
   
   
 c
 1 
  
  
  
  
  
 z
  + 2 +
  · · 
 ·
  + 
   
  
   
   
 c
 2 
  
  
  
  
  
  
  
  
 z
  +
  N
 +
  ϵ
  
   
   
   
  
 c
 N 
   
  
  
  
    
  
  
 (
 z >
  0) 
    
   
  
  
  
  
  
  
 (
 6.1.5
 )
  
 You can see that this is a sort of take-off on Stirling’s approximation, but with a 
 series of corrections that take into account the first few poles in the left complex 
 plane. The constant
  c
 0
  is very nearly equal to 1. The error term is parametrized by",NA
"6.2 Incomplete Gamma Function, Error ",NA,NA
"Function, Chi-Square Probability Function, ",NA,NA
Cumulative Poisson Function,"The incomplete gamma function is defined by
  
 P
  (
 a, x
 )
  ≡γ
 (
 a, x
 )
  
 ≡
  
 1
  
  x
  
 e
 −t
 t
 a−
 1
 dt
  
 (
 a >
  0)
  
 (
 6.2.1
 )
  
 Γ(
 a
 )
  
 0",NA
6.3 Exponential Integrals,"The standard definition of the exponential integral is
  
 E
 n
 (
 x
 ) =
  
  ∞
  
 e
 −xt 
  
 t
 n
  dt,
  
 x >
  0
 ,
  
 n
  = 0
 ,
  1
 , . . .
  
 (
 6.3.1
 )
  
 1
  
 The function defined by the principal value of the integral
  
 Ei(
 x
 ) =
  −
  
  
  ∞
 e
 −t
  
 t
  
 dt
  =
  
  x 
 e
 t
  
 t dt, 
  
 x >
  0 
  
 (
 6.3.2
 )
  
 −x
  
 −∞
  
 is also called an exponential integral. Note that
  Ei(
 −x
 )
  is related to
  −E
 1
 (
 x
 )
  by analytic continuation.",NA
"6.4 Incomplete Beta Function, Student’s ",NA,NA
"Distribution, F-Distribution, Cumulative ",NA,NA
Binomial Distribution,"The incomplete beta function is defined by
  
 I
 x
 (
 a, b
 )
  ≡B
 x
 (
 a, b
 ) 
 B
 (
 a, b
 )
 ≡
  
 1
  
  x
  
 t
 a−
 1
 (1
  − t
 )
 b−
 1
 dt
  
 (
 a, b >
  0)
  
 (
 6.4.1
 )
  
 B
 (
 a, b
 )
  
 0
  
 It has the limiting values
  
 I
 0
 (
 a, b
 ) = 0
  
 I
 1
 (
 a, b
 ) = 1
  
 (
 6.4.2
 )
  
 and the symmetry relation
  
 I
 x
 (
 a, b
 ) = 1
  − I
 1
 −x
 (
 b, a
 ) 
  
 (
 6.4.3
 )
  
 If
  a
  and
  b
  are both rather greater than one, then
  I
 x
 (
 a, b
 )
  rises from “near-zero” 
 to“near-unity” quite sharply at about
  x
  =
  a/
 (
 a
  +
  b
 )
 . Figure 6.4.1 plots the function 
 for several pairs
  (
 a, b
 )
 .
  
 The incomplete beta function has a series expansion
  
 I
 x
 (
 a, b
 ) =
 x
 a
 (1
  − x
 )
 b 
  
 aB
 (
 a, b
 )
  
 1 +
  
 ∞
  
 B
 (
 a
  + 1
 , n
  + 1) 
  
 B
 (
 a
  +
  b, n
  + 1)
 x
 n
 +1
  
 ,
  
 (
 6.4.4
 )
  
 n
 =0
  
 but this does not prove to be very useful in its numerical evaluation. (Note, 
 however, that the beta functions in the coefficients can be evaluated for each value 
 of
  n
  with just the previous value and a few multiplies, using equations 6.1.9 and 
 6.1.3.) 
  
 The continued fraction representation proves to be much more 
 useful,
  
 I
 x
 (
 a, b
 ) =
 x
 a
 (1
  − x
 )
 b 
 aB
 (
 a, b
 )
  
  1
  
 d
 1
  
 d
 2 
  
 1+
 · · ·
  
 (
 6.4.5
 )
  
 1+
  
 1+",NA
6.5 Bessel Functions of Integer Order,"This section and the next one present practical algorithmsfor computing 
 various kinds of Bessel functions of integer order. In
  §
 6.7 we deal with fractional 
 order. In fact, the more complicated routines for fractional order work fine for 
 integer order too. For integer order, however, the routines in this section (and
  §
 6.6) 
 are simpler and faster. 
  
 Their only drawback is that they are limited by the 
 precision of the underlying rational approximations. For full double precision, it is 
 best to work with 
  
 For any real
  ν
 , the Bessel function
  J
 ν
 (
 x
 )
  can be defined by 
 the series the routines for fractional order in
  §
 6.7.
  
 representation
  
 J
 ν
 (
 x
 ) = 
  
 1 
  
 2
 x
  
  
  
 ν
  
 ∞
  
 k
 !Γ(
 ν
  +
  k
  + 1) 
  
 (
 −
 1 4
 x
 2
 )
 k 
  
 (
 6.5.1
 )
  
 k
 =0
  
 The series converges for all
  x
 , but it is not computationally very useful for
  x ≪
  1
 . For
  ν
  not
  an integer the Bessel 
 function
  Y
 ν
 (
 x
 )
  is given by
  
 Y
 ν
 (
 x
 ) =
 J
 ν
 (
 x
 ) cos(
 νπ
 )
  − J
 −ν
 (
 x
 ) 
  
 (
 6.5.2
 ) 
  
 sin(
 νπ
 )
  
 The right-hand side goes to the correct limiting value
  Y
 n
 (
 x
 )
  as
  ν
  goes to some 
 integer
  n
 , but this is also not computationally useful.
  
  
 For arguments
  x < ν
 , both Bessel functions look qualitatively like simple power 
 laws, with the asymptotic forms for
  0
  < x ≪ ν",NA
6.6 Modified Bessel Functions of Integer Order,"The modified Bessel functions
  I
 n
 (
 x
 )
  and
  K
 n
 (
 x
 )
  are equivalent to the usual 
 Bessel functions
  J
 n
  and
  Y
 n
  evaluated for purely imaginary arguments. In detail, the 
 relationship is
  
 I
 n
 (
 x
 ) = (
 −i
 )
 n
 J
 n
 (
 ix
 ) 
  
 (
 6.6.1
 ) 
 K
 n
 (
 x
 ) =
 π
 2
 i
 n
 +1
 [
 J
 n
 (
 ix
 ) +
  iY
 n
 (
 ix
 )]
  
 The particular choice of prefactor and of the linear combination of
  J
 n
  and
  Y
 n
  to form 
 K
 n
  are simply choices that make the functions real-valued for real arguments
  x
 .
  
 simple powers of their argument For small arguments
  x ≪ n
 , both
  I
 n
 (
 x
 )
  and
  K
 n
 (
 x
 )
  become, asymptotically,
  
 I
 n
 (
 x
 )
  ≈
 1 
 n
 ! 
  
 2 
   
 n ≥
  0 
  
  
  
 x 
  
 n
  
 K
 0
 (
 x
 )
  ≈ −
  ln(
 x
 ) 
  
 (
 6.6.2
 )
  
 K
 n
 (
 x
 )
  ≈
 (
 n −
  1)! 
  
  
 x
  
 2
  
  
 −n 
  
 n >
  0",NA
"6.7 Bessel Functions of Fractional Order, Airy ",NA,NA
"Functions, Spherical Bessel Functions","Many algorithms have been proposed for computing Bessel functions of fractional 
 order numerically. Most of them are, in fact, not very good in practice. The routines given 
 here are rather complicated, but they can be recommended wholeheartedly.
  
 Ordinary Bessel Functions
  
 The basic idea is
  Steed’s method
 , which was originally developed
 [1]
 for Coulomb wave 
 functions. The method calculates
  J
 ν
 ,
  J
 ′ν
 ,
  Y
 ν
 , and
  Y
  ′ν
 simultaneously, and so involves four 
 relations among these functions. Three of the relations come from two continued fractions, 
 one of which is complex. The fourth is provided by the Wronskian relation
  
 W ≡ J
 ν
 Y
 ′ν
 − Y
 ν
 J
  ′ν
 = 2
  
  
 πx 
   
  
  
 (
 6.7.1
 )
  
 The first continued fraction, CF1, is defined by
  
 f
 ν
  ≡J
  ′
 J
 ν
 =
  νx− J
 ν
 +1 
   
  
  
 (
 6.7.2
 ) 
  
 =
 νx−
 2(
 ν
  + 1)
 /x −
   
  
  
  
 1 
  
  
   
  
  
 2(
 ν
  + 2)
 /x − · · ·
  
  
  
  
   
  
 1
  
 You can easily derive it from the three-term recurrence relation for Bessel functions: Start 
 with equation (6.5.6) and use equation (5.5.18). Forward evaluation of the continued fraction 
 by one of the methods of
  §
 5.2 is essentially equivalent to backward recurrence of the 
 recurrence relation. The rate of convergence of CF1 is determined by the position of the
  
 turning point
  
 x
 tp
  =
  
 ν
 (
 ν
  + 1)
  ≈ ν
 , beyond which the Bessel functions become oscillatory. If
  x
 <≪
  x
 tp
 , 
 convergenceis very rapid. If
  x
 >≪
  x
 tp
 , then each iteration of the continued fraction effectively 
 increases
  ν
  by one until
  x
 <≪
  x
 tp
 ; thereafter rapid convergence sets in. Thus the number 
 allowed number of iterations to 10,000. 
  
 For larger
  x
 , you can use the usual asymptotic 
 expressions for Bessel functions.
  
  
 One can show that the sign of
  J
 ν
  is the same as the sign of the denominator of CF1 once 
 it has converged.
  
 The complex continued fraction CF2 is defined by
  
 p
  +
  iq ≡J
  ′
 J
 ν
  +
  iY
 ν
 =
  −
  1 2
 x
 +
  i
  +
  i x 
  
    
 (1
 /
 2)
 2
 − ν
 2 
  
  
  
  
  
 2(
 x
  +
  i
 ) + 
  
 2(
 x
  + 2
 i
 ) +
 · · ·
 (3
 /
 2)
 2
 − ν
 2 
  
 (
 6.7.3
 )
  
 (We sketch the derivation of CF2 in the analogous case of modified Bessel functions in the 
 next subsection.) This continued fraction converges rapidly for
  x
 >≪
  x
 tp
 , while convergence",NA
6.8 Spherical Harmonics,"Spherical harmonics occur in a large variety of physical problems, for ex-
 ample, whenever a wave equation, or Laplace’s equation, is solved by separa-tion of 
 variables in spherical coordinates. 
  
 The spherical harmonic
  Y
 lm
 (
 θ, φ
 )
 ,−l 
 ≤ m ≤ l,
  is a function of the two coordinates
  θ, φ
  on the surface of a sphere. The 
 spherical harmonics are orthogonal for different
  l
  and
  m
 , and they are normalized so 
 that their integrated square over the sphere is unity:
  
  2
 π
  
  1
  
 dφd
 (cos
  θ
 )
 Y
 l
 ′
 m
 ′
 *(
 θ, φ
 )
 Y
 lm
 (
 θ, φ
 ) =
  δ
 l
 ′
 l
 δ
 m
 ′
 m 
  
 (
 6.8.1
 )
  
 0
 −
 1 
  
 Here asterisk denotes complex conjugation.
  
  
 Mathematically, the spherical harmonics are related to
  associated Legendre 
 polynomials
  by the equation
  
 Y
 lm
 (
 θ, φ
 ) = 
  
  
 2
 l
  + 1
  
 4
 π
 (
 l − m
 )! (
 l
  +
  m
 )!
 P
  m l
 (cos
  θ
 )
 e
 imφ
  
 (
 6.8.2
 )
  
 By using the relation
  
 Y
 l,−m
 (
 θ, φ
 ) = (
 −
 1)
 m
 Y
 lm
 *(
 θ, φ
 ) 
  
 (
 6.8.3
 )
  
 we can always relate a spherical harmonic to an associated Legendre polynomial 
 with
  m ≥
  0
 . With
  x ≡
  cos
  θ
 , these are defined in terms of the ordinary Legendre 
 polynomials (cf.
  §
 4.5 and
  §
 5.5) by
  
 P
 m l
 (
 x
 ) = (
 −
 1)
 m
 (1
  − x
 2
 )
 m/
 2
  d
 m 
 dx
 m
  P
 l
 (
 x
 ) 
  
 (
 6.8.4
 )
  
  
 The first few associated Legendre polynomials, and their corresponding nor-
 malized spherical harmonics, are
  
 P
 0 0
 (
 x
 ) = 
  
 1 
  
 Y
 00
  = 
 4
 π
  
   
  
  
 1
  
 P
 1 1
 (
 x
 ) =
  −
  (1
  − x
 2
 )
 1
 /
 2 
  
 Y
 11
  =
  −
 8
 π
 sin
  θe
 iφ
  
 P
 0 1
 (
 x
 ) = 
  
 x 
  
 Y
 10
  = 
 4
 π
 cos
  θ
  
  
  
  
  
 3
  
 P
 2 2
 (
 x
 ) = 3 (1
  − x
 2
 ) 
  
 Y
 22
  =
 1 4 2
 π
 sin
 2
  θe
 2
 iφ
  
 P
 1 2
 (
 x
 ) =
  −
 3 (1
  − x
 2
 )
 1
 /
 2
 x 
  
 Y
 21
  =
  −
 8
 π
 sin
  θ
  cos
  θe
 iφ
  
 P
 0 2
 (
 x
 ) = 
  
 2
 (3
 x
 2
  −
  1) 
  
 Y
 20
  = 
 4
 π
 (
  3 2
 cos
 2
  θ −
  1 2
 ) 
  
  
  
  
  
  
  
 (
 6.8.5
 )
  
  
 There are many bad ways to evaluate associated Legendre polynomials numer-
 ically. For example, there are explicit expressions, such as
  
 P
 m l
 (
 x
 ) = (
 −
 1)
 m
 (
 l
  +
  m
 )! 2
 m
 m
 !(
 l − m
 )! (1
  
 − x
 2
 )
 m/
 2
  
 1
  −
 (
 l − m
 )(
 m
  +
  l
  + 1)
  
 2
  
 1
  − x 
  
 2
  
 + (
 l − m
 )(
 l − m −
  1)(
 m
  +
  l
  + 1)(
 m
  +
  l
  + 2) 2!(
 m
  + 
 1)(
 m
  + 2)
  
 1
  − x 
 2
  
 − · · ·
  
 (
 6.8.6
 )",NA
"6.9 Fresnel Integrals, Cosine and Sine Integrals","Fresnel Integrals
  
 The two Fresnel integrals are defined by
  
 C
 (
 x
 ) =
  
  x
  
 cos
  
 π
  
 2
 t
 2
  
 dt,
  
 S
 (
 x
 ) =
  
  x
  
 sin
  
 π
  
 2
 t
 2
  
 dt
  
 (
 6.9.1
 )
  
 0
  
 0
  
  
 The most convenient way of evaluating these functions to arbitrary precision is 
 to use power series for small
  x
  and a continued fraction for large
  x
 . The series are
  
 C
 (
 x
 ) =
  x −
  
 π
 2 
  
 x
 5
  
  x
 3 
  
 2 
  
 5
  ·
  2! 
 +
  
 π
  
 3
  ·
  1!
 −
  
 2
  
 3
  
 π
 4 
  
 x
 9
  
 2
  
 x
 7 
  
 9
  ·
  4!
 − · · ·
  
 π
 5 
 x
 11
  
 7
  ·
  3! + 2 11
  ·
  5!
 − · · ·
  
 (
 6.9.2
 )
  
 S
 (
 x
 ) =
  
 π
  
 2
  
  
 There is a complex continued fraction that yields both
  S
 (
 x
 )
  and
  C
 (
 x
 )
  si-
 multaneously:
  
 C
 (
 x
 ) +
  iS
 (
 x
 ) = 1 +
  i 
 2
  
 erf
  z,
  
 z
  =
  
 √π
  
 2 (1
  − i
 )
 x
  
 (
 6.9.3
 )
  
 where
  
 e
 z
 2
 erfc
  z
  =
  
 1
  
 √π
  
  1
  
 1
 /
 2
  
 1
  
 3
 /
 2
  
  
 2 
  
 z
  +
 · · ·
  
 (
 6.9.4
 )
  
 z
  +
  
 z
  +
  
 z
  +
  
 z
  +
  
 = 2
 z√π
  
 1
  
 1
  ·
  2 
  
 2
 z
 2
 + 5
  −
  
  
 3
  ·
  4 
  
 2
 z
 2
 + 9
  − · · ·
  
 2
 z
 2
 + 1
  −",NA
6.10 Dawson’s Integral,"Dawson’s Integral
  F
  (
 x
 )
  is defined by
  
 F
  (
 x
 ) =
  e
 −x
 2
  x
  
 e
 t
 2
 dt
  
 (
 6.10.1
 )
  
 0
  
 The function can also be related to the complex error function by
  
 F
  (
 z
 ) =
 i√π
 2
 e
 −z
 2
  [1
  −
  erfc
 (
 −iz
 )]
  . 
  
 (
 6.10.2
 )
  
 A remarkable approximation for
  F
  (
 x
 )
 , due to Rybicki
 [1]
 , is
  
 F
  (
 z
 ) = lim 
  
 h→
 0
  
 1
  
 √π
  
 n
  odd
  
 e
 −
 (
 z−nh
 )
 2
  
 (
 6.10.3
 )
  
 n
  
 What makes equation (6.10.3) unusual is that its accuracy increases
  exponentially 
 as
  h
  gets small, so that quite moderate values of
  h
  (and correspondingly quite rapid 
 convergence of the series) give very accurate approximations.",NA
6.11 Elliptic Integrals and Jacobian Elliptic ,NA,NA
Functions,"Elliptic integrals occur in many applications, because any integral of the form
  
 R
 (
 t, s
 )
  dt 
 (
 6.11.1
 )
  
 where
  R
  is a rational function of
  t
  and
  s
 , and
  s
  is the square root of a cubic or 
 quartic polynomial in
  t
 , can be evaluated in terms of elliptic integrals. Standard 
 references
 [1]
  describe how to carry out the reduction, which was originally done by 
 Legendre. Legendre showed that only three basic elliptic integrals are required.
  
 The simplest of these is
  
  x 
   
  
 dt 
  
 I
 1
  = 
   
  
 (
 6.11.2
 )
  
 y 
  
 (
 a
 1
  +
  b
 1
 t
 )(
 a
 2
  +
  b
 2
 t
 )(
 a
 3
  +
  b
 3
 t
 )(
 a
 4
  +
  b
 4
 t
 )
  
 where we have written the quartic
  s
 2
 in factored form. In standard integral tables
 [2]
 , 
 one of the limits of integration is always a zero of the quartic, while the other limit 
 lies closer than the next zero, so that there is no singularity within the interval. To 
 evaluate
  I
 1
 , we simply break the interval
  [
 y, x
 ]
  into subintervals, each of which either 
 begins or ends on a singularity. The tables, therefore, need only distinguish the eight 
 cases in which each of the four zeros (ordered according to size) appears as the 
 upper or lower limit of integration. In addition, when one of the
  b
 ’s in (6.11.2) tends 
 to zero, the quartic reduces to a cubic, with the largest or smallest singularity 
 moving to
  ±∞
 ; this leads to eight more cases (actually just special cases of the first 
 eight). The sixteen cases in total are then usually tabulated in terms of Legendre’s 
 standard elliptic integral of the 1st kind, which we will define below. By a change of 
 the variable of integration
  t
 , the zeros of the quartic are mapped to standard 
 locations",NA
6.12 Hypergeometric Functions,"ometric function
  2
 F
 1
 (
 a, b, c
 ;
  z
 )
 , is difficult or impossible. The function is defined as As was discussed in
  §
 5.14, a 
 fast, general routine for the the complex hyperge-
  
 the analytic continuation of the hypergeometric series,
  
 2
 F
 1
 (
 a, b, c
 ;
  z
 ) = 1 +
  ab 
  
 c 
  
 1! +
  a
 (
 a
  + 1)
 b
 (
 b
  + 1) 
  
  
 z
 2 
  
  
  
 2! +
  · · ·
  
  
 +
 a
 (
 a
  + 1)
  . . .
 (
 a
  +
  j −
  1)
 b
 (
 b
  + 1)
  . . .
 (
 b
  +
  j −
  1) 
  
  
 c
 (
 c
  + 1)
  . . 
 .
 (
 c
  +
  j −
  1) 
  
  
  
 z
 j 
   
  
  
 j
 ! +
  · · ·
  
    
  
 (
 6.12.1
 ) 
 This series converges only within the unit circle
  |z| <
  
 1
  (see
 [1]
 ), but one’s interest in the function is not confined to this region.
  
  
 Section 5.14 discussed the method of evaluating this function by direct path 
 integration in the complex plane. We here merely list the routines that result.
  
 Implementation of the function
  hypgeo
  is straightforward, and is described by 
 comments in the program. The machinery associated with Chapter 16’s routine for 
 integrating differential equations,
  odeint
 , is only minimally intrusive, and need not",NA
Chapter 7. Random Numbers,NA,NA
7.0 Introduction,"It may seem perverse to use a computer, that most precise and deterministic of 
 all machines conceived by the human mind, to produce “random” numbers. More 
 than perverse, it may seem to be a conceptual impossibility. Any program, after all, 
 will produce output that is entirely predictable, hence not truly “random.”
  
  
 Nevertheless, practical computer “random number generators” are in common 
 use. We will leave it to philosophers of the computer age to resolve the paradox in a 
 deep way (see, e.g., Knuth
 [1]
  §
 3.5 for discussion and references). One sometimes 
 hears computer-generated sequences termed
  pseudo-random
 , while the word
  
 random 
 is reserved for the output of an intrinsicallyrandom physical process, like 
 the elapsed time between clicks of a Geiger counter placed next to a sample of some 
 radioactive element. We will not try to make such fine distinctions.
  
 A working, though imprecise, definition of randomness in the context of 
 computer-generated sequences, is to say that the deterministic program that 
 produces a random sequence should be different from, and — in all measurable 
 respects —statistically uncorrelated with, the computer program that
  uses
  its 
 output. In other words, any two different random number generators ought to 
 produce statistically the same results when coupled to your particular applications 
 program. If they don’t, then at least one of them is not (from your point of view) a 
 good generator.
  
 The above definition may seem circular, comparing, as it does, one generator 
 to another. However, there exists a body of random number generators which 
 mutually do satisfy the definition over a very, very broad class of applications 
 programs. And it is also found empirically that statistically identical results are 
 obtained from random numbers produced by physical processes. So, because such 
 generators are known to exist, we can leave to the philosophers the problem of 
 defining them.
  
 A pragmatic point of view, then, is that randomness is in the eye of the 
 beholder (or programmer). What is random enough for one application may not be 
 random enough for another. Still, one is not entirely adrift in a sea of 
 incommensurable applications programs: There is a certain list of statistical tests, 
 some sensible and some merely enshrined by history, which on the whole will do a 
 very good job of ferreting out any correlations that are likely to be detected by an 
 applications program (in this case, yours). Good random number generators ought 
 to pass all of these tests; or at least the user had better be aware of any that they 
 fail, so that he or she will be able to judge whether they are relevant to the case at 
 hand.
  
 266",NA
7.1 Uniform Deviates,"Uniform deviates are just random numbers that lie within a specified range 
 (typically 0 to 1), with any one number in the range just as likely as any other. They 
 are, in other words, what you probably think “random numbers” are. 
  
 However, 
 we want to distinguish uniform deviates from other sorts of random numbers, for 
 example numbers drawn from a normal (Gaussian) distribution of specified mean 
 and standard deviation. These other sorts of deviates are almost always generated by 
 performing appropriate operations on one or more uniform deviates, as we will see 
 in subsequent sections. So, a reliable source of random uniform deviates, the subject 
 of this section, is an essential building block for any sort of stochastic modeling or 
 Monte Carlo computer work.
  
 System-Supplied Random Number Generators
  
 Your computer very likely has lurking within it a library routine which is 
 called a “random number generator.” That routine typically has an unforgettable 
 name like“
 ran
 ,” and a calling sequence like
  
 x=ran(iseed) 
  
 sets x to the next random number and updates iseed
  
 You initialize
  iseed
  to a (usually) arbitrary value before the first call to
  ran
 . 
 Each initializing value will typically return a different subsequent random 
 sequence, or at least a different subsequence of some one enormously long 
 sequence. The
  same 
 initializing value of
  iseed
  will always return the
  same
  random 
 sequence, however.
  
 Now our first, and perhaps most important, lesson in this chapter is: Be
  very, 
 very
  suspicious of a system-supplied
  ran
  that resembles the one just described. If 
 all scientific papers whose results are in doubt because of bad
  ran
 s were to 
 disappear from library shelves, there would be a gap on each shelf about as big as 
 your fist. System-supplied
  ran
 s are almost always
  linear congruential generators
 , 
 which",NA
7.2 Transformation Method: Exponential and ,NA,NA
Normal Deviates,"In the previous section, we learned how to generate random deviates with a 
 uniform probability distribution, so that the probability of generating a number 
 between
  x
  and
  x
  +
  dx
 , denoted
  p
 (
 x
 )
 dx
 , is given by
  
 p
 (
 x
 )
 dx
  =
  
  dx
  
 0
  < x <
  1 
  
 otherwise
  
 (
 7.2.1
 )
  
 0
  
 The probability distribution
  p
 (
 x
 )
  is of course normalized, so that
  
  ∞
  
 p
 (
 x
 )
 dx
  = 1
  
 (
 7.2.2
 )
  
 −∞
  
 Now suppose that we generate a uniform deviate
 x
  and then take some 
 prescribed function of it,
  y
 (
 x
 )
 . The probability distributionof
  y
 , denoted
  p
 (
 y
 )
 dy
 , is 
 determined by the fundamental transformation law of probabilities, which is simply
  
 or
  
 |p
 (
 y
 )
 dy|
  =
  |p
 (
 x
 )
 dx|
  
 (
 7.2.3
 )
  
 p
 (
 y
 ) =
  p
 (
 x
 )
  
 dx 
  
 dy
  
 (
 7.2.4
 )",NA
"7.3 Rejection Method: Gamma, Poisson, ",NA,NA
Binomial Deviates,"The
  rejection method
  is a powerful, general technique for generating random 
 deviateswhosedistributionfunction
 p
 (
 x
 )
 dx
  (probabilityofavalueoccurringbetween 
 x
  
 and
  x
  +
  dx
 ) is known and computable. The rejection method does
  not
  require that 
 the cumulative distribution function [indefinite integral of
  p
 (
 x
 )
 ] be readily 
 computable, much less the inverse of that function — which was required for the 
 transformation method in the previous section.
  
  
 The rejection method is based on a simple geometrical argument: 
  
  
 Draw a graph of the probability distribution
  p
 (
 x
 )
  that you wish to generate, so 
 that the area under the curve in any range of
  x
  corresponds to the desired probability 
 of generating an
  x
  in that range. If we had some way of choosing a random point
  in 
 two dimensions
 , with uniform probability in the
  area
  under your curve, then the
  x 
 value of that random point would have the desired distribution.
  
  
 Now, on the same graph, draw any other curve
  f
 (
 x
 )
  which has finite (not 
 infinite) area and lies everywhere
  above
  your original probability distribution. (This 
 is always possible, because your original curve encloses only unit area, by definition 
  
 We will call this
  f
 (
 x
 )
  the
  comparison function
 . 
  
 Imagine now 
 of probability.) 
  
 that you have some way of choosing a random point in two dimensions that is 
 uniform in the area under the comparison function. Whenever that point lies outside 
 the area under the original probability distribution, we will
  reject
  it and choose 
 another random point. Whenever it lies inside the area under the original probability 
 distribution, we will
  accept
  it. It should be obvious that the accepted points are 
 uniform in the accepted area, so that their
  x
  values have the desired distribution. It 
 should also be obvious that the fraction of points rejected just depends on the ratio 
 of the area of the comparison function to the area of the probability distribution 
 function, not on the details of shape of either function. For example, a comparison 
 function whose area is less than 2 will reject fewer than half the points, even if it 
 approximates the probability function very badly at some values of
  x
 , e.g., remains 
 finite in some region where
  x
  is zero.
  
 It remains only to suggest how to choose a uniform random point in two 
 dimensions under the comparison function
  f
 (
 x
 )
 . A variant of the transformation 
 method (
 §
 7.2) does nicely: Be sure to have chosen a comparison function whose 
 indefinite integral is known analytically, and is also analytically invertible to give
  x 
 as a function of “area under the comparison function to the left of
  x
 .” Now pick a 
 uniform deviate between 0 and
  A
 , where
  A
  is the total area under
  f
 (
 x
 )
 , and use it to 
 get a corresponding
  x
 . Then pick a uniform deviate between 0 and
  f
 (
 x
 )
  as the
  y 
 value for the two-dimensional point. You should be able to convince yourself that 
 the point
  (
 x, y
 )
  is uniformly distributed in the area under the comparison function
  
 f
 (
 x
 )
 .
  
 An equivalent procedure is to pick the second uniform deviate between zero 
 and one, and accept or reject according to whether it is respectively less than or 
 greater than the ratio
  p
 (
 x
 )
 /f
 (
 x
 )
 .
  
 So, to summarize, the rejection method for some given
  p
 (
 x
 )
  requires that one 
 find, once and for all, some reasonably good comparison function
  f
 (
 x
 )
 . Thereafter, 
 each deviate generated requires two uniform random deviates, one evaluation of
  f",NA
7.4 Generation of Random Bits,"This topic is not very useful for programming in high-level languages, but it 
 can be quite useful when you have access to the machine-language level of a 
 machine or when you are in a position to build special-purpose hardware out of 
 readily available chips.
  
 The problem is how to generate single random bits, with 0 and 1 equally 
 probable. Of course you can just generate uniform random deviates between zero 
 and one and use their high-order bit (i.e., test if they are greater than or less than 
 0.5). However this takes a lot of arithmetic; there are special-purpose applications, 
 such as real-time signal processing, where you want to generate bits very much 
 faster than that.
  
  
 One method for generating random bits, with two variant implementations, is 
 based on “primitive polynomials modulo 2.” The theory of these polynomials is 
 beyond our scope (although
  §
 7.7 and
  §
 20.3 will give you small tastes of it). Here, 
 suffice it to say that there are special polynomials among those whose coefficients 
 are zero or one. An example is
  
 x
 18
 +
  x
 5
 +
  x
 2
 +
  x
 1
 +
  x
 0 
  
 (
 7.4.1
 )
  
 which we can abbreviate by just writing the nonzero powers of
  x
 , e.g.,
  
 (18
 ,
  5
 ,
  2
 ,
  1
 ,
  0)
  
 Every primitive polynomial modulo 2 of order
  n
  (=18 above) defines a 
 recurrence relation for obtaining a new random bit from the
  n
  preceding ones. The 
 recurrence relation is guaranteed to produce a sequence of maximal length, i.e., 
 cycle through all possible sequences of
  n
  bits (except all zeros) before it repeats. 
 Therefore one can seed the sequence with any initial bit pattern (except all zeros), 
 and get
  2
 n
 −
  1
  random bits before the sequence repeats. Let the bits be numbered 
 from 1 (most recently generated) through
  n
  (generated 
 n
  steps ago), and denoted
  
 a
 1
 , a
 2
 , . . ., a
 n
 . We want to give a formula for a new bit 
 a
 0
 . After generating
  a
 0
  we 
 will shift all the bits by one, so that the old
  a
 n
  is finally lost, and the new
  a
 0
  
 becomes
  a
 1
 . We then apply the formula again, and so on.
  
 “Method I” is the easiest to implement in hardware, requiring only a single 
 shift register
  n
  bits long and a few XOR (“exclusive or” or bit addition mod 2) 
 gates. For the primitive polynomial given above, the recurrence formula is
  
 a
 0
  =
  a
 18
  XOR
  a
 5
  XOR
  a
 2
  XOR
  a
 1 
  
 (
 7.4.2
 )
  
 The terms that are XOR’d together can be thought of as “taps” on the shift register, 
 XOR’d into the register’s input. More generally, there is precisely one term for 
 each nonzero coefficient in the primitive polynomial except the constant (zero bit) 
 term. So the first term will always be
  a
 n
  for a primitive polynomial of degree
  n
 , 
 while the last term might or might not be
  a
 1
 , depending on whether the primitive 
 polynomial has a term in
  x
 1
 .
  
 It is rather cumbersome to illustrate the method in
  FORTRAN
 . Assume that
  
 iand 
 is a bitwise AND function,
  not
  is bitwise complement,
  ishft( ,1)
  is leftshift by 
 one bit,
  
 ior
  is bitwise OR. (These are available in many
  
 FORTRAN
  
 implementations.) Then we have the following routine.",NA
7.5 Random Sequences Based on Data ,NA,NA
Encryption,"In
  NumericalRecipes’
 firstedition,we described how to use theData Encryption Standard 
 (DES)
 [1-3]
 for the generation of random numbers. Unfortunately, when implemented in 
 software in a high-level language like
  FORTRAN
 , DES is very slow, so excruciatingly slow, 
 in fact, that our previous implementation can be viewed as more mischievous than useful. 
 Here we give a much faster and simpler algorithm which, though it may not be secure in the 
 cryptographic sense, generates about equally good random numbers.
  
 DES, like its progenitor cryptographic system LUCIFER, is a so-called “block product 
 cipher”
 [4]
 . It acts on 64 bits of input by iteratively applying (16 times, in fact) a kind of 
 highly",NA
+,"reverse 
  
 half-words
  
 C
 2 
  
 XOR",NA
+,"Figure 7.5.2. The nonlinear function
  g
  used by the routine
  psdes
 .
  
 via exclusive-or ensures that the overall
  g
  has no bias towards 0 or 1 bits.
  
 The “reverse half-words” operation in Figure 7.5.2 turns out to be essential; otherwise, 
 the very lowest and very highest bits are not properly mixed by the three multiplications. 
 The nonobvious choices in
  g
  are therefore: where along the vertical “pipeline” to do the 
 reverse; in what order to combine the three products and
  C
 2
 ; and with which operation (add 
 or exclusive-or) should each combining be done? We tested these choices exhaustively 
 before settling on the algorithm shown in the figure.
  
  
 It remains to determine the smallest number of iterations
  N
 it
  that we can get away with. 
 The minimum meaningful
  N
 it
  is evidently two, since a single iteration simply moves one 32-
 bit word without altering it. One can use the constants
  C
 1
  and
  C
 2
  to help determine an 
 appropriate
  N
 it
 : When
  N
 it
  = 2
  and
  C
 1
  =
  C
 2
  = 0
  (an intentionally very poor choice), the 
 generator fails several tests of randomness by easily measurable, though not overwhelming, 
 amounts. 
  
 When
  N
 it
  = 4
 , on the other hand, or with
  N
 it
  = 2
  but with the constants 
 C
 1
 , C
 2
  
 nonsparse, we have been unable to find
  any
  statistical deviation from randomness in 
 sequencesof up to
  10
 9
 floating numbers
  r
 i
  derived from this scheme. The combined strength 
 of
  N
 it
  = 4
  and nonsparse
  C
 1
 , C
 2
  should therefore give sequences that are random to tests even 
 far beyond those that we have actually tried. These are our recommended conservative 
 parameter values, notwithstanding the fact that
  N
 it
  = 2
  (which is, of course, twice as fast) has 
 no nonrandomness discernible (by us).
  
  
 We turn now to implementation. The nonlinear function shown in Figure 7.5.2 is not 
 implementable in strictly portable
  FORTRAN
 , for at least three reasons: (1) The addition of 
 two 32-bit integers may overflow, and the multiplication of two 16-bit integers may not 
 produce the correct 32-bit product because of sign-bit conventions. We intend that the 
 overflow be ignored, and that the 16-bit integers be multiplied as if they are positive. 
  
 It is 
 possible to force this behavior on most machines. (2) We assume 32-bit integers; however, 
 there",NA
7.6 Simple Monte Carlo Integration,"Inspirations for numerical methods can spring from unlikely sources. 
 “Splines”first were flexible strips of wood used by draftsmen. “Simulated 
 annealing” (we shall see in
  §
 10.9) is rooted in a thermodynamic analogy. And who 
 does not feel at least a faint echo of glamor in the name “Monte Carlo method”?
  
 Suppose that we pick
  N
  random points, uniformly distributed in a multidimen-
 sional volume
  V
  . Call them
  x
 1
 , . . ., x
 N
 . Then the basic theorem of Monte Carlo 
 integration estimates the integral of a function
  f
  over the multidimensional volume,
  
 f dV ≈ V ≪f≪ ± V
  
 ≪f
 2
 ≪ − ≪f≪
 2 
  
  
 N 
  
  
  
 (
 7.6.1
 )
  
 Here the angle brackets denote taking the arithmetic mean over the
  N
  sample points,
  
  
 N 
   
  
  
  
 N
  
 ≪f≪ ≡
 1 
 N 
   
 f
 (
 x
 i
 ) 
  
 f
 2
 ≡
 1 
 N 
  
  
  
  
  
  
  
  
 f
 2
 (
 x
 i
 ) 
  
 (
 7.6.2
 )
  
 i
 =1 
  
 i
 =1
  
 The “plus-or-minus” term in (7.6.1) is a one standard deviation error estimate for 
 the integral, not a rigorous bound; further, there is no guarantee that the error is 
 distributed as a Gaussian, so the error term should be taken only as a rough 
 indication of probable error.
  
 Suppose that you want to integrate a function
  g
  over a region
  W
  that is not easy 
 to sample randomly. For example,
  W
  might have a very complicated shape. No 
 problem. Just find a region
  V
  that
  includes
  W
  and that
  can
  easily be sampled (Figure 
 7.6.1), and then define
  f
  to be equal to
  g
  for points in
  W
  and equal to zero for points 
 outside of
  W
  (but still inside the sampled
  V
  ). You want to try to make 
 V
  enclose
  W
  
 as closely as possible, because the zero values of
  f
  will increase the error estimate 
 term of (7.6.1). And well they should: points chosen outside of
  W 
 have no 
 information content, so the effective value of
  N
 , the number of points, is reduced. 
 The error estimate in (7.6.1) takes this into account.",NA
"7.7 Quasi- (that is, Sub-) Random Sequences","We have just seen that choosing
  N
  points uniformly randomly in an
  n
 -
 dimensional space leads to an error term in Monte Carlo integration that decreases 
 as
  1
 /√N
 . In essence, each new point sampled adds linearly to an accumulated sum 
 that will become the function average, and also linearly to an accumulated sum of 
 squares that will become the variance (equation 7.6.2). The estimated error comes 
 from the square root of this variance, hence the power
  N
 −
 1
 /
 2
 .
  
 Just because this square root convergence is familiar does not, however, mean 
 that it is inevitable. A simple counterexample is to choose sample points that lie on 
 a Cartesian grid, and to sample each grid point exactly once (in whatever order). 
 The Monte Carlo method thus becomes a deterministic quadrature scheme — albeit 
 a simple one — whose fractional error decreases at least as fast as
  N
 −
 1
 (even faster 
 if the function goes to zero smoothly at the boundaries of the sampled region, or is 
 periodic in the region).",NA
.. . . ... ,NA,NA
.. .... ... . ... ,NA,NA
.,NA,NA
..,NA,NA
.,NA,NA
. .,NA,NA
. ,NA,NA
.....,NA,NA
7.8 Adaptive and Recursive Monte Carlo ,NA,NA
Methods,"This section discusses more advanced techniques of Monte Carlo integration. 
  
 As 
 examples of the use of these techniques, we include two rather different, fairly sophisticated, 
 multidimensional Monte Carlo codes:
  vegas
 [1,2]
 , and
  miser
 [3]
 . The techniques that we 
 discuss all fall under the general rubric of
  reduction of variance
  (
 §
 7.6), but are otherwise 
 quite distinct.
  
 Importance Sampling
  
 The use of
  importance sampling
  was already implicit in equations (7.6.6) and (7.6.7). 
 We now return to it in a slightly more formal way. Suppose that an integrand
  f
  can be 
 written as the product of a function
  h
  that is almost constant times another, positive, function
  
 g
 . Then its integral over a multidimensional volume
  V
  is
  
 f dV
  = 
  
 (
 f/g
 )
  gdV
  = 
 h gdV 
  
 (
 7.8.1
 )
  
 In equation (7.6.7) we interpreted equation (7.8.1) as suggesting a change of variable to 
 G
 , the 
 indefinite integral of
  g
 . That made
  gdV
  a perfect differential. We then proceeded to use the 
 basic theorem of Monte Carlo integration, equation (7.6.1). 
  
 A more general 
 interpretation of equation (7.8.1) is that we can integrate
  f
  by instead sampling
  h
  — not, 
 however, with uniform probability density
  dV
  , but rather with nonuniform density
  gdV
  . In 
 this second interpretation, the first interpretation follows as the special case, where the
  means 
 of generating the nonuniform sampling of
  gdV
  is via the transformation method, using the 
 indefinite integral
  G
  (see
  §
 7.2). More directly, one can go back and generalize the basic 
 theorem (7.6.1) to the case of nonuniform sampling: Suppose that points
  x
 i
  are chosen within 
 the volume
  V
  with a probability density
  p
  satisfying
  
 p dV
  = 1 
  
 (
 7.8.2
 )",NA
Chapter 8. ,NA,NA
Sorting,NA,NA
8.0 Introduction,"This chapter almost doesn’t belong in a book on
  numerical
  methods. 
 However, some practical knowledge of techniques for sorting is an indispensable 
 part of any good programmer’s expertise. We would not want you to consider 
 yourself expert in numerical techniques while remaining ignorant of so basic a 
 subject.
  
 In conjunction with numerical work, sorting is frequently necessary when data 
 (either experimental or numerically generated) are being handled. One has tables or 
 lists of numbers, representing one or more independent (or “control”) variables, 
 and one or more dependent (or “measured”) variables. One may wish to arrange 
 these data, in various circumstances, in order by one or another of these variables. 
 Alternatively, one may simply wish to identify the “median” value, or the “upper 
 quartile” value of one of the lists of values. This task, closely related to sorting, is 
 called
  selection
 .
  
 Here, more specifically, are the tasks that this chapter will deal with:
 •
  
 Sort, i.e., rearrange, an array of numbers into numerical order.
  
 •
  Rearrange an array into numerical order while performing the corre-
 sponding rearrangement of one or more additional arrays, so that the 
 correspondence between elements in all arrays is maintained.
  
 •
  Given an array, prepare an
  index table
  for it, i.e., a table of pointers telling 
 which number array element comes first in numerical order, which second, 
 and so on.
  
 •
  Given an array, prepare a
  rank table
  for it, i.e., a table telling what is the 
 numerical rank of the first array element, the second array element, 
  
 and so on.
  
 •
  Select the
  M
 th largest element from an array.
  
  
 For the basic task of sorting
  N
  elements, the best algorithms require on the 
 order of several times
  N
  log
 2
  N
  operations. The algorithm inventor tries to reduce 
 the constant in front of this estimate to as small a value as possible. Two of the best 
 algorithms are
  Quicksort
  (
 §
 8.2), invented by the inimitable C.A.R. Hoare, and 
 Heapsort
  (
 §
 8.3), invented by J.W.J. Williams. For large
  N
  (say
  >
  1000
 ), Quicksort 
 is faster, on most machines, by a factor of 1.5 or 2; it requires a bit of extra memory, 
 however, and is a moderately complicated 
   
 Heapsort is a true “sort in 
 place,” and is somewhat more compact to program.",NA
8.1 Straight Insertion and Shell’s Method,"Straight insertion
  is an
  N
 2
 routine, and should be used only for small
  N
 , say
  <
  
 20
 .
  
 The technique is exactly the one used by experienced card players to sort their 
 cards: Pick out the second card and put it in order with respect to the first; then pick 
 out the third card and insert it into the sequence among the first two; and so on until 
 the last card has been picked out and inserted.
  
 SUBROUTINE piksrt(n,arr)
  
 INTEGER n
  
 REAL arr(n)
  
 Sorts an array
  arr(1:n)
  into ascending numerical order, by straight insertion.
  n
  is input;
  
 arr
  is replaced on output by its sorted rearrangement.
  
 INTEGER i,j
  
 REAL a
  
 do
  12
  j=2,n 
  
 Pick out each element in turn.
  
 a=arr(j)
  
 do
  11
  i=j-1,1,-1 
  
 Look for the place to insert it.
  
 if(arr(i).le.a)goto 10
  
 arr(i+1)=arr(i)
  
 enddo
  11
  
 i=0
  
 10
  
 arr(i+1)=a
  
 Insert it.
  
 enddo
  12
  
 return
  
 END
  
  
 What if you also want to rearrange an array
  brr
  at the same time as you sort 
 arr
 ? Simply move an element of
  brr
  whenever you move an element of
  arr
 :",NA
8.2 Quicksort,"Quicksort is, on most machines, on average, for large
  N
 , the fastest known 
 sorting algorithm. 
  
 It is a “partition-exchange” sorting method: A “partitioning 
 element”
  a
  is selected from the array. Then by pairwise exchanges of elements, the 
 original array is partitioned into two subarrays. At the end of a round of partitioning, 
 the element
  a
  is in its final place in the array. All elements in the left subarray are
 ≤
  
 a
 , while all elements in the right subarray are
  ≥
  a
 . The process is then repeated on 
 the left and right subarrays independently, and so on.
  
 The partitioning process is carried out by selecting some element, say the 
 leftmost, as the partitioning element
  a
 . Scan a pointer up the array until you find an 
 element
  >
  a
 , and then scan another pointer down from the end of the array until you 
 find an element
  <
  a
 . These two elements are clearly out of place for the final 
 partitioned array, so exchange them. Continue this process until the pointers",NA
8.3 Heapsort,"While usually not quite as fast as Quicksort, Heapsort is one of our favorite 
 sorting routines. It is a true “in-place” sort, requiring no auxiliary storage. It is an 
 N
  
 log
 2
  N
  process, not onlyon average, but also for the worst-case order of input data. 
 In fact, its worst case is only 20 percent or so worse than its average running time.
  
 It is beyond our scope to give a complete exposition on the theory of 
 Heapsort. We will mention the general principles, then let you refer to the 
 references
 [1,2]
 , or analyze the program yourself, if you want to understand the 
 details.
  
  
 A set of
  N
  numbers
  a
 i
 , i
  = 1
 , . . ., N
 , is said to form a “heap” if it satisfies the 
 relation
  
 a
 j/
 2
  ≥ a
 j
  
 for
  
 1
  ≤ j/
 2
  < j ≤ N
  
 (
 8.3.1
 )",NA
8.4 Indexing and Ranking,"The concept of
  keys
  plays a prominent role in the management of data files. A 
 data
  record
  in such a file may contain several items, or
  fields
 . For example, a 
 record in a file of weather observations may have fields recording time, 
 temperature, and",NA
8.5 Selecting the Mth Largest,"Selection is sorting’saustere sister. (Say
  that
  five times quickly!) Where 
 sorting demands the rearrangement of an entire data array, selection politely asks 
 for a single returned value: What isthe
 k
 thsmallest (or, equivalently,the
 m
  =
  
 N
 +1
 −k
 thlargest) element out of
  N
  elements? The fastest methods for selection do, 
 unfortunately, rearrange the array for their own computational purposes, 
 typicallyputtingall smaller elements to the left of the
  k
 th, all larger elements to the 
 right, and scrambling the order within each subset. This side effect is at best 
 innocuous, at worst downright inconvenient. When the array is verylong, so that 
 making a scratch copy ofit is taxing on memory, or when the computational burden 
 of the selection is a negligible part of a larger calculation, one turns to selection 
 algorithms without side effects, which leave the original array undisturbed. Such
  in 
 place
  selection is slower than the faster selection methods by a factor of about 10. 
 We give routines of both types, below.
  
  
 The most common use of selection is in the statistical characterization of a set 
 of data. One often wants to know the median element in an array, or the top and 
 bottom quartile elements. 
  
 When
  N
  is odd, the median is the
  k
 th element, with 
 k
  = 
 (
 N
  +1)
 /
 2
 . When
  N
  is even, statistics books define the median as the arithmetic 
 mean of the elements
  k
  =
  N/
 2
  and
  k
  =
  N/
 2 + 1
  (that is,
  N/
 2
  from the bottom and
  
 N/
 2
  from the top). If you accept such pedantry, you must perform two separate 
 selections to find these elements. For
  N >
  100
  we usually define
  k
  =
  N/
 2
  to be the 
 median element, pedants be damned.
  
 The fastest general method for selection, allowing rearrangement, is
  partition-
 ing
 , exactly as was done in the Quicksort algorithm (
 §
 8.2). Selecting a 
 “random”partition element, one marches through the array, forcing smaller 
 elements to the left, larger elements to the right. As in Quicksort, it is important to 
 optimize the inner loop, using “sentinels” (
 §
 8.2) to minimize the number of 
 comparisons. For sorting, one would then proceed to further partition both subsets. 
 For selection, we can ignore one subset and attend only to the one that contains our 
 desired
  k
 th element. Selection by partitioning thus does not need a stack of pending",NA
8.6 Determination of Equivalence Classes,"A number of techniques for sorting and searching relate to data structures whose 
 details are beyond the scope of this book, for example, trees, linked lists, etc. These 
 structures and their manipulations are the bread and butter of computer science, as distinct 
 from numerical analysis, and there is no shortage of books on the subject.
  
 In working with experimental data, we have found that one particular such 
 manipulation, namely the determination of equivalence classes, arises sufficiently often to 
 justify inclusion here.
  
  
 The problem is this: There are
  N
  “elements” (or “data points” or whatever), numbered 
 1
 , . . . , N
 . 
  
 You are given pairwise information about whether elements are in the same 
 equivalence class
  of “sameness,” by whatever criterion happens to be of interest. 
  
 For 
 example, you may have a list of facts like: “Element 3 and element 7 are in the same class; 
 element 19 and element 4 are in the same class; element 7 and element 12 are in the same 
 class,
  . . .
  .” Alternatively, you may have a procedure, given the numbers of two elements",NA
Chapter 9. ,NA,NA
Root Finding and ,NA,NA
Nonlinear Sets of Equations,NA,NA
9.0 Introduction,"We now consider that most basic of tasks, solving equations numerically. 
 While most equations are born with both a right-hand side and a left-hand side, one 
 traditionally moves all terms to the left, leaving
  
 f
 (
 x
 ) = 0 
  
 (
 9.0.1
 )
  
 whose solutionor solutionsare desired. When there is onlyone independent variable, 
 the problem is
  one-dimensional
 , namely to find the root or roots of a function.
  
  
 With more than one independent variable, more than one equation can be 
 satisfied simultaneously. 
  
 You likely once learned the
  implicit function theorem 
 which (in this context) gives us the hope of satisfying
  N
  equations in
  N
  unknowns 
 simultaneously. Note that we have only hope, not certainty. A nonlinear set of 
 equations may have no (real) solutions at all. Contrariwise, it may have more than 
 one solution. The implicit function theorem tells us that “generically” the solutions 
 will be distinct, pointlike, and separated from each other. If, however, life is so 
 unkind as to present you with a nongeneric, i.e., degenerate, case, then you can get a 
 continuous family of solutions. In vector notation, we want to find one or more 
 N
 -
 dimensional solution vectors
  x
  such that
  
 f
 (
 x
 ) =
  0 
  
 (
 9.0.2
 )
  
 where
  f
  is the
  N
 -dimensional vector-valued function whose components are the 
 individual equations to be satisfied simultaneously.
  
 Don’t be fooled by the apparent notational similarity of equations (9.0.2) and 
 (9.0.1). Simultaneous solution of equations in
  N
  dimensions is
  much
  more difficult 
 than finding roots in the one-dimensional case. The principal difference between 
 one and many dimensions isthat, inone dimension, it ispossible tobracket or “trap” 
 a root between bracketing values, and then hunt it down like a rabbit. In 
 multidimensions, you can never be sure that the root is there at all until you have 
 found it.
  
 Except in linear problems, root finding invariably proceeds by iteration, and 
 this is equally true in one or in many dimensions. Starting from some approximate 
 trial solution, a useful algorithm will improve the solution until some 
 predetermined convergence criterion is satisfied. For smoothly varying functions, 
 good algorithms
  
 340",NA
9.1 Bracketing and Bisection,"We will say that a root is
  bracketed
  in the interval
  (
 a, b
 )
  if
  f
 (
 a
 )
  and
  f
 (
 b
 ) 
 have 
 opposite signs. If the function is continuous, then at least one root must lie in that 
 interval (the
  intermediate value theorem
 ). If the function is discontinuous, but 
 bounded, then instead of a root there might be a step discontinuity which crosses 
 zero (see Figure 9.1.1). For numerical purposes, that might as well be a root, since 
 the behavior is indistinguishable from the case of a continuous function whose zero 
 crossing occurs in between two “adjacent” floating-point numbers in a machine’s 
  
  
 Only for functions with singularities is there the 
 finite-precision representation.
  
 possibility that a bracketed root is not really there, as for example
  
  
  
 1 
  
 f
 (
 x
 ) = 
    
 (
 9.1.1
 ) 
  
  
 x − c
  
 Some root-finding algorithms (e.g., bisection in this section) will readily converge 
 to
  c
  in (9.1.1). Luckily there is not much possibility of your mistaking
  c
 , or any 
 number
  x
  close to it, for a root, since mere evaluation of
  |f
 (
 x
 )
 |
  will give a very 
 large, rather than a very small, result.
  
 If you are given a function in a black box, there is no sure way of bracketing its 
 roots, or of even determining that it has roots. If you like pathological examples, 
 think about the problem of locating the two real roots of equation (3.0.1), which 
 dips In the next chapter we will deal with the related problem of bracketing a below 
 zero only in the ridiculously small interval of about
  x
  =
  π ±
  10
 −
 667
 .
  
 function’s minimum. There it is possible to give a procedure that always succeeds; 
 in essence, “Go downhill, taking steps of increasing size, until your function starts 
 back uphill.” There is no analogous procedure for roots. The procedure “go 
 downhill until your function changes sign,” can be foiled by a function that has a 
 simple extremum. Nevertheless, if you are prepared to deal with a “failure” 
 outcome, this procedure is often a good first start; success is usual if your function 
 has opposite signs in the limit
  x → ±∞
 .",NA
"9.2 Secant Method, False Position Method, ",NA,NA
and Ridders’ Method,"For functions that are smooth near a root, the methods known respectively as
  
 false position
  (or
  regula falsi
 ) and
  secant method
  generally converge faster than 
 bisection. In both of these methods the function is assumed to be approximately 
 linear in the local region of interest, and the next improvement in the root is taken 
 as the point where the approximating line crosses the axis. After each iteration one 
 of the previous boundary points is discarded in favor of the latest estimate of the 
 root.
  
 The
  only
  difference between the methods is that secant retains the most recent 
 of the prior estimates (Figure 9.2.1; this requires an arbitrary choice on the first 
 iteration), while false position retains that prior estimate for which the function 
 value",NA
9.3 Van Wijngaarden–Dekker–Brent Method,"While secant and false position formally converge faster than bisection, one 
 finds in practice pathological functions for which bisection converges more rapidly.",NA
9.4 Newton-Raphson Method Using Derivative,"Perhaps the most celebrated of all one-dimensional root-findingroutines is
 New-
 ton’s method
 , also called the
  Newton-Raphson method
 . This method is distinguished 
 from the methods of previous sections by the fact that it requires the evaluation of 
 both the function
  f
 (
 x
 )
 ,
  and
  the derivative
  f
 ′
 (
 x
 )
 , at arbitrary points
  x
 . 
  
 The 
 Newton-Raphson formula consists geometrically of extending the tangent line at a 
 current point
  x
 i
  until it crosses zero, then setting the next guess
  x
 i
 +1
  to the abscissa of 
 that zero-crossing (see Figure 9.4.1). Algebraically, the method derives from the 
 familiar Taylor series expansion of a function in the neighborhood of a point,
  
 f
 (
 x
  +
  δ
 )
  ≈ f
 (
 x
 ) +
  f
 ′
 (
 x
 )
 δ
  +
 f
 ′′
 (
 x
 )
 δ
 2
 +
  . . . . 
  
 (
 9.4.1
 )
  
 For small enough values of
  δ
 , and for well-behaved functions, the terms beyond 
 linear are unimportant, hence
  f
 (
 x
  +
  δ
 ) = 0
  implies
  
 δ
  =
  −f
 (
 x
 ) 
 f
 ′
 (
 x
 )
 . 
  
 (
 9.4.2
 )",NA
9.5 Roots of Polynomials,"Here we present a few methods for finding roots of polynomials. These will 
 serve for most practical problems involving polynomials of low-to-moderate degree 
 or for well-conditioned polynomials of higher degree. Not as well appreciated as it 
 ought to be is the fact that some polynomials are exceedingly ill-conditioned. The 
 tiniest changes in a polynomial’s coefficients can, in the worst case, send its roots 
 sprawling all over the complex plane. (An infamous example due to Wilkinson is 
 detailed by Acton
 [1]
 .) 
  
  
 Recall that a polynomial of degree
  n
  will have
  n
  roots. The roots can be real or 
 complex, and they might not be distinct. If the coefficients of the polynomial are 
 real, then complex roots will occur in pairs that are conjugate, i.e., if
  x
 1
  =
  a
  +
  bi 
 is a 
 root then
  x
 2
  =
  a − bi
  will also be a root. When the coefficients are complex, the 
 complex roots need not be related.
  
  
 Multipleroots, or closely spaced roots, produce the most difficulty for 
 numerical algorithms (see Figure 9.5.1). For example,
  P
  (
 x
 ) = (
 x − a
 )
 2
 has a double 
 real root at
  x
  =
  a
 . However, we cannot bracket the root by the usual technique of 
 identifying neighborhoods where the function changes sign, nor will slope-
 following methods such as Newton-Raphson work well, because both the function 
 and its derivative vanish at a multiple root. 
  
 Newton-Raphson
  may
  work, but 
 slowly, since large roundoff errors can occur. When a root is known in advance to 
 be multiple, then special methods of attack are readily devised. Problems arise when 
 (as is generally the case) we do not know in advance what pathology a root will 
 display.
  
 Deflation of Polynomials
  
 When seeking several or all roots of a polynomial, the total effort can be 
 significantly reduced by the use of
  deflation
 . As each root
  r
  is found, the 
 polynomial is factored into a product involving the root and a reduced polynomial 
 of degree one less than the original, i.e.,
  P
  (
 x
 ) = (
 x − r
 )
 Q
 (
 x
 )
 . exactly the remaining 
 roots of
  P
  , the effort of finding additional roots decreases, Since the roots of
  Q
  are
  
 because we work with polynomials of lower and lower degree as we find 
 successive roots. Even more important, with deflation we can avoid the blunder of 
 having our iterative method converge twice to the same (nonmultiple) root instead 
 of separately to two different roots.
  
 Deflation, which amounts to synthetic division, is a simple operation that acts 
 on the array of polynomial coefficients. The concise code for synthetic division by 
 a monomial factor was given in
  §
 5.3 above. You can deflate complex roots either 
 by converting that code to complex data type, or else — in the case of a polynomial",NA
9.6 Newton-Raphson Method for Nonlinear ,NA,NA
Systems of Equations,"We make an extreme, but wholly defensible, statement: There are
  no
  good, 
 gen-eral methods for solving systems of more than one nonlinear equation. 
 Furthermore, it is not hard to see why (very likely) there
  never will be
  any good, 
 general methods: Consider the case of two dimensions, where we want to solve 
 simultaneously
  
 f
 (
 x, y
 ) = 0 
  
 g
 (
 x, y
 ) = 0
  
 (
 9.6.1
 )
  
 The functions
  f
  and
  g
  are two arbitrary functions, each of which has zero 
 contour lines that divide the
  (
 x, y
 )
  plane into regions where their respective 
 function is positive or negative. These zero contour boundaries are of interest to us. 
 The solutions that we seek are those points (if any) that are common to the zero 
 contours of
  f
  and
  g
  (see Figure 9.6.1). Unfortunately, the functions
  f
  and
  g
  have, in 
 general, no relation to each other at all! There is nothing special about a common 
 point from either
  f
 ’s point of view, or from
  g
 ’s. In order to find all common points, 
 which are the solutions of our nonlinear equations, we will (in general) have to do 
 neither more nor less than map out the full zero contours of both functions. Note 
 further that the zero contours will (in general) consist of an unknown number of 
 disjoint closed curves. How can we ever hope to know when we have found all 
 such disjoint pieces?
  
 For problems in more than two dimensions, we need to find points mutually 
 common to
  N
  unrelated zero-contour hypersurfaces, each of dimension
  N −
  1
 .",NA
9.7 Globally Convergent Methods for Nonlinear ,NA,NA
Systems of Equations,"We have seen that Newton’s method for solving nonlinear equations has an 
 unfortunate tendency to wander off into the wild blue yonder if the initial guess is 
 not sufficiently close to the root. 
  
 A
  global
  method is one that converges to a 
 solution from almost any starting point. 
  
 In this section we will develop an 
 algorithm that combines the rapid local convergence of Newton’s method with a 
 globally convergent strategy that will guarantee some progress towards the solution 
 at each iteration. The algorithm is closely related to the quasi-Newton method of 
 minimization which we will describe in
  §
 10.7.
  
  
 Recall our discussion of
  §
 9.6: the Newton step for the set of equations 
  
  
 F
 (
 x
 ) = 0 
  
 (
 9.7.1
 ) 
 is
  
 x
 new
  =
  x
 old
  +
  δ
 x 
  
 (
 9.7.2
 )
  
 where
  
 δ
 x
  =
  −
 J
 −
 1
 ·
  F 
  
 (
 9.7.3
 )
  
 Here
  J
  is the Jacobian matrix. How do we decide whether to accept the Newton 
 step
 δ
 x
 ? A reasonable strategy is to require that the step decrease
  |
 F
 |
 2
 =
  F
  ·
  F
 . This is 
 the same requirement we would impose if we were trying to minimize
  
 f
  = 1 2
 F
  ·
  F 
  
 (
 9.7.4
 )
  
 (The
 1 2
 is for later convenience.) Every solution to (9.7.1) minimizes (9.7.4), but 
 there may be local minima of (9.7.4) that are not solutions to (9.7.1). 
  
 Thus, as 
 already mentioned, simply applying one of our minimum finding algorithms from 
 Chapter 10 to (9.7.4) is
  not
  a good idea.
  
  
 To develop a better strategy, note that the Newton step (9.7.3) is a
  descent 
 direction
  for
  f
 :
  
 ≪f · δ
 x
  = (
 F
  ·
  J
 )
  ·
  (
 −
 J
 −
 1
 ·
  F
 ) =
  −
 F
  ·
  F
  <
  0 
  
 (
 9.7.5
 )
  
 Thus our strategy is quite simple: We always first try the full Newton step, 
 because once we are close enough to the solution we will get quadratic 
 convergence. However, we check at each iteration that the proposed step reduces
  f
 . 
 If not, we 
 backtrack
  along the Newton direction until we have an acceptable step. 
 Because the Newton step is a descent direction for
  f
 , we are guaranteed to find an 
 acceptable step by backtracking. We will discuss the backtracking algorithm in 
 more detail below.
  
 Note that this method essentially minimizes
  f
  by taking Newton steps designed 
 to bring
  F
  to zero. This is
  not
  equivalent to minimizing
  f
  directly by taking Newton 
 steps designed to bring
  ≪f
  to zero. While the method can still occasionally fail by 
 landing on a local minimum of
  f
 , this is quite rare in practice. The routine
  newt 
 below will warn you if this happens. The remedy is to try a new starting point.",NA
Chapter 10. ,NA,NA
Minimization or ,NA,NA
Maximization of Functions,NA,NA
10.0 Introduction,"In a nutshell: You are given a single function
  f
  that depends on one or more 
 independent variables. You want to find the value of those variables where
  f
  takes 
 on a maximum or a minimum value. You can then calculate what value of
  f
  is 
 achieved at the maximum or minimum. The tasks of maximization and 
 minimization are trivially related to each other, since one person’s function
  f
  could 
 just as well be another’s
  −f
 . The computational desiderata are the usual ones: Do it 
 quickly, cheaply, and in small memory. 
  
 Often the computational effort is 
 dominated by the cost of evaluating
  f
  (and also perhaps its partial derivatives with 
 respect to all variables, if the chosen algorithm requires them). In such cases the 
 desiderata are sometimes replaced by the simple surrogate: Evaluate
  f
  as few times 
 as possible.
  
 An extremum (maximum or minimum point) can be either
  global
  (truly the 
 highest or lowest function value) or
  local
  (the highest or lowest in a finite 
 neighborhood and not on the boundary of that neighborhood). (See Figure 10.0.1.) 
 Finding a global extremum is, in general, a very difficult problem. Two standard 
 heuristics are widely used: (i) find local extrema starting from widely varying 
 starting values of the independent variables (perhaps chosen quasi-randomly, as 
 in
 §
 7.7), and then pick the most extreme of these (if they are not all the same); or 
 (ii) perturb a local extremum by taking a finite amplitude step away from it, and 
 then see if your routine returns you to a better point, or “always” to the same one. 
 demonstrated important successes on a variety of global extremization problems. 
 Relatively recently, so-called “simulated annealing methods” (
 §
 10.9) have
  
  
 Our chapter title could just as well be
  optimization
 , which is the usual name for 
 this very large field of numerical research. 
  
 The importance ascribed to the 
 various tasks in this field depends strongly on the particular interests of whom you 
 talk to. Economists, and some engineers, are particularly concerned with 
 constrained optimization
 , where there are
  a priori
  limitations on the allowed values 
 of independent variables. For example, the production of wheat in the U.S. must be 
 a nonnegative number. 
  
 One particularly well-developed area of constrained 
 optimization is
  linear programming
 , where both the function to be optimized and 
 the constraints happen to be linear functions of the independent variables. Section 
 10.8, which is otherwise somewhat disconnected from the rest of the material that 
 we have chosen to include in this chapter, implements the so-called “simplex 
 algorithm”for linear programming problems.",NA
10.1 Golden Section Search in One Dimension,"Recall how the bisection method finds roots of functions in one dimension 
 (
 §
 9.1): The root is supposed to have been bracketed in an interval
  (
 a, b
 )
 . then 
 evaluates the function at an intermediate point
  x
  and obtains a new, smaller One
  
 bracketing interval, either
  (
 a, x
 )
  or
  (
 x, b
 )
 . The process continues until the 
 bracketing interval is acceptably small. It is optimal to choose
  x
  to be the midpoint 
 of
  (
 a, b
 ) 
 so that the decrease in the interval length is maximized when the function 
 is as uncooperative as it can be, i.e., when the luck of the draw forces you to take 
 the bigger bisected segment.
  
 There is a precise, though slightly subtle, translation of these considerations to 
 the minimization problem: What does it mean to
  bracket
  a minimum? A root of a 
 function is known to be bracketed by a pair of points,
  a
  and
  b
 , when the function 
 has opposite sign at those two points. A minimum, by contrast, is known to be 
 bracketed only when there is a
  triplet
  of points,
  a < b < c
  (or
  c < b < a
 ), such that 
 f
 (
 b
 )
  is less than both
  f
 (
 a
 )
  and
  f
 (
 c
 )
 . In this case we know that the function (if it is 
 nonsingular) has a minimum in the interval
  (
 a, c
 )
 .
  
 The analog of bisection is to choose a new point
  x
 , either between
  a
  and
  b
  or 
 between
  b
  and
  c
 . Suppose, to be specific, that we make the latter choice. Then we 
 evaluate
  f
 (
 x
 )
 . If
  f
 (
 b
 )
  < f
 (
 x
 )
 , then the new bracketing triplet of points is
  (
 a, b, x
 )
 ;",NA
10.2 Parabolic Interpolation and Brent’s ,NA,NA
Method in One Dimension,"We already tipped our hand about the desirability of parabolic interpolation in 
 the previous section’s
  mnbrak
  routine, but it is now time to be more explicit. A 
 golden section search is designed to handle, in effect, the worst possible case of 
 function minimization, with the uncooperative minimum hunted down and 
 cornered like a scared rabbit. But why assume the worst? If the function is nicely 
 parabolic near to the minimum — surely the generic case for sufficiently smooth 
 functions —then the parabola fitted through any three points ought to take us in a 
 single leap to the minimum, or at least very near to it (see Figure 10.2.1). Since we 
 want to find an abscissa rather than an ordinate, the procedure is technically called
  
 inverse parabolic interpolation
 .
  
  
 The formula for the abscissa
  x
  that is the minimum of a parabola through three 
 points
  f
 (
 a
 )
 ,
  f
 (
 b
 )
 , and
  f
 (
 c
 )
  is
  
 x
  =
  b −
 1
  
 (
 b − a
 )
 2
 [
 f
 (
 b
 )
  − f
 (
 c
 )]
  −
  (
 b − c
 )
 2
 [
 f
 (
 b
 )
  − f
 (
 a
 )] (
 b − 
 a
 )[
 f
 (
 b
 )
  − f
 (
 c
 )]
  −
  (
 b − c
 )[
 f
 (
 b
 )
  − f
 (
 a
 )]
  
 (
 10.2.1
 )",NA
10.3 One-Dimensional Search with First ,NA,NA
Derivatives,"Here we want to accomplish precisely the same goal as in the previous 
 section, namely to isolate a functional minimum that is bracketed by the triplet of 
 abscissas
  (
 a, b, c
 )
 , but utilizing an additional capability to compute the function’s 
 first derivative as well as its value.
  
 In principle, we might simply search for a zero of the derivative, ignoring the 
 function value information, using a root finder like
  rtflsp
  or
  zbrent
  (
 §§
 9.2–9.3). It 
 doesn’t take long to reject
  that
  idea: How do we distinguishmaxima from minima? 
 Where do we go from initial conditions where the derivatives on one or both of the 
 outer bracketing points indicate that “downhill” is in the direction
  out
  of the 
 bracketed interval?
  
 We don’t want to give up our strategy of maintaining a rigorous bracket on the 
 minimum at all times. The only way to keep such a bracket is to update it using 
 function (not derivative) information, with the central point in the bracketing triplet 
 always that with the lowest function value. Therefore the role of the derivatives can 
 only be to help us choose new trial points within the bracket.
  
 One school of thought is to “use everythingyou’ve got”: Compute a 
 polynomial of relatively high order (cubic or above) that agrees with some number 
 of previous function and derivative evaluations. For example, there is a unique 
 cubic that agrees with function and derivative at two points, and one can jump to 
 the interpolated minimum of that cubic (if there is a minimum within the bracket). 
 Suggested by Davidon and others, formulas for this tactic are given in
 [1]
 .
  
 We like to be more conservative than this. Once superlinear convergence sets 
 in, it hardly matters whether its order is moderately lower or higher. In practical 
 problems that we have met, most function evaluations are spent in getting globally 
 close enough to the minimum for superlinear convergence to commence. So we are 
 more worried about all the funny “stiff” things that high-order polynomials can do 
 (cf. Figure 3.0.1b), and about their sensitivities to roundoff error.
  
 This leads us to use derivative information only as follows: The sign of the 
 derivative at the central point of the bracketing triplet
  (
 a, b, c
 )
  indicates uniquely 
 whether the next test point should be taken in the interval
  (
 a, b
 )
  or in the interval 
 (
 b, c
 )
 . The value of this derivative and of the derivative at the second-best-so-far 
 point are extrapolated to zero by the secant method (inverse linear interpolation), 
 which by itself is superlinear of order 1.618. (The golden mean again: see
 [1]
 , p. 57.) 
 We impose the same sort of restrictions on this new trial point as in Brent’s 
 method. If the trial point must be rejected, we
  bisect
  the interval under scrutiny.
  
 Yes, we are fuddy-duddies when it comes to making flamboyant use of 
 derivative information in one-dimensional minimization. But we have met too 
 many functions whose computed “derivatives”
  don’t
  integrate up to the function 
 value and
  don’t 
 accurately point the way to the minimum, usually because of 
 roundoff errors, sometimes because of truncation error in the method of derivative 
 evaluation.
  
  
 You will see that the following routine is closely modeled on
  brent
  in the 
 previous section.",NA
10.4 Downhill Simplex Method in ,NA,NA
Multidimensions,"With this section we begin consideration of multidimensional minimization, 
 that is, finding the minimum of a function of more than one independent variable. 
 This section stands apart from those which follow, however: All of the algorithms 
 after this section will make explicit use of a one-dimensional minimization 
 algorithm as a part of their computational strategy. 
  
 This section 
 implements an entirely self-contained strategy, in which one-dimensional 
 minimization does not figure. 
  
  
  
 The method 
 The
  downhill simplex method
  is due to Nelder and Mead
 [1]
 .
  
 requires only function evaluations, not derivatives. It is not very efficient in terms 
 of the number of function evaluations that it requires. Powell’s method (
 §
 10.5) is 
 almost surely faster in all likelyapplications. However, the downhill simplex 
 method may frequently be the
  best
  method to use if the figure of merit is “get 
 something working quickly” for a problem whose computational burden is small.
  
  
 The method has a geometrical naturalness about it which makes it delightful to 
 describe or work through: 
  
  
 A
  simplex
  is the geometrical figure consisting, in
  N
  dimensions, of
  N
  + 1 
 points 
 (or vertices) and all their interconnecting line segments, polygonal faces, etc. In two 
 dimensions, a simplex is a triangle. In three dimensions it is a tetrahedron, not 
 necessarily the regular tetrahedron. (The
  simplex method
  of linear programming, 
 described in
 §
 10.8, also makes use of the geometrical concept ofa simplex. 
 Otherwise it is completely unrelated to the algorithm that we are describing in this 
 section.) In general we are only interested in simplexes that are nondegenerate, i.e., 
 that enclose a finite inner
  N
 -dimensional volume. If any point of a nondegenerate 
 simplex is taken as the origin, then the
  N
  other points define vector directions that 
 span the 
 N
 -dimensional vector space.
  
 In one-dimensional minimization, it was possible to bracket a minimum, so 
 that the success of a subsequent isolation was guaranteed. Alas! There is no 
 analogous 
 procedure 
 in 
 multidimensional 
 space. 
 For 
 multidimensional 
 minimization, the best we can do is give our algorithm a starting guess, that is, an
  
 N
 -vector of independent variables as the first point to try. The algorithm is then 
 supposed to make its own way downhill through the unimaginable complexity of 
 an
  N
 -dimensional topography, until it encounters a (local, at least) minimum.
  
 The downhill simplex method must be started not just with a single point, but 
 with
  N
  + 1
  points, defining an initial simplex. If you think of one of these points (it 
 matters not which) as being your initial starting point
  P
 0
 , then you can take the 
 other
  N
  points to be
  
 P
 i
  =
  P
 0
  +
  λ
 e
 i 
  
 (
 10.4.1
 )
  
 where the
  e
 i
 ’s are
  N
  unit vectors, and where
  λ
  is a constant which is your guess of 
 the problem’s characteristic length scale. (Or, you could have different
  λ
 i
 ’s for each 
 vector direction.) 
  
   
 The downhill simplex method now takes a series of steps, most steps just 
 moving the point of the simplex where the function is largest (“highest point”) 
 through the opposite face of the simplex to a lower point. These steps are called",NA
10.5 Direction Set (Powell’s) Methods in ,NA,NA
Multidimensions,"start at a point
  P
  in
  N
 -dimensional space, and proceed from there in some vector We know (
 §
 10.1–
 §
 10.3) how to 
 minimize a function of one variable. If we
  
 direction
  n
 , then any function of
  N
  variables
  f
 (
 P
 )
  can be minimized along the line 
 n
  
 by our one-dimensional methods. One can dream up various multidimensional 
 minimization methods that consist of sequences ofsuch lineminimizations. 
 Different methods will differ only by how, at each stage, they choose the next 
 direction
  n
  to try. All such methods presume the existence of a “black-box” sub-
 algorithm, which we might call
  linmin
  (given as an explicit routine at the end of 
 this section), whose definition can be taken for now as
  
 linmin:
  Given as input the vectors
  P
  and
  n
 , and the 
  
 function
  f
 , find the scalar
  λ
  that minimizes
  f
 (
 P
  +
 λ
 n
 )
 . 
  
 Replace
  P
  by
  P
  +
  λ
 n
 . Replace
  n
  by
  λ
 n
 . Done.
  
 All the minimization methods in this section and in the two sections following 
 fall under this general schema of successive line minimizations. (The algorithm in
  
 §
 10.7 does not need very accurate line minimizations. Accordingly, it has its own 
 approximate line minimization routine,
  lnsrch
 .) In this section we consider a class 
 of methods whose choice of successive directions does not involve explicit 
 computation of the function’s gradient; the next two sections do require such 
 gradient calculations. You will note that we need not specify whether
  linmin
  uses 
 gradient information or not. That choice is up to you, and its optimization depends 
 on your particular function. You would be crazy, however, to use gradients in
  
 linmin
  and 
 not
  use them in the choice of directions, since in this latter role they can 
 drastically reduce the total computational burden.",NA
10.6 Conjugate Gradient Methods in ,NA,NA
Multidimensions,"We consider now the case where you are able to calculate, at a given
  N
 -
 dimensional point
  P
 , not just the value of a function
  f
 (
 P
 )
  but also the gradient 
 (vector of first partial derivatives)
  ≪f
 (
 P
 )
 . A rough countingargument will show 
 how advantageous it is to use the gradient information: Suppose that the function
  f
  
 is roughly approximated as a quadratic form, as above in equation (10.5.1),
  
 f
 (
 x
 )
  ≈ c −
  b
  ·
  x
  + 1 2
 x
  ·
  A
  ·
  x 
 (
 10.6.1
 )
  
 Then the number of unknown parameters in
  f
  is equal to the number of free 
 parameters in
  A
  and
  b
 , which is
 1 2
 N
 (
 N
  + 1)
 , which we see to be of order
  N
  2
 . 
 Changing any one of these parameters can move the location of the minimum. 
 Therefore, we should not expect to be able to
  find
  the minimum until we have 
 collected an equivalent information content, of order
  N
 2
 numbers.",NA
10.7 Variable Metric Methods in ,NA,NA
Multidimensions,"The goal of
  variable metric
  methods, which are sometimes called
  quasi-
 Newton 
 methods, is not different from the goal of conjugate gradient methods: to 
 accumulate information from successive line minimizations so that
  N
  such line 
 minimizations lead to the exact minimum of a quadratic form in
  N
  dimensions. In 
 that case, the method will also be quadratically convergent for more general 
 smooth functions.
  
 Both variable metric and conjugate gradient methods require that you are able 
 to compute your function’s gradient, or first partial derivatives, at arbitrary points. 
 The variable metric approach differs from the conjugate gradient in the way that it 
 stores and updates the information that is accumulated. Instead of requiring 
 intermediate storage on the order of
  N
 , the number of dimensions, it requires a 
 matrix of size 
 N × N
 . Generally, for any moderate
  N
 , this is an entirely trivial 
 disadvantage. On the other hand, there is not, as far as we know, any overwhelming 
 advantage that the variable metric methods hold over the conjugate gradient 
 techniques, except perhaps a historical one. Developed somewhat earlier, and more 
 widely propagated, the variable metric methods have by now developed a wider 
 constituency of satisfied users. Likewise, some fancier implementations of variable 
 metric methods (going beyond the scope of this book, see below) have been 
 developed to a greater level of sophistication on issues like the minimization of 
 roundoff error, handling of special conditions, and so on.
  We
  tend to use variable 
 metric rather than conjugate gradient, but we have no reason to urge this habit on 
 you.
  
  
 Variablemetricmethodscomeintwomain flavors. Oneisthe
 Davidon-Fletcher-
 Powell (DFP)
  algorithm (sometimes referred to as simply
  Fletcher-Powell
 ). The 
 other goes by the name
  Broyden-Fletcher-Goldfarb-Shanno (BFGS)
 . The BFGS and 
 DFP schemes differ only in details of their roundoff error, convergence tolerances, 
 and similar “dirty” issues which are outside of our scope
 [1,2]
 . 
  
 However, it has 
 become generally recognized that, empirically, the BFGS scheme is superior in 
 these details. We will implement BFGS in this section.",NA
10.8 Linear Programming and the Simplex ,NA,NA
Method,"The subject of
  linear programming
 , sometimes called
  linear optimization
 , 
 concerns itselfwiththe followingproblem: For
  N
  independent variables
  x
 1
 , . . ., x
 N
 , 
 maximize
  the function
  
 z
  =
  a
 01
 x
 1
  +
  a
 02
 x
 2
  +
  · · ·
  +
  a
 0
 N
 x
 N 
 (
 10.8.1
 )
  
 subject to the primary constraints
  
 x
 1
  ≥
  0
 ,
  
 x
 2
  ≥
  0
 ,
  
 . . .
  
 x
 N
  ≥
  0
  
 (
 10.8.2
 )
  
 and simultaneously subject to
  M
  =
  m
 1
  +
  m
 2
  +
  m
 3
  additional constraints,
  m
 1
  of them 
 of the form
  
 a
 i
 1
 x
 1
  +
  a
 i
 2
 x
 2
  +
  · · ·
  +
  a
 iN
 x
 N
  ≤ b
 i
  
 (
 b
 i
  ≥
  0)
  
 i
  = 1
 , . . ., m
 1
  
 (
 10.8.3
 )
  
 m
 2
  of them of the form
  
 a
 j
 1
 x
 1
  +
  a
 j
 2
 x
 2
  +
  · · ·
  +
  a
 jN
 x
 N
  ≥ b
 j
  ≥
  0 
 and
  m
 3
  
 of them of the form
  
 j
  =
  m
 1
  + 1
 , . . ., m
 1
  +
  m
 2
  (
 10.8.4
 )
  
 a
 k
 1
 x
 1
  +
  a
 k
 2
 x
 2
  +
  · · ·
  +
  a
 kN
 x
 N
  =
  b
 k
  ≥
  0 
  
 (
 10.8.5
 )
  
 k
  =
  m
 1
  +
  m
 2
  + 1
 , . . ., m
 1
  +
  m
 2
  +
  m
 3
  
 The various
  a
 ij
 ’s can have either sign, or be zero. The fact that the
  b
 ’s must all be
  
 nonnegative (as indicated by the final inequality in the above three equations) is a
  
 matter of convention only, since you can multiply any contrary inequality by
  −
 1
 . There is no particular significance 
 in the number of constraints
  M
  being less than,
  
 equal to, or greater than the number of unknowns
  N
 .",NA
10.9 Simulated Annealing Methods,"The
  method of simulated annealing
 [1,2]
  is a technique that has attracted signif-
 icant attention as suitable for optimization problems of large scale, especially ones 
 where a desired global extremum is hidden among many, poorer, local extrema. 
 For practical purposes, simulated annealing has effectively “solved” the 
 famous
 traveling salesman problem
  of finding the shortest cyclical itinerary for a 
 traveling salesman who must visit each of
  N
  cities in turn. (Other practical methods 
 have also been found.) The method has also been used successfully for 
 designingcomplex integrated circuits: The arrangement of several hundred 
 thousand circuit elements on a tiny silicon substrate is optimized so as to minimize 
 interference among their connecting wires
 [3,4]
 . Surprisingly, the implementation of 
 the algorithm is relatively simple.
  
 Notice that the two applications cited are both examples of
  combinatorial 
 minimization
 . There is an objective function to be minimized, as usual; but the 
 space over which that function is defined is not simply the
  N
 -dimensional space of
  
 N 
 continuouslyvariable parameters. Rather, it is a discrete, but very large, 
 configuration",NA
Chapter 11. ,NA,NA
Eigensystems,NA,NA
11.0 Introduction,"eigenvalue
  λ
  if An
  N × N
  matrix
  A
  is said to have an
  eigenvector
  x
  and corresponding
  
 A
  ·
  x
  =
  λ
 x 
  
 (
 11.0.1
 )
  
 Obviously any multiple of an eigenvector
  x
  will also be an eigenvector, but we 
 won’t consider such multiples as being distinct eigenvectors. (The zero vector is 
 not considered to be an eigenvector at all.) Evidently (11.0.1) can hold only if
  
 det
  |
 A
  − λ
 1
 |
  = 0 (
 11.0.2
 )
  
 which, if expanded out, is an
  N
 th degree polynomial in
  λ
  whose roots are the eigen-
 values. This proves that there are always
  N
  (not necessarily distinct) eigenvalues. 
 Equal eigenvalues coming from multiple roots are called
  degenerate
 . Root-
 searching in the characteristic equation (11.0.2) is usually a very poor 
 computational method for finding eigenvalues. We will learn much better ways in 
 this chapter, as well as efficient ways for finding corresponding eigenvectors.
  
  
 The above two equations also prove that every one of the
  N
  eigenvalues has a 
 (not necessarily distinct) corresponding eigenvector: If
  λ
  is set to an eigenvalue, 
 then the matrix
  A
  − λ
 1
  is singular, and we know that every singular matrix has at 
 least one nonzero vector in its nullspace (see
  §
 2.6 on singular value decomposition). 
 If you add
  τ
 x
  to both sides of (11.0.1), you will easily see that the eigenvalues of 
 any matrix can be changed or
  shifted
  by an additive constant
  τ
  by adding to the 
 matrix that constant times the identity matrix. The eigenvectors are unchanged by 
 this shift. 
  
  
 Shifting, as we will see, is an important part of many algorithms for computing 
 eigenvalues. We see also that there is no special significance to a zero eigenvalue. 
 Any eigenvalue can be shifted to zero, or any zero eigenvalue can be shifted away 
 from zero.
  
 449",NA
11.1 Jacobi Transformations of a Symmetric ,NA,NA
Matrix,"The Jacobi method consists of a sequence of orthogonal similarity transforma-
 tions of the form of equation (11.0.14). Each transformation (a
  Jacobi rotation
 ) is 
 just a plane rotation designed to annihilate one of the off-diagonal matrix elements. 
 Successive transformations undo previously set zeros, but the off-diagonal 
 elements nevertheless get smaller and smaller, until the matrix is diagonal to 
 machine preci-sion. Accumulating the product of the transformations as you go 
 gives the matrix of eigenvectors, equation (11.0.15), while the elements of the final 
 diagonal matrix are the eigenvalues.
  
 The Jacobi method is absolutely foolproof for all real symmetric matrices. For 
 matrices of order greater than about 10, say, the algorithm is slower, by a 
 significant constant factor, than the
  QR
  method we shall give in
  §
 11.3. However, 
 the Jacobi algorithm is much simpler than the more efficient methods. We thus 
 recommend it for matrices of moderate order, where expense is not a major 
 consideration.
  
 The basic Jacobi rotation
  P
 pq
  is a matrix of the form
  
 P
 pq
  =
  
  
 · · ·
  
 c 
  
   
  
 ...
  
 · · ·
  
  
  
  
  
  
 1 
  
  
   
   
 s 
  
   
  
  
  
  
  
 ...
  
  
   
   
   
  
  
  
 (
 11.1.1
 ) 
  
 1",NA
11.2 Reduction of a Symmetric Matrix ,NA,NA
to Tridiagonal Form: Givens and ,NA,NA
Householder Reductions,"As already mentioned, the optimum strategy for finding eigenvalues and 
 eigenvectors is, first, to reduce the matrix to a simple form, only then beginning an 
 iterative procedure. For symmetric matrices, the preferred simple form is 
 tridiagonal. The
  Givens reduction
  is a modification of the Jacobi method. Instead of 
 trying to reduce the matrix all the way to diagonal form, we are content to stop 
 when the matrix is tridiagonal. This allows the procedure to be carried out
  in a 
 finite number of steps
 , unlike the Jacobi method, which requires iteration to 
 convergence.",NA
11.3 Eigenvalues and Eigenvectors of a ,NA,NA
Tridiagonal Matrix,"Evaluation of the Characteristic Polynomial
  
  
 Once our original, real, symmetric matrix has been reduced to tridiagonal form, 
 one possible way to determine its eigenvalues is to find the roots of the 
 characteristic polynomial
  p
 n
 (
 λ
 ) directly. The characteristic polynomial of a 
 tridiagonal matrix can be evaluated for any trial value of
  λ
  by an efficient recursion 
 relation (see
 [1]
 , for example). The polynomials of lower degree produced during the 
 recurrence form a Sturmian sequence that can be used to localize the eigenvalues to 
 intervals on the real axis. A root-finding method such as bisection or Newton’s 
 method can then be employed to refine the intervals. The corresponding 
 eigenvectors can then be found by inverse iteration (see
  §
 11.7). Procedures based on 
 these ideas can be found in
 [2,3]
 . 
  
 If, however, more 
 than a small fraction of all the eigenvalues and eigenvectors are required, then the 
 factorization method next considered is much more efficient.
  
 The QR and QL Algorithms
  
  
 The basic idea behind the
  QR
  algorithm is that any real matrix can be 
 decomposed in the form
  
 A
  =
  Q
  ·
  R 
  
 (
 11.3.1
 )
  
 where
  Q
  is orthogonal and
  R
  is upper triangular. 
  
 For a general matrix, the 
 decomposition is constructed by applying Householder transformations to annihilate 
 successive columns of
  A
  below the diagonal (see
  §
 2.10). Now consider the matrix 
 formed by writing the factors in (11.3.1) in the opposite order:
  
 A
 ′
 =
  R
  ·
  Q 
  
 (
 11.3.2
 )
  
 Since
  Q
  is orthogonal, equation (11.3.1) gives
  R
  =
  Q
 T
 ·
  A
 . Thus equation (11.3.2) becomes
  
 A
 ′
 =
  Q
 T
 ·
  A
  ·
  Q 
  
 (
 11.3.3
 )",NA
11.4 Hermitian Matrices,"The complex analog of a real, symmetric matrix is a Hermitian matrix, 
 satisfying equation (11.0.4). Jacobi transformations can be used to find eigenvalues 
 and eigenvectors, as also can Householder reduction to tridiagonal form followed 
 by 
 QL
  iteration. Complex versions of the previous routines
  jacobi
 ,
  tred2
 , and
  tqli 
 are quite analogous to their real counterparts. For working routines, consult
 [1,2]
 .
  
 An alternative, using the routines in this book, is to convert the Hermitian 
 problem to a real, symmetric one: If
  C
  =
  A
  +
  i
 B
  is a Hermitian matrix, then the 
 n × 
 n
  complex eigenvalue problem
  
 (
 A
  +
  i
 B
 )
  ·
  (
 u
  +
  i
 v
 ) =
  λ
 (
 u
  +
  i
 v
 ) (
 11.4.1
 )
  
 is equivalent to the
  2
 n ×
  2
 n
  real problem
  
 A B
 −
 B A
 ·
   
  
 u 
   
   
 v 
 =
  λ
   
  
  
  
  
 u 
  
  
   
  
   
 v 
 (
 11.4.2
 )
  
 Note that the
  2
 n ×
  2
 n
  matrix in (11.4.2) is symmetric:
  A
 T
 =
  A
  and
  B
 T
 =
  −
 B 
 if
  C
  is Hermitian.
  
 Corresponding to a given eigenvalue
  λ
 , the vector
  
 −
 v u 
  
 (
 11.4.3
 )
  
 is also an eigenvector, as you can verify by writing out the two matrix equa-tions 
 implied by (11.4.2). Thus if
  λ
 1
 , λ
 2
 , . . ., λ
 n
  are the eigenvalues of
  C
 , then the
  2
 n
  
 eigenvalues of the augmented problem (11.4.2) are
  λ
 1
 , λ
 1
 , λ
 2
 , λ
 2
 , . . .,λ
 n
 , λ
 n
 ; each, in 
 other words, is repeated twice. The eigenvectors are pairs of the form 
 u
  +
  i
 v
  and
  i
 (
 u
  
 +
  i
 v
 )
 ; that is, they are the same up to an inessential phase. Thus we solve the 
 augmented problem (11.4.2), and choose one eigenvalue and eigenvector from each 
 pair. These give the eigenvalues and eigenvectors of the original matrix
 C
 .
  
 Working with the augmented matrix requires a factor of 2 more storage than 
 the original complex matrix. In principle, a complex algorithm is also a factor of 2 
 more efficient in computer time than is the solution of the augmented problem. In 
 practice, most complex implementations do not achieve this factor unless they are 
 written entirely in real arithmetic. (Good library routines always do this.)
  
 CITED REFERENCES AND FURTHER READING:
  
 Wilkinson, J.H., and Reinsch, C. 1971, Linear Algebra, vol. II of Handbook for Automatic Com-
  
 putation (New York: Springer-Verlag). [1]
  
 Smith, B.T., et al. 1976, Matrix Eigensystem Routines — EISPACK Guide, 2nd ed., vol. 6 of 
  
 Lecture Notes in Computer Science (New York: Springer-Verlag). [2]",NA
11.5 Reduction of a General Matrix to ,NA,NA
Hessenberg Form,"The algorithms for symmetric matrices, given in the preceding sections, are 
 highly satisfactory in practice. 
  
 By contrast, it is impossible to design equally 
 satisfactory algorithms for the nonsymmetric case. There are two reasons for this. 
 First, the eigenvalues ofa nonsymmetricmatrixcan be very sensitivetosmall changes 
 in the matrix elements. Second, the matrix itself can be defective, so that there is no 
 complete set of eigenvectors. We emphasize that these difficulties are intrinsic 
 properties of certain nonsymmetric matrices, and no numerical procedure can 
 “cure”them. The best we can hope for are procedures that don’t exacerbate such 
 problems.
  
 The presence of rounding error can only make the situation worse. With finite-
 precision arithmetic, one cannot even design a foolproof algorithm to determine 
 whether a given matrix is defective or not. Thus current algorithms generally
  try
  to 
 find a
  complete
  set of eigenvectors, and rely on the user to inspect the results. If 
 any eigenvectors are almost parallel, the matrix is probably defective.
  
 Apart fromreferringyou tothe literature, and tothe collectedroutinesin
 [1,2]
 , we 
 are going to sidestep the problem of eigenvectors, giving algorithms for 
 eigenvalues only. If you require just a few eigenvectors, you can read
  §
 11.7 and 
 consider finding them by inverse iteration. We consider the problem of finding
  all
  
 eigenvectors of a nonsymmetric matrix as lying beyond the scope of this book.
  
 Balancing
  
  
 The sensitivity of eigenvalues to rounding errors during the execution of some 
 algorithms can be reduced by the procedure of
  balancing
 . 
  
 The errors in 
 the eigensystem found by a numerical procedure are generally proportional to the 
 Euclidean norm of the matrix, that is, to the square root of the sum of the squares of 
 the elements. 
  
 The idea of balancing is to use similarity transformations to 
 make corresponding rows and columns of the matrix have comparable norms, thus 
 reducing the overall norm of the matrix while leaving the eigenvalues unchanged. A 
 symmetric matrix is already balanced.
  
 Balancing is a procedure with of order
  N
 2
 operations. Thus, the time taken by 
 the procedure
  balanc
 , given below, should never be more than a few percent of the 
 total time required to find the eigenvalues. It is therefore recommended that you
  
 always
  balance nonsymmetric matrices. It never hurts, and it can substantially 
 improve the accuracy of the eigenvalues computed for a badly balanced matrix.
  
 The actual algorithm used is due to Osborne, as discussed in
 [1]
 . It consists of a 
 sequence of similarity transformations by diagonal matrices
  D
 . To avoid 
 introducing rounding errors during the balancing process, the elements of
  D
  are 
 restricted to be exact powers of the radix base employed for floating-point 
 arithmetic (i.e., 2 for most machines, but 16 for IBM mainframe architectures). The 
 output is a matrix that is balanced in the norm given by summing the absolute 
 magnitudes of the matrix elements. This is more efficient than using the Euclidean 
 norm, and equally effective: A large reduction in one norm implies a large 
 reduction in the other.
  
 Note that if the off-diagonal elements of any row or column of a matrix are all 
 zero, then the diagonal element is an eigenvalue. If the eigenvalue happens to",NA
11.6 The QR Algorithm for Real Hessenberg ,NA,NA
Matrices,"Recall the following relations for the
  QR
  algorithm with shifts:
  
 Q
 s
  ·
  (
 A
 s
  − k
 s
 1
 ) =
  R
 s 
 (
 11.6.1
 )
  
 where
  Q
  is orthogonal and
  R
  is upper triangular, and
  
 A
 s
 +1
  =
  R
 s
  ·
  Q
 T s
 +
  k
 s
 1 
  
  
  
 (
 11.6.2
 ) 
  
  
 =
  Q
 s
  ·
  A
 s
  ·
  Q
 T
  
 The
  QR
  transformation preserves the upper Hessenberg form of the original matrix 
 A
  ≡
  A
 1
 , and the workload on such a matrix is
  O
 (
 n
 2
 )
  per iteration as opposed to
  
 O
 (
 n
 3
 )
  on a general matrix. 
  
 As
  s → ∞
 ,
  A
 s
  converges to a form where the 
 eigenvalues are either isolated on the diagonal or are eigenvalues of a
  2
  ×
  2 
 submatrix on the diagonal.
  
 difference here is that a nonsymmetric real matrix can have complex eigenvalues. As we pointed out in
  §
 11.3, 
 shifting is essential for rapid convergence. A key
  
 This means that good choices for the shifts
  k
 s
  may be complex, apparently 
 necessitating complex arithmetic.
  
  
 Complex arithmetic can be avoided, however, by a clever trick. 
  
 The trick 
 depends on a result analogous to the lemma we used for implicit shifts in
  §
 11.3. The 
 lemma we need here states that if
  B
  is a nonsingular matrix such that
  
 B
  ·
  Q
  =
  Q
  ·
  H 
  
 (
 11.6.3
 )
  
 where
  Q
  is orthogonal and
  H
  is upper Hessenberg, then
  Q
  and
  H
  are fully 
 determined by the first column of
  Q
 . (The determination is unique if
  H
  has positive 
 subdiagonal elements.) The lemma can be proved by induction analogously to the 
 proof given for tridiagonal matrices in
  §
 11.3. The lemma is used in practice by",NA
11.7 Improving Eigenvalues and/or Finding ,NA,NA
Eigenvectors by Inverse Iteration,"The basic idea behind inverse iteration is quite simple. Let
  y
  be the solution of 
 the linear system
  
 (
 A
  − τ
 1
 )
  ·
  y
  =
  b 
  
 (
 11.7.1
 )
  
 where
  b
  is a random vector and
  τ
  is close to some eigenvalue
  λ
  of
  A
 . Then the 
 solution
  y
  will be close to the eigenvector corresponding to
  λ
 . The procedure can 
 be iterated: Replace
  b
  by
  y
  and solve for a new
  y
 , which will be even closer to the 
 true eigenvector.
  
  
 We can see why this works by expanding both
  y
  and
  b
  as linear combinations 
 of the eigenvectors
  x
 j
  of
  A
 :
  
 y
  =
  
 j
  
 α
 j
 x
 j
  
 b
  =
  
 j
  
 β
 j
 x
 j
  
 (
 11.7.2
 )
  
 Then (11.7.1) gives
  
 j
  
 α
 j
 (
 λ
 j
  − τ
 )
 x
 j
  =
  
 j
  
 β
 j
 x
 j
  
 (
 11.7.3
 )
  
 so that
  
 α
 j
  =
 β
 j 
  
 (
 11.7.4
 )
  
 and
  
 λ
 j
  − τ
  
 y
  =
  
 β
 j
 x
 j 
  
 (
 11.7.5
 )
  
 j
  
 λ
 j
  − τ
  
 If
  τ
  is close to
  λ
 n
 , say, then provided
  β
 n
  is not accidentally too small,
  y
  will be 
 approximately
  x
 n
 , up to a normalization. Moreover, each iteration of this procedure 
 gives another power of
  λ
 j
  − τ
  in the denominator of (11.7.5). Thus the convergence 
 is rapid for well-separated eigenvalues.
  
 Suppose at the
  k
 th stage of iteration we are solving the equation
  
 (
 A
  − τ
 k
 1
 )
  ·
  y
  =
  b
 k 
  
 (
 11.7.6
 )
  
 where
  b
 k
  and
  τ
 k
  are our current guesses for some eigenvector and eigenvalue of 
 interest (let’s say,
  x
 n
  and
  λ
 n
 ). eigenvector and eigenvalue satisfy Normalize
  b
 k
  so 
 that
  b
 k
  ·
  b
 k
  = 1
 . 
  
 The exact
  
 A
  ·
  x
 n
  =
  λ
 n
 x
 n 
 (
 11.7.7
 )
  
 so
  
 (
 A
  − τ
 k
 1
 )
  ·
  x
 n
  = (
 λ
 n
  − τ
 k
 )
 x
 n 
 (
 11.7.8
 )
  
 Since
  y
  of (11.7.6) is an improved approximation to
  x
 n
 , we normalize it and set
  
 b
 k
 +1
  =
 y 
  
 (
 11.7.9
 ) 
  
  
 |
 y
 |",NA
Chapter 12. ,NA,NA
Fast Fourier Transform,NA,NA
12.0 Introduction,"A very large class of important computational problems falls under the general 
 rubric of “Fourier transform methods” or “spectral methods.” For some of these 
 problems, the Fourier transform is simply an efficient computational tool for 
 accomplishing certain common manipulations of data. 
  
 In other cases, we have 
 problems for which the Fourier transform (or the related “power spectrum”) is itself 
 of intrinsic interest. These two kinds of problems share a common methodology.
  
 Largely for historical reasons the literature on Fourier and spectral methods 
 has been disjointfrom the literature on “classical” numerical analysis. Nowadays 
 there is no justificationfor such a split. Fourier methods are commonplace in 
 research and we shall not treat them as specialized or arcane. At the same time, we 
 realize that many computer users have had relatively less experience with this field 
 than with, say, differential equations or numerical integration. Therefore our 
 summary of analytical results will be more complete. Numerical algorithms, per se, 
 begin in
  §
 12.2. Various applications of Fourier transform methods are discussed in 
 Chapter 13.
  
 A physical process can be described either in the
  time domain
 , by the values 
 of some quantity
  h
  as a function of time
  t
 , e.g.,
  h
 (
 t
 )
 , or else in the
  frequency 
 domain
 , where the process is specified by giving its amplitude
  H
  (generally a 
 complex number indicating phase also) as a function of frequency
  f
 , that is
  H
 (
 f
 )
 , 
 with
 −∞ < f < ∞
 . For many purposes it is useful to think of
  h
 (
 t
 )
  and
  H
 (
 f
 )
  as being 
 two different
  representations
  of the
  same
  function. One goes back and forth 
 between these two representations by means of the
  Fourier transform
  equations,
  
  
  ∞
  
 H
 (
 f
 ) = 
  
  
 h
 (
 t
 )
 e
 2
 πift
 dt
  
 −∞ ∞
  
 (
 12.0.1
 )
  
 h
 (
 t
 ) = 
  
 H
 (
 f
 )
 e
 −
 2
 πift
 df
  
 −∞
  
 If
  t
  is measured in seconds, then
  f
  in equation (12.0.1) is in cycles per second, 
 or Hertz (the unit of frequency). However, the equations work with other units too. 
 If
  h
  is a functionof position
  x
  (in meters),
  H
  will be a functionof inverse wavelength 
 (cycles per meter), and so on. If you are trained as a physicist or mathematician, 
 you are probably more used to using
  angular frequency
  ω
 , which is given in
  
 radians
  per sec. The relation between
  ω
  and
  f
 ,
  H
 (
 ω
 )
  and
  H
 (
 f
 )
  is
  
 ω ≡
  2
 πf
  
 H
 (
 ω
 )
  ≡
  [
 H
 (
 f
 )]
 f
 =
 ω/
 2
 π
  
 (
 12.0.2
 )
  
 490",NA
12.1 Fourier Transform of Discretely Sampled ,NA,NA
Data,"In the most common situations, function
  h
 (
 t
 )
  is sampled (i.e., its value is 
 recorded) at evenly spaced intervals in time. Let
  ∆
  denote the time interval between 
 consecutive samples, so that the sequence of sampled values is
  
 h
 n
  =
  h
 (
 n
 ∆)
  
 n
  =
  . . ., −
 3
 , −
 2
 , −
 1
 ,
  0
 ,
  1
 ,
  2
 ,
  3
 , . . .
  
 (
 12.1.1
 )
  
 The reciprocal of the time interval
  ∆
  is called the
  sampling rate
 ; if
  ∆
  is measured in 
 seconds, for example, then the sampling rate is the number of samples recorded per 
 second.
  
 Sampling Theorem and Aliasing
  
  
 For any sampling interval
  ∆
 , there is also a special frequency
  f
 c
 , called the 
 Nyquist critical frequency
 , given by
  
 f
 c
  ≡
  
 1
  
 (
 12.1.2
 )
  
 2∆
  
 If a sine wave of the Nyquist critical frequency is sampled at its positive peak 
 value, then the next sample will be at its negative trough value, the sample after 
 that at the positive peak again, and so on. Expressed otherwise:
  Critical sampling 
 of a sine wave is two sample points per cycle.
  One frequently chooses to measure 
 time in units of the sampling interval
  ∆
 . In this case the Nyquist critical frequency 
 is just the constant 1/2.
  
 The Nyquist critical frequency is important for two related, but distinct, 
 reasons. One is good news, and the other bad news. First the good news. It is the 
 remarkable",NA
12.2 Fast Fourier Transform (FFT),"How much computation is involved in computing the discrete Fourier 
 transform (12.1.7) of
  N
  points? For many years, until the mid-1960s, the standard 
 answer was this: Define
  W
  as the complex number
  
 W ≡ e
 2
 πi/N 
  
 (
 12.2.1
 )
  
 Then (12.1.7) can be written as
  
 H
 n
  =
  
 N−
 1
  
 W
 nk
 h
 k
  
 (
 12.2.2
 )
  
 k
 =0
  
 In other words, the vector of
  h
 k
 ’s is multiplied by a matrix whose
  (
 n, k
 )
 th element is 
 the constant
  W
  to the power
  n × k
 . The matrix multiplication produces a vector 
 result whose components are the
  H
 n
 ’s. This matrix multiplicationevidently requires 
 N
 2
 complex multiplications, plus a smaller number of operations to generate the 
 required powers of
  W
 . So, the discrete Fourier transform appears to be an
  O
 (
 N
 2
 ) 
 process. These appearances are deceiving! 
  
 The discrete Fourier transform can, 
 in fact, be computed in
  O
 (
 N
  log
 2
  N
 )
  operations with an algorithm called the
  fast 
 Fourier transform
 , or
  FFT
 . The difference between
  N
  log
 2
  N
  and
  N
 2
 is immense. 
 With
  N
  = 10
 6
 , for example, it is the difference between, roughly, 30 seconds of CPU 
 time and 2 weeks of CPU time on a microsecond cycle time computer. The 
 existence of an FFT algorithm became generally known only in the mid-1960s, 
 from the work of J.W. Cooley and J.W. Tukey. Retrospectively, we now know 
 (see
 [1]
 ) that efficient methods for computing the DFT had been independently 
 discovered, and in some cases implemented, by as many as a dozen individuals, 
 starting with Gauss in 1805!
  
 One “rediscovery” of the FFT, that of Danielson and Lanczos in 1942, 
 provides one of the clearest derivations of the algorithm. Danielson and Lanczos 
 showed that a discrete Fourier transform of length
  N
  can be rewritten as the sum of 
 two discrete Fourier transforms, each of length
  N/
 2
 . One of the two is formed from 
 the",NA
"12.3 FFT of Real Functions, Sine and Cosine ",NA,NA
Transforms,"It happens frequently that the data whose FFT is desired consist of real-valued 
 samples
  f
 j
 , j
  = 0
  . . .N −
  1
 . To use
  four1
 , we put these into a complex array with all 
 imaginary parts set to zero. The resulting transform
  F
 n
 , n
  = 0
  . . .N −
  1 
 satisfies
  F
 N−n
 * 
 =
  F
 n
 . 
  
 Since this complex-valued array has real values for
  F
 0 
 and
  
 F
 N/
 2
 , and
  (
 N/
 2)
  −
  1
  other independent values
  F
 1
  . . . F
 N/
 2
 −
 1
 , it has the same 
 2(
 N/
 2
  −
  
 1) + 2 =
  N
  “degrees of freedom” as the original, real data set. However, the use of 
 the full complex FFT algorithmfor real data is inefficient, bothin execution time and 
 in storage required. You would think that there is a better way.
  
 There are
  two
  better ways. The first is “mass production”: Pack two separate 
 real functions into the input array in such a way that their individual transforms can 
 be separated from the result. This is implemented in the program
  twofft
  below. 
 This may remind you of a one-cent sale, at which you are coerced to purchase two 
 of an item when you only need one. However, remember that for correlations and 
 convolutions the Fourier transforms of two functions are involved, and this is a 
 handy way to do them both at once. The second method is to pack the real input 
 array cleverly, without extra zeros, into a complex array of half its length. One then 
 performs a complex FFT on this shorter length; the trick is then to get the required 
 answer out of the result. This is done in the program
  realft
  below.",NA
12.4 FFT in Two or More Dimensions,"Given a complex function
  h
 (
 k
 1
 , k
 2
 )
  defined over the two-dimensional grid 
 0
  ≤ 
 k
 1
  ≤ N
 1
  −
  1
 ,
  0
  ≤ k
 2
  ≤ N
 2
  −
  1
 , we can define its two-dimensional discrete Fourier 
 transform as a complex function
  H
 (
 n
 1
 , n
 2
 )
 , defined over the same grid,
  
  
 N
 2
 −
 1 
 N
 1
 −
 1 
  
 H
 (
 n
 1
 , n
 2
 )
  ≡
   
  
 exp(2
 πik
 2
 n
 2
 /N
 2
 ) exp(2
 πik
 1
 n
 1
 /N
 1
 )
  h
 (
 k
 1
 , k
 2
 )
  
 k
 2
 =0 
 k
 1
 =0 
  
  
  
 (
 12.4.1
 )
  
 By pulling the “subscripts 2” exponential outside of the sum over
  k
 1
 , or by reversing 
 the order of summation and pulling the “subscripts 1” outside of the sum over
  k
 2
 ,",NA
12.5 Fourier Transforms of Real Data in Two ,NA,NA
and Three Dimensions,"Two-dimensional FFTs are particularly important in the field of image 
 process-ing. An image is usually represented as a two-dimensional array of pixel 
 intensities, real (and usually positive) numbers. One commonly desires to filter 
 high, or low, frequency spatial components from an image; or to convolve or 
 deconvolve the image with some instrumental point spread function. Use of the 
 FFT is by far the most efficient technique.
  
  
 In three dimensions, a common use of the FFT is to solve Poisson’s equation 
 for a potential (e.g., electromagnetic or gravitational) on a three-dimensional lattice 
 that represents the discretization of three-dimensional space. Here the source terms 
 (mass or charge distribution) and the desired potentials are also real. In two and 
 three dimensions, with large arrays, memory is often at a premium. It is therefore 
 important to perform the FFTs, insofar as possible, on the data “in place.”
  
 We 
 want a routine with functionalitysimilar to the multidimensional FFT routine
  fourn 
 (
 §
 12.4), but which operates on real, not complex, input data. 
  
 We give such a 
 routine in this section. The development is analogous to that of
  §
 12.3 leading to the 
 one-dimensional routine
  realft
 . (You might wish to review that material at this 
 point, particularly equation 12.3.5.) 
  
  
 It is convenient to think of the independent variables
  n
 1
 , . . ., n
 L
  in equation 
 (12.4.3) as representing an
  L
 -dimensional vector
  ≪n
  in wave-number space, with 
 values on the lattice of integers. The transform
  H
 (
 n
 1
 , . . ., n
 L
 )
  is then denoted
  H
 (
 ≪n
 )
 .
  
 It is easy to see that the transform
  H
 (
 ≪n
 )
  is periodic in each of its
  L
  dimensions.
  
 Specifically, if
 ≪P
 1
 , ≪P
 2
 , ≪P
 3
 , . . .
  denote the vectors
  (
 N
 1
 ,
  0
 ,
  0
 , . . .
 )
 ,
  (0
 , N
 2
 ,
  0
 , . . .
 )
 , 
 (0
 ,
  
 0
 , N
 3
 , . . .
 )
 , and so forth, then
  
 H
 (
 ≪n ±≪P
 j
 ) =
  H
 (
 ≪n
 ) 
  
 j
  = 1
 , . . ., L 
  
 (
 12.5.1
 )",NA
12.6 External Storage or Memory-Local FFTs,"Sometime in your life, you might have to compute the Fourier transform of a
  really 
 large
  data set, larger than the size of your computer’s physical memory. In such a case, the 
 data will be stored on some external medium, such as magnetic or optical tape or disk. 
 Needed is an algorithm that makes some manageable number of sequential passes through 
 the external data, processing it on the fly and outputting intermediate results to other external 
 media, which can be read on subsequent passes.
  
 In fact, an algorithm of just this description was developed by Singleton
 [1]
 very soon 
 after the discovery of the FFT. The algorithm requires four sequential storage devices, each 
 capable of holding half of the input data. The first half of the input data is initially on one 
 device, the second half on another.
  
 Singleton’s algorithm is based on the observation that it is possible to bit-reverse
  2
 M 
 values by the following sequence of operations: On the first pass, values are read alternately 
 from the two input devices, and written to a single output device (until it holds half the data), 
 and then to the other output device. On the second pass, the output devices become input 
 devices, and vice versa. Now, we copy
  two
  values from the first device, then
  two
  values from 
 the second, writing them (as before) first to fill one output device, then to fill a second. 
 Subsequent passes read 4, 8, etc., input values at a time. After completion of pass
  M −
  1
 , the 
 data are in bit-reverse order.
  
 Singleton’s next observation is that it is possible to alternate the passes of essentially this bit-
 reversal technique with passes that implement one stage of the Danielson-Lanczos 
 combination formula (12.2.3). The scheme, roughly, is this: One starts as before with half the 
 input data on one device, half on another. In the first pass, one complex value is read from 
 each input device. Two combinations are formed, and one is written to each of two output 
 devices. After this “computing” pass, the devices are rewound, and a “permutation”pass is 
 performed, where groups of values are read from the first input device and alternately written 
 to the first and second output devices; when the first input device is exhausted, the second is 
 similarly processed. This sequenceof computing and permutation passesis repeated 
 M − K −
  1
  
 times, where
  2
 K
 is the size of internal buffer available to the program. The second phase of the 
 computation consists of a final
  K
  computation passes. What distinguishes the second phase 
 from the first is that, now, the permutations are local enough to do in place during the 
 computation. There are thus no separate permutation passes in the second phase. Here is an 
 implementation of Singleton’s algorithm, based on
 [1]
 : In all, there are
  2
 M − K −
  2
  passes 
 through the data.
  
 SUBROUTINE fourfs(iunit,nn,ndim,isign)
  
 INTEGER ndim,nn(ndim),isign,iunit(4),KBF
  
 C
  
 PARAMETER (KBF=128) 
  
 USES fourew
  
 One- or multi-dimensional Fourier transform of a large data set stored on external media.
  
 On input,
  ndim
  is the number of dimensions, and
  nn(1:ndim)
  contains the lengths of
  
 each dimension (number of complex values), which must be powers of two.
  iunit(1:4)
  
 contains the unit numbers of 4 sequential files, each large enough to hold half of the data.
  
 The four units must be opened for
  FORTRAN
  unformatted access. The input data must be
  
 in
  FORTRAN
  normal order, with its first half stored on unit
  iunit(1)
 , its second half on
  
 iunit(2)
 , in unformatted form, with
  KBF
  real numbers per record.
  isign
  should be set
  
 to 1 for the Fourier transform, to
  −
 1 for its inverse. On output, values in the array
  iunit 
 may 
 have been permuted; the first half of the result is stored on
  iunit(3)
 , the second half on
  
 iunit(4)
 . N.B.: For
  ndim
  >
  1, the output is stored by rows, i.e.,
  not
  in
  FORTRAN
  
 normal order; in other words, the output is the transpose of that which would have been
  
 produced by routine
  fourn
 .
  
 INTEGER j,j12,jk,k,kk,n,mm,kc,kd,ks,kr,nr,ns,nv,jx,
  
 * 
  
 mate(4),na,nb,nc,nd
  
 REAL tempr,tempi,afa(KBF),afb(KBF),afc(KBF)
  
 DOUBLE PRECISION wr,wi,wpr,wpi,wtemp,theta
  
 SAVE mate
  
 DATA mate /2,1,4,3/",NA
Chapter 13.,NA,NA
Fourier and Spectral ,NA,NA
Applications,NA,NA
13.0 Introduction,"Fourier methods have revolutionized fields of science and engineering, from 
 radio astronomy to medical imaging, from seismology to spectroscopy. 
  
 In this 
 chapter, we present some of the basic applications of Fourier and spectral methods 
 that have made these revolutions possible.
  
  
 Say the word “Fourier” to a numericist, and the response, as if by Pavlovian 
 conditioning, will likely be “FFT.” Indeed, the wide application of Fourier methods 
 must be credited principally to the existence of the fast Fourier transform. Better 
 mousetraps stand aside: If you speed up
  any
  nontrivial algorithm by a factor of a 
 million or so, the world will beat a path towards finding useful applications for it. 
 The most direct applications of the FFT are to the convolution or deconvolution of 
 data (
 §
 13.1), correlation and autocorrelation (
 §
 13.2), optimal filtering (
 §
 13.3), 
 power spectrum estimation (
 §
 13.4), and the computation of Fourier integrals 
 (
 §
 13.9). As important as they are, however, FFT methods are not the be-all and end-
 all of spectral analysis. Section 13.5 is a brief introduction to the field of time-
 domain digital filters. In the spectral domain, one limitation of the FFT is that it 
 always represents a function’s Fourier transform as a polynomial in
  z
  = exp(2
 πif
 ∆) 
 (cf. equation 12.1.7). 
  
 Sometimes, processes have spectra whose shapes are not 
 well represented by this form. An alternative form, which allows the spectrum to 
 have poles in
  z
 , is used in the techniques of linear prediction (
 §
 13.6) and maximum 
 entropy spectral estimation (
 §
 13.7). Another significant limitation of all FFT 
 methods is that they require the input 
  
   
  
 For 
 irregularly or incompletely data to be sampled at evenly spaced intervals.
  
 sampled data, other (albeit slower) methods are available, as discussed in
  §
 13.8. 
 So-called wavelet methods inhabit a representation of function space that is neither 
 in the temporal, nor in the spectral, domain, but rather something in-between. 
 Section 13.10 is an introduction to this subject. Finally
  §
 13.11 is an excursion into 
 numerical use of the Fourier sampling theorem.",NA
13.1 Convolution and Deconvolution Using ,NA,NA
the FFT,"We have defined the
  convolution
  of two functions for the continuous case in 
 equation (12.0.8), and have given the
  convolution theorem
  as equation (12.0.9). 
 The theorem says that the Fourier transform of the convolution of two functions is 
 equal to the product of their individual Fourier transforms. Now, we want to deal 
 with the discrete case. We will mention first the context in which convolution is a 
 useful procedure, and then discuss how to compute it efficiently using the FFT.
  
 equal to their convolution in the opposite order,
  s ≪ r
 . applications the two functions have quite different meanings 
 and characters. One of The convolutionof two functions
  r
 (
 t
 )
  and
  s
 (
 t
 )
 , denoted
  r ≪s
 , is mathematically Nevertheless, 
 in most
  
 the functions, say
  s
 , is typically a signal or data stream, which goes on indefinitely 
 in time (or in whatever the appropriate independent variable may be). The other 
 function
  r
  is a “response function,” typically a peaked function that falls to zero in 
 both directions from its maximum. The effect of convolution is to smear the signal 
 s
 (
 t
 )
  in time according to the recipe provided by the response function
  r
 (
 t
 )
 , as 
 shown in Figure 13.1.1. In particular, a spike or delta-function of unit area in
  s
  
 which occurs at some time
  t
 0
  is supposed to be smeared into the shape of the 
 response function In the discrete case, the signal
  s
 (
 t
 )
  is represented by its sampled 
 values at equal itself, but translated from time 0 to time
  t
 0
  as
  r
 (
 t − t
 0
 )
 .
  
 time intervals
  s
 j
 . The response function is also a discrete set of numbers
  r
 k
 , with the 
 followinginterpretation:
  r
 0
  tells what multipleof the input signal in one channel 
 (one particular value of
  j
 ) is copied into the identical output channel (same value of
  
 j
 ); 
 r
 1
  tells what multiple of input signal in channel
  j
  is additionally copied into 
 output channel
  j
  + 1
 ;
  r
 −
 1
  tells the multiple that is copied into channel
  j −
  1
 ; and so 
 on for both positive and negative values of
  k
  in
  r
 k
 . Figure 13.1.2 illustrates the 
 situation.
  
 Example: a response function with
  r
 0
  = 1
  and all other
  r
 k
 ’s equal to zero is just 
 the identity filter: convolution of a signal with this response function gives 
 identically the signal. Another example is the response function with
  r
 14
  = 1
 .
 5
  and 
 all other
  r
 k
 ’s equal to zero. This produces convolved output that is the input signal 
 multiplied by
  1
 .
 5
  and delayed by
  14
  sample intervals.
  
  
 Evidently, we have just described in words the following definition of discrete 
 convolution with a response function of finite duration
  M
 :
  
 M/
 2
  
 (
 r ≪ s
 )
 j
  ≡
  
 s
 j−k
  r
 k 
 (
 13.1.1
 )
  
 k
 =
 −M/
 2+1
  
 If a discrete response function is nonzero only in some range
  −M/
 2
  < k ≤ M/
 2
 , 
 where
  M
  is a sufficiently large even integer, then the response function is called a 
 finite impulse response (FIR)
 , and its
  duration
  is
  M
 . (Notice that we are defining
  M 
 as the number of nonzero
  values
  of
  r
 k
 ; these values span a time interval of
  M −
  1 
 sampling times.) In most practical circumstances the case of finite
  M
  is the case of",NA
13.2 Correlation and Autocorrelation Using ,NA,NA
the FFT,"Correlation is the close mathematical cousin of convolution. It is in some 
 ways simpler, however, because the two functions that go into a correlation are not 
 as conceptually distinct as were the data and response functions that entered into 
 convolution. Rather, in correlation, the functions are represented by different, but 
 generally similar, data sets. We investigate their “correlation,” by comparing them 
 both directly superposed, and with one of them shifted left or right.
  
  
 We have already defined in equation (12.0.10) the correlation between two 
 continuous functions
  g
 (
 t
 )
  and
  h
 (
 t
 )
 , which is denoted Corr
 (
 g, h
 )
 , and is a function of
  
 lag
  t
 . We will occasionally show this time dependence explicitly, with the rather 
 awkward notation Corr
 (
 g, h
 )(
 t
 )
 . 
  
 The correlation will be large at some value of 
 t
  if 
 the first function (
 g
 ) is a close copy of the second (
 h
 ) but lags it in time by 
 t
 , i.e., if 
 the first function is shifted to the right of the second. 
  
 Likewise, the 
 correlation will be large for some negative value of
  t
  if the first function
  leads
  the 
 second, i.e., is shifted to the left of the second. The relation that holds when the two 
 functions are interchanged is
  
 Corr
 (
 g, h
 )(
 t
 ) =
  Corr
 (
 h, g
 )(
 −t
 ) 
  
 (
 13.2.1
 )
  
  
 The discrete correlation of two sampled functions
  g
 k
  and
  h
 k
 , each periodic with 
 period
  N
 , is defined by
  
 Corr
 (
 g, h
 )
 j
  ≡
  
 N−
 1
  
 g
 j
 +
 k
 h
 k
  
 (
 13.2.2
 )
  
 k
 =0
  
 The
  discrete correlation theorem
  says that this discrete correlation of two real 
 functions
  g
  and
  h
  is one member of the discrete Fourier transform pair
  
 Corr
 (
 g, h
 )
 j
  ≪≪ G
 k
 H
 k
 * (
 13.2.3
 )
  
 where
  G
 k
  and
  H
 k
  are the discrete Fourier transforms of
  g
 j
  and
  h
 j
 , and the asterisk 
 denotes complex conjugation. This theorem makes the same presumptions about 
 the functions as those encountered for the discrete convolution theorem.
  
 We can compute correlations using the FFT as follows: FFT the two data sets, 
 multiply one resulting transform by the complex conjugate of the other, and inverse 
 transform the product. The result (call it
  r
 k
 ) will formally be a complex vector of 
 length
  N
 . However, it will turn out to have all its imaginary parts zero since the 
 original data sets were both real. The components of
  r
 k
  are the values of the 
 correlation at different lags, with positive and negative lags stored in the by now 
 familiar wrap-around order: The correlation at zero lag is in
  r
 0
 , the first component; 
 the correlation at lag 1 is in
  r
 1
 , the second component; the correlation at lag
  −
 1 
 is in
  
 r
 N−
 1
 , the last component; etc.
  
 Just as in the case of convolution we have to consider end effects, since our 
 data will not, in general, be periodic as intended by the correlation theorem. Here 
 again, we can use zero padding. If you are interested in the correlation for lags as",NA
13.3 Optimal (Wiener) Filtering with the FFT,"There are a number of other tasks in numerical processing that are routinely 
 handled with Fourier techniques. One of these is filtering for the removal of noise 
 from a “corrupted” signal. The particular situationwe consider is this: There is some 
 underlying, uncorrupted signal
  u
 (
 t
 )
  that we want to measure. The measurement 
 process is imperfect, however, and what comes out of our measurement device is a 
 corrupted signal
  c
 (
 t
 )
 . The signal
  c
 (
 t
 )
  may be less than perfect in either or both of 
 two respects. First, the apparatus may not have a perfect “delta-function” response,",NA
13.4 Power Spectrum Estimation Using the FFT,"In the previous section we “informally”estimated the power spectral densityof 
 a function
  c
 (
 t
 )
  by taking the modulus-squaredof the discrete Fouriertransform of 
 some finite, sampled stretch of it. In this section we’ll do roughly the same thing, 
 but with considerably greater attention to details. Our attention will uncover some 
 surprises.
  
 The first detail is power spectrum (also called a power spectral density or 
 PSD) normalization. In general there is
  some
  relation of proportionality between a 
 measure of the squared amplitude of the function and a measure of the amplitude of 
 the PSD. Unfortunately there are several different conventions for describing the 
 normalization in each domain, and many opportunities for getting wrong the 
 relationship between the two domains. Suppose that our function
  c
 (
 t
 )
  is sampled at 
 N
  points to produce values
  c
 0
  . . . c
 N−
 1
 , and that these points span a range of time 
 T
 , 
 that is
  T
  = (
 N −
  1)∆
 , where
  ∆
  is the sampling interval. Then here are several",NA
13.5 Digital Filtering in the Time Domain,"Suppose that you have a signal that you want to filter digitally. For example, perhaps 
 you want to apply
  high-pass
  or
  low-pass
  filtering, to eliminate noise at low or high 
 frequencies respectively; or perhaps the interesting part of your signal lies only in a certain 
 frequency band, so that you need a
  bandpass
  filter. Or, if your measurements are 
 contaminated by 60 Hz power-line interference, you may need a
  notch filter
  to remove only 
 a narrow band around that frequency. This section speaks particularly about the case in 
 which you have chosen to do such filtering in the time domain.
  
 Before continuing, we hope you will reconsider this choice. Remember how convenient 
 it is to filter in the Fourier domain. You just take your whole data record, FFT it, multiply the 
 FFT output by a filter function
  H
 (
 f
 )
 , and then do an inverse FFT to get back a filtered data set 
 in time domain. Here is some additional background on the Fourier technique that you will 
 want to take into account.
  
 •
  Remember that you must define your filter function
  H
 (
 f
 )
  for both positive and 
 negative frequencies, and that the magnitude of the frequency extremes is always 
 the Nyquist frequency
  1
 /
 (2∆)
 , where
  ∆
  is the sampling interval. The magnitude 
 number of (complex) points in the FFT. The positive and negative frequencies to 
 of the smallest nonzero frequencies in the FFT is
  ±
 1
 /
 (
 N
 ∆)
 , where
  N
  is the which 
 this filter are applied are arranged in wrap-around order.
  
 •
  If the measured data are real, and you want the filtered output also to be real, then 
 your arbitrary filter function should obey
  H
 (
 −f
 ) =
  H
 (
 f
 )*
 . You can arrange this 
 most easily by picking an
  H
  that is real and even in
  f
 .
  
 •
  If your chosen
  H
 (
 f
 )
  has sharp vertical edges in it, then the
  impulse response
  of 
 your filter (the output arising from a short impulse as input) will have 
 damped“ringing” at frequencies corresponding to these edges. There is nothing 
 wrong with this, but if you don’t like it, then pick a smoother
  H
 (
 f
 )
 . To get a first-
 hand look at the impulse response of your filter, just take the inverse FFT of your",NA
13.6 Linear Prediction and Linear Predictive ,NA,NA
Coding,"We begin witha very general formulationthat will allow us to make 
 connections to various special cases. Let
  {y
 ′α
 }
  be a set of measured values for some 
 underlying set of true values of a quantity
  y
 , denoted
  {y
 α
 }
 , related to these true 
 values by the addition of random noise,
  
 y
 ′α
 =
  y
 α
 +
  n
 α
  
 (
 13.6.1
 )
  
 (compare equation 13.3.2, with a somewhat different notation). Our use of a Greek 
 subscript to index the members of the set is meant to indicate that the data points 
 are not necessarily equally spaced along a line, or even ordered: they might 
 be“random” points in three-dimensional space, for example. Now, suppose we 
 want to construct the “best” estimate of the true value of some particular point
  y
 ≪
  as 
 a linear combination of the known, noisy, values. Writing
  
 y
 ≪
  =
  
 d
 ≪α
 y
 ′α
 +
  x
 ≪
  
 (
 13.6.2
 )
  
 α
  
 we want to find coefficients
  d
 ≪α
  that minimize, in some way, the
 discrepancy
  x
 ≪
 . 
 The coefficients
  d
 ≪α
  have a “star” subscript to indicate that they depend on the 
 choice of point
  y
 ≪
 . Later, we might want to let
  y
 ≪
  be one of the existing
  y
 α
 ’s. In that 
 case, our problem becomes one of optimal filtering or estimation, closely related to 
 the discussion in
  §
 13.3. On the other hand, we might want
  y
 ≪
  to be a completely 
 new point. In that case, our problem will be one of
  linear prediction
 .
  
 A natural way to minimize the discrepancy
  x
 ≪
  is in the statistical mean square 
 sense. If angle brackets denote statistical averages, then we seek
  d
 ≪α
 ’s that minimize
  
 2
  
 x
 2
 ≪
 = 
  
  
 d
 ≪α
 (
 y
 α
  +
  n
 α
 )
  − y
 ≪
  
   
  
 α
   
 (
 13.6.3
 )
  
 =
  
 αβ
 (
 ≪y
 α
 y
 β
 ≪
  +
  ≪n
 α
 n
 β
 ≪
 )
 d
 ≪α
 d
 ≪β
  −
  2
  
 α
   
  
 ≪y
 ≪
 y
 α
 ≪ d
 ≪α
  + 
  
 y
 2
 ≪
  
 Here we have used the fact that noise is uncorrelated with signal, e.g.,
  ≪n
 α
 y
 β
 ≪
  = 0
 . 
 The quantities
  ≪y
 α
 y
 β
 ≪
  and
  ≪y
 ≪
 y
 α
 ≪
  describe the autocorrelation structure of the 
 underlying data. We have already seen an analogous expression, (13.2.2), for the 
 case of equally spaced data points on a line; we will meet correlation several times 
 again in its statistical sense in Chapters 14 and 15. The quantities
 ≪n
 α
 n
 β
 ≪
  describe 
 the autocorrelation properties of the noise. Often, for point-to-point uncorrelated 
 noise, we have
  ≪n
 α
 n
 β
 ≪
  =
 n
 2 
 quantities as comprising matrices and vectors,
  
 α
  
  δ
 αβ
 . It is convenient to think of the various correlation
  
 φ
 αβ
  ≡ ≪y
 α
 y
 β
 ≪φ
 ≪α
  ≡ ≪y
 ≪
 y
 α
 ≪
  
 η
 αβ
  ≡ ≪n
 α
 n
 β
 ≪
  or
 n
 2
 α
  
  δ
 αβ
  
 (
 13.6.4
 )
  
 Setting the derivative of equation (13.6.3) with respect to the
  d
 ≪α
 ’s equal to zero, 
 one readily obtains the set of linear equations,",NA
13.7 Power Spectrum Estimation by the ,NA,NA
Maximum Entropy (All Poles) Method,"The FFT is not the only way to estimate the power spectrum of a process, nor is it 
 necessarily the best way for all purposes. To see how one might devise another method, let 
 us enlarge our view for a moment, so that it includes not only real frequencies in the Nyquist 
 interval
  −f
 c
  < f < f
 c
 , but also the entire complex frequency plane. From that vantage point, let 
 us transform the complex
  f
 -plane to a new plane, called the
  z-transform plane
  or
  z-plane
 , by 
 the relation
  
 z ≡ e
 2
 πif
 ∆
  
 (
 13.7.1
 )
  
 where
  ∆
  is, as usual, the sampling interval in the time domain. Notice that the Nyquist 
 interval on the real axis of the
  f
 -plane maps one-to-one onto the unit circle in the complex
  z
 -
 plane.
  
  
 If we now compare (13.7.1) to equations (13.4.4) and (13.4.6), we see that the FFT 
 power spectrum estimate (13.4.5) for any real sampled function
  c
 k
  ≡ c
 (
 t
 k
 )
  can be written, 
 except for normalization convention, as
  
  
 2 
  
 N/
 2
 −
 1
  
 P
 (
 f
 ) = 
  
 c
 k
 z
 k 
  
 (
 13.7.2
 )
  
 k
 =
 −N/
 2
  
 Of course, (13.7.2) is not the
  true
  power spectrum of the underlying function
  c
 (
 t
 )
 , but only 
 an estimate. We can see in two related ways why the estimate is not likely to be exact. First, 
 in the time domain, the estimate is based on only a finite range of the function
  c
 (
 t
 )
  which 
 may, for all we know, have continued from
  t
  =
  −∞
  to
  ∞
 . Second, in the
  z
 -plane of equation 
 (13.7.2), the finite Laurent series offers, in general, only an approximation to a general",NA
13.8 Spectral Analysis of Unevenly Sampled ,NA,NA
Data,"Thus far, we have been dealing exclusively with evenly sampled data,
  
 h
 n
  =
  h
 (
 n
 ∆) 
  
 n
  =
  . . . , −
 3
 , −
 2
 , −
 1
 ,
  0
 ,
  1
 ,
  2
 ,
  3
 , . . . 
  
 (
 13.8.1
 )
  
 where
  ∆
  is the sampling interval, whose reciprocal is the sampling rate. Recall also (
 §
 12.1) the significance of the Nyquist critical 
 frequency
  
  
 1 
  
 f
 c
  ≡
 2∆
   
  
 (
 13.8.2
 )
  
 as codified by the sampling theorem: A sampled data set like equation (13.8.1) contains 
 complete
  information about all spectral components in a signal
  h
 (
 t
 )
  up to the Nyquist 
 frequency, and scrambled or
  aliased
  information about any signal components at frequencies 
 larger than the Nyquist frequency. The sampling theorem thus defines both the 
 attractiveness, and the limitation, of any analysis of an evenly spaced data set.
  
 There are situations, however, where evenly spaced data cannot be obtained. A common case 
 is where instrumental drop-outs occur, so that data is obtained only on a (not consecutive 
 Another case, integer) subset of equation (13.8.1), the so-called
  missing data
  problem.
  
 common in observational sciences like astronomy, is that the observer cannot completely 
 control the time of the observations, but must simply accept a certain dictated set of
  t
 i
 ’s.
  
 There are some obvious ways to get from unevenly spaced
 t
 i
 ’s to evenly spaced ones, as 
 in equation (13.8.1). Interpolation is one way: lay down a grid of evenly spaced times on 
 your data and interpolate values onto that grid; then use FFT methods. In the missing data 
 problem, you only have to interpolate on missing data points. If a lot of consecutive points 
 are missing, you might as well just set them to zero, or perhaps“clamp” the value at the last 
 measured point. However, the experience of practitioners of such interpolation techniques
  is 
 not reassuring
 . Generally speaking, such techniques perform poorly. Long gaps in the data, 
 for example, often produce a spurious bulge of power at low frequencies (wavelengths 
 comparable to gaps).
  
 A completely different method of spectral analysis for unevenly sampled data, one that 
 mitigates these difficulties and has some other very desirable properties, was developed by 
 Lomb
 [1]
 , based in part on earlier work by Barning
 [2]
 and Van´ıˇcek
 [3]
 , and additionally 
 elaborated by Scargle
 [4]
 . The Lomb method (as we will call it) evaluates data, and sines and 
 cosines, only at times
  t
 i
  that are actually measured. Suppose that there are
  N
  data points
  h
 i
  ≡ 
 h
 (
 t
 i
 )
 , i
  = 1
 , . . . , N
 . Then first find the mean and variance of the data by the usual formulas,
  
  
 N 
     
 N 
  
 h ≡
 1 
 N 
   
 1 
   
  
 h
 i
 σ
 2
 ≡N −
  1 
  
  
 1 
 (
 h
 i
  
 − h
 )
 2 
  
 (
 13.8.3
 ) 
   
   
   
 1
  
  
 Now, the Lomb
  normalized periodogram
  (spectral power as a function of angular 
 frequency
  ω ≡
  2
 πf >
  0
 ) is defined by
  
 P
 N
 (
 ω
 )
  ≡
 2
 σ
 2 
   
 1
  
  
   
  
  
 j
 (
 h
 j
  − h
 ) cos
  ω
 (
 t
 j
  − τ
 ) 
  
  
  
   
 j
 cos
 2
  ω
 (
 t
 j
  − τ
 ) 
  
  
  
  
  
  
 + 
  
 j
 (
 h
 j
  − h
 ) sin
  ω
 (
 t
 j
  − τ
 ) 
  
  
   
  
  
  
  
 j
 sin
 2
  ω
 (
 t
 j
  − τ
 )",NA
13.9 Computing Fourier Integrals Using the FFT,"Not uncommonly, one wants to calculate accurate numerical values for integrals of the 
 form
  
 I
  =
  
  b
  
 e
 iωt
 h
 (
 t
 )
 dt ,
  
 (
 13.9.1
 )
  
 a
  
 or the equivalent real and imaginary parts
  
 I
 c
  =
  
  b
  
 cos(
 ωt
 )
 h
 (
 t
 )
 dt
  
 I
 s
  =
  
  b
  
 sin(
 ωt
 )
 h
 (
 t
 )
 dt ,
  
 (
 13.9.2
 )
  
 a
  
 a
  
 and one wants to evaluate this integral for many different values of
  ω
 . In cases of interest,
  
 h
 (
 t
 ) 
 is often a smooth function, but it is not necessarily periodic in
  [
 a, b
 ]
 , nor does it 
 necessarily go to zero at
  a
  or
  b
 . While it seems intuitively obvious that the
  force majeure
  of 
 the FFT ought to be applicable to this problem, doing so turns out to be a surprisingly subtle 
 matter, as we will now see.
  
  
 Let us first approach the problem naively, to see where the difficulty lies. Divide the 
 interval
  [
 a, b
 ]
  into
  M
  subintervals, where
  M
  is a large integer, and define
  
 ∆
  ≡b − a
  
 ,
  
 t
 j
  ≡ a
  +
  j
 ∆
  ,
  
 h
 j
  ≡ h
 (
 t
 j
 )
  ,
  
 j
  = 0
 , . . . , M
  
 (
 13.9.3
 ) 
  
 We can
  
 (
 13.9.4
 )
  
 Notice that
  h
 0
  =
  h
 (
 a
 )
  and
  h
 M
  =
  h
 (
 b
 )
 , and that there are
  M
  + 1
  values
  h
 j
 . approximate 
 the integral
  I
  by a sum,
  
 I ≈
  ∆
  
 M−
 1
  
 h
 j
  exp(
 iωt
 j
 )
  
 j
 =0
  
 which is at any rate first-order accurate. (If we centered the
  h
 j
 ’s and the
  t
 j
 ’s in the intervals, 
 we could be accurate to second order.) Now for certain values of
  ω
  and
  M
 , the sum in 
 equation (13.9.4) can be made into a discrete Fourier transform, or DFT, and evaluated by 
 the fast Fourier transform (FFT) algorithm. In particular, we can choose
  M
  to be an integer 
 power of 2, and define a set of special
  ω
 ’s by
  
 ω
 m
 ∆
  ≡
 2
 πm 
  
 (
 13.9.5
 )",NA
13.10 Wavelet Transforms,"Like the fast Fourier transform (FFT), the discrete wavelet transform (DWT) is 
 a fast, linear operation that operates on a data vector whose length is an integer 
 power of two, transforming it into a numerically different vector of the same length. 
 Also like the FFT, the wavelet transform is invertible and in fact orthogonal — the 
 inverse transform, when viewed as a big matrix, is simply the transpose of the 
 transform. Both FFT and DWT, therefore, can be viewed as a rotation in function 
 space, from the input space (or time) domain, where the basis functions are the unit 
 vectors
  e
 i
 , or Dirac delta functions in the continuum limit, to a different domain. For 
 the FFT, this new domain has basis functions that are the familiar sines and cosines. 
 In the wavelet domain, the basis functions are somewhat more complicated and 
 have the fanciful names “mother functions” and “wavelets.”
  
  
 Of course there are an infinity of possible bases for function space, almost all 
 of them uninteresting! What makes the wavelet basis interesting is that,
  unlike
  sines 
 and cosines, individual wavelet functions are quite localized in space; 
 simultaneously, 
 like
  sines and cosines, individual wavelet functions are quite 
 localized in frequency or (more precisely) characteristic scale. As we will see 
 below, the particular kind of dual localization achieved by wavelets renders large 
 classes of functions and operators sparse, or sparse to some high accuracy, when 
 transformed into the wavelet domain. Analogously with the Fourier domain, where 
 a class of computations, like convolutions, become computationally fast, there is a 
 large class of computations— those that can take advantage of sparsity — that 
 become computationally fast in the wavelet domain
 [1]
 .
  
  
 Unlike sines and cosines, which define a unique Fourier transform, there is not 
 one single unique set of wavelets; in fact, there are infinitely many possible sets. 
  
 Roughly, the different sets of wavelets make different trade-offs between how 
 compactly they are localized in space and how smooth they are. (There are further 
 fine distinctions.)
  
 Daubechies Wavelet Filter Coefficients
  
 A particular set of wavelets is specified by a particular set of numbers, called 
 wavelet filter coefficients
 . Here, we will largely restrict ourselves to wavelet filters 
 in a class discovered by Daubechies
 [2]
 . This class includes members ranging from 
 highly localized to highly smooth. The simplest (and most localized) member, 
 often called
  DAUB4
 , has only four coefficients,
  c
 0
 , . . ., c
 3
 . For the moment we 
 specialize to this case for ease of notation.",NA
13.11 Numerical Use of the Sampling Theorem,"Rybicki. Now that we have become Fourier sophisticates, we can learn that the formula In
  §
 6.10 we implemented an 
 approximating formula for Dawson’s integral due to
  
 derives from
  numerical
  application of the sampling theorem (
 §
 12.1), normally considered to be a purely analytic tool. Our 
 discussion is identical to Rybicki
 [1]
 .
  
  
 For present purposes, the sampling theorem is most conveniently stated as follows: 
 Consider an arbitrary function
  g
 (
 t
 )
  and the grid of sampling points
  t
 n
  =
  α
  +
  nh
 , where
  n 
 ranges over the integers and
  α
  is a constant that allows an arbitrary shift of the sampling grid. 
  
  
 We then write
  
  
 ∞
  
 g
 (
 t
 ) = 
  
 g
 (
 t
 n
 ) sinc
 πh
 (
 t − t
 n
 ) +
  e
 (
 t
 ) (
 13.11.1
 )
  
 n
 =
 −∞
  
 where
  sinc
  x ≡
  sin
  x/x
 . The summation over the sampling points is called the
  sampling 
 representation
  of
  g
 (
 t
 )
 , and
  e
 (
 t
 )
  is its error term. 
  
 The sampling theorem asserts that the 
 sampling representation is exact, that is,
  e
 (
 t
 )
  ≡
  0
 , if the Fourier transform of
  g
 (
 t
 )
 ,
  
  
  
  ∞
  
  
 G
 (
 ω
 ) = 
   
 g
 (
 t
 )
 e
 iωt
 dt 
  
 (
 13.11.2
 )
  
 −∞
  
 vanishes identically for
  |ω| ≥ π/h
 . When can sampling representations be used to advantage 
 for the approximate numerical computation of functions? In order that the error term be 
 small, the Fourier transform
  G
 (
 ω
 ) 
 must be sufficiently small for
  |ω| ≥ π/h
 . On the other 
 hand, in order for the summation in (13.11.1) to be approximated by a reasonably small 
 number of terms, the function
  g
 (
 t
 ) 
 itself should be very small outside of a fairly limited 
 range of values of
  t
 . Thus we are led to two conditions to be satisfied in order that (13.11.1) 
 be useful numerically: Both the function
  g
 (
 t
 )
  and its Fourier transform
  G
 (
 ω
 )
  must rapidly 
 approach zero for large values of their respective arguments.
  
 Unfortunately, these two conditions are mutually antagonistic — the Uncertainty Princi-
 ple in quantum mechanics. There exist strict limits on how rapidly the simultaneous approach
  
 to zero can be in both arguments. According to a theorem of Hardy
 [2]
 , if
  g
 (
 t
 ) =
  O
 (
 e
 −t
 2
 )
  
 as
  |t| → ∞
  and
  G
 (
 ω
 ) =
  O
 (
 e
 −ω
 2
 /
 4
 )
  as
  |ω| → ∞
 , then
  g
 (
 t
 )
  ≡ Ce
 −t
 2
 , where
  C
  is a constant. This 
 can be interpreted as saying that of all functions the Gaussian is the most rapidly decaying in 
 both
  t
  and
  ω
 , and in this sense is the “best” function to be expressed numerically as a 
 sampling representation.
  
 Let us then write for the Gaussian
  g
 (
 t
 ) =
  e
 −t
 2
 ,
  
 ∞
  
 e
 −t
 2
 = 
  
 e
 −t
 2 
 n
  sinc
 πh
 (
 t − t
 n
 ) +
  e
 (
 t
 ) (
 13.11.3
 )
  
 n
 =
 −∞
  
 The error
  e
 (
 t
 )
  depends on the parameters
  h
  and
  α
  as well as on
  t
 , but it is sufficient for the 
 present purposes to state the bound,
  
 |e
 (
 t
 )
 | < e
 −
 (
 π/
 2
 h
 )
 2 
  
 (
 13.11.4
 )
  
 which can be understood simply as the order of magnitude of the Fourier transform of the 
 Gaussian at the point where it “spills over” into the region
  |ω| > π/h
 . When the summation in 
 (13.11.3) is approximated by one with finite limits, say from 
 N
 0
  − N
  to
  N
 0
  +
  N
 , where
  N
 0
  is 
 the integer nearest to
  −α/h
 , there is a further truncation error. However, if
  N
  is chosen so that
  
 N > π/
 (2
 h
 2
 )
 , the truncation error in the summation is less than the bound given by (13.11.4),",NA
Chapter 14.,NA,NA
Statistical Description ,NA,NA
of Data,NA,NA
14.0 Introduction,"In this chapter and the next, the concept of
  data
  enters the discussion more 
 prominently than before.
  
 Data consist of numbers, of course. But these numbers are fed intothe 
 computer, not produced by it. These are numbers to be treated with considerable 
 respect, neither to be tampered with, nor subjected to a numerical process whose 
 character you do not completely understand. You are well advised to acquire a 
 reverence for data that is rather different from the “sporty” attitude that is 
 sometimes allowable, or even commendable, in other numerical tasks.
  
  
 The analysis of data inevitably involves some trafficking with the field of 
 statistics
 , that gray area which is not quite a branch of mathematics — and just as 
 surely not quite a branch of science. In the following sections, you will repeatedly 
 encounter the following paradigm:
  
  
  
 •
  apply some formula to the data to compute “a statistic”
  
  
  
 •
  compute where the value of that statistic falls in a probability distribution 
 that is computed on the basis of some “null hypothesis”
  
  
   
 conclude that the null hypothesis is
  false
  for your data set
  
 •
  if it falls in a very unlikely spot, way out on a tail of the distribution, 
  
 If a statistic 
 falls in a
  reasonable
  part of the distribution, you must not make the mistake of 
 concluding that the null hypothesis is “verified” or “proved.” That is the curse of 
 statistics, that it can never prove things, only disprove them! At best, you can 
 substantiate a hypothesis by ruling out, statistically, a whole long list of competing 
 hypotheses, every one that has ever been proposed. After a while your adversaries 
 and competitors will give up trying to think of alternative hypotheses, or else they 
 will grow old and die, and
  then your hypothesis will become accepted
 . Sounds 
 crazy, we know, but that’s how science works!
  
 In this book we make a somewhat arbitrary distinction between data analysis 
 procedures that are
  model-independent
  and those that are
  model-dependent
 . In the 
 former category, we include so-called
  descriptive statistics
  that characterize a data 
 set in general terms: its mean, variance, and so on. We also include statistical tests 
 that seek to establish the “sameness” or “differentness” of two or more data sets, or 
 that seek to establish and measure a degree of
  correlation
  between two data sets. 
 These subjects are discussed in this chapter.
  
 603",NA
"14.1 Moments of a Distribution: Mean, ",NA,NA
"Variance, Skewness, and So Forth","When a set of values has a sufficientlystrongcentral tendency, that is, a 
 tendency to cluster around some particular value, then it may be useful to 
 characterize the set by a few numbers that are related to its
  moments
 , the sums of 
 integer powers of the values.
  
 Best known is the
  mean
  of the values
  x
 1
 , . . ., x
 N
 ,
  
 x
  = 1 
  
 N
  
 N
  
 x
 j
  
 (
 14.1.1
 )
  
 j
 =1",NA
14.2 Do Two Distributions Have the Same ,NA,NA
Means or Variances?,"Not uncommonly we want to know whether two distributions have the same 
 mean. For example, a first set of measured values may have been gathered before 
 some event, a second set after it. We want to know whether the event, a 
 “treatment”or a “change in a control parameter,” made a difference.
  
 Our first thought is to ask “how many standard deviations” one sample mean 
 is from the other. That number may in fact be a useful thing to know. It does relate 
 to the strength or “importance” of a difference of means
  if that difference is 
 genuine
 . However, by itself, it says nothing about whether the difference
  is
  
 genuine, that is, statistically significant. A difference of means can be very small 
 compared to the standard deviation, and yet very significant, if the number of data 
 points is large. Conversely, a difference may be moderately large but not 
 significant, if the data",NA
14.3 Are Two Distributions Different?,"Given two sets of data, we can generalize the questions asked in the previous 
 section and ask the single question: Are the twosets drawn from the same 
 distribution function, or from different distribution functions? Equivalently, in 
 proper statistical language, “Can we disprove, to a certain required level of 
 significance, the null hypothesis that two data sets are drawn from the same 
 population distribution function?” Disproving the null hypothesis in effect proves 
 that the data sets are from different distributions. Failing to disprove the null 
 hypothesis, on the other hand, only shows that the data sets can be
  consistent
  with a 
 single distribution function. One can never
  prove
  that two data sets come from a 
 single distribution, since (e.g.) no practical amount of data can distinguish between 
 two distributions which differ only by one part in
  10
 10
 .
  
  
 Proving that two distributions are different, or showing that they are consistent, 
 is a task that comes up all the time in many areas of research: Are the visible stars 
 distributed uniformly in the sky? (That is, is the distribution of stars as a function of 
 declination — position in the sky — the same as the distribution of sky area as a 
 function of declination?) Are educational patterns the same in Brooklyn as in the 
 Bronx? (That is, are the distributions of people as a function of last-grade-attended 
 the same?) 
  
 Do two brands of fluorescent lights have the same distribution of 
 burn-out times? Is the incidence of chicken pox the same for first-born, second-
 born, third-born children, etc.?
  
  
 These four examples illustrate the four combinations arising from two different 
 dichotomies: (1) The data are either continuous or binned. (2) Either we wish to 
 compare one data set to a known distribution, or we wish to compare two equally 
 unknown data sets. The data sets on fluorescent lights and on stars are continuous, 
 since we can be given lists of individual burnout times or of stellar positions. The 
 data sets on chicken pox and educational level are binned, since we are given tables 
 of numbers of events in discrete categories: first-born, second-born, etc.; or 6th 
 Grade, 7th Grade, etc. 
  
  
 Stars and chicken pox, on the other hand, share the property that the null 
 hypothesis is a known distribution (distribution of area in the sky, or incidence of 
 chicken pox in the general population). Fluorescent lights and educational level 
 involve the comparison of two equally unknown data sets (the two brands, or 
 Brooklyn and the Bronx).
  
 One can always turn continuous data into binned data, by grouping the events 
 into specified ranges of the continuous variable(s): declinations between 0 and 10 
 degrees, 10 and 20, 20 and 30, etc. Binning involves a loss of information, 
 however. Also, there is often considerable arbitrariness as to how the bins should 
 be chosen. Along with many other investigators, we prefer to avoid unnecessary 
 binningof data.
  
  
 The accepted test for differences between binned distributions is the
  chi-square 
 test
 . 
   
 For continuous data as a function of a single variable, the most generally 
 accepted test is the
  Kolmogorov-Smirnov test
 . We consider each in turn.
  
 Chi-Square Test
  
 Suppose that
  N
 i
  is the number of events observed in the
  i
 th bin, and that
  n
 i
  is 
 the number expected according to some known distribution. Note that the
  N
 i
 ’s are",NA
14.4 Contingency Table Analysis of Two ,NA,NA
Distributions,"In this section, and the next two sections, we deal with
  measures of association 
 for two distributions. 
  
 The situation is this: Each data point has two or more 
 different quantities associated with it, and we want to know whether knowledge of 
 one quantity gives us any demonstrable advantage in predicting the value of another 
 quantity. In many cases, one variable will be an “independent” or “control” 
 variable, and another will be a “dependent” or “measured” variable. Then, we want 
 to know if the latter variable
  is
  in fact dependent on or
  associated
  with the former 
 variable. If it is, we want to have some quantitative measure of the strength of the 
 association. One often hears this loosely stated as the question of whether two 
 variables are
  correlated 
 or
  uncorrelated
 , but we will reserve those terms for a 
 particular kind of association (linear, or at least monotonic), as discussed in
  §
 14.5 
 and
  §
 14.6. Notice that, as in previous sections, the different concepts of significance 
 and strength appear: The association between two distributions may be very 
 significant even if that association is weak — if the quantity of data is large enough.
  
  
 It is useful to distinguish among some different kinds of variables, with 
 different categories forming a loose hierarchy.
  
 •
  A variable is called
  nominal
  if its values are the members of some 
 unordered set. For example, “state of residence” is a nominal variable 
 that (in the U.S.) takes on one of 50 values; in astrophysics, “type of 
 galaxy” is a nominal variable with the three values “spiral,” 
 “elliptical,”and “irregular.”",NA
14.5 Linear Correlation,"We next turn to measures of association between variables that are ordinal or 
 continuous, rather than nominal. 
  
 Most widely used is the
  linear correlation 
 coefficient
 . For pairs of quantities
  (
 x
 i
 , y
 i
 )
 , i
  = 1
 , . . ., N
 , the linear correlation 
 coefficient
  r
  (also called the product-moment correlation coefficient, or
  Pearson’s r
 ) 
 is given by the formula
  
 r
  = 
  
 i 
 (
 x
 i
  − x
 )(
 y
 i
  − y
 ) 
  
 (
 14.5.1
 )
  
 i 
 (
 x
 i
  − x
 )
 2 
  
 i 
 (
 y
 i
  − y
 )
 2
  
 where, as usual,
  x
  is the mean of the
  x
 i
 ’s,
  y
  is the mean of the
  y
 i
 ’s.
  
 “complete positive correlation,” when the data points lie on a perfect straight line The value of
  r
  lies between
  −
 1
  and
  
 1
 , inclusive. It takes on a value of
  1
 , termed
  
 with positive slope, with
  x
  and
  y
  increasing together. The value
  1
  holds 
 independent of the magnitude of the slope. If the data points lie on a perfect 
 straight line with negative slope,
  y
  decreasing as
  x
  increases, then
  r
  has the value
  
 −
 1
 ; this is called“complete negative correlation.” A value of
  r
  near zero indicates 
 that the variables 
 x
  and
  y
  are
  uncorrelated
 .
  
 When a correlation is known to be significant,
  r
  is one conventional way of 
 summarizing its strength. In fact, the value of
  r
  can be translated into a statement 
 about what residuals (root mean square deviations) are to be expected if the data 
 are fitted to a straight line by the least-squares method (see
  §
 15.2, especially 
 equations 15.2.13 – 15.2.14). Unfortunately,
  r
  is a rather poor statistic for deciding
  
 whether 
 an observed correlation is statistically significant, and/or whether one 
 observed correlation is significantly stronger than another. The reason is that
  r
  is 
 ignorant of the individual distributions of
  x
  and
  y
 , so there is no universal way to 
 compute its distribution in the case of the null hypothesis.
  
 About the only general statement that can be made is this: If the null 
 hypothesis is that
  x
  and
  y
  are uncorrelated, and if the distributions for
  x
  and
  y
  each 
 have enough convergent moments (“tails” die off sufficiently rapidly), and if
  N
  is 
 large",NA
14.6 Nonparametric or Rank Correlation,"It is precisely the uncertainty in interpreting the significance of the linear 
 correlation coefficient
  r
  that leads us to the important concepts of
  nonparametric
  or 
 rank correlation
 . As before, we are given
  N
  pairs of measurements
  (
 x
 i
 , y
 i
 )
 . Before, 
 difficulties arose because we did not necessarily know the probability distribution 
 function from which the
  x
 i
 ’s or
  y
 i
 ’s were drawn.
  
 The key concept of nonparametric correlation is this: If we replace the value 
 of each
  x
 i
  by the value of its
  rank
  among all the other
  x
 i
 ’s in the sample, that is,
  1
 ,
  
 2
 ,
  3
 , . . ., N
 , then the resulting list of numbers will be drawn from a perfectly known 
 distribution function, namely uniformly from the integers between
  1
  and
  N
 , 
 inclusive. Better than uniformly, in fact, since if the
  x
 i
 ’s are all distinct, then each 
 integer will occur precisely once. If some of the
  x
 i
 ’s have identical values, it is 
 conventional to assign to all these “ties” the mean of the ranks that they would have 
 had if their values had been slightly different. This
  midrank
  will sometimes be an",NA
14.7 Do Two-Dimensional Distributions Differ?,"distributions. We here discuss a useful generalization of the K–S test (
 §
 14.3) to
  two-
 dimensional 
 This generalization is due to Fasano and Franceschini
 [1]
 , a variant on an earlier 
 idea due to Peacock
 [2]
 .
  
  
 In a two-dimensional distribution, each data point is characterized by an
  (
 x, y
 )
  pair of 
 values. An example near to our hearts is that each of the 19 neutrinos that were detected from 
 Supernova 1987A is characterized by a time
  t
 i
  and by an energy
  E
 i
  (see
 [3]
 ). 
  
 We 
 might wish to know whether these measured pairs
  (
 t
 i
 , E
 i
 )
 , i
  = 1
  . . .
  19
  are consistent with a 
 theoretical model that predicts neutrino flux as a function of both time and energy — that is, 
 a two-dimensional probability distribution in the
  (
 x, y
 )
  [here,
  (
 t, E
 )
 ] plane. That would be a 
 one-sample test. Or, given two sets of neutrino detections, from two comparable detectors, 
 we might want to know whether they are compatible with each other, a two-sample test.
  
 In the spirit of the tried-and-true, one-dimensional K–S test, we want to range over the
  (
 x, y
 )
  
 plane in search of some kind of maximum
  cumulative
  difference between two Unfortunately, 
 cumulative probability distribution is not two-dimensional distributions.
  
 well-defined in more than one dimension! Peacock’s insight was that a good surrogate is the
  
 integrated probability in each of four natural quadrants
  around a given point
  (
 x
 i
 , y
 i
 )
 , namely 
 the total probabilities (or fraction of data) in
  (
 x > x
 i
 , y > y
 i
 )
 ,
  (
 x < x
 i
 , y > y
 i
 )
 , 
 (
 x < x
 i
 , y < y
 i
 )
 ,
  (
 x > 
 x
 i
 , y < y
 i
 )
 . The two-dimensional K–S statistic
  D
  is now taken to be the maximum difference 
 (ranging both over data points and over quadrants) of the corresponding integrated 
 probabilities. When comparing two data sets, the value of
  D
  may depend on which data set is 
 ranged over. In that case, define an effective
  D
  as the average of the two values obtained. If 
 you are confused at this point about the exact definition of
  D
 , don’t fret; the accompanying 
 computer routines amount to a precise algorithmic definition.
  
 Figure 14.7.1 gives a feeling for what is going on. The 65 triangles and 35 squares 
 seem to have somewhat different distributions in the plane. The dotted lines are centered on 
 the triangle that maximizes the
  D
  statistic; the maximum occurs in the upper-left quadrant. 
 That quadrant contains only 0.12 of all the triangles, but it contains 0.56 of all the squares. 
 The value of
  D
  is thus 0.44. Is this statistically significant?
  
 Even for fixed sample sizes, it is unfortunately not rigorously true that the distribution 
 of
  D
  in the null hypothesis is independent of the shape of the two-dimensional distribution. 
 In this respect the two-dimensional K–S test is not as natural as its one-dimensional parent. 
 However, extensive Monte Carlo integrations have shown that the distribution of the two-
 dimensional
  D
  is
  very nearly
  identical for even quite different distributions, as long as they 
 have the same coefficient of correlation
  r
 , defined in the usual way by equation (14.5.1). In 
 their paper, Fasano and Franceschini tabulate Monte Carlo results for (what amounts to) the 
 distribution of
  D
  as a function of (of course)
  D
 , sample size
  N
 , and coefficient of correlation 
 r
 . Analyzing their results, one finds that the significance levels for the two-dimensional K–S 
 test can be summarized by the simple, though approximate, formulas,
  
 Probability
  (
 D >
  observed
  ) =
  Q
 KS 
  
 1 +
 √
 1
  − r
 2
 (0
 .
 25
  −
  0
 .
 75
 /
    
  
 √N D
  
  
  
  
  
  
 √N
 ) 
  
   
   
  
  
  
 (
 14.7.1
 )
  
 for the one-sample case, and the same for the two-sample case, but with
  
 N
  = 
 N
 1
  +
  N
 2
 . 
  
  
 N
 1
 N
 2 
  
 (
 14.7.2
 )
  
 probability (significance level) is less than (more significant than)
  0
 .
 20
  or so. When the The 
 above formulas are accurate enough when
  N
 >≪
  20
 , and when the indicated indicated 
 probability is
  >
  0
 .
 20
 , its value may not be accurate, but the implication that the data and 
 model (or two data sets) are not significantly different is certainly correct. Notice that in the 
 limit of
  r →
  1
  (perfect correlation), equations (14.7.1) and (14.7.2) reduce to equations 
 (14.3.9) and (14.3.10): The two-dimensional data lie on a perfect straight line, and the two-
 dimensional K–S test becomes a one-dimensional K–S test.",NA
, ,NA
,"
  
 
  
 
  
 
  
  
 1
  
  
 2
  
  
 3
  
 ",NA
,"
  
  
  2
  
  
  1
  
 
  
 
  
 ",NA
,"
  
 3
  
  
 3
  
 
  
 Figure 14.7.1. Two-dimensional distributions of 65 triangles and 35 squares. The two-dimensional K–S 
 test finds that point one of whose quadrants (shown by dotted lines) maximizes the difference between 
 fraction of triangles and fraction of squares. Then, equation (14.7.1) indicates whether the difference is 
 statistically significant, i.e., whetherthe triangles and squaresmusthave differentunderlyingdistributions.
  
  
 The significance level for the data in Figure 14.7.1, by the way, is about 0.001. This 
 establishes to a near-certainty that the triangles and squares were drawn from different 
 distributions. (As in fact they were.) 
  
  
 Of course, if you do not want to rely on the Monte Carlo experiments embodied in 
 equation (14.7.1), you can do your own: Generate a lot of synthetic data sets from your 
 model, each one with the same number of points as the real data set. Compute
  D
  for each 
 synthetic data set, using the accompanying computer routines (but ignoring their calculated 
 probabilities), and count what fraction of the time these synthetic
  D
 ’s exceed the
  D
  from the 
 real data. That fraction is your significance.
  
 One disadvantage of the two-dimensional tests, by comparison with their one-
 dimensional progenitors, is that the two-dimensional tests require of order
  N
 2
 operations: 
 Two nested loops of order
  N
  take the place of an
  N
  log
  N
  sort. For small computers, this 
 restricts the usefulness of the tests to
  N
  less than several thousand.
  
  
 We now give computer implementations. 
  
 The one-sample case is embodied in the 
 routine
  ks2d1s
  (that is, 2-dimensions, 1-sample). This routine calls a straightforward utility 
 routine
  quadct
  to count points in the four quadrants, and it calls a user-supplied routine 
 quadvl
  that must be capable of returning the integrated probability of an analytic model in 
 each of four quadrants around an arbitrary
  (
 x, y
 )
  point. A trivial sample
  quadvl
  is shown; 
 realistic
  quadvl
 s can be quite complicated, often incorporating numerical quadratures over",NA
14.8 Savitzky-Golay Smoothing Filters,"but little guidance was given on
  which particular
  filter to use. That, of course, depends In
  §
 13.5 we learned something about the 
 construction and application of digital filters,
  
 on what you want to accomplish by filtering. 
  
 One obvious use for
  low-pass
  filters is to 
 smooth noisy data.
  
 The premise of data smoothing is that one is measuring a variable that is both slowly 
 varying and also corrupted by random noise. Then it can sometimes be useful to replace 
 each data point by some kind of local average of surrounding data points. Since nearby 
 points measure very nearly the same underlying value, averaging can reduce the level of 
 noise without (much) biasing the value obtained.
  
  
 We must comment editorially that the smoothing of data lies in a murky area, beyond 
 the fringe of some better posed, and therefore more highly recommended, techniques that are 
 discussed elsewhere in this book. 
  
 If you are fitting data to a parametric model, for 
 example (see Chapter 15), it is almost always better to use raw data than to use data that has 
 been pre-processed by a smoothing procedure. Another alternative to blind smoothing is so-
 called “optimal” or Wiener filtering, as discussed in
  §
 13.3 and more generally in
  §
 13.6. Data 
 smoothing is probably most justified when it is used simply as a graphical technique, to guide 
 the eye through a forest of data points all with large error bars; or as a means of making 
 initial
  rough
  estimates of simple parameters from a graph.
  
 In this section we discuss a particular type of low-pass filter, well-adapted for data 
 smoothing, and termed variously
  Savitzky-Golay
 [1]
 ,
  least-squares
 [2]
 , or
  DISPO
  (Digital 
 Smoothing Polynomial)
 [3]
 filters. Rather than having their properties defined in the Fourier 
 domain, and then translated to the time domain, Savitzky-Golay filters derive directly from a 
 particular formulation of the data smoothing problem in the time domain, as we will now 
 see. Savitzky-Golay filters were initially (and are still often) used to render visible the 
 relative widths and heights of spectral lines in noisy spectrometric data.
  
 Recall that a digital filter is applied to a series of equally spaced data values
  f
 i
  ≡ f
 (
 t
 i
 )
 , 
 where
  t
 i
  ≡ t
 0
  +
  i
 ∆
  for some constant sample spacing
  ∆
  and
  i
  =
  . . . −
  2
 , −
 1
 ,
  0
 ,
  1
 ,
  2
 , . . .
  . We 
 have seen (
 §
 13.5) that the simplest type of digital filter (the nonrecursive or finite impulse 
 response filter) replaces each data value
  f
 i
  by a linear combination
  g
 i
  of itself and some 
 number of nearby neighbors,
  
 n
 R
  
 g
 i
  = 
 c
 n
 f
 i
 +
 n 
  
 (
 14.8.1
 )
  
 n
 =
 −n
 L
  
 Here
  n
 L
  is the number of points used “to the left” of a data point
  i
 , i.e., earlier than it, while 
 n
 R
  
 is the number used to the right, i.e., later. A so-called
  causal
  filter would have
  n
 R
  = 0
 .
  
 As a starting point for understanding Savitzky-Golay filters, consider the simplest 
 possible averaging procedure: For some fixed
  n
 L
  =
  n
 R
 , compute each
  g
 i
  as the average of the 
 data points from
  f
 i−n
 L
  to
  f
 i
 +
 n
 R
 . This is sometimes called
  moving window averaging 
 and 
 corresponds to equation (14.8.1) with constant
  c
 n
  = 1
 /
 (
 n
 L
  +
  n
 R
  + 1)
 . If the underlying 
 function is constant, or is changing linearly with time (increasing or decreasing), then no 
 bias is introduced into the result. Higher points at one end of the averaging interval are on",NA
Chapter 15. ,NA,NA
Modeling of Data,NA,NA
15.0 Introduction,"Given a set of observations, one often wants to condense and summarize the 
 data by fitting it to a “model” that depends on adjustable parameters. Sometimes 
 the model is simply a convenient class of functions, such as polynomials or 
 Gaussians, and the fit supplies the appropriate coefficients. Other times, the 
 model’s parameters come from some underlying theory that the data are supposed 
 to satisfy; examples are coefficients of rate equations in a complex network of 
 chemical reactions, or orbital elements of a binary star. Modeling can also be used 
 as a kind of constrained interpolation, where you want to extend a few data points 
 into a continuous function, but with some underlying idea of what that function 
 should look like.
  
 The basic approach in all cases is usually the same: You choose or design a 
 figure-of-merit function
  (“merit function,” for short) that measures the agreement 
 between the data and the model with a particular choice of parameters. The merit 
 function is conventionally arranged so that small values represent close agreement. 
 The parameters of the model are then adjusted to achieve a minimum in the merit 
 function, yielding
  best-fit parameters
 . The adjustment process is thus a problem in 
 minimization in many dimensions. This optimization was the subject of Chapter 
 10; however, there exist special, more efficient, methods that are specific to 
 modeling, and we will discuss these in this chapter.
  
 There are important issues that go beyondthe mere findingof best-fit 
 parameters. Data are generally not exact. They are subject to
  measurement errors
  
 (called
  noise 
 in the context of signal-processing). Thus, typical data never exactly 
 fit the model that is being used, even when that model is correct. We need the 
 means to assess whether or not the model is appropriate, that is, we need to test the
  
 goodness-of-fit 
 against some useful statistical standard.
  
  
 We usually also need to know the accuracy with which parameters are de-
 termined by the data set. 
  
 In other words, we need to know the likely errors of the 
 best-fit parameters.
  
 Finally, it is not uncommon in fitting data to discover that the merit function is 
 not unimodal, with a single minimum. In some cases, we may be interested in 
 global rather than local questions. Not, “how good is this fit?” but rather, “how sure 
 am I that there is not a
  very much better
  fit in some corner of parameter space?”As 
 we have seen in Chapter 10, especially
  §
 10.9, this kind of problem is generally 
 quite difficult to solve.
  
 The important message we want to deliver is that fitting of parameters is not 
 the end-all of parameter estimation. To be genuinely useful, a fitting procedure
  
 650",NA
15.1 Least Squares as a Maximum Likelihood ,NA,NA
Estimator,"Suppose that we are fitting
  N
  data points
  (
 x
 i
 , y
 i
 )
  i
  = 1
 , . . ., N
 , to a model that 
 has
  M
  adjustable parameters
  a
 j
 , j
  = 1
 , . . ., M
 . The model predicts a functional 
 relationship between the measured independent and dependent variables,
  
 y
 (
 x
 ) =
  y
 (
 x
 ;
  a
 1
  . . .a
 M
 ) 
  
 (
 15.1.1
 )
  
 where the dependence on the parameters is indicated explicitlyon the right-
 handside. What, exactly, do we want to minimize to get fitted values for the
  a
 j
 ’s? 
 The first thing that comes to mind is the familiar least-squares fit,
  
 N
  
 minimize over
  a
 1
  . . .a
 M
  :
  
 i
 =1
  
 [
 y
 i
  − y
 (
 x
 i
 ;
  a
 1
  . . .a
 M
 )]
 2
  
 (
 15.1.2
 )
  
 But where does this come from? What general principles is it based on? The answer 
 to these questions takes us into the subject of
  maximum likelihood estimators
 .
  
 Given a particular data set of
  x
 i
 ’s and
  y
 i
 ’s, we have the intuitive feeling that 
 some parameter sets
  a
 1
  . . . a
 M
  are very unlikely — those for which the model 
 function
  y
 (
 x
 )
  looks
  nothing like
  the data — while others may be very likely — 
 those that closely resemble the data. How can we quantify this intuitive feeling? 
 How can we select fitted parameters that are “most likely” to be correct? It is not 
 meaningful to ask the question, “What is the probability that a particular set of 
 fitted parameters 
 a
 1
  . . . a
 M
  is correct?” The reason is that there is no statistical 
 universe of models from which the parameters are drawn. There is just one model, 
 the correct one, and a statistical universe of data sets that are drawn from it!",NA
15.2 Fitting Data to a Straight Line,"A concrete example will make the considerations of the previous section more 
 meaningful. We consider the problem of fitting a set of
  N
  data points
  (
 x
 i
 , y
 i
 )
  to a 
 straight-line model
  
 y
 (
 x
 ) =
  y
 (
 x
 ;
  a, b
 ) =
  a
  +
  bx 
  
 (
 15.2.1
 )",NA
15.3 Straight-Line Data with Errors in Both ,NA,NA
Coordinates,"If experimental data are subject to measurement error not only in the
  y
 i
 ’s, but also in the
  
 x
 i
 ’s, then the task of fitting a straight-line model
  
 y
 (
 x
 ) =
  a
  +
  bx 
  
 (
 15.3.1
 )
  
 is considerably harder. It is straightforward to write down the
  χ
 2
 merit function for this case,
  
  
 N
  
 χ
 2
 (
 a, b
 ) =
  
 i
 =1 
  
 (
 y
 i
  − a − bx
 i
 )
 2
 σ
 2 
 y i
 +
  b
 2
 σ
 2 
 x i 
  
  
  
  
  
 (
 15.3.2
 )
  
 where
  σ
 x i
  and
  σ
 y i
  are, respectively, the
  x
  and
  y
  standard deviations for the
  i
 th point. The 
 weighted sum of variances in the denominator of equation (15.3.2) can be understood both 
 as the variance in the direction of the smallest
  χ
 2
 between each data point and the line with 
 slope
  b
 , and also as the variance of the linear combination
  y
 i
  − a − bx
 i
  of two random 
 variables
  x
 i
  and
  y
 i
 ,
  
 Var
 (
 y
 i
  − a − bx
 i
 ) =
  Var
 (
 y
 i
 ) +
  b
 2
 Var
 (
 x
 i
 ) =
  σ
 2 
 y i
 +
  b
 2
 σ
 2 
 x i
 ≡
  1
 /w
 i 
  
 (
 15.3.3
 )
  
 The sum of the square of
  N
  random variables, each normalized by its variance, is thus
 χ
 2
 -
 distributed.
  
 We want to minimize equation (15.3.2) with respect to
  a
  and
  b
 . Unfortunately, the 
 occurrence of
  b
  in the denominator of equation (15.3.2) makes the resulting equation for the 
 slope
  ∂χ
 2
 /∂b
  = 0
  nonlinear. However, the corresponding condition for the intercept,
 ∂χ
 2
 /∂a
  
 = 0
 , is still linear and yields
  
 a
  =
  
 i 
 w
 i
 (
 y
 i
  − bx
 i
 ) 
 i 
  
  
 w
 i 
  
 (
 15.3.4
 )
  
 where the
  w
 i
 ’s are defined by equation (15.3.3). A reasonable strategy, now, is to use the 
 machinery of Chapter 10 (e.g., the routine
  brent
 ) for minimizing a general one-dimensional",NA
15.4 General Linear Least Squares,"model that is not just a linear combination of
  1
  and
  x
  (namely
  a
  +
  bx
 ), but rather a An immediate generalization of
  
 §
 15.2 is to fit a set of data points
  (
 x
 i
 , y
 i
 )
  to a
  
 linear combination of
  any
  M
  specified functions of
  x
 . For example, the functions 
 could be
  1
 , x, x
 2
 , . . ., x
 M−
 1
 , in which case their general linear combination,
  
 y
 (
 x
 ) =
  a
 1
  +
  a
 2
 x
  +
  a
 3
 x
 2
 +
  · · ·
  +
  a
 M
 x
 M−
 1 
  
 (
 15.4.1
 )
  
 is a polynomial of degree
  M −
  1
 . Or, the functions could be sines and cosines, in 
 which case their general linear combination is a harmonic series. 
  
  
 The general form of this kind of model is
  
 M
  
 y
 (
 x
 ) =
  
 a
 k
 X
 k
 (
 x
 )
  
 (
 15.4.2
 )
  
 k
 =1
  
 where
  X
 1
 (
 x
 )
 , . . ., X
 M
 (
 x
 )
  are arbitrary fixed functions of
  x
 , called the
  basis functions
 .
  
  
 Note that the functions
  X
 k
 (
 x
 )
  can be wildly nonlinear functions of
  x
 . In this 
 discussion “linear” refers only to the model’s dependence on its
  parameters
  a
 k
 . 
  
 For 
 these linear models we generalize the discussion of the previous section by defining 
 a merit function
  
 N 
 2
  
 χ
 2
 = 
 y
 i
  −
 M k
 =1
 a
 k
 X
 k
 (
 x
 i
 ) (
 15.4.3
 )
  
 i
 =1
 σ
 i
  
 As before,
  σ
 i
  is the measurement error (standard deviation) of the
  i
 th data point, 
 presumed to be known. If the measurement errors are not known, they may all (as 
 discussed at the end of
  §
 15.1) be set to the constant value
  σ
  = 1
 . Once again, we 
 will pick as best parameters those that minimize
  χ
 2
 . There are several different 
 techniques available for finding this minimum. Two are particularly useful, and we 
 will discuss both in this section. To introduce them and elucidate their relationship, 
 we need some notation.
  
 basis functions evaluated at the
  N
  abscissas
  x
 i
 , and from the
  N
  measurement errors Let
  A
  be a matrix whose
  N × M
  
 components are constructed from the
  M
  
 σ
 i
 , by the prescription
  
  
 A
 ij
  =
 X
 j
 (
 x
 i
 ) 
  
 (
 15.4.4
 )
  
  
 σ
 i 
  
 The matrix
  A
  is called the
  design matrix
  of the fitting problem. Notice that in 
 general 
 A
  has more rows than columns,
  N ≥M
 , since there must be more data points 
 than model parameters to be solved for. (You can fit a straight line to two points, 
 but not a very meaningful quintic!) The design matrixis shown schematically in 
 Figure 15.4.1.
  
 Also define a vector
  b
  of length
  N
  by
  
  
 b
 i
  =
 y
 i 
  
 (
 15.4.5
 )
  
  
 σ
 i 
  
 and denote the
  M
  vector whose components are the parameters to be fitted, 
 a
 1
 , . . ., 
 a
 M
 , by
  a
 .",NA
15.5 Nonlinear Models,"We now consider fitting when the model depends
  nonlinearly
  on the set of
  M 
 unknown parameters
  a
 k
 , k
  = 1
 ,
  2
 , . . ., M
 . We use the same approach as in previous 
 sections, namely to define a
  χ
 2
 merit function and determine best-fit parameters by 
 its minimization. With nonlinear dependences, however, the minimization must 
 proceed iteratively. Given trial values for the parameters, we develop a procedure 
 that improves the trial solution. The procedure is then repeated until
  χ
 2
 stops (or 
 effectively stops) decreasing.",NA
15.6 Confidence Limits on Estimated Model ,NA,NA
Parameters,"Several times already inthischapter we have made statements about the 
 standard errors, or uncertainties, in a set of
  M
  estimated parameters
  a
 . We have 
 given some formulas for computing standard deviations or variances of individual 
 parameters (equations 15.2.9, 15.4.15, 15.4.19), as well as some formulas for 
 covariances between pairs of parameters (equation 15.2.10; remark following 
 equation 15.4.15; equation 15.4.20; equation 15.5.15).
  
 In this section, we want to be more explicit regarding the precise meaning of 
 these quantitative uncertainties, and to give further information about how 
 quantitative confidence limits on fitted parameters can be estimated. The subject 
 can get somewhat technical, and even somewhat confusing, so we will try to make 
 precise statements, even when they must be offered without proof.
  
 Figure 15.6.1 shows the conceptual scheme of an experiment that “measures”a 
 set of parameters. There is some underlying true set of parameters
  a
 true
  that are 
 known to Mother Nature but hidden from the experimenter. These true parameters 
 are statistically realized, along with random measurement errors, as a measured 
 data He or she fits the data to a model by
  χ
 2
 minimization or some other technique, 
 and set, which we will symbolize as
  D
 (0)
 . The data set
  D
 (0)
  is
  known to the 
 experimenter. obtains measured, i.e., fitted, values for the parameters, which we 
 here denote
  a
 (0)
 .
  
 realization of the true parameters
  a
 true
 . Because measurement errors have a random 
 component,
  D
 (0)
  is not a unique Rather, there are infinitely many other realizations 
 of the true parameters as “hypothetical data sets” each of which
  could 
 have been the 
 one measured, but happened not to be. 
  
 Let us symbolize these by
  D
 (1)
 , D
 (2)
 , . . .
 . 
 different set of fitted parameters,
  a
 (1)
 ,
  a
 (2)
 , . . .
 , respectively. These parameter sets 
  
  
 Each one, had it been realized, would have given a slightly
  
 a
 (
 i
 )
  therefore occur with some probability distribution in the
  M
 -dimensional space 
 of all possible parameter sets
  a
 . The actual measured set
  a
 (0)
  is one member drawn 
 from this distribution.
  
 Even more interesting than the probability distribution of
  a
 (
 i
 )
  would be the 
 distribution of the difference
  a
 (
 i
 )
  −
  a
 true
 . This distribution differs from the former 
 one by a translationthat puts Mother Nature’s true value at the origin. If we knew
  
 this 
 distribution, we would know everything that there is to know about the 
 quantitative uncertainties in our experimental measurement
  a
 (0)
 .
  
  
 So the name of the game is to find some way of estimating or approximating 
 the probability distributionof
  a
 (
 i
 )
  −
  a
 true
  without knowing
  a
 true
  and without having 
 available to us an infinite universe of hypothetical data sets.
  
 Monte Carlo Simulation of Synthetic Data Sets",NA
15.7 Robust Estimation,"The concept of
  robustness
  has been mentioned in passing several times 
 already. In
  §
 14.1 we noted that the median was a more robust estimator of central 
 value than the mean; in
  §
 14.6 it was mentioned that rank correlation is more robust 
 than linear correlation. The concept of outlier points as exceptions to a Gaussian 
 model for experimental error was discussed in
  §
 15.1. The term “robust” was coined 
 in statistics by G.E.P. Box in 1953. Various definitions of greater or lesser 
 mathematical rigor are possible for the term, but in general, referring to a statistical 
 estimator, it means “insensitive to small departures from the idealized assumptions 
 for which the estimator is optimized.”
 [1,2]
  The word“small” can have two different 
 interpretations, both important: either fractionally small departures for all data 
 points, or else fractionally large departures for a small number of data points. It is 
 the latter interpretation, leading to the notion of outlier points, that is generally the 
 most stressful for statistical procedures.
  
  
 Statisticians have developed various sorts of robust statistical estimators. 
 Many, if not most, can be grouped in one of three categories.
  
  
 M-estimates
  follow from maximum-likelihood arguments very much as equa-
 tions (15.1.5) and (15.1.7) followed from equation (15.1.3). M-estimates are usually 
 the most relevant class for model-fitting, that is, estimation of parameters. 
  
 We 
 therefore consider these estimates in some detail below.
  
  
 L-estimates
  are “linear combinations of order statistics.”
  
 These are most 
 applicable to estimations of central value and central tendency, though they can 
  
  
  
 Two 
 occasionally be applied to some problems in estimation of parameters.
  
 “typical” L-estimates will give you the general idea. They are (i) the median, and 
 (ii)
  Tukey’s trimean
 , defined as the weighted average of the first, second, and third 
 quartile points in a distribution, with weights 1/4, 1/2, and 1/4, respectively.
  
 R-estimates
  are estimates based on rank tests. For example, the equality or 
 inequality of two distributions can be estimated by the
  Wilcoxon test
  of computing 
 the mean rank of one distribution in a combined sample of both distributions. The 
 Kolmogorov-Smirnov statistic (equation 14.3.6) and the Spearman rank-order",NA
Chapter 16.,NA,NA
Integration of Ordinary ,NA,NA
Differential Equations,NA,NA
16.0 Introduction,"Problems involving ordinary differential equations (ODEs) can always be 
 reduced to the study of sets of first-order differential equations. For example the 
 second-order equation
  
 d
 2
 y 
  
 dx
 2
  +
  q
 (
 x
 )
 dy dx
 =
  r
 (
 x
 )
  
 (
 16.0.1
 )
  
 can be rewritten as two first-order equations
  
 dy 
  
 dx
 =
  z
 (
 x
 )
  
 dz 
  
 dx
 =
  r
 (
 x
 )
  − q
 (
 x
 )
 z
 (
 x
 )
  
 (
 16.0.2
 )
  
 where
  z
  is a new variable. This exemplifies the procedure for an arbitrary ODE. 
 The usual choice for the new variables is to let them be just derivatives of each 
 other (and of the original variable). Occasionally, it is useful to incorporate into 
 their definition some other factors in the equation, or some powers of the 
 independent variable, for the purpose of mitigating singular behavior that could 
 result in overflows or increased roundoff error. Let common sense be your guide: If 
 you find that the original variables are smooth in a solution, while your auxiliary 
 variables are doing crazy things, then figure out why and choose different auxiliary 
 variables.
  
 The generic problem in ordinary differential equations is thus reduced to the 
 study of a set of
  N
  coupled
  first-order
  differential equations for the functions 
 y
 i
 , i
  = 
 1
 ,
  2
 , . . ., N
 , having the general form
  
 dy
 i
 (
 x
 )
  
 =
  f
 i
 (
 x, y
 1
 , . . ., y
 N
 )
 ,
  
 i
  = 1
 , . . ., N
  
 (
 16.0.3
 )
  
 dx
  
 where the functions
  f
 i
  on the right-hand side are known.
  
 A problem involving ODEs is not completely specified by its equations. Even 
 more crucial in determining how to attack the problem numerically is the nature of 
 the problem’s boundary conditions. Boundary conditions are algebraic conditions
  
 701",NA
16.1 Runge-Kutta Method,"The formula for the Euler method is
  
 y
 n
 +1
  =
  y
 n
  +
  hf
 (
 x
 n
 , y
 n
 ) 
  
 (
 16.1.1
 )
  
 which advances a solutionfrom
 x
 n
  to
  x
 n
 +1
  ≡ x
 n
 +
 h
 . The formula isunsymmetrical: It 
 advances the solution through an interval
  h
 , but uses derivative information only at 
 the beginning of that interval (see Figure 16.1.1). That means (and you can verify 
 by expansion in power series) that the step’s error is only one power of
  h
  smaller 
 than the correction, i.e
  O
 (
 h
 2
 )
  added to (16.1.1).
  
  
 There are several reasons that Euler’s method is not recommended for practical 
 use, among them, (i) the method is not very accurate when compared to other, 
 fancier, methods run at the equivalent stepsize, and (ii) neither is it very stable (see
  
 §
 16.6 below). Consider, however, the use of a step like (16.1.1) to take a “trial” step 
 to the midpoint of the interval. 
  
 Then use the value of both
  x
  and
  y
  at that 
 midpoint to compute the “real” step across the whole interval. Figure 16.1.2 
 illustrates the idea. 
  
  
 In equations,
  
 k
 1
  =
  hf
 (
 x
 n
 , y
 n
 )
  
 k
 2
  =
  hf
  
 x
 n
  +
 1 2
 h, y
 n
  +
  1 2
 k
 1
  
 (
 16.1.2
 )
  
 y
 n
 +1
  =
  y
 n
  +
  k
 2
  +
  O
 (
 h
 3
 )
  
 As indicated in the error term, this symmetrization cancels out the first-order error 
 term, making the method
  second order
 . [A method is conventionally called
  n
 th 
 order if its error term is
  O
 (
 h
 n
 +1
 )
 .] 
  
 In fact, (16.1.2) is called the
  second-order 
 Runge-Kutta
  or
  midpoint
  method.
  
 We needn’t stop there. There are many ways to evaluate the right-hand side 
 f
 (
 x, y
 )
  that all agree to first order, but that have different coefficients of higher-
 order error terms. Adding up the right combination of these, we can eliminate the 
 error terms order by order. That is the basic idea of the Runge-Kutta method. 
 Abramowitz and Stegun
 [1]
 , and Gear
 [2]
 , give various specific formulas that derive 
 from this basic",NA
16.2 Adaptive Stepsize Control for Runge-Kutta,"AgoodODEintegratorshouldexert someadaptivecontrol overitsownprogress, 
 making frequent changes in its stepsize. Usually the purpose of this adaptive 
 stepsize control is to achieve some predetermined accuracy in the solution with 
 minimum computational effort. Many small steps should tiptoe through treacherous 
 terrain, while a few great strides should speed through smooth uninteresting 
 countryside. The resulting gains in efficiency are not mere tens of percents or 
 factors of two; they can sometimes be factors of ten, a hundred, or more. 
 Sometimes accuracy may be demanded not directly in the solution itself, but in 
 some related conserved quantity that can be monitored.
  
 Implementation of adaptive stepsize control requires that the stepping 
 algorithm return information about its performance,most important,an estimate of 
 its truncation error. In this section we will learn how such informationcan be 
 obtained. Obviously, the calculation of this information will add to the 
 computational overhead, but the investment will generally be repaid handsomely.
  
  
 With fourth-order Runge-Kutta, the most straightforward technique by far is 
 step doubling
  (see, e.g.,
 [1]
 ). We take each step twice, once as a full step, then, 
 independently, as two half steps (see Figure 16.2.1). How much overhead is this, 
 say in terms of the number of evaluations of the right-hand sides? 
  
 Each of the 
 three separate Runge-Kutta steps in the procedure requires 4 evaluations, but the 
 single and double sequences share a starting point, so the total is 11. This is to be 
 compared not to 4, but to 8 (the two half-steps), since — stepsize control aside —
 we are achieving the accuracy of the smaller (half) stepsize. The overhead cost is 
 therefore a factor 1.375. What does it buy us?",NA
16.3 Modified Midpoint Method,"This section discusses the
  modified midpoint method
 , which advances a vector 
 of dependent variables
  y
 (
 x
 )
  from a point
  x
  to a point
  x
  +
  H
  by a sequence of
  n 
 substeps each of size
  h
 ,
  
 h
  =
  H/n 
  
 (
 16.3.1
 )
  
 In principle, one could use the modified midpoint method in its own right as an 
 ODE integrator. In practice, the method finds its most important application as a 
 part of the more powerful Bulirsch-Stoer technique, treated in
  §
 16.4. You can 
 therefore consider this section as a preamble to
  §
 16.4. The number of right-hand 
 side evaluations required by the modified midpoint method is
  n
  + 1
 . The formulas 
 for the method are
  
 z
 0
  ≡ y
 (
 x
 )
  
 z
 1
  =
  z
 0
  +
  hf
 (
 x, z
 0
 )
  
 z
 m
 +1
  =
  z
 m−
 1
  + 2
 hf
 (
 x
  +
  mh, z
 m
 )
  
 for
  
 m
  = 1
 ,
  2
 , . . ., n −
  1
  
 y
 (
 x
  +
  H
 )
  ≈ y
 n
  ≡
 1 2[
 z
 n
  +
  z
 n−
 1
  +
  hf
 (
 x
  +
  H, z
 n
 )]
  
 (
 16.3.2
 )
  
 Here the
  z
 ’s are intermediate approximations which march along in steps of
  h
 , while 
 y
 n
  is the final approximation to
  y
 (
 x
  +
  H
 )
 . The method is basically a “centered 
 difference” or “midpoint” method (compare equation 16.1.2), except at the first and 
 last points. Those give the qualifier “modified.”
  
  
 The modified midpoint method is a second-order method, like (16.1.2), but 
 with the advantage of requiring(asymptoticallyfor large
  n
 ) only one derivative 
 evaluation per step
  h
  instead of the two required by second-order Runge-Kutta. 
 Perhaps there are applications where the simplicity of (16.3.2), easily coded in-line 
 in some other program, recommends it. In general, however, use of the modified 
 midpoint method by itself will be dominated by the embedded Runge-Kutta method 
 with adaptive stepsize control, as implemented in the preceding section.
  
 The usefulness of the modified midpoint method to the Bulirsch-
 Stoertechnique (
 §
 16.4) derives from a “deep” result about equations (16.3.2), due to 
 Gragg. It turns",NA
16.4 Richardson Extrapolation and the ,NA,NA
Bulirsch-Stoer Method,"The techniques described in this section are not for differential equations 
 containing nonsmooth functions. 
  
 For example, you might have a differential 
 equation whose right-hand side involves a function that is evaluated by table look-
 up and interpolation. If so, go back to Runge-Kutta with adaptive stepsize choice: 
 That method does an excellent job of feeling its way through rocky or discontinuous 
 terrain. 
  
 It is also an excellent choice for quick-and-dirty, low-accuracy solution of 
 a set of equations. A second warning is that the techniques in this section are not 
 particularly good for differential equations that have singular points
  inside
  the 
 interval of integration. A regular solution must tiptoe very carefully across such 
 points. Runge-Kutta withadaptive stepsize can sometimes effect this;more 
 generally, there are special techniques available for such problems, beyond our 
 scope here.
  
  
 Apart from those two caveats, we believe that the Bulirsch-Stoer method, 
 discussed in this section, is the best known way to obtain high-accuracy solutions to 
 ordinary differential equations with minimal computational effort. (A possible 
 exception, infrequently encountered in practice, is discussed in
  §
 16.7.) Three key 
 ideas are involved. 
  
 The first is
  Richardson’s deferred approach 
 to the limit
 , which we already met in
  §
 4.3 on Romberg integration. The idea is to 
 consider the final answer of a numerical calculation as itself being an analytic 
 function (if a complicated one) of an adjustable parameter like the stepsize
  h
 . That 
 analytic function can be probed by performing the calculation with various values of
  
 h
 ,
  none
  of them being necessarily small enough to yield the accuracy that we desire. 
 When we know enough about the function, we
  fit
  it to some analytic form, and then
  
 evaluate
  it at that mythical and golden point
  h
  = 0
  (see Figure 16.4.1). Richardson 
 extrapolation is a method for turning straw into gold! (Lead into gold for alchemist 
 readers.) 
  
  
 The second idea has to do withwhat kind of fittingfunctionis used. Bulirschand 
 Stoer first recognized the strength of
  rational function extrapolation
  in Richardson-
 type applications. That strength is to break the shackles of the power series and its 
 limited radius of convergence, out only to the distance of the first pole in the 
 complex",NA
16.5 Second-Order Conservative Equations,"Usually when you have a system of high-order differential equations to solve it is best 
 to reformulate them as a system of first-order equations, as discussed in
  §
 16.0. There is a 
 particular class of equations that occurs quite frequently in practice where you can gain 
 about a factor of two in efficiency by differencing the equations directly. The equations are 
 second-order systems where the derivative does not appear on the right-hand side:
  
 y
 ′′
 =
  f
 (
 x,y
 )
 , y
 (
 x
 0
 ) =
  y
 0
 , 
  
 y
 ′
 (
 x
 0
 ) =
  z
 0 
  
 (
 16.5.1
 )
  
 As usual,
  y
  can denote a vector of values.
  
  
 Stoermer’s rule
 , dating back to 1907, has been a popular method for discretizing such 
 systems. 
  
 With
  h
  =
  H/m
  we have
  
 y
 1
  =
  y
 0
  +
  h
 [
 z
 0
  +
 1 2
 hf
 (
 x
 0
 , y
 0
 )]
  
 y
 k
 +1
  −
  2
 y
 k
  +
  y
 k−
 1
  =
  h
 2
 f
 (
 x
 0
  +
  kh, y
 k
 )
 ,
  
 k
  = 1
 , . . . , m −
  1
  
 (
 16.5.2
 )
  
 z
 m
  = (
 y
 m
  − y
 m−
 1
 )
 /h
  +
 1 2
 hf
 (
 x
 0
  +
  H, y
 m
 )
  
 Here
  z
 m
  is
  y
 ′
 (
 x
 0
  +
  H
 )
 . Henrici showed how to rewrite equations (16.5.2) to reduce roundoff 
 error by using the quantities
  ∆
 k
  ≡ y
 k
 +1
  − y
 k
 . Start with
  
  
 ∆
 0
  =
  h
 [
 z
 0
  +
 1 2
 hf
 (
 x
 0
 , y
 0
 )] 
  
  
   
  
 (
 16.5.3
 ) 
  
 y
 1
  =
  y
 0
  + ∆
 0
  
 Then for
  k
  = 1
 , . . . , m −
  1
 , set
  
  
 ∆
 k
  = ∆
 k−
 1
  +
  h
 2
 f
 (
 x
 0
  +
  kh, y
 k
 )
  
 y
 k
 +1
  =
  y
 k
  + ∆
 k
  
 (
 16.5.4
 )
  
 Finally compute the derivative from
  
 z
 m
  = ∆
 m−
 1
 /h
  +
 1 2
 hf
 (
 x
 0
  +
  H, y
 m
 ) 
  
 (
 16.5.5
 )
  
 Gragg again showed that the error series for equations (16.5.3)–(16.5.5) contains only 
 even powers of
  h
 , and so the method is a logical candidatefor extrapolation `a la Bulirsch-
 Stoer.
  
 We replace
  mmid
  by the following routine
  stoerm
 :
  
 SUBROUTINE stoerm(y,d2y,nv,xs,htot,nstep,yout,derivs) 
  
 INTEGER nstep,nv,NMAX 
  
 REAL htot,xs,d2y(nv),y(nv),yout(nv) 
  
 EXTERNAL derivs
  
 C
  
 PARAMETER (NMAX=50)
  
 Maximum value of nv.
  
 USES derivs 
  
 Stoermer’s rule for integrating
  y
 ′′
 =
  f
 (
 x, y
 ) for a system of
  n
  =
  nv
 /
 2 equations. On input 
 y(1:nv)
  
 contains
  y
  in its first
  n
  elements and
  y
 ′
 in its second
  n
  elements, all evaluated at
  xs
 .
  d2y(1:nv)
  
 contains the right-hand side function
  f
  (also evaluated at
  xs
 ) in its
  
 first
  n
  elements. Its second
  n
  elements are not referenced. Also input is
  htot
 , the total
  
 step to be taken, and
  nstep
 , the number of substeps to be used. The output is returned as
  
 yout(1:nv)
 , with the same storage arrangement as
  y
 .
  derivs
  is the user-supplied subroutine 
 that calculates
  f
 .
  
 INTEGER i,n,neqns,nn 
  
 REAL h,h2,halfh,x,ytemp(NMAX) 
  
 h=htot/nstep 
  
 Stepsize this trip.
  
 halfh=0.5*h 
  
 neqns=nv/2 
  
 Number of equations.
  
 do
  11
  i=1,neqns 
  
 First step.
  
 n=neqns+i 
  
 ytemp(n)=h*(y(n)+halfh*d2y(i))",NA
16.6 Stiff Sets of Equations,"As soon as one deals with more than one first-order differential equation, the 
 possibility of a
  stiff
  set of equations arises. Stiffness occurs in a problem where 
 there are two or more very different scales of the independent variable on which the 
 dependent variables are changing. 
  
 For example, consider the following set of 
 equations
 [1]
 :
  
 u
 ′
 = 998
 u
  + 1998
 v 
  
  
 (
 16.6.1
 ) 
  
 v
 ′
 =
  −
 999
 u −
  1999
 v
  
 with boundary conditions
  
 u
 (0) = 1
  
 v
 (0) = 0
  
 (
 16.6.2
 )",NA
"16.7 Multistep, Multivalue, and ",NA,NA
Predictor-Corrector Methods,"The terms multistepand multivaluedescribe twodifferent ways ofimplementing 
 essentially the same integration technique for ODEs. Predictor-corrector is a partic-
 ular subcategrory of these methods — in fact, the most widely used. Accordingly, 
 the name predictor-corrector is often loosely used to denote all these methods.
  
  
 We suspect that predictor-corrector integrators have had their day, and that 
 they are no longer the method of choice for most problems in ODEs. For high-
 precision applications, or applications where evaluations of the right-hand sides are 
 expensive, Bulirsch-Stoer dominates. For convenience, or for low precision, 
 adaptive-stepsize Runge-Kutta dominates. Predictor-corrector methods have been, 
 we think, squeezed out in the middle. 
  
 There is possibly only one exceptional 
 case: high-precision solution of very smooth equations with very complicated right-
 hand sides, as we will describe later.
  
  
 Nevertheless, these methods have had a long historical run. 
  
 Textbooks are 
 full of information on them, and there are a lot of standard ODE programs around 
 that are based on predictor-corrector methods. Many capable researchers have a lot 
 of experience with predictor-corrector routines, and they see no reason to make a 
 precipitous change of habit. It is not a bad idea for you to be familiar with the 
 principles involved, and even with the sorts of bookkeeping details that are the bane 
 of these methods. Otherwise there will be a big surprise in store when you first have 
 to fix a problem in a predictor-corrector routine.
  
 Let us first consider the multistep approach. Think about how integrating an 
 ODE is different from finding the integral of a function: For a function, the 
 integrand has a known dependence on the independent variable
  x
 , and can be 
 evaluated at will. For an ODE, the “integrand” is the right-hand side, which 
 depends both on 
 x
  and on the dependent variables
  y
 . Thus to advance the solution 
 of
  y
 ′
 =
  f
 (
 x, y
 ) 
 from
  x
 n
  to
  x
 , we have
  
  x
  
 y
 (
 x
 ) =
  y
 n
  + 
  
 f
 (
 x
 ′
 , y
 )
  dx
 ′
  
 (
 16.7.1
 )
  
 x
 n
  
 In a single-step method like Runge-Kutta or Bulirsch-Stoer, the value
  y
 n
 +1
  at
  x
 n
 +1 
 depends only on
  y
 n
 . In a multistep method, we approximate
  f
 (
 x, y
 )
  by a polynomial 
 passing through
  several
  previous points
  x
 n
 , x
 n−
 1
 , . . .
  and possibly also through 
 x
 n
 +1
 . 
 The result of evaluating the integral (16.7.1) at
  x
  =
  x
 n
 +1
  is then of the form
  
 y
 n
 +1
  =
  y
 n
  +
  h
 (
 β
 0
 y
 ′n
 +1
 +
  β
 1
 y
 ′n
 +
  β
 2
 y
 ′n−
 1
 +
  β
 3
 y
 ′n−
 2
 +
  · · ·
 ) 
  
 (
 16.7.2
 )
  
 where
  y
 ′n
 denotes
  f
 (
 x
 n
 , y
 n
 )
 , and so on. If
  β
 0
 = 0
 , the method is explicit; otherwise it is 
 implicit. The order of the method depends on how many previous steps we use to 
 get each new value of
  y
 .
  
 Consider how we might solve an implicit formula of the form (16.7.2) for
  
 y
 n
 +1
 . Two methods suggest themselves:
  functional iteration
  and
  Newton’s method
 . 
 In functional iteration, we take some initial guess for
  y
 n
 +1
 , insert it into the right-
 hand side of (16.7.2) to get an updated value of
  y
 n
 +1
 , insert this updated value back 
 into the right-hand side, and continue iterating. But how are we to get an initial 
 guess for",NA
Chapter 17.,NA,NA
Two Point Boundary ,NA,NA
Value Problems,NA,NA
17.0 Introduction,"When ordinarydifferential equations are required to satisfy boundary 
 conditions at more than one value of the independent variable, the resulting 
 problem is called a 
 two point boundary value problem
 . As the terminology 
 indicates, the most common case by far is where boundary conditions are supposed 
 to be satisfied at two points —usually the starting and ending values of the 
 integration. However, the phrase “two point boundary value problem” is also used 
 loosely to include more complicated cases, e.g., where some conditions are 
 specified at endpoints, others at interior (usually singular) points.
  
 The crucial distinction between initial value problems (Chapter 16) and two 
 point boundary value problems (this chapter) is that in the former case we are able 
 to start an acceptable solution at its beginning (initial values) and just march it 
 along by numerical integration to its end (final values); while in the present case, 
 the boundary conditions at the starting point do not determine a unique solution to 
 start with — and a “random” choice among the solutions that satisfy these 
 (incomplete) starting boundary conditions is almost certain
  not
  to satisfy the 
 boundary conditions at the other specified point(s).
  
 It should not surprise you that iteration is in general required to meld these 
 spatially scattered boundary conditionsinto a single global solutionof the 
 differential equations. For this reason, two point boundary value problems require 
 considerably more effort to solve than do initial value problems. You have to 
 integrate your dif-ferential equations over the interval of interest, or perform an 
 analogous “relaxation”procedure (see below), at least several, and sometimes very 
 many, times. Only in the special case of linear differential equations can you say in 
 advance just how many such iterations will be required.
  
 The “standard” two point boundary value problem has the following form: We 
 desire the solution to a set of
  N
  coupled first-order ordinary differential equations, 
 satisfying
  n
 1
  boundary conditions at the starting point
  x
 1
 , and a remaining set of 
 n
 2
  
 =
  N − n
 1
  boundary conditions at the final point
  x
 2
 . (Recall that all differential 
 equations of order higher than first can be written as coupled sets of first-order 
 equations, cf.
  §
 16.0.) The differential equations are
  
 dy
 i
 (
 x
 ) 
  
 =
  g
 i
 (
 x, y
 1
 , y
 2
 , . . ., y
 N
 ) 
  
 i
  = 1
 ,
  2
 , . . ., N 
  
 (
 17.0.1
 ) 
  
 dx
  
 745",NA
17.1 The Shooting Method,"In this section we discuss “pure” shooting, where the integration proceeds 
 from 
 x
 1
  to
  x
 2
 , and we try to match boundary conditions at the end of the 
 integration. In the next section, we describe shooting to an intermediate fitting 
 point, where the solution to the equations and boundary conditions is found by 
 launching “shots”from both sides of the interval and trying to match continuity 
 conditions at some intermediate point.
  
  
 Our implementation of the shooting method exactly implements multidimen-of
  
 n
 2
  variables. The functions are obtained by integrating
  N
  differential equations 
 sional, globally convergent Newton-Raphson (
 §
 9.7). It seeks to zero
  n
 2
  functions 
 from
  x
 1
  to
  x
 2
 . Let us see how this works: 
  
  
 At the starting point
  x
 1
  there are
  N
  starting values
  y
 i
  to be specified, but subject 
 to
  n
 1
  conditions. Therefore there are
  n
 2
  =
  N − n
 1
  freely specifiable
  starting values. 
 Let us imagine that these freely specifiable values are the components of a vector
  V
  
 that lives in a vector space of dimension
  n
 2
 . Then you, the user, knowing the 
 functional form of the boundary conditions (17.0.2), can write a subroutine that 
 generates a complete set of
  N
  starting values
  y
 , satisfying the boundary conditions at
  
 x
 1
 , from an arbitrary vector value of
  V
  in which there are no restrictions on the
  n
 2 
 component values. In other words, (17.0.2) converts to a prescription
  
 y
 i
 (
 x
 1
 ) =
  y
 i
 (
 x
 1
 ;
  V
 1
 , . . ., V
 n
 2
 ) 
  
 i
  = 1
 , . . ., N 
  
 (
 17.1.1
 )
  
 Below, the subroutine that implements (17.1.1) will be called
  load
 .
  
 Notice that the components of
  V
  might be exactly the values of certain 
 “free”components of
  y
 , with the other components of
  y
  determined by the 
 boundary conditions. Alternatively, the components of
  V
  might parametrize the 
 solutions that satisfy the starting boundary conditions in some other convenient 
 way. Boundary conditions often impose algebraic relations among the
  y
 i
 , rather 
 than specific values for each of them. Using some auxiliary set of parameters often 
 makes it easier to“solve” the boundary relations for a consistent set of
  y
 i
 ’s. It makes 
 no difference which way you go, as long as your vector space of
  V
 ’s generates 
 (through 17.1.1) all allowed starting vectors
  y
 .
  
 Given a particular
  V
 , a particular
  y
 (
 x
 1
 )
  is thus generated. It can then be turned 
 into a
  y
 (
 x
 2
 )
  by integrating the ODEs to
  x
 2
  as an initial value problem (e.g., using 
 Chapter 16’s
  odeint
 ). Now, at
  x
 2
 , let us define a
  discrepancy vector
  F
 , also of 
 dimension
  n
 2
 , whose components measure how far we are from satisfying the
  n
 2 
 boundary conditions at
  x
 2
  (17.0.3). Simplest of all is just to use the right-hand sides 
 of (17.0.3),
  
 F
 k
  =
  B
 2
 k
 (
 x
 2
 ,
  y
 )
  
 k
  = 1
 , . . ., n
 2
  
 (
 17.1.2
 )
  
 As in the case of
  V
 , however, you can use any other convenient parametrization, as 
 long as your space of
  F
 ’s spans the space of possible discrepancies from the 
 desired boundary conditions, with all components of
  F
  equal to zero if and only if 
 the boundary conditions at
  x
 2
  are satisfied. Below, you will be asked to supply a 
 user-written subroutine
  score
  which uses (17.0.3) to convert an
  N
 -vector of ending 
 values
  y
 (
 x
 2
 )
  into an
  n
 2
 -vector of discrepancies
  F
 .",NA
17.2 Shooting to a Fitting Point,"be able to traverse the entire domain of integration, even at the early stages of The shooting method described in
  
 §
 17.1 tacitly assumed that the “shots” would
  
 convergence to a correct solution. In some problems it can happen that, for very 
 wrong starting conditions, an initial solution can’t even get from
  x
 1
  to
  x
 2
  without 
 encountering some incalculable, or catastrophic, result. For example, the argument 
 of a square root might go negative, causing the numerical code to crash. Simple 
 shooting would be stymied.
  
 A different, but related, case is where the endpoints are both singular points of 
 the set of ODEs. One frequently needs to use special methods to integrate near the 
 singular points, analytic asymptotic expansions, for example. In such cases it is 
 feasible to integrate in the direction
  away
  from a singular point, using the special 
 method to get through the first little bit and then reading off “initial” values for 
 further numerical integration. However it is usually not feasible to integrate
  into 
 a 
 singular point, if only because one has not usually expended the same analytic",NA
17.3 Relaxation Methods,"In
  relaxation methods
  we replace ODEs by approximate
  finite-difference equations 
 (FDEs) on a grid or mesh of points that spans the domain of interest. As a typical example, 
 we could replace a general first-order differential equation
  
 dy
  
 dx
 =
  g
 (
 x, y
 )
  
 with an algebraic equation relating function values at two points
  k, k −
  1
 :
  
 y
 k
  − y
 k−
 1
  −
  (
 x
 k
  − x
 k−
 1
 )
  g
  
  
  1
  
 2
 (
 x
 k
  +
  x
 k−
 1
 )
 ,
  1 2
 (
 y
 k
  +
  y
 k−
 1
 ) = 0
  
 (
 17.3.1
 )
  
 (
 17.3.2
 )",NA
17.4 A Worked Example: Spheroidal Harmonics,"The best way to understand the algorithms of the previous sections is to see 
 them employed to solve an actual problem. As a sample problem, we have selected 
 the computation of spheroidal harmonics. (The more common name is spheroidal 
 angle functions, but we prefer the explicit reminder of the kinship with spherical 
 harmonics.) We will show how to find spheroidal harmonics, first by the method of 
 relaxation (
 §
 17.3), and then by the methods of shooting (
 §
 17.1) and shooting to a 
 fitting point (
 §
 17.2). Spheroidal 
  
 harmonics 
  
 typically 
  
 arise 
  
 when 
  
 certain 
  
 partial 
  
 differential 
  
  
  
  
  
  
  
  
  
 They equations are solved by separation of variables 
 in spheroidal coordinates.
  
 satisfy the following differential equation on the interval
  −
 1
  ≤ x ≤
  1
 : 
 d 
  
 m
 2
  
 dx 
 (1
  − x
 2
 )
 dS 
 +
  
 λ − c
 2
 x
 2
 −
 1
  − x
 2 
   
  
  
  
 S
  = 0 
  
 (
 17.4.1
 )
  
 Here
  m
  is an integer,
  c
  is the “oblateness parameter,” and
  λ
  is the eigenvalue. 
 Despite the notation,
  c
 2
 can be positive or negative. For
  c
 2
 >
  0
  the functions are 
 called“prolate,” while if
  c
 2
 <
  0
  they are called “oblate.” The equation has singular 
 points at
  x
  =
  ±
 1
  and is to be solved subject to the boundary conditions that the 
 solution be regular at
  x
  =
  ±
 1
 . Only for certain values of
  λ
 , the eigenvalues, will this 
 be possible. If we consider first the spherical case, where
  c
  = 0
 , we recognize the 
 differential equation for Legendre functions
  P
 m n
 (
 x
 )
 . In this case the eigenvalues are
  
 λ
 mn
 = 
 n
 (
 n
  + 1)
 ,
  n
  =
  m, m
  + 1
 , . . .
 . 
  
 The integer
  n
  labels successive eigenvalues for 
 fixed
  m
 : When
  n
  =
  m
  we have the lowest eigenvalue, and the corresponding 
 eigenfunction has no nodes in the interval
  −
 1
  < x <
  1
 ; when
  n
  =
  m
  + 1
  we have the 
 next eigenvalue, and the eigenfunction has one node inside
  (
 −
 1
 ,
  1)
 ; and so on. A 
 similar situation holds for the general case
  c
 2
 ̸
 = 0
 . We write the eigenvalues of 
 (17.4.1) as
  λ
 mn
 (
 c
 )
  and the eigenfunctions as
  S
 mn
 (
 x
 ;
  c
 )
 . 
  
 For fixed
  m
 ,
  n
  = 
 m, 
 m
  + 1
 , . . .
  labels the successive eigenvalues.
  
  
 The computation of
  λ
 mn
 (
 c
 )
  and
  S
 mn
 (
 x
 ;
  c
 )
  traditionallyhas been quite difficult. 
 Complicated recurrence relations, power series expansions, etc., can be found in 
 references
 [1-3]
 . 
  
 Cheap computing makes evaluation by direct solution of the 
 differential equation quite feasible.
  
  
 The first step is to investigate the behavior of the solution near the singular 
 points
  x
  =
  ±
 1
 . Substituting a power series expansion of the form
  
  
  
  
 ∞
  
  
  
 S
  = (1
  ± x
 )
 α
  
  
 a
 k
 (1
  ± x
 )
 k 
  
 (
 17.4.2
 )
  
 k
 =0
  
 in equation (17.4.1), we find that the regular solution has
  α
  =
  m/
 2
 . (Without loss of 
 generality we can take
  m ≥
  0
  since
  m → −m
  is a symmetry of the equation.) We get 
 an equation that is numerically more tractable if we factor out this behavior.
  
 Accordingly we set
  
 S
  = (1
  − x
 2
 )
 m/
 2
 y 
 (
 17.4.3
 )
  
 We then find from (17.4.1) that
  y
  satisfies the equation",NA
17.5 Automated Allocation of Mesh Points,"In relaxation problems, you have to choose values for the independent variable at the 
 mesh points. This is called
  allocating
  the grid or mesh. The usual procedure is to pick a 
 plausible set of values and, if it works, to be content. If it doesn’t work, increasing the 
 number of points usually cures the problem.
  
 If we know ahead of time where our solutions will be rapidly varying, we can put more 
 grid points there and less elsewhere. Alternatively, we can solve the problem first on a 
 uniform mesh and then examine the solution to see where we should add more points. We 
 then repeat the solution with the improved grid. The object of the exercise is to allocate 
 points in such a way as to represent the solution accurately.
  
 It is also possible to automate the allocation of mesh points, so that it is 
 done“dynamically” during the relaxation process. This powerful technique not only 
 improves the accuracy of the relaxation method, but also (as we will see in the next section) 
 allows internal singularities to be handled in quite a neat way. Here we learn how to 
 accomplish the automatic allocation.
  
 We want to focus attention on the independent variable
  x
 , and consider two alternative 
 reparametrizations of it. The first, we term
  q
 ; this is just the coordinate corresponding to the 
 mesh points themselves, so that
  q
  = 1
  at
  k = 1
 ,
  q
  = 2
  at
  k = 2
 , and so on. Between any two 
 mesh points we have
  ∆
 q
  = 1
 . In the change of independent variable in the ODEs from
  x
  to
  q
 ,
  
 becomes
  
 d
 y 
  
 dx
 =
  g
  
 (
 17.5.1
 )
  
 d
 y 
  
 dq
 =
  g
 dx
  
 (
 17.5.2
 )
  
 In terms of
  q
 , equation (17.5.2) as an FDE might be written
  
 y
 k
  −
  y
 k−
 1
  −
 1 
  
 g
 dx 
   
 dq 
    
 k 
  
  
  
  
 + 
 g
 dx 
  
  
  
  
   
 dq 
  
   
  
  
  
  
 k−
 1 
  
  
  
  
   
   
 = 0 
  
 (
 17.5.3
 )
  
 or some related version. Note that
  dx/dq
  should accompany
  g
 . The transformation between 
 x
  
 and
  q
  depends only on the
  Jacobian
  dx/dq
 . Its reciprocal
  dq/dx
  is proportional to the 
 density of mesh points.
  
 Now, given the function
  y
 (
 x
 )
 , or its approximation at the current stage of relaxation, 
 we are supposed to have some idea of how we want to specify the density of mesh points. 
 For example, we might want
  dq/dx
  to be larger where
  y
  is changing rapidly, or near to the 
 boundaries, or both. In fact, we can probably make up a formula for what we would like 
 dq/dx
  to be proportional to. The problem is that we do not know the proportionality 
 constant. That is, the formula that we might invent would not have the correct integral over 
 the whole range of
  x
  so as to make
  q
  vary from
  1
  to
  M
 , according to its definition. To solve 
 this problem we introduce a second reparametrization
  Q
 (
 q
 )
 , where
  Q
  is a new independent 
 variable. The relation between
  Q
  and
  q
  is taken to be
  linear
 , so that a mesh spacing formula 
 for
  dQ/dx 
 differs only in its unknown proportionality constant. A linear relation implies
  
 d
 2
 Q 
  
 dq
 2
  = 0 
  
 (
 17.5.4
 )
  
 or, expressed in the usual manner as coupled first-order equations,
  
 dQ
 (
 x
 )
  
 =
  ψ
  
 dψ
  
 dq
 = 0
  
 (
 17.5.5
 )
  
 dq
  
 where
  ψ
  is a new intermediate variable. We add these two equations to the set of ODEs being 
 solved.
  
  
 Completing the prescription, we add a third ODE that is just our desired mesh-density 
 function, namely
  
 φ
 (
 x
 ) =
 dQ dx
 =
  dQ
  
 dq
  
 (
 17.5.6
 )",NA
17.6 Handling Internal Boundary Conditions ,NA,NA
or Singular Points,"Singularities can occur in the interiors of two point boundary value problems. Typically, 
 there is a point
  x
 s
  at which a derivative must be evaluated by an expression of the form
  
 S
 (
 x
 s
 ) =
 N
 (
 x
 s
 ,
  y
 ) 
  
 (
 17.6.1
 ) 
  
  
 D
 (
 x
 s
 ,
  y
 )
  
 where the denominator
  D
 (
 x
 s
 ,
  y
 ) = 0
 . In physical problems with finite answers, singular points 
 usually come with their own cure: Where
  D →
  0
 , there the physical solution
  y
  must be such 
 as to make
  N →
  0
  simultaneously, in such a way that the ratio takes on a meaningful value. 
 This constraint on the solution
  y
  is often called a
  regularity condition
 . The condition that
  
 D
 (
 x
 s
 ,
  y
 )
  satisfy some special constraint at
  x
 s
  is entirely analogous to an extra boundary 
 condition, an algebraic relation among the dependent variables that must hold at a point.
  
 method” to handle the task of integrating equations with singular behavior at the boundaries. We discussed a related situation 
 earlier, in
  §
 17.2, when we described the “fitting point
  
 In those problems you are unable to integrate from one side of the domain to the other.",NA
Chapter 18.,NA,NA
Integral Equations ,NA,NA
and Inverse Theory,NA,NA
18.0 Introduction,"Many people, otherwise numerically knowledgable, imagine that the 
 numerical solution of integral equations must be an extremely arcane topic, since, 
 until recently, it was almost never treated in numerical analysis textbooks. Actually 
 there is a large and growing literature on the numerical solution of integral 
 equations; several monographs have by now appeared
 [1-3]
 . One reason for the sheer 
 volume of this activity is that there are many different kinds of equations, each with 
 many different possible pitfalls; often many different algorithms have been 
 proposed to deal with a single case.
  
 There is a close correspondence between linear integral equations, which 
 specify linear, integral relations among functions in an infinite-dimensional 
 function space, and plain old linear equations, which specify analogous relations 
 among vectors in a finite-dimensional vector space. Because this correspondence 
 lies at the heart of most computational algorithms, it is worth making it explicit as 
 we recall how integral equations are classified.
  
 Fredholm equations
  involve definite integrals with fixed upper and lower limits.
  
 An
  inhomogeneous Fredholm equation of the first kind
  has the form
  
 g
 (
 t
 ) =
  
  b
  
 K
 (
 t, s
 )
 f
 (
 s
 )
  ds
  
 (
 18.0.1
 )
  
 a
  
 Here
  f
 (
 t
 )
  is the unknownfunction to be solved for, while
 g
 (
 t
 )
  is a known “right-
 hand side.” (In integral equations, for some odd reason, the familiar “right-hand 
 side” is conventionally written on the left!) The function of two variables,
  K
 (
 t, s
 )
  is 
 called the
  kernel
 . Equation (18.0.1) is analogous to the matrix equation
  
 K
  ·
  f
  =
  g 
  
 (
 18.0.2
 )
  
 whose solution is
  f
  =
  K
 −
 1
 ·
  g
 , where
  K
 −
 1
 is the matrix inverse. Like equation 
 (18.0.2), equation (18.0.1) has a unique solution whenever
  g
  is nonzero (the 
 homogeneous case with
  g
  = 0
  is almost never useful) and
  K
  is invertible. However, 
 as we shall see, this latter condition is as often the exception as the rule.
  
 The analog of the finite-dimensional eigenvalue problem
  
 (
 K
  − σ
 1
 )
  ·
  f
  =
  g 
  
 (
 18.0.3
 )
  
 779",NA
18.1 Fredholm Equations of the Second Kind,"We desire a numerical solution for
  f
 (
 t
 )
  in the equation
  
 f
 (
 t
 ) =
  λ
  
  b
  
 K
 (
 t, s
 )
 f
 (
 s
 )
  ds
  +
  g
 (
 t
 )
  
 (
 18.1.1
 )
  
 a
  
 The method we describe, a very basic one, is called the
  Nystrom method
 . It requires 
 the choice of some approximate
  quadrature rule
 :
  
  b N
  
 y
 (
 s
 )
  ds
  = 
 w
 j
 y
 (
 s
 j
 ) (
 18.1.2
 )
  
 a j
 =1
  
 Here the set
  {w
 j
 }
  are the weights of the quadrature rule, while the
  N
  points
  {s
 j
 } 
 are the abscissas.
  
 What quadrature rule should we use? It is certainly possible to solve integral 
 equations with low-order quadrature rules like the repeated trapezoidal or 
 Simpson’s",NA
18.2 Volterra Equations,"Let us now turn to Volterra equations, of which our prototype is the Volterra 
 equation of the second kind,
  
 f
 (
 t
 ) =
  
  t
  
 K
 (
 t, s
 )
 f
 (
 s
 )
  ds
  +
  g
 (
 t
 )
  
 (
 18.2.1
 )
  
 a
  
 Most algorithmsfor Volterraequationsmarch out from
  t
  =
  a
 , buildingup the solution 
 as they go. In this sense they resemble not only forward substitution (as discussed 
 in
  §
 18.0), but also initial-value problems for ordinary differential equations. In fact, 
 many algorithms for ODEs have counterparts for Volterra equations.
  
  
 The simplest way to proceed is to solve the equation on a mesh with uniform 
 spacing:
  
 t
 i
  =
  a
  +
  ih, 
  
 i
  = 0
 ,
  1
 , . . ., N, 
  
 h ≡b − a 
  
 (
 18.2.2
 )
  
 To do so, we must choose a quadrature rule. For a uniform mesh, the simplest 
 scheme is the trapezoidal rule, equation (4.1.11):
  
  t
 i
  
 a 
  
 K
 (
 t
 i
 , s
 )
 f
 (
 s
 )
  ds
  =
  h
 1 
    
 2
 K
 i
 0
 f
 0
  +
  
 j
 =1 
 i−
 1 
  
 K
 ij
 f
 j
  +
 1 2
 K
 ii
 f
 i
   
  
  
 (
 18.2.3
 )
  
 Thus the trapezoidal method for equation (18.2.1) is:
  
 f
 0
  =
  g
 0
  
 (1
  −
 1 2
 hK
 ii
 )
 f
 i
  =
  h
 1 2
 K
 i
 0
 f
 0
  +
  
 j
 =1 
 i−
 1 
  
 K
 ij
 f
 j
  +
  g
 i
 , 
   
  
 i
  = 1
 , . . ., N 
  
  
  
  
 (
 18.2.4
 )
  
 (For a Volterra equation of the first kind, the leading
  1
  on the left would be absent, 
 and
  g
  would have opposite sign, with corresponding straightforward changes in the 
 rest of the discussion.) 
  
  
 Equation (18.2.4) is an explicit prescription that gives the solution in
  O
 (
 N
 2
 ) 
 operations. Unlike Fredholm equations, it is not necessary to solve a system of 
 linear equations. Volterra equations thus usually involve less work than the 
 corresponding Fredholm equations which, as we have seen, do involve the inversion 
 of, sometimes large, linear systems.
  
 The efficiency of solving Volterra equations is somewhat counterbalanced by 
 the fact that
  systems
  of these equations occur more frequently in practice. If we 
 interpret equation (18.2.1) as a
  vector
  equation for the vector of
  m
  functions
  f
 (
 t
 )
 , 
 then the kernel
  K
 (
 t, s
 )
  is an
  m × m
  matrix. Equation (18.2.4) must now also be 
 understood as a vector equation. For each
  i
 , we have to solve the
  m × m
  set of 
 linear algebraic equations by Gaussian elimination.
  
 The routine
  voltra
  below implements this algorithm. You must supply an 
 external function that returns the
  k
 th function of the vector
  g
 (
 t
 )
  at the point
  t
 , and 
 another that returns the
  (
 k, l
 )
  element of the matrix
  K
 (
 t, s
 )
  at
  (
 t, s
 )
 . The routine 
 voltra
  then returns the vector
  f
 (
 t
 )
  at the regularly spaced points
  t
 i
 .",NA
18.3 Integral Equations with Singular Kernels,"Many integral equations have singularities in either the kernel or the solution or both. 
 A simple quadrature method will show poor convergence with
  N
  if such singularities are 
 ignored. There is sometimes art in how singularities are best handled.
  
  
 We start with a few straightforward suggestions: 
  
  
 1. Integrablesingularities canoften be removedby achangeofvariable. Forexample, the 
 singular behavior
  K
 (
 t,s
 )
  ≪ s
 1
 /
 2
 or
  s
 −
 1
 /
 2
 near
  s
  = 0
  can be removed by the transformation 
 z
  =
  s
 1
 /
 2
 . 
 Note that we are assuming that the singular behavior is confined to
  K
 , whereas the quadrature 
 actually involves the product
  K
 (
 t,s
 )
 f
 (
 s
 )
 , and it is this product that must be “fixed.” Ideally, 
 you must deduce the singular nature of the product before you try a numerical solution, and 
 take the appropriate action. Commonly, however, a singular kernel does
  not
  produce a 
 singular solution
  f
 (
 t
 )
 . (The highly singular kernel
  K
 (
 t,s
 ) =
  δ
 (
 t − s
 ) 
 is simply the identity 
 operator, for example.) 
  
  
 2. If
  K
 (
 t,s
 )
  can be factored as
  w
 (
 s
 )
 K
 (
 t, s
 )
 , where
  w
 (
 s
 )
  
 is singular and
  K
 (
 t, s
 )
  is smooth, then a Gaussian quadrature based on
  w
 (
 s
 )
  as a weight 
 function will work well. Even if the factorization is only approximate, the convergence is 
 often improved dramatically. All you have to do is replace
  gauleg
  in the routine
  fred2
  by 
 another quadrature routine. Section 4.5 explained how to construct such quadratures; or you 
 can find tabulated abscissas and weights in the standard references
 [1,2]
 . You must of course 
 supply
  K
  instead of
  K
 .",NA
18.4 Inverse Problems and the Use of A Priori ,NA,NA
Information,"Later discussion will be facilitated by some preliminary mention of a couple 
 of mathematical points. Suppose that
  u
  is an “unknown” vector that we plan to 
 determine by some minimization principle. Let
  A
 [
 u
 ]
  >
  0
  and
  B
 [
 u
 ]
  >
  0
  be two 
 positive functionals of
  u
 , so that we can try to determine
  u
  by either
  
 minimize: 
  
 A
 [
 u
 ] 
 or minimize: 
 B
 [
 u
 ] (
 18.4.1
 )
  
 (Of course these will generally give different answers for
  u
 .) As another possibility, 
 now suppose that we want to minimize
  A
 [
 u
 ]
  subject to the
  constraint
  that
  B
 [
 u
 ]
  have 
 some particular value, say
  b
 . The method of Lagrange multipliers gives the variation
  
 δ
 u
 {A
 [
 u
 ] +
  λ
 1
 (
 B
 [
 u
 ]
  − b
 )
 }
  =
  δδ
 u
 (
 A
 [
 u
 ] +
  λ
 1
 B
 [
 u
 ]) = 0 
  
 (
 18.4.2
 )
  
 where
  λ
 1
  is a Lagrange multiplier. Notice that
  b
  is absent in the second equality, 
 since it doesn’t depend on
  u
 .
  
  
 Next, suppose that we change our minds and decide to minimize
  B
 [
 u
 ]
  subject 
 to the constraint that
  A
 [
 u
 ]
  have a particular value,
  a
 . Instead of equation (18.4.2) we 
 have
  
 δ
 u
 {B
 [
 u
 ] +
  λ
 2
 (
 A
 [
 u
 ]
  − a
 )
 }
  =
  δδ
 u
 (
 B
 [
 u
 ] +
  λ
 2
 A
 [
 u
 ]) = 0 
  
 (
 18.4.3
 )
  
 with, this time,
  λ
 2
  the Lagrange multiplier. Multiplying equation (18.4.3) by the 
 constant
  1
 /λ
 2
 , and identifying
  1
 /λ
 2
  with
  λ
 1
 , we see that the actual variations are 
 exactly the same in the two cases. Both cases will yield the same one-parameter 
 family of solutions, say,
  u
 (
 λ
 1
 )
 . 
   
 As
  λ
 1
  varies from
  0
  to
  ∞
 , the solution
  u
 (
 λ
 1
 ) 
 varies along a so-called
  trade-off curve
  between the problem of minimizing
  A
  and 
 the problem of minimizing
  B
 . 
  
 Any solution along this curve can equally well be 
 thought of as either (i) a minimization of
  A
  for some constrained value of
  B
 , or (ii) a 
 minimization of
  B
  for some constrained value of
  A
 , or (iii) a weighted minimization 
 of the sum
  A
  +
  λ
 1
 B
 . The second preliminarypointhas to dowith
 degenerate
  
 minimizationprinciples.
  
 In the example above, now suppose that
  A
 [
 u
 ]
  has the particular form
  
 A
 [
 u
 ] =
  |
 A
  ·
  u
  −
  c
 |
 2 
 (
 18.4.4
 )
  
 for some matrix
  A
  and vector
  c
 . If
  A
  has fewer rows than columns, or if
  A
  is square 
 but degenerate (has a nontrivial nullspace, see
  §
 2.6, especially Figure 2.6.1), then 
 minimizing
  A
 [
 u
 ]
  will
  not
  give a unique solution for
  u
 . (To see why, review
  §
 15.4, 
 and note that for a “design matrix”
  A
  with fewer rows than columns, the matrix 
 A
 T
 ·
  
 A
  in the normal equations 15.4.10 is degenerate.)
  However
 , if we add any multiple",NA
18.5 Linear Regularization Methods,"What we will call
  linear regularization
  is also called the
  Phillips-Twomey 
 method
 [1,2]
 , the
  constrained linear inversion method
 [3]
 , the
  method of regulariza-
 tion
 [4]
 , and
  Tikhonov-Miller regularization
 [5-7]
 . (It probably has other names also,",NA
18.6 Backus-Gilbert Method,"The
  Backus-Gilbert method
 [1,2]
  (see, e.g.,
 [3]
  or
 [4]
  for summaries) differs from 
 other regularization methods in the nature of its functionals
  A
  and
  B
 . For
  B
 , the 
 method seeks to maximize the
  stability
  of the solution
 u
 (
 x
 )
  rather than, in the first 
 instance, its smoothness. That is,
  
 B ≡
  Var
 [
 u
 (
 x
 )] 
  
 (
 18.6.1
 )",NA
18.7 Maximum Entropy Image Restoration,"Above, we commented that the association of certain inversion methods with 
 Bayesian arguments is more historical accident than intellectual imperative. 
 Maximum entropy methods
 , so-called, are notorious in this regard; to summarize",NA
Chapter 19.,NA,NA
Partial Differential ,NA,NA
Equations,NA,NA
19.0 Introduction,"The numerical treatment of partial differential equations is, by itself, a vast 
 subject. 
  
 Partial differential equations are at the heart of many, if not most, 
 computer analyses or simulations of continuous physical systems, such as fluids, 
 electromagnetic fields, the human body, and so on. The intent of this chapter is to 
 give the briefest possible useful introduction. Ideally, there wouldbe an entire 
 second volume of
  Numerical Recipes
  dealing with partial differential equations 
 alone. (The references
 [1-4]
  provide, of course, available alternatives.) 
  
  
 In most mathematics books, partial differential equations (PDEs) are classified 
 into the three categories,
  hyperbolic, parabolic,
  and
  elliptic
 , on the basis of their 
 characteristics
 , or curves of information propagation. The prototypical example of a 
 hyperbolic equation is the one-dimensional
  wave
  equation
  
 ∂t
 2
  =
  v
 2
  ∂
 2
 u 
  
 (
 19.0.1
 )
  
 where
  v
  =
  constant is the velocity of wave propagation. The prototypical parabolic 
 equation is the
  diffusion
  equation
  
 ∂t
 =
  ∂∂x
  
 D∂u
  
 ∂x
  
 (
 19.0.2
 )
  
  
 where
  D
  is the diffusion coefficient. 
 Poisson
  equation
  
 The prototypical elliptic equation is the
  
 ∂x
 2
  +
  ∂
 2
 u∂y
 2
  =
  ρ
 (
 x, y
 ) (
 19.0.3
 )
  
 where the source term
  ρ
  is given. If the source term is equal to zero, the equation is
  
 Laplace’s equation
 .
  
 From a computational point of view, the classification into these three 
 canonical types is not very meaningful — or at least not as important as some other 
 essential distinctions. Equations (19.0.1) and (19.0.2) both define
  initial value
  or
  
 Cauchy 
 problems: If information on
  u
  (perhaps including time derivative 
 information) is
  
 818",NA
. ,NA,NA
. ,NA,NA
.,NA,NA
. ,NA,NA
. ,NA,NA
.,NA,NA
. ,NA,NA
. ,NA,NA
.,NA,NA
. ,NA,NA
. ,NA,NA
.,NA,NA
. ,NA,NA
. ,NA,NA
.,NA,NA
. ,NA,NA
. ,NA,NA
.,NA,NA
. ,NA,NA
. ,NA,NA
.,"boundary
  
 conditions
  
  
  
  
  
  
 (a)
  
  
  
  
  
  
  
  
  
 initial values
  
  
  
  
 boundary
  
 values
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 (b)
  
 Figure 19.0.1. 
  
 Initial value problem (a) and boundary value problem (b) are contrasted. In (a) initial 
 values are given on one “time slice,” and it is desired to advance the solution in time, computing 
 successive rows of open dots in the direction shown by the arrows. Boundary conditions at the left and 
 right edges of each row (
 ≪
 ) must also be supplied, but only one row at a time. Only one, or a few, 
 previous rows need be maintained in memory. In (b), boundary values are specified around the edge of a 
 grid, and an iterative process is employed to find the values of all the internal points (open circles). All 
 grid points must be maintained in memory.
  
 given at some initial time
  t
 0
  for all
  x
 , then the equations describe how
  u
 (
 x, t
 ) 
 propagates itself forward in time. In other words, equations (19.0.1) and (19.0.2) 
 describe time evolution. The goal of a numerical code should be to track that time 
 evolution with some desired accuracy.
  
 By contrast, equation (19.0.3) directs us to find a single “static” function
  u
 (
 x, 
 y
 ) 
 which satisfies the equation within some
  (
 x, y
 )
  region of interest, and which — 
 one must also specify — has some desired behavior on the boundary of the region 
 of interest. These problems are called
  boundary value problems
 . In general it is not",NA
. . .,"x
 J
  
 Figure 19.0.2. Finite-difference representation of a second-order elliptic equation on a two-dimensional 
 grid. The second derivatives at the point
  A
  are evaluated using the points to which
  A
  is shown connected. 
 The second derivatives at point
  B
  are evaluated using the connected points and also using “right-hand 
 side” boundary information, shown schematically as
  ≪
 .
  
 are boundary points where either
  u
  or its derivative has been specified. If we pull 
 all this “known” information over to the right-hand side of equation (19.0.8), then 
 the equation takes the form
  
 A
  ·
  u
  =
  b 
  
 (
 19.0.10
 )
  
 where
  A
  has the form shown in Figure 19.0.3. The matrix
  A
  is called “tridiagonal 
 with fringes.” A general linear second-order elliptic equation
  
 a
 (
 x, y
 )
 ∂
 2
 u∂x
 2
  +
  b
 (
 x, y
 )
 ∂u∂x
 +
  c
 (
 x, y
 )
 ∂
 2
 u∂y
 2
  +
  d
 (
 x, y
 )
 ∂u 
  
 (
 19.0.11
 ) 
  
  
  
 +
  e
 (
 x, y
 )
 ∂
 2
 u∂x∂y
 +
  f
 (
 x, y
 )
 u
  =
  g
 (
 x, y
 )
  
 will lead to a matrix of similar structure except that the nonzero entries will not be 
 constants.
  
 As a rough classification, there are three different approaches to the solution 
 of equation (19.0.10), not all applicable in all cases: relaxation methods, 
 “rapid”methods (e.g., Fourier methods), and direct matrix methods.",NA
19.1 Flux-Conservative Initial Value Problems,"A large class of initial value (time-evolution) PDEs in one space dimension can 
 be cast into the form of a
  flux-conservative equation
 ,
  
 ∂t
 =
  −∂
 F
 (
 u
 ) 
  
 (
 19.1.1
 )
  
 where
  u
  and
  F
  are vectors, and where (in some cases)
  F
  may depend not only on
  u 
 but also on spatial derivatives of
  u
 . The vector
  F
  is called the
  conserved flux
 . 
  
 For 
 example, the prototypical hyperbolic equation, the one-dimensional wave equation 
 with constant velocity of propagation
  v
  
 ∂t
 2
  =
  v
 2
  ∂
 2
 u 
  
 (
 19.1.2
 )",NA
19.2 Diffusive Initial Value Problems,"Recall the model parabolic equation, the diffusion equation in one space 
 dimension,
  
 ∂t
 =
  ∂∂x
  
 D∂u
  
 ∂x
  
 (
 19.2.1
 )
  
 where
  D
  is the diffusion coefficient. Actually, this equation is a flux-conservative 
 equation of the form considered in the previous section, with
  
 F
  =
  −D∂u 
 (
 19.2.2
 )
  
 the flux in the
  x
 -direction. We will assume
  D ≥
  0
 , otherwise equation (19.2.1) has 
 physically unstable solutions: A small disturbance evolves to become more and 
 more concentrated instead of dispersing. (Don’t make the mistake of trying to find 
 a stable differencing scheme for a problem whose underlyingPDEs are themselves 
 unstable!) Even though (19.2.1) is of the form already considered, it is useful to 
 consider it as a model in its own right. The particular form of flux (19.2.2), and its 
 direct generalizations, occur quite frequently in practice. Moreover, we have 
 already seen that numerical viscosity and artificial viscosity can introduce diffusive 
 pieces like the right-hand side of (19.2.1) in many other situations.
  
 Consider first the case when
  D
  is a constant. Then the equation
  
 ∂t
 =
  D∂
 2
 u 
  
 (
 19.2.3
 )
  
 can be differenced in the obvious way:
  
 u
 n
 +1 
 j
  
 − u
 n 
 =
  D 
  
   
  
  
 u
 n j
 +1
 −
  2
 u
 n j
 +
  u
 n j−
 1 
  
 (
 19.2.4
 )
   
 ∆
 t 
  
  
  
 (∆
 x
 )
 2
  
 This is the FTCS scheme again, except that it is a second derivative that has been 
 differenced on the right-hand side. 
  
 But this makes a world of difference! 
  
 The 
 FTCS scheme was unstable for the hyperbolicequation; however, a quick 
 calculation shows that the amplification factor for equation (19.2.4) is
  
 ξ
  = 1
  −
 4
 D
 ∆
 t 
 (∆
 x
 )
 2
  sin
 2 
  
 2 
  
  
  
  
 (
 19.2.5
 ) 
  
  
 k
 ∆
 x
  
 The requirement
  |ξ| ≤
  1
  leads to the stability criterion
  
 2
 D
 ∆
 t 
  
 (∆
 x
 )
 2
  ≤
  1
  
 (
 19.2.6
 )",NA
19.3 Initial Value Problems in Multidimensions,"(one space and one time dimension) can easily be generalized to
  N
  + 1
  dimensions. The methods described in
  §
 19.1 
 and
  §
 19.2 for problems in
  1 + 1
  dimension
  
 However, the computing power necessary to solve the resulting equations is enor-
 mous. If you have solved a one-dimensional problem with 100 spatial grid points, 
 solving the two-dimensional version with 100
  ×
  100 mesh points requires
  at least 
 100 times as much computing. You generally have to be content with very modest 
 spatial resolution in multidimensional problems.
  
 Indulge us in offering a bit of advice about the development and testing of 
 multidimensional PDE codes: You should always first run your programs on
  very 
 useless. When your program is all debugged and demonstrably stable,
  then
  you can 
 small
  grids, e.g.,
  8
  ×
  8
 , even though the resulting accuracy is so poor as to be 
 increase the grid size to a reasonable one and start looking at the results. We have 
 actually heard someone protest, “my program would be unstable for a crude grid, 
 but I am sure the instability will go away on a larger grid.” That is nonsense of a 
 most pernicious sort, evidencing total confusion between accuracy and stability. In 
 fact, new instabilities sometimes do show up on
  larger
  grids; but old instabilities 
 never (in our experience) just go away.",NA
19.4 Fourier and Cyclic Reduction Methods for ,NA,NA
Boundary Value Problems,"example) reduce to solving large sparse linear systems of the form As discussed in
  §
 19.0, most boundary value 
 problems (elliptic equations, for",NA
19.5 Relaxation Methods for Boundary Value ,NA,NA
Problems,"matrix that arises from finite differencing and then iterating until a solution is found. As we mentioned in
  §
 19.0, 
 relaxation methods involve splitting the sparse
  
  
 There is another way of thinking about relaxation methods that is somewhat 
 more physical. Suppose we wish to solve the elliptic equation
  
 Lu
  =
  ρ
 (
 19.5.1
 )",NA
19.6 Multigrid Methods for Boundary Value ,NA,NA
Problems,"Practical multigridmethods were first introduced in the 1970s by Brandt. 
 These methods can solve elliptic PDEs discretized on
  N
  grid points in
  O
 (
 N
 )
  
 operations. The “rapid” direct elliptic solvers discussed in
  §
 19.4 solve special kinds 
 of elliptic equations in
  O
 (
 N
  log
 N
 )
  operations. The numerical coefficients in these 
 estimates are such that multigrid methods are comparable to the rapid methods in 
 execution speed. Unlike the rapid methods, however, the multigrid methods can 
 solve general elliptic equations with nonconstant coefficients with hardly any loss 
 in efficiency. Even nonlinear equations can be solved with comparable speed.
  
 Unfortunately there is not a single multigrid algorithm that solves all elliptic 
 problems. Rather there is a multigrid technique that provides the framework for 
 solving these problems. You have to adjust the various components of the",NA
Chapter 20.,NA,NA
Less-Numerical ,NA,NA
Algorithms,NA,NA
20.0 Introduction,"You can stop reading now. You are done with
  Numerical Recipes
 , as such. 
 This final chapter is an idiosyncratic collection of “
 less-
 numerical recipes” which, 
 for one reason or another, we have decided to include between the covers of an 
 otherwise 
 more-
 numerically oriented book. Authors of computer science texts, 
 we’ve noticed, like to throw in a token numerical subject (usually quite a dull one 
 — quadrature, for example). We find that we are not free of the reverse tendency.
  
 Our selection of material is not completely arbitrary. One topic, Gray codes, 
 was only some additional explication. Two other topics, on diagnosing a 
 computer’s already used in the construction of quasi-random sequences (
 §
 7.7), and 
 here needs floating-point parameters, and on arbitrary precision arithmetic, give 
 additional insight into the machinery behind the casual assumption that computers 
 are useful for doing things with numbers (as opposed to bits or characters). The 
 latter of these topics also shows a very different use for Chapter 12’s fast Fourier 
 transform.
  
 The three other topics (checksums, Huffman and arithmetic coding) involve 
 different aspects of data coding, compression, and validation. If you handle a large 
 amount of data — numerical data, even — then a passing familiarity with these 
 subjects might at some point come in handy. In
  §
 13.6, for example, we already 
 encountered a good use for Huffman coding.
  
  
 But again, you don’t have to read this chapter. (And you should learn about 
 quadrature from Chapters 4 and 16, not from a computer science text!)",NA
20.1 Diagnosing Machine Parameters,"A convenient fiction is that a computer’s floating-point arithmetic is “accurate 
 enough.” If you believe this fiction, then numerical analysis becomes a very clean 
 subject. 
  
 Roundoff error disappears from view; many finite algorithms 
 become“exact”; only docile truncation error (
 §
 1.2) stands between you and a perfect 
 calculation. Sounds rather naive, doesn’t it?
  
  
 Yes, it is naive. Notwithstanding, it is a fiction necessarily adopted throughout 
 most of this book. To do a good job of answering the question of how roundoff 
 error",NA
20.2 Gray Codes,"A Gray code is a function
  G
 (
 i
 )
  of the integers
  i
 , that for each integer
  N ≥
  0 
 is 
 one-to-one for
  0
  ≤ i ≤
  2
 N
 −
  1
 , and that has the following remarkable property: The 
 binary representation of
  G
 (
 i
 )
  and
  G
 (
 i
 +1)
  differ in
  exactly one bit
 . An example of a 
 Gray code (in fact, the most commonly used one) is the sequence 0000, 0001, 
 0011, 0010, 0110, 0111, 0101, 0100, 1100, 1101, 1111, 1110, 1010, 1011, 1001, 
 and 1000, for
  i
  = 0
 , . . .,
  15
 . The algorithm for generating this code is simply to form 
 the bitwise exclusive-or (XOR) of
  i
  with
  i/
 2
  (integer part). Think about how the 
 carries work when you add one to a number in binary, and you will be able to see 
 why this works. You will also see that
  G
 (
 i
 )
  and
  G
 (
 i
  + 1)
  differ in the bit position of 
 the rightmost zero bit of
  i
  (prefixing a leading zero if necessary).
  
  
 The spelling is “Gray,” not “gray”: The codes are named after one Frank Gray, 
 who first patented the idea for use in shaft encoders. A shaft encoder is a wheel with 
 concentric coded stripes each of which is “read” by a fixed conducting brush. The 
 idea is to generate a binary code describing the angle of the wheel. The obvious, but 
 wrong, way to build a shaft encoder is to have one stripe (the innermost, say) 
 conducting on half the wheel, but insulating on the other half; the next stripe is 
 conducting in quadrants 1 and 3; the next stripe is conducting in octants 1, 3, 5, and 
 7; and so on. 
  
  
 The brushes together then read a direct binary code for the position of the 
 wheel.",NA
20.3 Cyclic Redundancy and Other Checksums,"When you send a sequence of bits from point A to point B, you want to know 
 that it will arrive without error. A common form of insurance is the “parity 
 bit,”attached to 7-bit ASCII characters to put them into 8-bit format. The parity bit 
 is chosen so as to make the total number of one-bits (versus zero-bits) either always 
 even (“even parity”) or always odd (“odd parity”). Any
  single bit
  error in a 
 character will thereby be detected. When errors are sufficiently rare, and do not 
 occur closely bunched in time, use of parity provides sufficient error detection.
  
 Unfortunately, in real situations, a single noise “event” is likely to disrupt 
 more than one bit. Since the parity bit has two possible values (0 and 1), it gives, 
 on average, only a 50% chance of detecting an erroneous character with more than 
 one wrong bit. That probability, 50%, is not nearly good enough for most 
 applications. Most communications protocols
 [1]
 use a multibit generalization of the 
 parity bit called a “cyclic redundancy check” or CRC. In typical applications the 
 CRC is
  16 
 bits long (two bytes or two characters), so that the chance of a random 
 error going undetected is 1 in
  2
 16
 = 65536
 . Moreover,
  M
 -bit CRCs have the 
 mathematical property of detecting
  all
  errors that occur in
  M
  or fewer
  consecutive
  
 bits, for any",NA
20.4 Huffman Coding and Compression of Data,"A lossless data compression algorithm takes a string of symbols (typically 
 ASCII characters or bytes) and translates it
  reversibly
  into another string, one that is
  
 on the average
  of shorter length. 
  
 The words “on the average” are crucial; it is 
 obvious that no reversible algorithm can make all strings shorter — there just aren’t 
 enough short strings to be in one-to-one correspondence with longer strings. 
 Compression algorithms are possible only when, on the input side, some strings, or 
 some input symbols, are more common than others. These can then be encoded in 
 fewer bits than rarer input strings or symbols, giving a net average gain.
  
  
 There exist many, quite different, compression techniques, corresponding to 
 different ways of detecting and usingdepartures from equiprobabilityin input strings. 
 In this section and the next we shall consider only
  variable length codes
  with
  
 defined word
  inputs. In these, the input is sliced into fixed units, for example ASCII 
 characters, while the corresponding output comes in chunks of variable size. The 
  
  
  
 Another 
 simplest such method is Huffman coding
 [1]
 , discussed in this section.
  
 example,
  arithmetic compression
 , is discussed in
  §
 20.5. At the opposite extreme 
 from defined-word, variable length codes are schemes that divide up the
  input
  into 
 units of variable length (words or phrases of English text, for example) and then 
 transmit these, often witha fixed-lengthoutput code. The most widely used code of 
 this type is the Ziv-Lempel code
 [2]
 . References
 [3-6]
  give the flavor of some other 
 compression techniques, with references to the large literature.
  
 The idea behind Huffman coding is simply to use shorter bit patterns for more 
 common characters. We can make this idea quantitative by considering the concept 
 of
  entropy
 . Suppose the input alphabet has
  N
 ch
  characters, and that these occur in 
 the input string with respective probabilities
  p
 i
 ,
  i
  = 1
 , . . ., N
 ch
 , so that
 p
 i
  = 1
 . Then 
 the fundamental theorem of information theory says that strings consisting of 
 independently random sequences of these characters (a conservative, but not 
 always realistic assumption) require, on the average, at least
  
 H
  =
  −p
 i
  log
 2
  p
 i 
 (
 20.4.1
 )
  
 bits per character. Here
  H
  is the entropy of the probability distribution. Moreover, 
 coding schemes exist which approach the bound arbitrarily closely. For the case of 
 equiprobable characters, with all
  p
 i
  = 1
 /N
 ch
 , one easily sees that
  H
  = log
 2
  N
 ch
 , 
 which is the case of no compression at all. Any other set of
  p
 i
 ’s gives a smaller 
 entropy, allowing some useful compression.
  
 Notice that the boundof(20.4.1) wouldbe achieved ifwe couldencode character 
 i
  with a code of length
  L
 i
  =
  −
  log
 2
  p
 i
  bits: Equation (20.4.1) would then be the an 
 integer. How can we encode the letter “Q” in 5.32 bits? Huffman coding makes 
 average
 p
 i
 L
 i
 . The trouble with such a scheme is that
  −
  log
 2
  p
 i
  is not generally a stab 
 at this by, in effect, approximating all the probabilities
  p
 i
  by integer powers of 1/2, 
 so that all the
  L
 i
 ’s are integral. If all the
  p
 i
 ’s are in fact of this form, then a Huffman 
 code does achieve the entropy bound
  H
 .
  
 The construction of a Huffman code is best illustrated by example. Imagine a 
 language, Vowellish, with the
  N
 ch
  = 5
  character alphabet A, E, I, O, and U, 
 occurring with the respective probabilities 0.12, 0.42, 0.09, 0.30, and 0.07. Then",NA
20.5 Arithmetic Coding,"We saw in the previous section that a perfect (entropy-bounded) coding 
 scheme would use
  L
 i
  =
  −
  log
 2
  p
 i
  bits to encode character
  i
  (in the range
  1
  ≤ i ≤ N
 ch
 ), 
 if
  p
 i
  is its probability of occurrence. Huffman coding gives a way of rounding the 
 L
 i
 ’s to close integer values and constructing a code with those lengths.
  Arithmetic 
 coding
 [1]
 , which we now discuss, actually does manage to encode characters using 
 noninteger numbers of bits! It also provides a convenient way to output the result 
 not as a stream of bits, but as a stream of symbols in any desired radix. This latter 
 property is particularly useful if you want, e.g., to convert data from bytes (radix 
 256) to printable ASCII characters (radix 94), or to case-independent alphanumeric 
 sequences containing only A-Z and 0-9 (radix 36).
  
  
 In arithmetic coding, an input message of any length is represented as a real 
 number
  R
  in the range
  0
  ≤ R <
  1
 . The longer the message, the more precision 
 required of
  R
 . This is best illustrated by an example, so let us return to the fictitious 
 language, Vowellish, of the previous section. Recall that Vowellish has a 5 
 character alphabet (A, E, I, O, U), with occurrence probabilities 0.12, 0.42, 0.09, 
 0.30, and 0.07, respectively. Figure 20.5.1 shows how a message beginning “IOU” 
 is encoded: The interval
  [0
 ,
  1)
  is divided into segments corresponding to the 5 
 alphabetical characters; the length of a segment is the corresponding
  p
 i
 . We see that 
 the first message character, “I”, narrows the range of
  R
  to
  0
 .
 37
  ≤ R <
  0
 .
 46
 . This 
 interval is now subdividedintofive subintervals, again withlengths proportionalto the
  
 p
 i
 ’s. The second message character, “O”, narrows the range of
  R
  to
  0
 .
 3763
  ≤ R <
  
 0
 .
 4033
 . The “U” character further narrows the range to
  0
 .
 37630
  ≤ R <
  0
 .
 37819
 .
  
 Any
  value of
  R
  in this range can be sent as encoding “IOU”. In particular, the binary 
 fraction 
 .
 011000001
  is in this range, so “IOU” can be sent in 9 bits. (Huffman 
 coding took 10 bits for this example, see
  §
 20.4.) Of course there is the problem of 
 knowing when to stop decoding. 
  
 The fraction
  .
 011000001
  
 represents not simply “IOU,” but “IOU
 . . .
 ,” where the ellipses represent an infinite 
 string of successor characters. 
  
 To resolve this ambiguity, 
 arithmetic coding generally assumes the existence of a special
  N
 ch
  + 1
 th character, 
 EOM (end of message), which occurs only once at the end of the input. Since EOM 
 has a low probability of occurrence, it gets allocated only a very tiny piece of the 
 number line.
  
 In the above example, we gave
  R
  as a binary fraction. We could just as well 
 have output it in any other radix, e.g., base 94 or base 36, whatever is convenient 
 for the anticipated storage or communication channel.
  
 You might wonder how one deals with the seemingly incredible precision 
 required of
  R
  for a long message. The answer is that
  R
  is never actually represented 
 all at once. At any give stage we have upper and lower bounds for
  R
  represented as 
 a finite number of digits in the output radix. As digits of the upper and lower 
 bounds become identical, we can left-shift them away and bring in new digits at the 
 low-significance end. The routines below have a parameter
  NWK
  for the number of 
 working digits to keep around. This must be large enough to make the chance of an 
 accidental degeneracy vanishingly small. (The routines signal if a degeneracy ever",NA
20.6 Arithmetic at Arbitrary Precision,"Let’s compute the number
  π
  to a couple of thousand decimal places. In doing 
 so, we’ll learn some things about multiple precision arithmetic on computers and 
 meet quite an unusual application of the fast Fourier transform (FFT). We’ll also 
 develop a set of routines that you can use for other calculations at any desired level 
 of arithmetic precision.
  
  
 To start with, we need an analytic algorithm for
  π
 . 
  
 Useful algorithms are 
 quadratically convergent, i.e., they double the number of significant digits at each 
 iteration. Quadratically convergent algorithms for
  π
  are based on the
  AGM 
 (arithmetic geometric mean)
  method, which also finds application to the calculation 
 of elliptic integrals (cf.
  §
 6.11) and in advanced implementations of the ADI method 
 for elliptic partial differential equations (
 §
 19.5). Borwein and Borwein
 [1]
  treat this 
 subject, which is beyond our scope here. One of their algorithms for
  π
  starts with 
 the initializations
  
 X
 0
  =
 √
 2
  
 π
 0
  = 2 +
 √
 2 (
 20.6.1
 )
  
 Y
 0
  = 
 4
 √
 2",NA
References,"The references collected here are those of general usefulness, usually cited in 
 more than one section of this book. More specialized sources, usually cited in a 
 single section, are not repeated here.
  
 We first list a small number of books that form the nucleus of a recommended 
 personal reference collection on numerical methods, numerical analysis, and 
 closely related subjects. These are the books that we like to have within easy reach.
  
 Abramowitz, M., and Stegun, I.A. 1964,
  Handbook of Mathematical 
 Functions
 , Applied Mathematics Series, Volume 55 (Washington: 
 National Bureau of Standards; reprinted 1968 by Dover 
 Publications, New York)
  
 Acton, F.S. 1970,
  Numerical Methods That Work
 ; 1990, corrected edition 
 (Washington: Mathematical Association of America)
  
 Ames, W.F. 1977,
  Numerical Methods for Partial Differential Equations
 , 
 2nd ed. (New York: Academic Press)
  
 Bratley, P., Fox, B.L., and Schrage, E.L. 1983,
  A Guide to 
 Simulation
 (New York: Springer-Verlag)
  
 Dahlquist, G., and Bjorck, A. 1974,
  Numerical Methods
  (Englewood 
 Cliffs, NJ: Prentice-Hall)
  
 Delves, L.M., and Mohamed, J.L. 1985,
  Computational Methods for Inte-
 gral Equations
  (Cambridge, U.K.: Cambridge University Press)
  
 Dennis, J.E., and Schnabel, R.B. 1983,
  Numerical Methods for Uncon-
 strained Optimization and Nonlinear Equations
  (Englewood Cliffs, 
 NJ: Prentice-Hall)
  
 Gill, P.E., Murray, W., and Wright, M.H. 1991,
  Numerical Linear Algebra 
 and Optimization
 , vol. 1 (Redwood City, CA: Addison-Wesley)
  
 Golub, G.H., and Van Loan, C.F. 1989,
  Matrix Computations
 , 2nd ed. 
 (Baltimore: Johns Hopkins University Press)
  
 Oppenheim, A.V., and Schafer, R.W. 1989,
  Discrete-Time Signal 
 Process-ing
  (Englewood Cliffs, NJ: Prentice-Hall)
  
 Ralston, A., and Rabinowitz, P. 1978,
 A First Course inNumerical 
 Analysis
 , 2nd ed. (New York: McGraw-Hill)
  
 Sedgewick, R. 1988,
  Algorithms
 , 2nd ed. (Reading, MA: Addison-Wesley)
  
 Stoer, J., and Bulirsch, R. 1980,
  Introduction to Numerical Analysis
  (New 
 York: Springer-Verlag)
  
 Wilkinson,J.H., and Reinsch, C. 1971,
 Linear Algebra
 , vol. II of
  
 Handbook for Automatic Computation
  (New York: Springer-Verlag)
  
 916",NA
Index of Programs and Dependencies,"The following table lists, in alphabetical order, all the routines in
  Numerical
  
 Recipes
 . When a routine requires subsidiary routines, either from this book or else
  
 user-supplied, the full dependency tree is shown: A routine calls directly all routines
  
 to which it is connected by a solid line in the column immediately to its right; it
  
 calls indirectly the connected routines in all columns to its right. Typographical
  
 conventions: Routines from this book are in typewriter font (e.g.,
  eulsum
 ,
  gammln
 ).
  
 The smaller, slanted font is used for the second and subsequent occurences of a
  
 routine in a single dependency tree. 
  
 (When you are getting routines from the
  
 Numerical Recipes
  diskettes, or their archive files, you need only specify names in
  
 the larger, upright font.) User-supplied routines are indicated by the use of text
  
 font and square brackets, e.g., [funcv]. Consult the text for individual specifications
  
 of these routines. The right-hand side of the table lists section and page numbers
  
 for each program.
  
 addint 
  
 interp 
  
 . 
  
 . 
  
 . 
  
 . 
  
 . 
  
 . 
  
 . . 
  
 . . 
  
 . 
  
 .
  
 §
 19.6 (p. 871)
  
 airy 
  
 bessik
  
 bessjy 
  
 beschb 
  
  
  
 . 
  
 . .
  
 chebev 
  
 . . 
  
 . . 
  
 . . 
  
 . 
  
 .
  
 §
 6.7 (p. 244)
  
 amebsa 
  
 ran1
  .
  
 amotsa 
  
  
 .
  
 [funk] 
  
 . 
  
 . . 
  
 . . 
  
 . . 
  
 . 
  
 . 
  
 . .
  
 §
 10.9 (p. 445)
  
 ran1
  
 [funk]
  
 amoeba 
  
 amotry
  
 [funk] 
  
 [funk] 
  
 . 
  
 . 
  
 . 
  
 . . 
  
 . . 
  
 . .
  
 §
 10.4 (p. 404)
  
 amotry 
  
 [funk] 
  
 . 
  
 . 
  
 . 
  
 . 
  
 . 
  
 . 
  
 . . 
  
 . . 
  
 . 
  
 .
  
 §
 10.4 (p. 405)
  
 amotsa 
  
 [funk]
  
 ran1 
  
 . 
  
 . 
  
 . . 
  
 . . 
  
 . . 
  
 . . 
  
 . .
  
 §
 10.9 (p. 446)
  
 anneal 
  
 ran3
  .
  
 irbit1 
  
 . 
  
 . 
  
 . . 
  
 . . 
  
 . . 
  
 . 
  
 . 
  
 . .
  
 §
 10.9 (p. 439)
  
 trncst
  
 metrop 
  
 ran3
  
 trnspt
  
 revcst
  
 revers
  
 anorm2
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 §
 19.6 (p. 879)
  
 §
 20.5 (p. 904)
  
 §
 20.5 (p. 904)
  
 §
 20.5 (p. 906)
  
 §
 14.2 (p. 611)
  
 §
 1.1 (p. 14)
  
 arcmak
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 arcode
  
 arcsum
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 arcsum
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 avevar
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 badluk
  
 julday
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 flmoon
  
 balanc
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 .
  
 §
 11.5 (p. 477)
  
 920",NA
General Index to Volumes 1 and 2,"In this index, page numbers 1 through 934 refer to Volume 1,
  Numerical Recipes in Fortran 77
 , while 
 page numbers 935 through 1446 refer to Volume 2,
  Numerical Recipes in Fortran 90
 . Front matter in 
 Volume 1 is indicated by page numbers in the range 1/i through 1/xxxi, while front matter in Volume 2 
 is indicated 2/i through 2/xx.
  
 A
 bstract data types 
  
 2/xiii, 1030 
  
 Accelerated convergence of series 160ff., 
 1070 
  
 Accuracy 19f.
  
 achievable in minimization 
   
 392, 397, 404 
 achievable in root finding 
  
 346f.
  
  
 contrasted with fidelity 
   
 832, 840 
  
  
 CPU different from memory 181 
  
  
 vs. stability 
  
 704, 729, 830, 844 
  
  
    
  
 1362f. Accuracy 
 parameters 
  
 Acknowledgments 1/xvi, 2/ix 
  
 Ada 
  
 2/x 
  
 Adams-Bashford-Moulton method 
  
 741 
  
 Adams’ stopping criterion 
  
 366 
  
 Adaptive integration 123, 135, 703, 708ff., 
  
  
   
 720, 726, 731f., 737, 742ff., 788, 1298ff., 
  
   
 1303, 1308f.
  
 Monte Carlo 
  
 306ff., 1161ff.
  
 Addition, multiple precision 907, 1353 
  
  
  
  
  
 255 
 Addition theorem, elliptic integrals 
  
 ADI (alternating direction implicit) method 
  
 847, 861f., 906 
  
 Adjoint operator 867 
  
 Adobe Illustrator 
  
  
 1/xvi, 2/xx Advective equation 826 
  
  
  
  
  
 906 
 AGM (arithmetic geometric mean) 
  
 Airy function 204, 234, 243f.
  
  
 routine for 244f., 1121 
  
 Aitken’s delta squared process 160 
  
 Aitken’s interpolation algorithm 
  
 102 
  
  
  
 2/x, 2/xiv Algol 
  
 Algorithms, non-numerical 881ff., 1343ff.
  
 Aliasing 495, 569 
  
  
 see also
  Fourier transform 
  
 all() intrinsic function 
  
 945, 948 
  
 All-poles model 566 
  
  
 see also
  Maximum entropy method (MEM) 
 All-zeros model 566 
  
  
 see also
  Periodogram 
  
 Allocatable array 
  
 938, 941, 952ff., 1197, 
  
  
  
 1212, 1266, 1293, 1306, 1336 
  
 allocate statement 
   
 938f., 941, 953f., 1197, 
  
  
 1266, 1293, 1306, 1336 
  
 allocated() intrinsic function 938, 952ff., 
  
  
  
 1197, 1266, 1293 
  
 Allocation status 
  
 938, 952ff., 961, 1197, 
  
  
  
 1266, 1293
  
 Alpha AXP 
  
 2/xix 
  
 Alternating-direction implicit method (ADI) 
  
 847, 861f., 906 
  
 Alternating series 
  
 160f., 1070 
  
 Alternative extended Simpson’s rule 
  
 128 
  
 American National Standards Institute (ANSI) 
  
 2/x, 2/xiii 
  
 Amoeba 403 
  
 see also
  Simplex, method of Nelder and 
  
 Mead 
  
 Amplification factor 
  
 828, 830, 832, 840, 845f.
  
  
  
   
 831 Amplitude error 
  
 Analog-to-digital converter 812, 886 
  
 Analyticity 195 
  
 Analyze/factorize/operate package 64, 824 
 Anderson-Darling statistic 621 
  
  
  
 697 Andrew’s sine 
  
 Annealing, method of simulated 387f., 436ff., 
 1219ff.
  
 assessment 447 
  
 for continuous variables 
  
 437, 443ff., 1222 
 schedule 438 
  
 thermodynamic analogy 437 
  
 traveling salesman problem 
   
 438ff., 1219ff. 
 ANSI (American National Standards Institute) 
  
 2/x, 2/xiii 
  
 Antonov-Saleev variant of Sobol’ sequence 
  
 300, 1160 
  
 any() intrinsic function 945, 948 
  
 APL (computer language) 2/xi 
  
 Apple 
   
 1/xxiii 
  
 Macintosh 2/xix, 4, 886 
  
 Approximate inverse of matrix 
  
 49 
  
 Approximation of functions 
  
 99, 1043 
  
 by Chebyshev polynomials 185f., 513, 
  
 1076ff.
  
 Pad´e approximant 194ff., 1080f.
  
 by rational functions 
  
 197ff., 1081f.
  
 by wavelets 
  
 594f., 782 
  
 see also
  Fitting 
  
 Argument 
  
 keyword 2/xiv, 947f., 1341 
  
 optional 2/xiv, 947f., 1092, 1228, 1230, 
  
 1256, 
 1272, 1275, 1340 
  
 Argument checking 994f., 1086, 1090, 1092, 
  
 1370f.
  
 934",NA
