Larger Text,Smaller Text,Symbol
F,NA,NA
LEXIBLE ,NA,NA
S,NA,NA
OFTWARE ,NA,NA
D,NA,NA
ESIGN,NA,NA
"Other Auerbach Publications in Software Development, ",NA,NA
"Software Engineering, and Project Management","The Complete Project Management 
  
 Software Configuration Management
  
 Office Handbook
  
 Jessica Keyes
  
 Gerard M. Hill
  
 0-8493-1976-5
  
 0-8493-2173-5
  
 Software Engineering for Image 
  
 Complex IT Project Management: 
  
 Processing
  
 16 Steps to Success
  
 Phillip A. Laplante
  
 Peter Schulte
  
 0-8493-1376-7
  
 0-8493-1932-3
  
 Software Engineering Handbook
  
 Creating Components: Object Oriented, 
  
 Jessica Keyes
  
 Concurrent, and Distributed Computing 
  
 0-8493-1479-8
  
  
 in Java 
  
 Charles W. Kann 
  
 0-8493-1499-2
  
 The Hands-On Project Office: 
  
 Guaranteeing ROI and On-Time Delivery 
 Richard M. Kesner 
  
 0-8493-1991-9
  
 Interpreting the CMMI®: A Process 
 Improvement Approach 
  
 Software Engineering Measurement 
 John C. Munson 
  
 0-8493-1503-4
  
 Software Metrics: A Guide to Planning, 
 Analysis, and Application 
  
 C.R. Pandian 
  
 0-8493-1661-8
  
 Software Testing: A Craftsman’s 
 Approach, Second Edition
  
 Margaret Kulpa and Kent Johnson 
  
 Paul C. Jorgensen
  
 0-8493-1654-5 
  
 0-8493-0809-7
  
 ISO 9001:2000 for Software and Systems 
  
 Software Testing and Continuous Quality 
  
 Providers: An Engineering Approach 
  
 Improvement, Second Edition 
  
 Robert Bamford and William John Deibler II 
  
 William E. Lewis
  
 0-8493-2063-1 
  
 0-8493-2524-2
  
 The Laws of Software Process: A 
 New Model for the Production 
  
 IS Management Handbook, 8th Edition 
 Carol V. Brown and Heikki Topi, Editors
  
 and Management of Software 
  
 0-8493-1595-9
  
 Phillip G. Armour 
 0-8493-1489-5
  
 Lightweight Enterprise Architectures 
 Fenix Theuerkorn 
  
 Real Process Improvement Using the 
 CMMI®
  
 Michael West 
  
 0-8493-2109-3
  
 Six Sigma Software Development 
 Christine Tayntor 
  
 0-8493-1193-4
  
 Software Architecture Design Patterns in 
 Java 
  
 Partha Kuchana 
  
 0-8493-2142-5
  
 0-8493-2114-X
  
 Outsourcing Software Development 
 Offshore: Making It Work 
  
 Tandy Gold 
  
 0-8493-1943-9
  
 Maximizing ROI on Software Development 
 Vijay Sikka 
  
 0-8493-2312-6
  
 Implementing the IT Balanced Scorecard 
 Jessica Keyes 
  
 0-8493-2621-4
  
 AUERBACH PUBLICATIONS
  
 www.auerbach-publications.com 
  
 To Order Call: 1-800-272-7737 • Fax: 1-800-374-3401 
 E-mail: orders@crcpress.com",NA
F,NA,NA
LEXIBLE ,NA,NA
S,NA,NA
OFTWARE ,NA,NA
D,NA,NA
ESIGN,NA,NA
S,NA,NA
YSTEMS ,NA,NA
D,NA,NA
EVELOPMENT ,NA,NA
FOR,NA,NA
 C,NA,NA
HANGING ,NA,NA
R,NA,NA
EQUIREMENTS,NA,NA
"Bruce Johnson, Ph.D. ",NA,NA
Walter W. Woolfolk ,NA,NA
Robert Miller ,NA,NA
"Cindy Johnson, PMP",Boca Raton   London   New York   Singapore,NA
Dedication,"This book is dedicated to those information technology (IT) professionals who 
 want the systems they develop to continue to serve the changing needs of their 
 enterprises long after they have left the project. It is also dedicated to the business 
 experts who wish to make critical system updates without being hamstrung by an 
 IT backlog.",NA
Contents ,"Acknowledgments........................................................................................xv
  
 Introduction................................................................................................xvii
  
 Part I 
  
 Introduction to Flexibility
  
 1 
  
 The Serious Problems with IT Today .........................................3
  
 1.1 
  
 The Industrywide Maintenance Problem .............................................. 4
  
 1.2 
  
 What Is Wrong with Nonflexible Systems? Two Cautionary Tales..... 7
  
 1.3 
  
 The Typical IT Environment: No Time to Do It Right — Time 
  
 to Do It Over!.......................................................................................... 8
  
 1.4 
  
 Summary .................................................................................................. 9
  
 2 
  
 The Reality of Imperfect Knowledge .......................................13
  
 2.1 
  
 Flexibility: An Improved Way of Thinking ......................................... 14
  
 2.1.1 
  
 Real World/Automated World................................................ 14
  
 2.1.2 
  
 Synchronization and Resynchronization ............................... 15
  
 2.1.3 
  
 Flexibility and Local Modifiability ......................................... 15
  
 2.1.4 
  
 Natural and Artificial Limits ................................................... 16
  
 2.2 
  
 What Is Flexible Software? ................................................................... 18
  
 2.2.1 
  
 Structural Stability ................................................................... 19
  
 2.2.1.1 
  
 Invariant, Unique, and Meaningless Identifiers... 19
  
 2.2.1.2 
  
 Generic Entity Types............................................. 19
  
 2.2.1.3 
  
 Generic Entity Relationships................................. 20
  
 2.2.1.4 
  
 Recursive Entity Relationships.............................. 20
  
 2.2.1.5 
  
 Variable Cardinality................................................ 20
  
 2.2.1.6 
  
 Variable Typing...................................................... 20
  
 2.2.1.7 
  
 Consistent Typing.................................................. 20
  
 2.2.2 
  
 Processes That Exploit Stable Structures .............................. 21
  
 2.3 
  
 Change or Die....................................................................................... 22
  
 2.4 
  
 Evolution of Flexibility ......................................................................... 23
  
 2.4.1 
  
 More Flexible Handling of “Constants” ................................ 23
  
 vii",NA
Acknowledgments,"First and foremost, the authors would like to thank Auerbach for the opportunity 
 to fulfill our aspiration to make this flexibility handbook available. Thanks are also 
 given to Peter Ligezinski, Mark Murphy, Jack Scheuer, and an unnamed 
 representative from Auerbach for taking time to read the manuscript and make 
 valuable suggestions. Also, we want to thank Andrea Shultz for the computer 
 graphics support.
  
 Special thanks go to our families for their continued support and 
 encouragement. We truly appreciate your understanding, patience, and 
 forbearance as this project took much time away from family activities and 
 responsibilities.
  
 We have made extensive use of material that we have published earlier. 
 Appreciation is expressed to the publishers of these earlier works for their 
 gracious permission to use this material.
  
 There are others along the way with whom we have shared ideas and who 
 have influenced our thinking, including Dale Atkins, Chris Dent, Hahn Tram, 
 Kevin Clanahan, Jeff Gruber, and Shaun Achmad. And there are others, although 
 not acknowledged specifically by name, whose contributions are also appreciated.
  
 We couldn’t have completed this work without all of you.
  
 xv",NA
Introduction,"One of our colleagues reported the following (the airline name and locations have 
 been removed).
  
 I was sitting in the Airport VIP Lounge waiting for my flight 
 and reviewing the manuscript for this book. I looked at the 
 departures screen and saw that my flight was not listed; yet 
 an earlier flight, which had already departed, was still 
 showing. I went to the desk to get my flight information. 
 When I asked why the discrep-ancy was shown on the 
 display screen, I was told,“We’ve requested many times for 
 that problem be fixed, but they keep telling us that it’s too 
 expensive to modify the program.”
  
  
 I suggested that perhaps a copy of the book should be 
 made available to the Information Technology (IT) staff of 
 the airline. With flexible software, this program 
 modification would be easy and inexpensive to make 
 [Scheuer 2004]!
  
 Many IT experts talk about flexible software. They say that it is a good thing 
 and that ease of modification of a software system is one of its most important 
 attributes, but they do not say how to do it. We do. We understand techniques and 
 principles of building flexible software as well as the theory behind these 
 techniques. The authors are seasoned IT professionals with over 50 years of 
 combined experience, much of it developing flexible systems and flexibility 
 techniques.
  
 The lack of flexibility has been recognized for a long time; we are bringing 
 forward into present practice many of the critiques and design
  
 xvii",NA
The Authors,"Bruce Johnson
  resides in Estes Park, Colorado, and is a retired associate 
 professor at Xavier University in Cincinnati, Ohio, where he taught infor-mation 
 and decision sciences for 17 years. Prior to that, he operated his own software 
 consulting company, held various positions with software firms as an independent 
 consultant, and was manager of systems and programming for Billboard 
 Publications. He started his career as an analyst and data center manager with 
 Procter & Gamble. His technical interests include the management of technology 
 and the effects of technical knowl-edge on decision making.
  
 He is currently researching design and implementation principles of flexible 
 computer systems and is developing (in Java) an information-structure generator 
 for flexible systems. He has an M.B.A. and Ph.D. in operations management, 
 information systems, and organizational behavior from the University of 
 Cincinnati and B.S. and M.S. degrees in civil engineering from Washington State 
 University. Bruce has been writing and researching the subject of flexible 
 computer systems for more than a dozen years and has coauthored a number of 
 papers dealing with the subject of computer software flexibility.
  
 Walter W. Woolfolk
  is information systems director for Taylor Distributing in 
 Cincinnati, Ohio. Prior to that, he was a systems architect with Unisys Europe-
 Africa, data administration manager for Federated Department Stores Corporate, 
 held various other IT management and technical posi-tions, and taught graduate 
 and undergraduate database systems courses at the University of Cincinnati. His 
 technical interests include the charac-teristics of flexible information systems, 
 structure/process differentiation in systems, and dictionary-based systems. He has 
 a B.A. in mathematics from Graceland College in Iowa and has done graduate 
 work in philos-ophy and general systems theory at Indiana University and the 
 University of Louisville.
  
 xxi",NA
INTRODUCTION ,NA,NA
I,NA,NA
TO FLEXIBILITY,"This book offers an approach to system development that reduces the need for 
 maintenance by the information technology (IT) department. For most 
 organizations, the demand for increased automation of business processes exceeds 
 the capacity of the IT function to deliver satisfactory results, and the gap is 
 increasing. People and organizations are aware that there is a problem, but the 
 identification of what is wrong is often incorrect. Incorrect diagnosis will not lead 
 to effective treatment or cure. Part I provides the reader with an awareness of 
 where the real problem lies —with inflexible software systems — and introduces 
 the advantages of flexible software design.
  
 Chapter 1 examines from a fresh perspective the lack of success of many, 
 if not most, of today’s IT projects and systems. It exposes the lack of 
 flexibility that results in maintenance backlogs, com-pounding costs, 
 deferred development, customer dissatisfaction, and declining competitive 
 position.
  
 Chapter 2 introduces flexibility as an improved approach for soft-ware 
 design and system development. It discusses the characteristics of flexible 
 systems and recognizes historical progress in the direc-tion of flexibility. It 
 also explores a series of pervasive and persistent misconceptions about IT, 
 myths that impede the application of IT to a changing world.
  
 Chapter 3 addresses the shift in thinking that is required. We need to shift 
 our objective from functional accuracy with regard to current business 
 requirements to adaptability to future changes in business requirements. 
 The specific outcome we are looking for is ease of maintenance. Systems 
 that are easy to maintain permit",NA
Chapter 1,NA,NA
The Serious ,NA,NA
Problems with IT ,NA,NA
Today,"Information technology (IT) publications chronicle the troubles with today’s 
 computer systems. These difficulties are also a topic of interest in the popular 
 press. Most relevant statistics of these “troubles” deal with development or 
 operational problems.
  
 Whitmarsh [1995] and others quote disturbing statistics provided by the 
 Standish Group International. Defining a successful computer appli-cation 
 development project as “one that is delivered on time, on budget and with most 
 of the features as originally specified,” they reported the success rate in Fortune 
 500 companies as a shocking 9 percent. Among those companies with annual 
 revenues exceeding $100 million, a 31 percent cancellation rate and a runaway 
 project rate of 53 percent were reported.
  
 The situation has not improved much, if at all, since these statistics were 
 published in 1995. The Standish Group International more recently reported the 
 following: 63 percent of information technology projects had time overruns, 45 
 percent faced cost overruns, and 23 percent were cancelled before completion or 
 never implemented [Elkins, 2001].
  
 In his study of system economics, Keen [1991, pp. 18, 44] reports that no large 
 system fell into the “easy to deliver category, the average large system 
 development lead-time being seven years.” Little needs to be said about the perils 
 of undertaking a large or even a medium systems development initiative. It is 
 necessary only to read the newspaper or talk to industry colleagues.",NA
1.1 The Industrywide Maintenance Problem,"For each dollar spent on development, typically 40 cents goes to nondis-cretionary 
 maintenance annually for the life of the system.
  
 Systems maintenance is not a happy topic. Most executives say that their 
 businesses are changing faster than their IT organizations can keep critical systems 
 current. Yet IT cannot afford to make any major modifi-cations because so much 
 of the technology budget is devoted to incre-mental maintenance [Lytton, 2001].
  
 The industrywide maintenance problem has people frustrated. The frustration 
 is most acute at Fortune 1000 companies. A recent Crossroads-OSA poll of 200 
 executives showed that only about 3 percent of their companies’ programmers are 
 assigned to new systems development. Almost 52 percent are devoted to software 
 maintenance. Just over 45 percent are",NA
1.2 What Is Wrong with Nonflexible Systems? ,NA,NA
Two Cautionary Tales,"This book is not about how to do maintenance. It is about how to 
 not
  do 
 maintenance.
  
 To illustrate the problem of inflexibility, we present two tales of problems caused 
 by inflexible systems (Exhibit 1.2 and Exhibit 1.3). The first is true; the second is 
 representative of many of the authors’ frustrations in dealing with inflexible 
 systems that we have inherited.
  
 The problem at the aluminum plant was not a missed requirement in the 
 traditional sense; the original systems accurately reflected the plant’s organization. 
 Rather, it was a failure to see the variability of the organi-zation as a requirement 
 on the system. Consequently, what was variable in the real world of the plant was 
 designed as a static property of its computer systems (for example, by embedding 
 the organization scheme in the identifiers of production, inventory, and financial 
 files).",NA
1.3 The Typical IT Environment: No Time to Do It ,NA,NA
Right — Time to Do It Over!,"As the maintenance backlog increases, costs compound, devel-opment is deferred, 
 customer dissatisfaction grows, and compet-itive position declines.
  
 The high maintenance costs, extensive project backlogs, and frequent service 
 interruptions caused by inflexible software systems are painfully familiar. The 
 experts agree.
  
 For the most, part we’re still using the same traditional design 
 methodologies that were originally designed to address far more static 
 business information needs. These static applications aren’t flexible 
 enough to meet our current needs and are forcing an upheaval on the 
 application front…. You need a new approach",NA
1.4 Summary,"Many sources report disturbing statistics regarding the lack of success of 
 many, if not most, of today’s IT projects and systems. This lack of success 
 appears to have been with the IT industry for a long time, and the reasons, 
 in many cases, have not been properly diagnosed.",NA
Chapter 2,NA,NA
The Reality of ,NA,NA
Imperfect ,NA,NA
Knowledge,"Flexible systems are needed because we cannot predict the future. Because 
 organizations change over time, complete knowledge of a system’s require-ments, 
 in the traditional sense, is necessarily imperfect. Some requirements lie in the 
 future, and they are unknowable at the time the software system is designed or 
 being built. The traditional objective of system design is functional accuracy, but 
 when designers do not look beyond the current requirements, the result is often 
 inflexible software. Acceptance of the reality of imperfect knowledge of 
 requirements adds a new and funda-mental objective — adaptability to functional 
 change. That adaptability is essential to good system design.
  
 Parnas [1979] perhaps overstates the case when he says, “Any design can be 
 bent until it works. It is only in the ease of change that they differ,” but the 
 overriding importance of business change on system design is clear. The automated 
 system is necessarily subject to continual modifi-cation to maintain synchronization 
 with unfolding requirements. We want to design the software to cope with change 
 affordably, so as to maximize the possibility of maintaining this synchronization 
 without gross disruption or modification costs that are out of proportion to the 
 magnitude of the corresponding real-world changes.
  
 An improved approach — what we call flexible systems and others call organic 
 or adaptable systems — is required. We have had favorable and ongoing 
 experience with techniques that, when applied with care, allow automated systems 
 to flex with their real-world counterparts.
  
 13",NA
2.1 Flexibility: An Improved Way of Thinking,"We have had favorable and ongoing experience with techniques that, 
 when applied with care, allow automated systems to flex with their 
 real-world counterparts.
  
 Two basic approaches have been taken to flexibility in computer systems. 
 Boogaard [1994] characterizes these as active flexibility and passive flex-ibility. 
 Active flexibility is basically fast modification. Many techniques have been devised 
 for speeding up the process of modifying computer systems to meet new 
 functional or operational requirements, including automatic program modification 
 as seen in application generators. Active flexibility focuses on the modification 
 process. In recent years, this has been the approach taken almost exclusively. 
 However, the continuing crisis level of the maintenance backlog demonstrates the 
 futility of relying on the active-flexibility approach alone. In contrast, Boogaard’s 
 passive flexibility is built in. The computer system is designed to require inherently 
 less modification, fast or otherwise; flexibility focuses on the system itself. We are 
 concerned throughout this book with this latter approach of built-in or planned 
 flexibility.",NA
2.1.1 Real World/Automated World,"We are concerned throughout this book with … built-in or planned flexibility.
  
 A computerized information system can be viewed as a representation of a real-
 world (RW) system that is actually, relative to the real-world system, an 
 automated-world (AW) system. Systems development is therefore a series of 
 transformations [Wand and Weber, 1990, p. 123], as shown in Exhibit 2.1:
  
 Real-World
  
 Real-World
  
 Automated-
  
 Automated-
  
  World
  
  World
  
 System
  
 Model
  
 Model
  
 System
  
 Analyze
  
 Design
  
 Build
  
  
 Exhibit 2.1.
  
 Real-World/Automated-World Transformation",NA
2.1.2 Synchronization and Resynchronization,"The real world 
 changes
 ; the automated world is 
 modified
 .
  
 These transformations, taken together, synchronize the functionality of the 
 automated-world system with that of the real-world system. When the real world 
 subsequently undergoes some change in functionality, then the automated-world 
 system needs to be resynchronized with it or else fail to continue to be useful 
 [Weinberg, 1975, p. 254]. We will say that the real world
  changes
  and the automated 
 world is 
 modified
 . For example, the change in a payroll procedure that requires a 
 new type of deduction in the real-world payroll system requires a corresponding 
 modification 
 to 
 the 
 automated 
 payroll 
 system. 
 Synchronization 
 and 
 resynchronization are, of course, software development and software 
 maintenance, respectively. Maintenance repeats the transformation steps of 
 development, but starts with a changed real-world system, analyzes the change in 
 the context of the existing automated-world system, and designs and builds a 
 modifica-tion to the automated-world software.
  
 The transformation-series concept is deceptively simple but fundamen-tal, and 
 it will be employed extensively throughout this book. Primarily, it reminds us that 
 the real world and the automated world are different, with significantly different 
 characteristics. The main intention of this book is to explore how, despite the 
 differences, the inherent flexibility of the real world can be carried into the 
 automated world.
  
 IT people expect users to always know what they want, and they can 
 get exasperated when they don’t. Business people have a right to 
 change their minds, because the business changes [Ellen Gottesdiener 
 in Horowitz, 2004].",NA
2.1.3 Flexibility and Local Modifiability,"This book proposes that a flexible system, in basic operational terms, is one that 
 can be resynchronized with changes in the real-world system almost entirely 
 through user-controlled data-value modifications with minimal or",NA
2.1.4 Natural and Artificial Limits,"We already know that most AW systems are not flexible enough. In contrast, we 
 observe that RW systems are flexible enough.
  
 The organization as a whole is able to adapt more fluidly than the 
 software upon which it has grown dependent. In fact, software 
 systems are usually the least responsive element in many organizations 
 today [Cox, 1986].
  
 Let us agree that if AW systems could be modified as readily as the corresponding 
 RW systems are changed, that would be flexible enough.",NA
2.2 What Is Flexible Software?,"Designed well, flexible software can serve an organization over many decades and 
 multiple technological generations.
  
 Let us begin with another question. What is the difference between 
 “good”software and “bad” software? Good software serves an organization well, 
 and bad software does not. Let us assume that any software that is successfully 
 implemented is good initially. Does good software go bad? Yes. Good software 
 goes bad when the cost of keeping it good is perceived as being greater than the 
 cost of replacing it. By keeping it good, of course, we mean modifying it to 
 accommodate changes in business requirements. Flexible software is good 
 software that can be kept good at low cost by accommodating change with a 
 minimum of IT intervention. Designed well, flexible software can serve an 
 organization over many decades and multiple technological generations.
  
 Throughout the book we use the term “generic” to describe software 
 components that can be used in a variety of different ways, depending on the 
 needs of the individual organization, with a minimum of interven-tion from the IT 
 staff. The term “generic” may carry with it a connotation of vanilla, or basic, or 
 unsophisticated. As we will demonstrate, this need not be the case. Careful 
 analysis of business requirements, and equally careful design, can result in highly 
 sophisticated software that is easily maintained by business staff.",NA
2.2.1 Structural Stability,"Flexible computer software requires stable information structures. This is not an 
 oxymoron. In the design of a flexible information system, something static can 
 and does serve as the foundation for something flexible. The more static a 
 structure becomes (i.e., the more variability is excluded), the more generic it 
 becomes, both in the things it represents and the relationships among them. Thus, 
 in static structures, changes are viewed as new interpretations of software 
 components rather than as modifications to those components. For example, a 
 generic “person” entity in an infor-mation system can be interpreted variously as 
 an employee, manager, or contractor without needing to alter the declaration of 
 the entity itself. This is exactly what happens in real-world systems. Individuals 
 wear different hats. Sometimes a single individual wears more than one hat. 
 Sometimes new hats come into existence. Sometimes the hats need to be 
 reassigned. Accommodating new hats or assigning hats differently should not 
 require major software modification and the high cost that goes with it. 
 Throughout this book, we will provide examples of how to achieve structural 
 stability.
  
 By way of preview, here are some key points of stable information structures. 
 The characteristics of stable information structures are outlined in the following 
 subsections.
  
 2.2.1.1 Invariant, Unique, and Meaningless Identifiers
  
 One of the deadly sins of software design is poor design of record identifiers, or 
 keys. The use of unstable keys is a major source of maintenance as well as the 
 cause of a host of other problems. There is more than simple uniqueness to better 
 key design. We will discuss that better design.
  
 2.2.1.2 Generic Entity Types
  
 A major emphasis in designing a flexible software system is identifying entities, 
 those real-world things about which we want to store information. The objective 
 is to define only entities that are actually needed, distin-guishing between things 
 that truly differ from each other and things that are simply variations on a theme. 
 For example, “employee” and “student”could be considered categories of a single 
 entity — “person.” “Building”",NA
2.2.2 Processes That Exploit Stable Structures,"When information structures remain constant, software developers can construct 
 stable and reliable processes in which software behavior can easily be modified to 
 handle most processing eventualities. Although the development costs of these 
 processes may be higher than with traditional development, it is, by and large, a 
 one-time investment. Some of the basic characteristics of this software are listed 
 below. These points assume, of course, that stable, flexible data structures serve as 
 the software foundation. Each is developed fully in subsequent chapters.
  
 Assume the most general case with respect to cardinality
 : If an attribute can 
 potentially have multiple occurrences, write the pro-gram to handle 
 multiple occurrences, even if today’s records have only one occurrence.
  
 Interact with an external cardinality regulation facility
 : Store the rule for the 
 number of allowable occurrences in the software and write the program to 
 use that stored number to control processing. This is really powerful: 
 imagine altering cardinality relationships without modifying structural 
 declarations.
  
 Provide generic explosion/implosion capability for bill-of-material-like structures, 
 including recursive nested structures
 : This will be explained later in the context 
 of entity typing. It is possible to develop a general design that provides for 
 nested recursive rela-tionships within an entity, one that offers potentially 
 great savings on software maintenance.
  
 Provide generic ultimate-ancestor/ultimate-child detection in bill-of-material-like 
 structures
 : Given any starting point in a bill-of-materials-like structure, the 
 highest and lowest levels of the struc-ture can readily be determined.
  
 Provide automatic or semiautomatic adjustments when a level of a bill-of-material-like 
 structure is moved up or down
 : Components in the structure can be added or 
 deleted at any level, and the parent and child relationships remain intact. 
 Components can be moved from one branch to another.
  
 Provide for enforcement of integrity rules
 : This includes restrictions on cycles and 
 ensures consistency of type hierarchies.
  
 Determine an outcome based upon a complex interaction of multiple parameters
 : This 
 can take multiple forms, two of which are explored in detail: dynamic 
 condition search and general-purpose evaluation.",NA
2.3 Change or Die,"Real-world systems must change or they die. However, most automated-world 
 systems are so brittle that, when they are modified, they die or are crippled unless 
 costly life-support measures are taken. To continue its life beyond the present, the 
 automated-world system must ideally be as flexible as the real-world system it 
 represents. A good example of such a flexible system was developed at the 
 Investment Trust Bank in Vienna [Woolfolk et al., 1996]. During initial 
 development in 1990, approximately 30 work processes were incorporated into an 
 automated system. This development project consumed 140 person-months of 
 effort.
  
 During the early years of system operation, over 170 work processes were 
 added to the system, requiring over 2700 modifications. Specially trained and 
 designated system end users maintained the control data that defined the work 
 processes. IT professionals did not make these modifi-cations. The bank’s original 
 requirements were not detailed; instead, the systems development effort 
 concentrated on achieving flexibility. Programs were designed to process 
 elementary actions that could be added or modified independent of existing code 
 by manipulating the control data. Due in large part to this adaptability, the bank 
 has enjoyed an enviable record of rapid response to challenges, market 
 opportunities, and changing regulatory demands.
  
 These 2700 modifications required only 24 person-months of effort over three 
 years. This is a remarkably low level of effort in comparison with nonflexible 
 systems. Applying Keen’s [1995] cost dynamics, one would expect these 
 modifications to require roughly 168 person-months (more than the original 
 development effort). Initial development would result in 40 percent maintenance 
 for each of these three years, or 56 person-months per year. The 2700 
 modifications made at the Investment Trust Bank included much more than 
 routine maintenance, and they were accomplished at 14 percent of the typical 
 effort.",NA
2.4 Evolution of Flexibility,"Since the dawn of computer programming and computer systems, there have been 
 efforts to make systems easier to modify and to reduce the side effects from such 
 modifications. Three clear examples are:
  
 1. 
  
 More flexible handling of “constants”
  
 2. 
  
 Adoption of structured programming techniques 3. 
  
 Introduction of database management systems",NA
2.4.1 More Flexible Handling of “Constants”,"Early on, values for elements such as “tax rate” were implemented as literals and 
 embedded in the procedural code. Although values may be relatively stable, they 
 do change over the course of time. Later, they were moved out of procedural code 
 into a “constant section” or “data division,” where they could more easily and 
 more reliably be found and modified. Eventually, some of these “constants” were 
 moved to files where they could be modified without changing and recompiling 
 affected programs. Refer to Exhibit 2.2 for an illustration of this progression. A 
 flexibility progression can easily be seen here. In the first case, the entire program 
 had to be searched for occurrences of values such as “BJ,” whose meanings were 
 not always clear. Then the program had to be modified, recompiled, and tested. In 
 the second case, only the data portion of the program had to be searched. With 
 luck, the value was contained in a meaningful data name such as SALESPERSON. 
 But the program still had to be modified, recompiled, and tested. In the third case, 
 no programs needed to be changed or compiled, and only the external file had to 
 be changed. And, of course, the changes still needed to be tested, but the chances 
 of side effects were reduced and, if the logic and procedure were done right, could 
 be eliminated.
  
 We introduce a tabular notation in Exhibit 2.2 that is used throughout the 
 book. The tabular notation is a convenient way to define various sample relations:
  
 Label: | A-ID | B-ID || Attribute 1 | Attribute 2 | . . . | Attribute n |",NA
2.4.2 Structured Programming,"The adoption of structured programming techniques increased program-mer 
 productivity by almost ten times and fostered easier program main-tenance. In 
 1960, a professional programmer would code in the neighborhood of 12 lines of 
 tested code per day.
  
  
 Structured programming is defined as a method of developing program logic 
 using only three control structures. The three are: the sequence, if-then-else, and 
 looping. Structured programming was designed to avoid the jumps in logic that 
 were embodied in the “GO TO” statement that was in popular use and tended to 
 create “spaghetti code.”
  
  
 Edsger W. Dijkstra of the Netherlands wrote a letter to the editor of the 
 Communications of the ACM
  in March 1968 entitled “GO TO Statement Considered 
 Harmful.” His conclusions were based upon work presented by Bohm and 
 Jacopini at an international conference in Israel in 1964 and published in 1966 in 
 Communications of the ACM
 . Dijkstra stated that the quality of a program was 
 inversely proportional to the number of GO TOs. (Particularly programmers 
 trained in FORTRAN, a heavy user of GO TOs, had difficulty visualizing 
 programs without GO TOs.) But remem-ber, it is not the absence of the GO TO 
 that makes a structured program; it is the proper utilization of the three basic 
 control structures.
  
 Yet, like so many things in the history of computing in the United States, the 
 concept was not taken seriously until IBM took an interest. Two IBM employees, 
 Harlan Mills and F. Terry Baker, were able to demonstrate the practical aspects of 
 the technique while working on a 
 New York Times
  project [Baker, 1972]. The 
 structured programming tech-nique became widely accepted and dramatically 
 increased the lines of tested code produced per day. While the increase in 
 productivity from structured programming and the like is important, as well as 
 considerable,",NA
2.4.3 Database Management Systems,"In the early days of batch-process-driven systems, electronic record keep-ing 
 mirrored paper record keeping. The business rules were maintained in the heads 
 of the staff. Design of the sequential files was typically based on input and output 
 used to support traditional paper processes, i.e., lists sorted in a specified order. 
 Interpretation of the data was done in the programs that did the processing. 
 Exhibit 2.3 illustrates such a batch process.
  
 Data input was a batch process, often very complex, involving sorting and 
 matching records. Output could be relatively simple to produce if it came from a 
 single file. If multiple files were required to produce the output, the programming 
 became increasingly complex. For example, from the “class” file shown in Exhibit 
 2.3, you could produce the following lists by varying the sort order.
  
 1. 
  
 Instructor’s list of students in the class, with students in alphabetical 
  
 order 
  
 2. 
  
 List of classes a specified instructor is teaching 
  
 3. 
  
 List of classes a specified student is taking
  
 If you wanted to add the student’s major and phone number to the instructor’s list 
 (list 1), you would need to add programming to retrieve that information from the 
 “student” file.
  
 At that time, processing time and machine efficiency drove most design 
 decisions. The design goal was to make processes as efficient as possible. Logical 
 data design was not necessarily a high priority and data redundancy was common. 
 For example, in the above design, if the student’s name changes, you would need 
 to change it in the student file and in all class records where it occurs.
  
 The introduction of database management systems and the processing capacity 
 of modern computers have combined to give developers the tools to eliminate 
 data redundancy. The elimination or reduction of redundancy, among other 
 things, reduces the number of potential side effects. For example, making a name 
 change to most — but not all — records. Or, again, changing the class or 
 instructor in some records but not all. Having to make the change in only one 
 place makes it easier and faster to modify the system, making it more flexible.
  
 Even with flexibility improvements such as these, systems still are not very 
 flexible. The goals of greater processing efficiency, and more recently",NA
2.5 IT Misconceptions and Flexibility Concepts,"When developing flexible systems, mind-set and understanding are just as 
 important as — if not more important than — tools and techniques. This section 
 presents a series of pervasive and persistent misconceptions about IT that have 
 led to such problems as failed and runaway projects and the severe maintenance 
 burdens noted previously. These IT miscon-ceptions have acquired the status of 
 industry myths, in line with Roget’s [Roget’s II, 2003] definition of a myth:",NA
2.6 Summary,"Over the life of an information system, it is maintenance, not 
 development, that is the main work. And within maintenance, it is 
 resynchronization, not error correction (“debugging”), that is the 
 dominant activity.",NA
Chapter 3,NA,NA
"Outcome, Not ",NA,NA
Methodology,"In their 1996 paper, “The Problem of the Dynamic Organization and the Static 
 System: Principles and Techniques for Achieving Flexibility,” Wool-folk, 
 Ligezinski, and Johnson emphasized that development of a flexible information 
 system requires a shift in thinking. The design objective is no longer functional 
 accuracy with regard to current business requirements, but rather adaptability to 
 changes so that current and future requirements can be met.",NA
3.1 Mired in Methodology,"The design objective is no longer functional accuracy with regard to current business 
 requirements, but rather adaptability to changes so that current and future 
 requirements can be met.
  
 Many software development methodologies already exist, and new ones are 
 introduced almost daily. The history of these methodologies includes the waterfall 
 method, object-oriented (OO) design, and rapid application development (RAD). 
 More recently introduced methodologies include the rational unified process 
 (RUP), adaptive software development (ASD), and the many agile development 
 methods.
  
 35",NA
3.1.1 Myth of Methodology,"The industrywide focus on improving methods has led to the myth of 
 methodology:
  
 Myth: Good methods produce good systems.
  
 Reality: Good methods can and do produce bad systems, especially when 
 the system perfectly fitted to current requirements cannot be efficiently 
 adapted to unanticipated future requirements.
  
 Organizations rely increasingly on system development methods to improve the 
 precision with which requirements are elicited and implemented.",NA
3.1.2 Myth of Rapid Application Development,"As the pace of change in the real world increases, organizations have reacted by 
 finding ways to speed up the pace of computer systems development. That it is 
 better to go faster is the myth of rapid application development (RAD).
  
 Myth: The race against change is won by going faster — rapid application 
 development.
  
 Reality: Rapid application development may simply lead to faster 
 development of inflexible systems if adaptability to future require-ments 
 has not been considered.
  
 Treating software development as a race rather than as the dance that it really 
 is leads to this myth. It results in application of method-oriented solutions to an 
 outcome-based problem. RAD tools and methods are valuable additions to the 
 developer’s toolkit, but they are not magic. The result of rapid, streamlined 
 development of new systems (or more often replacements for old systems) can 
 simply be inflexible systems that are built faster. The erosion of development 
 capacity by maintenance is accelerated as inflexible development is accelerated. 
 Because techniques of rapid application development may not be transferable to 
 maintenance work, the maintenance backlog may increase more rapidly. The point 
 of decreasing return on IT resource investment arrives much sooner, and attention 
 is diverted from solving the real problem — the maintenance burden created by 
 inflexible systems. An existing inflexible automated-world system is not a green 
 field amenable to fast footwork but more like a minefield requiring extreme care in 
 moving about. Rapid application",NA
3.2 Software Engineering Shifts,"The specific outcome that we are looking for is low maintenance, because it allows 
 organizations to respond to business needs as they develop and change over time.
  
 The popularly recognized methodologies address issues associated with the initial 
 system development, including requirements uncovered during the development 
 process itself, but they do not address, in any serious or detailed way, the key 
 postinstallation issue: maintenance. So exactly what outcomes should we be 
 looking for? Obviously, all of the traditional development project outcomes 
 addressed by one of more of the mentioned methodologies — meeting 
 specifications, being on time and on budget, customer satisfaction, and the like — 
 are required outcomes. But these are not enough when months or even years after 
 the system is installed it becomes too cumbersome to modify to meet ongoing 
 business needs.
  
 Proponents of methodologies may recognize that postinstallation issues do 
 exist. The following quote comes from a book on an object-oriented analysis and 
 design approach.
  
 But the real measure of goodness may not be apparent for several years 
 after a system has been put into operation. Soft-ware lasts forever; many 
 large organizations around the world are now maintaining application 
 systems that are older than the programmers who maintain them! From 
 this perspective, a good design is one that balances a series of tradeoffs 
 in order to minimize the 
 total cost
  of the system over its entire productive 
 life span. Obviously, we want a system that is reasonably efficient, and 
 we want it to be elegant, user-friendly, portable and so forth. But we 
 also want it to be reasonably easy to test, modify, and maintain. At least 
 half of the total cost of the system — and often as much as 90%! — 
 will be incurred 
 after",NA
3.2.1 Myth of the Successful System,"A flexible system is supposed to be modified.
  
 Managers are often uncomfortable with change, because it tends to upset both 
 people and information systems. This yields the myth of the suc-cessful system.
  
 Myth: Successful computer systems usually generate few, if any, 
 modification requests.
  
 Reality: Successful computer systems generally generate continuous 
 demands for modification.
  
  
 Often the unsuccessful system is mistaken for a successful one, and vice versa. 
 The system that is unused does not generate requests for the system to do more. 
 On the other hand, the system that is really being used effectively is subjected to 
 high levels of customer demand. “If you can produce my design report, why can’t 
 you also calculate shop times?”And once that has been done, “Why can’t you 
 make materials order lists by supplier?” Because such systems are “never finished,” 
 they are often looked upon as failures. The truth is, “Use it or lose it.” Successful 
 computer systems generally generate continuous demands for modification. Thus, 
 it is a counterintuitive managerial truth that being bugged for money and resources 
 for modifications is really a sign of a successful, not a failed, system. Inability to 
 keep up with demand for modifications is a sign of an inflexible “successful 
 system.”
  
  
 A system “success metric” that includes the level of usage and modi-fication 
 requests by system customers would be a useful indicator of",NA
3.2.2 Myth of the Naïve Customer,"The cost of adding tollbooths to a bridge should be independent of the length of the 
 bridge.
  
 System customers generally perceive that the level of effort needed to make 
 systems modifications is out of proportion to the change requested:“All I wanted 
 was for the system to reflect that now one person often holds two jobs. What’s the 
 big deal? How can it take six people six months? What do you mean you have to 
 modify the information structure? And what’s to test? You keep talking about all 
 the testing that will be needed; it’s just a simple request!” This common scene 
 from the experience of IT managers has led to the myth of the naïve customer.
  
 Myth: Customer perceptions of what it should take to implement systems 
 modifications are grossly unrealistic; they do not appreciate how complex 
 automated systems are. Thus, IT needs to educate customers in this 
 matter.
  
 Reality: Customer perceptions of what ought to be the case are realistic. 
 What they do not perceive correctly is the inflexibility and fragility of 
 current systems. IT must learn how to develop flexible and stable systems.
  
 In one sense, the customer’s feeling for the size of a modification is not 
 realistic. IT customers generally do not appreciate the internal com-plexity of their 
 computer applications. And when a large estimate is made for what seems to the 
 customer to be a small modification, the estimate more or less accurately reflects 
 the size of the work, not the size of the request. But despite the efforts to educate 
 the customer about system complexity, the discrepancy between the customer’s 
 intuition and the current reality persists. After all, the customer deals with the real-
 world system and is an integral part of it, while the computer application is only a 
 representation of the real-world system. Consequently, there is an almost 
 inescapable expectation on the customer’s part that the effort required to modify 
 the computer system should be approximately the same size as, if not smaller than, 
 the effort expended on the real-world system to implement the same change. In 
 this sense, the customer’s intuition should be right, particularly when the 
 modification seems unrelated to the size of the system. Like adding tollbooths to a 
 bridge, the cost of adding tollbooths to a bridge should be independent of the 
 length of the bridge.",NA
3.2.3 CRUDmudgeons: Information Structure ,NA,NA
Is the Critical Foundation,"On the surface, the IT world appears to be moving very fast. Yet, in reality, the 
 underlying foundation does not change all that rapidly or perhaps at all. Data still 
 must be collected, validated, organized, stored, updated, deleted, and disseminated 
 as, hopefully, useful information from which timely and enlightened decisions can 
 be made. The most critical aspect of this underlying foundational technology is the 
 organizing and storing of data — the database in some form.
  
 By far the majority of systems analysis and design activity is centered on 
 process. This is not necessarily surprising, as most users of IT systems are 
 engulfed in their processes, i.e., what these systems do. This process orientation 
 turns out to be unfortunate for system flexibility. When the data exists, is accurate, 
 is properly and flexibly organized, and is properly maintained, the vast majority, if 
 not all, of the processes can be supported both in its current form and as the 
 business inevitably changes. It is easier and less disruptive to modify process than 
 it is to modify data structures. With flexible information structures, even process 
 code often requires little or no modification at all.
  
 We focus much of our effort, therefore, on the analysis and design of the 
 CRUD (create, read, update, destroy) portions of the systems. In effect, we are old 
 CRUDmudgeons. The fact is that with well-analyzed and well-designed flexible 
 databases, virtually any processes/techniques are not only eminently possible, but 
 they are fully supported, and systems devel-oped using them will be orders of 
 magnitude more flexible.
  
 We do understand that processes are important. We would apply to processes 
 the same standards regarding quality of outcomes that we apply to information 
 structures.",NA
3.2.4 Object-Oriented Approach — Another Cautionary Tale,"Inflexibility is its own punishment.
  
 In doing the programming, developers of flexible system generally use an iterative 
 prototyping approach. The assumption is that business experts are satisfied only 
 when they have a chance to test-drive a product — the",NA
3.3 Summary,"Development of a flexible information system requires a shift in thinking. The 
 design objective is no longer functional accuracy with regard to current business 
 requirements, but rather adaptability to future changes in business requirements.
  
 While we must be “methodical” in our system-development efforts we 
 must not become mired in methodology.
  
 Recognized, popular software engineering methodologies address issues 
 associated with the initial system development, including requirements 
 uncovered during the development process itself. They do not address 
 postinstallation issues such as low mainte-nance and the ability to easily 
 respond to changing business needs. The “myth of methodology” shows 
 that bad outcomes can proceed from “good” methods. Methods are not 
 the answer.
  
 The “myth of rapid application development” tells us that without 
 attention to flexibility, inflexible systems are just made faster while the 
 maintenance burden increases.",NA
Chapter 4,NA,NA
Realignment of Roles,"The development and support of an information system is a complex undertaking, 
 involving many individuals. The development and support of a 
 flexible
  information 
 system adds additional responsibilities for the participants, but it also provides 
 benefits to the business and technical staff, to individual business units, and to the 
 organization as a whole.
  
  
 Flexibility brings additional responsibilities for business and technical staff, 
 including, but not limited to, the following:
  
 Business staff must fully participate in the development, testing, and 
 subsequent operation of a flexible system. They cannot dis-tance 
 themselves from any of these phases. They will ultimately maintain the 
 software system, so they must understand how it meets their needs today 
 and in the future.
  
 Technical staff must design and develop the software system so that, once 
 it is in operation, they can step back and be assured that the business staff 
 can continue to maintain the software.
  
  
 The benefits of flexible systems to the business and its staff include, but are not 
 limited to, the following:
  
 Enabling business people to do their jobs more effectively without having 
 to develop work-arounds for systems that are unable to respond to their 
 business needs.
  
 The ability to respond to business opportunities and threats without 
 waiting for the maintenance logjam to clear.
  
 47",NA
4.1 Roles and Responsibilities in ,NA,NA
Traditional ,NA,NA
and Flexible Development,"No one person can provide all the knowledge, expertise, or time required either to 
 develop a large formal system or to evaluate vendor-developed software products. 
 Many individuals are typically involved. Participants fall into three major groups, 
 or roles:
  
 1. 
  
 Managers
 : those who set direction and manage the business and 
  
 IT 
 resources 
  
 2. 
  
 Customers
 : those who use a system to do their business 
  
 3. 
  
 Developers
 : those who do the technical work of building and 
  
 maintaining 
 a system
  
 Unfortunately, these three groups are frequently at odds with each other. For 
 example, developers often believe that customers do not know what they want, 
 either because requirements are vague or because they keep changing. Customers 
 often believe that developers speak a foreign language and that it takes them much 
 too long to do everything. Fingers are often pointed in blame when a system-
 related business failure occurs. The failure may be that the system did not perform 
 as expected. That type of failure may result from incorrect programming, or poor 
 commu-nication about the business requirements, or inadequate testing, or the 
 overlooking of possible scenarios in defining the requirements, or other reasons. 
 Another type of failure is that system-related work was simply not completed, 
 often due to lack of technical resources. All of these issues reflect a “myth of 
 parallel perceptions” that must be understood and overcome if flexible software 
 systems are to be developed.",NA
4.1.1 Myth of Parallel Perceptions,"In the daily pressure to get things done, we often fall victim to the myth of parallel 
 perceptions.
  
 Myth: Managers, customers, and technical staff have shared per-ceptions 
 of the business, the technology, and their interaction. Reality: Managers, 
 customers, and technical staff speak widely different languages and have 
 different views of both real-world and automated-world systems.
  
 This myth is different from the others that we examine throughout the book. We 
 say
  that we do not really believe the myth, but we 
 act
  as if we 
 do
  believe it. 
 Furthermore, although we say that we understand that there are serious 
 communication difficulties among managers, customers, and technical staff, we 
 often do not try hard enough to overcome them.
  
 Business staff must learn and understand flexible software system 
 development as they work with the technical staff. Technical staff must obtain 
 sufficient knowledge of the business to be able to effectively communicate the 
 nature of flexible software systems and their develop-ment to the business staff. 
 This requires dedication to the process as well as time and patience.
  
 All persons/roles involved in system development have professional 
 responsibility, responsibility to the organization as a whole, and respon-sibility to 
 their individual business units or specialties. Role responsibilities exist in both 
 traditional and flexible development, but they expand when flexibility is the goal. 
 The primary expansion can be thought of in terms of each camp spending time in 
 the other camp to fully understand the partnership required for flexible software 
 development.
  
 Exhibit 4.1 and the following discussions presenttraditional roles in system 
 development as well as the added responsibilities for the flexible approach. The 
 additional responsibilities are not trivial. They require understanding of the 
 business, dedication to the organization, and most importantly, a focus on the 
 future. That is, they require focus on what can happen after initial implementation, 
 when things change.
  
 We have assumed that customers 
 want
  to be in control of their business, free of 
 the need for IT intervention. Similarly, we have assumed that developers 
 want
  to 
 design creative and flexible approaches that free them from routine maintenance 
 activities. If, for a given project, these two assumptions are invalid, a flexible 
 design is not likely to emerge because it is not important to the participants.",NA
4.1.2 Manager,"The role of manager includes executive management, business manage-ment, and 
 IT management. Managers clearly have a stake in successful system development. 
 Typically, executives establish the vision and strat-egies of the organization, and 
 departmental management identifies the",NA
4.1.3 Customers,"Flexible systems offer the best possibility to achieve “new, improved good old days.”
  
 Customers are individuals who use a system to do their work. They include front-
 line business staff, business supervisors, and what we call “business",NA
4.1.4 Developer,"Developers are the individuals who do the technical work of building systems, 
 both traditional and flexible. They are also generally involved in the maintenance 
 of traditional systems. Typical job titles include developer, programmer, system 
 analyst, system architect, software engineer, and designer.
  
  
 It is critical for developers to understand that an information system is a means 
 to a business end. It is not an end in itself. The following item from a project 
 mission statement identifies criteria for success that apply to any information 
 system project: “Services and systems will be driven by client needs and will 
 exceed client expectations.”
  
  
 Developer responsibilities include:
  
 Translating business requirements into a technical design that will support 
 those requirements 
  
 Developing system from technical design 
  
 Anticipating potential changes in business requirements and devel-oping a 
 system that minimizes the need for IT intervention as those changes occur",NA
4.2 Flexibility Attitudes,"Everyone must be committed to the goal of flexibility.
  
 It is our firm belief that customers, technical staff, and, for that matter, all actors 
 involved in the development of flexible systems must adopt the following 
 attitudes:
  
 Commitment
 : Everyone, from the project sponsors to the technical staff and 
 business staff, must be committed to the goal of flexibility. They must all 
 take the vow of flexibility. Developers and customers must always ask the 
 question, “Might this change in the future?”
 Patience
 : It may take longer to 
 develop a flexible implementation than a specific implementation, at least 
 until you get used to doing it. 
 Persistence
 : Under pressure, developers and 
 customers may be tempted to go with a quick-and-dirty (i.e., rigid) design, 
 with the intention of going back later to do it right. Unfortunately, going 
 back to it is difficult to justify when other work needs to be done.“If it 
 ain’t broke, don’t fix it” becomes the justification for leaving the rigid 
 solution in place. Eventually, the time saved with the quick-and-dirty 
 specific implementation is lost many times over to the effort required to 
 maintain it. No one ever goes back and does it over.
  
 Creativity
 : By this we mean simply thinking in new ways. This is essential 
 and rewarding at the same time for customers and devel-opers as they free 
 themselves from “the way we’ve always done it.”",NA
4.3 Summary,"All participants in the development and operation of flexible sys-tems 
 acquire added responsibilities as well as added benefits. Customers must 
 fully participate in all phases of development and operation. In turn, they 
 are freed from many job limitations brought on by their inflexible software 
 systems.
  
 Developers, managers, and customers must work to eliminate the 
 developer’s maintenance jobs so that they can concentrate on the more 
 creative and professional work of developing flexible soft-ware systems.
  
 With flexibility, the organization gains the ability to adapt to changing 
 business requirements and to compete more effectively. Flexibility frees up 
 the resources of business experts who no longer need to spend time 
 circumventing systems that impede the conduct of their jobs.
  
 All parties must overcome the myth of parallel perceptions and recognize 
 the need to work together to understand both the business requirements 
 and the process of developing flexible soft-ware system.
  
 Above all, all parties to the development of flexible systems must adopt 
 the attitudes of commitment to the process, patience with the process, 
 persistence with and at the process, and creativity. Think in new ways.
  
 When compared with traditional systems, flexible systems represent a paradigm 
 shift in the roles of those who are involved in its development, operation, and 
 maintenance. Customers must be more involved in the development and 
 maintenance of their software systems as well as the operation. Developers must 
 design and build so as to eliminate the developer’s role in maintenance. Managers 
 at all levels are responsible for seeing that this happens.",NA
Chapter 5,NA,NA
UniverSIS: A ,NA,NA
Flexible ,NA,NA
System,"This chapter introduces an information system that was developed with flexibility 
 as the guiding principle. One of the authors implemented this system, University 
 Student Information System (UniverSIS), in the late 1990s at the University of 
 Cincinnati (UC) and has monitored the system’s evolution up to the present day. 
 As will be seen, in that time the system has undergone frequent and even major 
 enhancements with minimal professional IT intervention.
  
 We present a few success stories and then explore two system features in detail 
 from a business perspective, focusing on the benefits to the university and its 
 business units. Chapter 17 examines these and other features in more detail, 
 focusing on the technical design. We do not attempt to cover all aspects of the 
 business of university administration. For our illustrations, we have selected 
 features that have applicability to businesses other than a university. Our point is to 
 illustrate how the flexible features save time and effort. Think flexibly as you read 
 this chapter.",NA
5.1 Background,"The University of Cincinnati (UC) is the second-largest public institution in the 
 state of Ohio, with approximately 34,000 students, and the largest
  
 63",NA
5.2 Success Stories,"Several brief anecdotes illustrate the positive impact of the flexible design of 
 UniverSIS. In an inflexible system, the modification necessitated by the changes in 
 requirements described in these anecdotes could be any or all of the following: 
 costly, time-consuming, disruptive, or, most likely, not done at all. Some of the 
 features described in these success stories are covered in more detail in Chapter 
 17.",NA
5.2.1 On-Campus Transfer,"Although the central admissions office used UniverSIS to process applica-tions for 
 admission to the university, students who wished to transfer from one college to 
 another within UC (on-campus transfer) were required to fill out paper forms. All 
 on-campus transfer processing continued to be done manually. The situation 
 occurred because the developers designed the admissions module based on 
 specifications provided by the central office and were told nothing about the on-
 campus transfer process. Some time after the admissions module was in place, a 
 clerical staff member from the central admissions office took a position in one of 
 the colleges, where she was responsible for processing on-campus transfers. She 
 recognized that the process was nearly identical to the process of the central office 
 and asked, “Can’t we do this in UniverSIS somehow?” Adding a single code",NA
5.2.2 Correspondence Control,"UniverSIS provides a correspondence-management feature that can be used to 
 generate personalized letters. The feature was initially developed to produce offer 
 letters for the admissions office. Without any changes to program code, the",NA
5.2.3 Financial Oversight for Athletes,"UC, like other large universities, is frequently under scrutiny by the NCAA to 
 make sure that athletes are not receiving money they should not be receiving. The 
 athletic director ordered that the system be modified, immediately, to block 
 financial aid checks for athletes until financial aid award requirements had been 
 verified. Only 12 hours of programmer time were required to develop the required 
 modification, which includes auto-mated block of the checks and automated e-
 mail notification to the athletics department when a change in an athlete’s 
 enrollment or financial aid status occurs. The developers were able to adapt and 
 reuse existing features, reducing significantly the need for custom coding. In this 
 instance, UniverSIS already had a mechanism called the “service block,” a general-
 purpose feature used to record administrative blocks of specified services such as 
 transcripts and grade reports. Adding a service block for financial aid checks for 
 athletes required very minor modification to programs and no changes to data 
 structures. The modular, flexible design proved its value.",NA
5.2.4 Tuition and Fees,"The university was faced with a sudden and unexpected midyear drop in financial 
 support from the state. In the middle of autumn quarter, a decision was made to 
 increase all tuition and fees as of winter quarter, five weeks away. One business 
 staff member made all rate adjustments in less than two business days. No IT 
 intervention was required.
  
 The ability to change rates through adjustment of data values is of course 
 unremarkable. In addition, however, the business staff member was also able to 
 make any necessary adjustments to the business rules that determine which 
 students are assessed each charge. Such rules are typically embedded in program 
 code:
  
 IF the student is registered for 12 to 18 credit 
 hours
  
 AND the student is enrolled in the College of Arts & 
 Sciences
  
 AND the student is an out-of-state resident
  
 AND the student does not live in a Kentucky county 
 with which the university has a reciprocity 
 agreement
  
 THEN assess Charge #1",NA
5.2.5 A New College,"In 1996, prior to implementation of UniverSIS, UC added a new college. By 
 estimates of the IT department, it took approximately 5000 person-hours to make 
 the necessary changes in the legacy student information system. Subsequently, 
 another college was added, this time after UniverSIS was in place. As part of this 
 change, some current students migrated to programs in the new college but were 
 allowed to retain the tuition rates of their previous college. Those responsible for 
 planning the addition of the new college and these special charging rules did not 
 consider the impact on the student information system until quite late in the 
 process. Just a few weeks before implementation of this business plan was to 
 occur, a discussion of the system-related changes finally took place. Much to 
 everyone’s relief, business staff were able to establish the new college, its academic 
 programs, its courses, its tuition and fees, special rules for students migrating to 
 the new college, etc. by entering data values in existing data structures. No IT 
 intervention was required. This was possible because the answer to the question, 
 “What can change?” was, “We could add a new college,” and UniverSIS was 
 designed to accommodate such an occurrence.",NA
5.2.6 Telecounseling,"The admissions office decided to initiate a telecounseling effort, i.e., phone banks 
 for recruitment of prospective students. Some of the admissions staff had seen a 
 telecounseling software package at a conference and were anxious to buy it. One 
 of the authors asked to see a demonstration, which was conducted over the Web. 
 After seeing it, he pointed out that UniverSIS already had essentially all the 
 features of the package. These existing features simply needed be combined in a 
 new way. With approx-imately two days of effort, one programmer was able to 
 provide the required functionality without any file changes or any modifications to 
 core data maintenance logic.",NA
5.2.7 Success Stories Summary,"What these anecdotes have in common is a need to provide system support for 
 modest changes in business requirements and to provide it quickly. The value of 
 the flexible design is reflected in the absence of impact on the IT department. In 
 some cases, no IT intervention was required. In the other cases, it was limited to a 
 few days of programming effort. There was no need to realign priorities, pull 
 programmers off ongoing projects",NA
5.3 Two System Features,"We will now look at two flexible features of UniverSIS in more detail. In Chapter 
 17, we provide a more extensive list of such features. The first feature, generic 
 code and code-to-code is presented here because it is probably the easiest to 
 understand. The second feature, locators, is pre-sented because we often use it as 
 an example of flexible design in later sections.",NA
5.3.1 Generic Code and Code-to-Code,"The developers of UniverSIS identified two types of regulatory data: simple 
 entities and complex entities. These are discussed further in Chapter 8 on 
 regulation. All records for simple regulatory entities are maintained in a single 
 physical data structure called a “generic code table.” Each simple regulatory record 
 is composed of an entity identifier, a code, a description, an active/inactive 
 indicator, and a default indicator. Simple regulatory records for the same entity 
 make up a (logical) simple table. Typical examples are state, gender, and ethnic 
 category. Exhibit 5.2 illustrates such a generic code table for state records.
  
 When a simple regulatory entity is added to the system, no programs need to 
 change. A new simple table is added to the generic code table, and table owners are 
 designated. The table owners determine who has access to the table. Those who 
 have access to the table maintain its contents. The data dictionary enforces the 
 correct length of values stored in the code field. The instant a value is added to a 
 simple table by a
  
  
 Entity 
  
 Code 
  
 Description 
  
 Inactive Default
  
 STATE 
  
 AL 
  
 Alabama 
  
  N 
  
 N
  
 STATE 
  
 AR 
  
 Arkansas 
  
  N 
  
 N
  
 Exhibit 5.2.
  
 Generic Code Table",NA
5.3.2 Generic Code and Code-to-Code: Discussion,"The data structures of the simple tables and the code-to-code mechanism are very 
 stable, yet UC continues to find new ways to use the features. Control of the 
 contents is in the hands of the business staff. When coding must make use of the 
 simple tables or code-to-code relationships, the programmer needs to know only 
 which tables and code-to-code relation-ships are needed to support a given 
 process. A program is coded to pass parameters identifying the tables and 
 relationships to a standard, reusable routine that returns the desired results.",NA
5.3.3 Locators,"To generalize the concept of addresses, the developers coined the term“locator,” 
 the idea being that the point of an address was to have a means of locating an 
 individual. Since the ways of locating an individual have expanded beyond physical 
 location, it was necessary to accommodate both addresses and nonphysical 
 locations, e.g., cell phones, e-mail addresses, and World Wide Web addresses.
  
 The developers identified four categories of locator:
  
 1. 
  
 Residence 
  
 2. 
  
 Business 
  
 3. 
  
 Campus 
  
 4. 
  
 Telecommunication",NA
5.3.4 Locator: Discussion,"Like those of the generic code and code-to-code features, the data struc-tures of 
 the locator mechanism are very stable. There is no limit to the number of locators 
 that can be recorded for an individual. This provides",NA
5.3.5 Two System Features: Summary,"The two features presented here convey the nature of flexible software design. 
 Neither is especially complex. For those at UC, it may even seem obvious that 
 such features should be part of the system design. In fact, though the value of 
 these features is now obvious, their design was not.",NA
5.4 Summary,"UniverSIS is an example of a successful flexible system with a multiyear 
 track record of maintenance changes and enhancements performed largely 
 by business staff.
  
 The primary success of UniverSIS is that it helps the business staff do 
 their jobs better and with less effort. Its success can also be judged by 
 how well it accommodates current and future business requirements and 
 by how business staff have taken ownership of the system.
  
 The value of UniverSIS’s flexible design is further reflected in the absence 
 of impact on the IT department.
  
 Generic code tables and code-to-code mechanisms — examples of 
 flexible features used in UniverSIS — allow the system to serve as a 
 virtual business expert. These data structures are very stable. UC 
 continues to find new ways to use the features.
  
 The locator feature shows that an apparently simple thing, an address, can 
 be quite complex. Designing a flexible feature to accommodate that 
 complexity positioned the organization well for real-world changes of the 
 future.
  
 The UniverSIS developers found that some of the UC’s business staff enjoyed 
 the process of developing a system more than others, but in the end they all 
 judged the system by the results. Success was measured by whether the system 
 helped them to do their jobs better and with less effort. The developers found it 
 worthwhile to emphasize to the business staff that they were designing UniverSIS 
 with future modification in mind.",NA
WHAT IS ,NA,NA
II,NA,NA
REQUIRED TO ,NA,NA
ACHIEVE FLEXIBILITY,"The specific system development outcome we are looking for is ease of 
 maintenance. Systems that are easy to maintain permit organizations to respond to 
 changing business conditions and requirements quickly and easily. Our definition 
 of a flexible, easily maintained system is one that can accommodate change with 
 little or no program modification.
  
 The potential maintenance backlog of the future cannot be reduced or 
 eliminated unless you think about it during the development phase. But what are 
 the essential ingredients for flexible software design? And how are flexible systems 
 designed and developed?
  
  
 The five chapters in Part II present the key ingredients, or techniques, for 
 achieving flexibility:
  
 The discussion of what to do to achieve flexibility starts in Chapter 6 with 
 a set of guidelines for flexible design. These design guidelines provide a 
 solid foundation upon which the flexibility techniques in the subsequent 
 chapters build.
  
 Chapter 7 emphasizes the importance of stable identifiers in flexible 
 software design. It presents key characteristics of stable identifiers, lists 
 what is wrong with many of today’s identifiers from a flexibility 
 standpoint, and shows the errors to avoid in designing and assign-ing 
 identifiers.
  
 Chapter 8 presents the concept of regulation, which is used to manage a 
 system’s artificial limits or business rules. Two types of",NA
Chapter 6,NA,NA
Guidelines for Flexible ,NA,NA
Software Design,"Done well, software systems can serve an organization for many decades over 
 multiple technological generations. If the attributes of flexible soft-ware systems 
 are recognized, and if the guidelines and techniques are understood and practiced, 
 then fewer inflexible software systems will be created. The schedule and cost 
 trade-offs that today often result in seriously compromised design quality can be 
 shifted in favor of preserving designs that will pay for themselves, if not quickly, 
 then repeatedly, by extending the cost-effective life of the system.
  
 System flexibility does not occur serendipitously; it is the result of focused 
 efforts. In learning what to do to achieve flexibility, start by following the 
 guidelines presented in this chapter:
  
 Treat “design” as a noun 
  
 Design for the long haul 
  
 Observe consistent standards 
  
 Use N-tiered architecture 
  
 Employ individual data objects 
  
 Take advantage of reusable logic 
  
 Code general-purpose routines 
  
 Recognize the limits of flexibility
  
 81",NA
6.1 Treat “Design” as a Noun,"Design is typically treated as a process — as part of software development. This 
 again puts the emphasis on the process rather than the outcome. Treat “design” as 
 a noun so that it describes what flexible software systems are, do, and look like.",NA
6.2 Design for the Long Haul,"Flexibility is about the system being functional for the long haul. The top 
 executive or sponsor must be involved in the identification of broad long-term 
 objectives of the organization and of the system that is to support it. A mission 
 statement for a specific software development project is helpful in providing a 
 long-term focus. System development is hard work, often over an extended period 
 of time, and participants in a project must be able to step back periodically and 
 recall the long-term purpose of their efforts. The long-term purpose is never 
 simply to “get the system implemented.”In flexible development, when the design 
 proves inadequate because the original design is too rigid, it must be revisited and 
 revised where necessary. Though this can be painful, the effort to correct the 
 design and make it more flexible will be worthwhile in the long run. Remember, 
 we are not designing just for current requirements, but also for business needs that 
 will surface in the future. New requirements may emerge even during the 
 development process. If you discovered during development that a new 
 requirement necessitated changes to data structures and pro-gram code, you can 
 be nearly certain that this pattern will be repeated in the future after the system is 
 in production.",NA
6.3 Observe Consistent Standards,"All the members of the development team must follow a consistent approach. 
 This means that consistent technical and user interface standards must be defined 
 and enforced. Effective software tools can facilitate establishment of standards. A 
 data dictionary can be used to define standard fields and data relationships. Use of 
 program models and tem-plates facilitates coding. A code generator, in 
 conjunction with the active data dictionary, reduces significantly the amount of 
 manual coding that must be done. Technical managers must ensure that standards 
 are docu-mented and must enforce their use.
  
 We have found absence of standards to be one of the greatest imped-iments to 
 quality designs. It appears that very few programming managers",NA
6.4 Use N-Tiered Architecture,"While it can be a good thing, N-tiered architecture does not guarantee flexibility.
  
 The term “N-tiered architecture” is used widely in IT today. Even when a 
 traditional development approach is used, incorporating N-tiered archi-tecture into 
 system design provides flexibility by separating the user interface, business logic, 
 and data storage. This approach allows various interface media, such as touch-
 tone, cell-phone, World Wide Web (WWW), or personal digital assistant (PDA), to 
 be utilized without change to business logic or data storage. For example, when 
 the UniverSIS project",NA
6.5 Employ Individual Data Objects,"Identify logical data entities, and entity types, and maintain them as individual 
 objects — generic entities and generic-entity clouds (GECs, presented in Chapter 
 10). Like N-tiered architecture, object-oriented (OO) design is consistent with, 
 though not synonymous with, flexible design. In UniverSIS, each object has its 
 own maintenance program. The object maintenance program performs all 
 maintenance of object records. All business rules are enforced through that object, 
 ensuring that those rules are applied consistently. It is essential that generic entity 
 types be con-sidered in the design.
  
  
 We have more to say on this topic in Chapter 9 on stable data structures and 
 Chapter 10 on generic-entity clouds (GECs).",NA
6.6 Take Advantage of Reusable Logic,"Code reusable logic in callable routines. Use of such routines falls under the 
 heading of “standards.” Documenting such routines and requiring uniform use of 
 the routines is an essential aspect of technical management. This is an area where 
 communication and supervision of technical staff are critical.
  
 There generally is more than one logical way to solve a problem, and it is 
 critical that the review process ensure that an effective logical solution is used. A 
 colleague [Scheuer, 2004] recently reported this situation to us.
  
 I remember a very specific situation where an individual who reported 
 to me complained that his “very logical approach” to modifying a 
 program didn’t work. I pointed out to him that",NA
6.7 Code General-Purpose Routines,"Develop general-purpose, reusable business processes whenever possible. Separate 
 business processes often follow the same pattern. In such cases, a general-purpose 
 processing tool should be developed, rather than purpose-specific processing 
 tools. We provide examples throughout the book. For example, the UniverSIS 
 developers generalized the process of producing admission decision letters, the 
 result being the correspondence-manage-ment feature identified in Chapter 5.",NA
6.8 Recognize the Limits of Flexibility,"Recognize that there are limits to flexible design. We emphasize the importance of 
 letting business staff control system behavior through main-tenance of data. There 
 will be times when this is simply not possible. For example, in the UniverSIS 
 admissions module, a status is recorded for each application: denied, accepted, 
 confirmed. Each status triggers a predefined process that results in creation of 
 other records. The developers could not give users the capability of adding new 
 status values because they had no way of simultaneously giving them control over 
 which processes were triggered by those values. New processes, i.e., program-
 ming, may be needed when a new value is added.
  
 In a human-resource system, there may be two types of employee, hourly and 
 salaried. Certain information would be recorded for each type. Let us say that a 
 new type, contractor, was introduced. Simply adding a",NA
6.9 Summary,"Design is typically treated as a process — as part of software 
 development. This puts the emphasis on the process rather than the 
 outcome. Treat “design” as a noun so that it describes what flexible 
 software systems are, do, and look like.
  
 Flexibility is about the system being functional for the long haul. The top 
 executive or sponsor must be involved in the identification of broad, long-
 term objectives of the organization and of the system that is to support it.
  
 System development is hard work, often over an extended period of time, 
 and participants in a project must be able to step back periodically and 
 recall the long-term purpose of their efforts. All the members of the 
 development team must follow a consistent approach. This means that 
 consistent technical and user interface standards must be defined and 
 enforced. Technical managers must ensure that standards are documented 
 and must enforce their use. Incorporating N-tiered architecture into 
 system design provides flexibility by separating the user interface, business 
 logic, and data storage. This approach allows various interface media, such 
 as touch-tone, cell-phone, World Wide Web, or personal digital assistant 
 (PDA), to be utilized without change to business logic or data storage. 
 Identify logical data entities, and entity types, and maintain them as 
 individual objects — generic entities and generic-entity clouds (GECs, 
 presented in Chapter 10).
  
 Code reusable logic in callable routines. Use of such routines falls under 
 the heading of “standards.” Documenting such routines and requiring 
 uniform use of the routines is an essential aspect of technical 
 management.
  
 Develop general-purpose, reusable business processes whenever possible. 
 Separate business processes often follow the same pat-tern. In such cases, 
 a general-purpose processing tool should be developed, rather than 
 purpose-specific processing tools.
  
 Recognize that there are limits to flexible design. There will be times when 
 it is simply not possible or affordable to have business staff control 
 system behavior through maintenance of data.
  
  
 These design guidelines provide a solid foundation upon which to build the 
 flexibility techniques presented in the subsequent chapters.",NA
Chapter 7,NA,NA
The Importance of ,NA,NA
Stable Identifiers,"Unstable identifiers are responsible for a significant share of the mainte-nance 
 burden. Identifiers are unstable when they contain information, because virtually 
 any information about the thing identified is subject to change. In contrast, stable 
 identifiers are information-free, conforming to the principle of strict uniqueness 
 discussed below. Stable identifiers are an essential component of a stable 
 information structure, and they play an important part in reducing the 
 maintenance burden. It is essential that the identifiers (primary keys) used in a 
 system not be subject to modifi-cation as the requirements of the system change.",NA
7.1 Information-Free Stable Identifiers,"The key to identifier stability is the exclusion of meaning from the 
 identifier. That really is the beginning and end of this subject: 
 descriptive IDs, no; indicative-only IDs, yes.
  
 Identifiers are the names we give to things, and naming conventions are the rules 
 devised to assign names to things. Identifiers are artifacts of serious convenience. 
 The ability and inclination to name things is so convenient that it is probably wired 
 into our brains. This chapter highlights serious mistakes that are frequently made in 
 the design of identifiers.
  
 89",NA
7.1.1 Uniqueness and Invariance,"Uniqueness is a necessary condition, but it is not a sufficient condition. The other 
 fundamental requirement is invariance.
  
 A fundamental requirement that identifiers must satisfy is, of course, uniqueness
 . 
 Without uniqueness you have ambiguity (Exhibit 7.2). Spe-cifically, a naming 
 convention must assign unique identifier values on a one-to-one basis to each 
 distinct thing to which the convention applies. Here are a few names that satisfy 
 this condition; they are each unique within their appropriate contexts: Zooey, 
 Slartybartfast, Chingachgook, Gilgamesh, THX1130, Heliogabalus, Albuquerque, 
 Poodpah, and 3944865. In contrast, we have not only the fictitious Bruces, but the 
 2300 Zhang Lis in Tianjin, China; the 4000 Hansens of Oslo, including 50 Hans 
 Hansens; and the Danes’ reaction to ambiguity with tombstone inscriptions such 
 as Mr. Managing Director Jensen and Mr. Unskilled Worker Jensen [Kaplan and 
 Bernays, 1997].
  
 Uniqueness is a necessary condition, but it is not a sufficient condition. The 
 other fundamental requirement is invariance. Stability of an identifier under 
 changing conditions is as essential as uniqueness if we want stability in the 
 information structure. The names given above also satisfy this condition: they are 
 unchanging by virtue of being meaningless, and they convey nothing about the 
 things to which they have been assigned —not color, gender, age, political 
 persuasion, or even type. We may know, with the exception of the last two names, 
 that these refer to people and places only because they are famous, not because of 
 any information in the names themselves (Exhibit 7.3).",NA
7.1.2 Strict Uniqueness,"The frequent failure in systems design to engineer static names has serious and 
 costly consequences and takes many forms.
  
  
 We introduce a term, strict uniqueness, at this point, which we define in 
 contrast to simple uniqueness as follows.
  
 Simple uniqueness
 : An identifier must be at least unique.
  
 Strict uniqueness
 : A stable identifier must be at least unique and at most 
 unique.",NA
7.1.3 Name Changes,"How serious is the problem of name changes? The systems that interest us here 
 are just those systems that deal with many instances of the same kind of thing and 
 many different kinds of things — multiple orders, customers, assets, etc. — and 
 with multiple objects of any sort and of many sorts. When references are made to 
 those instances within a system, they are recorded in the system’s current files, in 
 history files, in archived files, in reports, forms, drawings, charts, etc., on paper, on 
 microfiche, in catalogs, in people’s memories, and so on. This is not a consequence 
 of“uncontrolled” redundancy, it is a normal outcome in even a fully nor-malized 
 database system. If the value of the ID is changed, the many references to it must 
 also be located and changed accordingly. While changing an ID value or the size of 
 an ID is not intellectually demanding, even in a large system or set of systems, it 
 can be laborious and pains-taking. All the uses must be located (hopefully, with the 
 help of an accurate data dictionary), changed, recompiled, and tested. Files must be 
 reloaded, and screens and reports must be reformatted, sometimes necessitating 
 some clever and irritating work to fit in the (usually) larger name.
  
 Changing the internal structure of a name, which is the equivalent of changing 
 its semantic content or meaning, is much worse, involving value changes and 
 often size changes, as above, plus program logic changes. For example, consider 
 the identifier of an organization unit as shown in Exhibit 7.4. If the organization 
 structure changes and the ID must be modified to, say, insert a Group ID 
 between division and department, then any programs that access inventory 
 records must also be modified to assemble or interpret the primary key differently. 
 Most database man-agement systems (DBMS) today provide a “view” facility that 
 enables a program’s view of its data records to be restricted to only those data 
 fields it needs. However, because every view of any record must include at a 
 minimum the record’s primary-key field, view facilities cannot insulate programs 
 from name-definition changes. As organization IDs are typically used in multiple 
 files and even multiple systems, the modifications multiply.
  
 What happened in the aluminum plant discussed in Exhibit 1.2? Why were the 
 automated-world systems modifications far more costly than the corresponding 
 real-world systems changes? The answer is not that the IT function was inefficient 
 or had inadequate tools or used expensive",NA
7.1.4 Shared Identifiers versus Hidden Surrogates,"Before proceeding further, we should briefly mention surrogates. The term 
 surrogate normally refers to an identifier that is primarily intended for the internal 
 use of a DBMS (or DBMS/operating-system ensemble). Typically these are very 
 large floating-point format DBMS-assigned numbers, usually information-free, by 
 which every record can be distinguished. In some",NA
7.2 Types of Unstable Identifiers,"There are five primary types of information found in traditional identifiers:
  
 1. 
  
 Qualification information 
  
 2. 
  
 Embedded information 
  
 3. 
  
 Abbreviation information 
  
 4. 
  
 Sequence information 
  
 5. 
  
 Function-selection information, check digits, and delimiters
  
  
 The principle problem, of course, is change, but other problems also accrue to 
 the use of unstable identifiers. There are problems of:
  
 Scope 
  
 Existence 
  
 Inclusiveness 
  
 Redundancy 
  
 Error proneness 
  
 Reliability",NA
7.2.1 Qualification Information,"When multiple things have the same name, there is potential ambiguity unless a 
 context is given within which the name is unique. A common technique for 
 resolving this ambiguity is to use qualification. Qualification is a single or nested 
 set of context names appended to the object’s otherwise nonunique name to 
 achieve uniqueness. Context names can be explicit or implicit; implicit naming is 
 referred to as partial qualification. A simple example is city (Columbus) qualified 
 by state (Indiana, or Ohio, or Georgia, etc.). Qualifications can be nested, such as a 
 complete street address number, street, city, and state. The zip code, of course, is 
 not",NA
7.2.2 Embedded Information,"Excessive length is a clue to the existence of embedded informa-tion and, hence, of 
 instability.
  
 Qualification information is a special case of embedded information. There is no 
 limit to the information that ID designers include. Indeed, any or all of a thing’s 
 properties and relationships are candidates for embedded information. In 
 computer file IDs, for example, it is common practice to",NA
7.2.3 Abbreviation Information,"The example above of the embedded and qualified file ID also illustrates another 
 ploy for using an ID as a vehicle for information: the abbreviation, as in PAYroll 
 system. Abbreviations (and acronyms) are a little less stable than the names they 
 represent. If we abbreviate an identifier that in itself is stable, the abbreviation 
 should also be stable. The difficulty is that, being shorter, the abbreviation is more 
 susceptible to duplicate values arising. For example, the word processor used to 
 compose this sentence lists 12 subfunctions under the File menu, only five of 
 which use the initial letter of the function. When duplicates arise, the designer of 
 an abbreviation ID lengthens the abbreviation to retain the characteristic of being 
 a meaningful short substitute for the full name, or permits departures from the 
 abbreviation scheme to ensure uniqueness.",NA
7.2.4 Sequence Information,"Sequencing, or collating, information is used to keep records in a conve-nient order 
 and, of course, is subject to change (Exhibit 7.7).",NA
"7.2.5 Function Selection, Check Digits, and Delimiters","It should be noted that not everything that is attached to or embedded in an 
 identifier necessarily destabilizes it. Function-selection information specifies a 
 function to be performed on the ID to which it is attached. A familiar example is 
 found in North American telephone numbers. The digits 0, 1, 800, etc. tell the 
 phone system what to do with the phone number. The long-distance function code 
 embedded, until recently, in the area code part of the phone number has not 
 destabilized phone numbers but has merely limited the quantity of available 
 numbers. The area code prefix is qualification information, which is what has 
 caused many existing phone numbers to be changed. Of course, now that cell 
 phones are so prevalent and one can keep the number when moving, area codes are 
 becoming less associated with place and the 10-digit phone number is becoming 
 more of a stable identifier.",NA
7.3 Identifiers and the Relational Data Model,"Identifiers are not attributes; they are identifiers, a distinct component 
 of information structure.
  
 This section assumes that the reader is familiar with the relational model, 
 normalization, and referential and existence integrity; readers who are not may 
 wish to skip this section.
  
 It is important to establish that the information-free identifier is not only 
 consistent with, but specifically supports the relational data model, normalization, 
 and the maintenance of referential and existence integrity in a system. The 
 relational model provides for relations and their attributes as a form of 
 representation of information about things and their prop-erties. But despite the 
 existence of the relational model as a guide to good information structure design, 
 identifiers continue to be incorrectly designed.",NA
7.4 Summary,"Unstable identifiers are responsible for a significant share of the 
 maintenance burden.
  
 Identifiers are unstable when they contain information, because virtually 
 any information about the thing identified is subject to change.
  
 Stable identifiers are information-free, conforming to the principle of 
 strict uniqueness. As an essential component of a stable infor-mation 
 structure, they contribute to reducing the maintenance burden.
  
 The chapters on stable information structures (Chapter 9) and the generic-
 entity cloud (Chapter 10) assume stable identifiers that are designed according to 
 the chapter on implementation of stable identifiers (Chapter 14). We cannot 
 overemphasize the importance of strictly unique identifiers!",NA
Chapter 8,NA,NA
Regulation: ,NA,NA
Managing Artificial ,NA,NA
Limits,"The behavior of any real-world system is constrained by both natural limits (the 
 laws of physics and logic) and artificial limits (business rules established or 
 observed by an organization). In a flexible system, the natural limits are 
 represented in stable information structures that are acted upon by stable 
 processes. The artificial limits, or business rules, are represented in a way that does 
 not affect the information structures or processes. The interpretation of artificial 
 limits, or business rules, can be changed as the business changes. We use the term 
 “regulation”to describe the management of artificial limits within a system.
  
 Flexibility in an automated system is the characteristic of allowing 
 resynchronization with its changed real-world system at low cost. A flexible 
 system can be resynchronized through business-staff-controlled data-value 
 modification and without the need to modify program code or information 
 structures. This no-programming approach brings the benefits of reduced 
 maintenance but may result in additional development costs. We will discuss the 
 benefit/cost trade-offs.",NA
8.1 Business Rules as Artificial Limits,"A user-controlled resynchronization process is accomplished through regulation or 
 management of the system’s artificial limits.
  
 107",NA
8.1.1 Maintaining Business Rules,"A guiding principle in designing flexible systems is that business staff, through the 
 alteration of data values, should manage the maintenance of business rules.
  
 Changes in business rules are the most likely trigger of system modifica-tions. A 
 guiding principle in designing flexible systems is that business staff, through the 
 alteration of data values, should manage the maintenance of business rules. In the 
 past, the current interpretations of business rules were typically coded in programs. 
 A rule could involve something as straightforward as validating a value against a 
 list of values, such as lists of valid states, genders, and countries. A rule could also 
 involve something much more complicated, such as evaluating an individual’s 
 profile against a set of conditions that control some aspect of the business process. 
 Over time, developers have adopted some forms of flexibility. They have 
 recognized the advantage of storing lists of valid values as data, maintained by 
 business staff. This is now standard practice in systems development. We believe 
 that developers can push this concept even further. One way is with rules engines; 
 Babcock [2004] says, “Rules engines let companies adapt offerings without lots of 
 programming.”",NA
8.2 General Regulation of Business Rules,"By general regulation we mean those aspects of regulation that have to do with 
 processing-oriented business rules — what the BRG calls action assertions. 
 General regulation is “on top of” the BRG structural assertions; these structural 
 assertions are, in essence, our cardinality regulation.",NA
8.2.1 Identifying Entities and Rules,"The following simple example of a business process helps us to identify potential 
 system entities and business rules.
  
  
 When asked about the admissions process at a university, the director of 
 admissions said something like this:
  
 An applicant submits an application, indicating the term and major. 
 We review the applicant’s test scores, high school tran-script, etc. If 
 the applicant meets the criteria for that major, we send an offer letter. 
 If not, we send a denial letter, suggesting alternatives.
  
 In a discussion of business requirements, any noun is a potential entity. The nouns 
 (and adjectives) in the above passage are underscored. Further investigation of 
 each of these entities will identify other entities, the need to record more 
 information about each of these entities, and so on. Eventually, we will reach a 
 point where we have identified all the entities and all the attributes about those 
 entities that are of interest to the system.
  
 Where adjectives are encountered, the potential for entity types exists. We 
 explore entity typing in Chapter 9, but the description provided by the director of 
 admissions includes a few possibilities. Note that the description differentiates 
 offer letters from denial letters. We should there-fore explore the possibility of a 
 generic data structure for letters, providing for different types of letters. The term 
 “high school transcript” was spec-ified, which should lead us to investigate what 
 other type of transcript might exist.
  
 Wherever the description specifies a condition of some kind, we have the 
 potential for a business-staff-maintained business rule. Such rules can be very 
 simple. For example, the description indicates that a term and major must be 
 specified. The fact that they must be specified constitutes a simple rule. 
 Presumably, there are some business rules that determine which term and major 
 values are valid, another form of simple rule. Designers should provide a 
 mechanism to allow business staff to maintain those rules as data.",NA
8.2.2 Validation Rules,"The developer of a flexible system should think in terms of a design that allows a 
 new logical table to be added to the system without a change in information 
 structure.
  
 The term “validation rule” can be used to describe a basic form of business rule, 
 which is to verify that the value entered into a field is valid. Such rules range from 
 validation of a single value against a single file to validation of complex 
 combinations of values and multiple files and operators. For simple validation of a 
 value against a list of values, a generic logical table facility works well. One of the 
 most common modifications to a system’s information structure is the addition of 
 a table for storing valid values for a new data element. Knowing that, the 
 developer of a flexible system should think in terms of a design that allows a new 
 logical table to be added to the system without modifications to the information 
 structure. This can be accomplished by adding an element to the infor-mation 
 structure that identifies the logical table. Where an inflexible design would contain 
 separate physical validation tables for ethnicity, state, and country, a flexible design 
 would contain a single physical validation table separated into logical tables by 
 type. Ethnicity, state, and country would be types. Addition of a new data element 
 to the system requires only a new record type to be accommodated in the 
 information structure. This approach works for simple regulatory entities in which 
 each logical table type requires the same data elements. We use the term 
 “regulatory” to indicate that its purpose is to support the business rules.
  
 UniverSIS makes use of this approach, as illustrated by several examples in 
 Exhibit 8.1. In UniverSIS, when a simple regulatory entity is added to the system, 
 no programs need to change. A new simple table is added to the code table. The 
 table owners determine who should have access to it. Those who have access to 
 the table maintain its contents. The data dictionary determines the correct length 
 of the code field and prevents values for that table from exceeding the correct 
 length. The instant a value",NA
8.2.3 Business Rules and Logic,"Another level of regulation involves determining whether an action is valid. 
 Conditional logic, generally in the form of IF/THEN/ELSE program statements, 
 is used to determine what action should occur. The validity of the action is 
 typically determined by characteristics of an instance of an entity. For example, 
 looking at a student entity, we might see that Mary may register for a calculus class 
 but John may not. The decision regarding who may register will be based on data 
 values on the students’records. In a traditional system design, program logic would 
 be coded to retrieve the data and execute conditional logic to arrive at the 
 decision. If a change of logic is needed because additional data values must be 
 considered, a programmer must change the code. Multiply that scenario by the 
 number of processes in a system and you have the makings of a maintenance 
 backlog.
  
 It is best to design system components to allow business staff some control 
 over conditional logic as well as valid values. In other words, allow business staff 
 to write the business rules without IT intervention. An example from UniverSIS is 
 the tool called the Evaluator, described in Chapter 18. It is a general-purpose tool 
 that permits business staff to construct complex conditional statements from 
 predefined elements and associated data-retrieval routines. It is independent of 
 specific business processes. The elements can be combined in any set of logical 
 statements that the business staff find useful. The tool is used in several different 
 modules, e.g., charging, registration restrictions, assignment to correspon-dence 
 tracks, etc.",NA
8.2.4 Regulation and New Processes,"Another type of business rule involves determining which action the system 
 should take. Implicit in this type of regulation is the addition of new actions and 
 new processes. Modification of a system to accommodate a new business process 
 typically requires new programming, as illustrated in Exhibit 8.2.
  
 Exhibit 8.2 illustrates a university admissions process. The original system 
 shown in Case 1 is designed with two valid values: admitted and denied. If the 
 applicant is admitted, an offer letter is sent and the",NA
8.2.5 No Retroactive Regulation,"Business rules should have effective periods, but regulation must not be 
 retroactive. In other words, if a specific regulatory rule was in effect when the 
 action was taken, a subsequent change in that rule can affect only actions taken in 
 the future, not actions taken in the past. Retroactive regulation is not permitted 
 because it would cause the system to violate its own rules.
  
 For example, if order 6629 were taken when there was insufficient inventory 
 and back orders and if partial shipments were not allowed, the",NA
8.2.6 Summary of General Regulation,"Regulatory processes should be content-free programs that“know” where to retrieve 
 information about rules and how to enforce the rules.
  
 Careful analysis and design of regulatory features is one of the key requirements of 
 a flexible system. Regulatory processes should be content-free programs that 
 “know” where to retrieve information about rules and how to enforce the rules. 
 Changes in the content of the rules should not affect the regulatory process unless 
 a new factor is introduced. However, even when a new factor is introduced, most 
 of the time a flexible design should limit the impact to minor program code 
 modifications and rarely to file-structure modifications.
  
 Appendix 8A (Using Regulation to Make a Flexible System) is presented for 
 readers desiring to study regulation in greater detail. It walks through two 
 examples — one with regulation and one without — illustrating the use of 
 decision tables to determine shipments in an order-processing system.",NA
"8.3 Cardinality Regulation: Variable Cardinality, ",NA,NA
Many-to-Many Associations,"In many ways, cardinality regulation is “adjustable” structure. We have stated that a 
 key objective of flexible design is a stable data structure.",NA
8.4 Summary,"The behavior of any real-world system is constrained by both natural and 
 artificial limits. Artificial limits are business rules estab-lished or observed 
 by an organization.
  
 User-controlled resynchronization of the automated system with its 
 changed real-world system is accomplished through regulation or 
 management of the system’s artificial limits.
  
 Changes in business rules are the most likely trigger of system 
 modifications. A guiding principle in designing flexible systems is that 
 business staff, through the modification of data values, should manage all 
 maintenance of business rules.
  
 The current interpretations of business rules are typically coded in 
 programs. Migrating such logic to business-staff-maintained data 
 structures offers great potential for improving system stability and 
 flexibility and reducing system maintenance.
  
 The first principle of regulation is to store business rules as data. There are 
 (at least) two types of regulation: (a) general business rules regulation and 
 (b) cardinality regulation. General regulation of business rules allows 
 adjustment of business processing; cardi-nality regulation allows 
 adjustment of the underlying information structures.
  
 Regulatory processes should be content-free programs that “know”where 
 to retrieve information about rules and how to enforce the rules. General 
 business-rules regulation can accomplish the follow-ing without the need 
 for program or database modifications:–
  
 Verifying, or validating, that 
 the value entered into a field is valid–
  
 Determining whether an 
 action is valid
  
 –
  
 Determining what action the system should take
  
 –
  
 Accommodating the addition of new actions/processes 
  
 Regulation should have effective dates, and it cannot be retroactive. In 
 other words, the setting of regulation values must not cause the system to 
 violate its own rules.
  
 Cardinality regulation is one technique for varying constraints on the 
 system without modifying the system’s structure (or its processes). For an 
 information structure to remain unmodified while the car-dinality 
 requirements change (e.g., from hierarchical to network organization or 
 vice versa), the information structure must always represent the more 
 general case (in this instance, the network or many-to-many organization). 
 If enforcement of one-to-many (the hierarchical organization) is a current 
 requirement of the system, then that enforcement must be implemented 
 outside the informa-tion structure by means of cardinality rules.",NA
Appendix 8A: Using Regulation to Make ,NA,NA
a Flexible System,"This appendix is for those inclined to work through examples, as it requires the 
 reader to study the details. The two examples, one with and one without 
 regulation, use decision tables to determine shipments in an order-processing 
 system. Knowledge of decision tables is assumed.
  
 The entities and decision table in Exhibit 8.7 show an order entry/ship-ment 
 subsystem that does not provide for business-staff regulation of rules, specifically 
 rules governing back orders and shipping of partial orders. There is no way to 
 change parameters without modifying data structures or program code. Partial 
 shipments and back orders are not allowed under current business policies. 
 Programming modifications would be required to reflect changes in these policies 
 to allow either back orders or partial shipments or both. In Exhibit 8.7, columns 2, 
 5, and 6 and rows C and F are included as placeholders. They are left blank 
 because they are not active. Note also that the pseudocode includes only 
 operational data.
  
 The decision table in Exhibit 8.7 represents logic that is managed via program 
 code. It might be an internal table in a program implemented with constants in the 
 “data division,” or it might be IF/THEN/ELSE state-ments with embedded 
 literals. The point here is that it is under programmer control and not business 
 staff control. Throughout the book, we have planted the idea that business staff 
 should maintain values in tables. Here is what happens when the IT staff, rather 
 than the business staff, maintain the business rules.
  
 As seen in Exhibit 8.7, when management decides to allow back orders, an IT 
 professional, via program modifications, can activate columns 2 and 6 and 
 deactivate columns 3 and 4. Should management decide to allow partial shipments, 
 an IT professional, via program modification, can acti-vate column 5. If both 
 partial shipments and back orders are allowed, program modifications can activate 
 columns 2, 5, and 6 and deactivate columns 3 and 4. Any or all of these changes 
 would then require regression testing to ensure that (a) the program modifications 
 allowed orders to be processed correctly and (b) the modifications did not create 
 side effects.",NA
Appendix 8B: Business Rules Manifesto,See Exhibit 8.9.,NA
Business Rules Manifesto,"The Principles of Rule Independence
  
 by Business Rules Group
  
 Article 1.  Primary Requirements, 
 Not Secondary
  
 1.1. Rules are a first-class citizen of 
 the requirements world.
  
 1.2. Rules are essential for, and a discrete part 
 of, business models and technology models.
  
 Article 2.  Separate From Processes, 
 Not Contained In Them
  
 2.1. Rules are explicit constraints on behavior 
 and/or provide support to behavior.
  
 2.2. Rules are not process and not procedure. 
 They should not be contained in either of 
 these.
  
  2.3. Rules apply across processes and 
  
 procedures.  There should be one cohesive 
 body of rules, enforced consistently across all 
 relevant areas of business activity.
  
 Article 3.  Deliberate Knowledge, 
 Not A By-Product
  
 3.1. Rules build on facts, and facts build on 
 concepts as expressed by terms.
  
 3.2. Terms express business concepts; facts 
 make assertions about these concepts; rules 
 constrain and support these facts.
  
 3.3. Rules must be explicit.  No rule is ever 
 assumed about any concept or fact.
  
 3.4. Rules are basic to what the business 
  
 knows about itself — that is, to basic business 
 knowledge.
  
 3.5. Rules need to be nurtured, protected, and
  
 Article 4.  Declarative, Not Procedural
  
 4.1. Rules should be expressed 
 declaratively in natural-language sentences 
 for the 
  
 business audience.
  
 4.2. If something cannot be expressed, then it 
 is not a rule.
  
 4.3. A set of statements is declarative only if 
 the set has no implicit sequencing.
  
 4.4. Any statements of rules that require 
  
 constructs other than terms and facts imply 
 assumptions about a system implementation.
  
 4.5. A rule is distinct from any enforcement 
 defined for it.  A rule and its enforcement are 
 separate concerns.
  
 4.6. Rules should be defined independently of 
 responsibility for the who, where, when, or how of 
 their enforcement.
  
 4.7. Exceptions to rules are expressed by 
 other rules.
  
 Article 5.  Well-Formed 
 Expression, Not Ad Hoc
  
 5.1. Business rules should be expressed 
 in such a way that they can be validated 
 for correctness by business people.
  
 5.2. Business rules should be expressed in 
 such a way that they can be verified against 
 each other for consistency.
  
 5.3. Formal logics, such as predicate logic, are 
 fundamental to well-formed expression of 
 rules in business terms, as well as to the 
  
 technologies that implement business rules.
  
 continued…
  
 managed.
  
 Copyright, 2003.  Business Rules Group. 
  
 Version 2.0, November 1, 2003.  Edited by Ronald G. Ross.
  
 www.BusinessRulesGroup.org
  
 Permission is granted for unlimited reproduction and distribution of this document under the following conditions: (a) The copyright and this permission notice 
 are clearly included. (b) The work is clearly credited to the Business Rules Group. (c) No part of the document, including title, content, copyright, and permission 
 notice, is altered, abridged or extended in any manner.
  
  
 Exhibit 8.9.
  
 Business Rules Manifesto",NA
Chapter 9,NA,NA
Stable Information ,NA,NA
Structures,"The differentiation between structure and process in a system — between, roughly 
 speaking, the fixed and the variable parts of the system — is generally recognized 
 [Wand and Weber, 1990, pp. 125–126; Weinberg and Weinberg, 1979, pp. 122–
 135]. The relationship between structure and process is that 
 structure constrains 
 process
 . Changes made to a system that are limited to its process components tend 
 to be low in cost because the changes remain local. Changes to a system’s 
 structure tend to be high in cost because they alter the constraints on all the 
 system’s processes that access the changed portion of the structure.
  
 This provides an important part of the explanation for why a concep-tually 
 simple and inexpensive change in a real-world (RW) system is often accompanied 
 by a complex and costly modification to its supporting automated-world (AW) 
 system. This happens when the RW system change is limited to process 
 components, but the corresponding AW system modification requires alteration to 
 structural components. This in turn has nonlocal effects on the system’s 
 processes. High costs are incurred when a chain reaction of compensatory 
 modifications is triggered by the need to adjust many other components of the 
 system to the new constraints.
  
 This constraint relationship between structure and process presents us with a 
 fundamental design problem: how to keep the structural part of a system stable 
 while supporting a wide procedural repertoire that can accommodate future 
 changes. We want changes to be enacted with few
  
 133",NA
9.1 Structure/Process ,NA,NA
Differentiation: ,NA,NA
Generic Structures,"The essence of adaptability to change lies in structure/process differentiation, which 
 is essentially the exclusion of what is variable from what is constant.
  
 The static, structural part of a system is referred to as the “composition”of the 
 system — the set of “things,” their properties, and their interrela-tionships [Wand 
 and Weber, 1990]. Agents that implement value changes within this framework 
 constitute the variable, i.e., the process, part of the system. The essence of 
 adaptability to change lies in structure/process differentiation, which is essentially 
 the exclusion of that which is variable from that which is constant. The implied 
 methodological principle is that, in proceeding through the transformations: RW 
 system 
 
  RW model 
 
 AW model 
 
  AW system, the distinction between structure 
 and process must be discerned in the RW system, then be preserved in the model 
 of the RW system, and in the specification and construction of the AW system. 
 Differentiation of structure and process can also be viewed as an increase in the 
 level of generality of the composition of a system. So we can say",NA
9.1.1 Generic Entities,"Because an entity is a person, place, thing, concept, etc., the idea of a generic entity 
 recognizes that such things come in subtypes. For example, a Person entity can 
 have subtypes of employee, student, dependent, client, etc. The generic entity 
 “organizational unit” can be used to represent an organization’s divisions, sections, 
 departments, etc. Subtypes of a generic entity necessarily have some attributes in 
 common and some that differ. The flexibility to be gained from generic treatment 
 far outweighs the problem of unshared attributes.
  
 Consider an enterprise organized into companies, divisions, and stores as 
 shown in Exhibit 9.1. Exhibit 9.2 shows the traditional structure model 
 representing this organization scheme along with a simple example of a sales entity 
 in which the store sales amount is determined by the key of
  
 Co-ID + Div-ID + Store-ID
  
 If a new type of organization is added to the enterprise, e.g., if strategic 
 business units (SBU) are created to manage groups of divisions, then the model 
 and its corresponding database representation would have to be modified as 
 shown in Exhibit 9.3. What is most important, however, is
  
 Company
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
 Divisi
  
 on 1
  
  
 Divis
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
   
 Store 1
  
 Store 2
  
 Store 3
  
 Store 4
  
 Store 5
  
  
  
 Exhibit 9.1.
  
 Example of Enterprise Organization",NA
9.1.2 Generic Relationships,"The one-to-one (1:1) and one-to-many (1:
 n
 ) relationships are special cases of the 
 many-to-many (
 m
 :
 n
 ) relationship. Wherever we have an 
 m
 :
 n 
 relationship in an 
 information structure, it is clear that it can represent a corresponding 
 m
 :
 n
  or 1:
 n
  or 
 1:1 RW relationship, depending on what data fills it. Thus, it can accommodate a 
 change to the cardinality require-ment at any time without itself needing to be 
 modified. If we desire to enforce a specific cardinality requirement, say 1:
 m
 , then 
 such enforcement needs to be provided outside the information structure. At this 
 point in the discussion, we will simply assume that such an external cardinality 
 enforcement facility exists, as was discussed in Chapter 8.
  
 It is clear that generic relationships along with generic entities confer 
 additional stability on the information structure. As noted previously, generic 
 entities employ recursive relationships.",NA
9.2 Recursive Relationships,"Recursive relationships are a direct consequence of generalization. When an entity, 
 such as organization unit, is a generalization of more specialized entities, such as 
 company, division, and store, and when instances of those specialized entities can 
 be related to each other, then those relation-ships are necessarily represented at the 
 level of the generic entity by a relationship of the generic entity to itself — a 
 recursive relationship. Another way to look at this is to consider that generalization 
 of a set of specialized entities is a sensible concept simply because those entities do 
 stand in one or more relationships to each other. Therefore, the generic entity will 
 necessarily stand in one or more relationships to itself. (The phrase “or more” in 
 the previous sentence will be taken up later in the discussion of roles in Chapter 10, 
 Section 4.) 
  
  
 The combination of the generic entity with a recursive relationship to itself 
 provides the structure for the familiar bill of material (BOM) that relates products 
 to assemblies to parts, etc., from which the traditional indented materials list is 
 produced, as seen in Exhibit 9.6. Of course, the recursions in such a structure must 
 not be endless. The mechanism used
  
  
  
 Exhibit 9.6.
  
 Example of Indented Bill of Material",NA
9.2.1 Nested Recursive Relationships,"The existence of recursive relationships in an information structure has significant 
 implications for processing. It requires reusable routines that can cope with 
 recursive relationships. These, of course, have been built many times for the bill-
 of-materials structure. What is less common is processing of related BOM-like 
 structures. Information structures that contain generic entities will necessarily also 
 contain relationships among different generic entities. For example, consider an 
 on-hand inventory quantity for a specific combination of product, location, and 
 organization unit, each of which is represented generically in Exhibit 9.7. That is, 
 at the database level, the quantity field is an attribute of an association relation 
 with a primary key of product ID + location ID + organization unit ID.
  
 Product
  
 Location
  
 Org Unit
  
  
 Org Unit Inventory
  
  
    
 Exhibit 9.7.
  
 Related Generic Entities",NA
9.3 Typing and Generic Entities,"We use the term 
 m
 :
 n
  relationship and association entity interchangeably. We prefer 
 the term association entity in recognition that it has attributes just as a simple 
 entity does. Attributes, independent of the type of entity, can be single valued, 
 such as a person’s birth date, or multivalued, such as a person’s hobbies. A 
 permanently single-valued attribute can appro-priately be represented “within” the 
 entity it describes, as an attribute functionally determined by the entity’s identifier, 
 as shown in Exhibit 9.8. Assuming we disallow repeating attributes in an entity as 
 required by
  
 Person Person
  
 [Person ID  Birth Date
  
 Hobby
  
 Person ID  Hobby ID
  
  
 Single Valued
  
 Multivalued
  
  
 Exhibit 9.8.
  
 Single-Valued and Multivalued Attributes",NA
9.3.1 Control Types and Consistent Typing,"A generic entity will typically have at least one typing that characterizes the entity as 
 generic. We call this a control type.
  
 There are two distinct ways of grouping entities: “selection” and “typing.”Any 
 dynamic combination of attribute or relationship values of an entity can be used to 
 select the entity for a transient purpose such as production of a report. 
 Generalized query and report-writer tools are designed to do selection to a greater 
 degree than most specialized code. And the larger the set of attribute values, 
 relationship values, and comparisons among these values that such a tool can 
 simultaneously accommodate, the stron-ger is the tool. Typing refers to classifying 
 an entity for an ongoing business purpose. It is typing that concerns us here, not 
 selection.
  
 Typing of a generic entity is accomplished through proper design of the 
 information structure and population of the structure with data values. One or 
 more attributes of a generic entity can be used to type the generic entity. We call 
 such an attribute a control type.
  
 In Exhibit 9.9, recognizing that the business may need to view an 
 organizational unit differently for different purposes, we establish an Org-Type 
 control-type attribute with potential values of company, division, and store. The 
 exhibit shows several instances of organizational units, their types, and the 
 relationships between them.
  
 In Chapter 10, we introduce the generic-entity cloud and show how control 
 types can be used to manage data-related business rules. They can be used to 
 control the number of type values an entity can have. They can also be used to 
 define relationships between control-type values. For example, there may be a 
 need to allow a company to be directly responsible for a division but disallow 
 direct responsibility for a store.
  
 A generic entity can have more than one control type. For example, a generic 
 organization unit might have the usual organization control type (e.g., company, 
 division, store, etc.) and also, say, a legal control type (e.g., incorporated, wholly 
 owned subsidiary, holding, etc.).
  
 The relationship rules imposed by these types may legitimately be inconsistent 
 with each other. This simply means that organization units participate in more 
 than one organization scheme and that the different schemes have different 
 relationship roles. In Chapter 10 we also demon-strate how data structures and 
 values can be used to reflect and manage these inconsistent concurrent types and 
 relationships.",NA
9.3.2 Variable versus Fixed Typing,"If there is anything in the real world that is variable, it is the groupings that we use.
  
 Those involved in exploration of database design methods have focused much of 
 their attention on capturing more meaning in the database schema. An approach 
 that appeared promising was that of declaring sub-/ supertyping distinctions 
 [Hammer and McLeod, 1981]. However, because such typing is static, this method 
 presents significant limitations. Profes-sional IT intervention is required when 
 typing is to be altered. Such alterations are necessarily modifications of the 
 information structure.
  
 If there is anything in the real world that is variable, it is the groupings that we 
 use. A flexible system needs to reflect these groupings used by",NA
9.4 Recognizing Certain Forms of Data,"Developers often find a need to store dates, times, flags, and derived values for 
 system performance reasons. We offer additional flexibility-oriented thinking on 
 these data forms. Derived values need to be in the right place in the data structure. 
 Date and time data may serve two purposes. Flags can be replaced by more 
 flexible multivalued attributes.",NA
9.4.1 Derived Values,"Derived values are implemented for performance reasons. For example, an 
 individual’s current account balance might be stored rather than cal-culated 
 whenever it is needed. Derived values have no effect on the flexibility 
 characteristics of a system. However, it should be emphasized that when derived 
 values are identified during analysis or design, they must be correctly located in the 
 information-structure model. Derived values, regardless of their nature, have 
 functional determinants that estab-lish their correct placement in the information 
 structure. While it may seem obvious that they must be placed correctly, their 
 seemingly informal nature can cause this fact to be ignored. If you find it advisable 
 to maintain derived data elements, recognize that they, just like any other 
 attributes, require adherence to sound information-structure design.",NA
9.4.2 Date and Time,"Date and time can be both attributes and (parts of) identifiers. Generally they 
 serve as attributes. However, when an entity is an event or when an effective 
 period is required, date and time values are used to ensure identifier uniqueness. 
 Dates/times subject to change must always be treated as attributes. If a date or 
 time is part of an identifier (such as effective date), then — because identifiers 
 must be stable and unchange-able — the date in this ID cannot be changed. If the 
 date or time is the expected ship date or time, then it is subject to change and may 
 be changed as the information changes. Any field that is changeable must be an 
 attribute and not (part of) an identifier.
  
 Effective dates and effective periods come into play when it is desirable to 
 track versions of an entity. In analyzing what aspects of a system can change, 
 consider the possibility of versions. When business rules are stored as data, as we 
 strongly recommend, considering that rules change over time, they should have 
 effective dates. If a rule (or any entity for that matter) can have multiple effective 
 dates, then you have a requirement",NA
9.4.3 Flag,"Avoid a physical design that includes data elements that are themselves single-
 purpose flags.
  
 There may appear to be good reasons to include flags in the design of a system, 
 but when designing a flexible system, one must think carefully. For example, in the 
 following cases, the answers to the yes/no questions may provide enough 
 information for certain business processes.
  
 Account Active flag (Is the account active?) 
  
 Y/N 
 Tuition Remission Eligibility flag (Is the person eligible?) 
  
 Y/N 
 Child of Alumnus flag (Is this person the child of an alumnus?) 
  
 Y/N 
 Employee Child flag (Is this person the child of an employee?) 
  
 Y/N 
 U.S. Citizen flag (Is this person a U.S. citizen?) 
  
 Y/N 
 Deceased flag (Has the person died?) 
  
 Y/N",NA
9.5 Bottom-Up Derivation of Generic Entities,"Significant overlap of attributes between two specific entities provides a clue that it 
 may make sense to declare the two as subtypes of a single generic entity.
  
 As discussed previously, attributes contain descriptive information (e.g., name, 
 street address, and social security number) about the entity, but an attribute can 
 serve an additional purpose: to distinguish one entity from another. Sometimes, 
 careful analysis reveals that two apparently different entities have a significant 
 number of attributes in common. However, one or more data elements or 
 attributes typically differentiate one entity from the other.
  
 Significant overlap of attributes between two specific entities provides a clue 
 that it may make sense to declare the two as subtypes of a single generic entity. We 
 believe that a thorough analysis of the necessary data structures requires the 
 analyst to combine both a top-down approach and a bottom-up approach. The 
 top-down approach typically works well when gathering business requirements. 
 When describing an organization’s busi-ness, a member of the business staff 
 might, for example, use terms such as customer, employee, clerk, representative, 
 salesman, etc. Taking a top-down approach might lead the analyst to identify an 
 entity in the system for each of those terms. Taking a bottom-up approach, which 
 works well when designing the actual information structures, is likely to lead to the 
 discovery that these terms have many common attributes and that having one 
 entity — Person — with multiple types provides greater system flexibility.",NA
9.6 Summary,"The differentiation between structure and process in a system —between, 
 roughly speaking, the fixed and the variable parts of the system — is 
 accepted wisdom.
  
 Flexible systems are characterized as stable information structures with 
 wide behavioral repertoires.
  
 Flexible systems require stable information structures.
  
 Separating structure from process raises the generality of the system and 
 makes it more flexible.
  
 Stable information structures are characterized by: invariant, unique 
 identifiers; variable cardinality; generic entities; generic-entity relation-
 ships; recursive-entity relationships; consistent typing; and variable typing.",NA
Chapter 10,NA,NA
The Generic-Entity Cloud,"This chapter introduces the generic-entity cloud (GEC) approach, an 
 analysis/design technique that is particularly effective for developing flex-ible 
 information systems. The GEC is a stable information structure. The following 
 sections show how the GEC is developed step by step, utilizing the characteristics 
 of stable information structures: invariant and unique identifiers, variable 
 cardinality, 
 generic 
 entities, 
 generic-entity 
 relationships, 
 recursive-entity 
 relationships, consistent typing, and variable typing.
  
 The GEC approach utilizes a cardinality-regulation mechanism to define and 
 enforce relationships between and within GECs, as well as broader regulatory 
 mechanisms that eliminate artificial limits from the structural and procedural parts 
 of the software system. The GEC approach provides a pattern for analysis of 
 information system requirements and design of a flexible system that satisfies 
 those requirements. Analyses that follow the GEC pattern will lead to sound and 
 flexible designs. That is, developers will build information systems that support 
 current business requirements and accommodate changes to those requirements 
 with a minimum of intervention from IT staff.",NA
10.1 What Is a Generic-Entity Cloud?,"We want to identify entities in a generic way because things will change.
  
 The generic-entity cloud (GEC) provides an automatic way to implement highly 
 stable data structures. The information structure of a GEC consists
  
 153",NA
10.2 Three-Node Generic-Entity Cloud,"The GEC must support relationships between instances of a generic entity 
 (recursion). This is shown in the general sense in Exhibit 10.3. In the GEC, the 
 generic entity, type, and entity-entity nodes fall within the cloud.
  
 Exhibit 10.3 (and many of the exhibits that follow) is a variation on the typical 
 entity-relationship diagram. The presence of a dot on the line indicates “many.” 
 The absence of a dot indicates “one.” For example, tracing the relationship from 
 “type” to “generic entity,” we see that a given",NA
10.3 Externals,"In addition to the recursive relationships within a generic entity, the GEC 
 approach must support relationships between GECs. This is the typical 
 relationship depicted in an entity-relationship diagram (ERD).",NA
10.4 Six-Node Generic-Entity Cloud,"The schema in Exhibit 10.3 and Exhibit 10.4 allowed the entity to be typed, but 
 only one value of the typing attribute was allowed because the type value was 
 stored with the entity. Similarly, only one association was allowed between entities. 
 For example, two persons could not have multiple relationships, e.g., 
 father/daughter, supervisor/worker, etc. Such limitations do not reflect the real 
 world, where multiple type values and multiple associations are possible. 
 Remember from Chapter 9, control types are what set apart generic entities. The 
 entity itself becomes the generic node in the GEC.
  
 The six-node GEC, by using additional building blocks, facilitates rec-ognition 
 that multiple control-type values may exist and that associations are often qualified 
 with “roles.” The six-node GEC shown in Exhibit 10.13 is not restricted to a 
 mutually exclusive control typing, and the (relation-ship) role adds a dimension to 
 the entity-entity association. An example of multiple control-type values and role-
 qualified associations would be an organization scheme where some organization 
 units are of more than one control type. This could occur in a single-store division 
 or where the relationships among organization units can take on one or more 
 roles, such as direct, line, staff, dotted line, etc., as shown earlier in Exhibit 10.2. 
 The *role file supports adherence to the type-control mechanism (Chapter 9)
  
 *type *type *role 
  
 *type
  
 *role
  
 *generic *type
  
 *generic
  
 *generic *role
  
 *generic
  
  
 Exhibit 10.13.
  
 Six-Node Generic-Entity Cloud",NA
10.4.1 The Final-Form GEC,"As Exhibit 10.14 shows, for a given entity control type, the GEC requires a ring of 
 six supporting information structures. For each control type, the supporting 
 information structures form a ring shape, as illustrated in Exhibit 10.15 (identical 
 to Exhibit 10.1). A series of such rings superim-posed on a single diagram yield a 
 cloudlike appearance, hence the term“generic-entity cloud” or GEC.
  
 The six-node GEC is designed to accommodate the most complex situation. 
 For simpler, more typical situations, cardinality regulation effec-tively masks this 
 complexity. For example, if the generic entity, as currently used in the enterprise, 
 does not have a bill-of-materials relationship, the number of child occurrences is 
 simply set to zero. If an organization currently has multiple control-type values, 
 the number of child occurrences is set to many. If only one is allowed, then the 
 maximum number of children is set to one, and so on. The same logic applies to 
 roles. In a",NA
"10.5 GECs, Attributes, and Flexibility","In the GEC, the T node represents a control type, but it too is characterized by 
 flexibility. The T node represents a multivalued element (MVE). In its most basic 
 form, the MVE simply represents a multivalued attribute (MVA). In its more 
 powerful form, it represents a control type (CT) that generates rings, as we have 
 shown above.
  
 In Chapter 9, we indicated that attribute values provided more flexibility than 
 flags. The GEC structure supports this approach. Exhibit 10.17 gives an example 
 of a system that maintains data about admission prospects who have multiple 
 academic interests and multiple extracurricular interests, all represented as 
 attribute values.
  
 Each of these attributes would be represented as a T node in the GEC. 
 Because a T node always represents a multivalued element (MVE), one or more 
 values can be defined for each attribute, the number being governed by regulation. 
 If the T node is to be considered a control type (CT), rather than simply a 
 multivalued attribute (MVA), the GEC provides for declaration of a typing ring, 
 which includes role (R), type-role-type (TRT), and generic-role-generic (GRG) 
 nodes. R, TRT, and GRG node creation are controlled through cardinality and 
 record-count regulation. To add new attribute values to an existing T node is a 
 simple data-entry job. To add a new T node, another ring must be generated. That 
 auto-matically builds the files and their identifiers. Attribute values can then be 
 added as needed, but no existing data structures need to change.
  
 An MVA-type T node can be converted into a CT-type T node. When this 
 occurs, the declaration of the T node must be modified. This allows the regulatory 
 data for R, TRT, and GRG nodes to be modified. Together, these data 
 modifications result in changes to the operational behavior of the system. Where a 
 T node of type MVA does not permit R, TRT, and GRG nodes, a T node of type 
 CT does. The system modification is purely automatic and safe, without changes 
 to data structure and program code and therefore without the normal maintenance 
 repercussions.
  
 For purposes of data-entry convenience, a system designer might wish to 
 implement a mechanism that allows business staff to enter abbreviations or codes 
 rather than full attribute values. An obvious example would be the entry of well-
 known codes for states, e.g., entry of the code “MA” requires much less time than 
 entry of “Massachusetts.” The code also requires less space for data storage. This 
 approach is neither required nor precluded by the generic-entity cloud. A code by 
 its very nature requires a decoding mechanism. System designers should 
 implement such a mechanism via the generic-entity cloud in a way that provides 
 business control over maintenance of code values. Of course, logic to translate the 
 code into its full equivalent must be developed and implemented in appropriate 
 business processes.",NA
10.6 Externals Connected to Generic-Type Node,"For simplicity of presentation in the previous examples, we have shown externals 
 with a connection between IDs from the generic nodes of the associated GECs. 
 In fact, the connection is made between the external and the *generic*type nodes 
 of the GECs. This means that specific control types of generic entities can be 
 connected, providing additional flexibility. The design of the GEC supports this 
 approach by providing as ring 0 a default control type that carries the name of the 
 GEC.
  
 Default control type has only one value, which matches the name of the 
 generic entity and the control type. The default cardinality of the *generic*type 
 node is set to allow minimum = maximum = 1 from both the generic and the type 
 nodes. For example, the Person GEC has a default control-type value of Person 
 for the control-type Person. This means that if a *generic Person record exists 
 with a value of “Jane,” a *generic*type record with a value of |Jane|Person|| will 
 also exist.
  
 Exhibit 10.18 shows that Locator and Class only have one ring — the default 
 ring — with name and one value of Locator and Class. Person has two rings, one 
 for Person and one for Student, both with one value the same as the name of the 
 control type. Exhibit 10.18 shows that Jane and Tom’s connection to their various 
 locator possibilities is made through their control type of Person. Their 
 connection to enrollment is made through their control type of Student. The 
 |Jane|Person|| *entity*type association record within the GEC may have 
 attributes dealing with Jane as a person, whereas the *entity*type dealing with Jane 
 as a student may have different attributes. Taking this approach allows us to 
 specify that all persons can have locators, but only students can register for 
 classes, exactly the flexibility that the business requires.",NA
10.7 Summary,"The generic-entity cloud (GEC) provides an automatic way to imple-ment 
 highly stable data structures utilizing invariant, unique identi-fiers; variable 
 cardinality; generic entities; generic-entity relationships; recursive-entity 
 relationships; consistent typing; and variable typing. Essential to GEC 
 development is reduction in the number of entities. Where a more 
 traditional approach would identify many specific entities, the GEC 
 approach identifies a reduced number of 
 generic
  entities.
  
 The fully developed GEC has one or more control types, each of which 
 causes a ring of six nodes, all anchored by the common generic entity 
 itself. The generic-entity cloud is named for its cloudlike appearance.
  
 GEC systems do not require reprogramming or database reorgani-zation 
 to reflect changes. Rather, the change can be accommodated with a few 
 entries to the nodes.
  
 Where a many-to-many relationship exists between two GECs, it is 
 generally shown as two separate one-to-many relationships with a separate 
 relationship node that is external to the GECs them-selves. This external 
 general-entity relationship (association) is referred to as an “external.”
  
 The six-node GEC facilitates recognition that multiple control-type values 
 may exist and that associations are often qualified with“roles.”
  
 All GEC relationships are inherently many-to-many associations, which 
 are required for a flexible system.
  
 Part IV presents more detail on the GEC, including several applications of the 
 GEC as well as a number of extensions that show its versatility in designing and 
 developing flexible software.",NA
HOW TO ,NA,NA
III,NA,NA
DESIGN FLEXIBLE ,NA,NA
SOFTWARE SYSTEMS,"Part I introduced the concept of software flexibility and made a case for its 
 necessity. Part II clarified the key ingredients of flexible design, with emphasis on 
 stability of data structures and how stability facilitates business control over 
 change. The six chapters in Part III provide guidance on how to apply the 
 techniques presented in Part II to develop flexible software.
  
 Chapter 11 addresses strategic systems planning as an ideal oppor-tunity 
 to gain access to the diversity of requirements needed for designing 
 flexible software systems. We clarify the importance of both flexibility and 
 application integration and show how the two are mutually reinforcing.
  
 Chapter 12 presents requirements-determination methods for flex-ible 
 software systems. These methods are based on a fundamental 
 reorientation to software design, in which the focus is no longer primarily 
 on functional accuracy, but rather on achieving flexibility. The emphasis 
 of requirements gathering thus shifts to identifying dynamic requirements, 
 especially eliciting and modeling informa-tion 
 structure
  requirements.
  
 Chapter 13 covers two general techniques for flexible software design: 
 structure-oriented and process-oriented. Structure-oriented techniques 
 take the form of information structures composed of generic-entity types 
 and many-to-many relationships that identify and exploit common data 
 characteristics and common patterns of rela-tionships between and within 
 entities. Process-oriented techniques",NA
Chapter 11,NA,NA
Flexibility and ,NA,NA
Strategic Systems ,NA,NA
Planning,"The more diverse the current requirements supported by an information structure, 
 the more that structure will be able to support future require-ments without 
 needing modification. In effect, designing a single database to support multiple 
 application systems is like looking into the future. One does not actually see future 
 requirements per se, of course, but the need to support a broad variety of 
 requirements confers a concurrent need to increase the generality of the database. 
 It is a way to partially offset the reality of imperfect knowledge caused by the 
 impossibility of knowing future requirements.
  
 A good example of this “future now” effect occurred as a result of a strategic 
 systems planning study at a major retailer. Their financial account structure was 
 routinely used for reporting to senior management, share-holders, and the 
 Securities and Exchange Commission (SEC). The enter-prisewide planning study 
 recognized that many of the same accounts were also used for tax reporting but 
 employed a different set of interaccount relationships required by the tax rules. To 
 accommodate the different but related requirements, the database design was 
 generalized to be capable of representing multiple sets of account relationships 
 concurrently. This allowed the integration of general-ledger and financial reporting 
 with tax reporting and the elimination of the previously intractable problems of 
 reports that did not agree with each other. It also made it easy to do what-if 
 processing to explore the financial effects of alternative accounting
  
 177",NA
11.1 The Myth of the Isolated System,"It is common for organizations to develop systems in isolation.
  
 It is common for organizations to develop systems in isolation. Typical thinking 
 goes something like this: “We’ll develop the new project control system initially 
 for the engineering department. Then, as we get require-ments from other 
 departments, we’ll evolve the system and roll it out across the company. This 
 evolutionary approach will be cost-effective and will not commit us to too big a 
 development piece at any one time.” This thinking is based on the myth of the 
 isolated system:
  
 Myth: We can develop systems one at a time and fit them together into an 
 integrated whole as we go along.",NA
11.2 Traditional Planning Approach,"Entire books have been written on the subject of strategic systems planning [e.g., 
 Martin, 1982; Ward and Peppard, 2002], but not many. Enterprisewide systems 
 planning has tended to be the purview of the larger information technology 
 consulting organizations with their proprietary methods. In spite of some 
 distinguishing differences, the usual approaches follow more or less the same steps 
 and apply the same techniques. The basic idea is to develop a blueprint for long-
 term IT direction and investment. There are at least three planning dimensions:
  
 1. 
  
 Technology 
  
 2. 
  
 Organization/management 
  
 3. 
  
 Applications
  
  
 Traditional strategic systems planning steps, which are related to the 
 enterprise’s application portfolio, are usually as follows:
  
 Obtain the backing of top management for the planning study. Identify 
 critical success factors within each major management area. Obtain the 
 organization chart.
  
 Break down the enterprise functionally into understandable pieces 
 (functional decomposition).
  
 Assess current automation coverage by function and identify new 
 automation opportunities.
  
 Construct a high-level data flow model, e.g., data flow diagram (DFD). 
 Construct a high-level information-structure model, e.g., entity-
 relationship diagram (ERD).
  
 Assemble an information-precedence matrix.
  
 Identify development projects and development sequences sug-gested by 
 the precedence matrix.
  
 Apply business priorities to projects.
  
 Prepare a development projects schedule and cost/benefit analysis.",NA
11.3 Stable Enterprise Model,"Pant and Hsu (1995) reviewed the six top planning methods, all of which were 
 developed in the early 1980s with evolutionary refinements accruing through the 
 1990s. Their overall assessment is that most companies found that “planning is 
 unnecessarily detailed and takes a long time,” with notable deficiencies being lack 
 of adequate information-structure models and lack of connection of planning 
 results to subsequent development. Our observation is that the enterprise model 
 that results from traditional planning emphasizes the procedural and variable 
 aspects of a business. In contrast, an enterprise model that emphasizes the 
 structural and stable aspects — those characteristics of an enterprise upon which 
 long-term decisions about its automation resources can be based — provides the 
 foundation for successful strategic planning. Its core deliverable is a reasonably 
 accurate modelof the structural components of the enterprise. (The term “model” 
 here does not refer to a simulation model. In a simulation model, the time-varying 
 activities of a process are simulated to recreate or predict the process’s behavior by 
 altering input parameters and iterating over successive units of time. Rather, we are 
 referring here to an analytic model, in which a system (enterprise) is statically 
 described; a change in the system’s structure or processes will require that the 
 model itself be changed.) It is vital to be able to express automation plans in terms 
 of the real and permanent functions the enterprise performs and the equally real 
 and permanent entities about which it keeps information.
  
 The traditional enterprise model, as a real-world model, is a collection of 
 specialized submodels, some of which are stable and some of which are subject to 
 change. The submodels that are relevant to the application-planning dimension 
 and that are relatively technology-independent include the following:
  
 Organization model (variable) 
  
 Business-function model (stable) 
  
 Information-process model (variable) 
 Information-structure model (stable) 
 Information-precedence model (stable)",NA
11.4 Strategic Systems Planning for Flexibility,"Exhibit 11.4 combines the planning steps and the enterprise submodels to which 
 they apply. The long-term utility of each planning step is assessed in terms of its 
 contribution to the stability of the submodel. Step 8, normally missing from 
 conventional planning methods, has been added as essential for effective planning.",NA
11.4.1 Obtain Top Management Approval (Step 1) ,NA,NA
,"We begin with an equivocal step. This step does not get a full thumbs-up rating to 
 draw attention to some cautions. Obtaining top management approval is always 
 the recommended first step in any systems planning method, invariably strongly 
 recommended by any consultancy involved. This insistence on access and 
 continued visibility to senior management is, of course, a lucrative posture for a 
 consultancy to adopt. The fact is that strategic systems planning and its enterprise 
 model building process entail a great deal of detailed analytical work in which top 
 management typically has little interest. Large portions of the study can be 
 accomplished through a grassroots effort requiring virtually no top-level 
 involvement other than sponsorship. The materials needed to perform the really 
 essential analyses are plentiful at low levels in an organization. The focus of top 
 management approval should, after all, be on the planning study’s recom-
 mendations and results, not on the study itself. Indeed, senior management might 
 expect strategic systems planning to be a normal, ongoing function within MIS 
 (management information system) rather than an extraordinary one. Regarding top 
 management — approval, yes; heavy involvement, no.
  
 Moreover, the process of obtaining a high-level go-ahead usually means 
 overselling the program and proposing to deliver too much in less than the 
 minimum time required. Done properly, a planning study takes time. In an 
 organization characterized by a senior-sponsorship approach to major initiatives, 
 the duration of the effort required will usually exhaust the brief tenure of one 
 sponsor, and the attempted transition to a second often kills the study. Similarly, 
 in the many organizations where IT is itself traditionally under a business manager 
 who is “passing through,” the program becomes associated with the IT head at 
 the time and rarely survives the next change in leadership. In summary, a great 
 deal can be accomplished at a low expense rate over an extended time without 
 major senior management involvement and without the compromises and risks to 
 an effective outcome that go along with high-level visibility.",NA
11.4.2 Identify Critical Success Factors (Step 2) ,NA,NA
,"The point of this step, like the first, is to get buy-in. Identification of critical 
 success factors typically focuses on the performance goals of senior managers 
 whose cooperation is sought. Thus this step can be omitted without loss of 
 essential planning data.",NA
11.4.3 Obtain Organization Chart (Step 3) ,NA,NA
,"A typical product of the early stages of a planning study is a model of the 
 company’s organization. This is simply an organization chart, showing",NA
11.4.4 Perform Functional Decomposition (Step 4) ,NA,NA
,"In contrast to the organization chart, the function model is stable. It identifies the 
 enterprise’s business functions through the well-known process of functional 
 decomposition. The result is a hierarchical structure describing, in a top-down 
 fashion, the most fundamental functions, their subfunctions, and their 
 subfunction’s subfunctions (Exhibit 11.5). The set of functions of an enterprise is 
 one of its most stable characteristics. That
  
 MANUFACTURING
  
 PLANNING
  
   
 M
  
 ARKET 
 A
  
 NALYSIS
  
    
 ·
  
 ·
  
 ·
  
 ANALYZE CUSTOMERS 
  
 ESTIMATE COMPONENT 
 PRICES
  
   
 ·
  
 ·
  
 ·
  
  
  
   
 M
  
 ATERIA
 L
  
 S
  
    
  
 PURCHASING
  
    
  
  CREATE REQUISITION
  
  MAINTAIN SUPPLIER 
 INFORMATION
  
 ·
  
  
 ·
  
  
 ·
  
  
   
 Exhibit 11.5.
  
 Part of a Business Function Model",NA
11.4.5 Assess Automation Coverage (Step 5) ,NA,NA
,"Obviously, we need to know the current state of the organization’s automation 
 efforts. Taking an inventory of current application systems and their health, age, 
 technology employed, maintenance level, degree of integration/interfacing, etc. is 
 useful in itself. It also provides the oppor-tunity to establish a clear and simple 
 correspondence between application systems and enterprise functions. The 
 functional decomposition step (Step 4) produces a stable set of hierarchically 
 related functions, any or all of which are candidates for automation assistance. We 
 recommend establishing a one-to-one correspondence between a 
 function/subfunction and its supporting automated system/subsystem (Exhibit 
 11.6).
  
 This allows the entire application portfolio to be identified, both existing and 
 future, and provides a stable reference for years of planning and implementation. 
 System boundaries are, after all, arbitrary — we can draw them where we want to 
 — so why not make them coincide with the functions they are to automate? 
 Purchased systems can also be fitted into this scheme. Even if their components 
 are scattered noncontiguously over the function model, the correspondence with 
 specific functions/sub-functions is perfectly valid. The degree of automation can 
 be graphically represented and updated over time without destabilizing the 
 business function submodel. Hence, although the degree of automation changes 
 over time, the assessment step is making an essentially stable contribution.
  
 This assessment of automation coverage is a good time to ensure that the 
 enterprise has a technology obsolescence/application retirement plan in place. 
 Without such a plan (one that is followed), the enterprise faces an ever-enlarging 
 application portfolio with its ever-increasing maintenance burden — unless, of 
 course, all the applications are flexible.",NA
11.4.6 Construct a Data Flow Diagram (Step 6) ,NA,NA
,"Counter to expectations, the flow of information actually tells us nothing about the 
 internal structure of that information.
  
 A data flow diagram (DFD) is a picture of how things are done 
 now
 . It is a model 
 of the flow of information within the enterprise and between the enterprise and its 
 environment. It includes descriptions of the processes that originate, change, 
 calculate, store, discard, etc. that information. Producing a data flow diagram for 
 an enterprise, even at a high level, involves time-consuming and painstaking work. 
 The diagram is subject to constant revision as the day-to-day activities of the 
 enterprise evolve. It",NA
11.4.7 Construct High-Level Entity Relationship Diagram ,NA,NA
(Step 7) ,NA,NA
,"The entity relationship diagram (ERD) shown in Exhibit 11.8 can be a useful tool 
 but, by itself, is not adequate for producing a fully developed information-
 structure model of the enterprise, as provided for in Step 8",NA
11.4.8 Construct Detailed Data-Element-Level Information-,NA,NA
Structure Schematic (Step 8) ,NA,NA
,"It is precisely for lack of a 
 detailed
  information-structure model, upon which an 
 enterprise’s application portfolio can be based, that traditional planning efforts fail.
  
 Of the planning steps that have significant planning value, this is the most difficult 
 and time-consuming. But it is a vital step if we are concerned with obtaining 
 something strategically useful over the long term. Although information-structure 
 schematics (in traditional strategic plans) are usually",NA
11.4.9 Identify Subject Databases (Step 9) ,NA,NA
,"Faced with the task of designing a large system, the analyst may be tempted to 
 break the database into separate subject areas. It might appear sensible, for example, 
 to divide the database along the lines of business unit responsibility and design the 
 pieces separately. While dividing a large task into smaller, more manageable tasks 
 makes sense in some contexts, it does not make sense in the context of designing a 
 database. An examination of the information-structure model for any enterprise will 
 show that there are virtually no isolated entities or collections of entities.
  
 Attempts to partition the logical database usually reflect current polit-ical, 
 demographic, or business priority factors, and the long-term result is therefore 
 likely to be unsatisfactory. Virtually all the entities in an enter-prise’s information 
 structure participate in chains of associations, and the functions that access them 
 are subject to changing processing requirements. While there are often technical 
 reasons for physical database partitioning,",NA
11.4.10 Assemble Precedence Matrix (Step 10) ,NA,NA
,"The information-precedence matrix combines the function model from the 
 functional decomposition step (Step 4) with the data entities identified in the 
 information-structure model (Step 8). It simply defines the optimum order for 
 systems implementation based on which information is used by which business 
 functions.
  
 The appropriate access requirement, which we will limit to “create”(C) and 
 “use” (U), is recorded at the intersections for the lowest-level functions. Exhibit 
 11.10 shows the initial stage of a portion of the matrix. Exhibit 11.11 shows the 
 final stage after shifting entities right to left and functions bottom to top until all 
 necessary data creation is accounted for prior to (i.e., above) corresponding data 
 use.
  
  
 The following examples explain how the matrix is interpreted (see Exhibit 
 11.11).
  
 Organization data maintenance
 : To perform this function, one must be able to 
 create (C) an organization unit and create (C) an organization structure.
  
 Cash management
 : To perform this function, one must be able to update (U) 
 an organization unit, update (U) an organization struc-ture, and create (C) 
 a bank account.
  
 Exhibit 11.11 also shows that the matrix was examined for “loops” in which 
 data is both created and used by the same function and for entities used but never 
 created. These conditions are resolved by adding specific entity-creation functions, 
 in this case “organization data maintenance.”Such functions are currently 
 performed within the enterprise but are embedded within other functions, and 
 they need to be identified explicitly (other examples might be “customer data 
 maintenance,” “rate data main-tenance,” etc.).
  
 We can now extract from the matrix one or more optimum development 
 sequences, such that functions that supply data are developed before those that 
 use that data. Automation support for those functions that fall below the gray line 
 in Exhibit 11.11 can be done in any order. When business priorities require 
 development of a system or portion of a system out of the optimum sequence 
 (and they will), the matrix can be used to identify the portions of other 
 systems/subsystems that will need to be at least partially constructed to supply 
 needed data. This is essential informa-tion for properly sizing a development 
 project. The information-precedence",NA
11.4.11 Getting to Projects (Steps 11 to 13) ,NA,NA
,"The last three steps are normal IT project-management practices commonly 
 performed iteratively whether strategic planning has been done or not:
  
 Step 11: Identify development projects.
  
 Step 12: Apply business priorities to projects.
  
 Step 13: Prepare projects schedule and cost/benefit analysis.
  
 As such, they require no expansion here. What is important to empha-size, 
 however, is the acceleration effect that comes with working within an information 
 framework that is already well developed. As each devel-opment project is begun 
 in turn, more of the data is found to be already present and being maintained in 
 production. Making use of previously developed information structures works well 
 when business priorities allow approximating the optimum development sequence. 
 When this is not the case, at least it can be determined when additional steps must 
 be taken.",NA
11.5 Summary,"The more diverse the current requirements supported by an infor-mation 
 structure, the more that structure will be able to support future 
 requirements without needing modification. Strategic sys-tems planning 
 can provide that diversity. As a result, the stable information structure 
 needed to achieve the planning goal of sustainable applications 
 interoperability can emerge.
  
 Achieving interoperability of applications (via integration or inter-facing) 
 across an enterprise is often one of the objectives of strategic",NA
Chapter 12,NA,NA
Requirements ,NA,NA
Determination for ,NA,NA
Flexible Systems,"The software development process is driven by requirements. Typically, the focus 
 is on defining precise requirements and then implementing exactly those 
 requirements. However, once delivered, virtually every major software product 
 produces major disappointments for its customers as new requirements emerge. 
 Experts agree that it is unrealistic to specify precise requirements:
  
 Detailed specification writing is often wasted effort because rapid 
 changes occur during the project, making the specifica-tions obsolete 
 [McConnell, 1996].
  
 Sometimes, our technically oriented analytical personalities would have 
 us specify every detail up front, but it is difficult to do so for two 
 simple reasons. First, the requirements con-stantly change in extreme 
 environments and second, even when the requirements are known, 
 they can too easily be misinter-preted, in part because of the ambiguity 
 of language [Gause and Weinberg, 1989, pp. 14–33].
  
 It is impossible to precisely specify software requirements.…Since 
 complex projects are nonlinear and can be unpredictable,
  
 199",NA
12.1 Myth of Perfect Knowledge,"It is widely accepted that the cost of system modification increases over the course 
 of the development cycle. Clearly, it is more costly to modify a software system at 
 the back end of the development process than at the front end. It takes more 
 effort to modify computer programs and file structures than to modify design 
 specifications, and it takes more effort to modify design specifications than to 
 modify a requirements model. From these facts, a fundamental misconception has 
 emerged: that high system maintenance costs are largely due to imprecise 
 requirements deter-mination (analysis) at the front end of the process. Business 
 staff and managers often say, “We’re spending a lot of money changing this 
 system because we didn’t get all the requirements right at the beginning. We need 
 more exact requirements analysis in our systems development method.”This is the 
 myth of perfect knowledge at work:
  
 Myth: With enough effort, we can attain perfect knowledge of a system’s 
 requirements.
  
 Reality: The real world changes, so knowledge of a system’s requirements 
 is necessarily imperfect because a significant part of the requirements lies 
 in the future and is not available at the time the automated system is 
 developed.
  
 Given this myth, arriving future requirements are viewed as “missed 
 requirements,” whose incorporation into existing software is disruptive. This 
 means that we must rely on techniques other than mere determination of 
 improved requirements. As Brooks [1987] stated long ago in his famous essay, 
 “No Silver Bullet: Essence and Accidents in Software Engineering,”the 
 assumption that a satisfactory software system can be specified in advance is 
 basically wrong. The fact that knowledge of requirements is necessarily imperfect 
 alters the development objective fundamentally — from achieving functional 
 accuracy to providing adaptability to functional change. We must remember that 
 most of the system’s life is in tomorrow and that accuracy today has virtually no 
 effect on flexibility, which is needed to synchronize change with tomorrow’s 
 reality.",NA
12.2 Definition of Effective Requirements,"A fundamental reorientation to software design is required, one in which the focus 
 is no longer primarily on functional accuracy but rather on achieving flexibility.
  
  
 Inadequate definition of requirements often bears the brunt of the blame for 
 systems problems:
  
 Requirements champions can point to millions of dollars that are 
 written off each year in failed software projects; as often as not, they 
 contend, sloppy initial requirements were at the root of the problem 
 [Seeley, 2003, p. 31].
  
 The analytical approach discussed in this chapter can both limit the amount of 
 detail and expand the effectiveness of requirements definitions. One of the driving 
 forces behind the techniques for eliciting flexible-systems requirements is that the 
 more generic the requirements model, the less detailed it needs to be. Think of it: 
 we are getting more (a less costly system to maintain) for a less costly analysis 
 effort. A core concept in getting more for less concerns achieving a better balance 
 between process- and structure-requirements analysis.",NA
12.2.1 Structure/Process Differentiation,"The structure of information, as we perceive it, affects both our process design 
 and our design process.
  
 The imbalance of attention between processing requirements and structural 
 requirements is a major cause of our current legacy of inflexible systems. This 
 imbalance developed, in part, because computerized infor-mation systems have 
 their roots in computer science rather than in business. Even though the first use 
 of computers in business was called“data processing” (and not “information 
 systems”) the main emphasis was on the processing rather than on the data.",NA
12.3 Identifying Dynamic Requirements,"The development of flexible systems shifts the emphasis to iden-tifying dynamic 
 requirements.
  
 The search for the perfect set of static requirements is never ending. The 
 development of flexible systems shifts the emphasis to identifying dynamic 
 requirements. The approach toeliciting requirements for flexible systems builds on 
 standard analytical practice. It adds emphasis to eliciting and modeling 
 information-structure requirements, and it is consistent with various guides on the 
 subject of data modeling.
  
 Our approach has the following primary characteristics:
  
 It discovers both the structure and the processes that govern the behavior 
 of the real-world system.
  
 It clearly differentiates between the structure and the process in its 
 analytical model.
  
 It requires that the physical design observe the analytical model’s 
 structure/process differentiation.
  
  
 These characteristics are achieved through the following analytical tasks:
  
 1. 
  
 Gathering current requirements, both structural and procedural 2. 
  
 Representing the current structural and procedural requirements in 
  
 an 
 analytical model 
  
 3. 
  
 Identifying past, and probable future, variations from current struc-
  
 tural and procedural requirements 
  
 4. 
  
 Questioning cardinality assumptions 
  
 5. 
  
 Identifying candidates for generic entities 
  
 6. 
  
 Identifying conditional logic patterns 
  
 7. 
  
 Iterative analysis and design",NA
"12.1.1 Gathering Current Requirements, Both Structural ",NA,NA
and Procedural (Task 1),"The analyst needs to guide discussions back and forth between business data and 
 business processes to identify what is essential and what is simply an adaptation to 
 a limitation in the current automated system. The",NA
12.3.2 Representing the Current Requirements ,NA,NA
in an Analytical Model (Task 2),"After initial requirements are gathered, the next task involves representing these 
 current requirements in an analytical model or real-world model. We show two 
 diagramming conventions, one for representing processes (Exhibit 12.2) and one 
 for representing information structures (Exhibit 12.3), each at different levels of 
 detail.
  
 Process-oriented models are commonly used at this stage in requirements 
 definition. Exhibit 12.2 presents a traditional information-flow diagram (generally 
 referred to as a data flow diagram, DFD) with labeled symbols: circles 
 representing processes, boxes representing data stores and arrows representing the 
 flow of information. (Sometimes distinctions are also made between information-
 flow arrows and control-flow arrows.)",NA
12.3.3 Identifying Past and Probable Future Variations ,NA,NA
from Current Structural Requirements (Task 3),"When an automated system has been in place for a long time, business staff may 
 have difficulty imagining that business could be done any other",NA
12.3.4 Questioning Cardinality Assumptions (Task 4),"Structural information elicited in the first task included cardinality infor-mation. 
 Questions asked during this initial task included: “What are the cardinalities of the 
 relationships among entities (in relationship to 
 x
  can therebe more than one 
 y
 ,…)?” As the flexibility requirements are further explored through analytical 
 modeling (Task 2) and asking “why” and“change” questions to identify variability 
 (Task 3), the analyst should cultivate an attitude of questioning every cardinality 
 assumption, and particularly those that are one-to-many. In most cases, the usual 
 assumption",NA
12.3.5 Identifying Candidates for Generic Entities (Task 5),"A basic entity is a person, place, or thing in the real world about which we want to 
 record information. Almost any basic, nonassociation entity is a candidate for 
 generic treatment. They may be more common than one realizes at first; generic 
 entities can be obscured by the use of different terms. Often different parts of the 
 organization call the same thing — the same entity — by different names, such as 
 material, item, assembly, part, component, product, packaging, finished good, etc. 
 When the analyst has a set of terms that are generally recognized as merely 
 synonymous, then it is only necessary to ensure that a standard term is adopted in 
 the information-structure model. The difficulty arises when there is not general 
 agreement.
  
 For example, at an aluminum company, materials management and operations 
 personnel were organized separately from the manufacturing management and 
 operations personnel, who in turn were organizationally separate from the 
 finished-goods people. There were three distinct sub-cultures within just the 
 production stream, with their own terms and proprietary attitudes about “their” 
 items. It took analysts several iterations to see that they were all working with a 
 common entity. With the identification of a generic “item” entity, multiple entities 
 were reduced to",NA
12.3.6 Identifying Conditional Logic Patterns — Business ,NA,NA
Rules (Task 6),"As the analyst asks the process questions — “What is done?” “How is it done?” 
 — some of the answers identify conditional logic patterns. These patterns 
 constitute rules for order shipment when inventory is short, credit terms, sales 
 commissions, billing algorithms, wire sizing, overtime and bonus calculations, and 
 the like. Today, these are generally called business rules. Consider some of the 
 “requirements” uncovered by an analyst during a sales automation project, as 
 shown in Exhibit 12.8.
  
 It should not take much of this for the alert analyst from Exhibit 12.8 to 
 discern that she has essentially a set of varying selection conditions that is a 
 candidate for a generic condition selection process. At that point it is necessary 
 only to document the factors (e.g., product type, price, customer, etc.) and not the 
 details or specific combinations. Elaborate modeling of rules is often not 
 necessary if the essence of a rule set is understood and if the intention is to design 
 a facility that provides maintenance of rules through data manipulation during the 
 operation of the system. For another example, see the Investment Trust Bank 
 project discussed in Chapter 2.",NA
12.3.7 Iterative Analysis and Design (Task 7),"The traditional waterfall or serial development method can be character-ized as 
 “first you do this, then you do that, then you’re done.” While a certain degree of 
 analysis must necessarily precede design, there is much to be gained from iterating 
 the two steps in a cycle and intentionally overlapping design with analysis.
  
 In the case of UniverSIS, the work began with a careful analysis of the business 
 data requirements followed by design of the supporting information structure. On 
 those occasions when design work indicated that essential details had been missed, 
 further analysis was undertaken. When analysis showed the design to be inadequate, 
 the developers reworked the design. More often than not, the redesign was 
 necessary because the original design was too rigid. Though it was painful, the 
 effort of correcting the design to make it more flexible was worthwhile in the long 
 run.
  
 12.3.7.1 Prototyping — a Strong Note of Caution
  
 We recommend use of prototyping only with a stable information structure and 
 only where it will elicit better, faster, or more flexible requirements.
  
 It is a short step from analysis/design iteration to analysis/design/build 
 iteration, which, when done in small increments, is prototyping. Proto-typing is a 
 way to both elicit and confirm understanding of requirements.",NA
12.4 Agile Methodologies,"Lying in the same methodological direction, but beyond prototyping, are more 
 “extreme” approaches to programming referred to collectively as 
 agile methodologies
 . 
 From the perspective of systems flexibility, what is most significant about these 
 methodologies is, first, their recognition of the primacy of change and, second, the 
 direction taken in reaction to this recognition.
  
 The perceived expense of the initial development process and the even 
 higher perceived expense of making adjustments after",NA
12.5 Summary,"A fundamental reorientation to software design is required, one in which 
 the focus is no longer primarily on functional accuracy but rather on 
 achieving flexibility.
  
 A key point behind the techniques of eliciting and presenting 
 requirements in a flexible structure is that the more generic the 
 requirements model is, the less detailed it needs to be.
  
 The development of flexible systems shifts the emphasis to identi-fying 
 dynamic requirements. It builds on standard analytical practice, yet adds 
 emphasis on eliciting and modeling information-structure requirements.
  
 The flexible approach has the following primary characteristics: 1. It 
 discovers both the structure and the processes that govern 
  
 the 
 behavior of the real-world system.
  
 2. It clearly differentiates between structure and process in its 
  
 analytical 
 model.
  
 3. It requires that the physical design observe the analytical 
  
 model’s 
 structure/process differentiation.",NA
Chapter 13,NA,NA
System Design with ,NA,NA
an Eye on ,NA,NA
Flexibility,"To build flexible systems, programmers must orient their thinking to writing code 
 that works indirectly rather than directly. This approach runs counter to the 
 traditional approach of programmers, who take pride in finding ways to reduce 
 processing time. In flexible systems, programs often contain the logic to look up 
 the rules wherever they are stored rather than the logic of the actual business rules 
 themselves. Furthermore, because the developers have isolated many reusable 
 pieces of complex logic, programs are often assemblies of references to other 
 specialized programs. This approach takes some getting used to. It also requires 
 good communication, good documentation, and good project management. The 
 independent-minded programmer who would rather do things his own way 
 presents a significant barrier to the success of such an approach. It iscritical that 
 management take an active role in establishing and enforcing adherence to 
 standards, including the concept of reuse.
  
 This chapter covers two overall techniques for flexible software design:
  
 1. 
  
 Structure-oriented techniques 
  
 2. 
  
 Process-oriented techniques",NA
13.1 Structure-Oriented Techniques for ,NA,NA
Flexible ,NA,NA
Software Design,"Structure-oriented techniques were introduced in Chapters 9 and 10. They take the 
 form of information structures composed of generic entity types and many-to-
 many relationships that identify and exploit common data characteristics and 
 common patterns of relationships between and within entities. Exhibit 13.1, which 
 is a diagram of the basic generic components discussed in Chapter 9, shows least-
 specialized entities and least-constrained relationships used in combination. Exhibit 
 13.1 shows multiple generic things related to themselves recursively as well to other 
 generic entities.
  
 An order-processing system is used to illustrate what happens when a series of 
 requirements changes are imposed on a system with overly constrained 
 information structure (Exhibit 13.2) compared with the corre-sponding effect on a 
 flexible schema (Exhibit 13.3) employing an external cardinality-enforcement 
 mechanism.",NA
13.1.1 Requirement A,"The initial requirement is that there is only one customer per order and that all 
 products are in one location. Exhibit 13.2 supports this requirement.
  
 Thing-Thing
  
 Generic
  
 Thing-Type
  
 Relationship
  
 Thing
  
 Associative 
  
 Other Generic
  
 Thing
  
 Thing(s)
  
  
 Thing-Thing
  
 Generic
  
 Thing-Type
  
 Relationship
  
 Thing
  
 [Parent-Thing-ID]
  
 + [Child-Thing-ID]
  
 Thing-ID
  
 Thing-Type-ID
  
 Exhibit 13.1.
  
 Basic Generic Components",NA
13.1.2 Requirement B,"The company expands to multiple warehouses, with the possibility of each 
 product being inventoried at multiple warehouses. Exhibit 13.2 runs into trouble 
 here. The product record is linked to a specific warehouse. Recording the fact that 
 a product can be inventoried at multiple locations will require modifications to 
 information structures and program code.
  
 The inventory entity of Exhibit 13.3 absorbs this change without modification. 
 The initial requirement of a product being inventoried in only one location is 
 managed with cardinality regulation. Adjustment to allow multiple inventory 
 locations is accommodated with only a data value update in the cardinality facility.",NA
13.1.3 Requirement C,"Customers require additional discrimination: ordered-by, ship-to, bill-to, and sale-to 
 customer. Again Exhibit 13.2 runs into trouble. The data",NA
13.1.4 Requirement D,"Multiple ship-to customers and split commissions are required on the same order. 
 For Exhibit 13.2, modifications to accommodate this new require-ment build on 
 its previous modifications, continuing to move it closer to the Exhibit 13.3 design.
  
 In Exhibit 13.3, recording of multiple ship-to customers is just a matter of 
 recording shipment action and Customer-ID along with Order-ID in the Order 
 Disposition record. The customer record will be associated with the salesperson 
 or persons (not shown) who is to receive the correspond-ing whole or fractional 
 commission.",NA
13.1.5 Requirement E,"Different types of related organization components (corporate office, division, 
 subsidiary, etc.) are required, as are different types of related orders, products (bills 
 of material), and company properties. Modifications to the Exhibit 13.2 design 
 would by now have brought it essentially into agreement with the Exhibit 13.3 
 design.
  
 The generic structure in Exhibit 13.3 absorbed all the changes without 
 modification. It is important to recognize that the specific changes iden-tified in 
 these scenarios need not have been known in advance for the designers to have 
 adopted the flexible design at the outset. Also, the flexible schema and the 
 cardinality-regulation facility provide independent benefits. That is, the schema 
 can be used without a cardinality-regulation facility, in which case business staff 
 must be relied upon to manually enforce current cardinality requirements. The 
 addition of automated support for cardinality enforcement confers an extra 
 benefit of improved reliability on top of an already substantial benefit of reduced 
 IT maintenance.",NA
13.2 Process-Oriented Techniques for ,NA,NA
Flexible ,NA,NA
Software Design,"Process-oriented techniques identify and exploit common logic patterns supported 
 by common information structures. The following are two specific examples of 
 process-oriented flexibility techniques that have been successfully employed in 
 commercial systems.",NA
13.2.1 The Dynamic Condition Search,"Consider a sales commission example based upon the order-processing system 
 requirements presented in Exhibit 1.3 and Exhibit 12.8. Converted to a general, 
 but still informal, description, the commission requirements could look like this:
  
 In our business practice we use a condition value called “com-
 mission.” The value of this condition depends on a number of factors 
 that are connected with products, salespersons, and customers, 
 including product, salesperson, and customer clas-sifications. The 
 connection between the condition value and these factors is not fixed; 
 it varies based on changing business situations.
  
  
 Other values like discounts, fees, etc. often have similar complex and variable 
 requirements.
  
 The dynamic-condition-search approach represents this requirement with two 
 files and a search program that operates on data provided by, in our example, a 
 transaction file. The transaction file is shown in Exhibit 13.4 along with the 
 transactions as a table with a header designating the fields in the transaction file. 
 The two specific dynamic-condition-search files are:
  
 1. 
  
 The condition file along with its table, which is shown in Exhibit 13.5 2. 
  
 The commission file along with its table, which is shown in Exhibit 
  
 13.6
  
 In Exhibit 13.7 we show the results of running the dynamic-condition-search 
 program using the data shown in Exhibits 13.4 through 13.6. The Java program 
 that produced the output is shown in Appendix 13 at the end of the chapter.
  
 For each transaction file record, the dynamic search program starts again with 
 the first record in the condition file to build an argument with",NA
13.2.2 The UniverSIS Evaluator,"This section introduces the UniverSIS Evaluator and describes its general 
 operation. A much more detailed presentation with examples is included in 
 Chapter 18.
  
 The goal of flexibility often runs up against the reality of complex business 
 requirements. In a university, examples include admission requirements, 
 registration requirements, charging requirements, and eligi-bility requirements of 
 various types. These requirements combine logic with valid values. Even in 
 systems where developers have placed the lists of valid values under user control, 
 the logic is typically coded in programs. Because change in business logic is a high-
 cost maintenance item, the UniverSIS developers analyzed how a system handles 
 business logic. The goal was to place control of business logic in the hands of 
 business staff for those processes in which the business rules are known to change.
  
 One way of placing control of business logic in the hands of business staff is 
 the process of selecting records based on specified criteria. Selection logic, often 
 used in report processing, actually involves specifying business rules. Business 
 staff want to select a group of students who fit a particular profile. They specify 
 parameters. A program compares the parameter values with the values on the 
 student’s record. If the values match, the record is selected. The users control the 
 valid values, but the programmer codes the logic directly in the program.
  
 IF ACADEMIC-INTEREST EQ “parameter”
  
 If the parameter value is HISTORY, the above statement becomes
  
 IF ACADEMIC-INTEREST EQ HISTORY
  
 In this example, the logic IF ACADEMIC-INTEREST EQ is coded in the 
 program, and the parameter HISTORY is under business control. If the result of 
 this statement is true, the student is selected. Note that the use of parameters 
 rather than hard-coding HISTORY provides some flexibility. Programmers can 
 add complexity and flexibility to this approach, allowing ranges of values and 
 multiple input parameters, but the logic is tied to specific data elements.
  
 The UniverSIS developers built something more flexible: a set of general-
 purpose tools that give users control over both the logic and the values. Business 
 staff define and store criteria. The system evaluates those criteria and determines 
 whether an individual meets them.
  
 For example, the admissions office might wish to recruit students from a 
 particular area who are interested in science. The criteria might look like the 
 following.",NA
13.3 Summary,"Structure-oriented techniques for flexible software design take the form of 
 information structures composed of generic entity types and many-to-
 many relationships that identify and exploit common data characteristics 
 and common patterns of relationships between and within entities.
  
 Systems that follow structure-oriented techniques for flexible soft-ware 
 design, through data value and cardinality changes, avoid information 
 structure (and processing) modifications as the busi-ness develops and 
 new requirements are encountered.
  
 Generic structures generally absorb business changes without mod-
 ification, even when such changes are not known in advance. Process-
 oriented techniques identify and exploit common logic patterns, supported 
 by common information structures.
  
 In a flexible system, business rule processing must not be buried in 
 program code. Business rule processing must be under the control of 
 business personnel, not IT personnel.
  
 The dynamic condition search and the UniverSIS Evaluator present two 
 examples of business rule processing that meet the require-ments for a 
 flexible system.
  
 Although the approaches presented in this chapter may require more 
 computing resources, given today’s ever-increasing computer capabilities 
 and their ever-decreasing costs, it seems more than prudent to reduce 
 maintenance costs by enabling business person-nel to make business rule 
 changes without having to call upon IT to modify the program code.
  
 As shown in this chapter, structure-oriented techniques for flexible software 
 design go hand in hand with process-oriented techniques for flexible software 
 design. Without generic stable information structures, it is difficult to produce 
 stable flexible processes.
  
 The application of the dynamic condition search and evaluator tools is limited 
 only by the designer’s imagination. More information on the UniverSIS Evaluator 
 operation and implementation is provided in Chapter 18.",NA
Appendix 13: Dynamic Condition Search ,NA,NA
Program Listing (in Java),"import java.util.*; 
  
 import java.io.*; 
  
 import java.awt.*; 
  
 import java.lang.*; 
  
 public class DynamicConditionSearch 
  
 {  public static void buildArgument(String s)throws 
 IOException
  
  {   String t, c, argument = """", commission;
  
  int i, 
 j,k, l;
  
  
  t = s;
  
  
  RandomAccessFile C = new RandomAccessFile
  
   
   
  
  (""C:\\java\\DynamicConditionSearch\\Data\\ 
   
   
  
   
 Condition.dat"",""r"");
  
  
  if (C != null)
  
  
  {  c = C.readLine();
  
   
   
  commission = ""00.00"";
  
   
   
  while (!c.equals(""EOF""))
  
   
   
  {   //System.out.println (""c = "" + c );
  
   
   
  //EnterKey e1 = new EnterKey();
  
   
   
  
  argument = """";
  
   
   
  
  for (i = 0; i < 6; i++)
  
   
   
  
  { if (c.substring(i + 5,i + 
 6).equals(""1""))
   
  
  
  
  
  
  
  {    l = (i * 5 )+ 5; 
  
   
   
  
     
  
 k = l + 5; 
  
   
   
  
     
 argument = argument + 
 t.substring(l,k);
  
  
  
  
  
  
   
  } //if
  
   
   
  
    
  else argument = argument + ""*****"";
  
   
   
  } //i loop
  
   
   
  
  commission = findCommission(argument);
  
   
   
  c = C.readLine();",NA
Chapter 14,NA,NA
Implementing ,NA,NA
Stable Identifiers,"Chapter 7 presented many types of unstable identifiers to be avoided when 
 implementing a flexible software system. This chapter presents the“how to” of 
 implementing stable identifiers in multiple contexts. We start with the basic rule 
 and then discuss its various applications.",NA
14.1 The Basic Rule,"Our basic rule for generating stable identifiers (IDs) is as follows:
  
 A stable-entity identifier is assigned on a next-sequentially-available-
 number basis starting with 0 and incrementing by 1.
  
  
 There should be no omissions or reservations of blocks of numbers. Each 
 assigned value is unique and contains no explicit or implied infor-mation of any 
 kind. A practical rule regarding the size of the identifier is that the number of digits 
 in an identifier is that which accommodates ten times the highest of three informed 
 estimates of the maximum number of instances of the entity likely to occur over 
 the lifetime of the enterprise or for the next 20 years, whichever is longer. (This is 
 equivalent to adding an extra digit to the estimated number.) 
  
  
 This rule forms IDs from numbers simply for convenience in assigning them, 
 whether manually or automatically. Obviously, using numbers and
  
 243",NA
14.2 Applying the Basic Rule,"The following are factors in applying the basic rule:
  
 Internal and external identifiers 
  
 Hidden versus exposed internal identifiers 
  
 Global internal identifiers 
  
 Identifier size 
  
 Reuse of IDs assigned to deleted (obsolete) things 
 Distributed ID assignment 
  
 Codes 
  
 Internet names
  
  
 Most of the following material is oriented toward design considerations in 
 implementing system-assigned identifiers.",NA
14.2.1 Internal and External Identifiers,"If an existing real-world ID is a fully stable ID, then it can be used as an ID in the 
 automated-world system, and it is a simple matter to incorporate it by starting the 
 automatic assignment with the next unused value. If it is not a stable ID — and 
 most existing IDs are not — then it cannot be used as a primary identifier in the 
 automated-world system. There are basically two options for resolving this:
  
 1. 
  
 Replace the old unstable ID with the new stable ID. This is the 
  
 simplest solution if costs and preferences permit. However, the",NA
14.2.2 Hidden versus Exposed Internal Identifiers,"Others who have proposed the use of information-free IDs in automated-world 
 systems tend to recommend restricting them to internal use only",NA
14.2.3 Global Internal Identifiers,"Handling duplicate internal IDs that arise when systems are merged was discussed 
 in Section 14.2.1. But there are two additional ways in which duplicate internal IDs 
 can occur: through consolidator applications and through entity supertyping. 
 Assigning internal identifiers globally, without regard to entity type, will prevent 
 such duplicates from occurring.
  
 What are sometimes termed “consolidator” applications can give rise to 
 duplicate IDs. The accounts payable application is an example. At a food 
 distributor company, the freight management system assigned IDs to shipment 
 invoices and fed them to the accounts payable system. The warehouse 
 management system also fed its independently identified invoices to the same 
 payables system. Despite care taken to ensure that the IDs were assigned from 
 different number ranges, the different rates of invoice generation resulted in 
 duplicate IDs arriving at the payables system every few years. The ancient payables 
 system did unspeakable things to records with duplicate IDs, and it typically took 
 some weeks for the overlap to be recognized and corrected. This situation 
 worsened with the addition of a new brokerage system and its independently (and 
 manually) assigned invoice IDs. Of course, in a mixed environment of packaged 
 and custom applications, it is unrealistic to expect all applica-tions to use a 
 common ID generator. In that case, one is forced to ensure that consolidator 
 applications such as accounts receivable expect dupli-cates and handle them 
 appropriately. This could range from simply raising an error condition to treating 
 all inbound IDs as external IDs, as described in Section 14.2.1 The essential point 
 is that, where possible and practical, one should assign internal IDs globally 
 regardless of entity type to avoid possible future duplicates.
  
  
 The ability to support changes in the classification of an entity is an essential 
 element of the flexible system. The structures that support flexible subtyping were 
 discussed in Chapter 9. It is important to recognize that supertyping as well as 
 subtyping can occur. For example, suppose an existing real-estate entity and an 
 existing equipment entity are subsumed under a more generic asset entity, as 
 shown in Exhibit 14.5. A globally assigned internal ID would have avoided the 
 duplicate Asset ID values. (The example in Exhibit 14.5 is only to illustrate 
 duplicate IDs and does not reflect encoding of asset type or the possibility that an 
 asset might be of more than one type.) 
  
  
 Another benefit of a global internal ID is that it supports an ultimate supertype 
 entity. Supertyping cannot be done without IT intervention. Only subtyping can be 
 done dynamically. Implementing the example of Exhibit 14.5, where a supertype 
 entity replaced existing entities, would entail significant information-structure 
 change and consequent reprogramming,",NA
14.2.4 Identifier Size,"A practical consequence of global ID assignment is that the ID must be large 
 enough to accommodate all instances of all types of things that can be expected to 
 occur in the lifetime of the system while alsoallowing for multiple systems sharing 
 a single ID-assignment facility. This is why, in Exhibit 14.1, Bruce suggested to 
 Cindy that the potential instance counts in the proposed general-ledger software 
 be added to the estimates just received for the MRP software.
  
 This leads to two design issues: the response time of a shared ID-assignment 
 function and the presentation of a large ID. The resource-contention problem has 
 numerous solutions, including keeping the next available ID in memory or 
 employing a resource-allocation algorithm. For",NA
14.2.5 Reuse of IDs Assigned to Deleted (Obsolete) Things,Just do not do it.,NA
14.2.6 Distributed ID Assignment,"For various reasons, an ID-assignment facility must sometimes be physi-cally 
 distributed, say, to different plants in different cities. In such cases, a block of 
 nonoverlapping numbers may need to be distributed to a separate ID assigner. 
 There are two considerations in this case. First, as we saw earlier, some mechanism 
 must be in place to ensure that there is no overlap in the IDs assigned, or, failing 
 that, there must be some mechanism to cope with a temporary overlap. Second, 
 application systems must not exploit any information that can be inferred from the 
 number range in which an ID occurs. If that information is significant, then it 
 must be recorded as an attribute. This is not a trivial concern. It raises the issue of 
 what we call circumvention paths, which are discussed at the end of this chapter.",NA
14.2.7 Codes,"Codes are not usually accorded the status of a full identifier due to the often 
 mistaken notion that one is encoding only an attribute rather than an entity.
  
 Many codes found in systems today are unstable. Codes are not usually accorded 
 the status of a full identifier due to the often mistaken notion that one is encoding 
 only an attribute rather than an entity. For example, the color of a product might 
 be encoded as R (red), B (blue), G (green); or the product line might be encoded as 
 HDL (heavy duty liquid), LDL (light duty liquid), DRY (dry powder), etc. Virtually 
 any attribute is a candidate for encoding for ease of data entry, space savings, and, 
 of course, uniqueness. But virtually any attribute also has the potential to become 
 an entity in its own right about which information is to be kept.
  
 Color, to interested parties as diverse as chemical engineers and adver-tisers, 
 has numerous relevant attributes: how the color is produced, its reflectivity, its 
 covering ability, its connotations, etc. In a system initially designed to track 
 shipping orders, warehouses were encoded as M (main warehouse), 2 (2nd Street 
 warehouse), and B (Bank Street warehouse).",NA
14.2.8 Internet Names,"A significant issue in Internet operations concerns the persistence of names. The 
 Web is full of broken strands. In some cases, the object referenced by a link no 
 longer exists; in other cases, the object still exists, but the name that serves as its 
 link has been changed. This is a serious matter that will soon have repercussions 
 that go far beyond the current inconvenience experienced by people who come 
 upon a broken link. As Internet-served data becomes integrated into the operation 
 of application systems, this problem will have the same effects as a system that 
 failed to maintain existence and referential integrity in the databases used by those 
 same applications. Both would be equivalent failures.
  
 The Web currently provides no automatic detection or appropriate response to 
 an attempt to (a) delete an object to which a link points or",NA
14.3 Circumvention Paths — Back to the Beginning,"Flexible systems need stable IDs, and stable IDs need flexible systems.
  
 Customers of automated-world systems are quite ingenious at devising ways to 
 circumvent limitations in the systems with which they work. Customers frequently 
 resort to using identifiers to convey information that is not otherwise maintainable 
 in the system as it currently functions. The",NA
14.4 Summary,"Stable identifiers used by automated-world systems must be assigned 
 automatically on a next-sequential-number basis.
  
 Identifiers should also be assigned globally without regard to entity type to 
 preclude duplicate IDs where different entity types become subtypes of a 
 common supertype.",NA
Chapter 15,NA,NA
Testing and ,NA,NA
Maintenance of Flexible ,NA,NA
Software,"It is generally understood that testing is essential, even on a small software 
 modification, to ensure the fidelity of the modification. Testing is required not 
 only for a modification in the system code or information structure, but it is also 
 required for changes in input data if the purpose of the data is to “instruct” the 
 system, i.e., to alter the system’s reaction to transactions. Such input data fall into 
 the category of regulatory data.
  
 When testing changes to regulatory data that will result in implemen-tation of 
 new or modified business rules, it is not enough to test entry of the data. The fact 
 that the system accepted the data may mean only that they were entered in correct 
 form using valid values. That in itself does not guarantee that they will produce 
 correct results. Programmers are all too familiar with the distinction between 
 correct program syntax and correct program results.
  
 Testing involves executing system processes and comparing the results with 
 results determined to be correct. Testing occurs in two distinct phases: (a) during 
 development, prior to system operation, and (b) during ongoing operations and 
 modifications. See Exhibit 15.1 for a discussion of real-life testing challenges.",NA
15.1 Errors Encountered in Testing,"Errors encountered in testing fall into four categories:
  
 257",NA
15.1.1 Operator Error,"Operator error typically involves recording valid but incorrect data. Because no 
 business rules are violated, the system cannot trap the error. Examples would be 
 typing an individual’s address incorrectly, transposing digits in an amount, etc. 
 There is no system protection against valid but erroneous data entry. Operator 
 errors are typically the easiest to detect and correct.",NA
15.1.2 Invalid Data Error,"Invalid data typically results from a hole in the business rule logic, an error of 
 omission. Discovery of invalid data will be traced to data validation logic. Rigorous 
 design and testing at initial implementation keeps this type of error infrequent, but 
 any time new data structures and programs are introduced, there is a chance that 
 such errors will occur. This is where a flexible system has an advantage over an 
 inflexible system. The data structures and supporting business rule logic will be 
 stable, i.e., they will not need to change as business staff make system 
 modifications through changes in regulatory data.",NA
15.1.3 Processing Logic Error,"Processing logic errors involve either (a) the system doing something it should not 
 do or (b) the system not doing something it should do. Such errors also indicate 
 inadequate testing of scenarios. It is critical that unlikely scenarios be tested as well 
 as likely scenarios.
  
 Unfortunately, when logic errors have resulted in generation of invalid data, IT 
 staff intervention is needed to find and correct the records. It does not matter 
 whether the system that generated the invalid data is flexible or inflexible, or 
 whether the logic was coded or maintained as data by business staff. There is 
 nothing magic about flexible systems in this regard. Correction of records is a 
 highly technical and time-consuming process that can and should be avoided 
 through thorough and rigorous testing.",NA
15.1.4 Hardware and System Software Error,"While the three types of errors above are the most common and may account for 
 99.44 percent of the errors in a software system, hardware and system software 
 errors cannot be totally excluded. The authors, in their careers, have experienced 
 system software errors. One such error caused the operating system to crash 
 whenever the software split a disk sector. Another operating system sort could not 
 handle zero records. The temporary solution was to (a) modify the documentation 
 to indicate that a zero record sort was not possible and (b) make sure to write one 
 dummy record that could be deleted downstream. Even the hardware cannot be 
 assumed to be totally guiltless. Consider, for example, the case of the card reader 
 that intermittently skipped a column and read the contents of an 80-column 
 punched card into 81 columns. The 81st column just happened to be a malicious 
 instruction that caused the next print job to abort. This was a case where cause 
 and effect were far, far removed. These examples of hardware and software errors 
 are relatively old; modern errors lead to",NA
15.1.5 Flexible System Can Reduce Processing Logic Error ,NA,NA
to Operator Error,"In UniverSIS, a processing logic error actually falls in the category of operator 
 error.
  
 Business staff controlling business rules through regulatory data can easily 
 make the same types of errors that programmers make in coding business rules in 
 programs. The good news is that, in a flexible system, what used to be logic errors 
 can become operator (business staff) errors, which are typically easy to detect and 
 correct. For example, within UniverSIS, there is a feature called the Evaluator, 
 discussed in Chapters 13 and 18. The Evaluator allows business staff to define 
 logical conditions in much the same way that programmers write such conditions:
  
 Balance
  
 GT
  
 10.00
  
 GPA
  
 LT
  
 2.00
  
 Major
  
 EQ
  
 History
  
 State
  
 NE
  
 California
  
  
 It is very easy to set a condition as GT (greater than) by mistake when in fact it 
 should be been LT (less than), or to set a condition as NE (not equal) when it 
 should have been EQ (equal). The system can validate that, for example, “State” is 
 a valid value and that “NE” is a valid value and that “California” is a valid value 
 for “State.” It cannot determine that you actually meant to say “State EQ 
 California.”
  
  
 In an inflexible system, such logic would have been in program code. The error 
 would have fallen into the category of “processing logic error.”In UniverSIS, it 
 actually falls into the category of “operator error.” Detection of the cause of the 
 error may involve approximately equivalent effort, although in the inflexible 
 system a programmer would have to do the research. In the Evaluator example, 
 business staff does the research by examining the data they entered. Correction of 
 the error in the inflexible system would involve a change to program code and all 
 associated testing.
  
 Business staff manage correction and testing of Evaluator conditions.",NA
15.2 Two Phases of Testing,"Business staff have always been responsible for testing. They have always provided 
 initial business requirements for technical staff and verified the",NA
15.2.1 System Testing during Development,"There will be no possibility of calling the developer from the middle of the ocean. 
 The business staff will have to do their own maintenance.
  
 For initial development of a flexible system, the testing process will be similar to 
 that of traditional development. During this phase, the program information 
 structures and code are tested, which is in effect a test of the accuracy of the 
 communication of business requirements from business staff to the IT staff. 
 Programmers do their best to make their code bug-free and efficient in satisfying 
 the requirements stated by the business experts. But errors occur and 
 misunderstandings arise. Even when there are no errors or misunderstandings, 
 testing may reveal holes in the logic. Errors of omission are common — what we 
 called in Chapter 1 “missed requirements.”
  
  
 It is important to remember here the need to test with an eye on flexibility. 
 Highsmith [2000, p. 168] warns that “without expending con-siderable effort, 
 developers find it difficult to test for maintainability of an application.” It is 
 essential that designers make sure not to reduce flexibility with ill-conceived design 
 features that will lead to expensive and disruptive maintenance.
  
 It may not occur to anyone who has not experienced it that someone might 
 enter data that is completely wrong. The business staff and pro-grammer may have 
 tested the situation in which all data was entered correctly and found that things 
 work perfectly. That is a best-case scenario, and both business staff and 
 programmer must never think in terms of the best-case scenario. They must 
 consider that anything that physically can happen will happen and account for it in 
 the regulatory logic of the system (see Chapter 8, Regulation). There may be a 
 tendency on the part of the business staff to trust that the programmer has done 
 things right, particularly if things have gone well in the past. In the back of their 
 minds may be the thought that the programmer will fix things that are found to be 
 wrong. Business staff must not have this attitude. They should be thinking in 
 terms of a sea voyage. The system has to be seaworthy when it leaves the dock. 
 There will be no possibility of calling the programmer from the middle of the 
 ocean. The business staff will have to do their own maintenance.",NA
15.2.2 Testing during Ongoing Operations,"Maintenance will still be required, but who performs the main-tenance and how it is 
 performed will change.",NA
15.2.3 Guidelines for Testing,"Wherever it resides, business logic must be tested before it is activated in a 
 production environment. Business staff who maintain business rules",NA
15.2.4 Testing Platform,"For programmers who are accustomed to testing a system, it is a given that 
 modifications are made and tested in a nonproduction environment. This fact may 
 not be obvious to business staff, and so it must be emphasized as part of their 
 training. An approach used in many shops provides a minisystem to test the 
 localized effects of the proposed modifications. Such a minisystem will have a 
 complete set of programs and data structures but a minimal amount of data. A 
 larger test system, a duplicate of the production system, is provided for broader 
 testing, regression testing, etc.
  
 The first step of testing, once the nature of the modification has been 
 determined, is to implement the modifications in the minisystem and validate that 
 they do, in fact, accomplish their purpose. The next step is then to move the 
 modifications to the larger duplicate system and perform thorough testing with 
 more-extensive test data and possibly live data that has been copied to the test 
 system. The purpose here is to ensure that the modifications do only what they are 
 supposed to do, and that they do not cause side effects.
  
 There is an important distinction between production data and test data that 
 experienced testers appreciate. Production data is a crapshoot,",NA
15.3 Summary,"Testing involves executing system processes and then comparing the 
 results with results determined to be correct. Errors encountered in testing 
 fall into four categories: operator error, invalid data error, processing logic 
 error, and hardware and system software error. In a flexible system, what 
 used to be logic errors may become operator (business staff) errors, which 
 are typically easy to detect and correct.
  
 Testing occurs in two distinct phases: during development and prior to 
 system implementation, and during ongoing operations and modifications.
  
 Business staff have always been responsible for testing. With a flexible 
 system, there is an added dimension. Not only do business staff test the 
 system during initial development, but they also make the modifications 
 during ongoing operation and do the testing of the modifications.
  
 Initial system testing must include testing of the regulatory mech-anisms 
 within the system.
  
 In flexible systems, the rule is that customers make system modi-fications 
 by making adjustments to data stored in the system. Eliminating the need 
 for IT staff to perform maintenance offers great potential for reducing or 
 preventing a maintenance backlog. With the implementation of an 
 integrated and flexible system, business staff must change their thinking 
 significantly because they have control over changes in system behavior, 
 which may impact other business units besides their own.
  
 The impact of business-controlled changes to regulatory data can be far-
 reaching.",NA
Chapter 16,NA,NA
"Identifying, Managing, ",NA,NA
and Acquiring Quality ,NA,NA
Flexible Software,"This is the final chapter of Part III, How to Design Flexible Software Systems. In 
 many ways, it is also the final chapter of this book, because Part IV acts rather like 
 an appendix, providing details about UniverSIS and the generic-entity cloud 
 (GEC). Having looked at building systems with flexibility characteristics, we now 
 want to consider applying those design factors to purchased systems. We also 
 want to relate flexibility characteristics to the important issue of software quality 
 and to project management:
  
 What is the connection between flexible systems and various quality 
 movements?
  
 How do I manage system development or system acquisition to implement 
 a flexible software system?
  
 How can I ensure that software acquired (versus built) by our organization 
 is flexible?",NA
16.1 Flexibility and Quality,"Several of the authors who went through the quality revolution think that it is 
 relevant to today’s enterprises and that its message is germane to
  
 271",NA
16.2 Managing System Development/Acquisition ,NA,NA
to Achieve Flexibility,"Project managers play a key role in achieving flexibility. A project manager (PM) is 
 typically charged with planning and implementing each IT initia-tive, whether it be 
 a major new system or an improvement of the existing system. The PM becomes a 
 champion for flexibility, representing the best",NA
16.2.1 Managing Trade-Offs,"Project management is all about managing trade-offs and balancing con-straints. 
 Flexible systems are also subject to trade-offs. One cannot get something for 
 nothing. Clearly, the programs that access generic-entity clouds will be more 
 complex than programs that access more traditional databases. For a retail 
 organization, for example, the logic for summarizing",NA
16.2.2 Using Teamwork and Communications ,NA,NA
to Achieve Flexibility,"Project managers rely heavily on team building and human-resource management 
 skills. A PM sets the tone for the project team — typically formed with people 
 from different parts of the organization — and uses their skills to make the team 
 fully functional. Given that flexibility is a new way of systems development, 
 particular attention to teamwork and communications is required.
  
 It is critical to the success of the project that all members of the team 
 understand the design rationale and have adequate knowledge of and training in 
 software flexibility. Design reviews and code reviews must be enforced as vehicles 
 for ensuring that flexibility has been built into the system. Exhibit 16.2 presents 
 several accounts from UniverSIS where a lack of understanding of the design 
 rationale or lack of standards enforce-ment led to a compromise in flexibility. 
 Exhibit 16.3 presents an account",NA
16.2.3 Tools for Flexible Software Development,"We originally planned to include a chapter covering tools for implemen-tation of 
 flexible software systems. After some discussion, we realized that there 
 are
  no 
 tools specifically designed for implementation of flexible software systems, but we 
 still felt that something should be said.
  
 At various points in the book we have talked about tools that help with 
 analysis and design (entity-relationship diagram [ERD], data flow diagram [DFD], 
 etc.). Software products that support these activities fall in the “nice to have” 
 category, but they are not essential. Often a big piece of paper taped to the wall 
 does a great job.
  
 A code generator is a valuable tool for speeding up programming. It is not 
 specific to flexible systems, but because it can be such a time-saver, it may push a 
 management decision in the direction of tearing down and redesigning rather than 
 patching when flaws are discovered. So the code generator may well ease the way 
 for flexible design by reducing recovery time, but it is not essential.
  
 So what is essential? A database management system (DBMS) seems essential 
 for data storage and management these days, but that is not specific to flexible 
 systems. The data dictionary, mentioned several times in this work, is essential as a 
 repository for information about the system: characteristics of data elements; 
 information-structure relationships; iden-tification of modules; cross-referencing 
 of system components, etc. But we think a data dictionary is essential even if one 
 is determined to develop an inflexible system.
  
 There appear to be no tools that are appropriate for the development of 
 flexible system that are not also appropriate for the development of inflexible 
 systems. Even rules engines, like the UniverSIS Evaluator and comparable 
 commercial products, provide benefits in both arenas. The use of an effective 
 rules engine contributes a significant measure of flexibility to an otherwise 
 inflexible system and provides an even greater benefit in a comprehensively 
 flexible system. The same tools that make life easier for development of traditional 
 systems make life easier for development of flexible systems as well.
  
 Flexible system design has to come from the heads of the designers. Acquiring 
 and using software tools will not lead to flexible design. Good tools, like good 
 methods, will help, but they are never a substitute for good thinking.",NA
16.2.4 Enforcing Flexibility as Part of Daily Builds,"An important aspect of much of today’s software development is the “daily build” 
 in which code produced (modified) during the day is incorporated",NA
16.3 Procuring Flexible Software,"Acquisition of packaged software is at an all-time high and continues to grow. 
 According to 
 Gartner
 , the worldwide IT services marketplace — or the market for 
 software, integration, and maintenance services procured externally — was $540 
 billion in 2002, and it is projected to reach $700 billion in 2007 [Pring, 2003]. The 
 United States is the largest market worldwide, representing half of this world 
 market. Of course, the custom-ization dilemma remains a major issue.
  
 Many users have come to realize that the cost of software product 
 customizations often outweighs the benefits. This mis-alignment 
 between cost and benefit is particularly felt in areas of noncore 
 competency for an organization. 
 Gartner Dataquest
 ’s view is that 
 application development — of software product and custom code — 
 will change fundamentally over the midterm as declining customization 
 of all aspects of IT envi-ronments becomes widely accepted as the 
 norm in the IT industry.… more users we see will accept “good 
 enough,”standard, noncustomized solutions for these areas of noncore 
 competency and will seek to customize only applications and business 
 processes that can genuinely deliver competitive advantage. One large 
 insurance company says that its contracts with outside suppliers now 
 stipulate that no more than 25 percent of any new project can be 
 allocated to new code develop-ment…. This is a clear indication of the 
 direction in which the industry is going [Pring, 2003].",NA
16.3.1 Myth of Comparative Evaluation,"Do not compare apples to apples; compare them to a description of the apple you 
 need.
  
  
 If a packaged system is to be purchased, take care not to fall prey to the myth 
 of comparative evaluation.
  
 Myth: The best product is chosen by comparing candidate products with 
 each other.
  
 Reality: The best product is chosen by comparing candidate prod-ucts 
 with requirements.
  
 It seems obvious, but the myth persists, so it is worth a reminder. Exhibit 16.6 
 provides a real-world example of the myth of comparative evaluation in action. 
 Do not compare apples to apples; compare them to",NA
16.3.2 The Myth of Outsourcing,"There is a strong belief that by washing our hands of information tech-nology 
 issues and turning them over to outside experts, effective infor-mation technology 
 systems will painlessly appear. This isthe myth of outsourcing.
  
 Myth: We can hire an outside firm with the appropriate expertise that will 
 manage our information technology cheaper and better, and we will avoid 
 the management headaches.
  
 Reality: It is your business, and you must manage it, including the IT 
 component.
  
 The transformation processes leading to successful IT systems require diligent 
 effort, proper project management, and just plain hard work by management, 
 system customers, and IT professionals alike. This fact of IT life cannot be 
 stressed enough; there is no way around it. If outsourcing occurs, at the very least 
 project management responsibility must be retained internally. This is true even if 
 the bulk of the development work is done by persons outside the enterprise and 
 regardless of whether custom or off-the-shelf IT systems are used. And, as 
 mentioned above in Section 16.2.1, while programming is frequently outsourced 
 to foreign countries, the IT intervention required for on-site changes to business 
 rules cannot generally be outsourced.",NA
16.4 Summary,"The flexibility agenda is consistent with TQM principles and par-ticularly 
 supports the objective of continuous incremental quality improvement.
  
 As with quality, there is synergy between good project management and 
 flexibility considerations in system development.
  
 Flexibility should be taken into account in cost/benefit trade-offs. 
 Standards and tools are as appropriate to flexible systems as to 
 conventional systems.
  
 Apply a flexibility characteristics checklist to product acquisition and 
 development outsourcing.
  
 There is evidence that vendors of packaged applications are paying more 
 attention to flexibility. A number of vendors offer business rule engines that can 
 interface with an organization’s system. SAP has increased the flexibility of its 
 products: “SAP AG is working on a variety of developer technologies designed to 
 make its notoriously difficult-to-program enter-prise software easier to configure 
 and customize and, as a result, faster and less expensive to modify” [Boucher and 
 Mccright, 2003]. The biggest payoff for flexibility may be in packaged and 
 application service providers (ASP)-based applications. The fact that vendors can 
 satisfy multiple cus-tomers with the same product provides a powerful incentive 
 for flexible systems. Flexibility can provide virtual customization for different 
 custom-ers without the burden of actual custom coding.",NA
FLEXIBILITY: ,NA,NA
IV,NA,NA
DELVING DEEPER,"Part I introduced flexibility and why it is needed. Part II presented the key 
 ingredients, or techniques, for achieving flexibility. The application of these 
 techniques to design flexible software systems was addressed in Part III. What 
 more could be left to say? The reader now knows what to do and how to do it. 
 Some readers will choose to stop here.
  
 For readers interested in delving more deeply into flexibility, Part IV provides 
 details and case studies on specific flexibility topics. These six chapters enable 
 readers to expand their knowledge of flexibility practices and present possibilities 
 and to venture where very few have trod before.
  
 Chapter 17 presents a closer look at specific features of UniverSIS, 
 showing how their design is consistent with the approach promoted 
 throughout the book. Each feature includes an overview of the business 
 function that it serves, a discussion of its operation, and implications for 
 flexibility.
  
 Chapter 18 explains the Evaluator, a flexible tool for maintaining business 
 rules. Examples of increasing complexity are used to show the power of 
 this tool for implementing flexible software.
  
 Chapter 19 is a case study that contrasts traditional software design with 
 flexible software design. A hypothetical tuition-remission soft-ware 
 feature that was developed using traditional methods requires structural 
 and procedural modifications by the IT staff when busi-ness requirements 
 change. In contrast, the same system developed with a flexible design 
 utilizing the generic-entity cloud (GEC) accommodates the same changes 
 to business requirements with no intervention by IT staff.",NA
Chapter 17,NA,NA
A Closer Look ,NA,NA
at UniverSIS,"UniverSIS was introduced in Chapter 5 as a system developed using principles of 
 flexibility. Two of its flexible features were discussed: (a) locators and (b) generic 
 code/code-to-code. The Evaluator function was introduced in Chapter 13. 
 Additional features are presented in this chapter, indicating how their design is 
 consistent with the approach promoted throughout this book.
  
 Before proceeding with discussion of these features, we observe that certain 
 information about an individual is independent of the individual’s relationship to 
 the university. Information that falls in this category is stored in the data structure 
 of a Person entity. Examples of such informa-tion include date of birth, gender, 
 ethnicity, country of citizenship, social security number, and religious affiliation. 
 The UniverSIS Person entity is a limited implementation of the fully generic entity 
 type discussed through-out the book.
  
 Much of the data stored in UniverSIS is connected to the Person entity, rather 
 than to status-specific entities such as “prospect,” “applicant,” “stu-dent,” or 
 “employee.” For example, the locator feature mentioned in Chapter 5 allows 
 address information to be recorded for an individual. The connection is made 
 between the Person entity and the locator entity. Any individual, regardless of 
 relationship with the university, will have locator information. In general, unless an 
 individual’s information was clearly connected only to a specific status, the 
 designers linked to the Person entity, as we will note in the examples.
  
 293",NA
17.1 Navigation and Security,"Online functions in UniverSIS are defined through creation of database records. 
 Each function has identified business owners. Those owners grant access to the 
 functions directly, without IT intervention. Access to functions is also defined to 
 the system through creation of database records. Each member of the business 
 staff works from a personalized menu.",NA
17.1.1 Discussion,"Designers of information systems often use a standard menu to present to the 
 staff member the list of available features. A typical approach is to define major 
 groupings in the top-level menu. Selecting a major grouping will lead to a display 
 of subgroupings, which leads to sub-subgroupings, etc. Security features prevent 
 the staff from selecting menu items for which they are not authorized. A drawback 
 of this approach is that it lacks flexibility. As the system grows, the number of 
 menu items increases. At some point, screen-size limitations require 
 reorganization of the groupings. Perhaps most frustrating to the staff member is 
 that he does not know, by looking at his menu, which features he is authorized to 
 use.
  
 UniverSIS allows each staff member’s menu to be personalized. The 
 developers identified discrete business activities, called functions, that correspond 
 to the lowest-level items in the chains of a hierarchical menu. The list of available 
 functions serves as an inventory of the online capa-bilities of the system. A 
 scrolling menu lists the functions that the staff member is authorized to use. As a 
 new function is added to the system, it is made available to the appropriate staff 
 members.
  
 This approach has several benefits. It eliminates the need to redesign menus as 
 the system grows, since all menus are personalized and dynamic. Staff members 
 know that they are authorized to use whatever they see on the menu. No data 
 structures are added or modified as new functions are added to the system. No 
 existing programs need to be modified as functions are added. Identification of 
 functions and assignment of functions to individuals are controlled through 
 maintenance of records by business staff.
  
 A common bottleneck in any organization is IT security. Authorization 
 typically involves signing forms and passing them to the IT security staff, whose 
 job it is to physically perform the task of providing the business staff with the 
 required access to the system. The IT security staff add no value to the process—
 they are simply carrying out orders in a mechanical way because the person with 
 the actual authority to grant access to the data is unable to do it directly.",NA
17.1.2 Implications for Flexibility,"Defining both functions and access to those functions as database records is in 
 effect storing business rules as data. The usual benefits come into play. Business 
 staff gain direct control, and IT involvement is reduced. The IT staff is involved 
 only when new functions, requiring new pro-gramming, are established. The role 
 of IT security, working from paper forms signed by function owners, is 
 eliminated. Assignment of function access is performed directly by function 
 owners. As staff turnover, reas-signment, or reorganization occurs, modifications 
 to access are managed entirely by function owners.",NA
17.2 Documents,"Organizations often require individuals to provide credentials and docu-mentation 
 of various types. Through a “document” feature, the developers of UniverSIS 
 generalized this concept, developing a single mechanism that is used to record a 
 variety of credentials and documentation.",NA
17.2.1 Discussion,"In gathering business requirements, the UniverSIS developers identified a category 
 of information that could be served by a general-purpose entity. The common 
 thread was recording that an individual had performed some specific activity about 
 which a record needed to be maintained, e.g., submitted a required form, attended 
 a required event, or provided required documentation. The amount of information 
 to be recorded was very limited. In some cases, it was necessary only to record 
 that the activity had been performed and when. In other cases, there was 
 additional qualifying information.
  
 For example, the music department requires an audition of all appli-cants. The 
 members of an audition committee submit evaluations, from which a single 
 overall rating is determined. Another example involves international students, who 
 are required to submit a federal form that indicates source of financial support. 
 The form has to be resubmitted periodically.
  
 The UniverSIS developers identified a pattern to accommodate these 
 situations and created a multipurpose mechanism called a “document.” In addition 
 to its other attributes, the document can have a series of ratings, all business staff-
 defined. A document recorded for an individual is called a Person-Document. 
 Additional information can be recorded on the Per-son-Document: date of 
 receipt, date of verification, individual who did the verification, expiration date or 
 term, and free-form notes. Exhibit 17.3 illustrates the document created by the 
 admissions office for music audi-tions. For each applicant who auditions, a 
 Person-Document is recorded, with the rating the applicant received, as shown in 
 Exhibit 17.4.
  
 To track the international students’ financial forms, the Office of International 
 Students created a document corresponding to the standard paper financial form. 
 For each international student, office staff record a Person-Document to indicate 
 receipt of the paper financial form as well as the expiration date of the period 
 covered by that form. Any notes explaining special circumstances are recorded on 
 the Person-Document.
  
 The document mechanism has proved to be a very flexible tool for adding 
 isolated pieces of information to the system without modification",NA
17.2.2 Implications for Flexibility,"A single, stable information structure is used to record a variety of document 
 types. Because documents are linked to the Person entity, the feature can be used 
 to record information about any individual, regardless of relationship with the 
 university. Business staff can create new types of documents without IT 
 intervention. Standard features can be used in a variety of ways.",NA
17.3 Required Admission Credentials,"Building on the document feature described above, this feature allows the 
 admissions office to specify the credentials that applicants to the university’s 
 academic programs must provide.",NA
17.3.1 Discussion,"The University of Cincinnati (UC) offers over 300 academic programs in a wide 
 variety of academic disciplines. There is a need to record, for each academic 
 program, which credentials an applicant must provide. There is also a need to 
 determine, for an individual applicant, whether all required credentials have been 
 received. The developers were able to use the document feature as the basis for a 
 credential-requirement mechanism.
  
 Credentials take a variety of forms. Transcripts, test scores, letters of 
 recommendation, auditions, and portfolios are examples. Business staff define and 
 maintain credentials as documents. As in the example shown earlier, a credential 
 definition can specify ratings where appropriate, as in the music department’s 
 audition ratings.
  
 Business staff define the standard credential requirements of each academic 
 program, as shown in Exhibit 17.5, where three examples are provided:",NA
17.3.2 Implications for Flexibility,"Business staff can, through adjustment of business rules, accommodate the unique 
 requirements of each academic program. No IT intervention is required to define 
 new credentials or to maintain credential require-ments. Unique needs of 
 individual applicants 
 
  exceptions to the rules 
 
 can be accommodated within the 
 system, without IT intervention.",NA
17.4 Contact Management,"To support various recruitment and retention efforts, and to evaluate their 
 effectiveness, the university needs a mechanism for tracking contacts with 
 students and prospective students. The contact-management feature of UniverSIS 
 provides a simple yet flexible tool for this purpose.",NA
17.4.1 Discussion,"Customer relationship management (CRM) software appears prominently in 
 vendor marketing materials. The developers of UniverSIS included a simple yet 
 flexible feature for scheduling and maintaining records of personal contacts 
 between business staff and prospects, applicants, and students. The “type” of 
 contact is identified by a “context.” Business staff maintain the values for context. 
 Context can be general, such as admis-sions, student records, and academic 
 advising, or they can be very specific, as the business staff choose. The contact 
 record itself is very simple, as shown in Exhibit 17.6, including elements for the 
 date and time of the contact, the form (personal, telephone, e-mail, etc.), the 
 identifier of the business staff member, follow-up action, and notes about the 
 contact. Future contacts can be scheduled, and a staff member can view a per-
 sonalized to-do list of scheduled contacts for a given day.
  
 The tool has proved to be flexible and useful in a variety of ways. A 
 telecounseling feature, described in Chapter 5, for example, was built on the 
 contact feature.",NA
17.4.2 Implications for Flexibility,"The feature was designed as a general-purpose tool. Through adjustment of data 
 values, business units can use the feature in a variety of ways and for a variety of 
 purposes. It can be used both to prepare for contact
  
  PERSON-CONTACT - Maintain Prospect Contact          
  
  *ID: ___ __ ____
  
  *Contact Context: ____
  
  *University Contact: ___ __ ____
  
  *Contact Position....: __________
  
  *Initiator......................: __
  
  *Contact Form..........: ____
  
  *Action Taken...........: ____
  
  Notes: ____________________________________________________________
  
  
 ____________________________________________________________ 
  
  
 ____________________________________________________________
  
  
 ____________________________________________________________
  
  
 Exhibit 17.6.
  
 Person-Contact Document",NA
17.5 Correspondence,"A university sends a great deal of mail. Typical mailings might be an information 
 packet sent to a prospect, a letter of acceptance to an applicant, and a bill to a 
 student. UniverSIS has a correspondence-management module that allows 
 administrative offices to define such mailings, schedule them for delivery, cancel 
 the delivery if necessary, produce the printed materials, and log the results.",NA
17.5.1 Discussion,"The correspondence feature was designed as a general-purpose corre-spondence 
 tool, available for use by any business unit. Individual pro-cessing objects pull 
 specified information from the database management system (DBMS) for 
 insertion into the correspondence, e.g., name, address, salutation, academic 
 program, missing information, etc. New objects can be added without disruption 
 of any existing processes or data structures.
  
 In designing this module as a general-purpose tool, the developers looked 
 carefully at what could be done to make it flexible. Business staff identified the 
 following characteristics of correspondence:
  
 Mailing items are often sent together as a “packet.”Some 
 mailing items are personalized; others are not.
  
 The address to which a mailing is to be sent may vary.
  
 Each administrative office has its own set of mailings.
  
 Sometimes a mailing needs to be cancelled because it is no longer 
 necessary.
  
 Sometimes there is a limit to the number of times a particular mailing is 
 sent to an individual.
  
 If the output is in paper form, it has to be delivered by operations to the 
 right person or office.
  
 Rules change over time.
  
  
 The term “correspondence” identifies the packet (Exhibit 17.7). A particular 
 business area owns each correspondence.
  
 Business staff define different “versions” of a correspondence, specified by 
 date. Correspondence can contain nonpersonalized items such as brochures, 
 informational pamphlets, etc. called “enclosures.” Business staff define enclosures 
 in a simple table. Correspondence can contain personalized",NA
17.5.2 Implications for Flexibility,"Business staff have full control over both text and insertion of information stored 
 in the DBMS and also control the logic for cancellation of corre-spondence. While 
 the correspondence feature does not have the full capabilities of a word processor, 
 it does have the significant benefit of integration with the student information 
 system. Once again, because there may be a need to correspond with individuals 
 who have different relation-ships with the university, the correspondence is linked 
 to the Person entity.",NA
17.6 Correspondence Tracks,"The correspondence-track feature builds on the correspondence feature described 
 in Exhibit 17.6. It enables a business unit to identify a sequence of mailings that 
 are to be sent to an individual or identifiable group of individuals. The timing of 
 the mailings, dependencies between mailings, and cancellation of mailings are 
 controlled by rules managed by business staff.",NA
17.6.1 Discussion,"UniverSIS provides a correspondence-track feature that can be used to send a 
 series of designated mailings on a personalized schedule to individuals",NA
17.6.2 Implications for Flexibility,"The correspondence-track feature was designed for general use. Any business unit 
 that has a need to send a sequence of mailings can make use of it. The 
 correspondence-track feature itself reused general-purpose system features. Like 
 correspondence, tracks are linked to the Person entity.",NA
17.7 Selected-ID Lists,"Business processing often requires that individuals be identified as mem-bers of a 
 specific list. The “selected-ID list” feature provides a standard mechanism for 
 recording membership in a list. Business staff can create lists on an ad hoc basis or 
 make use of standard, predefined lists. Members can be added to lists online 
 through a manual process or in a batch process using standard logic.",NA
17.7.1 Discussion,"Much of business processing involves identification of individuals to be processed, 
 i.e., creating a list. Business staff might create a list of individ-uals for purposes of 
 identification, or to support some manual activity such as making phone calls. In 
 many cases, the list is created so that some batch process can act on it. The ideal 
 for batch-processing efficiency is to access only those records that actually need to 
 be accessed.",NA
17.7.2 Implications for Flexibility,"Records on the selected-ID list use a standard set of data elements, making the 
 feature essentially generic. Logic for maintaining records is generic, allowing one 
 set of programs to be used to maintain all lists. Business staff can create new lists 
 and modify membership of lists without IT intervention. Because logic for 
 accessing lists for batch processing has been standardized, programmers can reuse 
 that logic when coding new processes involving lists, reducing the amount of 
 development time. Because records are linked to the Person entity, Selected-ID 
 lists are available for use with any individual whose records are stored in the 
 system.",NA
17.8 Tests,"Standardized tests can take a variety of forms, using a variety of test components 
 and subcomponents and rules for scoring. UniverSIS provides a flexible 
 mechanism for defining standardized tests and recording student test results.",NA
17.8.1 Discussion,"A university uses various types of tests for nonclassroom purposes. Exam-ples 
 include entrance examinations such as the ACT, SAT, and GRE; advanced 
 placement tests; English language proficiency tests; etc. Recog-nizing that new 
 tests are introduced fairly frequently and that existing tests may undergo revisions, 
 the developers designed a flexible mechanism for defining tests and recording test 
 results. The feature has two principle components: (a) a function for defining 
 tests: TEST-DEFINITION (Exhibit 17.11) and (b) a function for recording an 
 individual’s test results: TEST-SCORES (Exhibit 17.12).
  
  
 TEST-DEFINITION provides an information structure for recording 
 attributes of the test. The structure provides for three levels of scores within a test, 
 i.e., test, test component, and test component subcomponent. Test score ranges 
 are specified. Scores can be nonnumeric. Component or subcomponent scores can 
 be marked as “required.”
  
  
 Note that the fixed limit to the levels of a test represents a departure from the 
 approach that we have generally promoted. However, the reality was that no one 
 had ever encountered a test that had a level below",NA
17.8.2 Implications for Flexibility,"The format, scoring rules, number of components and subcomponents, etc. 
 comprise, in effect, business rules. These rules are all under business control. 
 Versions of tests, with effective periods, can be maintained.",NA
17.9 Employee Profile,"Although UniverSIS is not a personnel system, a small amount of infor-mation 
 about employees is recorded. This information includes a list of functional 
 positions an individual holds. In combination with other gen-eral-purpose 
 features, this allows automated assignment of responsibilities.",NA
17.9.1 Discussion,"The developers identified a need to maintain within UniverSIS a small amount of 
 information about employees, as shown in Exhibit 17.13. Certain features",NA
17.9.2 Implications for Flexibility,"Permission to maintain certain types of data is managed through user-maintained 
 business rules keyed to the business-position feature of the employee profile. 
 Business managers can assign or reassign responsibilities directly, without IT 
 intervention.",NA
17.10 Grades,"Grades are familiar to anyone who has attended school. In clarifying business 
 requirements for keeping student grades, the developers discov-ered that the 
 business rules could be quite complex. It is definitely not as simple as A, B, C.",NA
17.10.1 Discussion,"From the screen sample shown in Exhibit 17.17, it is clear that:
  
 Grades can have a context, defined by “grading system” and “grade type.”
  
 Different grading systems can exist, e.g., undergraduate, graduate, medical 
 school, law school, etc.
  
 Different types of grades can exist within a grading system, e.g., normal, 
 pass/fail, etc.",NA
17.10.2 Implications for Flexibility,"Storing the business rules associated with grades as data, maintained by business 
 staff, has eliminated the need for IT intervention when the rules change. In 
 addition, the rules themselves are visible and readable. They are not hidden in 
 program code.",NA
17.11 Summary,"We have presented ten specific examples of flexible features implemented in 
 UniverSIS, which is in use at the University of Cincinnati. The presen-tation of 
 each example provided an overview, a discussion of how the",NA
Chapter 18,NA,NA
Evaluator: a Flexible ,NA,NA
Tool for Maintaining ,NA,NA
Business Rules,"In Chapter 8, the discussion of regulation pointed out the benefits of giving 
 business staff control over maintenance of business rules. Simple rules such as 
 “value A is valid and value B is not” have long been represented in software as lists 
 of valid values maintained by business staff. This chapter discusses in detail a 
 technique that gives business staff control over complex business rules.
  
 Changes in business policy account for a significant percentage of the IT effort 
 expended in maintaining inflexible systems. One day the policy states that condition 
 ABC is invalid. The next day, the policy is changed to consider condition ABC valid 
 in some circumstances and invalid in others. The policy is an artificial limit on the 
 behavior of the software —a general business rule — and is subject to change as 
 the business environment changes. When such rules are recorded in programs in 
 the form of traditional IF/THEN/ELSE logic, changes in those rules require 
 modification of program code.
  
 The developers of UniverSIS designed a general-purpose tool —dubbed the 
 Evaluator — that allows business staff to define and maintain complex rules 
 without modifications to programs. The Evaluator has two major components:
  
 319",NA
18.1 Record Rules,"An element is a piece of information about an individual that can be used in a 
 business rule. In the case of admissions decisions, the following elements were 
 defined:
  
 High-school GPA (grade-point average) 
  
 Percentage rank in high-school class 
  
 Ohio high-school proficiency test rating 
  
 Best ACT math score or SAT math score 
  
 Best composite ACT score or SAT total score High-
 school core courses completed indicator
  
 An element is a form of regulatory entity. Before an element can be used, it 
 has to be identified to the Evaluator. Once an element has been established, IT 
 staff need do nothing further with it. Evaluator allows business staff to use 
 elements to construct rules in the form of conditions composed of logical 
 statements. Many administrators were immediately comfortable with this approach 
 because the statements are similar to those they encode on a daily basis to generate 
 reports from UC’s data warehouse. The rules can be as simple or as complex as 
 necessary. A rule also has date-sensitive versions, which allows a history of rules to 
 be maintained. It also allows administrative staff to prepare and test new versions 
 of rules without affecting current processes.",NA
18.2 Evaluate,"The Evaluator provides a mechanism to compare an individual’s data, as defined 
 by the elements, to the criteria specified in the rules. This mech-anism consists of 
 two parts:
  
 1. 
  
 A set of modules that retrieves the individual’s data 
  
 2. 
  
 An evaluation module that compares the individual’s data with the 
  
 specified rules
  
 In the automated decision example, the retrieval modules assemble the 
 applicant’s data for the specified elements. For example, given that the element is 
 high school GPA, a module retrieves the applicant’s high school GPA data. The 
 evaluation module compares the applicant’s data against the rule, element by 
 element, until it can be determined whether the applicant has satisfied all criteria. 
 If all criteria have been satisfied, the evaluation module returns a result of TRUE. 
 Otherwise, it returns a result of FALSE. The process that is using the Evaluator 
 determines what",NA
18.3 Evaluator: the Details,"This section explains the data structures and some of the processing that underlie 
 the Evaluator. This discussion is presented for readers who are interested in the 
 details. In designing the Evaluator, the challenge was to develop a tool that could 
 store, retrieve, and evaluate business logic and allow users to maintain not only 
 data values, but also the business logic itself. The business logic was broken into 
 conceptual components:
  
 Elements 
  
 Values 
  
 Relational operators 
  
 Logical operators 
  
 Subconditions 
  
 Conditions 
  
 Rules 
  
 Business requirements 
  
 Results 
  
 Business decisions
  
 Evaluation criteria are recorded in the form shown in Exhibit 18.1. The 
 evaluation process receives the identifier of a person, evaluates the per-son’s data 
 according to the specified criteria, and returns a result of TRUE or FALSE. The 
 result is passed to the module that makes the required business decision. In 
 UniverSIS, the Evaluator is used only to evaluate persons, though it could be 
 adapted for use with any entity.",NA
18.3.1 Building Evaluator Requirements,"The lowest level of logic is called a subcondition. A logical statement or 
 statements expressing a relationship between a single element and a value or set of 
 values forms a subcondition. The relational operator defines the relationship; six 
 values are possible. As shown in Exhibit 18.1, they are EQ, NE, GT, GE, LT, and 
 LE. An example would be:
  
 ACAD-PROGRAM   EQ   15BA
  
 The statement must be true for the subcondition to be satisfied. Logical 
 operators (and/or) can be components of a subcondition. The subcondi-tion is 
 composed of a statement or statements referring to a single element and giving a 
 single result. For example:
  
 ACAD-AREA   EQ   HIST
  
 or 
  
 ACAD-AREA   EQ   ECON",NA
18.4 Working through Examples,"Exhibit 18.6 shows a partial list of Evaluator elements used in subsequent 
 examples. Note that each element has both a name and a numeric ID. The 
 element ID is a five-digit number that follows the basic rule for generating stable 
 IDs (the leading zeros are suppressed).
  
 A condition is a set of logic statements in Boolean form. Users identify the 
 element by name, use a relational operator to indicate the type of comparison to 
 be made, and specify a value. The following condition",NA
18.5 Summary,"In the Evaluator, criteria for business decisions are defined as a set of 
 conditional statements.
  
 When evaluated, conditional statements yield a true or false result. The 
 Evaluator mechanism is independent of any business process for which it 
 is used.
  
 The Evaluator approach has flexibly handled all logical business decision 
 criteria encountered that could be defined in terms of data stored in the 
 system as evaluator rules, conditions, and subconditions. The Evaluator is 
 a general-purpose tool, a flexible tool.
  
 The Evaluator mechanism itself has been completely stable since its 
 implementation. No modifications of data structures or program code 
 have occurred.
  
 The UniverSIS Evaluator has been incorporated into the business logic of 
 admission decisions, charging, correspondence tracks, and other business 
 decision processes.
  
 New Evaluator elements have been added over the years, which has 
 required coding of individual data-retrieval modules. These modules 
 follow a standard template and typically require only a few hours to code 
 and test.
  
 As new business processes have been added to the system, new uses for 
 the Evaluator have been identified.
  
 The Evaluator illustrates the potential for transferring control over business 
 rules to business staff and simultaneously reducing IT mainte-nance effort. The 
 tool makes use of stable data structures and generic processing patterns. Evaluator 
 can and does serve a variety of business purposes and can be deployed easily as 
 new purposes are identified. In Chapter 19, we provide a case study showing how 
 two software tools —the generic-entity cloud (GEC) and the Evaluator — can be 
 used together to provide a flexible system.",NA
Chapter 19,NA,NA
Tuition-Remission ,NA,NA
Case Study: ,NA,NA
Traditional ,NA,NA
versus Flexible,"In this chapter, we review previous material by examining a business process and 
 demonstrating how a software system can be designed to support it. First, we 
 describe how a more traditional method of system design would approach the 
 task. Then we approach the same task using some of our flexibility tools — the 
 generic-entity cloud (GEC) and the Evaluator. For readers who have grasped fully 
 the concepts of those tools, this chapter may be unnecessary. For those who are 
 less confident, we believe that the comparison of the two approaches will 
 reinforce under-standing of the difference between inflexible and flexible design.
  
 At some universities, tuition is remitted or waived for individuals who are 
 university employees or who have specified relationships with uni-versity 
 employees. We will consider only the case of children of employ-ees. A typical 
 business rule for tuition remission can be stated simply:
  
 The child of an employee is eligible for tuition remission.
  
 The process under discussion is “award tuition remission.” That process 
 determines whether a given student is eligible for tuition remission. If the student 
 is eligible, the process will store a record of eligibility in the system.",NA
19.1 Traditional Approach,"It is very common for analysis of business processes to drive system design. We 
 will perform such a process-oriented analysis as our example of the traditional 
 approach.
  
 The output of the process is a record of a student’s eligibility for tuition 
 remission. Discussion with the business staff reveals that tuition remission is 
 awarded on a term-by-term basis. Because we want our process to determine 
 whether a student is eligible for tuition remission in a given term, the basic inputs 
 are Student ID and Term. We know that not all students are eligible for tuition 
 remission. The business rule stated earlier defines who is eligible.
  
 To enforce the rule, the process needs access to pertinent information. The 
 business rule contains the words “child,” “employee,” and “tuition remission,” 
 which indicates the need to store data about these entities. Applying some 
 common sense, we conclude that the “child” must be a student. We also conclude 
 that we need to keep information about the academic terms. We therefore need 
 data found in four (logical) data stores: Employee, Student, Term, and Student 
 Term Tuit-Rem.
  
 For purposes of this discussion, we specify very simple data stores, having the 
 elements shown in Exhibit 19.1. Note that we have anticipated the possibility of 
 an employee having multiple children. For ease of reading, we have omitted 
 system-assigned identifiers.
  
 A data flow diagram (DFD) is often used for recording the results of an 
 analysis, as illustrated in Exhibit 19.2. In Exhibit 19.2, we see that the basic Input 
 (Student ID and Term) parameters are passed to the “award tuition remission” 
 process. The process receives information about",NA
19.1.1 Traditional Approach: an Employee Has More ,NA,NA
than Three Children,"The original design of the Employee file specified a maximum of three children. 
 The likely modification will be to estimate a larger maximum, say ten, and modify 
 the Employee file to accommodate ten occurrences of Child-Name and Child-ID. 
 The logic of the program will need to change as shown in Exhibit 19.4.",NA
19.1.2 Traditional Approach: Spouses Become Eligible ,NA,NA
for Tuition Remission,"The original design of the Employee file did not provide for a spouse. The likely 
 solution will be to add Spouse-ID and Spouse-Name to the Employee file. The 
 program will need to be modified to add a #SPOUSE-SW. The logic of the 
 READ of the Employee file will need to change as shown in Exhibit 19.5.
  
 READ Employee File 
  
 IF Employee.Child-ID-1 = #INPUT-STUDENT-ID 
  
  
 OR Employee.Child-ID-2 = #INPUT-STUDENT-ID 
  
  
 OR Employee.Child-ID-3 = #INPUT-STUDENT-ID
  
 … (and so on) 
  
  
 OR Employee.Child-ID-10 = #INPUT-STUDENT-
 ID 
  
  
 Set #CHILD-SW = TRUE 
  
 END-IF 
  
 END-READ
  
  
  
 Exhibit 19.4.
  
 Employee File Modification for More than Three Children",NA
19.1.3 Traditional Approach: an Age Limit of 23 Is Placed ,NA,NA
on Tuition-Remission Eligibility,"Birth date is already available on the Student record. Within the program, we 
 would add a field for #STUDENT-AGE, and logic would be added to calculate 
 #STUDENT-AGE by comparing the student’s birth date with the current date. 
 The logic for writing the Student Term Tuit-Rem record would need to be 
 modified to something like that shown in Exhibit 19.6.",NA
19.1.4 Discussion,"Three fairly simple changes … necessitated modifications to program code and, in 
 two of the three cases, modifications to data structures. This is what is meant by a 
 high-maintenance system.
  
 These examples illustrate the typical problems found in an inflexible design. It is 
 not that the original work has been performed incorrectly. The process-oriented 
 approach effectively identified and accommodated the original requirements. The 
 logic of awarding tuition remission was isolated in a single module. Modularity is a 
 sound design principle for both traditional and flexible software. Input to the 
 process is provided",NA
19.2 Flexible Approach,"Let us look at how the same business requirements might be implemented in a 
 system designed with flexibility in mind. We would start with a careful GEC 
 analysis of data structures. The GEC diagram in Exhibit 19.7 represents the way in 
 which the data pertaining to employees and students would be organized. We 
 identify employee and student as types of a more general entity called Person.” We 
 identify parent and child as relationships between",NA
19.2.1 Review of the GEC-Building Process,"Define the generic node (G) 
  
 Define the type node (T) 
  
 Define the role node (R) 
  
 Define the type-role-type node (TRT) 
  
 Define the generic-type node (GT) 
  
 Define the generic-role-generic node (GRG)
  
 We are not showing all the detail of the steps identified above. Included in the 
 activities of definition will be identification of the data elements of each node. For 
 this illustration we show only representations of the IDs of the node records.",NA
19.2.2 Using the GEC to Apply Business Rules,"Stated simply once again, the business rule for tuition remission is this:
  
 The child of an employee is eligible for tuition remission.
  
 More precisely stated, the rule is:
  
 A Person who is both (a Student) and (a Child of a Person who is an 
 Employee) is eligible for tuition remission.
  
 We can use a DFD to represent the process of awarding tuition remission 
 (Exhibit 19.10). In contrast to Exhibit 19.2, Employee and Student have been 
 replaced by a single entity — Person — and the Student Term Tuit-Rem entity has 
 been renamed to Person Term Tuit-Rem. The logic described for the traditional 
 approach will be needed in the flexible approach as well.
  
 Input: 
  
 Student ID 
  
 Term
  
 Person
  
 Award 
  
 Tuition 
  
 Remission
  
 Person 
  
 Term 
  
 Tuit-Rem
  
 Term
  
 Exhibit 19.10.
  
 Data Flow Diagram for Award Tuition Remission: Flexible 
  
 Approach",NA
19.2.3 Defining General Business Rules,"How might we store the rules for tuition remission in our software so that they 
 can be enforced? Because business logic is involved, we need to write a program. 
 The program needs to do two things:
  
 1. 
  
 Take Mary’s ID and read through the GRG records looking for the 
  
 specified condition.
  
 2. 
  
 Take Mary’s ID and read through the GT records looking for the 
  
 specified condition.",NA
19.2.4 Flexible Approach: an Employee Has More ,NA,NA
than Three Children,"For the flexible approach, accommodating an employee who has more than three 
 children proves to be trivial. Student and Employee are types of Person. Every 
 individual on the system has a Person record. Subject to the data integrity rules of 
 the GEC, simply adding a new GRG record can represent a relationship between 
 any two Persons. No IT intervention is required to increase the number of 
 children that can be recorded for an employee because whatever limits exist are 
 adjustable through cardi-nality regulation. The flexible approach has indeed 
 proved flexible in this case.
  
 This particular bit of flexibility is a natural by-product of normalization when 
 analyzing data requirements. The authors do not claim to have invented data 
 normalization. Normalization is a good data analysis tool, but it is not at all 
 unusual for system designers to design data structures that are not fully 
 normalized. When they do, however, they must recognize the potential for 
 inflexibility. In designing the system, they must take into consideration not only 
 today’s requirements, but tomorrow’s potential changes.",NA
19.2.5 Flexible Approach: Spouses Become Eligible ,NA,NA
for Tuition Remission,"Let us say that this is the new situation, as illustrated in Exhibit 19.14.
  
 John is an employee. 
  
 John is also a student. 
  
 Mary is a student.",NA
19.2.6 Flexible Approach: an Age Limit of 23 Is Placed ,NA,NA
on Tuition-Remission Eligibility,"Our GRG and GT rule mechanisms cannot accommodate this business 
 requirement. The GRG rule, though flexible in its way, is very specific to 
 relationships in the GEC. The GT rule is very specific to control type in the GEC. 
 We need a different mechanism for evaluating the age of the child.
  
 Would it be possible to design an evaluation mechanism that works for this 
 new requirement as well as many others? The answer is yes. In Chapter 18 we 
 describe such a mechanism, called Evaluator — a general-purpose evaluation tool 
 based on the premise that any business processing decision can be constructed 
 with the following components:
  
 A predefined set of decision elements 
  
 A true/false question based on decision elements 
 Action to be taken for a true result 
  
 Action to be taken for a false result",NA
19.2.7 Additional Thoughts,"Let us not stop here. The Evaluator mechanism actually provides enough 
 flexibility that it can be used to enforce the GRG and GT rules as well as the 
 AGE rule, making the VALIDATE-PERSON-GRG and VALIDATE-PERSON-
 GT routines unnecessary. In addition to AGE, we define two other decision 
 elements:",NA
19.3 Comparison of ,NA,NA
Traditional ,NA,NA
and Flexible ,NA,NA
Approaches,"Once change was introduced,… the traditional approach required significantly more 
 IT intervention than the flexible approach.
  
 Both the traditional and flexible approach resulted in systems that met the original 
 business requirements. Once change was introduced, however, the traditional 
 approach required significantly more IT intervention than the flexible approach. 
 The flexible approach does in fact prove to be the low-maintenance option.",NA
19.4 Summary,"In this case study, we compared a traditional process-oriented approach to 
 a flexible, information-structure-oriented approach. Both approaches 
 yielded good results in the initial implementation. As changes in business 
 requirements occurred, the traditional approach required modifications to 
 both program code and infor-mation structures, even when the changes in 
 requirements appeared to be fairly minor.
  
 With the flexible approach, the same changes were accommodated 
 without modification to either information structures or program code. 
 Thoughtful design offers the possibility of generic data structures and 
 generic program code for recording and evaluating business rules. Such 
 generic tools can be reused in a variety of business situations.
  
 The GEC and the Evaluator are examples of such generic tools.",NA
Chapter 20,NA,NA
Regulatory GECs,"In Chapter 10, we introduced the generic-entity cloud (GEC) and discussed its 
 internal regulatory capabilities. In Sections 10.3 and 10.6, we indicated that the 
 GEC approach also provided for regulation of the relationships between GECs 
 via data structures called “externals.” This chapter looks at specific examples to 
 see how the combination of GECs and externals provides business staff with 
 control over the characteristics of entities and the relationships between them. In 
 the initial example we look at financial transactions involving tuition charges and 
 payments at a university.
  
 Exhibit 20.1 presents an example Person GEC. Every GEC has a default 
 multivalued element (MVE) having the same name as the GEC itself and a default 
 instance of the MVE having the same name as the GEC itself. The Person GEC 
 therefore has an MVE called Person (T-Person) that has an instance called Person. 
 For this discussion, we also define one non-default T-Person instance: Student. 
 We have identified Jane as a Person who has Person-Type (GT-Person|Person) 
 values of Student and Person. By default, the T node designates a multivalued 
 attribute (MVA) rather than a control type (CT), so the type (T), type-role-type 
 (TRT), and generic-role-generic (GRG) nodes are inactiveand are shown in gray.
  
 Next, Transaction is presented as a GEC in Exhibit 20.2. It has two values, 
 Charge and Payment. It has only the default type of transaction (T-Transaction), 
 which has two values, Tuition and Cash. Charge-Tuition and Payment-Cash are 
 identified as valid generic-type (GT) values. Again, because the T node is an MVA, 
 not a CT, no role (R), type-role-type (TRT), or generic-role-generic (GRG) values 
 are present.
  
 365",NA
20.1 Attached versus Detached Regulation ,NA,NA
of GT Values,"An essential aspect of GEC regulatory activity is validation of values. There are two 
 forms of value validation:
  
 1. 
  
 Attached regulation
 : attached to a specific GEC 
  
 2. 
  
 Detached regulation
 : detached through the use of externals 
  
 attached to 
 an additional GEC",NA
20.2 GEC Validation Tables,"We generally think of GECs as containing application information about persons, 
 places, or things. It is also possible to construct entire GECs whose only purpose 
 is regulatory.
  
 A great deal of regulatory data may reside in a system in the form of tables of 
 “valid values,” sometimes called “domains.” Domains are often implemented 
 within the database in such a way that modification requires the intervention of IT 
 professionals. The approach shown here uses GECs to store and control tables of 
 valid values. The data elements of State and Country are used to illustrate how this 
 occurs.
  
 State and Country often serve different purposes in a system, yet those 
 purposes should share a common set of values. It does not make sense to have 
 separate — and identical — sets of valid values for each purpose. All purposes 
 should be served by the same set of values.
  
 We can use the GEC mechanism. Start by identifying a State GEC. It has the 
 usual default MVE (T-State) and the default instance of T-State (State). Establish 
 the State T node as an MVA, not a CT. Therefore, only the T, G, and GT nodes 
 are shown. Exhibit 20.5 shows five possible instances
  
 T - State 
  
 State          || 
  
 Birth          || 
  
 Residence  || 
  
 Death         || 
  
 Temporary 
 ||
  
 GT 
  
 State         |State || 
  
 Kentucky |State || 
  
 New York |Birth  || 
  
 Kentucky |Residence  ||
  
 G - State 
  
 Colorado  || 
  
 Ohio           || 
  
 Indiana      || 
  
 Kentucky   || 
  
 New York  || 
  
 etc.
  
 Indiana     |Death 
  
 ||
  
 Ohio          |Temporary   ||
  
 Colorado  |Residence ||
  
  
 Exhibit 20.5.
  
 State GEC",NA
20.3 Generic Validation Table GECs,"GEC support for validation tables can be made even more generic by changing 
 the approach slightly. Instead of defining separate GECs for State and Country, 
 define a single GEC called Table, as shown in Exhibit 20.9.
  
 T values in this GEC are formed by combining G value and “purpose,”e.g., 
 State+Purpose and Country+Purpose. Each T value identifies a logical“table” of 
 valid values. The instances of each logical table are stored as GT records. To add a 
 new table does not require a new GEC, just a new T value and G values and their 
 appropriate linkage in the GT node. This approach requires that all G, T, and GT 
 records within the Table GEC use common GT data elements.
  
 Consider the following elements to be likely candidates:
  
 Value+Purpose: GT node 
  
 Description of the Purpose: T node 
  
 Indicator to report that a Value+Purpose combination has been retired 
 and is no longer valid: GT node 
  
 Indicator to show that, for a given purpose, this is the default value: GT 
 node 
  
 Audit-User: All nodes 
  
 Audit-Timestamp: All nodes
  
 When a new element is introduced into the system, it is defined in the data 
 dictionary. Once defined, it can be established as a T value in the generic table 
 GEC. A new logical table can then be created within",NA
20.4 When to Use Attached or Detached Regulation,"The choice of whether to use attached or detached regulation is made by the 
 designer. If a T node will share a list of valid values, the use of detached regulation 
 is recommended. This will ensure that only one set of values needs to be 
 maintained. For example, if T values for Country-Residence and Country-Birth 
 share the same list of valid countries, entry of Country-Residence and Country-
 Birth values for a Person should be validated against a single central list. It would 
 not make business sense to maintain parallel lists, as that requires a process, 
 manual or automated, for keeping the lists synchronized. And remember, when 
 data exists in two places, it will not necessarily be the same in both places. 
 Although this has nothing to do with flexibility per se, the ability to maintain a 
 nonduplicate list in a flexible manner means that it is much more likely to be done, 
 and it enables business experts to improve the operation of their systems.
  
 Even in the unlikely case that the lists of valid Country-Residence and 
 Country-Birth are not the same, all the involved countries can be listed in the G 
 node. Subsets of the G node values can be established for Residence and Birth 
 using the GT node.
  
 The GEC is flexible in this regard. Attached regulation can be declared initially 
 and later changed to detached regulation through a change in or addition to data 
 values in the T node, thus establishing a logical table in the generic table GEC and 
 connecting to system data via one or more externals.",NA
20.5 Value-to-Value Translation,"Value-to-value translation is one of the most elegant uses of the generic table 
 GEC. We think of it as a kind of regulatory Rosetta stone. There are times when a 
 system process requires translation of one value to another value or values. This 
 discussion looks at how to implement an automated mechanism to serve this 
 purpose by making use of the pr eviously described generic table GEC.",NA
20.6 Summary,NA,NA
Chapter 21,NA,NA
GEC Applications ,NA,NA
and Extensions,"This chapter covers several GEC-oriented topics. Some have to do with the 
 application of the GEC approach. Others are extensions of the basic GEC 
 presented elsewhere in the book. Still others are ideas of how to extend the GEC 
 to make it an even more valuable tool for achieving system flexibility.",NA
21.1 Developing a GEC,"In Chapter 10, we introduced the GEC, showing an example of how information 
 pertaining to positions could be managed. We begin this chapter by exploring 
 another GEC that has only one ring, showing how the Course entity from 
 UniverSIS can be implemented as a GEC. See Exhibit 21.1.
  
 A course is the basic unit of academic instruction at a university. Each course 
 has a system-assigned identifier. A course has numerous attributes such as title 
 (name), subject matter, home college, credit hours, etc. All of this can be 
 accommodated by identifying a Course entity in its simplest form, without use of 
 the GEC. However, using the GEC as a design aid, we are prompted to ask 
 additional questions:
  
 1. 
  
 What are the course names?
  
 2. 
  
 Are there (or could there be) different types of courses? If so, we 
  
 need 
 to define them in the T node.
  
 379",NA
21.2 GEC with Business Rules,"The GEC information structure takes us only part way toward full satis-faction of 
 business requirements. It provides support for data structures and relationships 
 within those structures. With the Role node of the GEC, we can specify a 
 relationship between types, but that may not provide the system with all the 
 business rules related to specific business processes. For example, the role Pre-
 Requisite means that the student cannot register for the course of the type on the 
 right side of the TRT until he has completed the course of the type on the left side 
 of the TRT.
  
 To support our earlier example, Course1|Pre-Req|Course2||, the reg-
 istration process requires logic that tells the system to look for a previous 
 enrollment in Course1 before allowing a student to register for Course2.",NA
21.3 Multi-Ring (3) GEC,"In Chapter 10 we mentioned that a GEC could have multiple rings. The following 
 example shows a GEC-based Person entity having three rings corresponding to 
 three T nodes.
  
 Ring 0: T-Employee 
  
 Ring 1: T-Student 
  
 Ring 2: T-Relationship
  
 The reader will note that we took the business requirements of Chapter 19’s 
 tuition remission example and implemented them in a different way within the 
 GEC structure. Rather than declaring Student and Employee as values of a single 
 T node as in Chapter 19, we declare separate T nodes (and rings) for Student and 
 Employee. Rather than declaring Child, Parent, and Spouse as values of the 
 Person R node, we declare a T node for Relationship. We show this alternative 
 approach to illustrate that the designer can exercise judgment about how to use 
 the GEC structures within the context of the organization’s business 
 requirements.
  
 All the rings share the generic entity file (G). Each ring has a separate file for 
 each of the following: Type (T), Generic Type (GT), Type Role Type (TRT), Role 
 (R), and Generic Role Generic (GRG). In Exhibit 21.7 these are labeled R0, R1, 
 and R2, indicating the ring in which they reside.
  
 To demonstrate how these rings work, we populate the nodes with data. The 
 data is presented in list format, as it is much easier to follow than placing data in 
 the nodes of Exhibit 21.7. Also, for ease of presen-tation, we will treat the data 
 values in these files as if they were the identifiers controlling internode 
 connections.",NA
21.4 The Atomic GEC,"Never content with our work, we ask whether additional flexibility can be 
 incorporated into the GEC design. This section describes what may be the 
 ultimate form of the GEC: the atomic GEC. As a practical matter, this approach 
 may not be ideal, but it provides food for thought. Assume infinite speed and 
 storage and keep an open mind.
  
 What if the system designer decides that all attributes describing the entity are 
 to be implemented as multivalued entities (MVEs)? There would be a (potential) 
 ring for each attribute. Any attribute could have zero, one, or more optional values 
 (in addition to the identity value) dynami-cally. This is the atomic GEC!
  
 This approach may not seem to make sense for “obviously” single-valued 
 elements like birth date, amount owed, name, etc. However, even elements such as 
 these deserve a closer look. One of our authors devel-oped a personnel records 
 system that had no input of its own; it rummaged through existing systems such as 
 payroll, plans, medical, etc. and extracted specific field values such as birth date. It 
 occasionally uncovered more than one value. When this happened, both were 
 reported and stored until the right one was determined and the wrong one deleted 
 via manual data entry. The same thing happens in the case of name. Names can 
 and do change. One of our authors has dropped his middle initial/name and Jr. 
 since his father died. But in some legal situations, he must keep one or the other 
 or both, yielding up to four possible names for the same person.
  
 This again shows the value of cardinality regulation, which can be used to shut 
 down portions of the ring that are not needed initially. Even if all attributes are 
 designated as MVEs, most will be implemented with one occurrence, and most 
 will not need R, TRT, or GRG nodes for either their entity values or their control-
 type values. However, by including at initial implementation time the capability to 
 extend and refine the meaning and use of an attribute without IT intervention, 
 designers provides great —one might say “atomic” — power to the system.",NA
21.5 SubGECs,"The evolution of GEC design is ongoing. This section presents ideas on what we 
 call the “SubGEC.” The MVE typing ring of the GEC allows a great deal of 
 flexibility in typing and categorizing people, and, as shown above, the use of the 
 multi-ring features allows multiple typing within a given GEC. However the multi-
 ring feature does not recognize the hier-archy of types that actually exists.
  
 There may be another way to handle the situation, as shown in Exhibit 21.12. 
 Under the T-Person node, we have the values shown. Presumably, we would 
 record the same information about every person, every employee, and every 
 student. What if we record additional information for degree-seeking students that 
 is different from the additional information for non-degree-seeking students? 
 What about employee/faculty versus employee/staff? To make it more complex, 
 what if we record different additional data for tenured and adjunct faculty?
  
 One approach is to make each Type value in the T node of the GEC a 
 combination of Type and Purpose. For example, in a T node for Country, the 
 values could be Country-Residence, Country-Birth, etc. This approach seems to 
 work well for Country because the possibility of subpurposes seemed fairly 
 remote. We should, however, recognize the lack of flexibility to handle 
 subpurposes should the need for them arise.
  
 Another approach would be to connect the GT node in a Parent GEC to the 
 G node in a Child GEC, as seen in Exhibit 21.13, which shows only the Employee 
 SubGEC. The same approach would be used for a Student SubGEC. The R, TRT, 
 and GRG nodes would be available within the SubGECs as well, though we have 
 not shown them in the exhibit.
  
 With the SubGEC approach, we have an information structure in which data 
 about and relationships between persons as persons can be handled",NA
21.6 Summary,"This chapter has demonstrated the following:
  
 The development of a GEC showing how each node is used The inclusion 
 of general business rules to utilize the information-structure enforcement 
 inherent in the GEC 
  
 The possibility of an atomic GEC in which every attribute of a generic 
 entity is implemented as a multivalued element (MVE) The multiple ring 
 feature of the GEC, which can be used to support and enforce 
 relationships required for the enforcement of complex business rules 
  
 The evolution of GEC technology, which is undergoing continuing 
 development and refinement in the constant quest for more-flexible 
 software systems
  
 The GEC approach provides a way to design information structures that are 
 stable and flexible, resulting in reduction or elimination of main-tenance by the IT 
 staff. This chapter provided various examples of GEC applications and 
 extensions. Chapter 22 presents several tools to facilitate the use and extension of 
 the GEC approach.",NA
Chapter 22,NA,NA
GEC Aids,"The rigor and discipline of the generic-entity cloud (GEC) information structure 
 enables us to create aids for the development and operation of GEC-based 
 flexible software. The GECAnalyzer and GECBuilder are imple-mentation aids; 
 the GECPhazer is an operational aid.
  
 This chapter is meant for the reader who is interested in the details, who wants 
 to know more about GEC operation, and who has thoughts of developing or 
 utilizing similar aids. These aids are described in the sequence in which they are 
 used to develop and implement the informa-tion structures:
  
 GECAnalyzer
 : Once the GECs have been chosen, the GECAnalyzer 
 generates all possible combinations of GECs that may yield external 
 entities in the information structure. This helps ensure that the 
 analyst/designer will not overlook valid combinations, even if they are not 
 currently needed.
  
 GECBuilder
 : The GECBuilder actually builds the files and fields, and 
 provides for raw data entry. The GECBuilder can receive data three ways: 
 (a) from specifications automatically provided by the GECAnalyzer, (b) 
 interactively via GUI screens, and (c) from spec-ification files created with 
 an editor.
  
 GECPhazer
 : After the work of the GECBuilder has been completed, lists of 
 control types and role values are entered into the operational software. We 
 are, in effect, in “maintenance” mode at this point. The GECPhazer 
 generates all possible combinations of the GT (generic-type) node and the 
 TRT (type-role-type) nodes. The business
  
 397",NA
22.1 The GECAnalyzer,"A simple corporate organizational structure is used to illustrate the GECAn-alyzer. 
 Analysis of this sample corporate “system” leads to identification of three generic 
 entities: Organization, Position, and Person. The GECAn-alyzer identifies all 
 possible pairings of those generic entities. Discussion with the business staff 
 reveals which pairings are needed as externals. The process is iterative. Initially, the 
 externals associated with generic entities are identified and marked “yes” or “no.” 
 In the next round, all possible pairings are identified, including those paired with 
 newly created externals, and marked for inclusion or exclusion. Iterations continue 
 until a round results in identification of no new externals. In Exhibit 22.1, we 
 show the process of generating possibilities and accepting or rejecting them. The 
 names of the resulting entities shown as entries in the table are simply the 
 accumulation of the names of the parent entities.
  
 In Exhibit 22.2, we show the net result of the GECAnalyzer’s work. At this 
 point, the analyst and business staff should agree on more meaningful names for 
 the resulting entries. Note that one parent of the Assign external is a GEC, and 
 the other is itself an external.
  
  
 Exhibit 22.3 illustrates the GEC-based flexible software system resulting from 
 the analysis shown in Exhibit 22.2.
  
 The output from the GECAnalyzer is fed to the GECBuilder. It would look 
 like Exhibit 22.4 (only the GECs and externals are shown). The left-hand column 
 is the actual “code,” the right-hand column is the explanation. In Exhibit 22.4, the 
 Org and Pos GECs have as their MVEs (multivalued",NA
22.2 The GECBuilder,"The next two sections describe the GECBuilder operation. First we provide a 
 general description, and then we use a portion of the system above to show 
 samples of the GECBuilder in operation.",NA
22.2.1 The GECBuilder: General Operation,"Once the combinations of GECs and externals have been analyzed and generated 
 in the GECAnalyzer (or manually), the GECBuilder is then used to develop a 
 GEC-based system from an input file. Exhibit 22.5 shows that the GECBuilder is 
 itself made up of GECs and externals. The information structure of the 
 GECBuilder has five GECs represented by boldly outlined boxes (Barber, Role, 
 GE (generic entity), Field, and File) and four externals represented by the lightly 
 lined boxes (GE/Field, File/Field, File/Instance, and Field/Instance). The File-
 GRG file, which is internal to the File GEC, serves as the Relationship file, which 
 supports cardinality regulation.
  
 The GECBuilder is implemented as an atomic database with elementary pieces 
 stored as atomic items. For example, each field value is stored in a separate 
 GECBuilder record so that assembly of an application file record requires access 
 to the GECBuilder field/instance record for each field in an application record 
 instance. This may not be very efficient operationally, but it simplified the 
 implementation of the prototype. The feasibility and practicality of operating an 
 atomic system in a production environment has provided much food for thought 
 and conversation for system designers over the years. We will not review those 
 discussions here. We chose this approach simply because we found it to be an 
 effective way to illustrate our points.",NA
22.2.2 The GECBuilder: Examples of Operation,"Exhibit 22.6 shows part of the system created by the GECBuilder from the file 
 produced in Exhibit 22.4. The first line shows the header of the file generic node, 
 its time produced in the same format as above, its association order, the record 
 length of the records that follow (52 bytes), and a filler. Note that the | delineates 
 fields in the report.
  
  
  
 Exhibit 22.6.
  
 Part of the File GEC Output from a GECBuilder Run",NA
22.3 The GECPhazer,"It helps clarify how truly complex the task of building an infor-mation system really 
 is.
  
 Just as the GECAnalyzer can help the designer include all valid externals, the 
 GECPhazer can help business staff to include all valid combinations of values in 
 the GT and TRT nodes. Once a GEC-based system has been established and data 
 entered into the T and G nodes as presented in the sections above, then the 
 GECPhazer can be used to make sure that no valid business combinations are 
 missed.
  
 Exhibit 22.13 shows a Person GEC based upon Exhibit 10.14 with positions 
 and persons managing themselves. While we do not think it makes sense for an 
 executive to manage himself or herself, nor for the HR director to manage himself 
 or herself, we have seen such situations in organizations. That is the beauty of the 
 GECPhazer aid. It presents all possible combinations for review. The business 
 staff determines validity. If it is invalid, exclude it; if it is valid, include it.
  
 Having defined the valid values for Position, Type, and Role, we can generate 
 all possible combinations for Position|Type|| and Type| Role|Type||. It is 
 likely that not all are current business realities. A business decision must be made 
 regarding which of the possibilities reflects reality. However, the process of 
 generating all the mathematical possibilities and then having business staff review 
 them in a systematic way helps avoid the “oh, I forgot about that” situation. Plus 
 it helps clarify how truly complex the task of building an information system really 
 is.",NA
22.4 Summary,"The rigor and discipline of the GEC information structure enabled the building of 
 three aids for development and operation of GEC-based flexible software. The 
 first two, GECAnalyzer and GECBuilder, are implementation aids; the third, 
 GECPhazer, is an operational aid. Readers can develop similar aids or procure 
 vendor products that provide such capabilities to support GEC design.
  
 GECAnalyzer
 : This module identifies all possible combinations of GECs 
 and externals, thus aiding the information-structure designer in ensuring 
 that no valid combination is omitted.
  
 GECBuilder
 : This module produces a working software system based on 
 GECs and externals designed either manually or by the interaction of the 
 designer, business staff, and the GECAnalyzer.
  
 The GECBuilder can be used to: 
  
 Enter data into a working system in batch or GUI interactive mode",NA
Appendix A,NA,NA
Bibliography ,NA,NA
and References,"Agile Manifesto; available online at http://agilemanifesto.org/principles.html, 3/25/05. 
 Babcock, C., Software lets insurers play by the rules, 
 Information Week, 
 Aug. 16, 26, 2004.
  
 Bach, J., The challenge of good-enough software, 
 Am. Programmer
 , 8, 3–11, 1995. Baker, 
 T.F., Chief programmer team management of production programming, 
 IBM Syst. J.
 , 1, 
 1972.
  
 Barker, J., 
 Paradigms: the Business of Discovering the Future
 , Harper Collins, New 
  
 York, 1992.
  
 Berners-Lee, T., Axioms of Web Architecture: 2 — the Myth of Names and Addresses, 
 1996; available online at http://www.w3.or g/DesignIs-sues/NameMyth.html.
  
 Berners-Lee, T., Cool URIs Don’t Change, 1998; available online at 
  
 http://www.w3.org/Provider/Style/URI.html.
  
 Boehm, C. and Jacopini, A., Flow diagrams: Turing machines and languages with 
  
 only 
 two formation rules, 
 Commn. ACM
 , 9, 366–371, 1996.
  
 Boogaard, M., 
 Defusing the Software Crisis: Information Systems Flexibility through 
  
 Data 
 Independence
 , Book 79, Tinberg Institute Research Series, 1994.
  
 Boucher, R.F. and Mccright, J.S., SAP eyes web services development, 
 eWeek
 , Nov. 17, 
  
 2003.
  
 Brandel, M., Educating Your CXO (sidebar), 
 Computerworld
 , July 26, 2004. Brooks, F., 
 The 
 Mythical Man Month: Essays on Software Engineering
 , Addison-
  
 Wesley, Reading, MA, 
 1975.
  
 Brooks, F., No silver bullet: Essence and accidents in software engineering, 
  
 Computer
 , Apr. 
 1987, pp. 10–19.
  
 417",NA
Use of Our Earlier Material,"We have made extensive use of material that we have published earlier. We have 
 taken the original computer text files and molded them to fit with various sections 
 of the book. Here we acknowledge this material and these publishers.
  
 Our first publication treating the subject of flexible software systems was “The 
 Problem of the Dynamic Organization and the Static System: Principles and 
 Techniques for Achieving Flexibility,” published in 
 Pro-ceedings of the 29th Annual 
 Hawaii International Conference on Systems Sciences
 , HICSS-29, Vol. III, p. 482, IEEE 
 Computer Society Press. Maui, Hawaii, January 1996 [Woolfolk, Ligezinski, and 
 Johnson, 1996] (© 2004 IEEE).
  
 Some of the material relating to the Generic Entity Cloud (GEC) has been 
 taken from “Generic Entity Clouds: a Stable Information Structure for Flexible 
 Computer Systems,” 
 Systems Development Management
 , Octo-ber 2001 [Johnson and 
 Woolfolk, 2001].",NA
Index,NA,NA
A,"regulatory features, 120 
  
 tasks for, 203, 222
  
 Abbreviation information, 96, 100 
  
 tools for, 282
  
 Acceleration effect, 196 
 Access requirements, 193
  
 Analysts. 
 See
  system analysts 
  
 Application data, support of through 
  
 Acronyms, 100 
  
 GECBuilder, 407
  
 Action assertions, 108 
  
 Active flexibility, 14 
  
 Adaptability, 13, 35, 134 
  
  
 change and, 34, 200 
  
 Adaptable systems, 13 
  
 Adaptive code modification, 16 
  
 Adaptive maintenance, 6 
  
 Adaptive software development, 35 
  
 Admissions module of UniverSIS, 65 
  
 Agile development methods, 35, 218, 223, 
  
  
 262 
  
 Agile Manifesto, 219 
  
 Algorithms, 202 
  
  
 resource-allocation, 250 
  
 Analysis, 34, 109 
  
  
 business requirements, 53 
  
  
 derived valued identified during, 148 
  
 GEC, 
 154 
  
  
 generic entities identified during, 216 
  
 iterative, 217 
  
  
 logical, 56 
  
  
 models, 182 
  
  
 overlapping and iterating with design, 
  
 Application development, successful, 3 
 Application integration, 178, 198 
  
  
 lack of, 180 
  
 Application interoperability, 178, 196 
  
 Application systems, correspondence with 
  
  
 enterprise functions, 187 
  
 Applications planning dimension, 179 
  
 Applications systems evaluation, 284 
  
 Applications, packaged, 289 
  
 Architect, 56 
  
 Architecture, N-tiered, 83 
  
 Area code, 101 
  
 Artificial limits, 16, 107, 125, 153, 209 
  
 Assertions, 108 
  
 Assignment, 163 
  
 Association entity, 141, 149 
  
  
 identifiers, 248 
  
 Associations, qualification of with roles, 
  
  
 164, 173 
  
 Atomic GEC, 392, 401 
  
 Attached regulation, 367 
  
  
 when to use, 375
  
 211 
  
 Attribute values, 169
  
 process- and structure-requirements, 
  
 Attributes, 103, 152
  
 201 
  
 coding, 251
  
 423",NA
B ,"analysis of, 53
  
 changes in, 363
  
 Backlog, 263, 269 
  
  
 changes in logic and, 116 
  
 Bad software, 18 
  
 Barber, GECBuilder, 402 
  
 Basic entity, 215 
  
 Basic rule for stable identifiers, 243 
 Batch processes 
  
  
 changes affecting, 264
  
  
 Evaluator, 325 
  
  
 flexible system design and, 76 
  
  
 system support for changes in, 68 
  
  
 top-down approach to gathering, 151 
  
 using GEC structures in context of, 385 
 Business rule logic, invalid data errors and, 
  
  
 259 
  
 Business rules, 25, 57, 107, 216, 277, 311, 
  
 efficiency of, 307 
  
 315, 388
  
 Batch-process-driven systems, 25 
  
 Behavioral outcomes, 95 
  
 Bill-of-materials structure, 21, 157, 216 
  
 control types and, 168 
  
  
 nested recursive relationships and, 140
  
 “if” statements and, 111 
  
 adjustment of, 359 
  
 approach to development, 36 changes 
 in as trigger for system 
  
 modifications, 108, 125
  
 Binary tree, 330 
  
 data-related, 142
  
 BOM Exploder module of GECBuilder, 407 
 Bond group, 327
  
 defining general, 354 
  
 effective periods, 119",NA
C ,"Commissions requirements, 8
  
 Commitment, 60
  
 Callable routines, 82, 84 
  
 Cancellation rate, 3 
  
 Cardinality, 169, 277 
  
  
 assumptions, 214, 222 
  
  
 automated support for enforcement of, 
  
 Common schema, 178 
  
 Communication 
  
  
 as a project management skill, 274 
  
 using 
 to achieve flexibility, 274 
  
 Comparative analyses, versions and, 149
  
 229 
  
 Comparative evaluation, myth of, 287
  
 changes, 108, 238 
  
 externally enforced, 134, 226 
  
 one-to-many relationship, 330 
  
 regulation, 21, 109, 120, 125, 153, 165, 
  
 Compensatory modifications, 133, 221 
 Completeness, 220 
  
 Complex entities, 69 
  
 Complex identifier, 105
  
 392 
  
 Composition, 134
  
 data, 210 
  
 Computer application development, 
  
 implementation of, 123 
  
 successful, 3
  
 limit adjustment through, 357
  
 Computer-assisted systems engineering, 39",NA
D,"Constraints, 57, 133 
  
  
 enterprise-specific entity relationships, 
  
  
 121 
  
 Contact management feature of UniverSIS, 
  
  
 301 
  
 Content-free programs, 120, 125 
  
 Continuous quality improvement, 273, 289 
 Control structures, 24 
  
 Control types, 142, 152, 161, 173, 365, 399, 
  
 Daily builds, enforcing flexibility as part of, 
  
  
 282 
  
 Data, 56 
  
  
 architecture model, 191 
  
  
 creation, information-precedence matrix 
  
  
 and, 193 
  
  
 developer questions about, 205 
  
  
 distinction between testing and 
  
  
  
 production, 268
  
 403 
  
 duplication of, 144
  
 generic entities, 171 
  
 functional determinants of, 208
  
 multiple, 168 
  
 modeling, 203
  
  
 multiple values, 164 
  
 Control-data change, effect of, 234 
  
 Control-type attributes, 142 
  
 Control-type values, 392 
  
 Core business systems, in-house 
  
  
  
 development of, 284 
  
 Corrective maintenance, 6 
  
 Correspondence control, 66, 86 
  
 Correspondence feature of UniverSIS, 303 
 Correspondence tracks feature of 
  
  
  
 UniverSIS, 305 
  
 Cost, 133 
  
  
 dynamics, 22 
  
  
 overruns, 3 
  
 Cost/benefit analysis, 179, 196 
  
 CPU demand, implication of GEC on, 277 
 Create, 193 
  
 Creativity of design, 54, 60 
  
 Critical success factors, 179 
  
  
 identifying, 184 
  
 Cross-reference tables, 95, 264 
  
  
 requirements for, 377 
  
 CRUD, 43 
  
 Custom code, 284 
  
 Customer data maintenance, 193
  
  
 modifications, 169, 347 
  
  
 organization and storage of, 43 
  
  
 processing, 201 
  
  
 requirements, 204 
  
  
  
 normalization and analysis of, 357 
  
 storage, 148 
  
  
  
 flags and, 150 
  
  
 stores, 342 
  
  
 structure-oriented design techniques, 
  
  
  
 226, 238 
  
  
 structures, development and 
  
  
  
  
 understanding of, 202 
  
  
 validation, 378 
  
  
 value, 238 
  
 Data dictionary, 69, 82, 211, 264, 282, 372 Data 
 division, 23 
  
 Data flow diagram, 179, 205, 282, 342, 353 
  
 construction of, 188 
  
 Data flow model, 179 
  
 Data integrity, 353 
  
  
 rules, 351, 357 
  
 Data objects, individual, 84 
  
 Data redundancy 
  
  
 elimination of, 25 
  
  
 fixed typing and, 144 
  
 Data relationships, definition of using data 
  
 Customer dissatisfaction, 9 
  
 dictionary, 82
  
 role of system maintenance in, 10
  
 Data retrieval module of Evaluator, 325",NA
E,"Entity-creation functions, 193
  
 Entity-entity association, 164
  
  
 Effective period dating, 120, 125, 148 
  
 Effective requirements, definition of, 201 
 Efficiency, 25 
  
 Ego-less programming, 85 
  
 Electronic record keeping, 25 
  
 Element ID, 328 
  
 Elements, 372 
  
 Embedded information, 97 
  
  
 identifiers and, 104 
  
  
 Internet naming and, 253 
  
  
 UPC, 99 
  
 Embedded literals, 126 
  
 Employee profile feature in UniverSIS, 312 
 Enterprise functions, correspondence with 
  
  
 application systems, 187 
  
 Enterprise model, 182, 197 
  
  
 information-precedence matrix in, 196 
 Enterprise-specific entity relationship 
  
  
  
 constraints, 121 
  
 Enterprisewide systems planning, 179 
  
 Enterprise-world system, 17 
  
 Entities, 69, 126 
  
  
 associations among, 121 
  
  
 basic, 215 
  
  
 bottom-up derivation of, 152 
  
  
 coding of, 251 
  
  
 external, 168 
  
  
 general-purpose, 297 
  
  
 generic, 173. 
 See also
  generic entities 
  
 identifying, 110 
  
  
 least-specialized, 226 
  
  
 locator, 293. 
 See also
  locators 
  
  
 reduction in the number of, 154, 173 
  
 relationship values, 142 
  
  
 subtypes, 135 
  
  
 supertyping, 249 
  
 Entity generalization schemes, 207 
  
 Entity level constraints, 210 
  
 Entity relationship diagram, 179 
  
  
 construction for strategic planning, 189 
 Entity relationships 
  
  
 enterprise-specific constraints, 121 
  
  
 recursive, 20
  
 Entity-entity nodes, 154 
  
 Entity-relationship diagram, 154, 161, 282 
 Entity-role-entity files, 165 
  
 Environmental changes, analysis of, 272 Error 
 proneness, unstable identifiers and, 
  
  
 96 
  
 Errors of omission, 259 
  
 Evaluation mechanism, 360 
  
 Evaluation module of Evaluator, 321 
  
 Evaluation questions, 284 
  
 Evaluator tool of UniverSIS, 116, 235, 238, 
  
  
 260, 265, 293, 306, 360, 363, 384 
  
 binary tree, 331 
  
  
 building requirements for, 324 
  
  
 components of, 320 
  
  
 cost, 322 
  
  
 criteria for business decisions, 340 
  
  
 details of, 324 
  
  
 maintenance of conditions and 
  
  
  
 requirements, 313 
  
  
 system design and, 341 
  
  
 testing conditions, 268 
  
 Existence 
  
  
 integrity, 102, 105 
  
  
 unstable identifiers and, 96 
  
 Expanded variable typing, 146 
  
 Explicit information, lack of in stable 
  
  
  
 identifiers, 243 
  
 Explicit typing-integrity maintenance, 134 
 Explosion/implosion capability, 21 
  
 Exposed internal identifiers 
 vs.
  hidden 
  
  
 identifiers, 244, 246 
  
 Extension, 103 
  
 External cardinality enforcement, 138, 226 
 External entities, 168 
  
 External identifiers, 90, 96, 244, 377 
  
 External nodes, GECBuilder, 403 
  
 External rules declaration, 392 
  
 Externally enforced cardinality, 134 
  
 Externals, 161, 378, 382, 398 
  
  
 connected to generic-type node, 171 
 Extreme programming, 219
  
 Entity types, 82 
  
  
 assigning of global identifiers without 
  
  
 regard to, 254 
  
  
 generic, 19",NA
F ,"Fast flexibility, 14
  
  
 Entity typing, 110 
 Entity values, 392
  
 Fast-changing variables, 213 Fees, 
 use of UniverSIS for, 67",NA
G ,"G node, 349
  
  
  
 tools for development of, 274 
  
 Flexible systems 
  
  
 accommodation of change in, 263 
  
 comparison with traditional system 
  
  
 design, 363 
  
  
 design of, 348 
  
  
 development of, 221 
  
  
 groupings, 143 
  
  
 identifying dynamic requirements for, 
  
  
 203 
  
  
 Investment Trust Bank in Vienna, 22 
  
 iterative prototyping approach to, 43 
  
 maintenance of, 48 
  
  
 natural limits in, 107 
  
  
 need for, 13
  
 GE node, GECBuilder, 402 
  
 GE/field node, GECBuilder, 403 
  
 GEC, 21, 82, 84, 142, 152, 173, 252, 271, 
  
  
 275, 363 
  
  
 aids for development and operation of 
  
  
 flexible software, 397 
  
  
 analysis of data structures, 348 
  
  
 atomic, 392 
  
  
 building process, 349 
  
  
 business rules and, 382 
  
  
 data integrity rules of, 357 
  
  
 decoding mechanisms and, 169 
  
  
 developing, 379 
  
  
 final-form, 165 
  
  
 flexible design and, 153 
  
  
 generation of rings by multiple control 
  
 reducing of processing logic error to 
  
 types, 168
  
  
  
  
 operator error in, 260 
  
  
 regulatory data in, 262 
  
  
 responsibilities of business and technical 
  
  
  
 staff for, 47 
  
  
 resynchronization and, 34 
  
  
 single-purpose flags and, 149 
  
  
 stable identifiers in, 253 
  
  
 stable structures in, 135, 151 
  
  
 structural stability and, 178, 198 
  
  
 support for changes in requirements, 68 
  
 testing, 53, 259 
  
  
  
 during development, 261 
  
 Foreign key, 95, 141, 248 
  
 FORTRAN, 24
  
 information structure of, 153 
  
  
 flexibility and, 391 
  
 internal regulatory capabilities of, 365 multi-
 ring, 385 
  
 principles for flexible software design, 
  
  
 377 
  
 regulatory activity, 367 
  
 relationships between, 163 
  
 six-node, 161, 164 
  
 sub, 393 
  
 synchronization of, 358 
  
 system design and, 341 
  
 three-node, 154 
  
 use with Evaluator tool, 340 
  
 validation tables, 369
  
 Function-selection information, 96, 101 
  
 generic, 372
  
 Functional accuracy, 36, 200 
  
 Functional components, 186 
  
 Functional decomposition, 179, 185 
 Functional dependencies, 104 
  
 Functional determinant, 90, 148 
  
  
 data elements, 208 
  
 Functional model, components of, 187 
 Functions, 57, 294 
  
  
 access to, 294 
  
  
 changing ownership of, 295 
  
  
 granting access to, 295 
  
  
 owners of, 296 
  
 Future now effect, 177 
  
 Future requirements, 200
  
  
 value-to-value translation, 375 
  
 GECAnalyzer, 397, 411, 414 
  
 GECBuilder, 397, 414 
  
  
 BOM Exploder module of, 407 
  
  
 functions of, 402 
  
  
 general operation, 401 
  
  
 GUI modules of, 405 
  
  
 operation examples, 404 
  
  
 prototype, 411 
  
 GECPhazer, 397, 411, 415 
  
 General business rules. 
 See
  business rules 
 General regulation of business rules, 110, 
  
  
 120, 125 
  
 General-purpose entities, 297 
  
 General-purpose routines, 82, 86",NA
I,"Identification 
  
  
 conventions, 93 
  
  
 importance of, 90 
  
 Identifiers, 19, 106, 141, 152 
  
 assignment of, 244
  
 Generic software, 18 
  
 complex, 105
  
 Generic structures, 134, 238 
  
 Generic tables, 314, 378 
  
 Generic validation table, 372, 378
  
 control of internode connections by, 385 
 date and time, 148 
  
 distributed assignment of, 244, 251
  
 potential problems with, 374 
  
 global, 252
  
 Generic-entity clouds. 
 See
  GEC 
  
 Generic-role-generic nodes. 
 See
  GRG nodes 
 Generic-type node. 
 See
  GT nodes
  
 information-free. 
 See
  information-free 
  
 stable identifiers 
  
 invariant. 
 See
  invariant identifiers
  
 Global data model, 191 
  
 meaningless, 115
  
 Global identifiers, 252 
  
 Global internal identifiers, 244, 249 
  
 GO TO statement, 24 
  
 Good software, 18 
  
 Grade feature of UniverSIS, 315 
  
 GRG nodes, 169, 349, 365, 376, 380, 389, 
  
  
 392, 399 
  
  
 values, 351 
  
 GRG rules, 356, 360 
  
 Groupings, variability of, 143 
  
 GT nodes, 349, 372, 376, 380, 389 
  
  
 externals connected to, 171 
  
 GT rules, 356, 360
  
  
 nested qualification, 136 
  
  
 number of recommended digits in, 243 
  
 relational data model and, 102 
  
  
 reuse of, 244, 251 
  
  
 shared, 95 
  
  
 size, 244, 250 
  
  
 stabilization and normalization, 104 
  
 stable, 
 89 
  
  
 system-assigned, 254 
  
  
 unique. 
 See
  unique identifiers 
  
  
 unstable, 89, 106, 243, 255 
  
  
  
 types of, 96 
  
 Identifying properties, 103 
  
 Identity value, 392",NA
H ,"Handle, 90
  
 If-then-else control structures, 24 
  
 IF/THEN/ELSE program statements, 116, 
  
 126 
  
 Imperfect knowledge, 13
  
  
 Hardware errors, 259, 269
  
 Implicit naming, 96",NA
J,NA,NA
M,"Index
  
 433
  
 Java, 16, 84, 230, 398
  
 Maintenance, 262
  
  
 backlog, 263, 269 
  
  
  
 changes in logic and, 116",NA
K ,"cost of nondiscretionary, 4 
  
 cost 
 rationale underlying, 272
  
 Key customers, 52 
 Keyness, 103
  
 developing teamwork with 
  
 development group, 279 
 flexible systems and, 48, 270 
 interface development and, 5",NA
L,"IT budget, 5 
  
 overload, 180
  
  
 Label, 90 
  
 Laws of physics, constraints on real-world 
  
  
 systems by, 109 
  
 Leadership, as a project management skill, 
  
  
 274 
  
 Least-constrained relationships, 226 
  
 Least-specialized entities, 226 
  
 Legacy systems, maintaining, 5 
  
 Letter of the law interpretation of standards, 
  
  
 83 
  
 Life-cycle cost, 277 
  
 Limited variable typing, 144 
  
 Local modifiability, flexibility and, 15 
  
 Locators, 69, 72, 76, 293 
  
  
 data structures of, 75 
  
 Logic, 116 
  
  
 business, 235, 259 
  
  
 business rules and, 116 
  
  
 conditional. 
 See
  conditional logic 
  
  
 data validation, 259 
  
  
 errors, 269 
  
  
 negative, 267 
  
  
 regulatory, 261 
  
  
 reusable, 82, 84 
  
  
 selection, 235 
  
  
 standard, 211 
  
 Logical analysis and design, 56 
  
 Logical business decision criteria, 340 
  
 Logical data entities, 82, 84, 342 
  
 Logical databases, partitioning, 192 
  
 Logical rings, 154
  
  
 rapid application development and, 39 
  
 reduction of by business rule 
  
  
  
 maintenance, 109, 126 
  
  
 resynchronization, 33 
  
  
 role of in customer dissatisfaction, 10 
  
 types of, 6 
  
  
 unstable keys as a major source of, 19 
 Manageability, 180 
  
 Management, obtaining approval of for 
  
  
 systems planning, 184 
  
 Managers, 48, 61 
  
  
 role and responsibilities of in system 
  
  
 development, 50 
  
 Manufacturing resource planning, 
  
  
  
 generation of stable identifiers for, 
  
  
 244 
  
 Many-to-many associations, 120, 138, 141, 
  
  
 163, 173, 210, 226, 377 
  
  
 functional and organizational units and, 
  
  
 186 
  
 Market opportunities, flexible system 
  
  
  
 response to, 22 
  
 Market research companies, UPC and, 99 
 Meaningless identifiers, 19, 115 
  
  
 system-assigned, 254 
  
 Medium flexibility, 278 
  
 Menus, personalization of, 294 
  
 Mergers, UPC values and, 99 
  
 Metadata, access to, 211 
  
 Method-oriented answers, 95 
  
 Method-
 versus
 -outcome, 36
  
 Logical tables, 111, 372, 378 
  
 Methodology, 35
  
 Long-distance function code, 101 
  
 myth of, 38, 45
  
 Long-term objectives, 82, 87 
  
 Looping control structures, 24 
  
 Loops, information-precedence matrix and, 
  
 Minisystem, testing on, 268 
  
 Missed requirements, 8, 200 
  
 Modifications, 15, 270, 346. 
 See also
  system 
  
 193 
  
 modifications",NA
O,"definition of, 31 
  
 isolated system, 178, 197 
  
 methodology, 38 
  
 naive customer, 42 
  
 outsourcing, 288 
  
 parallel perceptions, 48, 61 
  
 perfect knowledge, 200 
  
 rapid application development, 39 
 retroactive documentation, 213 
  
 solution, 33 
  
 successful system, 41
  
 Object classes, 56 
  
 Object maintenance program, 84 
  
 Object records, 84 
  
 Object subprograms, 196, 328 
  
 Object-oriented design, 35 
  
  
 flexible design and, 44, 84 
  
  
 functions and data in, 57 
  
 Objectives, long-term, 82 
  
 On-Campus Transfer, use of UniverSIS for, 
  
  
 64 
  
 One-to-many associations, 121, 138, 163, 
  
  
 210",NA
N,"One-to-one associations, 121, 138, 377 
 Ongoing operations, testing during, 262 
 Online manipulation, 407
  
  
 N-tiered architecture, 82 
 flexibility and, 83
  
 Operational costs, 5 
  
 Operational problems, 3
  
 Name, 90 
  
 Operational testing, responsibility for 
  
 changes of, 94 
  
 ongoing, 263
  
 Names, qualification information and, 96 
 Naming conventions, 91. 
 See also
  identifiers 
  
 meaningless identifiers and, 115 
  
  
 unique identifiers and, 91
  
 Operator error, 258, 269 
  
 Optimum development sequences, 193 
 Organic systems, 13 
  
 Organization, as a project management 
  
 Naming schemes, 253 
  
 skill, 274
  
 NATURAL, 398 
  
 Natural limits, 16, 107, 209 
 Natural-constraint model, 210
  
 Organization chart, obtaining for systems 
  
 planning, 179, 184 
  
 Organization data maintenance, 193",NA
P,"regulation and, 116 
  
 stable, 34
  
  
 Packaged applications, 289 
  
 Parallel lists, 375 
  
 Parallel perceptions, myth of, 48, 61 
  
 Parameters, 348, 355 
  
 Partial qualification, 96 
  
 Passive flexibility, 14 
  
 Passive/active flexibility dichotomy, 219 
 Patience, 60 
  
 People, 56 
  
 Perfect knowledge, myth of, 200 
  
 Perfective maintenance, 6 
  
 Performance, 109 
  
 Permanent entities, 197 
  
 Permanent functions, 197 
  
 Persistence, 60 
  
 Physical database partitioning, technical 
  
 reasons for, 192 
  
 Planned flexibility, 14 
  
 Planner, 56 
  
 Planning dimensions, 179 
  
 Policies, 109
  
 Processing logic, 117 
  
  
 errors, 259, 269 
  
 Processing requirements 
  
  
 changes to, 18, 192 
  
  
 prototyping and, 218 
  
 Processing time, 237 
  
 Product acquisition, 289 
  
 Product numbers, 103 
  
 Production data, distinction from test data, 
  
  
 268 
  
 Program code, generic, 363 
  
 Program logic, 116, 323 
  
 Program models, 82 
  
 Program modifications, 346 
  
 Programmer/analyst, 55. 
 See also
  system 
  
  
 analysts 
  
 Programmers, 53, 56 
  
  
 GECBuilder as a tool for, 403 
  
  
 minimizing intervention of, 119, 130 
  
 reducing intervention of, 125 
  
  
 testing during development by, 262
  
 Position-type hierarchy, six-node GEC and, 
  
 Programming
  
 161 
  
 extreme, 219
  
 Postinstallation issues, 40 
  
 modifications, 126
  
 Position-role-position relationships, 165 
  
 structured, 24
  
 Precedence considerations, 196 
  
 Precedence matrix, assembling, 193 
 Preferred customer rule, 149 
  
 Primary keys, 89, 103
  
 Programs, modular design of, 117 
 Project management 
  
  
 outsourcing and, 288 
  
  
 synergy with flexibility, 289",NA
Q,"Regulatory data, 69, 260, 369, 388 
  
  
 impact of business-controlled changes 
  
  
 to, 269
  
  
 Qualification identifiers, nested, 136 
 Qualification information, 96 
  
 Quality, flexibility and, 271 
  
 Query tools, design of, 142
  
  
 testing changes to, 257 
  
 Regulatory demands, flexible system 
  
  
 response to changes in, 22 Regulatory 
 entities, 356 
  
  
 complex, 114 
  
  
 elements and, 320",NA
R,"example of, 115 
  
 logical tables and, 111
  
  
 R nodes, 169, 349, 380, 392 
  
  
 GECBuilder, 402 
  
 Random assignment of identifiers, 244 Rapid 
 application development, 35, 44 
  
 myth of, 39, 45 
  
 Rate data maintenance, 193 
  
 Rational unified process, 35 
  
 Real entities, 197 
  
 Real functions, 197 
  
 Real-world model, 205 
  
 Real-world system, 14, 42, 133, 134, 211 
  
 constraints of, 107, 125 
  
  
 identifiers, 90 
  
  
 transformation of to real-world model, 
  
 Regulatory features, analysis and design of, 
  
  
 120 
  
 Regulatory logic, accounting for possible 
  
  
 errors in, 261 
  
 Regulatory mechanisms, 153 
  
  
 GEC, 378 
  
  
 testing of after new development, 264, 
  
  
 269 
  
 Regulatory processes, 120, 125 
  
 Regulatory variables, 130 
  
 Relational data model, identifiers and, 102 
 Relationship node, GECBuilder, 402 
  
 Relationship rules, 142 
  
 Relationship values, entity, 142 
  
 Reliability, unstable identifiers and, 96
  
  
  
 109 
  
 Report processing, use of selection logic in, 
  
 transformation to automated-world 
  
  
  
 235 
  
  
  
 system, 56 
  
 Report-writer tools, design of, 142 Real-world 
 system to real-world model 
  
 Required admission credentials feature of 
  
  
 mapping, 105 
  
  
  
 UniverSIS, 301 
  
 Record identifiers, design of, 19 
  
 Requirements, 8 
  
 Record-count regulation, 169 
  
  
 changes in, 82
  
 Recursion, 154
  
 changes to processing, 18",NA
S,"Index
  
 437
  
 determination, 8
  
 diversity of, 177, 196, 220
  
 Scale, 220
  
  
  
 dynamic, 221 
  
  
  
 identifying, 203 
  
  
 effective, definition of, 201 
  
  
 gathering structural and procedural, 203, 
  
  
  
 204, 222 
  
  
 generic, 221 
  
  
 identifying variations from current, 211 
  
 representing in an analytical model, 205 
  
 software development process and, 199 
  
 specification of, 199 
  
 Resource-allocation algorithm, 250 
  
 Resource-contention problem, 250 
  
 Response time, shared identifier assignment 
  
  
  
 function, 250 
  
 Restructuring of keys, 95 
  
 Resynchronization, 15, 33, 107 
  
  
 user-controlled, 125 
  
 Retroactive documentation, myth of, 213 
 Retroactive regulation, 119, 125 
  
 Reusable logic, 82, 84 
  
 Reuse of identifiers, 244, 251 
  
 Review process, 84
  
 Scope, unstable identifiers and, 96 
  
 Search arguments, 384 
  
 Security, 294 
  
 Selected-ID lists feature of UniverSIS, 307 
 Selection, 142 
  
  
 complexity, 334 
  
 Selection element programs, 237, 322 
  
 Selection logic, 235 
  
 Semantic characteristics, 90, 202 
  
  
 changing, 94 
  
 Semi-automatic program modification, 21 
 Senior-sponsorship approach to planning, 
  
  
 184 
  
 Sense codes, 100 
  
 Sequence control structure, 24 
  
 Sequence information, 96, 101 
  
 Sequential assignment of identifiers, 244 
 Sequential files, design of, 25 
  
 Serial development, 213 
  
 Shared identifiers 
 vs.
  hidden surrogates, 95 
 Simple entities, 69, 141 
  
 Simple regulatory records, 69 
  
 Simple tables, data structure of, 72
  
 Rings 
  
 Simple uniqueness, 92
  
 GEC, 168 
  
 Single-purpose flags, 150
  
  
 typing, 169 
  
 Role nodes. 
 See
  R nodes 
  
 Role responsibilities in software 
  
  
  
 development, 48 
  
 Roles, qualification of associations with, 
  
  
 164, 173 
  
 Routines 
  
  
 callable, 82, 84 
  
  
 coding of, 355 
  
  
 GECBuilder, 403 
  
  
 general purpose, 82, 86 
  
 Rule changes, maintaining a history of, 361 Rule 
 independence, principles of, 131 
  
 Rules, 57 
  
  
 engines, 282 
  
  
 Evaluator, 325 
  
  
 identifying, 110 
  
  
 record, 320 
  
 Rules engines, 108
  
 Single-valued attributes, 141 
  
 Situated software, 220 
  
 Six-node generic-entity cloud, 161, 164, 173 
 Slow-changing variables, 213 
  
 Social environment of a system, 220 
  
 Social security numbers, delimiters in, 102 
 Software development process, 
  
  
  
 requirements as driver for, 199 
 Software engineering, shifts in, 40 
  
 Software engineers, 53 
  
 Software errors, 259, 269 
  
 Software systems 
  
  
 failure of, 9 
  
  
 flexible, 18 
  
 Solution, myth of, 33 
  
 Spaghetti code, 24 
  
 Specifications, 344 
  
 Speed of operation, implication of GEC on, 
  
  
 277 
  
 Spirit of the law interpretation of standards, 
  
 Rules modeling, 223 
  
 83
  
 Runaway project rate, 3 
  
 Stability, 125",NA
T,"approach, 363 
  
 Training, 268
  
  
 T node, 169, 349, 365, 372 
  
 Table definitions, 56 
  
 Tabular notation, 158 
  
 Tag, 90 
  
 Taguchi's loss function, 272 
  
 Team building, as a project management 
  
  
 skill, 274 
  
 Teamwork, using to achieve flexibility, 274 
 Technical design, translating business 
  
  
  
 requirements into, 53 
  
 Technical staff, responsibilities of, 47 
  
 Techniques 
  
  
 data structure-oriented design, 226, 238 
  
 design, 225, 238 
  
  
 process-oriented design, 225, 230, 238, 
  
  
 342 
  
 Technology model, 57 
  
 Technology obsolescence/application 
  
  
  
 retirement plan, 187 
  
 Technology planning dimension, 179 
  
 Telecounseling, UniverSIS and, 68 
  
 Templates, 82 
  
 Test data, distinction from production data, 
  
  
 268 
  
 Test recording feature of UniverSIS, 310
  
 Transformation world concept, 17 
  
 Transformation-series concept, 15 
  
 Transformations, 109 
  
 Trigger mechanism, establishment of, 309 TRT 
 nodes, 169, 349, 376, 380, 387, 392, 399 Tuition, 
 use of UniverSIS for, 67 
  
 Tuition-remission case study, 341 
  
 Type node. 
 See
  T node 
  
 Type validation rule, 351 
  
 Type-role-type files, 165, 365 
  
 Type-role-type nodes. 
 See
  TRT nodes 
  
 Types, defining new relationships between, 
  
  
  
 359 
  
 Typing, 20 
  
  
 attributes, 164 
  
  
 consistent, 142, 151, 153, 173 
  
  
 fixed, 144, 152 
  
  
 generic entities, 141 
  
  
 multiple, 393 
  
  
 mutual exclusivity of, 165 
  
  
 rings, 169 
  
  
 variable, 20, 151, 153, 173 
  
  
  
 limited, 144 
  
 Typing-integrity maintenance, explicit, 134
  
 Testing 
  
 business rules, 267 
  
 during development, 261, 269",NA
U,"during ongoing operations, 262 
 errors encountered in, 257 
  
 guidelines for, 264
  
 Ultimate flexibility, 221 
  
 Ultimate supertype entity, 250 
  
 Ultimate-ancestor/ultimate-child detection, 
  
 phases of, 260 
  
 21
  
 platform, 268, 270 
  
 Three-node generic-entity cloud, 154 Time, 
 56, 152
  
 Uncontrolled technology, 180 
  
 Unexpressed demand, 5 
  
 Unique identifiers, 19, 134, 148, 151, 153, 
  
  
 derived values and, 148 
  
  
  
 173 
  
  
 overruns, 3 
  
  
 naming conventions and, 91 
 Tools, 262, 289 
  
 Uniqueness, 91 
  
 Top-down approach, 151, 208 
  
  
 scope of, 97 
  
 Total quality management, 272 
  
  
 strict, 92",NA
W ,"Waterfall method, 35 
  
 What-if processing, 177 
  
  
 effective period dating and, 120
  
 maintenance, 19 
  
 World Wide Web
  
 UPC, 98 
  
 broken strands on, 252
  
 UPC Council, 98 
  
 flexible design and, 84
  
 Upgrading technology, 6
  
 URI, 253
  
 URL, 253 
  
 URN, 253 
  
 Usage, success, 41 
  
 Use, 193 
  
 User-controlled business rules, 287",NA
X ,"XML standards, meaningless identifiers and, 
  
 115",NA
V ,NA,NA
Z,"Valid values, 369 
  
 Zachman's framework, 56, 60
  
 Validation programming, 351 
  
 Zucchini, 213",NA
