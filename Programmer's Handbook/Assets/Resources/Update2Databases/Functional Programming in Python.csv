Larger Text,Smaller Text,Symbol
Functional ,NA,NA
Programmi,NA,NA
ng ,NA,NA
in Python,NA,NA
David Mertz,NA,NA
Additional ,NA,NA
Resources ,NA,NA
4 Easy Ways to Learn More and Stay ,NA,NA
Current,"Programming Newsletter
  
 Get programming  related news and content delivered weekly to your inbox.
  
 oreilly.com/programming/newsletter 
  
 Free Webcast Series 
  
 Learn about popular programming topics from experts 
 live, online.
  
 webcasts.oreilly.com 
  
 O’Reilly Radar 
  
 Read more insight and analysis about emerging 
 technologies.
  
 radar.oreilly.com 
  
 Conferences 
  
 Immerse yourself in learning at an upcoming O’Reilly 
 conference.
  
 conferences.oreilly.com",NA
Functional ,NA,NA
Progra,NA,NA
mming ,NA,NA
in ,NA,NA
Pytho,NA,NA
n,NA,NA
David Mertz,NA,NA
Table of Contents,"Preface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . . .  v
  
 (Avoiding) Flow Control. . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . . . . .  1
  
 Encapsulation                                                                                       1 
 Comprehensions                                                                                  2 
 Recursion                                                                                              5 
 Eliminating Loops                                                                                7
  
 Callables. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . .  11
  
 Named 
 Functions 
 and 
 Lambdas                                
 12 
 Closures 
 and 
 Callable 
 Instances                                
 13 
 Methods 
 of 
 Classes                                
 15 
 Multiple 
 Dispatch                                
 19
  
 Lazy Evaluation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . .  25
  
 The Iterator Protocol                                                                         
 27 Module: itertools                                                                                
 29
  
 Higher-Order Functions. . . . . . . . . . . . . . . . . . . . . . . . . . 
 . . . . . . . . . . .  33
  
 Utility 
 Higher-Order 
 Functions                                
 35 
 The 
 operator 
 Module                                
 36 
 The 
 functools 
 Module",NA
Preface,NA,NA
What Is Functional ,NA,NA
Programming?,"We’d better start with the hardest question: “What is functional 
 pro‐gramming (FP), anyway?”
  
 One answer would be to say that functional programming is 
 what you do when you program in languages like Lisp, Scheme, 
 Clojure, Scala, Haskell, ML, OCAML, Erlang, or a few others. That 
 is a safe answer, but not one that clarifies very much. 
 Unfortunately, it is hard to get a consistent opinion on just what 
 functional program‐ming is, even from functional programmers 
 themselves. A story about elephants and blind men seems 
 apropos here. It is also safe to contrast functional programming 
 with “imperative programming”(what you do in languages like 
 C, Pascal, C++, Java, Perl, Awk, TCL, and most others, at least for 
 the most part). Functional program‐ming is also not object-
 oriented programming (OOP), although some languages are 
 both. And it is not Logic Programming (e.g., Prolog), but again 
 some languages are multiparadigm.
  
 Personally, 
 I 
 would 
 roughly 
 characterize 
 functional 
 programming as having at least several of the following 
 characteristics. Languages that get called functional make these 
 things easy, and make other things either hard or impossible:
  
 • Functions are first class (objects). That is, everything you 
 can do with “data” can be done with functions themselves 
 (such as passing a function to another function).
  
 • Recursion is used as a primary control structure. In some 
 lan‐guages, no other “loop” construct exists.",NA
Beyond the Standard Library,"While they will not be discussed withing the limited space of 
 this report, a large number of useful third-party Python libraries 
 for",NA
Resources,"There are a large number of other papers, articles, and books 
 written about functional programming, in Python and 
 otherwise. The Python standard documentation itself contains 
 an excellent intro‐duction called 
 “Functional Programming 
 HOWTO,”
  by Andrew Kuchling, that discusses some of the 
 motivation for functional pro‐gramming styles, as well as 
 particular capabilities in Python.
  
 Preface 
  
 | 
  
 vii",NA
A Stylistic Note,"As in most programming texts, a fixed font will be used both for 
 inline and block samples of code, including simple command or 
 function names. Within code blocks, a notional segment of 
 pseudo-code is indicated with a word surrounded by angle 
 brackets (i.e., not valid Python), such as 
 <code-block>
 . In other 
 cases, syntactically valid but undefined functions are used with 
 descriptive names, such as 
 get_the_data()
 .
  
 viii 
  
 | 
  
 Preface",NA
(Avoiding) Flow Control,"In typical imperative Python programs—including those that 
 make use of classes and methods to hold their imperative 
 code—a block of code generally consists of some outside loops 
 (
 for
  or 
 while
 ), assign‐ment of state variables within those loops, 
 modification of data structures like dicts, lists, and sets (or 
 various other structures, either from the standard library or 
 from third-party packages), and some branch statements 
 (
 if
 /
 elif
 /
 else
  or 
 try
 /
 except
 /
 finally
 ). All of this is both natural and 
 seems at first easy to reason about. The problems often arise, 
 however, precisely with those side effects that come with state 
 variables and mutable data structures; they often model our 
 concepts from the physical world of containers fairly well, but it 
 is also difficult to reason accurately about what state data is in 
 at a given point in a program.
  
 One solution is to focus not on constructing a data collection but 
 rather on describing “what” that data collection consists of. 
 When one simply thinks, “Here’s some data, what do I need to 
 do with it?”rather than the mechanism of constructing the data, 
 more direct reasoning is often possible. The imperative flow 
 control described in the last paragraph is much more about the 
 “how” than the “what”and we can often shift the question.",NA
Encapsulation,"One obvious way of focusing more on “what” than “how” is 
 simply to refactor code, and to put the data construction in a 
 more isolated place—i.e., in a function or method. For example, 
 consider an exist‐ing snippet of imperative code that looks like 
 this:",NA
Comprehensions,"Using comprehensions is often a way both to make code more 
 com‐pact and to shift our focus from the “how” to the “what.” A 
 compre‐hension is an expression that uses the same keywords 
 as loop and conditional blocks, but inverts their order to focus 
 on the data",NA
Generators,"Generator comprehensions have the same syntax as list 
 comprehen‐sions—other than that there are no square brackets 
 around them (but parentheses are needed syntactically in some 
 contexts, in place of brackets)—but they are also 
 lazy
 . That is to 
 say that they are merely a description of “how to get the data” 
 that is not realized until one explicitly asks for it, either by 
 calling 
 .next()
  on the object, or by looping over it. This often 
 saves memory for large sequences and defers computation until 
 it is actually needed. For example:
  
 log_lines
 =
 (
 line
 for
 line
 in
 read_line
 (
 huge_log_file
 )
  
 if
 complex_condition
 (
 line
 ))
  
 Comprehensions 
  
 | 
  
 3",NA
Dicts and Sets,"In the same fashion that lists can be created in comprehensions 
 rather than by creating an empty list, looping, and repeatedly 
 call‐",NA
Recursion,"Functional programmers often put weight in expressing flow 
 con‐trol through recursion rather than through loops. Done this 
 way, we can avoid altering the state of any variables or data 
 structures within an algorithm, and more importantly get more 
 at the “what” than the“how” of a computation. However, in 
 considering using recursive styles we should distinguish 
 between the cases where recursion is just “iteration by another 
 name” and those where a problem can readily be partitioned 
 into smaller problems, each approached in a similar way.
  
 There are two reasons why we should make the distinction 
 men‐tioned. On the one hand, using recursion effectively as a 
 way of marching through a sequence of elements is, while 
 possible, really not “Pythonic.” It matches the style of other 
 languages like Lisp, def‐initely, but it often feels contrived in 
 Python. On the other hand, Python is simply comparatively slow 
 at recursion, and has a limited stack depth limit. Yes, you can 
 change this with 
 sys.setrecursion limit()
  to more than the default 
 1000; but if you find yourself doing so it is probably a mistake. 
 Python lacks an internal feature called 
 tail call elimination
  that 
 makes deep recursion computation‐ally efficient in some 
 languages. Let us find a trivial example where recursion is really 
 just a kind of iteration:
  
 def
 running_sum
 (
 numbers
 ,
 start
 =
 0
 ):
  
 if
 len
 (
 numbers
 )
 ==
 0
 :
  
 print
 ()
  
 return
  
 total
 =
 numbers
 [
 0
 ]
 +
 start
  
 print
 (
 total
 ,
 end
 =
 "" ""
 )
  
 running_sum
 (
 numbers
 [
 1
 :],
 total
 )",NA
Eliminating Loops,"Just for fun, let us take a quick look at how we could take out all 
 loops from any Python program. Most of the time this is a bad 
 idea, both for readability and performance, but it is worth 
 looking at how simple it is to do in a systematic fashion as 
 background to contem‐plate those cases where it 
 is
  actually a 
 good idea.
  
 If we simply call a function inside a 
 for
  loop, the built-in higher-
 order function 
 map()
  comes to our aid:
  
 for
 e
 in
 it
 :
 # statement-based loop
  
 func
 (
 e
 )
  
 The following code is entirely equivalent to the functional 
 version, except there is no repeated rebinding of the variable 
 e
  
 involved, and hence no state:
  
 map
 (
 func
 ,
 it
 )
 # map()-based ""loop""
  
 Eliminating Loops 
  
 | 
  
 7",NA
Eliminating Recursion,"As with the simple factorial example given above, sometimes we 
 can
  
 perform 
  
 “recursion 
  
 without 
  
 recursion” 
  
 by 
  
 using 
  
 func
  
 tools.reduce()
  or other 
 folding
  operations (other “folds” are not 
 in the Python standard library, but can easily be constructed 
 and/or occur in third-party libraries). A recursion is often 
 simply a way of combining something simpler with an 
 accumulated intermediate result, and that is exactly what 
 reduce()
  does at heart. A slightly longer discussion of 
 functools.reduce()
  occurs in the chapter on higher-order 
 functions.
  
 10 
  
 | 
  
 (Avoiding) Flow Control",NA
Callables,"The emphasis in functional programming is, somewhat tautolo‐
 gously, on calling functions. Python actually gives us several 
 differ‐ent ways to create functions, or at least something very 
 function-like (i.e., that can be called). They are:
  
 • Regular functions created with 
 def
  and given a name at 
 defini‐tion time
  
 • Anonymous functions created with 
 lambda
  
 • Instances of classes that define a 
 __call()__
  method
  
 • Closures returned by function factories
  
 • Static methods of instances, either via the 
 @staticmethod
  
 deco‐rator or via the class 
 __dict__
  
 • Generator functions
  
 This list is probably not exhaustive, but it gives a sense of the 
 numerous slightly different ways one can create something 
 callable. Of course, a plain method of a class instance is also a 
 callable, but one generally uses those where the emphasis is on 
 accessing and modifying mutable state.
  
 Python is a multiple paradigm language, but it has an emphasis 
 on object-oriented styles. When one defines a class, it is 
 generally to generate instances meant as containers for data 
 that change as one calls methods of the class. This style is in 
 some ways opposite to a functional programming approach, 
 which emphasizes immutability and pure functions.
  
 11",NA
Named Functions and Lambdas,"The most obvious ways to create callables in Python are, in 
 definite order of obviousness, named functions and lambdas. 
 The only in-principle difference between them is simply 
 whether they have a 
 .__qualname__
  attribute, since both can very 
 well be bound to one or more names. In most cases, 
 lambda
  
 expressions are used within Python only for callbacks and other 
 uses where a simple action is 
 inlined
  into a function call. But as 
 we have shown in this report, flow control in general can be 
 incorporated into single-expression lamb‐das if we really want. 
 Let’s define a simple example to illustrate:
  
 >>>
 def
 hello1
 (
 name
 ):
  
 .....
 print
 (
 ""Hello""
 ,
 name
 )
  
 .....
  
 >>>
 hello2
 =
 lambda
 name
 :
 print
 (
 ""Hello""
 ,
 name
 )
  
 >>>
 hello1
 (
 'David'
 )
  
 HelloDavid",NA
Closures and Callable Instances,"There is a saying in computer science that a class is “data with 
 opera‐tions attached” while a closure is “operations with data 
 attached.” In some sense they accomplish much the same thing 
 of putting logic and data in the same object. But there is 
 definitely a philosophical difference in the approaches, with 
 classes emphasizing mutable or rebindable state, and closures 
 emphasizing immutability and pure functions. Neither side of 
 this divide is absolute—at least in Python—but different 
 attitudes motivate the use of each.",NA
Methods of Classes,"All methods of classes are callables. For the most part, however, 
 call‐ing a method of an instance goes against the grain of 
 functional pro‐gramming styles. Usually we use methods 
 because we want to refer‐ence mutable data that is bundled in 
 the attributes of the instance, and hence each call to a method 
 may produce a different result that varies independently of the 
 arguments passed to it.",NA
Accessors and Operators,"Even accessors, whether created with the 
 @property
  decorator 
 or otherwise, are technically callables, albeit accessors are 
 callables with",NA
Static Methods of Instances,"One use of classes and their methods that is more closely 
 aligned with a functional style of programming is to use them 
 simply as namespaces to hold a variety of related functions:
  
 16 
  
 | 
  
 Callables",NA
Generator Functions,"A special sort of function in Python is one that contains a 
 yield 
 statement, which turns it into a generator. What is returned 
 from calling such a function is not a regular value, but rather an 
 iterator 
 that produces a sequence of values as you call the 
 next()
  
 function on it or loop over it. This is discussed in more detail in 
 the chapter entitled “Lazy Evaluation.”
  
 While like any Python object, there are many ways to introduce 
 statefulness into a generator, in principle a generator can be 
 “pure”in the sense of a pure function. It is merely a pure 
 function that pro‐duces a (potentially infinite) sequence of 
 values rather than a single value, but still based only on the 
 arguments passed into it. Notice, however, that generator 
 functions typically have a great deal of 
 inter‐nal
  state; it is at the 
 boundaries of call signature and return value that they act like a 
 side-effect-free “black box.” A simple example:
  
 >>>
 def
 get_primes
 (): 
  
 ...
 ""Simple lazy Sieve of Eratosthenes"" 
  
 ...
 candidate
 =
 2 
  
 ...
 found
 =
 [] 
  
 ...
 while
 True
 : 
  
 ...
 if
 all
 (
 candidate
 %
 prime
 !=
 0
 for
 prime
 in
 found
 ): 
 ...
 yield
 candidate 
  
 ...
 found
 .
 append
 (
 candidate
 ) 
  
 ...
 candidate
 +=
 1
  
 18 
  
 | 
  
 Callables",NA
Multiple Dispatch,"A very interesting approach to programming multiple paths of 
 exe‐cution is a technique called “multiple dispatch” or 
 sometimes “mul‐timethods.” The idea here is to declare multiple 
 signatures for a sin‐gle function and call the actual computation 
 that matches the types or properties of the calling arguments. 
 This technique often allows one to avoid or reduce the use of 
 explicitly conditional branching, and instead substitute the use 
 of more intuitive pattern descriptions of arguments.
  
 A long time ago, this author wrote a module called 
 multimethods 
 that was quite flexible in its options for resolving “dispatch 
 lineariza‐tion” but is also so old as only to work with Python 2.x, 
 and was even written before Python had decorators for more 
 elegant expres‐sion of the concept. Matthew Rocklin’s more 
 recent 
 multipledis patch
  is a modern approach for recent Python 
 versions, albeit it lacks some of the theoretical arcana I explored 
 in my ancient mod‐ule. Ideally, in this author’s opinion, a future 
 Python version would include a standardized syntax or API for 
 multiple dispatch (but more likely the task will always be the 
 domain of third-party libra‐ries).
  
 To explain how multiple dispatch can make more readable and 
 less bug-prone code, let us implement the game of 
 rock/paper/scissors in three styles. Let us create the classes to 
 play the game for all the ver‐sions:
  
 class
 Thing
 (
 object
 ):
 pass
  
 class
 Rock
 (
 Thing
 ):
 pass
  
 Multiple Dispatch 
  
 | 
  
 19",NA
Many Branches,"First a purely imperative version. This is going to have a lot of 
 repet‐itive, nested, conditional blocks that are easy to get 
 wrong:
  
 def
 beats
 (
 x
 ,
 y
 ): 
  
  
 if
 isinstance
 (
 x
 ,
 Rock
 ): 
  
  
  
 if
 isinstance
 (
 y
 ,
 Rock
 ): 
  
  
  
  
 return
 None
 # No winner 
  
  
  
 elif
 isinstance
 (
 y
 ,
 Paper
 ): 
  
  
  
  
 return
 y 
  
  
  
 elif
 isinstance
 (
 y
 ,
 Scissors
 ): 
  
  
  
  
 return
 x 
  
  
  
 else
 : 
  
  
  
  
 raise
 TypeError
 (
 ""Unknown second thing""
 ) 
  
 elif
 isinstance
 (
 x
 ,
 Paper
 ): 
  
  
  
 if
 isinstance
 (
 y
 ,
 Rock
 ): 
  
  
  
  
 return
 x 
  
  
  
 elif
 isinstance
 (
 y
 ,
 Paper
 ): 
  
  
  
  
 return
 None
 # No winner 
  
  
  
 elif
 isinstance
 (
 y
 ,
 Scissors
 ): 
  
  
  
  
 return
 y 
  
  
  
 else
 : 
  
  
  
  
 raise
 TypeError
 (
 ""Unknown second thing""
 ) 
  
 elif
 isinstance
 (
 x
 ,
 Scissors
 ): 
  
  
  
 if
 isinstance
 (
 y
 ,
 Rock
 ): 
  
  
  
  
 return
 y 
  
  
  
 elif
 isinstance
 (
 y
 ,
 Paper
 ): 
  
  
  
  
 return
 x 
  
  
  
 elif
 isinstance
 (
 y
 ,
 Scissors
 ): 
  
  
  
  
 return
 None
 # No winner 
  
  
  
 else
 : 
  
  
  
  
 raise
 TypeError
 (
 ""Unknown second thing""
 ) 
  
 else
 : 
  
  
  
 raise
 TypeError
 (
 ""Unknown first thing""
 )
  
 rock
 ,
 paper
 ,
 scissors
 =
 Rock
 (),
 Paper
 (),
 Scissors
 () 
 # >>> 
 beats(paper, rock) 
  
 # <__main__.Paper at 0x103b96b00> 
  
 # >>> beats(paper, 3) 
  
 # TypeError: Unknown second thing",NA
Delegating to the Object,"As a second try we might try to eliminate some of the fragile 
 repiti‐tion with Python’s “duck typing”—that is, maybe we can 
 have differ‐ent things share a common method that is called as 
 needed:",NA
Pattern Matching,"As a final try, we can express all the logic more directly using 
 multi‐ple dispatch. This should be more readable, albeit there 
 are still a number of cases to define:
  
 from
 multipledispatch
 import
 dispatch
  
 @dispatch
 (
 Rock
 ,
 Rock
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 None
  
 @dispatch
 (
 Rock
 ,
 Paper
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 y
  
 @dispatch
 (
 Rock
 ,
 Scissors
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 x
  
 @dispatch
 (
 Paper
 ,
 Rock
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 x
  
 @dispatch
 (
 Paper
 ,
 Paper
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 None
  
 @dispatch
 (
 Paper
 ,
 Scissors
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 x
  
 @dispatch
 (
 Scissors
 ,
 Rock
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 y
  
 @dispatch
 (
 Scissors
 ,
 Paper
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 x
  
 @dispatch
 (
 Scissors
 ,
 Scissors
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ):
 return
 None
  
 @dispatch
 (
 object
 ,
 object
 ) 
  
 def
 beats3
 (
 x
 ,
 y
 ): 
  
  
 if
 not
 isinstance
 (
 x
 ,(
 Rock
 ,
 Paper
 ,
 Scissors
 )): 
  
  
 raise
 TypeError
 (
 ""Unknown first thing""
 ) 
  
 else
 : 
  
  
  
 raise
 TypeError
 (
 ""Unknown second thing""
 )
  
 # >>> beats3(rock, paper) 
  
 # <__main__.DuckPaper at 0x103b894a8> # 
 >>> beats3(rock, 3) 
  
 # TypeError: Unknown second thing
  
 22 
  
 | 
  
 Callables",NA
Predicate-Based Dispatch,"A really exotic approach to expressing conditionals as dispatch 
 deci‐sions is to include predicates directly within the function 
 signatures (or perhaps within decorators on them, as with 
 multipledispatch
 ). I do not know of any well-maintained Python 
 library that does this, but let us simply stipulate a hypothetical 
 library briefly to illustrate the concept. This imaginary library 
 might be aptly named 
 predicative_dispatch
 :
  
 from
 predicative_dispatch
 import
 predicate
  
 @predicate
 (
 lambda
 x
 :
 x
 <
 0
 ,
 lambda
 y
 :
 True
 )
  
 def
 sign
 (
 x
 ,
 y
 ):
  
 print
 (
 ""x is negative; y is""
 ,
 y
 )
  
 @predicate
 (
 lambda
 x
 :
 x
 ==
 0
 ,
 lambda
 y
 :
 True
 )
  
 def
 sign
 (
 x
 ,
 y
 ):
  
 print
 (
 ""x is zero; y is""
 ,
 y
 )
  
 @predicate
 (
 lambda
 x
 :
 x
 >
 0
 ,
 lambda
 y
 :
 True
 )
  
 def
 sign
 (
 x
 ,
 y
 ):
  
 print
 (
 ""x is positive; y is""
 ,
 y
 )
  
 While this small example is obviously not a full specification, the 
 reader can see how we might move much or all of the 
 conditional branching into the function call signatures 
 themselves, and this might result in smaller, more easily 
 understood and debugged func‐tions.
  
 Multiple Dispatch 
  
 | 
  
 23",NA
Lazy Evaluation,"A powerful feature of Python is its 
 iterator protocol
  (which we 
 will get to shortly). This capability is only loosely connected to 
 func‐tional programming per se, since Python does not quite 
 offer 
 lazy data structures
  in the sense of a language like Haskell. 
 However, use of the iterator protocol—and Python’s many 
 built-in or standard library iteratables—accomplish much the 
 same effect as an actual lazy data structure.
  
 Let us explain the contrast here in slightly more detail. In a 
 language like Haskell, which is inherently lazily evaluated, we 
 might define a list of all the prime numbers in a manner like the 
 following:
  
 -- Define a list of ALL the prime numbers
  
 primes
 =
 sieve
 [
 2
 ..
 ]
  
 where
 sieve
 (
 p
 :
 xs
 )
 =
 p
 :
 sieve
 [
 x
 |
 x
 <-
 xs
 ,(
 x
 `
 rem
 `
 p
 )
 /=
 0
 ]
  
 This report is not the place to try to teach Haskell, but you can 
 see a comprehension in there, which is in fact the model that 
 Python used in introducing its own comprehensions. There is 
 also deep recursion involved, which is not going to work in 
 Python.
  
 Apart from syntactic differences, or even the ability to recurse 
 to indefinite depth, the significant difference here is that the 
 Haskell version of 
 primes
  is an actual (infinite) sequence, not 
 just an object capable of sequentially producing elements (as 
 was the 
 primes 
 object we demonstrated in the chapter entitled 
 “Callables”). In par‐ticular, you can index into an arbitrary 
 element of the infinite list of primes in Haskell, and the 
 intermediate values will be produced internally as needed 
 based on the syntactic construction of the list itself.",NA
The Iterator Protocol,"The easiest way to create an iterator—that is to say, a lazy 
 sequence—in Python is to define a generator function, as was 
 discussed in the chapter entitled “Callables.” Simply use the 
 yield
  statement within the body of a function to define the 
 places (usually in a loop) where values are produced.
  
 Or, technically, the 
 easiest
  way is to use one of the many iterable 
 objects already produced by built-ins or the standard library 
 rather than programming a custom one at all. Generator 
 functions are syn‐tax sugar for defining a function that returns 
 an iterator.
  
 Many objects have a method named 
 .__iter__()
 , which will return 
 an iterator when it is called, generally via the 
 iter()
  built-in func‐
 tion, or even more often simply by looping over the object (e.g., 
 for item in collection: ...
 ).
  
 What an iterator 
 is
  is the object returned by a call to 
 iter(some 
 thing)
 , which itself has a method named 
 .__iter__()
  that simply 
 returns the object itself, and another method named 
 .__next__()
 . 
 The reason the iterable itself still has an 
 .__iter__()
  method is to 
 make 
 iter()
 idempotent
 . That is, this identity should always hold 
 (or raise 
 TypeError(""object is not iterable"")
 ):
  
 iter_seq
 =
 iter
 (
 sequence
 ) 
  
 iter
 (
 iter_seq
 )
 ==
 iter_seq
  
 The above remarks are a bit abstract, so let us look at a few 
 concrete examples:
  
 >>>
 lazy
 =
 open
 (
 '06-laziness.md'
 )
 # iterate over lines of file 
 >>>
 '__iter__'
 in
 dir
 (
 lazy
 )
 and
 '__next__'
 in
 dir
 (
 lazy
 ) 
  
 True 
  
 >>>
 plus1
 =
 map
 (
 lambda
 x
 :
 x
 +
 1
 ,
 range
 (
 10
 )) 
  
 >>>
 plus1
 # iterate over deferred computations 
 <
 map
 at
 0x103b002b0
 > 
  
 >>>
 '__iter__'
 in
 dir
 (
 plus1
 )
 and
 '__next__'
 in
 dir
 (
 plus1
 ) 
 True 
  
 >>>
 def
 to10
 (): 
  
 ...
 for
 i
 in
 range
 (
 10
 ): 
  
 ...
 yield
 i 
  
 ...
  
 >>>
 '__iter__'
 in
 dir
 (
 to10
 ) 
  
 False 
  
 >>>
 '__iter__'
 in
 dir
 (
 to10
 ())
 and
 '__next__'
 in
 dir
 (
 to10
 ()) 
 True
  
 The Iterator Protocol 
  
 | 
  
 27",NA
Module: itertools,"The module 
 itertools
  is a collection of very powerful—and care‐
 fully designed—functions for performing 
 iterator algebra
 . That 
 is, these allow you to combine iterators in sophisticated ways 
 without having to concretely instantiate anything more than is 
 currently required. As well as the basic functions in the module 
 itself, the 
 module documentation
  provides a number of short, 
 but easy to get subtly wrong, recipes for additional functions 
 that each utilize two or three of the basic functions in 
 combination. The third-party module 
 more_itertools
  mentioned 
 in the Preface provides addi‐tional functions that are likewise 
 designed to avoid common pitfalls and edge cases.
  
 The basic goal of using the building blocks inside 
 itertools
  is to 
 avoid performing computations before they are required, to 
 avoid the memory requirements of a large instantiated 
 collection, to avoid potentially slow I/O until it is stricly 
 required, and so on. Iterators are lazy sequences rather than 
 realized collections, and when com‐bined with functions or 
 recipes in 
 itertools
  they retain this prop‐erty.
  
 Here is a quick example of combining a few things. Rather than 
 the stateful 
 Fibonacci
  class to let us keep a running sum, we 
 might sim‐ply create a single lazy iterator to generate both the 
 current number and this sum:
  
 >>>
 def
 fibonacci
 (): 
  
 ...
 a
 ,
 b
 =
 1
 ,
 1 
  
 ...
 while
 True
 : 
  
 ...
 yield
 a 
  
 ...
 a
 ,
 b
 =
 b
 ,
 a
 +
 b 
  
 ...
  
 >>>
 from
 itertools
 import
 tee
 ,
 accumulate 
  
 >>>
 s
 ,
 t
 =
 tee
 (
 fibonacci
 ()) 
  
 >>>
 pairs
 =
 zip
 (
 t
 ,
 accumulate
 (
 s
 )) 
  
 >>>
 for
 _
 ,(
 fib
 ,
 total
 )
 in
 zip
 (
 range
 (
 7
 ),
 pairs
 ): 
 ...
 print
 (
 fib
 ,
 total
 ) 
  
 ...
  
 11 
  
 12 
  
 24 
  
 37 
  
 512 
  
 820 
  
 1333
  
 Module: itertools 
  
 | 
  
 29",NA
Chaining Iterables,"The 
 itertools.chain()
  and 
 itertools.chain.from_iterable() 
 functions 
 combine multiple iterables. Built-in 
 zip()
  and 
 iter 
 tools.zip_longest()
  also do this, of course, but in manners that 
 allow incremental advancement through the iterables. A conse‐
 quence of this is that while chaining infinite iterables is valid 
 syntac‐tically and semantically, no actual program will exhaust 
 the earlier iterable. For example:
  
 from
 itertools
 import
 chain
 ,
 count
  
 thrice_to_inf
 =
 chain
 (
 count
 (),
 count
 (),
 count
 ())
  
 Conceptually, 
 thrice_to_inf
  will count to infinity three times, but 
 in practice once would always be enough. However, for merely 
 large 
 iterables—not for infinite ones—chaining can be very 
 useful and parsimonious:
  
 def
 from_logs
 (
 fnames
 ):
  
 yield from
 (
 open
 (
 file
 )
 for
 file
 in
 fnames
 )
  
 lines
 =
 chain
 .
 from_iterable
 (
 from_logs
 (
  
 [
 'huge.log'
 ,
 'gigantic.log'
 ]))",NA
Higher-Order Functions,"In the last chapter we saw an iterator algebra that builds on the 
 iter tools
  module. In some ways, higher-order functions (often 
 abbrevi‐ated as “HOFs”) provide similar building blocks to 
 express complex concepts by combining simpler functions into 
 new functions. In general, a 
 higher-order function
  is simply a 
 function that takes one or more functions as arguments and/or 
 produces a function as a result. Many interesting abstractions 
 are available here. They allow chain‐ing and combining higher-
 order functions in a manner analogous to how we can combine 
 functions in 
 itertools
  to produce new itera‐bles.
  
 A few useful higher-order functions are contained in the 
 functools 
 module, and a few others are built-ins. It is common 
 the think of 
 map()
 , 
 filter()
 , and 
 functools.reduce()
  as the most 
 basic build‐ing blocks of higher-order functions, and most 
 functional program‐ming languages use these functions as their 
 primitives (occasionally under other names). Almost as basic as 
 map/filter/reduce as a build‐ing block is currying. In Python, 
 currying is spelled as 
 partial()
 , and is contained in the 
 functools
  
 module—this is a function that will take another function, along 
 with zero or more arguments to pre-fill, and return a function of 
 fewer arguments that operates as the input function would 
 when those arguments are passed to it.
  
 The built-in functions 
 map()
  and 
 filter()
  are equivalent to com‐
 prehensions—especially now that generator comprehensions 
 are available—and most Python programmers find the 
 comprehension versions more readable. For example, here are 
 some (almost) equiv‐alent pairs:
  
 33",NA
Utility Higher-Order Functions,"A handy utility is 
 compose()
 . This is a function that takes a 
 sequence of functions and returns a function that represents the 
 application of each of these argument functions to a data 
 argument:
  
 def
 compose
 (
 *
 funcs
 ): 
  
  
 """"""Return a new function s.t.
  
  
  compose(f,g,...)(x) == f(g(...(x)))"""""" 
 def
 inner
 (
 data
 ,
 funcs
 =
 funcs
 ): 
  
   
 result
 =
 data 
  
   
 for
 f
 in
 reversed
 (
 funcs
 ): 
  
    
 result
 =
 f
 (
 result
 ) 
  
   
 return
 result 
  
 return
 inner
  
 # >>> times2 = lambda x: x*2 
  
 # >>> minus3 = lambda x: x-3 
  
 # >>> mod6 = lambda x: x%6 
  
 # >>> f = compose(mod6, times2, minus3) 
  
 # >>> all(f(i)==((i-3)*2)%6 for i in range(1000000)) # True
  
 For these one-line math operations (
 times2
 , 
 minus3
 , etc.), we 
 could have simply written the underlying math expression at 
 least as easily; but if the composite calculations each involved 
 branching, flow control, complex logic, etc., this would not be 
 true.
  
 The built-in functions 
 all()
  and 
 any()
  are useful for asking 
 whether a predicate holds of elements of an iterable. But it is 
 also nice to be able to ask whether any/all of a collection of 
 predicates hold for a particular data item in a composable way. 
 We might implement these as:
  
 all_pred
 =
 lambda
 item
 ,
 *
 tests
 :
 all
 (
 p
 (
 item
 )
 for
 p
 in
 tests
 ) 
 any_pred
 =
 lambda
 item
 ,
 *
 tests
 :
 any
 (
 p
 (
 item
 )
 for
 p
 in
 tests
 )
  
 To show the use, let us make a few predicates:
  
 >>>
 is_lt100
 =
 partial
 (
 operator
 .
 ge
 ,
 100
 )
 # less than 100? 
 >>>
 is_gt10
 =
 partial
 (
 operator
 .
 le
 ,
 10
 )
 # greater than 10? 
 >>>
 from
 nums
 import
 is_prime
 # implemented elsewhere 
 >>>
 all_pred
 (
 71
 ,
 is_lt100
 ,
 is_gt10
 ,
 is_prime
 ) 
  
 True 
  
 >>>
 predicates
 =
 (
 is_lt100
 ,
 is_gt10
 ,
 is_prime
 ) 
  
 >>>
 all_pred
 (
 107
 ,
 *
 predicates
 ) 
  
 False
  
 The library 
 toolz
  has what might be a more general version of 
 this called 
 juxt()
  that creates a function that calls several 
 functions with",NA
The operator Module,"As has been shown in a few of the examples, every operation 
 that can be done with Python’s infix and prefix operators 
 corresponds to a named function in the 
 operator
  module. For 
 places where you want to be able to pass a function performing 
 the equivalent of some syntactic operation to some higher-order 
 function, using the name from 
 operator
  is faster and looks nicer 
 than a corresponding lambda. For example:
  
 # Compare ad hoc lambda with `operator` function
  
 sum1
 =
 reduce
 (
 lambda
 a
 ,
 b
 :
 a
 +
 b
 ,
 iterable
 ,
 0
 )
  
 sum2
 =
 reduce
 (
 operator
 .
 add
 ,
 iterable
 ,
 0
 )
  
 sum3
 =
 sum
 (
 iterable
 )
 # The actual Pythonic way",NA
The functools Module,"The obvious place for Python to include higher-order functions 
 is in the 
 functools
  module, and indeed a few are in there. 
 However, there are surprisingly few utility higher-order 
 functions in that module. It has gained a few interesting ones 
 over Python versions, but core developers have a resistence to 
 going in the direction of a full functional programming language. 
 On the other hand, as we have seen in a few example above, 
 many of the most useful higher-order functions only take a few 
 lines (sometimes a single line) to write yourself.
  
 Apart from 
 reduce()
 , which is discussed at the start of this 
 chapter, the main facility in the module is 
 partial()
 , which has 
 also been",NA
Decorators,"Although it is—by design—easy to forget it, probably the most 
 com‐mon use of higher-order functions in Python is as 
 decorators. A decorator is just syntax sugar that takes a function 
 as an argument, and if it is programmed correctly, returns a new 
 function that is in some way an 
 enhancement
  of the original 
 function (or method, or class). Just to remind readers, these two 
 snippets of code defining 
 some_func
  and 
 other_func
  are 
 equivalent:
  
 @enhanced
  
 def
 some_func
 (
 *
 args
 ):
  
 pass
  
 def
 other_func
 (
 *
 args
 ):
  
 pass
  
 other_func
 =
 enhanced
 (
 other_func
 )
  
 Used with the decorator syntax, of course, the higher-order 
 function is necessarily used at definition time for a function. For 
 their intended purpose, this is usually when they are best 
 applied. But the same decorator function can always, in 
 principle, be used elsewhere in a program, for example in a 
 more dynamic way (e.g., mapping a decorator function across a 
 runtime-generated collection of other functions). That would be 
 an unusual use case, however.
  
 Decorators are used in many places in the standard library and 
 in common third-party libraries. In some ways they tie in with 
 an idea that used to be called “aspect-oriented programming.” 
 For example, the decorator function 
 asyncio.coroutine
  is used to 
 mark a func‐tion as a coroutine. Within 
 functools
  the three 
 important 
 decorator 
 functions 
 are 
 functools.lru_cache
 , 
 functools.total_ordering
 , 
 and 
 functools.wraps
 . 
 The 
 first 
 “memoizes” a function (i.e., it caches the arguments passed and 
 returns stored values rather than performing new computation 
 or I/O). The second makes it easier to write custom classes that 
 want to use inequality operators. The last makes it easier to 
 write new decorators. All of these are important",NA
About the Author,"David Mertz
  is a director of the PSF, and chair of its 
 Trademarks Committee and Outreach & Education Committee. 
 He wrote the columns 
 Charming Python
  and 
 XML Matters
  for 
 IBM developer‐Works and the Addison-Wesley book 
 Text 
 Processing in Python
 , has spoken at multiple OSCONs and 
 PyCons, and was invited to be a keynote speaker at PyCon India, 
 PyCon UK, PyCon ZA, and PyCon Belarus.
  
 In the distant past, David spent some time as a university 
 professor, teaching in areas far removed from computer 
 programming, but gained some familiarity with the vicissitudes 
 of pedagogy.
  
 Since 2008, David has worked with folks who have built the 
 world’s fastest supercomputer for performing molecular 
 dynamics. He is pleased to find Python becoming the default 
 high-level language for most scientific computing projects.",NA
