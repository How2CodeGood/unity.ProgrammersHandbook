Larger Text,Smaller Text,Symbol
Unity AI Programming ,NA,NA
Essentials,NA,NA
"Use Unity3D, a popular game development ecosystem, ",NA,NA
to add realistic AI to your games quickly and effortlessly,NA,NA
Curtis Bennett,NA,NA
Dan Violet Sagmiller,"BIRMINGHAM - MUMBAI
 www.itbookshub.com",NA
Unity AI Programming Essentials,"Copyright © 2014 Packt Publishing
 All rights reserved. No part of this book may be reproduced, stored in a retrieval 
 system, or transmitted in any form or by any means, without the prior written 
 permission of the publisher, except in the case of brief quotations embedded in 
 critical articles or reviews.
 Every effort has been made in the preparation of this book to ensure the accuracy 
 of the information presented. However, the information contained in this book is 
 sold without warranty, either express or implied. Neither the authors, nor Packt 
 Publishing, and its dealers and distributors will be held liable for any damages 
 caused or alleged to be caused directly or indirectly by this book.
 Packt Publishing has endeavored to provide trademark information about all of the 
 companies and products mentioned in this book by the appropriate use of capitals. 
 However, Packt Publishing cannot guarantee the accuracy of this information.
 First published: December 2014
 Production reference: 1151214
 Published by Packt Publishing Ltd.
 Livery Place
 35 Livery Street
 Birmingham B3 2PB, UK.
 ISBN 978-1-78355-355-6
 www.packtpub.com
 www.itbookshub.com",NA
Credits,"Authors
 Curtis Bennett
 Dan Violet Sagmiller
 Reviewers
 Davide Aversa
 Adam Boyce
 Jesse Lu
 Brent Owens
 Angelo Tadres
 Francisco Ureña
 Commissioning Editor
 Akram Hussain
 Acquisition Editor
 Subho Gupta
 Content Development Editor
 Prachi Bisht
 Technical Editors
 Tanvi Bhatt
 Siddhi Rane
 Copy Editors
 Gladson Monteiro
 Deepa Nambiar
 Rashmi Sawant
 Project Coordinator
 Sageer Parkar
 Proofreaders
 Ameesha Green
 Jonathan Todd
 Indexer
 Priya Sane
 Graphics
 Disha Haria
 Production Coordinator
 Komal Ramchandani
 Cover Work
 Komal Ramchandani
 www.itbookshub.com",NA
Foreword,"Artificial intelligence can be one of the most challenging aspects of video game 
 development. Game AI encompasses difficult concepts such as spatial reasoning, 
 pathfinding, movement, awareness, and decision making, all with the goal of 
 combining these concepts into a realistic and lifelike experience for the player. It's 
 no wonder that so many game developers put off AI development to the end of the 
 project. This is a shame, because good AI can make or break the game experience 
 and great AI can make a player fall in love with your game and keep them coming 
 back again and again.
 In recent years, AI has become more important than ever. Although the quality 
 of AI in games has increased steadily over time, the results have come more from 
 added attention and effort on the part of developers, rather than from significant 
 breakthroughs in technology. The impact of this is that ""good"" AI in games has 
 often been limited to projects and teams with large budgets and access to high-end 
 tools. Unity changed the industry by making high-end game development tools 
 available to all developers, big and small. Today's indie developers are creating 
 player experiences that rival those of AAA companies. Until recently, they lacked 
 the tools, knowledge, and know-how to add AI-driven characters that have the same 
 fidelity as the rest of the game. Now this has changed too, with the very best AI tools 
 becoming accessible to every developer.
 This book serves an important role in the rise of AI in Unity. In these pages, you 
 will find the guidance, techniques, and examples you need to become a great AI 
 developer. For beginners, the book walks you step by step through the fundamentals 
 of concepts such as pathfinding, patrolling, and creating behaviors for common 
 scenarios such as attacking and crowd movement. You will also be introduced to the 
 numerous tools available for Unity that you'll need along the way. For experienced 
 developers, the book gives you access to best practices, tips, and techniques that will 
 take you from good to great.
 www.itbookshub.com",NA
About the Authors,"Curtis Bennett
  has been a developer in the games and computer graphics industry 
 for several years. He has worked on developing immersive virtual environments, 
 published research in visual simulation, taught college courses in game development, 
 and worked for various game studios, and he was also an engineer on early versions 
 of the RAIN AI plugin for Unity. Currently, he is the Technical Director for Creative 
 Services at Ideum, which focuses on creating interactive media projects.
 I'd like to thank all the Unity AI plugin developers who make 
 implementing AI with Unity so easy.
 Dan Violet Sagmiller
  has always had a strong passion for game development, 
 although most of his work leads him to senior business development roles. He 
 developed several games, including 
 Teams RPG
 , a space shooter (which won a game 
 development competition at Technology Center of DuPage), and some casual games. 
 He started teaching game development at Heartland Community College in 2005, 
 taking over the existing course and expanding it to six courses. Later, he took a 
 position with Microsoft and expanded the game development curriculum for  
 Bellevue College, including classes on AI, physics, testing and designing using C#  
 and XNA. Later, he moved on to a senior position with Wizards of the Coast, where  
 he also taught game development and AI internally. He also has given talks at multiple 
 schools about getting into game development and programming as a career. More 
 recently, he released a game development book on C# and XNA, which had 2,000 
 downloads in the first week. He also runs Learn Build Play, a small private school 
 dedicated to teaching game development and design mostly with C# and Unity 3D.
 He can be contacted at 
 Dan.Sagmiller@LearnBuildPlay.com
 .
 www.itbookshub.com",NA
About the Reviewers,"Davide Aversa
  graduated in Computer Science with a Master's degree in Artificial 
 Intelligence and Robotics. Currently, he is a PhD student at La Sapienza University of 
 Rome, where he works on game AI, character behavior, and computational creativity.
 Adam Boyce
  is a software developer and independent game developer who 
 specializes in C# scripting, game design, and AI development. His experience 
 includes application support, software development, and data architecture  
 with various Canadian corporations. This is his first technical review for Packt 
 Publishing. You can read his development blog at 
 www.gameovertures.ca
  and 
 follow him on Twitter at 
 @AdamBoyce4
 .
 I'd like to thank my wife, Gail, for her support through this process 
 and her patience with my late-night code review sessions.
 Jesse Lu
  has been a Unity 3D programmer for 5 years. In these years,  
 he developed some games with Unity 3D, for example, 
 《王途霸
 业
 》
 ,  
 《凡人修仙》
 , 
 《
 临
 兵斗者三国志》
 , and so on.
 www.itbookshub.com",NA
www.PacktPub.com,NA,NA
"Support files, eBooks, discount offers, and more TM","For support files and downloads related to your book, please visit 
 www.PacktPub.com
 .
 Did you know that Packt offers eBook versions of every book published, with PDF 
 and ePub files available? You can upgrade to the eBook version at 
 www.PacktPub.com
  
 and as a print book customer, you are entitled to a discount on the eBook copy. Get in 
 touch with us at 
 service@packtpub.com
  for more details.
 At 
 www.PacktPub.com
 , you can also read a collection of free technical articles, sign up  
 for a range of free newsletters and receive exclusive discounts and offers on Packt 
 books and eBooks.
 https://www2.packtpub.com/books/subscription/packtlib
 Do you need instant solutions to your IT questions? PacktLib is Packt's online digital 
 book library. Here, you can search, access, and read Packt's entire library of books.",NA
Why subscribe?,"• 
 Fully searchable across every book published by Packt
 • 
 Copy and paste, print, and bookmark content
 • 
 On demand and accessible via a web browser",NA
Free access for Packt account holders,"If you have an account with Packt at 
 www.PacktPub.com
 , you can use this to access 
 PacktLib today and view 9 entirely free books. Simply use your login credentials for 
 immediate access.",NA
Table of Contents,"Preface 
 1
 Chapter 1: Pathfinding 
 5
 An overview 
 5
 Quick Path AI 
 6
 React AI 
 8
 RAIN AI 
 12
 Comparing AI solutions 
 16
 Summary 
 17
 Chapter 2: Patrolling 
 19
 Quick Path AI 
 19
 React AI 
 21
 RAIN AI 
 23
 Summary 
 28
 Chapter 3: Behavior Trees  
 29
 An overview of behavior trees 
 30
 RAIN node types 
 30
 The behavior tree demo 
 32
 Summary 
 44
 Chapter 4: Crowd Chaos 
 45
 An overview of crowd chaos 
 45
 React AI 
 46
 Setting up a scene with React 
 46
 Building behavior trees in React 
 49
 Setting up wandering characters with React 
 50",NA
Preface,"Welcome to 
 Unity AI Programming Essentials
 . This book will guide you through 
 all the skills necessary to put realistic game AI into your Unity games. We won't 
 be spending much time discussing AI theory or how to implement popular AI 
 algorithms from scratch. Instead, we will take the more efficient approach of using 
 third-party Unity AI plugins to set up AI for your games easily. We will cover all the 
 essential game AI skills, such as pathfinding to have your characters navigate a game 
 scene, behavior trees to let them ""think"", and sensors so that they can react to their 
 environment. We'll also cover more specialized tasks such as setting up crowds and 
 cars for driving and integrating animation. By the end of the book, you should know 
 all the basic skills you need to create game AI with Unity.",NA
What this book covers,"Chapter 1
 , 
 Pathfinding
 , covers how to set up basic pathfinding so that game characters 
 can navigate a game scene realistically.
 Chapter 2
 , 
 Patrolling
 , extends our pathfinding to have characters patrol routes in  
 a scene.
 Chapter 3
 , 
 Behavior Trees
 , explains behavior trees and how they are used to give AI 
 characters the ability to make decisions.
 Chapter 4
 , 
 Crowd Chaos
 , focuses on creating a wander behavior that can be used to 
 create ambient crowds.
 Chapter 5
 , 
 Crowd Control
 , demonstrates using specialized crowd plugins how to 
 generate groups of AI characters.
 Chapter 6
 , 
 Sensors and Activities
 , shows how to set up sensors and have AI characters 
 change their activity based on what they sense in the environment.
 Chapter 7
 , 
 Adaptation
 , shows how to have AI characters react and adapt to different 
 events in the game.",NA
What you need for this book,"This book uses Unity 4 with a standard license. Additionally, it uses RAIN, a 
 Unity AI plugin that is available for free from 
 http://rivaltheory.com/rain/
 . 
 Additional plugins are used such as React AI and AI plugins for crowds and  
 driving that can be purchased from the Asset Store, for which details are provided  
 in the appropriate chapters.",NA
Who this book is for,"This book is aimed at developers who know the basics of game development with 
 Unity and want to learn how to add AI to their games. You do not need any previous 
 AI knowledge; this book will explain all the essential AI concepts and show you how 
 to add and use them in your games.",NA
Conventions,"In this book, you will find a number of styles of text that distinguish between 
 different kinds of information. Here are some examples of these styles, and an 
 explanation of their meaning.
 Code words in text, database table names, folder names, filenames, file extensions, 
 pathnames, dummy URLs, user input, and Twitter handles are shown as follows: ""We 
 find all the 
 NavigationTargetRig
  objects and store them in the 
 coverPoints
  array.""
 A block of code is set as follows:
 public override void Start(AI ai)
 {",NA
Reader feedback,"Feedback from our readers is always welcome. Let us know what you think about 
 this book—what you liked or disliked. Reader feedback is important for us as it helps 
 us develop titles that you will really get the most out of.
 To send us general feedback, simply e-mail 
 feedback@packtpub.com
 , and mention 
 the book's title in the subject of your message.
 If there is a topic that you have expertise in and you are interested in either writing 
 or contributing to a book, see our author guide at 
 www.packtpub.com/authors
 .",NA
Customer support,"Now that you are the proud owner of a Packt book, we have a number of things to 
 help you to get the most from your purchase.",NA
Downloading the example code,"You can download the example code files from your account at 
 http://www.
 packtpub.com
  for all the Packt Publishing books you have purchased. If you 
 purchased this book elsewhere, you can visit 
 http://www.packtpub.com/support
  
 and register to have the files e-mailed directly to you.",NA
Downloading the color images of this book,"We also provide you with a PDF file that has color images of the screenshots/
 diagrams used in this book. The color images will help you better understand the 
 changes in the output. You can download this file from: 
 https://www.packtpub.
 com/sites/default/files/downloads/3556OT_ColoredImages.pdf
 .",NA
Errata,"Although we have taken every care to ensure the accuracy of our content, mistakes 
 do happen. If you find a mistake in one of our books—maybe a mistake in the text or 
 the code—we would be grateful if you could report this to us. By doing so, you can 
 save other readers from frustration and help us improve subsequent versions of this 
 book. If you find any errata, please report them by visiting 
 http://www.packtpub.
 com/submit-errata
 , selecting your book, clicking on the 
 Errata
  
 Submission
  
 Form
  
 link, and entering the details of your errata. Once your errata are verified, your 
 submission will be accepted and the errata will be uploaded to our website or added 
 to any list of existing errata under the Errata section of that title.
 To view the previously submitted errata, go to 
 https://www.packtpub.com/books/
 content/support
  and enter the name of the book in the search field. The required 
 information will appear under the 
 Errata
  section.",NA
Piracy,"Piracy of copyrighted material on the Internet is an ongoing problem across all 
 media. At Packt, we take the protection of our copyright and licenses very seriously. 
 If you come across any illegal copies of our works in any form on the Internet, please 
 provide us with the location address or website name immediately so that we can 
 pursue a remedy.
 Please contact us at 
 copyright@packtpub.com
  with a link to the suspected  
 pirated material.
 We appreciate your help in protecting our authors and our ability to bring you 
 valuable content.",NA
Questions,"If you have a problem with any aspect of this book, you can contact us at 
 questions@packtpub.com
 , and we will do our best to address the problem.",NA
Pathfinding,"Probably the most useful game AI is pathfinding. Pathfinding is all about making 
 your way from one point to another while navigating around obstacles. Unity excels 
 at linking the worlds of designers and programmers. AI is no different, and we'll see 
 how to make simple pathfinding AIs without ever touching the code. Pathfinding is 
 probably the most common AI game task, and there are many Unity plugins for it. 
 We will be looking at three different ones.
 In this chapter, you will learn:
 • 
 Working with pathfinding
 • 
 Applying pathfinding in Quick Path, React, and RAIN AI packages
 • 
 Behavior trees
 • 
 Applying characters to Character Controller
 • 
 Unity's NavMesh",NA
An overview,"Pathfinding is a way to get an object from point A to point B. Assuming that there 
 are no obstacles, the object can just be moved in the direction of the target. But the  
 AI part of it is all about navigating the obstacles.
 A poor AI might try walking a 
 Non-Player Character
  (
 NPC
 ) directly to the target. 
 Then, if it is blocked, it randomly tries to go to the right or left to look for a space  
 that might help. The character can get caught in different areas and become 
 permanently stuck.
 www.itbookshub.com",NA
Quick Path AI,"Alekhine Games' Quick Path is a $10 AI that you can pick up from the Unity Asset 
 Store. Although the next two AIs have more features, this AI is added because of  
 its blocky nature. This block approach creates a grid-based path and is used with 
 many types of games, but this AI works especially well with the excitement in the 
 voxel game genre; it is suited for cubed topography.
 To start with, perform the following steps:
 1. Create a new 3D scene and import the Quick Path AI from the Asset Store.
 2. Next, set up some cubes, planes, or other objects as your terrain, and then 
 place all of these game objects into an empty game object. Name this game 
 object 
 Terrain
 .
 3. Next, on the 
 Inspector
  panel, add a component, 
 QuickPath
  | 
 Grid
 . 
 Immediately, you should see a series of blue lines that show up on the  
 cubes. These indicate all the points where a character can move in the AI.",NA
React AI,"Different Methods' React, a $45 AI, introduces a behavior tree and the use of a 
 navigation mesh, or NavMesh. A 
 NavMesh
  is a series of interconnected polygons 
 forming a complex area used for travel. It creates a simplified graph of the level 
 that is inputted into the pathfinding system. This simplified graph that it creates is 
 smoother and tends to have characters that travel better than a grid-based graph.  
 A behavior tree is a parent-child structure used for making decisions in many AIs. 
 We will look at behavior trees and navigation meshes in more detail in the later 
 chapters. NavMesh is a basic feature available in Unity, but the behavior tree is  
 not. Unlike the other two AIs shown, this AI requires a bit more coding to get 
 started, but not much.",NA
RAIN AI,"Rival Theory's RAIN AI
  is a very full-featured AI to use and it is free. It includes  
 a behavior tree with similar functionality to React, but has more features built in.  
 In fact, this one won't require any additional scripting to go from point A to point B.
 To get this going, we'll need the following bases:
 • 
 A map to move around on
 • 
 A character to move around in the map
 • 
 A route (series of waypoints) for the character to follow
 • 
 A navigation mesh that knows what to avoid
 • 
 An AI to control the character
 • 
 A behavior tree to tell the AI what to do
 To start with, you'll need to start a new Unity project, import Unity's Character 
 Controller, and import the RAIN AI package.
 Don't get the RAIN AI package that is found in the Asset store. The 
 current release (at the time of writing this book) can be found at the 
 Rival Theory site, 
 rivaltheory.com/rain/
 .
 Perform the following steps:
 1. To create our map, add a plane. Then, add a couple of objects to act as 
 obstacles. It is best if they create a 
 U
  or 
 V
  shape to potentially trap the player:",NA
Comparing AI solutions,"Each AI has its own strengths and weaknesses, ranging from price to flexibility 
 to designer friendliness. Also, each AI has more than one way to accomplish this 
 chapter's task of moving a character from point A to point B. We selected paths  
 that were faster and easier to start with, but keep in mind that each of them has 
 plenty of flexibility. All three proved to work well as terrain/trees as well as  
 simple planes and cubes.",NA
Summary,"Our AI characters need to be able to move between different points in our scene in  
 an intelligent way, and we looked at pathfinding AI systems that helped us do that. 
 We tried three different ones: Quick Path, React, and RAIN. But our characters need 
 to be able to do more than just walk from one point to a second one in our levels.  
 In the next chapter, we will extend what we have learned about pathfinding here  
 by seeing how to set up patrolling behaviors for our characters. This will be the  
 start for having characters walk around a level in a realistic way.",NA
Patrolling,"Patrolling is a simple extension to pathfinding. Instead of just having a single target 
 in mind, we might have two or more points. We might go back and forth between 
 them, or travel in a never-ending loop.
 In this chapter, you will learn about:
 • 
 How patrolling works
 • 
 Patrolling in Quick Path, React, and RAIN AI packages
 • 
 Getting to know more about behavior trees
 • 
 Creating patrols that go to different points in a level by not always  
 following the same path
 Patrolling is a way to get an object from point A to point B and then to point C,  
 and so on. Pathfinding is still required to get from one waypoint to another,  
 but here, we daisy-chain them into a larger, more meaningful path.",NA
Quick Path AI,"Quick Path is back again, with built-in capabilities to handle patrol. With its  
 simple approach to AI, only a few straightforward steps are needed to get a  
 scene finished. Here is a breakdown of these steps:
 • 
 Making the world ready for patrol
 • 
 Setting up the patrol script",NA
React AI,"React AI doesn't come equipped with a patrol script, so we provided one. We'll start 
 with this behavior tree script and look at how it works and how to use it. Here are 
 the steps to reproduce it:
 1. Create a patrol script.
 2. Create a patrol AI.
 3. Set up the NPC patrol.
 To start with, we've provided a script for you to use. In it, I started with the last script 
 for pathfinding, and then I extended it to use a similar configuration to the patrol path 
 in Quick Path's patrol script. Here are a couple of key points about this script:
 • 
 It is based on the 
 FollowThePlayer
  script from the previous chapter.
 • 
 You can find the code in the book's contents at 
 \Scripts\React AI\Patrol.
 cs
 .",NA
RAIN AI,"RAIN has this section put together pretty well. In reality, we only have one small 
 section to change from the pathfinding demo, especially because the pathfinding 
 demo had actually turned off the patrol feature.
 Start with the project for RAIN AI from 
 Chapter 1
 , 
 Pathfinding
 . From the menu, 
 navigate to 
 RAIN
  | 
 Behavior Tree Editor
 . From the editor, select 
 FollowGreenRoad
 . 
 Under 
 Sequence
  is a patrol route node called 
 waypointpatrol
 ; select it. Finally,  
 we have a property called 
 Loop Type
 . Presently, it is on 
 One
  
 Way
 , which stops  
 at the last waypoint. You can switch it to 
 Ping
  
 Pong
  or 
 Loop
 , as shown in the 
 following screenshot:
 Ping Pong
  bounces you back and forth on the path, while 
 Loop
  connects the last 
 waypoint to the first to start over.
 This works when creating a typical patrolling behavior, where a character loops 
 along a path. However, what if we want to have a character patrol an area by 
 walking around back and forth to different points without always following the 
 same route? In RAIN AI, we can do this by using a waypoint network instead of  
 a waypoint graph and updating our behavior tree to randomly pick different points 
 in the level to go to.",NA
Summary,"We were able to get patrolling operational in all three AIs. Each AI had its  
 own approach.
 For patrol as well as pathfinding, Quick Path had very few steps. If your need is  
 mostly pathfinding, it does exactly what it claims to do easily. As for React, it does  
 not have patrol out of the box, as we saw in the last chapter. However, it was not 
 difficult to create a script that operates inside its behavior tree AI editor. This is a 
 powerful system that you can use to allow designers to easily access and apply your 
 awesome scripts, but you have to be comfortable programming to build the pieces 
 for it. For RAIN, which made this about as easy as a big red button. With one setting 
 changed, we changed the pathfinding AI into a patrolling AI. RAIN comes equipped 
 with a huge variety of prebuilt character controlling; we looked at how to use a 
 different waypoint system, a waypoint network, to give variety to our character  
 when patrolling.
 This concludes our chapters on setting up basic character pathfinding and 
 movement. In later chapters, we will look in more detail at different aspects of  
 this, such as animation and creating navigation meshes. In the next chapter, we  
 will look at customizing our characters by investigating behavior trees in more 
 detail. We will also learn to create more advanced setups using behavior trees.",NA
Behavior Trees ,"When creating AI for game characters, we want them to appear to behave in realistic 
 ways. This is done by defining different behaviors that a character can do, such 
 as walking, patrolling, attacking, or searching for something, as well as how the 
 character reacts to different items or events in the game environment. In addition 
 to defining a character's behaviors, we need to define when the different behaviors 
 occur. For example, instead of just following a path, we might want the character to 
 change behaviors at different times. This chapter will look at the most popular way 
 to define behaviors and when they occur: behavior trees. We have already looked at 
 behavior trees in the previous chapters, but here, we will go into more detail.
 In this chapter, we will learn about:
 • 
 How behavior trees work
 • 
 Implementing complex behavior trees
 • 
 RAIN's behavior trees and the different options that we have to  
 configure them
 • 
 Setting up more advanced behavior trees with a character that has  
 multiple objectives",NA
An overview of behavior trees,"For game AI, we need to define logic for the different AI entity characters in the game, 
 that is, how they will act and react to different things in the game environment. The 
 traditional and simpler way to do this is to use 
 Finite State Machines
  (
 FSMs
 ). In this 
 approach, each character can be in a distinct state, and an FSM is a graph that defines 
 states (nodes) and their transitions (edges). A simple example would be an enemy 
 entity with two states, patrol and attack. The FSM will start in a patrol state, and when 
 it gets close to a player, it transitions to an attack state. FSMs work for very simple 
 state setups such as this, but they don't scale well, as the states and transitions have to 
 be manually configured, usually through code. What if instead of the two states, our 
 enemy character was more realistic and had 10 or even 100 different states, with many 
 transitions between each? This becomes very difficult to manage and implement.
 The popular alternative to FSMs is behavior trees. Behavior trees are a different  
 way to define logic for characters that scale easily to having many states. Instead  
 of defining states and transitions, behavior trees focus on defining behaviors, also 
 called tasks, for characters. Each behavior is a node in the tree and can consist of 
 different sub-behaviors; so, instead of a general graph, a tree is created of different 
 behaviors, where each behavior is a node on the graph.
 At every update for the character, the behavior tree is traversed, starting at the 
 root node and searching down the tree. The different behavior nodes execute and 
 return if the task is running, or has completed successfully or failed. If the node is 
 in a running state, it is updated. Behavior trees are built by creating and configuring 
 different behavior nodes.
 We will focus on RAIN's behavior tree system in this chapter. We can use a different 
 behavior tree system or create one from scratch; the basic logic is the same for all 
 implementations. When using a behavior tree system, the most important thing to 
 know are the different node types that we can use; so, let's look at RAIN's different 
 behavior nodes.",NA
RAIN node types,"For the RAIN implementation of behavior trees, the behavior nodes are split into two 
 categories: decisions and actions. Actions tell the AI system to actually do something; 
 it is where the actual 
 work
  of the AI is done. The most common action is the one we 
 saw in the previous chapters, 
 move
 , which tells the AI system to move a character. 
 Besides move, here is a list of the current actions RAIN supports:
 • 
 The Choose patrol path and Choose path waypoints
 : These nodes help to 
 move the AI through a network of waypoints.",NA
The behavior tree demo,"Now that we know about the different nodes we can use, we'll create a demo that 
 shows how to use the action and decision nodes. The demo will show how to have 
 a character perform multiple tasks. We will have an entity, an enemy spaceship, 
 patrolling an area, but only for a given amount of time; then, the ship will return  
 to its home base. The steps for this example might seem overly complicated and 
 we could do a similar AI ourselves without behavior trees with a simple script by 
 hardcoding the different states. However, remember that behavior trees are easily 
 extendible and scalable. With this demo, instead of two behaviors, we could take 
 time to create a more complex character, going up to about 30 behaviors easily, but 
 extending a script to do that would be pretty complicated and hard to maintain.
 The start of this is similar to the pathfinding and patrol RAIN demos, except we will 
 use a spaceship model instead of a walking character. You'll need to create a simple 
 scene with a ship model (the examples have a 
 ship.blend
  model you can use) and 
 an object for the home base. The initial setup should look something like this:",NA
Summary,"In this chapter, we went through the most popular way to set up behaviors  
 for game entities and behavior trees. We went through the process of defining 
 behaviors, deciding the different actions the behaviors will perform and the 
 transitions between the actions. Then, we set up a character and run the game.  
 This is the process to create logic for your game characters, deciding what the 
 behaviors are and the different conditions that can cause them to become active.
 In the next chapter, we will look at how to use behavior trees more with character 
 movement and see how to set up the wander behavior for crowd creation. We will 
 explore AIs that will control a large collection of NPCs moving in distinctly separate 
 low-repeating paths.",NA
Crowd Chaos,"Part of having a realistic game environment is having the nonplayer characters and 
 NPCs act in a believable way. Crowd chaos is all about keeping NPCs busy to create 
 crowded backgrounds for our games. Perhaps your game is set up in a mall, or a city, 
 or any other place where lots of NPCs need to wander around and look like they are 
 doing something. Crowds like these will be the subject of this chapter and the next.
 In this chapter, you will learn about:
 • 
 Working with crowd chaos
 • 
 How to create crowd type characters in the React and RAIN AI packages
 • 
 Expanding our knowledge of behavior trees",NA
An overview of crowd chaos,"Crowd Chaos is all about giving separate interests to a large number of NPCs, so  
 they look like they are living their own lives. In its lightest form, this can be something 
 very simple, such as a whole bunch of NPCs picking random targets, walking to 
 them, possibly sitting still for a moment, and then starting over. This stands out in 
 real-time strategy games when buildings are constructed, and you see a construction 
 worker walking to random points of the structure and waving their arms about.
 Every game that needs crowd chaos will typically have a basic wandering base, and 
 it can be extended as needed. Perhaps the crowd will form lines of more NPCs that 
 are waiting at a spot. Perhaps the targets have changing values and AIs prefer higher 
 values. They pick up a random block and put it somewhere else. The base wandering 
 behavior needed for these and other crowd behaviors is what we will implement in 
 both React and RAIN AI.
 www.itbookshub.com",NA
React AI,"For this demo, we will duplicate the path-following behavior demo in React from 
 Chapter 1
 , 
 Pathfinding
 , and then update it to see some emergent behavior develop 
 from it. We will need to complete the following:
 • 
 Create a world with some walls
 • 
 Create target markers in the scene
 • 
 Create a script with a custom editor to find the targets
 • 
 Create the behavior
 • 
 Create NPCs and assign the behavior",NA
Setting up a scene with React,"To start out with, we will need a basic environment for characters to walk in. Create 
 a plane, call it 
 Floor
 , and add some cubes, shaping them into walls. These will need 
 to be static so that Unity's navigation mesh can find them. Then, we'll need to select 
 the floor and add the navigation mesh. If you've forgotten how to do any of this, it  
 is all covered in the React tutorial in 
 Chapter 1
 , 
 Pathfinding
 .
 Next, we need some targets. We'll use a different approach for this from our previous 
 demos and let GameObjects mark the targets. Create an empty GameObject and 
 call it 
 Targets
 . Underneath it, add more empty GameObjects. Give them all a tag, 
 NpcActivityTarget
 , which you might need to create. Distribute these targets to 
 different locations on the screen like this:
 The preceding screenshot shows how our basic React scene setup with targets should 
 look like.",NA
Building behavior trees in React,"Now that we have our behavior methods, we can build the behavior tree. Right-click 
 on your project's 
 Assets
  folder and navigate to 
 Create
  | 
 Reactable
 . Rename it to 
 LookBusyReactable
 . Then, right-click on it and select 
 Edit Reactable
 :
 The preceding is a screenshot of the behavior tree editor completed. Right-click on 
 Root
  and navigate to 
 Add
  | 
 Branch
  | 
 Sequence
 . This is so it completes each step 
 before moving on to the next. Right-click on 
 Sequence
  and navigate to 
 Add
  | 
 Leaf
  | 
 Action
 . Do this three times:
 1. For the first one, click on the empty checkbox and navigate to 
 Scripts
  | 
 LookBusy
  | 
 FindTarget
 . This is part of the 
 LookBusy.cs
  script that we 
 added earlier.
 2. For the second one, do the same but instead navigate to 
 Scripts
  | 
 LookBusy
  
 | 
 MoveToTarget
 .
 3. For the third one, navigate to 
 Scripts
  | 
 LookBusy
  | 
 HangAround
 .
 The AI will find a random target from the list of GameObjects with the correct tag, 
 NpcActivityTarget
 , as we set in the 
 LookBusy
  script. Then, it moves to that target 
 and hangs around for 2 to 4 seconds.",NA
Setting up wandering characters with React,"Finally, we will create the NPCs and assign a behavior. For this, you can use a 
 character similar to the first, just a sphere stretch 2x tall, with a small cube on the 
 front of it so that we can see the direction it is facing. Add the 
 LookBusy
  script to  
 the NPC:
 This is how the 
 LookBusy
  script options look like.
 Minimum Distance
  is how far away you can be from the target and still be  
 satisfied that you reached it. 
 Short Wait Time
  and 
 Long Wait Time
  are time  
 ranges (in seconds) you hang around for, and 
 NpcActivityTarget
  is the tag that  
 the GameObjects have to identify as targets.
 Next, add 
 Nav Mesh Agent
  to the NPC so that it can navigate around the 
 level. Finally, add the 
 Reactor
  script and set its 
 Reactable
  property to 
 LookBusyReactable
 , which is the behavior tree we created earlier.
 This completes all the steps needed to have NPC characters wander around in  
 a game using React. You should now be able to create as many characters as you  
 like and have them walk around a level.",NA
RAIN AI,"We have already looked at a basic wander behavior for RAIN in 
 Chapter 2
 , 
 Patrolling
 , 
 when creating patrolling AI, but there, we manually created each possible location 
 for the NPC to go to. In this demo, we will pick random points to wander to from 
 anywhere in the navigation mesh. The NPCs won't have any interaction, though 
 such features are not difficult to add. Here is a breakdown of the steps we will do  
 in this section:
 • 
 Set up a world
 • 
 Build the behavior tree
 • 
 Add a script to pick new points
 • 
 Add the NPCs
 • 
 Learn about the RAIN AI world and behavior tree setup",NA
RAIN AI custom wander scripts,"To start creating our needed wander scripts, first select the 
 Select Next Target
   
 action in the behavior tree. Under the 
 Class
  property, set it to 
 Create Custom  
 Action
 , which pops up a box to define the script. The following screenshot  
 shows what a RAIN custom action creation dialog looks like:",NA
Putting NPCs in the RAIN demo,"Start by adding another simple NPC character to the game, like we did in the first 
 chapter. We don't need to add any scripts directly to it. Instead, make sure that the 
 NPC is selected in the hierarchy, and from the RAIN menu, select 
 Create AI
 .
 In the AI GameObject/component that was added, from the 
 Mind
  tab, set the 
 Behavior Tree Asset
  value to 
 RandomWalk
 , which is found in 
 Assets
 . Under the 
 animation tab, click on the 
 Add Existing Animations
  button.
 Now, try the game. A single NPC should be walking around the screen, pausing,  
 and then walking to another location at random. To create a larger crowd, just 
 duplicate the NPC GameObject in the scene at several locations.",NA
Summary,"We were able to use scripting and behavior trees in both React AI and RAIN to 
 effectively create a wandering AI. Each AI had strengths and weaknesses, though  
 the weaknesses were more of a preference.
 Behavior tree editors were used in both RAIN and React, and both work in a  
 similar fashion. In RAIN, you can start editing a tree from the menu, or from the 
 editor itself. (It had the option to select the behavior directly in the editor.) With 
 React, you can do this from the 
 Project
  tab, by right-clicking and choosing to edit  
 it. React had premade scripts that can do nearly all the actions that were needed, 
 except that instead of selecting randomly from a list of targets with the tag, it  
 would select a target expecting only one object with that tag. With RAIN, we  
 made a custom action node to choose a location to go to.
 Both React and RAIN AI are general AI systems that are useful for many different 
 types of game situations, so neither were designed specifically to handle crowds. In 
 the next chapter, we will look at different tools with more focus on creating crowd AI.",NA
Crowd Control,"In this chapter, you will learn how to build large crowds into your game. Instead  
 of having the crowd members wander freely, like we did in the previous chapter,  
 we will control the crowds better by giving them directions on what to do. This 
 material will be useful for a wide range of game use cases, such as planning  
 soldier attacks by groups or directing flows of traffic in a car game.
 In this chapter, you will learn about:
 • 
 Crowd-steering behaviors
 • 
 Using the Fame Crowd Simulation API to manage crowds
 • 
 Exploring ANT-Op to create more goal-directed crowds",NA
An overview of crowd control,"In 
  Chapter 4
 , 
 Crowd Chaos
 , we looked at creating crowds using wandering  
 behaviors, where different crowd members worked individually to travel to  
 different points. This works well for ambient crowds, but there was no working  
 as a group. As there was no larger group-defined behavior or director managing 
 crowds, our previous implementations required creating and configuring character 
 AIs individually. Defining and configuring individual AIs is fine for smaller groups, 
 but not practical when creating much larger crowds. In the demos in this chapter,  
 we will look at crowds that work, or at least move, as a group. Moving AI characters 
 in groups, also called flocks, has been a popular subject in AI for many years. The 
 most popular system is called 
 Boids
 , and it was designed in the 1980s by Craig 
 Reynolds, a renowned computer graphics and AI developer, and the basic design  
 is used in crowd AIs in most games today. In these systems, different simple steering 
 behaviors are defined, such as moving to a target position or following a path, as 
 well as behaviors to not collide with other agents or align to the same direction  
 of nearby agents.
 www.itbookshub.com",NA
The Fame Crowd Simulation API,"The Fame Crowd Simulation API by TechBizXccelerator is available at Unity Asset 
 Store under the name Crowd Simulator API for $45 at the time of writing this book. 
 It allows you to create groups and customize steering behaviors. For our crowd 
 demo, we will create a demo with many spaceships traveling in a group.",NA
Setting up a scene with Fame,"To create our demo, first create a new scene with a plane as the ground. Like most  
 of the AI plugins in this book, Fame Crowd Simulation also supports Unity's built-in 
 terrain system, but for this demo, a basic ground plane will be fine. Fame also uses a 
 singleton pattern that has one class that manages everything for crowd management, 
 so create an empty GameObject and call it 
 Crowd Manager
 . Then, import Fame if it 
 is not already in your project, and attach the 
 FameManager
  script from 
 Fame Assets/
 FameScripts/FameManager.cs
  to the 
 Crowd Manager
  GameObject. This initial 
 setup is shown in the following screenshot:
 The following should be the hierarchy:",NA
Setting up a group,"Next, we need to create the initial formation we want our group to be in. With the 
 Ships
  GameObject selected, you will see three connected gizmos in the Unity 3D 
 view that represent the shape of the initial group. Go to 
 Formation Shape
  in the 
 Inspector
  panel for 
 Ships
  and click on 
 Add Point
 . This creates a fourth point for  
 the shape of the group. Arrange the points into a pyramid-like shape and click  
 on 
 Create Avatars
 . A set of ships in a group will be created:",NA
Adding obstacles to Fame,"Next, let's add an obstacle inbetween the ships and their target. Increase the size of 
 the ground plane by increasing its 
 X
  scale. Then, add a cylinder to the middle of the 
 scene to be an obstacle for the ships. To have this obstacle recognized by Fame, add 
 the Fame obstacle script, 
 FameObstacle.cs
 , to it. Fame allows two types of obstacles: 
 round (circles) and 2D polygons. You specify the polygon ones, the same as we did 
 for group shapes, by modifying control points. For our obstacle, we just need it to 
 match the radius of the cylinder. In this example, the cylinder has a scale of 
 50
 ,  
 which makes its radius 25, so set the obstacle's 
 radius
  to 
 25
 .",NA
Adding vector fields to Fame,"We just saw how to add obstacles to our Fame crowd scene. Right now, all of our 
 ships split when avoiding the cylinder, about half to the left and the other half to the 
 right. However, we want all of them to move to the left. To do this, we can vector 
 fields to the scene. Vector fields are a popular way of adding directional 
 hints
  to a 
 scene, and they are defined areas that have directional vectors that are associated with 
 them. When a character is inside the field, the vector helps move the character in the 
 desired direction. Vector fields can be a powerful tool for level design and are easy to 
 add to your scene. To see how easy it is to add them to the scene, add a new empty 
 GameObject to the scene and name it 
 Field
 . Then, attach the 
 FameField.cs
  script 
 from 
 Assets/Fame Assets/FameScripts
  to it. The field can be rectangular, called 
 Uniform
  or 
 Circular
 . Select 
 Uniform
  for the type and set 
 x
  and 
 z widths
  to 
 75
 . Then, 
 set the angle to 
 45
  and the magnitude to 
 100
 . The white arrow visualizes the angle for 
 the vector field. Place the field over the initial positions for the ships, as shown:
 If you run the demo now, ships will all veer to the left before avoiding the cylinder. 
 For larger levels, you can set up multiple vector fields; they are a good way to  
 control the general movement of AI characters.",NA
ANT-Op,"Sometimes for your games, you might want to create crowd AIs that act in a very 
 unique way, and instead of using an existing AI plugin, you might want to create 
 a crowd AI from scratch. This would be done in the case of an ANT-Op AI. As we 
 mentioned before, ant behavior is a popular topic in AI research and computer 
 science in general. Initially, ants work independently and give off pheromones that 
 are sensed by other ants to communicate messages. For example, when ants start 
 searching for food, they give off pheromones as they search. When they find food, 
 they give off different pheromones as they bring it back to the colony, which directs 
 the next ants when searching for food. ANT-Op, by Gray Lake Studios, is available 
 on Unity Asset Store for $75, and it simulates this ant food search process. Unlike 
 the other AI plugins in this book, Ant-Op isn't really designed to be brought into an 
 existing game; it's more of a technical demonstration that is a simulation you can use 
 to see interesting AI at work and hopefully use it to inspire complex AI designs for 
 your games. To start the demo, import ANT-Op and double-click on 
 Test Scene
  to 
 open it. The scene will initially be blank, but if you start the demo, you can see the 
 simulation start. In the following screenshot, you can see ANT-Op in action:",NA
Summary,"This concludes the last of two chapters on crowd AI. Where the previous chapter 
 focused on defining crowds by defining wander behaviors for different characters 
 individually, in this chapter we focused on defining groups as a whole. We discussed 
 steering-based group design and looked at the Fame Crowd Simulation API that you 
 can use to set up crowds easily, give them direction, and have them adjust steering 
 based on other factors in the environment, obstacles, and vector fields. We then 
 discussed defining your own crowd AI for more unique systems and looked at  
 ANT-Op as an example of this. This should give you all the info you need to  
 create all kinds of crowds for your games.
 In the next few chapters, we will turn the focus to having AI characters interact  
 with their environment. In 
 Chapter 6
 , 
 Sensors and Activities
 , we will look  
 at having our characters sense things in the environment and react to them.",NA
Sensors and Activities,"In the previous chapters on pathfinding and behavior trees, we had AI characters 
 moving through our AI environments and changing states, but they didn't really 
 react to anything. They knew about the navigation mesh and different points in  
 the scene, but there was no way for them to sense different objects in the game and 
 react to them. This chapter changes that; we will look at how to tag objects in the 
 game so that our characters can sense and react to them.
 In this chapter, you will learn about:
 • 
 Sensors and tagging game objects so that they can be sensed
 • 
 AI characters that use sensors in RAIN
 • 
 Advanced configuration of sensors in RAIN
 • 
 Having AI characters react to different objects and perform different 
 activities once they are sensed",NA
An overview of sensing,"A part of having good game AI is having the AI characters react to other parts  
 of the game in a realistic way. For example, let's say you have an AI character in  
 a scene searching for something, such as the player to attack them or items to  
 collect (as in the demo in this chapter). We could have a simple proximity check,  
 for example, if the enemy is 10 units from the player, it starts attacking. However, 
 what if the enemy wasn't looking in the direction of the player and wouldn't be able 
 to see or hear the player in real life? Having the enemy attack then is very unrealistic. 
 We need to be able to set up more realistic and configurable sensors for our AI.",NA
Advanced visual sensor settings,"We've heard stories of people setting up their sensors—especially visual ones—and 
 starting the game, but nothing happens or it seems to work incorrectly. Configuring 
 the senses' advanced settings can help avoid issues such as these and make 
 development easier.
 To see visual sensor settings, add a RAIN AI to a game object and click on the  
 eye icon, select 
 Visual Sensor
  from the 
 Add Sensor
  dropdown, and then click  
 on the gear icon in the upper-right corner and select 
 Show Advanced Settings
 .  
 The following screenshot shows the 
 Visual Sensor
  section in RAIN:",NA
Advanced audio sensor settings,"The properties for the audio sensor is similar to that of the visual sensor, except it 
 doesn't have any line of sight properties and the volume of the sense is a radius  
 and doesn't have vertical or horizontal angle limits. The important properties are:
 • 
 Range
 : This specifies how far the sensor can detect",NA
Using senses with RAIN,"For this demo, we will use RAIN 2.14 and have a ship that patrols a path, looks for 
 pieces of gold, and picks them up. To start, we'll use a setup similar to that of the 
 demo in 
 Chapter 3
 , 
 Behavior Trees
 . You can start from there or recreate it; we just  
 need a ship, a wall, a path, with the ground being a little larger, and the objects 
 spread out a little.
 When changing the base geometry of your game levels, you need to 
 regenerate the navigation mesh. This is done by selecting the 
 Navigation 
 Mesh
  object in your scene and clicking on the 
 Generate NavMesh
  button.
 Here is our basic setup. The following image shows the starting point of our  
 sensor demo:",NA
Setting up aspects in RAIN,"For our sensor demo, we will have the ship look for gold, which will be represented 
 by a simple game object. Create a 
 Sphere
  object in Unity by navigating to 
 Game 
 Object
  | 
 Create Other
  | 
 Sphere
 . Make it a little smaller by giving it 
 Scale
  of 
 0.25
   
 for 
 X
 , 
 Y
 , and 
 Z
 , and change the material to a golden color. We'll be duplicating  
 the object later so if you want duplicating to be easier, make it a prefab. This is  
 our starting point, as illustrated in the following screenshot:
 The starting point of our object (Sphere)",NA
Setting up a visual sensor in RAIN,"We have the gold aspect; next we need a visual sensor. Select 
 Ship AI
 , click on the 
 eye icon for the sensors tab, and from the 
 Add Sensor
  dropdown, select 
 Visual 
 Sensor
 . Go to the 
 Advanced Settings
  (selecting the gear icon) icon and adjust the 
 horizontal and vertical angles as well as the range until the sensor can see a bit in 
 front of the ship. Typically, you will make these very large so that the character can 
 see most of the level. For this demo, the sensor values are 
 120
  for 
 Horizontal Angle
 , 
 45
  for 
 Vertical Angle
 , and 
 15
  for 
 Range
 . Also, check the 
 Require Line of Sight
  
 option so that the ship can't see gold through the wall. The setup should look like  
 the following screenshot:",NA
Changing activities based on sensing,"We now have the ship sensing the gold as it passes by, but it still doesn't react to it. 
 To do this, we will update the behavior tree for the ship.
 The first thing we want is a detect node as the ship is moving so it can know if  
 it sees 
 Gold
 . Open the behavior tree for the ship and create a detect node. As the  
 detect node will be running continuously, change its 
 Repeat
  type to 
 Forever
  and 
 right-click on the root node and change its type to 
 Parallel
 . For the detection part  
 of the detect node to work, set the 
 Aspect
  field to 
 ""Gold""
  and set the sensor it will  
 be using to 
 ""Visual Sensor
 "". Finally, we need to set the form of the aspect, the game 
 object attached. Set 
 Form Variable
  to 
 gold
 .
 The whole quotes thing in RAIN can be confusing: why some fields need 
 quotes and others don't. This is planned to be improved in future versions 
 of RAIN, but for now for Expressions (fields with the little e symbol) a 
 value with quotes means the name of an object and without means the 
 value of a variable. So in our case, 
 ""Visual Sensor""
  and 
 ""Gold""
  were both 
 in quotes as they were referring to objects by name, but 
 gold
  is an actual 
 variable we store data in, so it doesn't have quotes.",NA
RAIN sensor filters,"If you tried running the demo with multiple gold pieces, you must have seen a small 
 problem. The ship always goes to the first piece of gold it sees, but that might not 
 be the closest. If it sees a distant piece from the corner of its eye, it will go straight to 
 it even if there are ones closer to it. A quick fix for this is to add a filter to the RAIN 
 sensors. Filters are ways to manipulate the list of sensed objects, and RAIN might 
 have more in the future but for now, it just has one: 
 NearestXFilter
 . Select 
 Visual 
 Sensor
  in the ship and set the 
 Size
  field to 
 1
  and select 
 NearestXFilter
  under the 
 Filters
  section. The following screenshot will show the settings of 
 NearestXFilter
   
 on the sensor:",NA
Summary,"In this chapter, we looked at how to set up sensors for our AI characters so that they 
 can see the environment. We also saw how to tag objects with aspects so that they 
 are visible to our AI. We also saw how to change a character's activities based on 
 sensing, and we discussed different settings for sensors and how to tweak them. 
 Sensors and aspects can make your game's AI more realistic, but they need to be 
 carefully adjusted to give good results.
 In the next chapter, we will look at taking our work with navigation and mind 
 development to make our characters react more to their environments. Specifically, 
 we will see how all of the AI we have used so far can make our AI characters adapt 
 to different game events and create more complex AI.",NA
Adaptation,"Having good AI for our characters is more than just giving them simple tasks to 
 perform; we'd like to have our characters realistically react to the game environment. 
 Game events such as seeing new objects appear or having a bomb go off in a scene 
 should cause a reaction in the AI. Having the AI adapt to the environment is a huge 
 topic, but we will focus on the basic ways to have AI adapt to the environment. In 
 this chapter, we will look at taking AI skills we learned in previous chapters and 
 combining them to create AI characters that adapt to the game environment in a 
 realistic way, changing their tasks based on game events.
 In this chapter, you will be:
 • 
 Creating AI characters that react and adapt to multiple game events
 • 
 Setting up more complex AI characters in RAIN
 • 
 Getting to know the importance of creating larger AI scenes with REACT AI",NA
An overview,"In previous chapters, we looked at how to do different specific AI tasks. We learned 
 how to make characters patrol a path, have them wander an environment, change 
 state with behavior trees, and sense objects in the game environment. These are all 
 important, but it's more important to understand how we can combine these different 
 elements to make AI that works well in a large game environment. We will need 
 characters that can navigate an environment to perform tasks but then change based 
 on game events that occur. To do this, the game needs to be designed at a high level, 
 defining what the different AI character's main goals and actions are. These high-level 
 goals are things such as wanting an enemy to patrol an area until it sees the player and 
 then start to chase and attack him. From there, the different aspects of sensing need  
 to be designed for the level, deciding what objects need to be tagged, so they can be 
 used by the AI system. The characters then need sensors defined for the AI characters 
 and high-level goals can be created using existing nodes and custom actions.",NA
RAIN's demo,"The basic start of the demo will be similar to our others, a ground with several  
 walls around for our ships to travel. This is how the basic starting point of our  
 demo should look:
 The basic starting point of our demo
 One of the first things we will need is the ability to query a random location in the 
 scene to spawn and find points to travel to. Create a class called 
 Ground
  and add it  
 to the ground plane. This class will be used to provide higher-level information 
 about the level, the first of which is being able to find a random position in the  
 level. Here is the 
 Ground
  class with the random position chooser method:",NA
Reacting to game events,"Next, we want to have some ships chase gold pieces, but we'll make it more dynamic 
 than in the last demo. Create a 
 Sphere
  object with a gold color and add a 
 RAIN
  entity 
 to it (by navigating to 
 RAIN
  | 
 Create Entity
 ) and add a 
 Visual Aspect
  called 
 Gold
  to 
 it so that AI characters can sense it. Turn this gold piece into a prefab. Instead of just 
 placing it manually in the scene, we want them to be spawned randomly; add the  
 code mentioned in the following screenshot to the 
 Ground
  script:
 In the Unity editor, drag the 
 Gold
  prefab to the 
 Transform gold
  in this script. This 
 script randomly spawns a gold piece somewhere in the level every 2 seconds by 
 tracking the time using 
 Time.deltaTime
 . If you run the game now, you'll see a gold 
 piece created randomly every 2 seconds. Next, we need ships to collect these.",NA
Using RAIN's motor directly,"However, if you run the game now, you'll see a problem. As expected, the ship  
 will look for gold, and if it doesn't see any, it will pick a random position on the  
 level and move toward it. If it sees gold along the way, it doesn't stop to pick it  
 up; it keeps moving to its target location.",NA
Adding large game events,"As the last step of this demo, let's have a giant bomb go off in the scene and then have 
 all of our AI stop to simulate having them all destroyed. To start, create a large red 
 sphere to represent the bomb and turn it into a prefab. We will have the AI characters 
 react to this bomb in the standard way by adding a RAIN Entity component to it and  
 a visual aspect and have visual sensors on the ships detect it. But to show we can 
 access the AI systems directly, let's have the bomb go off using the 
 Ground
  class:
 Here, we added a bomb transform to the script, so drag the bomb prefab in the  
 Unity prefab over to it. There is also a field for a countdown that when it goes to 0, 
 the bomb goes off and is instantiated into the scene. At this point, we grab all the  
 AIs in the scene and send them a message, in this case, to disable it. We could have 
 made this more complex than a simple disabling; this just shows us that we can  
 have our game AI react to game events from anywhere. If you run the demo now,  
 the ships stop when the bomb goes off, as shown in the following screenshot:",NA
The React AI,"We have been using RAIN for our adaption so far, but there is no reason you cannot 
 create a demo like the one we just did with React. The basic behavior tree and node 
 logic can stay the same. The main difference is that React doesn't use a built-in sensor 
 system; instead, users define sensing based on what they think is the best. This can be 
 done through Unity's built-in ray casting methods to query the scene. The following 
 is a method adapted from React's sample that can be used with React to determine 
 the visibility of a target. This code takes in a target and first does a simple test to see 
 whether the target is within the field of view by finding the vector of the target from 
 the player and comparing the angle of it and the forward direction of the AI character.",NA
Summary,"In this chapter, we looked at how we can make our AI adapt to events in the game. 
 This was done using methods we learned in the previous chapters, and we also  
 took a look at RAIN's motor system to allow our adaptions to be more customizable. 
 Our demos in this chapter have been pretty straightforward, but there is no reason 
 why this demo couldn't be extended to have more events to send and more reactions 
 defined in the character behavior trees. However, our demos have been missing  
 one important thing, which is yet to be discussed: the player. In the next chapter,  
 we will discuss how AI characters attack by adding a player to our scene and  
 having our characters react and attack. We will discuss how to create enemies  
 for the player and have them attack the player.",NA
Attacking,"Fighting is an important part of a game's AI. For many games, fighting with  
 the player is the main game mechanic and the most noticeable AI in the game.  
 We will discuss the common methods for attack AI, how to make an enemy  
 character chase and attack the player, and then have the enemy character take  
 cover and hide from the player.
 In this chapter, you will learn about:
 • 
 Designing attack AI in RAIN 2.1.4
 • 
 Creating basic chase attack AI
 • 
 Creating and covering attack AI
 • 
 Having AI attack in groups",NA
An overview of attack AI,"Attack AI is a large and much studied subject. When you start dealing with things 
 such as different attack moves based on different player actions or having enemies 
 coordinate attacks, the AI can become quite complex. However, designing good AI 
 that attacks is the same as designing for other AI scenarios we have looked at so far 
 in this book. First, we need sensors for our AI characters to perceive game events  
 and to create aspects in the game world, tagging what they can sense. Then, we 
 define behavior trees for the characters, directing them to change actions based 
 on sensor response or other game states, such as running out of ammo. Defining 
 different behaviors is the main part of setting up attack AI.
 We'll look at two foundational AI attack behaviors in our demos in this chapter.  
 The first will use multiple sensors on the AI to determine when to chase and when 
 to stop and attack. The second behavior we will look at is the duck and cover type, 
 where the enemy attacker will retreat to a safe position after attacking, and this is 
 based on set navigation points. These are both best illustrated through demos,  
 so let's start one now.",NA
The attack demo,"Like our previous demos, we will start with a basic scene with a ground and walls. 
 The demos here will involve an enemy ship attacking a player, so add a ship to 
 the scene, name it 
 player
 , and add simple controls to move the ship around. Also, 
 tint the color of the material to make the player ship stand out from the enemy 
 ship that we'll add in a moment. Of course, the player ship isn't an AI, so it doesn't 
 need a RAIN AIRig, but it does need to have a RAIN Entity component. With the 
 player selected, go to 
 RAIN
  | 
 Create Entity
 . Next, it needs a visual aspect for the AI 
 enemies to see it; from the 
 Add Aspect
  dropdown, select 
 Visual Aspect
  and rename 
 the aspect to 
 player
 . This provides a base for our attack demo. This is how the RAIN 
 attack demos will look with a player ship:
 Next, we need an enemy for the attack. The enemies will also be ship models, and 
 as we are focusing on just the AI, we won't worry about the actual game mechanics 
 of attacking, such as having the ship fire projectiles at the player, then having the 
 player respond to being hit, and so on. Usually, these kind of attack AI states involve 
 playing different animations for the AI, and we will explore these more in 
 Chapter 10
 , 
 Animation and AI
 ; for now, we just need a simple visualization to illustrate the attack. 
 To visualize, we'll store a Boolean variable in RAIN's working memory flagging if 
 the enemy is attacking and if so, start blinking.
 To set this up, add a ship to the scene and add an AIRig to it by going to 
 RAIN
  
 | 
 Create AI
 . To add an attack flag, select the RAIN 
 Memory
  tab on the ship AI 
 (the light bulb icon) and from 
 Add Variable
 , select 
 bool
 . Rename the variable 
 to 
 isAttacking
  and leave it to the default value of false. The memory with the 
 isAttacking
  variable set should look like the following screenshot:",NA
The chase and attack demo,"In the first demo, we will build an enemy ship that senses for the player, and if it 
 sees the player, it starts moving toward it and then attacks it. A simple version of this 
 would be to have the enemy wander with a visual sensor to detect the player, and if 
 it sees the player, the enemy will move toward it and attack it. This would work but 
 it really wouldn't be any different from the demo from 
 Chapter 7
 , 
 Adaptation
 , where 
 the ship had to search for and collect gold. To make it a little different, we'll use a 
 two-sensor approach. We will have one larger sensor on the enemy that detects the 
 player, and if the enemy senses the player aspect, it will start chasing the player. 
 Then, there is a second smaller sensor that attacks the player, that is, if it senses the 
 player, then the enemy stops chasing and it instead attacks. This gives the effect 
 of chasing the player but when the enemy gets closer, it stops and starts attacking, 
 instead of just chasing and attacking at the same time.
 To begin setting these up, go to the 
 Perception
  tab on the enemy AI rig (the little 
 eye icon tab) and add a visual sensor called 
 ChaseSensor
 . This should be pretty 
 large and cover most of the scene. Then, add a second visual sensor and call it 
 AttackSensor
 . Make this one about a third the size of 
 ChaseSensor
 . The setup 
 should look something like the following screenshot:",NA
Creating cover AI,"Our AI enemy will just keep attacking the player as long as it is close enough to 
 the ship. However, this isn't very realistic; we'd like the enemy ship to attack for a 
 little bit but then duck and head for cover. We could have this hiding behavior be 
 based on a response to the player fighting back, but for this demo, we will make it a 
 constant value of 5 seconds; after attacking the player for 5 seconds, it will hide.
 To set this up, first we'll add an 
 isHidingbool
  variable to our behavior tree that is 
 set to true after 5 seconds of attacking. Create a new 
 constraint
  node under the 
 root
  
 parallel node with the 
 playerAttack != null && isHiding == false
  expression. This 
 node's children start when 
 playerAttack
  is valid and we are not already hiding 
 from the player. Add a 
 sequencer
  node under this constraint so it will go through  
 all of its children. The first child needs to be a new timer node with the 
 Seconds
  
 value of 
 5
  and 
 Returns
  set to 
 Success
 . Next, copy the 
 don't attack
  node and add  
 it below the timer so that the enemy won't attack as it's running to hide.",NA
Group attacks,"We spent 
 Chapter 4
 , 
 Crowd Chaos
 , and 
 Chapter 5
 , 
 Crowd Control
 , looking at group 
 behaviors, and we won't go through a full demo of attacking in groups here, but  
 we should discuss a few main points. With the demo in this chapter, we can add 
 more ships and they will attack in a fairly believable manner. However, there are 
 ways to make it better by considering other enemy positions.
 When the enemy ships choose a cover position, a simple method for a group is 
 to track each position if an enemy is already there. Then, when selecting a cover 
 position, each enemy won't go to one that is occupied, making the enemies more 
 diverse in their attacks.
 Similarly, when attacking the player, instead of just going as close as possible,  
 the attack pattern can be coordinated. Instead of just going directly to the player,  
 a set of points can be defined radially around the player, so enemies surround  
 and attack it. The key to these group behaviors is enemies taking into account  
 the behavior of other enemies.",NA
Summary,"In this chapter, we looked at attack AI, focusing on how to have enemies chase and 
 attack a player and then how to evade. These are basic attack behaviors and can be 
 extended to more complex and game-specific behaviors, and we discussed how to do 
 this when creating groups of enemies.
 In the next chapter, we will look at another special AI case, which is driving and cars. 
 However, instead of using a general-purpose AI system such as RAIN or React AI, 
 we will use an AI plugin specifically designed for cars that takes into account physics 
 to create realistic driving.",NA
Driving,"In this chapter, we will look at another specialized AI, driving. The other AI we  
 have looked at so far had pretty simple movement for characters. However, car 
 movement needs to take into account physics, and this makes driving AI more 
 complex, which is why we need an AI system specially designed for driving.  
 The AI driving system we will use for our demos is Smart Car AI. Smart Car  
 uses Unity's built-in navigation mesh system, so we will also take a look at it.
 In this chapter, you will learn about:
 • 
 Setting up the AI driving system
 • 
 Creating a Unity navigation mesh
 • 
 Using Smart Car to drive AI along a path
 • 
 Using Smart Car to drive and avoid obstacles",NA
An overview of driving,"When designing AI for our characters, one of the basic concepts is to have AI move 
 with the same rules as the player. If you ever played any old racing games, sometimes 
 the opponent cars wouldn't follow the same physics as the player, zooming along 
 unrealistically and therefore creating a bad player experience. So, it's important to  
 take car physics into account, including the shape of the car and four wheels, and  
 have the AI move in the same way as the player. This is the main reason for using  
 an AI system especially designed for autos and driving, instead of a general-purpose 
 game AI system we have been using such as RAIN.
 The driving system we'll use is Smart Car AI by BoneBreaker, which at the time of 
 writing this book is available in Unity Asset Store for $10. It takes into account physics 
 for the car and uses ray casting to sense the car's environment. It actually uses two 
 systems for navigation, which are Unity's built-in navigation system to determine 
 paths along a road and ray casting to sense obstacles and make adjustments to the car.",NA
Setting up a Smart Car vehicle,"As Smart Car uses a realistic car setup, there are many options to configure your 
 vehicle. To create a Smart Car vehicle, you'll need a car model with different models 
 for wheels and Unity wheel colliders setup on them. After adding a car model to 
 your scene, import the Smart Car 2.3 package and attach the 
 SmartAICar2_3.cs
  
 script from 
 SmartAICar2.3/Scripts
 . In the following screenshot, you can see some 
 of the Smart Car AI fields from the script:",NA
The Smart Car AI demo,"Now, we'll start setting up our driving demo that will have a car driving along a 
 road and avoiding obstacles.",NA
Setting up a Unity test scene,"Besides needing Smart Car, we'll need an environment for our AI cars to drive in. 
 We'll use Car Tutorial v1.3 that is made by Unity, which you can download for free 
 from the Asset Store. Import the project and open 
 TheTrack
  scene from the imported 
 Scenes
  folder. Next, add a car to the scene. The car prefab that comes with Car 
 Tutorial doesn't have the complete wheel physics setup, so you can configure it using 
 the steps in the last section or use the 
 EnemyAICar
  prefab from Smart Car. To make 
 the car work better with the 
 Tutorial
  scene, extend the rays a little, set 
 Wide
  and 
 Tight Ray Distance
  both to 
 40
  and 
 Long Ray Distance
  to 
 50
 . This keeps the car from 
 hitting obstacles when going too fast and missing tight turns. Once you have a car in 
 the scene configured for Smart Car, select the 
 Main_Camera
  object and set your car 
 to 
 Target
  for the 
 Car Camera
  script.",NA
Using Unity's built-in NavMesh system,"The next thing we need for our car demo is a navigation mesh. Smart Car uses 
 Unity's built-in system. Unity's system is similar to RAIN's but we haven't used 
 it much yet as unlike other plugins, Unity does not have a built-in behavior tree 
 system. Fortunately, we don't need behavior trees for our car demos, so navigate  
 to 
 Window
  | 
 Navigation
 .",NA
Setting up waypoints,"The final step to get a car driving is to set up waypoints for the car to follow. The 
 NavMesh we created defines the area that the car can navigate to and the waypoints 
 define the general path the car should follow. Create a new empty game object and 
 name it 
 Road Waypoints
 . Then, create a few more empties with the names 
 waypoint 
 1
 , 
 waypoint 2
 , 
 waypoint 3
 , and so on. Place the waypoint empties at different parts 
 along the road. Note that the NavMesh for the road will define how to get from one 
 waypoint to the next, so the line between waypoints doesn't have to go through 
 the road. For instance, you could have one waypoint at the start of a curve and the 
 second at the end and the car would still go around the curve through the waypoints. 
 In the Smart AICar script, set the empties to the 
 Waypoints
  field. After doing this, 
 the waypoints will be visualized in the edit or view to make adjusting their locations 
 easier. Refer to the following screenshot, and you can see how the visualization of 
 Smart car AI waypoints looks:",NA
Adding obstacles to driving,"As Smart Car uses a combination of a NavMesh and ray casting, you can add  
 objects dynamically to the scene, and as long as they have colliders attached  
 (and are on a car's 
 Recast Layers
 ), the car will avoid them. To try this out, add  
 a few large cylinders to the road, as shown in the following screenshot:
 Then, in the 
 Recast Layers
  dropdown for your car, make sure that it is set to ray cast 
 on the same layer as the obstacles. Select a 
 Cylinder
  object and in 
 Inspector
 , select 
 Add Layer
 . We need to create an obstacles layer, so select the dropdown and in the 
 first slot for 
 User Layer
 , set it to 
 obstacles
 .",NA
Additional features,"We've just completed creating a driving demo with a car avoiding obstacles, but 
 there are a few more things you can do with driving AI. We can add brake and drift 
 zones to help configure the general behavior of the car as it drives around the scene, 
 and we can integrate Smart Car with other AI systems such as RAIN.",NA
Adding brake zones and drift zones,"Another interesting thing you can do with Smart Car is define zones in the level to 
 either cause the car to brake and slow down or adjust the friction of the car to make it 
 drift. These are similar to the vector fields we saw in 
 Chapter 5
 , 
 Crowd Control
 , where 
 we place them in the level to affect the AI, and they aren't visible to the player but 
 are good to use for scripting level experiences. To create a brake or drift zone in your 
 game, add a cube to the game (go to 
 GameObject
  | 
 Create Other
  | 
 Cube
 ) and scale 
 and translate the area you want to tag in the level. In the Inspector window for the 
 cube, set its tag to 
 BrakeZone
  and for a drift zone set the tag to 
 DriftZone
 . Next, in 
 Box Collider
  for the cube, check 
 Is Trigger
  to true, so the car will get a message of 
 intersecting with a cube but won't stop and collide with it. Lastly, in the 
 Inspector
  
 window, uncheck 
 Mesh Renderer
  so that the cube is invisible in the game. Now when 
 you run the demo, if the car's speed is 
 25
  or over when it enters the brake zone, you 
 will see it slow down, and if its speed is 
 15
  or over, you will see it drift in the drift zone.",NA
Integrating with other AI systems,"In this demo, we've seen that setting up an AI car that drives around is easy to do with 
 Smart Car. However, what if your game isn't just a driving game but has car driving as 
 one part of the game? If that's the case, you can mix Smart Car with another AI system 
 easily. For RAIN integration, import the RAIN package into your scene. Then, go to 
 RAIN
  | 
 Create Entity
  and then select 
 Add Aspect: Visual Aspects
 . This creates an 
 entity with an aspect that can be sensed by additional RAIN AI entities you can create 
 in the scene, making the car just one part of a larger AI system.",NA
Summary,"In this chapter, we looked at Smart Car, an AI system specifically for car AI.  
 We discussed why automotive AI is different than most AIs because of the physics 
 involved, and we also saw how to set up a car model, create a path for the car, and 
 add obstacles. We also looked at using Unity's built-in navigation mesh system, 
 instead of using third-party ones such as RAIN, and discussed additional features  
 for car AI and how we can integrate it with another AI system such as RAIN.
 In the next two chapters, we will look at how to combine character animations 
 and AI to give them a realistic appearance and learn more about creating complex 
 navigation meshes for different AIs.",NA
Animation and AI,"Part of having realistic game AI is having characters play animations at times 
 appropriate to the AI character's state. In this chapter, we will look at animation  
 and how it is integrated with RAIN, both with Unity's legacy animation system  
 and Mecanim.
 In this chapter, you will learn about the following:
 • 
 Why animation management is an important part of game AI
 • 
 Managing animation with behavior trees and Unity's legacy animation
 • 
 Managing animation by AI with Unity's Mecanim animation system",NA
An overview of animation,"When you think about game AI, first you probably think about things such as 
 creating virtual minds and making characters ""think"". When I first started learning 
 about game AI years ago, I didn't think animation was really important for game AI 
 since it wasn't part of creating a virtual mind. But then I attended some AI sessions 
 at the Game Developers Conference and found out that one of the most discussed 
 topics in AI was integrating AI with animation systems; this is when I realized it 
 really is an important part of game AI. This makes sense since game AI is about 
 modeling real thinking instead of focusing on giving characters the appearance 
 of thinking, so having the characters play animations that match their state is 
 important. We can think of animations as just a visual depiction of the current  
 state of the character.
 The method we'll look at for integrating animations with the AI is RAIN's  
 animation integration with Unity. RAIN has an 
 Animation
  tab (with an icon  
 of a running man) in its AIRig. In this tab, animation clips can be configured  
 using one of two RAIN animators.",NA
The AI animation demo,"As the first step, create a new scene and add a plane to it with a scale of 
 X
  equal to 10, 
 Y
  equal to 1, and 
 Z
  equal to 10 to give us a floor where characters can walk around 
 (and if you want, change its material so it's not white). Then, add the 
 penelope
  model 
 to your scene that's at 
 Assets/Objects/penelopeFX
 . Next, we'll do our basic RAIN 
 setup and add a navigation mesh by going to 
 RAIN
  | 
 Create NavMesh
 . Make sure 
 the navigation mesh will cover the floor, so change its 
 Size
  to 
 100
  and then generate 
 the mesh. Next, create a waypoint route by going to 
 RAIN
  | 
 Create Waypoint Route
 , 
 rename it 
 PenelopeRoute
 , and add a few points in front of the 
 penelope
  model for  
 the character to walk. Lastly, add a RAIN AI object by selecting 
 penelope
  and going  
 to 
 RAIN
  | 
 Create AI
 . Your screen should look similar to the following screenshot:
 The scene for the AI animation demo",NA
Configuring RAIN animations,"To configure animation for Penelope on her RAIN menu, select the 
 Animation
  
 tab. (Again, this is the tab with a little figure running on it.) RAIN supports two 
 animation systems: 
 BasicAnimator
  and 
 MecanimAnimator
 . Since the Penelope 
 character doesn't use Mecanim, leave the animator as basic. The 
 Add Animation 
 State
  dropdown will then be automatically populated with the different animation 
 clips available. Choose the animation states 
 run
  and 
 idle
 .",NA
Using the animate node,"Now we need to configure the behavior tree to play the animations. As our first 
 step, let's get Penelope running. Right-click on the 
 root
  node in the 
 WalkPenelope
  
 behavior tree and go to 
 Switch To Parallel
  and then rename the node to 
 parallel
 . 
 By being parallel, we can add an animate node and have it update the animation at 
 the same time as the patrol node is being executed. So add an animate node, rename 
 it to 
 animate run
 , and set 
 Animation State
  to 
 run
 . Your setting should look like the 
 following screenshot:
 If you run the demo now, you'll see the Penelope character perform the animation 
 while it's moving. But the timing seems a little off. Change the moving speed of 
 the 
 move
  node to 
 3
 . Then slow down the animation a little by going back to the 
 Animation
  tab and setting the 
 Speed
  field to 
 0.75
 . If you run the demo now, the 
 animation is a bit better. But when Penelope gets to the end of the route, the run 
 animation just keeps on playing. To fix this, let's track a variable in the memory 
 called 
 stopped
 . When it is false, the run animation will play as it does now,  
 and when 
 stopped
  is 
 true
 , an idle animation will be played instead.
 The first thing you need to do to fix the animation's issues with ending is add a 
 selector
  node as the new root. Remember, the 
 selector
  node is used for the 
 if
 /
 else
  
 logic, so we'll use it to switch between its running state and playing an idle animation. 
 Add a 
 constraint
  node under 
 selector
  and rename it to 
 is stopped
 . Set 
 Constraint
  
 to 
 stopped == false
 . Then add a new animate node under the 
 selector
  node, name it 
 animate idle
 , and set 
 Animation State
  to 
 idle
 . This will only start running when 
 stopped
  is true, so we need to add an expression node to run the 
 expression
  node 
 after our moving is done. Make a new 
 sequencer
  node and make it the parent of 
 waypointpatrol
 . Then add an expression node under the 
 sequencer
  node with an 
 Expression
  value of 
 stopped = true
 .",NA
RAIN and the Mecanim demo,"Mecanim is Unity's latest animation system that's able to play animations on 
 arbitrary characters. We won't go into detail on how Mecanim works and instead 
 focus just on RAIN's usage.
 For this demo, we will use a character already set up for Mecanim from Unity's 
 sample. If you haven't already done so, download and import Unity's Mecanim 
 demo, 
 Mecanim Example Scenes v1.0
 , which is free on the Asset Store. Add the 
 teddy bear character from 
 Character/Teddy2/TeddyBar.fbx
  to your scene. Then, 
 in the 
 Animator
  component for Teddy, set the 
 Controller
  field to 
 IdleRunJump
   
 from 
 Controllers
 . Then, add a RAIN AIRig to Teddy by going to 
 RAIN
  | 
 Create  
 AI
 . We'll have Teddy walk on a different route, so create a new waypoint patrol 
 route and name it 
 TeddyRoute
 . Your scene should look like this:
 In the preceding screenshot, you can see Teddy with a new path set up in  
 your scene.
 Next, we need to configure animations for Teddy. Go to the 
 Animation
  tab in 
 Teddy's RAIN AIRig and select 
 MecanimAnimator
 . Then, we need to add states 
 for running and idling. Select 
 Base Layer.Run
  and 
 Base Layer.Idle
  from 
 Add 
 Animation State
 .",NA
Additional Mecanim nodes,"Besides using the animate node for Mecanim, RAIN has additional nodes specifically 
 for Mecanim, mostly useful in special cases. The nodes are as follows:
 • 
 Mecanim IK
 : This node is used to modify the inverse kinematics on part  
 of a model
 • 
 Mecanim State
 : This node is used to check the animation controller state
 • 
 Mecanim Parameter
 : This node is used to change a Mecanim parameter
 These are less-used nodes but are good to know.",NA
Summary,"In this chapter, we looked at how to integrate animation with our AI. We saw how 
 to use RAIN's animate node to change the character animation from its behavior tree 
 with both Unity's legacy animation system and Mecanim. In the next chapter, we 
 will go back to discussing character movement across a scene. We will look at more 
 advanced uses of navigation meshes and how to create them in more detail to give 
 our characters better movement.",NA
Advanced NavMesh ,NA,NA
Generation,"Navigation mesh generation is one of the most important topics in game AI. We  
 have been using navigation meshes in almost all the chapters in this book, but 
 haven't looked at them in detail. In this chapter, we will provide a more detailed 
 overview of navigation meshes and look at the algorithm used to generate them. 
 Then, we'll look at different options of customizing our navigation meshes better.
 In this chapter, you will learn about:
 • 
 The working of navigation mesh generation and the algorithm behind it
 • 
 Advanced options for customizing navigation meshes
 • 
 Creating advanced navigation meshes with RAIN",NA
An overview of a NavMesh,"To use navigation meshes effectively, also referred to as 
 NavMeshes
 , the first  
 things we need to know are what exactly navigation meshes are and how they are 
 created. A navigation mesh is a definition of the area an AI character can travel to 
 in a level. It is a mesh, but it is not intended to be rendered or seen by the player; 
 instead, it is used by the AI system. A NavMesh usually does not cover all the area  
 in a level (if it did, we wouldn't need one) as it's just the area a character can walk. 
 The mesh is also almost always a simplified version of the geometry. For instance, 
 you could have a cave floor in a game with thousands of polygons along the bottom 
 that show different details in the rock; however, for the navigation mesh, the areas 
 would just be a handful of very large polygons that give a simplified view of the 
 level. The purpose of a navigation mesh is to provide this simplified representation 
 to the rest of the AI system as a way to find a path between two points on a level  
 for a character. This is its purpose; let's discuss how they are created.",NA
Advanced NavMesh parameters,"Now that we know how navigation mesh generations works, let's look at the 
 different parameters you can set to generate them in more detail.
 We'll look at how to do these parameters with RAIN using the following steps:
 1. Open one of our previous scenes or create a new one with a floor and  
 some blocks for walls.
 2. Then, go to 
 RAIN
  | 
 Create NavMesh
 . Also, right-click on the 
 RAIN
  menu  
 and choose 
 Show Advanced Settings
 . The setup should look something  
 like the following screenshot:",NA
Culling areas,"Being able to set up areas as walkable or not is an important part of creating a level. 
 To demo this, let's divide the level into two parts and create a bridge between the 
 two. Take our demo and duplicate the floor and pull it down. Then transform one  
 of the walls to a bridge. Then, add two other pieces of geometry to mark areas that 
 are dangerous to walk on, like lava.",NA
Multiple navigation meshes,"So far, we have only looked at setting up a single navigation mesh in a scene,  
 but navigation meshes are designed to be per character and not just one for the  
 entire scene. We need multiple navigation meshes, but there is no field to directly  
 set which navigation mesh to use for a character. Instead, RAIN uses a field called 
 graph tags
  to correlate meshes with characters. To see how this works, let's add a 
 second bridge to our scene that is larger and a second ship with double the scale. 
 Here is an example setup:
 This is a demo scene setup with an additional larger ship and larger bridge. 
 Regenerating the mesh gives us a path over both bridges:",NA
Summary,"Navigation meshes are an important part of game AI. In this chapter, we looked at 
 the different parameters to customize navigation meshes. We looked at things such as 
 setting the character size and walkable slopes and discussed the importance of the cell 
 size parameter. We then saw how to customize our mesh by tagging different areas as 
 not walkable and how to set up multiple navigation meshes for different characters.
 We now have all the essential skills we need to create AI in Unity. We've seen how to 
 have a character move, navigate, and sense other characters in our game scenes as well 
 as how to set up behavior trees to make decisions and integrate animation. We also 
 looked at different AI use cases, such as crowds, driving, and had our characters attack 
 and change behavior based on game events. This covers a lot about AI, but game AI 
 is a huge and much studied topic and there is much more to learn. By doing some 
 searching, you'll find that there are many online articles, textbooks, and conference 
 talks that you can study to make even more advanced AI.",NA
Index,NA,NA
A,"actions, RAIN
 Animate and Mechanism  31
 Choose patrol path and Choose path  
 waypoints  30
 Custom action  31
 Detect  31
 Evaluate expression  31
 Play audio  31
 Wait for timer  31
 Yield  31
 additional features, driving AI
 about  113
 brake zones, adding  113
 drift zones, adding  113
 other AI systems, integrating with  114
 additional Mecanim nodes
 about  124
 Mecanim IK  124
 Mecanim Parameter  124
 Mecanim State  124
 advanced audio sensor settings  70
 advanced NavMesh parameters  128-133
 advanced visual sensor settings  69
 AI adapt
 about  81
 overview  81, 82
 AI animation demo
 about  116, 117
 additional Mecanim nodes  124
 animate node, using  119, 120
 Mecanim demo  121-124
 RAIN animations, configuring  117, 118
 RAIN demo  121-124
 AI solutions
 comparing  16, 17
 AI systems
 integrating with  114
 animate node
 using  119, 120
 animation
 integrating, with AI  115
 overview  115, 116
 animation parameters
 Animation Clip  118
 Fade in Time  118
 Fade Out Time  118
 State Name  118
 Wrap Mode  118
 ANT-Op  64, 65
 areas
 culling  133-135
 aspects
 about  69
 setting up, in RAIN  72, 73
 attack AI  93
 attack demo  94, 95
 audio sensor
 properties  70
 Avatar  58",NA
B,"behavior tree
 about  8, 30
 building, in React AI  49
 demo, creating  32-44
 Boids  55
 brake zones
 adding  113",NA
C,"center of mass (COM)  107
 Character Controller  10
 chase and attack demo  96-99
 cover AI
 creating  99-102
 crowd chaos
 overview  45
 crowd control  55, 56
 custom wander scripts, RAIN AI  52, 53",NA
D,"decision nodes
 Constraint  32
 Custom decision  32
 Iterator  31
 Parallel  31
 Priority  31
 Selector  31
 Sequential  31
 demo, behavior tree
 creating  32-44
 demo, RAIN
 about  84, 85
 game events, reacting to  85-87
 large game events, adding  90, 91
 motor, using  87-89
 drift zones
 adding  113
 driving
 about  105, 106
 obstacles, adding to  111-113",NA
E,Execute method  41,NA
F,"Fame Crowd Simulation API
 about  56
 group, setting up  59-61
 obstacles, adding to  61
 scene, setting up with  57, 58
 vector fields, adding to  63
 Fame scene setup
 with Crowd Manager object  58
 Finite State Machines (FSMs)  30
 flocking and steering systems
 URL  56
 FlockMemberScript  58
 Flock Type  58
 found variable  53",NA
G,"Go method  11
 graph tags  136
 group
 setting up  59-61
 group attacks  102",NA
H,HangAround function  48,NA
M,"Mecanim demo  121-124
 Mecanim Example Scenes v1.0  116, 121
 motors
 fields  83
 types  82
 MoveToTarget function  48
 multiple navigation meshes  136-139",NA
N,"Navigation tab, built-in NavMesh system
 Bake  109
 Layers  109
 Object  109
 navigation targets
 setting up  100
 NavMesh
 about  8, 127, 128
 need for  127, 128
 NavMeshAgent  110
 NavMesh parameters
 Cell Size  129
 Max Slope  132",NA
O,"obstacles
 adding, to driving  111-113
 adding, to Fame Crowd Simulation API  61
 setup, for ship group  62",NA
P,"pathfinding  5, 6
 patrolling  19
 Penelope Complete Project v1.1  116",NA
Q,"Quick Path AI  6-8, 17-21",NA
R,"RAIN AI
 about  12-17, 23-27, 50-52
 aspects, setting up  72, 73
 basic motor  82
 character controller  82
 custom wander scripts  52, 53
 demo  84, 85
 Mecanim controller  82
 motors  82
 NavMesh parameters, using  128, 129
 NPCs, putting in RAIN demo  54
 senses  68
 senses, using with  71, 72
 visual sensor, setting up  74, 75
 RAIN animations
 configuring  117, 118
 RAIN demo
 about  121-124
 NPCs, putting in  54
 RAIN node types  30, 31
 RAIN sensor filters  79
 Reactable  10
 React AI
 about  8-11, 17, 21-23, 46, 91, 92
 behavior trees, building  49
 importing, from Asset Store  9-11
 scene, setting up with  46-48
 wandering characters, setting up with  50
 Recast
 about  128
 URL  128
 Rival Theory site
 URL  12",NA
S,"scene
 setting up, with Fame Crowd  
 Simulation API  57, 58
 setting up, with React AI  46-48
 senses
 setting up  68
 senses, using with RAIN
 about  71
 activities, changing  75-78
 aspects, setting up in RAIN  72, 73
 RAIN sensor filters  79
 visual sensor, setting up in RAIN  74, 75
 sensing
 overview  67-69
 Smart Car AI demo
 about  107
 built-in NavMesh system, using  108-110
 obstacles, adding to driving  111-113
 Unity test scene, setting up  107, 108
 waypoints, setting up  110, 111
 Smart Car vehicle
 setting up  106, 107
 Start method  10
 steering algorithms
 implementing  56",NA
T,"TagOptions  47
 tasks  30",NA
U,"Unity test scene
 setting up  107, 108",NA
V,"vector fields
 adding, to Fame Crowd Simulation API  63
 visual sensor
 properties  70
 setting up, in RAIN  74, 75
 visual sensor settings
 viewing  69",NA
W,"wandering characters
 setting up, with React AI  50
 waypoints
 setting up  110, 111",NA
Thank you for buying ,NA,NA
 ,NA,NA
Unity AI Programming Essentials,NA,NA
About Packt Publishing,"Packt, pronounced 'packed', published its first book, 
 Mastering phpMyAdmin for Effective 
 MySQL Management
 , in April 2004, and subsequently continued to specialize in publishing 
 highly focused books on specific technologies and solutions.
 Our books and publications share the experiences of your fellow IT professionals in adapting 
 and customizing today's systems, applications, and frameworks. Our solution-based books 
 give you the knowledge and power to customize the software and technologies you're using 
 to get the job done. Packt books are more specific and less general than the IT books you have 
 seen in the past. Our unique business model allows us to bring you more focused information, 
 giving you more of what you need to know, and less of what you don't.
 Packt is a modern yet unique publishing company that focuses on producing quality,  
 cutting-edge books for communities of developers, administrators, and newbies alike.  
 For more information, please visit our website at 
 www.packtpub.com
 .",NA
Writing for Packt,"We welcome all inquiries from people who are interested in authoring. Book proposals should 
 be sent to 
 author@packtpub.com
 . If your book idea is still at an early stage and you would 
 like to discuss it first before writing a formal book proposal, then please contact us; one of our 
 commissioning editors will get in touch with you. 
 We're not just looking for published authors; if you have strong technical skills but no writing 
 experience, our experienced editors can help you develop a writing career, or simply get some 
 additional reward for your expertise.",NA
Unity 4.x Game AI Programming,"ISBN:  978-1-84969-340-0            Paperback: 232 pages
 Learn and implement game AI in Unity3D with a lot 
 of sample projects and next-generation techniques to 
 use in your Unity3D projects
 1. 
 A practical guide with step-by-step instructions 
 and example projects to learn Unity3D scripting.
 2. 
 Learn pathfinding using A* algorithms as well 
 as Unity3D pro features and navigation graphs.
 3. 
 Implement finite state machines (FSMs),  
 path following, and steering algorithms.",NA
Mastering Unity 2D Game ,NA,NA
Development,"ISBN: 978-1-84969-734-7            Paperback: 474 pages
 Become an expert in Unity3D's new 2D system,  
 and then join in the adventure to build an RPG  
 game framework!
 1. 
 Learn the advanced features of Unity 2D  
 to change and customize games to suit  
 your needs.
 2. 
 Discover tips and tricks for Unity2D's  
 new toolset.
 3. 
 Understand scripting, deployment, and 
 platform integration with an example at  
 each step.
 Please check 
 www.PacktPub.com
  for information on our titles",NA
Unity 4 Game Development ,NA,NA
HOTSHOT,"ISBN: 978-1-84969-558-9             Paperback: 466 pages
 Develop spectacular gaming content by exploring 
 and utilizing Unity 4
 1. 
 Understand the new 2D Sprite and Immediate 
 Mode GUI system (OnGUI()/GUI class) in Unity 
 4, and the difference between 2D and 3D worlds, 
 with clear instruction and examples.
 2. 
 Learn about Mecanim System, AI 
 programming, editor script, and Character 
 Controller programming including scripting 
 and how to adapt it to your needs.
 3. 
 Create a Menu for an RPG Game—Add 
 Powerups, Weapons, and Armor.",NA
Unity 4.x Game Development by ,NA,NA
Example: Beginner's Guide,"ISBN: 978-1-84969-526-8            Paperback: 572 pages
 A seat-of-your-pants manual for building fun, groovy 
 little games quickly with Unity 4.x
 1. 
 Learn the basics of the Unity 3D game  
 engine by building five small, functional  
 game projects.
 2. 
 Explore simplification and iteration  
 techniques that will make you more  
 successful as a game developer.
 3. 
 Take Unity for a spin with a refreshingly 
 humorous approach to technical manuals.
 Please check 
 www.PacktPub.com
  for information on our titles",NA
